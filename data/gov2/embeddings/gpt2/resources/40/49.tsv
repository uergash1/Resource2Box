id	content
GX267-86-1128545	"SVG Topofinder II uses SVG both to display data and to provide the graphical user interface (GUI) for mapping functions. SVG, or Scalable Vector Graphics, is an XML standard for displaying visual information. It is similar to HTML, but like PostScript, is a much more powerful way of doing screen layout. Designers and developers have much more control and flexibility with SVG.  http://nris.state.mt.us/topofinder2 Zoom in You can either click anywhere on the map or click and drag to draw a rectangle in any direction. Release the mouse button to zoom in.  Toggling between topos and photos Use the radio buttons on the right side of the map to toggle between topo maps (DRGs) or aerial photos (DOQs). Sometimes you can't see images when the DOQ option is selected. Either you are not zoomed in far enough or there is no coverage for that area. There is a checkbox for adding township and range (PLSS) to the map when DOQs are selected.  SVG is also scriptable (using Javascript), which allows us to create tools and behaviors similar to those found in traditional desktop applications. Because there are SVG viewer plug-ins for web browsers, such as Internet Explorer, we are able to deliver this functionality through a familiar and widely used application. Topofinder II requires Adobe's SVG Viewer plug-in. You can find out more by visiting http://nris.state.mt.us/svg/gettingstarted.htm  Zoom out Select the zoom out button and click on the map to zoom out.  Query Pan Select the pan button. Click and drag on the map in any direction to pan to a new location You can select one or more feature types and get a list of all the places in the state of those types.  Clicking the button will pop up a window with a menu of various ways to locate places or areas on the map. Named Features  Clicking on an item in the list will display it on the map.  Full Extent Clicking on this allows you to return to the full extent for Montana. You out will the can also type in a name withselecting a feature type. This bring up a list of all places in state.  Selection Rectangle This works much like the zoom in tool. Clicking and dragging with it will highlight quads on the map and will pop up a window with a list of quads for downloading.  Selecting both a feature type and entering a name will narrow your search considerably.  Map Name Search (24K) Locate a quad by name. Click on a letter to find quads beginning with that letter. Select from the pulldown menu and click ""Locate"" to display the quad on the map.  Navigation palette Click on the navigation button to bring up the navigation palette. You can drag the palette around on the screen to reposition it. Click on the ""X"" to close the palette. You can use the navigation palette to move to another part of the map, either by dragging the red box or using the arrow buttons. (Shiftclicking a button will move 9X farther). Lat/Lon Search (Decimal) Enter the decimal coordinates for a location. Hit ""Locate"" and it will be displayed on the map.  Location Move mouse over map to get coordinates in State Plane (NAD 83) and Latitude/Longitude  Measure Click on the map to start measuring. You can continue clicking around the map to find a total distance between several points. To start over, Alt-Click.  Scale bar Click on the scale bar button to bring up the scale bar. You can drag the palette around on the screen to reposition it. Click on the ""X"" to close the palette."
GX246-58-11423708	"DHS    home  |  Web  |  Webmasters' handbook  | Tools   & tips           Search the handbook        Tools & tips   Code snippets (redirects, date)     Image       libraries     Metadata       samples     Optimizing         graphics for the Web    XML     Code snippets   Here are some common bits of useful code. (Please contact the Communication   Office to contribute to   this section):   Redirects:   To redirect people from the old DHS site to the new one, put this code in   your metadata:       <META http-equiv=""refresh"" content=""0;       URL=http://www.dhs.state.or.us/(your topic location)/"">     The         number ""0; in the code above should be replaced with the number         of seconds you decide the user should wait to get to the new page. If         you         want the user to go to the new site immediately, you would use ""0;         however, if you want the user to have time to read your redirect and         find out that he/she should bookmark the new page, 20 seconds or so allows         a little more reading and comprehension time .   You can use a sentence like:       The Oregon Department       of Human Service site has moved. Our new home page is at  http://www.dhs.state.or.us .       The page that you have selected is now located at http://www.dhs.state.or.us/xxxx.  (xxxx       would be where you would complete the URL to get the user to your new page)  You       may click on this link to go there now, or be automatically redirected       to our new page in 20 seconds.     We suggest you bookmark       the new page. This redirect will expire December 31, 2003.      Today's date:       <SCRIPT language=""JavaScript"">  <!---      document.write(dayNames[day] + "", "" + monthNames[month] + "" "" +     date + "", "" + year)      //--->  </SCRIPT>     Note: be aware that later versions of Netscape (such as version 7.01) do   not read JavaScript correctly. You may end up with the wrong date on all   pages using this code. It might be advisable to use this script sparingly if   at all.   See also  HTML tutorial links     Back to top   Image libraries   Graphics for the Web site are available from the following download pages:      DHS logos     Navigation icons  (for the navigation      table)    Headers  (for the top     of page)      Graphic elements  (arrows,      bullets, dividers, bars, etc.)         Back to top   Metadata sample   Here's a sample of the minimum metadata you should have on each page to allow   people using our State Library search engine, FindOR, locate your material:     <meta name=""description"" content=""Guest Opinion: Report helps community leaders   achieve goals"">  <meta name=""originatorJurisdiction"" content=""State of Oregon"">  <meta name=""createDate"" content=""2002/04/09"">  <meta name=""dateofLastModification"" content=""2002/04/12"">  <meta name=""keywords"" content=""DHS guest opinion, DHS outcomes, DHS goals, DHS accountability, DHS performance measures, state managers, county commissioners, community leaders"">  <meta name=""subjects"" content=""Social and Family Issues and Programs"">   Please note, in order to allow the state's government locator feature to find   your page, you should use the  metadata   specifications  provided by the State Library on their FindOR site, especially   noting their  subject   tree . The State Library also offers metatag training (email FindOR trainer  Jey   Wann . GroupWise users: jey.a.wenn@state.or.us).  A word on dates:  Be careful with the content format of the date related   tags. Dates are expressed as YYYY/MM/DD.   Examples:   <meta name=""createDate"" content=""2001/11/01"">  <meta name=""dateofLastModification"" content=""2003/05/10"">    Note:   Unless you have the dates in YYYY/MM/DD format, a user using the correct date   format to search for a file in FindOR won't find your document.     Back to top   Optimizing graphics for the Web   When creating images for the Web, keep file size in mind. Large graphic files   take a long time for users with the minimum 28-baud modems to download. Waiting   too long for pages to load can make users frustrated with the site before they've   had a chance to really explore it.   To avoid this, produce illustrations and photos with the minimum   resolution, size and color depth necessary. You can do this manually, but programs   like  ImageReady  (bundled with  Photoshop)  can be used to automate   the process of minimizing your graphic file sizes.   Web page file size limit   Try to keep your Web page no larger than 64K, including all graphics. This   way, viewers with older modems can see your pages and get to your information   without waiting around too long for pages to load. 64K may seem like an impracticably   small size, but there are workarounds if you have pages that really need lots   of graphics.   For example, if you have large detailed graphic such as maps, rather than   slowing down the loading of your entire page, you could show tiny snapshot   of the maps with a link to see each one in a larger size on a separate page.   This way, the user has a choice whether or not to click for a more detailed   view, and will probably be willing to wait if it's exactly the information   he or she needs.   Another way to make a graphic load faster is to specify the height and width   in the HTML code (example:  <img   src=""art/masthead.gif"" height=""38"" width=""193"" border=""0"" alt=""Currents   Online""> ). By specifying the height and width of the graphic,   the page will load with the proper amount of space ""reserved"" for   each graphic prior to displaying the graphic. This makes for a faster load   and also keeps the page layout from sizing and resizing itself in an annoying   fashion as the viewer waits for it to display.     Back to top   Graphics file formats     There are two choices of Web graphics file formats in popular use,   *.jpg (Joint Photographic Experts Group) and *.gif (Graphics Interchange Format).   There   will hopefully   be more formats to use in the future (like the much-anticipated  Portable   Network Graphics  [PNG] format and  Scalable   Vector Graphics  [SVG] format).   Things to remember about both file formats:  Either file format   works for image maps (graphics with clickable areas). Note: There is an excellent  NCSA   tutorial  for making image maps.   Both formats compress your image and lose data that can't be recovered.   To avoid problems with this limitation, keep your master graphic in *.PSD   format (if you've used Photoshop with multiple layers) or in *.TIF format   (if the graphic is all on one layer). This way you always have a full-resolution   master to go back to when you need to make corrections or revisions.     Back to top   GIF file format   You should use the GIF format for most of your Web graphics. Use the GIF format   for:       Simple illustrations, logos, diagrams and charts     Graphic elements, like arrows and bars     Images that need a transparent background (called the GIF89a format. In  Photoshop,  you will need the GIF89a plug-in to create these)     Animated images (called the GIF89 format)       Things to remember about GIFs:  A GIF file contains only 256   colors (also called ""8-bit"" or ""indexed"" color). You really   have only 216 colors (also called ""Web safe"" or ""browser safe"" colors)   if you are building for both Mac and PC browsers with old 8-bit video cards   (see  ""browser friendly"" palette ).   However, since such cards have been obsolete for 5 years now, it is not as   important as it once was to stick to this palette.   The GIF file format also allows one of the 256 colors to be transparent in   what's called the GIF89a format. A transparent channel allows you to create   Web graphics that can be used on a colored background on a Web page. Note:   To create these graphics, make the background layer in  Photoshop  approximately   the same color as your Web background, so when you make the background transparent,   the image will be anti-aliased to the right color. (We've all seen graphics   with fuzzy halos on Web pages, and that's because the graphic artist who   created them didn't realize this, or else the HTML coder changed the background   color on the Web site without asking for a new graphic anti-aliased to the   new color.)   Images with lots of tiny detail (like the DHS logo) may need to be saved at   300 dpi or greater, but try to restrict most of your GIF images to 72 dpi to   save on file size. After all, most monitors only display at approximately that   resolution, so your viewer won't be missing much.    Tip:  Use   the ""interlace"" option when saving GIFs in  Photoshop.  That   way the image will begin building on the Web page and slowly evolve, instead   of showing a ""loading graphic"" symbol until the image is downloaded.     Back to top   JPEG file format   Use the JPEG file format for:       Photos, either black-and-white or color     Images for the Web that have lots of detail     Images that don't work well as GIFs, like images with many colors or gradiants     Things to remember about JPGs:  JPEGs, named after the committee   that invented it, was designed for compressing full-color or gray-scale images,   mainly photographic. Unlike GIFs, which are limited to 256 colors, JPEGs can   contain millions of colors. Because you can select from 12 degrees of compression,   you can moderate the file size and control degree of detail you are willing   to lose. Try to restrict JPG images to 72 dpi; in most cases, it will be sufficient.   Note you can't make transparent JPGs; if you need a transparent graphic,   you will have to make it a GIF. ( More   about JPEGS .)     Back to top   PNG: Web graphic file format of the future   PNG stands for ""Portable Network Graphic."" PNG is a file format   for raster images, like GIF and JPG, but the compression is ""lossless"" instead   of ""lossy""; in other words, no data is lost when the graphic is saved   as a PNG. It also can contain much more than 256 colors (8-bit indexed color),   unlike GIF. It supports thousands of grays (16-bit grayscale) and millions   of colors (24- and 36-bit truecolor).   PNG came about around a number of years ago when it looked like CompuServe   was going to charge for the use of its proprietary GIF format. Programmers   got   busy with   an alternative format for GIFs, and improved it both in compression capabilities   and number of colors. PNG was approved by the  WWW   Consortium  in 1996, but hasn't had widespread graphics application   support or browser support yet (for example, Netscape 7.0 and lower don't   support it).    PNG can also substitute nicely for TIF format as well. It handles indexed-color,   grayscale, and truecolor images equally well, and allows transparent images.   It doesn't offer animated images or photos yet, so it isn't ready   to replace animated GIFs or JPGs completely.   PNG has competition, however, Seeing how unpopular it's decision to charge   royalties for the GIF format was with users, CompuServe retracted its move   in that direction. Instead, it started developing a new compressed graphics   format, called GIF24. GIF24 was supposed to be a public domain format that   can support 24-bit images (unlike the current 8-bit limit on GIFs). As of this   writing, however, it looks like CompuServe is going to support the PNG file   format instead (source:  WWW   Consortium PNG Web site ).    SVG stands for ""Scalable Vector Graphic."" SVG is an XML-based graphics   language from  W3C specifications .   SVGs are vector images that scale well in a variety of displays, from desktop   monitors to PDAs to wireless phones.    SVG is text-based, so it is accessible to screen readers. It was developed   collaboratively ( Adobe  [which   has a  downloadable   SVG viewer ] and  Sun ,   among others).     Back to top   Optimizing graphics references       Boutell.com    www.boutell.com     Common Internet File       Formats  (archival)    www.matisse.net/files/formats.html       Internet FAQ Consortium    www.faqs.org     Lynda.com    www.lynda.com         World Wide Web Consortium (W3C)      www.w3c.org           Go   back:  see previous section,  Templates           (Text-only version of entire Webmasters' handbook)       Back to top             If you have questions about DHS, problems getting DHS services, or         comments about this site, email us:  DHS         Information . DHS Groupwise users, address email to dhs.info@state.or.us.         ( About this site ) ( Disclaimer )                                                                               Oregon Department of Human Services    Communication Office    500 Summer St. NE E25, Salem, OR 97301-1098    Phone: (503) 945-5944    Fax: (503) 378-2897    TTY: (503) 947-5330"
GX033-91-11385017	"Previous Table of Contents Next         Close Window          NAEP Data Tool Tutorial  Standard Graphic Presentations Flash version       The NAEP Data Tool allows you to display data in both tabular and graphic form. The graphics options use  scalable vector graphics technology (SVG)  and require the use of an SVG viewer such as the Adobe SVG Viewer 3.0 (or above). The graphics options are currently available for the following types of data:       Single-year bar graphs for a particular state/jurisdiction;    Multiple-year line chart for a particular state/jurisdiction;    Single-year Cross-State comparisons (comparing one or more states to each other or the nation for a particular variable);    Multiple-year cross-state comparisons (comparing a variable between two or more states across years).      To see either the single-year bar graphs or the multiple-year line chart, click on ""Show Graphic"" in the right-hand side above the table.        Once you have selected the ""Show Graphic"" option, you will see a ""Graphics Options"" box at the top of your screen that will allow you to dynamically generate new graphics based on the following:       Data Type (Average Scale Score or Row Percentage)    Year (if applicable)    Subgroup (if applicable)    Display (color or grayscale).      [Note: you can add/delete years or subgroups by selecting the ""User Options"" pull-down menu.]       To generate an SVG dynamic map of the United States that compares results of selected states/jurisdictions, you must perform the following steps:      Generate a table of data with desired variables.   Add the states/jurisdictions you are interested in comparing by selecting the ""User Options"" pull-down menu.   Once your data table has been generated, run a significance test using ""Check Differences"" within the ""User Options"" pull-down menu.   Click on the ""Show Graphic"" option after your significance test results have been computed. This will give you your SVG map of the United States.      Click on any of the pre-selected states/jurisdictions to make it the ""focal"" state/jurisdiction.    Printing/Saving the SVG images    You can easily cut and paste any of the SVG images into software packages such as Microsoft Word, Powerpoint or Excel. To do this, right click on the SVG image and select ""Copy SVG."" Then go to your desired application and select ""Edit/Paste Special"" and select ""Bitmap.""                   Previous Table of Contents Next         Close Window"
GX025-53-13533381	"Previous Table of Contents Next         Close Window        NAEP Data Tool Tutorial  Standard Graphic Presentations       The NAEP Data Tool allows you to display data in both tabular and graphic form. The graphics options use  scalable vector graphics technology (SVG)  and require the use of an SVG viewer such as the Adobe SVG Viewer 3.0 (or above). The graphics options are currently available for the following types of data:       Single-year bar graphs for a particular          state/jurisdiction;             Multiple-year line chart for a particular          state/jurisdiction;             A map of single-year cross-state comparisons (comparing          one or more states to each other or the nation for a particular          variable);             A map of multiple-year cross-state comparisons (comparing a variable between two or more states across years).      To see either the single-year bar graphs or the        multiple-year line chart, click on ""Show Graphic"" in the right-hand side above the table.  (Click on ""SVG Viewer Required"" if you need more information about how to view these graphics.)        Once you have selected the ""Show Graphic"" option, you will see a ""Graphics Options"" box at the top of your screen that will allow you to dynamically generate new graphics based on the following:       Data Type (Average Scale Score or secondary statistic)             Year (if applicable)             Subgroup (if applicable)             Display Values (shows each statistic as part of the graph).      [Note: you can add/delete years or subgroups by selecting the ""User Options"" pull-down menu.]    Printing/Saving the SVG images    You can easily cut and paste any of the SVG images into software packages such as Microsoft Word, Powerpoint or Excel. To do this, right click on the SVG image and select ""Copy SVG."" Then go to your desired application and select ""Edit/Paste Special"" and select ""Bitmap"" (or ""Device-Independent Bitmap"").    Continue on to learn how to generate a dynamic SVG map of the United States that compares results across jurisdictions.                 Previous Table of Contents Next         Close Window"
GX000-76-2231612	"site index    |    ED.gov                                                                   Who is NCES?  |  Where Can I Find...?  |  What About Technical Issues? How Do I Order NCES Products?  |  Have Any Questions?  |  Need More Help?  |  Site Index               What About Technical Issues?       This section aims to help you to maximize your browsing experience when viewing our site. Among other things it explains how to optimally view our site, demystify PDF and Zip file formats, and provide links to some useful downloads and resources.       Appearance -  Browsers     Zip Format Archive Files   Appearance -  Resolution   Useful Downloads   Appearance -  Start-up Page     Web Tools and Resources   Portable Document Format (PDF)   NCES Product Disclaimer   Video/Audio Playback and Flash     Scalable Vector Graphics (SVG)         Appearance   -   Browsers      There are a number of things that you can do to optimize the look of nces.ed.gov on your computer. We recommend browsing with either:      Microsoft Internet Explorer 5.0 or 6.0     Netscape 4.0 or 7.0     Of course, using versions of either of these browsers such as Netscape Communicator 4.79 and Internet Explorer 4.0 will also work. These browsers are all free downloads. We've designed our pages to take advantage of browser features such as Javascript. Both Microsoft and Netscape browsers support Javascript, but sometimes in slightly different ways. We also make sure that our pages can be viewed by older browsers.   If you're not using Netscape or Internet Explorer, you will also get a good view of nces.ed.gov by using a browser that supports tables, forms, and images.            Appearance   -   Resolution      NCES makes every effort possible to develop for our audience's varying graphics resolutions. While we currently develop most of our pages for 800 x 600 resolution, we try to develop for both 640 x 480 and up to 1280 x 1024 resolution.  By using this as our guideline, we can be sure that everyone can enjoy horizontal-free scrolling when viewing our pages. Of course our pages can be best viewed in 1280 x 1024 resolution.  As mentioned, although we try to accommodate all screen resolutions some of our data tables are just too large to fit on one screen in a 640 x 480 screen resolution. When this occurs we recommend changing your screen resolution to 800 x 600 or higher. This is easily done on your computer (PC's) by going to your ""control panel"" and selecting ""display"". Within display select ""settings"" and choose the screen resolution you would like.           Appearance   -   Start-up Page     Make  nces.ed.gov  your browser's start-up page to get the latest in education statistics.     If you are interested in education issues, then you would probably like to have your browser default to a site that satisfies your needs.       This three step process takes less than one minute!     Choose your browser from the two options below and follow the appropriate instructions.             Internet Exp. 5.0   1.   Select  ""Tools"" and "" Internet Options"" from the toolbar at the top of the screen.   2.   Click  on the tab labeled ""General"" and select ""Home Page"" from the options.   3.   Paste  or type  http://nces.ed.gov  into the ""Address"" box and Click ""Apply"" then ""OK.""         Netscape 4.0   1.   Select  ""Edit"" and ""Preferences"" from the toolbar at the top of the screen.   2.   Select  the tab labeled ""Navigator"" or ""Communicator"" and go to the section labeled ""Home Page.""   3.   Paste  or type  http://nces.ed.gov  in the ""Location"" dialog box. Click ""OK.""                   It's done.  The next time that you start your browser, you'll begin with the NCES home page, your source for the latest in education statistics.             Portable Document Format (PDF)       Why we use PDF      Many NCES reports and graphics placed on our website are created in Portable Document Format (PDF). They are most commonly denoted by the above icon. PDF is used because it maintains the original look and feel of large documents, and allows us to place more publications on the web in a quick and efficient manner.  Further, PDF products are independent of platforms, applications, and distribution media.       How to obtain a PDF Reader      Versions of Acrobat Reader exist for all major computer platforms, including Windows 98, Windows NT, Windows 2000, Windows ME, Macintosh, Sun, UNIX and several other operating systems. To download the reader, you'll need a computer and a Web browser (such as  Netscape Navigator  or  Internet Explorer ) connected to the Internet. If you are using a modem to connect to the Internet, it may take you extra time to complete the download. Please follow the instructions on the Adobe Acrobat  download page  to install the Acrobat Reader.     Following are the System Requirements for Acrobat Reader 5.0:      Windows System Requirements  * Intel® Pentium® processor    * Microsoft® Windows® 95 OSR 2.0, Windows 98 SE, Windows Millennium, Windows NT® 4.0 with Service Pack 5, or Windows 2000    * 64 MB of RAM    * 24 MB of available hard-disk space (70 MB additional for Asian fonts recommended)      Macintosh System Requirements  * PowerPC® processor  * Mac OS software version 8.6(*), 9.0.4, 9.1, or OS X(*),(* Some features may not be available due to OS limitations)  * 64 MB of RAM  * 24 MB of available hard-disk space (70 MB additional for Asian fonts recommended)    Download  the Adobe Acrobat Reader software now! This reader is free of charge.        Having problems with PDF Files?      Should you experience PDF files appearing as a blank window within Internet Explorer after downloading and are using Adobe Acrobat Reader version 3.0 or earlier, please upgrade to a later version.  If this does not resolve the issue please follow the following steps:    Use the ""Save Target As"" or ""Save Link As"" option to download the PDF file directly to your hard drive and bypass the Acrobat Reader plug-in.   1. Using the right-side mouse button click on the file (click on the title link) you are interested in.  2. Select the ""save target as"" option in Internet Explorer, or ""save link as"" in Netscape.  3. Save as type should be ""Adobe Acrobat Document"" or ""all files.""  4. Make sure you name the file (or accept the name supplied).  5. Know the location of where you are saving it.  6. Hit save.  7. Use the Adobe Acrobat Reader to open the file after downloading.         Accessibility and PDF's      Adobe Systems, Inc. is producing various products designed to make PDF documents accessible to persons using screen reading software.  Their  accessibility webpages  describe their efforts.  They also have a free downloadable accessibility plug-in called,  MakeAccessible . This plug-in runs under Microsoft Windows 95 OSR 2.0, Windows 98, Windows Millennium Edition, Windows NT 4.0 with SP 5 or SP 6, or Windows 2000. Each system should have at least 64 MB (128 MB recommended) of RAM per processor, 200 MB of virtual memory, and 870 K of disk space available.   The MakeAccessible Plug-in creates a tagged Adobe PDF file from an untagged PDF file. This allows a pdf document to be read by a screen reader for greater accessibility.      Other Acrobat Add-ons      Once you've downloaded and installed the Acrobat Reader, you'll be able to view PDF files simply by clicking on the link to the PDF file in your browser. Either the browser will handle the PDF file, or it will bring up another program for viewing the PDF file. Either way, a special window will appear that contains buttons that work only for PDF files. Use these buttons to navigate through the file.    If you want to print the PDF file, you must use the print button located within the Adobe Acrobat  viewer (usually this is just above the document on the left side).  Use of the browser print button or the browser's ""File, Print"" command will not result in a correct printout.   The NCES website supports  byteserving . Byteserving, also known as page-at-a-time or byte-range downloading, enables you to view a PDF file from a Web server before the entire file is downloaded.   Note:  Byteserving is not supported by the older versions of Adobe Acrobat Reader, so you may need to install a newer version.     Once you get byteserving working, if you'd like the full document to be downloaded in the background even as you browse through it, select the ""Allow Background Download of Entire File"" option in the General Preferences of the Acrobat Reader.                  Video/Audio Playback and Flash      About Video and Audio Playback                NCES has adopted Advanced Streaming Format (ASF) as its standard for video deployment. Videos will be able to be viewed immediately using Windows Media Player, or can be downloaded for easier viewing. The downloaded version will always be better quality than the streamed or viewable copy; this is due to performance reasons. The Windows Media Player should automatically download any needed codecs (these are needed to view certain video formats).        How to obtain Windows Media Player      Click  here  to acquire Windows Media Player.      About Macromedia Flash                NCES uses Macromedia Flash in some of our applications, most notably in the  NCES Student's Classroom . Macromedia Flash Player displays web application front-ends, high-impact website user interfaces, interactive online advertising, and short-form to long-form animation. Designers and developers use Macromedia Flash MX to develop distinctive and compelling content, revolutionary user interfaces, and rich applications for the web. It is pre-installed in most web browsers and on most computers. It is included in Windows 98 (including all new Windows 98 and Windows XP computers), Netscape Navigator, Apple Macintosh operating systems, America Online, and WebTV, among others.         How to obtain a Macromedia Flash Player      Click  here  to obtain a free Macromedia Flash Player.               Scalable Vector Graphics (SVG)      About Scalable Vector Graphics (SVG)                NCES has adopted Scalable Vector Graphics (SVG) as a graphics file format. SVG is a web development language based on XML. SVG, a W3C recommendation (web standard), enables web developers and designers to create dynamically generated, high-quality graphics from real-time data with precise structural and visual control. Through the use of SVG, we are able to offer dynamically generated, high-quality, scalable, interactive graphics from real-time data. Although many SVG viewers are available, NCES recommends the Adobe SVG Viewer 3.0 (or above) as a stable, well-supported viewer.       How to obtain Adobe's SVG Viewer      Visit  Adobe SVG Viewer Download Area   to download a free viewer.              ZIP Format Archive Files      Why we use ZIP                A Zip format allows either extremely large files, or files created in formats no longer widely used, to be combined and compressed and thus downloaded with more speed and ease.  The user requires an ""unzip"" utility to extract files from an archive (all files for downloading have been compressed using zip archiving and compression). NCES uses Zip archiving for several of its newer applications, such as video, and for many data sets. In addition, some older reports are available only in a combination of file formats, such as Lotus .WK1 format for tables and plain ASCII for the text.   The time it takes to download a file depends on two factors: the size of the file and your connection speed. To estimate the time required to download a file we have provided a link to a  ""File Download Time Calculator.""         How to obtain a ZIP Extractor      To acquire the decompressing utility for your computer's operating system, click on the appropriate link below:                               Windows   Download  a trial version of Winzip   Macintosh   Download  a zip/unzip utility for Macintosh (MacZip)                  Useful Downloads      The links below provide some useful downloads which can greatly minimize problems users encounter when viewing our site:        Internet Explorer   Download the latest version of this popular browser to access the latest features on the NCES site and the rest of the Web.   Netscape   Download the latest version of this popular browser to access the latest features on the NCES site and the rest of the Web.   Adobe Acrobat Reader   You will need to download this popular reader in order to view the various PDF files on our site.   Adobe Acrobat Reader -   Help Page   This is the place to go for all your PDF problems related to printing, viewing, and downloading.   Adobe Acrobat Reader -   Byteserving   This article discusses byteserving, or how to deliver PDF documents page by page as you browse, thus avoiding having to wait for the entire PDF file to download before viewing it.   Adobe Acrobat Access   This is a link to a special Adobe site that talks about how to make PDF documents accessible for people with visual disabilities   Microsoft Word Viewer   Microsoft Word Viewer 97 for Windows 16-bit Operating Systems (Word Viewer), the newest member of the Word Viewer family, is a freeware product that allows you to view and print Microsoft Word 2000 documents. Like previous versions of Word Viewer, the latest version can also open documents created with all previous versions of Word for Windows and version 4.x and above of Microsoft Word for Macintosh®. You cannot edit an open document in Word Viewer. However, you can copy text to the Clipboard to paste it in other applications.   Microsoft Excel Viewer   The Microsoft Excel 97 Viewer allows users to view and print Excel 97 and Excel 2000 spreadsheet files, in addition to other Excel for Windows® (versions 2.0 and greater) and Excel for the Macintosh® (versions 2.2a and greater) spreadsheet files. This small, freely distributable viewer gives users the flexibility to view page layout, copy and control cell sizes, and access the zoom and AutoFilter features. While this viewer is called the Microsoft Excel 97 Viewer (and is referred to by this name throughout this page), it is important to understand that you are not limited to only viewing Excel 97 spreadsheets.   Microsoft Powerpoint Viewer   With this release, the Microsoft PowerPoint® Viewer 97 now also supports PowerPoint 2000 files. This viewer allows people who use PowerPoint to share their presentations with people who do not have PowerPoint installed on their computers. When you post presentations on the Internet, you can include the PowerPoint Viewer to expand your online audience to people who might not have PowerPoint, or to those with different versions. You can view and print presentations, but you cannot edit them in the PowerPoint Viewer. The PowerPoint Viewer 97 supports PowerPoint 2000 files as well as those files created with previous versions of PowerPoint.   Microsoft Windows Media Player   For streaming and playing audio and video content in formats such as WMA, MP3, WAV, AVI, MPEG and more, download this viewer.   Macromedia Flash Player    Installing this free download of the Macromedia Flash Player lets you experience animation and entertainment in your Web browser.    WinZip Trial   Download this popular zip/unzip utility for Windows.   Macintosh Zip Utility   Download a zip/unzip utility for Macintosh called MacZip.              Web Tools and Resources      The resources below provide some useful tools and information which may help when viewing our site:        Download Time Calculator   Visit this site to find out download times for various modem and connection speeds. It allows you to specify any file size.   Bandwidth Speed Test   Does your Internet connection appear fast or slow? Whether you are using a cable modem, digital subscriber line (DSL), integrated services digital network (ISDN) connection, or a plain old dial-up modem, the Bandwidth Speed Test will give you the answer.     HyperStat   HyperStat Online is an introductory-level hypertext statistics book. It is a good place to start if you are a statistics ""newbie.""   Statistic Calculations   This page contains links to interactive webpages that perform statistical calculations. Together, they comprise a powerful, conveniently-accessible, and free, multi-platform statistical software package.              NCES Product Disclaimer      Reference herein to any specific commercial products, process, or service by trade name, trademark, manufacturer, or otherwise, does not necessarily constitute or imply its endorsement, recommendation, or favoring by the United States Government.                                                      NCES Headlines                  •      JUST RELEASED! Remedial Education at Degree-Granting Postsecondary Institutions      •      JUST RELEASED! Projections of Education Statistics to 2013      •      NEW! NAEP 2003 Reading and Mathematics Assessments                                               NCES Home   |   Publications   |   Surveys & Programs   |   Quick Tables & Figures   |   Data Tools       Search   |   Help   |   News Flash   |   NCES Staff   |   Contact NCES   |   Site Index               National Center for Education Statistics   Institute of Education Sciences ,  U.S. Dept. of Education   ( map )  1990 K Street, NW, Washington, DC 20006, USA, Phone: (202) 502-7300"
GX022-94-15754170	[ previous chapter ]   [ table of contents ]   [ next chapter ]     1. Overview    Chapter 1 Index       Architecture     Project Viewers     System Requirements    1.1 Architecture    The following diagram shows up the Synoptic Display architecture:         The system consists of four parts: (1) project builder, (2)  project viewer, (3) repository of components and projects, and (4) runtime project  engine. First two parts reside on user's PC, last ones  on the  server side.   Project Builder   is a console application which is  used to create and modify synoptic display projects. Actually,  this is a special graphical editor, that allows to define a logical flow of  data: data sources (such as  Accelerator Device ), data consumers (for example,  visual components for the dynamic data presentation), data handlers (for  examples, integrators and comparators), and data pipes. The second function  of the builder is definition of static visual components, such as immutable  lines, geometrical shapes and tests. Builder is connected to the server side  repositories in order to download the library of components, as well as to save and  load projects. Besides, projects may be stored in local files.   Project Viewer  is  a client side application, that renders graphical data received from the runtime project  engine. In most cases, this is a web browser. See details  below .   Repository of Components and Projects  is a  server side application, to keep and distribute synoptic display projects among project  builders instances and runtime project engine. It also keeps a common library of  elementary components for the builders.   Runtime Project Engine  is a server side machine, that  handles user's requests, downloads appropriate projects from the  repository, launches data acquisition jobs and generates graphical  data.   We would like to emphasize some important points related to the proposed  architecture:     An open, portable and human readable data    format is used to convey and store projects, components and    graphical data;      A central server side repository is used to store    common component library and projects, that allows to share data among    multiple developers;      Projects, stored in the server repository,    immediately become available for execution;          In most cases, a standard web browser may be  used as a project viewer, and very simple software installation is required.      1.2 Project Viewers   Project viewer is used to show data on user's PC. In most cases, this is the  only part of the Synoptic Display, that must be installed and configured on the  client machine. There are three options:      The recommended option is to use a standard Internet browser with  Scalable Vector Graphics  (SVG) support.  SVG allows to see dynamically changed images without visible blinking. SVG plug-ins for  browsers are provided by Adobe Systems, Inc. and they may be downloaded for  free from their   site .    Unfortunately, plug-ins are not available for all types of browsers and all  operating systems. Recommended configurations are   highlighted :    SVG Availability                     Microsoft Internet Explorer       Netscape 4       Netscape 6       Mozilla           Windows       available for: Windows 98XP   MS IE 4.0+       available for: Windows 98XP Netscape 4.54.78       N/A       N/A           UNIX       N/A       N/A       available        available           Mac       available for Mac 8.69.1, Mac 10.1   MS IE 5.0+       available for: Mac 8.69.1, Mac 10.1   Netscape 4.54.78       N/A       N/A          SVG plug-in  is available, but Synoptic Display does not work in this configuration;    Looks like an unofficial release, may be downloaded from the   archive of old versions .      If you are not able or do not want to use an  SVG viewer, it is possible to see results as JPEG or GIF image on any graphical  web browser without additional software. The disadvantage is a visible refreshing of  image every several seconds with blinking.    In the future, a special console SVG viewer will be developed to see dynamic  images on every platform without web browser.        1.3 System Requirements   Particular system requirements depend on which modules will be used.     In every case, a connection to   http://www-bd.fnal.gov/synoptic  is  required.   To see graphical data from the executed projects, you  will need a graphical web browser with SVG support. See table   above . Adobe  SVG plug-ins have their own limitations and requirements.   To use Project Builder, you should install on you computer:       Java Development Kit  (JDK) ver. 1.4.0 or higher.     Java Web Start  (JWS)  a system for remote software download and  installation. In some cases, JWS is installed automatically together with JDK.             [ previous chapter ]   [ table of contents ]   [ next chapter ]                           Last updated by  AP        07-19-2002.              [Security, Privacy, Legal]
GX000-45-8379972	"NOAA OR&R Home  /  Chemical Aids  /  CAMEO Intro  / MARPLOT        MARPLOT     MARPLOT is a general-purpose mapping application, jointly developed by NOAA and EPA, that runs on both Macintosh computers and in Windows. It is designed to be easy to use and fast, and to consume as little disk and memory space as possible, so that you can create, view, and modify maps quickly and easily. It also allows you to link objects on your computer maps to data in other programs, including CAMEO.     Maps and Map Data     Map data for MARPLOT comes from a variety of sources. All of the TIGER/Line data from the Bureau of the Census (roads, water bodies, railroads, parks, and so on) is available in MARPLOT format and can be  downloaded for free . Maps are also available on the  LandView IV DVD , which also contains EPA-regulated sites, demographic data, geographic boundaries (states, counties, cities, congressional districts, and so on), Geographic Names Information System (GNIS) Features and selected Federal Lands from the USGS National Atlas.     Other source data, in a number of formats, can be translated easily into MARPLOT files. The MARPLOT files themselves are compact and platform-independent.     How MARPLOT Works     Seven types of objects make up the content of MARPLOT maps, and are arranged within map layers. The seven kinds of MARPLOT objects include points (symbols), rectangles, circles, polygons, polylines, text labels, and pictures. You can create, examine, and modify each type of object. For example, you might use a point object to mark the location of a building or monitoring site, and polylines to represent things like roads and streams. You can use polygons to represent things like parks or water bodies. Using picture objects, you can take any bitmap or PICT image and display it at fixed geographical coordinates on a map.     Maps and layers are the groups into which objects are organized. Maps, which usually cover specific geographic areas, are subdivided into layers (layers usually span multiple maps). Any particular layer usually contains one type of object, such as roads, water bodies, or hospitals.         Searching for map objects by geographical criteria is easy and fast in MARPLOT. You can ask questions ranging in complexity from ""What objects are at this point?"" to ""How many objects on one of these three layers are within 1.5 miles of this threat zone?""         Inter-application communication allows MARPLOT to share information with databases and other programs that contain information about map objects. You can query a database for certain records, then show the selected records on the map. From the map, you also can select certain objects, and then get information from the database for those objects.     Examples of database programs that communicate with MARPLOT are CAMEO and LandView. MARPLOT can be used along with  CAMEO  to plot the locations of facilities, hospitals, and other sites of interest to planners and responders, and to examine the geographical extent of real or potential emergencies.  LandView , developed by EPA, NOAA, USGS, and the US Bureau of the Census, is a collection of data for EPA-regulated sites and demographic and economic information from the 1990 census, combined with a program for exploring the database and for displaying data in MARPLOT according to your queries.     MARPLOT Resources          Download MARPLOT  from the CAMEO Website.     MARPLOT Maps  Download free MARPLOT maps of US counties, boroughs, and/or territories.     MARPLOT Manual  (PDF file; 7.3 MB)     MARPLOT Technical Documentation  (PDF file; 196K)      LandView IV  (US Census Bureau page) LandView incorporates both MARPLOT and the LandView database management system. You can use LandView not only to view maps of U.S. counties or other geographic areas but also to see environmental and census data describing those counties.      MARPLOT factsheet  Basic description of MARPLOT in a one-page factsheet (77K  PDF  file).     The current version of MARPLOT (3.2.2) is fully Y2K-compatible. Previous versions (3.1 and 3.2) had  minor Y2K issues .              Back to the CAMEO Introduction                Revised: December 18, 2002      Office of Response and Restoration, National Ocean Service, National Oceanic and Atmospheric Administration"
GX021-41-12373349	"Introduction    The latest changes in Synoptic Display:     Added component ""FormattedBoolean"" and fixed problem with limits in the Scope 09/27/02  Added component ""DelayLine"" 09/26/02  Fixed SlowPlot4 ""refresh"" bug for Netscape 4.7X 09/06/02  New user interface was made by Wally Kissel for SlowPlot4.html 08/30/02  ""root is null"" bug cleaned up from Javascript code behind SVG picture 08/29/02  Derived projects added 08/23/02.  New ACNET components to work with digital Status/Control was added in the beginning of August 2002.  New web page is created 07/17/02.         Synoptic Display is a Java application for flexible online graphical  representation of data received from a data acquisition system. We consider this  project as a next generation of programs such as ACNET Lexigraphics and EPICS  MEDM.   Synoptic Display projects (an equivalent of MEDM screens) are rendered on  major Web browsers (for monitoring purposes) or started in a web-startable  console Java application (both for monitoring and control). Small bandwidth (as  low as 1001000 byte/sec) is required between client and server sides due to  usage of Scalable Vector Graphics (SVG) for data transfer.    Synoptic Display components (data sources, processing pipes, visualization  widgets) can be graphically arranged and logically interconnected in a  web-startable Project Builder; projects can be saved on a server-side repository  or in local files. XML is used as a project format. A Runtime Project Engine  (RPE) on the server side handles user's requests, downloads projects from the  repository, launches data acquisition jobs, and generates SVG pictures. Servlets  and JSPs (Java Server Pages) are used as RPE web-tier. At present time ACNET  Java Data Acquisition Engine is a primary data source for the Synoptic Display,  since this is corporate Fermilab standard; there are no limitations to create  new types of data sources.    The field of Synoptic Display's application primarily covers monitoring of  various data and presentation of current state of plants and equipments with  sketchy diagrams. Due to security reasons, Synoptic Display does not support  device settings at this time.   Synoptic Display has been developed at Fermilab, which is a U.S.  Department Of Energy National Laboratory. The project is deployed on the  computer network, owned by a U.S. government agency.  Please read the   official information  about copyrights and policy. If you are looking this page from outside Fermilab,  your access to the content of this site is limited."
GX005-33-16622901	"OFFICE OF THE AG                PROGRAMS & SERVICES             NEWS & ALERTS             PUBLICATIONS             CONTACT US             SEARCH                                                                                   REGISTERING WITH US             CAREER OPPORTUNITIES             LINKS TO STATE SITES                                                                                                                                                                                                                                       Tips For Curbing Annoying Internet Pop-up Advertisements        While using the Internet, do you find yourself having to stop and delete those annoying pop-up advertisements?  Or worse, finding one message morph into more even when you're not using your web browser?   Calling unsolicited Internet pop-up advertisements the next generation of spam, Attorney General Lockyer cautions that persistent pop-up ads could signal that your home computer is open to hackers who can install new programs and view, change or delete data without your permission.     One pop-up advertising campaign recently prompted a federal court to issue a temporary restraining order against the company that allegedly had been sending pop-up ads as frequently as every 10 minutes to urge viewers to buy software costing $25 to $30 to block future pop-up ads. The  Federal Trade Commission complaint  was filed in the U.S. District Court in Maryland.   Here are some tips to consider from the FTC for curbing these unwanted pop-up ads and better protecting your home computer from hackers.                DISABLE WINDOWS MESSENGER SERVICE IN MICROSOFT XP/2000    Pop-up spammers are exploiting a feature of the Microsoft Windows operating systems known as Messenger Service.  Despite the name, Windows Messenger Service doesn't have anything to do with instant messaging.    Messenger Service is designed to provide users on a local- or wide-area computer network with messages from the network administrator. For example, a company's network administrator might send a message to all its users that the company's network will be shutting down in five minutes.  If your home computer is connected only to the Internet, you may not have any practical uses for Windows Messenger Service.    Consumer should note that disabling the Windows Messenger Service may not be practical for computers connected to a home or business network. In such instances, your network should be protected by a firewall.    Steps for disabling Windows Messenger Service:    Click  Start    Click  Control Panel  (or point to  Settings , and then click  Control Panel )    Double click  Administrative Tools    Double click  Services    Double click  Messenger    In the  Startup  type list, click  Disabled    Click  Stop    Click  OK      INSTALL A FIREWALL   Another way to cut off pop-up spam is to run a firewall, software or hardware designed to block hackers from accessing your computer and getting into your programs and files.   Firewalls provide the benefit of preventing not just pop-up ads, but any unauthorized access.  Some new operating systems, including Windows XP, have built-in firewalls, but they may not be activated.  Consumers can find out how to set up built-in firewalls by consulting their online ""Help"" feature. You can check out several free firewall software programs via the Internet or purchase commercial products. In any case, a firewall needs to be updated regularly to stay effective.   A firewall is different from anti virus protection. Anti virus software scans incoming communications and files for troublesome files. A firewall helps make you invisible on the Internet and blocks all communications from unauthorized sources.  A firewall is especially important if you have high-speed Internet access through a cable modem or a DSL (digital subscriber line) connection.      Consumers can file a complaint about a deceptive pop-up advertisement by using the  Attorney General's online complaint form  or by writing the Attorney General's Public Inquiry Unit at P.O. Box 944255, Sacramento, CA 94244-2550.  Consumers also may file complaints and get more information from the  Federal Trade Commission .  Be sure your complaint includes the name of the company or Web site advertised in the pop-up spam.     BACK                                                                                                                             OFFICE OF THE AG  |  PROGRAMS & SERVICES  |  NEWS & ALERTS  |  PUBLICATIONS  |  CONTACT US  |  SEARCH REGISTERING WITH US  |  CAREER OPPORTUNITIES  |  LINKS TO STATE SITES Privacy Policy  |  Terms & Conditions  |  © 2001 DOJ"
GX058-90-10956323	"Next   Previous   Contents     6. Agents           Also known as intelligent software agents or just agents, this area of AI research deals with simple applications of small programs that aid the user in his/her work. They can be mobile (able to stop their execution on one machine and resume it on another) or static (live in one machine). They are usually specific to the task (and therefore fairly simple) and meant to help the user much as an assistant would. The most popular (ie. widely known) use of this type of application to date are the web robots that many of the indexing engines (eg. webcrawler) use.              Agent     FTP site:   www.cpan.org/modules/by-category/23_Miscellaneous_Modules/Agent/       The Agent is a prototype for an Information Agent system. It is both platform and language independent, as it stores contained information in simple packed strings. It can be packed and shipped across any network with any format, as it freezes itself in its current state.        agentTool     Web site:   en.afit.af.mil/ai/agentool.htm   Download site:   en.afit.af.mil/ai/_vti_bin/shtml.dll/registration.htm     Another Java based agent development framework. Fairly unique in that it emphasizes the use of a GUI for designing the system which will ""semi-automatically synthesize multiagent systems to meet those requirements"". You need a java enabled browser to download. :P        Aglets Workbench     Web site:   www.trl.ibm.com/aglets/index_e.htm       An aglet is a Java object that can move from one host on the Internet to another.  That is, an aglet that executes on one host can suddenly halt execution, dispatch to a remote host, and resume execution there. When the aglet moves, it takes along its program code as well as its state (data). A built-in security mechanism makes it safe for a computer to host untrusted aglets. The Java Aglet API (J-AAPI) is a proposed public standard for interfacing aglets and their environment. J-AAPI contains methods for initializing an aglet, message handling, and dispatching, retracting, deactivating/activating, cloning, and disposing of the aglet. J-AAPI is simple, flexible, and stable. Application developers can write platform-independent aglets and expect them to run on any host that supports J-AAPI.        A.L.I.C.E.     Web site:   www.alicebot.org     The ALICE software implements AIML (Artificial Intelligence Markup Language), a non-standard evolving markup language for creating chat robots. The primary design feature of AIML is minimalism. Compared with other chat robot languages, AIML is perhaps the simplest. The pattern matching language is very simple, for example permitting only one wild-card ('*') match character per pattern. AIML is an XML language, implying that it obeys certain grammatical meta-rules. The choice of XML syntax permits integration with other tools such as XML editors. Another motivation for XML is its familiar look and feel, especially to people with HTML experience.          Ara     Web site:   wwwagss.informatik.uni-kl.de/Projekte/Ara/index_e.html       Ara is a platform for the portable and secure execution of mobile agents in heterogeneous networks. Mobile agents in this sense are programs with the ability to change their host machine during execution while preserving their internal state. This enables them to handle interactions locally which otherwise had to be performed remotely. Ara's specific aim in comparison to similar platforms is to provide full mobile agent functionality while retaining as much as possible of established programming models and languages.        BattleBots     Web site:   www.bluefire.nu/battlebots/     AI programming game where you design the bot by selecting hardware and programming its CPU, then competing with other bots. Competitions can have teams and special rules for a game.   The hardware for use in your bot includes weapons, engine, scanners, CPU, etc. The programming lauguage is dependent on the CPU type and is similar to an assembly language.         Bee-gent     Web site:   www2.toshiba.co.jp/beegent/index.htm     Bee-gent is a new type of development framework in that it is a 100% pure agent system. As opposed to other systems which make only some use of agents, Bee-gent completely ""Agentifies"" the communication that takes place between software applications. The applications become agents, and all messages are carried by agents. Thus, Bee-gent allows developers to build flexible open distributed systems that make optimal use of existing applications.        Bond     Web site:   bond.cs.ucf.edu     Yet another java agent system...  Bond is a Java based distributed object system and agent framework. It implements a message based middleware and associated services like directory, persistence, monitoring and security. Bond allows to easily build multi agent, distributed applications. Another application of Bond will be a Virtual Laboratory supporting data annotation and metacomputing.         Cadaver     Web site:   www.erikyyy.de/cadaver/     Cadaver is a simulated world of cyborgs and nature in realtime.  The battlefield consists of forests, grain, water, grass, carcass (of course) and lots of other things. The game server manages the game and the rules.  You start a server and connect some clients.  The clients communicate with the server using a very primitive protocol.  They can order cyborgs to harvest grain, attack enemies or cut forest.  The game is not intended to be played by humans!  There is too much to control. Only for die-hards: Just telnet to the server and you can enter commands by hand.  Instead the idea is that you write artificial   intelligence clients to beat the other artificial intelligences.  You can choose a language (and operating system) of your choice to do that task.  It is enough to write a program that communicates on standard input and standard output channels.  Then you can use programs like ""socket"" to connect your clients to the server.  It is NOT needed to write TCP/IP code, although i did so :) The battle shall not be boring, and so there is the so called spyboss client that displays the action graphically on screen.        Cougaar     Web site:   www.cougaar.org/     Cougaar is java-based architecture for the construction of large-scale distributed agent-based applications.  It is the product of a multi-year DARPA research project into large scale agent systems and includes not only the core architecture but also a variety of demonstration, visualization and management components to simplify the development of complex, distributed applications. [Yet another java based agent system -- ed.]        D'Agent (was AGENT TCL)     Web site:   agent.cs.dartmouth.edu/software/agent2.0/   FTP site:   ftp.cs.dartmouth.edu/pub/agents/       A transportable agent is a program that can migrate from machine to machine in a heterogeneous network.  The program chooses when and where to migrate.  It can suspend its execution at an arbitrary point, transport to another machine and resume execution on the new machine. For example, an agent carrying a mail message migrates first to a router and then to the recipient's mailbox.  The agent can perform arbitrarily complex processing at each machine in order to ensure that the message reaches the intended recipient.        Dunce     Web site:   www.boswa.com/boswabits/       Dunce is a simple chatterbot (conversational AI) and a language for programming such chatterbots. It uses a basic regex pattern matching and a semi-neural rule/response firing mechanism (with excitement/decay cycles).  Dunce is listed about halfway down the page.        FIPA-OS     Web site:   fipa-os.sourceforge.net   Secondary Web site:   www.nortelnetworks.com/products/announcements/fipa/     FIPA-OS is an open source implementation of the mandatory elements contained within the FIPA specification for agent interoperability. In addition to supporting the FIPA interoperability concepts, FIPA-OS also provides a component based architecture to enable the development of domain specific agents which can utilise the services of the FIPA Platform agents. It is implemented in Java.        FishMarket     Web site:   www.iiia.csic.es/Projects/fishmarket/     FM - The FishMarket project conducted at the Artificial Intelligence Research Institute (IIIA-CSIC) attempts to contribute in that direction by developing FM, an agent-mediated electronic auction house which has been evolved into a test-bed for electronic auction markets. The framework, conceived and implemented as an extension of FM96.5 (a Java-based version of the Fishmarket auction house), allows to define trading scenarios based on fish market auctions (Dutch auctions). FM provides the framework wherein agent designers can perform controlled experimentation in such a way that a multitude of experimental market scenarios--that we regard as tournament scenarios due to the competitive nature of the domain-- of varying degrees of realism and complexity can be specified, activated, and recorded; and trading (buyer and seller) heterogeneous (human and software) agents compared, tuned and evaluated.        GNU Robots     Web site:   www.gnu.org/software/robots/robots.html     GNU Robots is a game/diversion where you construct a program for a little robot, then watch him explore a world. The world is filled with baddies that can hurt you, objects that you can bump into, and food that you can eat. The goal of the game is to collect as many prizes as possible before are killed by a baddie or you run out of energy. Robots can be written in Guile scheme or using a GUI.        Grasshopper     Web site:   www.grasshopper.de/     Another Java agent system. Full featured and actively developed. Commercial, but free. Historically targeted at embedded systems.          Hive     Web site:   hive.sourceforge.net     Hive is a Java software platform for creating distributed applications. Using Hive, programmers can easily create systems that connect and use data from all over the Internet. At its heart, Hive is an environment for distributed agents to live, communicating and moving to fulfill applications. We are trying to make the Internet alive.        ICM     Web site:   www.nar.fujitsulabs.com/   SourceForge site:   sourceforge.net/projects/networkagent/     The Inter-Agent Communication Model (ICM) is a communication mechanism that can be used for sending messages between agents in an asynchronous fashion. Its intended application area is as a transportation mechanism for agent communication languages (ACLs), such as KQML and FIPA's ACL.          Jacomma     Web site:   jacomma.sourceforge.net   SourceForge site:   sourceforge.net/projects/jacomma/     Jacomma is an agent development platform/framework for developing distributed, mobile, and reactive information agents with heterogeneous communication capabilities, in Java and JPython.  Jacomma provides a development framework and an execution environment, which sits on top of the Inter-Agent Communication Model infrastructure. The ICM defines a communication protocol, a store and forward messaging architecture, and low level communication infrastructure for message exchange.  Communication is truly asynchronous, based on TCP sockets.  ICM has an entry in this howto, or you can find it via a link off the site.          Jade     Web site:   sharon.cselt.it/projects/jade/     JADE (Java Agent DEvelopment Framework) is a software framework fully implemented in Java language. It simplifies the implementation of multi-agent systems through a middle-ware that claims to comply with the FIPA specifications and through a set of tools that supports the debugging and deployment phase. The agent platform can be distributed across machines (which not even need to share the same OS) and the configuration can be controlled via a remote GUI. The configuration can be even changed at run-time by moving agents from one machine to another one, as and when required.        JAM Agent     Web site:   members.home.net/marcush/IRS/     JAM supports both top-down, goal-based reasoning and bottom-up data-driven reasoning. JAM selects goals and plans based on maximal priority if metalevel reasoning is not used, or user-developed metalevel reasoning plans if they exist. JAM's conceptualization of goals and goal achievement is more classically defined (UMPRS is more behavioral performance-based than truly goal-based) and makes the distinction between plans to achieve goals and plans that simply encode behaviors. Goal-types implemented include achievement (attain a specified world state), maintenance (re-attain a specified world state), and performance. Execution of multiple simultaneous goals are supported, with suspension and resumption capabilities for each goal (i.e., intention) thread. JAM plans have explicit precondition and runtime attributes that restrict their applicability, a postcondition attribute, and a plan attributes section for specifying  plan/domain-specific plan features. Available plan constructs include: sequencing, iteration, subgoaling, atomic (i.e., non-interruptable) plan segments, n-branch deterministic and non-deterministic conditional execution, parallel execution of multiple plan segments, goal-based or world state-based synchronization, an explicit failure-handling section, and Java primitive function definition through building it into JAM as well as the invocation of predefined (i.e., legacy) class members via Java's reflection capabilities without having to build it into JAM.          JATLite     Web site:   java.stanford.edu/       JATLite is providing a set of java packages which makes easy to build multi-agent systems using Java. JATLite provides only light-weight, small set of packages so that the developers can handle all the packages with little efforts. For flexibility JATLite provides four different layers from abstract to Router implementation. A user can access any layer we are providing. Each layer has a different set of assumptions. The user can choose an appropriate layer according to the assumptions on the layer and user's application. The introduction page contains JATLite features and the set of assumptions for each layer.          JATLiteBeans     Web site:   waitaki.otago.ac.nz/JATLiteBean/         Improved, easier-to-use interface to JATLite features including KQML message parsing, receiving, and sending.                Extensible architecture for message handling and agent ""thread of control"" management                 Useful functions for parsing of simple KQML message content                JATLiteBean supports automatic advertising of agent capabilities to facilitator agents             Automatic, optional, handling of the ""forward"" performative            Generic configuration file parser            KQML syntax checker                      Java(tm) Agent Template     Web site:   www-cdr.stanford.edu/ABE/JavaAgent.html       The JAT provides a fully functional template, written entirely in the Java language, for constructing software agents which communicate peer-to-peer with a community of other agents distributed over the Internet. Although portions of the code which define each agent are portable, JAT agents are not migratory but rather have a static existence on a single host. This behavior is in contrast to many other ""agent"" technologies. (However, using the Java RMI, JAT agents could dynamically migrate to a foreign host via an agent resident on that host).  Currently, all agent messages use KQML as a top-level protocol or message wrapper. The JAT includes functionality for dynamically exchanging ""Resources"", which can include Java classes (e.g. new languages and interpreters, remote services, etc.), data files and information inlined into the KQML messages.        Khepera Simulator     Web site:   diwww.epfl.ch/lami/team/michel/khep-sim/     Khepera Simulator is a public domain software package written by  Olivier MICHEL  during the preparation of his Ph.D. thesis, at the Laboratoire I3S, URA 1376 of CNRS and University of Nice-Sophia Antipolis, France. It allows to write your own controller for the mobile robot Khepera using C or C++ languages, to test them in a simulated environment and features a nice colorful X11 graphical interface. Moreover, if you own a Khepera robot, it can drive the real robot using the same control algorithm. It is mainly oriented toward to researchers studying autonomous agents.      lyntin     Web site:   lyntin.sourceforge.net/     Lyntin is an extensible Mud client and framework for the creation of autonomous agents, or bots, as well as mudding in general. Lyntin is centered around Python, a dynamic, object-oriented, and fun programming language and based on TinTin++ a lovely mud client.        Mole     Web site:   mole.informatik.uni-stuttgart.de/       Mole is an agent system supporting mobile agents programmed in Java.  Mole's agents consist of a cluster of objects, which have no references to the outside, and as a whole work on tasks given by the user or another agent. They have the ability to roam a network of ""locations"" autonomously. These ""locations"" are an abstraction of real, existing nodes in the underlying network. They can use location-specific resources by communicating with dedicated agents representing these services. Agents are able to use services provided by other agents and to provide services as well.        Narval     Web site:   www.logilab.org     Narval is the acronym of ""Network Assistant Reasoning with a Validating Agent Language"". It is a personal network assistant based on artificial intelligence and agent technologies. It executes recipes (sequences of actions) to perform tasks. It is easy to specify a new action using XML and to implement it using Python.  Recipes can be built and debugged using a graphical interface.         NeL     Web site:   www.nevrax.org     NeL is actually a game development library (for massive multi-player games), but I'm including it here as it (will) include a fairly  sizable AI library. Here's a blurb from the whitepaper:  The purpose of the AI library is to provide a pragmatic approach to creating a distributed agents platform. Its focus is agents; individual entities that communicate regardless of location, using an action-reaction model.         OAA     Web site:   www.ai.sri.com/~oaa/     The Open Agent Architecture is a framework in which a community of software agents running on distributed machines can work together on tasks assigned by human or non-human participants in the community. Distributed cooperation and high-level communication are two ideas central to the foundation of the OAA.  It defines an interagent communication language and supports multiple platforms and programming languages.          PAI     Web site:   utenti.quipo.it/claudioscordino/pai.html     AI (Programmable Artificial Intelligence) is a program capable of having a conversation in its mother tongue, English. Written in  C++.        Penguin!     FTP site:   www.perl.org/CPAN/modules/by-category/23_Miscellaneous_Modules/Penguin/FSG/       Penguin is a Perl 5 module. It provides you with a set of functions which allow you to:    send encrypted, digitally signed Perl code to a remote machine to be executed.   receive code and, depending on who signed it, execute it in an arbitrarily secure, limited compartment.     The combination of these functions enable direct Perl coding of algorithms to handle safe internet commerce, mobile information-gathering agents, ""live content"" web browser helper apps, distributed load-balanced computation, remote software update, distance machine administration, content-based information propagation, Internet-wide shared-data applications, network application builders, and so on.        Ps-i     Web site:   ps-i.sourceforge.net     Ps-i is an environment for running agent-based simulations. It is cross-platform, with binaries available for Win32. Features include:       declarative language for model specification   industry standard Tcl/Tk scripting with built-in routine optimization, speculative evaluation and xf86 JIT compiler users can create complex models without sacrificing perfomance    user friendly interface    save and restore program runs    change model parameters on the fly    data visualization: field display with multiple agent shapes and color, statistics window, agent viewer, routine browser and highlight agents tool            RealTimeBattle     Web site:   www.lysator.liu.se/realtimebattle/     RealTimeBattle is a programming game, in which robots controlled by  programs are fighting each other. The goal is to destroy the enemies,  using the radar to examine the environment and the cannon to shoot.       Game progresses in real time, with the robot programs  running as child processes to RealTimeBattle.   The robots communicate with the main program using the  standard input and output.   Robots can be constructed in almost any programming language.   Maximum number of robots can compete simultaneously.   A simple messaging language is used for communication, which makes it easy to start constructing robots.   Robots behave like real physical object.   You can create your own arenas.   Highly configurable.             Remembrance Agents     Web site:   www.remem.org     Remembrance Agents are a set of applications that watch over a user's shoulder and suggest information relevant to the current situation. While query-based memory aids help with direct recall, remembrance agents are an augmented associative memory.  For example, the word-processor version of the RA continuously updates a list of documents relevant to what's being typed or read in an emacs buffer. These suggested documents can be any text files that might be relevant to what you are currently writing or reading.  They might be old emails related to the mail you are currently reading, or abstracts from papers and newspaper articles that discuss the topic of your writing.        RoboTournament     Web site:   robotournament.sourceforge.net/     RoboTournament is a RoboRally inspired game where players program their robots to vanquish their opponents. RoboTournament features: Multiple Game Types: Death Match, Rally, and Capture The Flag. Multi-Player through TCP/IP, Six weapons including BFG, Map Editor, and a wide variety of board elements.        SimRobot     Web site:   www.informatik.uni-bremen.de/~simrobot/     FTP site:   ftp.uni-bremen.de/pub/ZKW/INFORM/simrobot/       SimRobot is a program for simulation of sensor based robots in a 3D environment. It is written in C++, runs under UNIX and X11 and needs the graphics toolkit XView.    Simulation of robot kinematics   Hierarchically built scene definition via a simple definition language   Various sensors built in: camera, facette eye, distance  measurement, light sensor, etc.   Objects defined as polyeders   Emitter abstractly defined; can be interpreted e.g. as light or sound   Camera images computed according to the raytracing or Z-buffer algorithms known from computer graphics   Specific sensor/motor software interface for communicating  with the simulation   Texture mapping onto the object surfaces: bitmaps in various  formats   Comprehensive visualization of the scene: wire frame w/o hidden lines, sensor and actor values   Interactive as well as batch driven control of the agents and operation in the environment   Collision detection   Extendability with user defined object types   Possible socket communication to e.g. the Khoros image  processing software             Sulawesi     Web site ???:   wearables.essex.ac.uk/sulawesi/     A framework called Sulawesi has been designed and implemented to tackle what has been considered to be important challenges in a wearable user interface. The ability to accept input from any  number of modalities, and perform if necessary a translation to any number of modal outputs. It does this primarily through a set of proactive agents to act on the input.          TclRobots     Web site:   www.nyx.net/~tpoindex/       TclRobots is a programming game, similar to 'Core War'.  To play TclRobots, you must write a Tcl program that controls a robot.  The robot's mission is to survive a battle with other robots.  Two, three, or four robots compete during a battle, each running different programs (or possibly the same program in different robots.)  Each robot is equipped with a scanner, cannon, drive mechanism.  A single match continues until one robot is left running.  Robots may compete individually, or combine in a team oriented battle.  A tournament can be run with any number of robot programs, each robot playing every other in a round-robin fashion, one-on-one.  A battle simulator is available to help debug robot programs.    The TclRobots program provides a physical environment, imposing certain game parameters to which all robots must adhere.  TclRobots also provides a view on a battle, and a controlling user interface. TclRobots requirements: a wish interpreter built from Tcl 7.4 and Tk 4.0.          TKQML     Web site:   www.csee.umbc.edu/tkqml/       TKQML is a KQML application/addition to Tcl/Tk, which allows Tcl based systems to communicate easily with a powerful agent communication language.          The Tocoma Project     Web site:   www.tacoma.cs.uit.no/       An agent is a process that may migrate through a computer network in order to satisfy requests made by clients. Agents are an attractive way to describe network-wide computations.    The TACOMA project focuses on operating system support for agents and how agents can be used to solve problems traditionally addressed by operating systems. We have implemented a series of prototype systems to support agents.    TACOMA Version 1.2 is based on UNIX and TCP. The system supports agents written in C, Tcl/Tk, Perl, Python, and Scheme (Elk). It is implemented in C. This TACOMA version has been in public domain since April 1996.    We are currently focusing on heterogeneity, fault-tolerance, security and management issues. Also, several TACOMA applications are under construction. We implemented StormCast 4.0, a wide-area network weather monitoring system accessible over the internet, using TACOMA and Java. We are now in the process of evaluating this application, and plan to build a new StormCast version to be completed by June 1997.        Ummon     Web site:   www.spacetide.com/projects/ummon/     Ummon is an advanced Open Source chatterbot. The main principle of the bot is that it has no initial knowledge of either words or grammar; it learns everything ""on the fly."" Numerous AI techniques will be explored in the development of Ummon to achieve realistic ""human"" communication with support for different, customizable personalities.          UMPRS Agent     Web site:   http://www.marcush.net/IRS/     UMPRS supports top-down, goal-based reasoning and selects goals and plans based on maximal priority. Execution of multiple simultaneous goals are supported, with suspension and resumption capabilities for each goal (i.e., intention) thread. UMPRS plans have an integrated precondition/runtime attribute that constrain their applicability. Available plan constructs include: sequencing, iteration, subgoaling, atomic (i.e., non-interruptable) blocks, n-branch deterministic conditional execution, explicit failure-handling section, and C++ primitive function definition.          Virtual Secretary Project (ViSe) (Tcl/Tk)      Web site:   www.cs.uit.no/DOS/Virt_Sec       The motivation of the Virtual Secretary project is to construct user-model-based intelligent software agents, which could in most cases replace human for secretarial tasks, based on modern mobile computing and computer network. The project includes two different phases: the first phase (ViSe1) focuses on information filtering and process migration, its goal is to create a secure environment for software agents using the concept of user models; the second phase (ViSe2) concentrates on agents' intelligent and efficient cooperation in a distributed environment, its goal is to construct cooperative agents for achieving high intelligence. (Implemented in Tcl/TclX/Tix/Tk)            VWORLD     Web site:   zhar.net/projects/vworld/       Vworld is a simulated environment for research with autonomous agents written in prolog. It is currently in something of an beta stage. It works well with SWI-prolog, but should work with Quitnus-prolog with only a few changes.  It is being designed to serve as an educational tool for class projects dealing with prolog and autonomous agents. It comes with three demo worlds or environments, along with sample agents for them. There are two versions now. One written for SWI-prolog and one written for LPA-prolog. Documentation is roughly done (with a student/professor framework in mind), and a graphical interface is planned.          WebMate     Web site:   www.cs.cmu.edu/~softagents/webmate/       WebMate is a personal agent for World-Wide Web browsing and searching. It accompanies you when you travel on the internet and provides you what you want.   Features include:    Searching enhancement, including parallel search, searching keywords refinement using our relevant keywords extraction technology, relevant feedback, etc.    Browsing assistant, including learning your current interesting, recommending you new URLs according to your profile and selected resources, monitoring bookmarks of Netscape or IE, sending the current browsing page to your friends, etc.    Offline browsing, including downloading the following pages from the current page for offline browsing.    Filtering HTTP header, including recording http header and all the transactions between your browser and WWW servers, etc.    Checking the HTML page to find the errors or dead links,  etc.    Programming in Java, independent of operating system, runing in multi-thread.              Zeus     Web site:   more.btexact.com/projects/agents/zeus/     The construction of multi-agent systems involves long development times and requires solutions to some considerable technical  difficulties. This has motivated the development of the ZEUS toolkit, which provides a library of software components and tools that facilitate the rapid design, development and deployment of  agent system              Next   Previous   Contents"
GX004-34-12615095	"Overview       Current Activities       National       State       Long-Term Trend        Selected Schools       Special Studies       Parents       Researchers                     The Arts       Civics       Economics       Foreign Language       Geography       Mathematics        Reading       Science       U.S. History       World History       Writing                               site index    |    ED.gov                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Help    Browser Requirements    This web site is compatible with version 4 or higher of either Netscape Navigator or Microsoft Internet Explorer browsers, although it is best viewed with Internet Explorer. Earlier versions will work for most of the site but may cause occasional problems with their appearance.  To download the latest version of Internet Explorer, visit the  Microsoft web site .    In addition, the following plug-ins may be required for viewing certain multimedia or document files on the site:     Adobe Acrobat Reader (version 3.01 or higher)  Adobe SVG Viewer (version 3 or higher)  Apple QuickTime (version 3 or higher)  Windows Media Player     Display Resolution   The vast majority of the pages on this site are designed to be viewable without horizontal scrolling when using a 640 x 480 screen resolution. Occasionally, you may come across a data table or some other content where this has been impossible to assure. When this occurs, you can eliminate the need for horizontal scrolling by changing your screen resolution to 800 x 600.    PDF Documents   Many NAEP reports and documents are made available on this web site in Portable Document Format (PDF). PDF is used because this format maintains the original look and feel of large documents, and allows us to place more publications on the web in a quick and efficient manner. Further, PDF products are independent of platforms, applications, and distribution media.    Viewing PDF files requires Acrobat Reader, either as standalone software or as a browser plug-in. Free versions of Acrobat Reader exist for all major computer platforms, including Windows 95, Windows 98, Windows NT, Macintosh, Sun, UNIX and several other operating systems.  Please follow the instructions on the  Adobe Acrobat download page  to install Acrobat Reader.    SVG Graphics   Scalable Vector Graphics (SVG) is a W3C recommendation (web standard) for a graphics file format and web development language based on XML.  Through the use of SVG, NAEP is able to offer dynamically generated, high-quality, scalable, interactive graphics from real-time data.  Although many SVG viewers are available, NAEP recommends the Adobe SVG Viewer 3.0 (or above) as a stable, well-supported viewer.  Visit  Adobe's  svg zone  for more information and to download a free viewer.    You can easily cut and paste any of the SVG images into software packages such as Microsoft Word, PowerPoint or Excel. To do this, right click on the SVG image and select ""Copy SVG."" Then go to your desired application and select ""Edit/Paste Special…"" and select ""Bitmap"" or ""Device Independent Bitmap.""     The  NAEP Data Tool tutorial  includes information on how to best use SVG graphics in your day-to-day work.    For more information on the SVG standard, or to get a list of available viewers, visit the  W3C's official overview  of the Scalable Vector Graphics (SVG) format.    Webmaster's note:  As of August 23, 2002, Adobe has identified several  known problems  with Netscape 4.x and Netscape 6.x which may prevent the SVG viewer from properly rendering the image.  There are no known work-arounds at this time.  Therefore, if you would like to view SVG graphics, we recommend the latest version of Internet Explorer (see above).    Audio and Video    Many pages on this web site feature audio and video.  While video requires the use of  QuickTime Player version 3  or later, audio can be played using both the QuickTime Player or  Windows Media Player .    Flash   NAEP also presents certain material in the form of Flash animations.  In order to view these animations, you will need to install the  Macromedia Flash Player , version 5 or higher.  Refer to  Macromedia's Flash support center  for assistance in working with the Flash Player.    PowerPoint Presentations   Finally, some material may be presented in PowerPoint format.  Visit the  Microsoft PowerPoint Viewer  site to download and install the PowerPoint Viewer 97 for Windows 95, 98, and 2000.    Printing   If you're trying to print a page with color or shading behind the text, and the colors aren't showing on the printed page, check your browser settings to ensure that background colors are enabled during printing.        Internet Explorer:  From the ""Tools"" menu, select ""Internet Options"".   On the ""Advanced"" tab, under ""Printing"", make sure you check ""Print background colors and images"".   Netscape 4:  From the ""Edit"" menu, select ""Preferences"".   Expand ""Appearance"" and select ""Colors"".   Make sure ""Always use my colors, overriding document"" is unchecked.   Netscape 6:  From the ""Edit"" menu, select ""Preferences"".   Expand ""Appearance"" and select ""Colors"".   Make sure ""Always use the colors and background specified by the web page"" is selected.        Last updated 31 March 2003 (HM)                                                  NCES Headlines                  •      JUST RELEASED! Remedial Education at Degree-Granting Postsecondary Institutions      •      JUST RELEASED! Projections of Education Statistics to 2013      •      NEW! NAEP 2003 Reading and Mathematics Assessments                                               NCES Home   |   Publications   |   Surveys & Programs   |   Quick Tables & Figures   |   Data Tools       Search   |   Help   |   News Flash   |   NCES Staff   |   Contact NCES   |   Site Index               National Center for Education Statistics   Institute of Education Sciences ,  U.S. Dept. of Education   ( map )  1990 K Street, NW, Washington, DC 20006, USA, Phone: (202) 502-7300"
GX016-87-6279807	"Overview       Current Activities       National       State       Long-Term Trend        Selected Schools       Special Studies       Parents       Researchers                     The Arts       Civics       Economics       Foreign Language       Geography       Mathematics        Reading       Science       U.S. History       World History       Writing                               site index    |    ED.gov                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Help    Browser Requirements    This web site is compatible with version 4 or higher of either Netscape Navigator or Microsoft Internet Explorer browsers, although it is best viewed with Internet Explorer. Earlier versions will work for most of the site but may cause occasional problems with their appearance.  To download the latest version of Internet Explorer, visit the  Microsoft web site .    In addition, the following plug-ins may be required for viewing certain multimedia or document files on the site:     Adobe Acrobat Reader (version 3.01 or higher)  Adobe SVG Viewer (version 3 or higher)  Apple QuickTime (version 3 or higher)  Windows Media Player     Display Resolution   The vast majority of the pages on this site are designed to be viewable without horizontal scrolling when using a 640 x 480 screen resolution. Occasionally, you may come across a data table or some other content where this has been impossible to assure. When this occurs, you can eliminate the need for horizontal scrolling by changing your screen resolution to 800 x 600.    PDF Documents   Many NAEP reports and documents are made available on this web site in Portable Document Format (PDF). PDF is used because this format maintains the original look and feel of large documents, and allows us to place more publications on the web in a quick and efficient manner. Further, PDF products are independent of platforms, applications, and distribution media.    Viewing PDF files requires Acrobat Reader, either as standalone software or as a browser plug-in. Free versions of Acrobat Reader exist for all major computer platforms, including Windows 95, Windows 98, Windows NT, Macintosh, Sun, UNIX and several other operating systems.  Please follow the instructions on the  Adobe Acrobat download page  to install Acrobat Reader.    SVG Graphics   Scalable Vector Graphics (SVG) is a W3C recommendation (web standard) for a graphics file format and web development language based on XML.  Through the use of SVG, NAEP is able to offer dynamically generated, high-quality, scalable, interactive graphics from real-time data.  Although many SVG viewers are available, NAEP recommends the Adobe SVG Viewer 3.0 (or above) as a stable, well-supported viewer.  Visit  Adobe's  SVG Zone  for more information and to download a free viewer.    You can easily cut and paste any of the SVG images into software packages such as Microsoft Word, PowerPoint or Excel. To do this, right click on the SVG image and select ""Copy SVG."" Then go to your desired application and select ""Edit/Paste Special…"" and select ""Bitmap"" or ""Device Independent Bitmap.""     The  NAEP Data Tool tutorial  includes information on how to best use SVG graphics in your day-to-day work.    For more information on the SVG standard, or to get a list of available viewers, visit the  W3C's official overview  of the Scalable Vector Graphics (SVG) format.    Webmaster's note:  As of August 23, 2002, Adobe has identified several  known problems  with Netscape 4.x and Netscape 6.x which may prevent the SVG viewer from properly rendering the image.  There are no known work-arounds at this time.  Therefore, if you would like to view SVG graphics, we recommend the latest version of Internet Explorer (see above).    Audio and Video    Many pages on this web site feature audio and video.  While video requires the use of  QuickTime Player version 3  or later, audio can be played using both the QuickTime Player or  Windows Media Player .    Flash   NAEP also presents certain material in the form of Flash animations.  In order to view these animations, you will need to install the  Macromedia Flash Player , version 5 or higher.  Refer to  Macromedia's Flash support center  for assistance in working with the Flash Player.    PowerPoint Presentations   Finally, some material may be presented in PowerPoint format.  Visit the  Microsoft PowerPoint Viewer  site to download and install the PowerPoint Viewer 97 for Windows 95, 98, and 2000.    Printing   If you're trying to print a page with color or shading behind the text, and the colors aren't showing on the printed page, check your browser settings to ensure that background colors are enabled during printing.        Internet Explorer:  From the ""Tools"" menu, select ""Internet Options"".   On the ""Advanced"" tab, under ""Printing"", make sure you check ""Print background colors and images"".   Netscape 4:  From the ""Edit"" menu, select ""Preferences"".   Expand ""Appearance"" and select ""Colors"".   Make sure ""Always use my colors, overriding document"" is unchecked.   Netscape 6:  From the ""Edit"" menu, select ""Preferences"".   Expand ""Appearance"" and select ""Colors"".   Make sure ""Always use the colors and background specified by the web page"" is selected.        Last updated 3 December 2003 (HM)                                                  NCES Headlines                  •      JUST RELEASED! Remedial Education at Degree-Granting Postsecondary Institutions      •      JUST RELEASED! Projections of Education Statistics to 2013      •      NEW! NAEP 2003 Reading and Mathematics Assessments                                               NCES Home   |   Publications   |   Surveys & Programs   |   Quick Tables & Figures   |   Data Tools       Search   |   Help   |   News Flash   |   NCES Staff   |   Contact NCES   |   Site Index               National Center for Education Statistics   Institute of Education Sciences ,  U.S. Dept. of Education   ( map )  1990 K Street, NW, Washington, DC 20006, USA, Phone: (202) 502-7300"
GX090-96-15497931	"Next   Previous   Contents     6. Agents           Also known as intelligent software agents or just agents, this area of AI research deals with simple applications of small programs that aid the user in his/her work. They can be mobile (able to stop their execution on one machine and resume it on another) or static (live in one machine). They are usually specific to the task (and therefore fairly simple) and meant to help the user much as an assistant would. The most popular (ie. widely known) use of this type of application to date are the web robots that many of the indexing engines (eg. webcrawler) use.              AgentK     FTP site:   ftp.csd.abdn.ac.uk/pub/wdavies/agentk       This package synthesizes two well-known agent paradigms: Agent-Oriented Programming, Shoham (1990), and the Knowledge Query & Manipulation Language, Finin (1993). The initial implementation of AOP, Agent-0, is a simple language for specifying agent behaviour. KQML provides a standard language for inter-agent communication. Our integration (which we have called Agent-K) demonstrates that Agent-0 and KQML are highly compatible. Agent-K provides the possibility of inter-operable (or open) software agents, that can communicate via KQML and which are programmed using the AOP approach.          Agent     FTP site:   www.cpan.org/modules/by-category/23_Miscellaneous_Modules/Agent/       The Agent is a prototype for an Information Agent system. It is both platform and language independent, as it stores contained information in simple packed strings. It can be packed and shipped across any network with any format, as it freezes itself in its current state.        agentTool     Web site:   en.afit.af.mil/ai/agentool.htm   Download site:   en.afit.af.mil/ai/_vti_bin/shtml.dll/registration.htm     Another Java based agent development framework. Fairly unique in that it emphasizes the use of a GUI for designing the system which will ""semi-automatically synthesize multiagent systems to meet those requirements"". You need a java enabled browser to download. :P        Aglets Workbench     Web site:   www.trl.ibm.co.jp/aglets/       An aglet is a Java object that can move from one host on the Internet to another.  That is, an aglet that executes on one host can suddenly halt execution, dispatch to a remote host, and resume execution there. When the aglet moves, it takes along its program code as well as its state (data). A built-in security mechanism makes it safe for a computer to host untrusted aglets. The Java Aglet API (J-AAPI) is a proposed public standard for interfacing aglets and their environment. J-AAPI contains methods for initializing an aglet, message handling, and dispatching, retracting, deactivating/activating, cloning, and disposing of the aglet. J-AAPI is simple, flexible, and stable. Application developers can write platform-independent aglets and expect them to run on any host that supports J-AAPI.        A.L.I.C.E.     Web site:   www.alicebot.org     The ALICE software implements AIML (Artificial Intelligence Markup Language), a non-standard evolving markup language for creating chat robots. The primary design feature of AIML is minimalism. Compared with other chat robot languages, AIML is perhaps the simplest. The pattern matching language is very simple, for example permitting only one wild-card ('*') match character per pattern. AIML is an XML language, implying that it obeys certain grammatical meta-rules. The choice of XML syntax permits integration with other tools such as XML editors. Another motivation for XML is its familiar look and feel, especially to people with HTML experience.          Ara     Web site:   wwwagss.informatik.uni-kl.de/Projekte/Ara/index_e.html       Ara is a platform for the portable and secure execution of mobile agents in heterogeneous networks. Mobile agents in this sense are programs with the ability to change their host machine during execution while preserving their internal state. This enables them to handle interactions locally which otherwise had to be performed remotely. Ara's specific aim in comparison to similar platforms is to provide full mobile agent functionality while retaining as much as possible of established programming models and languages.        BattleBots     Web site:   www.bluefire.nu/battlebots/     AI programming game where you design the bot by selecting hardware and programming its CPU, then competing with other bots. Competitions can have teams and special rules for a game.   The hardware for use in your bot includes weapons, engine, scanners, CPU, etc. The programming lauguage is dependent on the CPU type and is similar to an assembly language.         Bee-gent     Web site:   www2.toshiba.co.jp/beegent/index.htm     Bee-gent is a new type of development framework in that it is a 100% pure agent system. As opposed to other systems which make only some use of agents, Bee-gent completely ""Agentifies"" the communication that takes place between software applications. The applications become agents, and all messages are carried by agents. Thus, Bee-gent allows developers to build flexible open distributed systems that make optimal use of existing applications.        Bond     Web site:   bond.cs.purdue.edu/     Yet another java agent system...  Bond is a Java based distributed object system and agent framework. It implements a message based middleware and associated services like directory, persistence, monitoring and security. Bond allows to easily build multi agent, distributed applications. Another application of Bond will be a Virtual Laboratory supporting data annotation and metacomputing.         Bots     Web site:   utenti.tripod.it/Claudio1977/bots.html     Another AI-robot battle simulation.  Utilizing probablistic logic as a machine learning technique.  Written in C++ (with C++ bots).        Cadaver     Web site:   www.erikyyy.de/cadaver/     Cadaver is a simulated world of cyborgs and nature in realtime.  The battlefield consists of forests, grain, water, grass, carcass (of course) and lots of other things. The game server manages the game and the rules.  You start a server and connect some clients.  The clients communicate with the server using a very primitive protocol.  They can order cyborgs to harvest grain, attack enemies or cut forest.  The game is not intended to be played by humans!  There is too much to control. Only for die-hards: Just telnet to the server and you can enter commands by hand.  Instead the idea is that you write artificial   intelligence clients to beat the other artificial intelligences.  You can choose a language (and operating system) of your choice to do that task.  It is enough to write a program that communicates on standard input and standard output channels.  Then you can use programs like ""socket"" to connect your clients to the server.  It is NOT needed to write TCP/IP code, although i did so :) The battle shall not be boring, and so there is the so called spyboss client that displays the action graphically on screen.        D'Agent (was AGENT TCL)     Web site:   agent.cs.dartmouth.edu/software/agent2.0/   FTP site:   ftp.cs.dartmouth.edu/pub/agents/       A transportable agent is a program that can migrate from machine to machine in a heterogeneous network.  The program chooses when and where to migrate.  It can suspend its execution at an arbitrary point, transport to another machine and resume execution on the new machine. For example, an agent carrying a mail message migrates first to a router and then to the recipient's mailbox.  The agent can perform arbitrarily complex processing at each machine in order to ensure that the message reaches the intended recipient.        Dunce     Web site:   www.boswa.com/boswabits/       Dunce is a simple chatterbot (conversational AI) and a language for programming such chatterbots. It uses a basic regex pattern matching and a semi-neural rule/response firing mechanism (with excitement/decay cycles).  Dunce is listed about halfway down the page.        FIPA-OS     Web site:   fipa-os.sourceforge.net   Secondary Web site:   www.nortelnetworks.com/products/announcements/fipa/     FIPA-OS is an open source implementation of the mandatory elements contained within the FIPA specification for agent interoperability. In addition to supporting the FIPA interoperability concepts, FIPA-OS also provides a component based architecture to enable the development of domain specific agents which can utilise the services of the FIPA Platform agents. It is implemented in Java.        FishMarket     Web site:   www.iiia.csic.es/Projects/fishmarket/     FM - The FishMarket project conducted at the Artificial Intelligence Research Institute (IIIA-CSIC) attempts to contribute in that direction by developing FM, an agent-mediated electronic auction house which has been evolved into a test-bed for electronic auction markets. The framework, conceived and implemented as an extension of FM96.5 (a Java-based version of the Fishmarket auction house), allows to define trading scenarios based on fish market auctions (Dutch auctions). FM provides the framework wherein agent designers can perform controlled experimentation in such a way that a multitude of experimental market scenarios--that we regard as tournament scenarios due to the competitive nature of the domain-- of varying degrees of realism and complexity can be specified, activated, and recorded; and trading (buyer and seller) heterogeneous (human and software) agents compared, tuned and evaluated.        GNU Robots     Web site:   www.gnu.org/software/robots/robots.html     GNU Robots is a game/diversion where you construct a program for a little robot, then watch him explore a world. The world is filled with baddies that can hurt you, objects that you can bump into, and food that you can eat. The goal of the game is to collect as many prizes as possible before are killed by a baddie or you run out of energy. Robots can be written in Guile scheme or using a GUI.        Grasshopper     Web site:   www.grasshopper.de/     Another Java agent system. Full featured and actively developed. Commercial, but free. Historically targeted at embedded systems.          Hive     Web site:   hive.sourceforge.net   Web site:   www.hivecell.net     Hive is a Java software platform for creating distributed applications. Using Hive, programmers can easily create systems that connect and use data from all over the Internet. At its heart, Hive is an environment for distributed agents to live, communicating and moving to fulfill applications. We are trying to make the Internet alive.        ICM     Web site:   www.nar.fujitsulabs.com/icm/   SourceForge site:   sourceforge.net/projects/networkagent/     The Inter-Agent Communication Model (ICM) is a communication mechanism that can be used for sending messages between agents in an asynchronous fashion. Its intended application area is as a transportation mechanism for agent communication languages (ACLs), such as KQML and FIPA's ACL.          Jacomma     Web site:   jacomma.sourceforge.net   SourceForge site:   sourceforge.net/projects/jacomma/     Jacomma is an agent development platform/framework for developing distributed, mobile, and reactive information agents with heterogeneous communication capabilities, in Java and JPython.  Jacomma provides a development framework and an execution environment, which sits on top of the Inter-Agent Communication Model infrastructure. The ICM defines a communication protocol, a store and forward messaging architecture, and low level communication infrastructure for message exchange.  Communication is truly asynchronous, based on TCP sockets.  ICM has an entry in this howto, or you can find it via a link off the site.          Jade     Web site:   sharon.cselt.it/projects/jade/     JADE (Java Agent DEvelopment Framework) is a software framework fully implemented in Java language. It simplifies the implementation of multi-agent systems through a middle-ware that claims to comply with the FIPA specifications and through a set of tools that supports the debugging and deployment phase. The agent platform can be distributed across machines (which not even need to share the same OS) and the configuration can be controlled via a remote GUI. The configuration can be even changed at run-time by moving agents from one machine to another one, as and when required.          JAFMAS     Web site:   www.ececs.uc.edu/~abaker/JAFMAS       JAFMAS provides a framework to guide the coherent development of multiagent systems along with a set of classes for agent deployment in Java. The framework is intended to help beginning and expert developers structure their ideas into concrete agent applications. It directs development from a speech-act perspective and supports multicast and directed communication, KQML or other speech-act performatives and analysis of multiagent system coherency and consistency.    Only four of the provided Java classes must be extended for any application. Provided examples of the N-Queens and Supply Chain Integration use only 567 and 1276 lines of additional code respectively for implementation.          JAM Agent     Web site:   members.home.net/marcush/IRS/     JAM supports both top-down, goal-based reasoning and bottom-up data-driven reasoning. JAM selects goals and plans based on maximal priority if metalevel reasoning is not used, or user-developed metalevel reasoning plans if they exist. JAM's conceptualization of goals and goal achievement is more classically defined (UMPRS is more behavioral performance-based than truly goal-based) and makes the distinction between plans to achieve goals and plans that simply encode behaviors. Goal-types implemented include achievement (attain a specified world state), maintenance (re-attain a specified world state), and performance. Execution of multiple simultaneous goals are supported, with suspension and resumption capabilities for each goal (i.e., intention) thread. JAM plans have explicit precondition and runtime attributes that restrict their applicability, a postcondition attribute, and a plan attributes section for specifying  plan/domain-specific plan features. Available plan constructs include: sequencing, iteration, subgoaling, atomic (i.e., non-interruptable) plan segments, n-branch deterministic and non-deterministic conditional execution, parallel execution of multiple plan segments, goal-based or world state-based synchronization, an explicit failure-handling section, and Java primitive function definition through building it into JAM as well as the invocation of predefined (i.e., legacy) class members via Java's reflection capabilities without having to build it into JAM.          JATLite     Web site:   java.stanford.edu/java_agent/html/       JATLite is providing a set of java packages which makes easy to build multi-agent systems using Java. JATLite provides only light-weight, small set of packages so that the developers can handle all the packages with little efforts. For flexibility JATLite provides four different layers from abstract to Router implementation. A user can access any layer we are providing. Each layer has a different set of assumptions. The user can choose an appropriate layer according to the assumptions on the layer and user's application. The introduction page contains JATLite features and the set of assumptions for each layer.          JATLiteBeans     Web site:   waitaki.otago.ac.nz/JATLiteBean/         Improved, easier-to-use interface to JATLite features including KQML message parsing, receiving, and sending.                Extensible architecture for message handling and agent ""thread of control"" management                 Useful functions for parsing of simple KQML message content                JATLiteBean supports automatic advertising of agent capabilities to facilitator agents             Automatic, optional, handling of the ""forward"" performative            Generic configuration file parser            KQML syntax checker                      Java(tm) Agent Template     Web site:   cdr.stanford.edu/ABE/JavaAgent.html       The JAT provides a fully functional template, written entirely in the Java language, for constructing software agents which communicate peer-to-peer with a community of other agents distributed over the Internet. Although portions of the code which define each agent are portable, JAT agents are not migratory but rather have a static existence on a single host. This behavior is in contrast to many other ""agent"" technologies. (However, using the Java RMI, JAT agents could dynamically migrate to a foreign host via an agent resident on that host).  Currently, all agent messages use KQML as a top-level protocol or message wrapper. The JAT includes functionality for dynamically exchanging ""Resources"", which can include Java classes (e.g. new languages and interpreters, remote services, etc.), data files and information inlined into the KQML messages.          Java-To-Go     Web site:   ptolemy.eecs.berkeley.edu/dgm/javatools/java-to-go/       Java-To-Go is an experimental infrastructure that assists in the development and experimentation of mobile agents and agent-based applications for itinerative computing (itinerative computing: the set of applications that requires site-to-site computations. The main emphasis here is on a easy-to-setup environment that promotes quick experimentation on mobile agents.          Kafka     Web site:   www.fujitsu.co.jp/hypertext/free/kafka/       Kafka is yet another agent library designed for constructing multi-agent based distributed applications. Kafka is a flexible, extendable, and easy-to-use java class library for programmers who are familiar with distributed programming. It is based on Java's RMI and has the following added features:    Runtime Reflection: Agents can modify their behaviour (program codes) at runtime. The behaviour of the agent is represented by an abstract class Action. It is useful for remote maintenance or installation services.   Remote Evaluation: Agents can receive and evaluate program codes (classes) with or without the serialized object. Remote evaluation is a fundamental function of a mobile agent and is thought to be a push model of service delivery.   Distributed Name Service: Agents have any number of logical names that don't contain the host name. These names can be managed by the distributed directories.   Customizable security policy: a very flexible, customizable, 3-layered security model is implemented in Kafka.   100% Java and RMI compatible: Kafka is written completely in Java. Agent is a Java RMI server object itself. So, agents can directly communicate with other RMI objects.             Khepera Simulator     Web site:   diwww.epfl.ch/lami/team/michel/khep-sim/       Khepera Simulator is a public domain software package written by  Olivier MICHEL  during the preparation of his Ph.D. thesis, at the Laboratoire I3S, URA 1376 of CNRS and University of Nice-Sophia Antipolis, France. It allows to write your own controller for the mobile robot Khepera using C or C++ languages, to test them in a simulated environment and features a nice colorful X11 graphical interface. Moreover, if you own a Khepera robot, it can drive the real robot using the same control algorithm. It is mainly oriented toward to researchers studying autonomous agents.      lyntin     Web site:   lyntin.sourceforge.net/     Lyntin is an extensible Mud client and framework for the creation of autonomous agents, or bots, as well as mudding in general. Lyntin is centered around Python, a dynamic, object-oriented, and fun programming language and based on TinTin++ a lovely mud client.        Mole     Web site:   mole.informatik.uni-stuttgart.de/       Mole is an agent system supporting mobile agents programmed in Java.  Mole's agents consist of a cluster of objects, which have no references to the outside, and as a whole work on tasks given by the user or another agent. They have the ability to roam a network of ""locations"" autonomously. These ""locations"" are an abstraction of real, existing nodes in the underlying network. They can use location-specific resources by communicating with dedicated agents representing these services. Agents are able to use services provided by other agents and to provide services as well.        Narval     Web site:   www.logilab.org     Narval is the acronym of ""Network Assistant Reasoning with a Validating Agent Language"". It is a personal network assistant based on artificial intelligence and agent technologies. It executes recipes (sequences of actions) to perform tasks. It is easy to specify a new action using XML and to implement it using Python.  Recipes can be built and debugged using a graphical interface.         NeL     Web site:   www.nevrax.org     NeL is actually a game development library (for massive multi-player games), but I'm including it here as it (will) include a fairly  sizable AI library. Here's a blurb from the whitepaper:  The purpose of the AI library is to provide a pragmatic approach to creating a distributed agents platform. Its focus is agents; individual entities that communicate regardless of location, using an action-reaction model.         PAI     Web site:   utenti.tripod.it/Claudio1977/pai.html     AI (Programmable Artificial Intelligence) is a program capable of having a conversation in its mother tongue, English. Written in  C++.        Penguin!     FTP site:   www.perl.org/CPAN/modules/by-category/23_Miscellaneous_Modules/Penguin/FSG/       Penguin is a Perl 5 module. It provides you with a set of functions which allow you to:    send encrypted, digitally signed Perl code to a remote machine to be executed.   receive code and, depending on who signed it, execute it in an arbitrarily secure, limited compartment.     The combination of these functions enable direct Perl coding of algorithms to handle safe internet commerce, mobile information-gathering agents, ""live content"" web browser helper apps, distributed load-balanced computation, remote software update, distance machine administration, content-based information propagation, Internet-wide shared-data applications, network application builders, and so on.        Ps-i     Web site:   ps-i.sourceforge.net     Ps-i is an environment for running agent-based simulations. It is cross-platform, with binaries available for Win32. Features include:       declarative language for model specification   industry standard Tcl/Tk scripting with built-in routine optimization, speculative evaluation and xf86 JIT compiler users can create complex models without sacrificing perfomance    user friendly interface    save and restore program runs    change model parameters on the fly    data visualization: field display with multiple agent shapes and color, statistics window, agent viewer, routine browser and highlight agents tool            RealTimeBattle     Web site:   www.lysator.liu.se/realtimebattle/     RealTimeBattle is a programming game, in which robots controlled by  programs are fighting each other. The goal is to destroy the enemies,  using the radar to examine the environment and the cannon to shoot.       Game progresses in real time, with the robot programs  running as child processes to RealTimeBattle.   The robots communicate with the main program using the  standard input and output.   Robots can be constructed in almost any programming language.   Maximum number of robots can compete simultaneously.   A simple messaging language is used for communication, which makes it easy to start constructing robots.   Robots behave like real physical object.   You can create your own arenas.   Highly configurable.             Remembrance Agents     Web site:   rhodes.www.media.mit.edu/people/rhodes/RA/     Remembrance Agents are a set of applications that watch over a user's shoulder and suggest information relevant to the current situation. While query-based memory aids help with direct recall, remembrance agents are an augmented associative memory.  For example, the word-processor version of the RA continuously updates a list of documents relevant to what's being typed or read in an emacs buffer. These suggested documents can be any text files that might be relevant to what you are currently writing or reading.  They might be old emails related to the mail you are currently reading, or abstracts from papers and newspaper articles that discuss the topic of your writing.          SimRobot     Web site:   www.informatik.uni-bremen.de/~simrobot/     FTP site:   ftp.uni-bremen.de/pub/ZKW/INFORM/simrobot/       SimRobot is a program for simulation of sensor based robots in a 3D environment. It is written in C++, runs under UNIX and X11 and needs the graphics toolkit XView.    Simulation of robot kinematics   Hierarchically built scene definition via a simple definition language   Various sensors built in: camera, facette eye, distance  measurement, light sensor, etc.   Objects defined as polyeders   Emitter abstractly defined; can be interpreted e.g. as light or sound   Camera images computed according to the raytracing or Z-buffer algorithms known from computer graphics   Specific sensor/motor software interface for communicating  with the simulation   Texture mapping onto the object surfaces: bitmaps in various  formats   Comprehensive visualization of the scene: wire frame w/o hidden lines, sensor and actor values   Interactive as well as batch driven control of the agents and operation in the environment   Collision detection   Extendability with user defined object types   Possible socket communication to e.g. the Khoros image  processing software             Sulawesi     Web site:   wearables.essex.ac.uk/sulawesi/     A framework called Sulawesi has been designed and implemented to tackle what has been considered to be important challenges in a wearable user interface. The ability to accept input from any  number of modalities, and perform if necessary a translation to any number of modal outputs. It does this primarily through a set of proactive agents to act on the input.          TclRobots     FTP site:   ftp.neosoft.com/pub/tcl/sorted/games/tclrobots-2.0/   Redhat Patch:   ftp.coe.uga.edu/users/jae/ai/tclrobots-redhat.patch   RPMs (search at):   http://rufus.w3.org/       TclRobots is a programming game, similar to 'Core War'.  To play TclRobots, you must write a Tcl program that controls a robot.  The robot's mission is to survive a battle with other robots.  Two, three, or four robots compete during a battle, each running different programs (or possibly the same program in different robots.)  Each robot is equipped with a scanner, cannon, drive mechanism.  A single match continues until one robot is left running.  Robots may compete individually, or combine in a team oriented battle.  A tournament can be run with any number of robot programs, each robot playing every other in a round-robin fashion, one-on-one.  A battle simulator is available to help debug robot programs.    The TclRobots program provides a physical environment, imposing certain game parameters to which all robots must adhere.  TclRobots also provides a view on a battle, and a controlling user interface. TclRobots requirements: a wish interpreter built from Tcl 7.4 and Tk 4.0.          TKQML     Web site:   www.csee.umbc.edu/tkqml/       TKQML is a KQML application/addition to Tcl/Tk, which allows Tcl based systems to communicate easily with a powerful agent communication language.          The Tocoma Project     Web site:   www.tacoma.cs.uit.no/       An agent is a process that may migrate through a computer network in order to satisfy requests made by clients. Agents are an attractive way to describe network-wide computations.    The TACOMA project focuses on operating system support for agents and how agents can be used to solve problems traditionally addressed by operating systems. We have implemented a series of prototype systems to support agents.    TACOMA Version 1.2 is based on UNIX and TCP. The system supports agents written in C, Tcl/Tk, Perl, Python, and Scheme (Elk). It is implemented in C. This TACOMA version has been in public domain since April 1996.    We are currently focusing on heterogeneity, fault-tolerance, security and management issues. Also, several TACOMA applications are under construction. We implemented StormCast 4.0, a wide-area network weather monitoring system accessible over the internet, using TACOMA and Java. We are now in the process of evaluating this application, and plan to build a new StormCast version to be completed by June 1997.        Ummon     Web site:   www.spacetide.com/projects/ummon/     Ummon is an advanced Open Source chatterbot. The main principle of the bot is that it has no initial knowledge of either words or grammar; it learns everything ""on the fly."" Numerous AI techniques will be explored in the development of Ummon to achieve realistic ""human"" communication with support for different, customizable personalities.          UMPRS Agent     Web site:   members.home.net/marcush/IRS/     UMPRS supports top-down, goal-based reasoning and selects goals and plans based on maximal priority. Execution of multiple simultaneous goals are supported, with suspension and resumption capabilities for each goal (i.e., intention) thread. UMPRS plans have an integrated precondition/runtime attribute that constrain their applicability. Available plan constructs include: sequencing, iteration, subgoaling, atomic (i.e., non-interruptable) blocks, n-branch deterministic conditional execution, explicit failure-handling section, and C++ primitive function definition.          Virtual Secretary Project (ViSe) (Tcl/Tk)      Web site:   www.cs.uit.no/DOS/Virt_Sec       The motivation of the Virtual Secretary project is to construct user-model-based intelligent software agents, which could in most cases replace human for secretarial tasks, based on modern mobile computing and computer network. The project includes two different phases: the first phase (ViSe1) focuses on information filtering and process migration, its goal is to create a secure environment for software agents using the concept of user models; the second phase (ViSe2) concentrates on agents' intelligent and efficient cooperation in a distributed environment, its goal is to construct cooperative agents for achieving high intelligence. (Implemented in Tcl/TclX/Tix/Tk)            VWORLD     Web site:   zhar.net/projects/vworld/       Vworld is a simulated environment for research with autonomous agents written in prolog. It is currently in something of an beta stage. It works well with SWI-prolog, but should work with Quitnus-prolog with only a few changes.  It is being designed to serve as an educational tool for class projects dealing with prolog and autonomous agents. It comes with three demo worlds or environments, along with sample agents for them. There are two versions now. One written for SWI-prolog and one written for LPA-prolog. Documentation is roughly done (with a student/professor framework in mind), and a graphical interface is planned.          WebMate     Web site:   www.cs.cmu.edu/~softagents/webmate/       WebMate is a personal agent for World-Wide Web browsing and searching. It accompanies you when you travel on the internet and provides you what you want.   Features include:    Searching enhancement, including parallel search, searching keywords refinement using our relevant keywords extraction technology, relevant feedback, etc.    Browsing assistant, including learning your current interesting, recommending you new URLs according to your profile and selected resources, monitoring bookmarks of Netscape or IE, sending the current browsing page to your friends, etc.    Offline browsing, including downloading the following pages from the current page for offline browsing.    Filtering HTTP header, including recording http header and all the transactions between your browser and WWW servers, etc.    Checking the HTML page to find the errors or dead links,  etc.    Programming in Java, independent of operating system, runing in multi-thread.              Zeus     Web site:   www.labs.bt.com/projects/agents/zeus/     The construction of multi-agent systems involves long development times and requires solutions to some considerable technical  difficulties. This has motivated the development of the ZEUS toolkit, which provides a library of software components and tools that facilitate the rapid design, development and deployment of  agent system              Next   Previous   Contents"
GX255-33-5118444	"Architecture of Garnet Collaborative Portal DoE Components Meeting July 24 2001 Geoffrey Fox  IPCRES Laboratory for Community Grids Computer Science, Informatics, Physics Indiana University Bloomington IN gcf@indiana.edu 9/5/2001 doecomponentsjuly01 1   Garnet Heritage/Assumptions Support Education, Training and if possible Computing as Grid(Web) Services Use best practice commercial and academic capabilities  Access Grid, HearMe, Anabas, (JMS, WSDL, EJB, Castor, Oracle etc.)  Worry about Centra, WebEx, Placeware, Blackboard, WebCT, Saba, Groove, Docent etc.  Respect IMS/ADL Learning Object standards (http://www.adlnet.org) and GGF Computing Objects  Integrate Synchronous ""learning management Support hand held and access) 9/5/2001  and Asynchronous ( system"") collaboration desktop clients (universal 2  doecomponentsjuly01   Uniform XML event (message) based architecture  Linked with a publish-subscribe paradigm  Garnet Technology  XML Schema GXOS supports hierarchical data structures (compatible with DoD ADL SCORM for learning objects)  XML for all metadata (Users, documents, computers) and object changes -- from text chats to display changes etc.)  Java Middleware using Enterprise Javabeans Production system uses JMS (Java Message Service) to implement publish-subscribe  JMS does Synchronous and Asynchronous Messaging  MyXoS manages XML information nuggets 9/5/2001 doecomponentsjuly01 3   Important Capabilities in Initial Garnet Standard stuff: built in shared display, whiteboard, HearMe Audio control, quizzes, annotations, chat/IM (Jabber.org)  Desktop video will be special case of shared display Record and replay all features of session (SMIL)  A/V, Presentation, Annotations, Text Chat Several Specialized Collaborative Shared Export Viewers: JSP, ( later HTML, Acrobat ..) Initial SVG (Scalable Vector Graphics) Shared Batik Viewer  2D Scientific Visualization/Whiteboard  Macromedia (Flash~SVG) and Adobe (already ""all"" to SVG) Initial source of SVG: Convert PowerPoint VML/WMF to SVG  Gives shared export model for PowerPoint with each client able to scale independently at high resolution 9/5/2001 doecomponentsjuly01 4   JMS (Java Message Service) Structure in Garnet Basic primitive is a topic/property labeled queue = JXTA Pipe Pipes are collections of either messages or other pipes and just ""nodes"" in information hierarchy labeled by a URI JMS Global (distributed) Event Receptor (Queue) Subscribe Subscribe Publish Convert Events to JMS  HHMS  JavaScript  Java C++  .....  HHMS (Hand Held Message Service) Optimized for Performance. 5  9/5/2001  doecomponentsjuly01   Performance of Commercial JMS I One millisecond Late ncy (Noniser sistent) latency -P 10000 fine for Synchronous Collaboration and fine for Grid Implementation 1000  JM Q iBus SonicM Q FioranoM Q  milli-seconds  100  10  1  M e ssage Siz e (byt es)  9/5/2001  doecomponentsjuly01  64 K 25 6K  Non-persistent as We do database backup outside JMS  0  4  16  64  1K  4K  25 6  16 K  1M  6   Peer to Peer P2P Networks Publish/Subscribe is mechanism we use to establish who gets what information for Collaboration and P2P and may be ALL Grid and ALL Web Services? Gnutella and JXTA are different implementations Message (or event) information propagation (from JMS) of P2P services underlie P2P Grids  GMS can be built on top of JXTA or JMS architecture  JXTA like MyXoS identifies the implicit distributed operating (control messages/metadata) system     Both have message queues as primitives Both have Shell Both use XML based messages JXTA Advertisements are similar to GXOS metadata for objects doecomponentsjuly01  9/5/2001  7   Classic Grid Architecture Database Database  Resources  Composition Netsolve Portal  Neos Security Portal  Middle Tier Brokers Service Providers  Typically separate Clients Servers Resources  9/5/2001  Clients  doecomponentsjuly01  Users and Devices  8   Peers  Peer to Peer Network User Service Resource Routing User Service Resource Routing User Service Resource Routing  Peers are Jacks of all Trades linked to ""all"" peers in community Typically Integrated Clients Servers and Resources User Service Resource Routing 9/5/2001  User Service Resource Routing doecomponentsjuly01  User Service Resource Routing 9   Peer to Peer Grid User Service Resource Routing User Service Resource Routing User Service Resource Routing  GMS Routing  Services  GMS or GES is Grid Message/Event Service User Service Resource 9/5/2001  Dynamic Message or Event Routing from Peers or Servers User Service  User Service Resource doecomponentsjuly01  Resource Routing 10  Routing  Routing   Single Server P2P Illusion  Data base JMS/GMS Server  Traditional Collaboration Architecture e.g. commercial WebEx and old Syracuse system Tango 9/5/2001 doecomponentsjuly01 11   P2P Grid Event Service  a better JMS Dynamic Collection of some billion computers each of which can either generate, route or consume events Publisher labels events by an (XML) object which is at simplest a URI but in general a collection of tag-values or instance of XML Schema Subscribers issue some sort of XML Query e.g. deliver all gxos://garnet/Education/Graduate/ComputerScience/ Indiana/Spring2001/CPS616/Lecture3/* Need Secure, High Performance, Efficient (don't propagate events further than they need), Fault Tolerant delivery service Shrideep Pallickara PhD June 1 2001 Current version Java RMI based  could be SOAP doecomponentsjuly01  9/5/2001  12   Proposed GMS Model for Messages All message publication labels and subscription profiles are defined in XML Subscribes to all events to get Database persistence Subscriber Profile Objects Specify Query to Event Label  Message Queue Labeled by (XML) Topic Object  Publishers 9/5/2001 doecomponentsjuly01  Subscribers 13   Multiple Server P2P Illusion  Data base  JMS Server  JMS Server  Generate ""Automatically""  We are client  server  resource model with Clearly defined responsibilities to a Heterogeneous Dynamic Grid of service providers and Service consumers which are not necessarily distinct 9/5/2001 doecomponentsjuly01 14  JMS movingServer from   Some Results  22 Servers Servers are logically but not necessarily physically distinct from clients  9/5/2001  doecomponentsjuly01  15   Match Rates of 10%  &  Server Hop to client = 1  9/5/2001  doecomponentsjuly01  16   9/5/2001  All Objects are defined in XML (metadata) this XML view could be ""virtual"" but can be used to discover, edit (etc.) objects  labeled by a URI GXOS manages meta data defining all Objects -- it doesn't really want to manage Objects, just information required to find, access, store, render and share it  MUST have a good object management system to build collaboration service  Rendering includes Palm devices as well as PC's  Entities are people, cuuricula, grades, computers etc. All actions including object changes are events  all events are GXOS objects  Instant Messenger access, Framebuffer changes etc. are all GXOS events uniformly routed/archived etc. There is a Shell MyXoS with basic Services (copy, create, collaborate etc.)  similar in concept to JXTA Shell doecomponentsjuly01  Event-based Garnet Architecture  17   Overall Structure of GXOS for a MegaMeeting Capabilities Global Root Devices Documents Admin Event Archive  Users  Multimedia  MegaMeeting  Have a hierarchy of MegaMeetings (any collection of meetings) Course, Degree .. Are MegaMeetings  Any level (except lowest) can be a pipe Meeting Meeting  Meeting  gxos://Education/University/Indiana/CS/PhD/Course/Lecture 9/5/2001 doecomponentsjuly01 18   Interface of XML and Java I How will we teach computing?  K-4: Internet Access  Middle School: (Simple) XML Schema interfaced to some scripting language  High School: Java as the programming model with Java classes (for external data) generated Probably don't want to specify objects twice  Start in Java; generate Schema Or Start with Schema and generate Java Need a natural API of computer code to real or virtual XML  Current mechanisms seem quaint (JDBC), inefficient (parsers), or non standard (Castor) 9/5/2001 doecomponentsjuly01 19   Interface of XML and Java II Suppose we have a quadrillion (1015) Database XML objects as say produced by a physics accelerator per year (Enterprise GXOS) Need to combine: (Virtual) XML View  Search Interface to select nodes of XML Tree Specify URI JDBC or Google like Interfaces  Castor like Interface to map XML into Java but need to control depth of conversion from XML into Java  Choose And Convert  Middleware(EJB) 9/5/2001 doecomponentsjuly01 20   Current GXOS API Architecture Initially implement ""Personal GXOS""  Information Repository small enough that we can afford to read all possibly relevant information into memory and refine this  E.g. Support course data for individual faculty  File.xml  XML Object  Java Object and vice versa   Use Castor to automate XML Schema to Java Object  Primitives Supported Initially  Get a ""leaf Object""  Get a Collection (Internal Node)  ""handle"" and self.xml (the GXOS properties associated with this node)  List Contents of a collection (recursively)  Get Contents of a collection (recursively) 9/5/2001 doecomponentsjuly01 21   Integration of Hand Held Clients Client Device (machine) Profile stored in GXOS specifies O/S, default Screen Size modified by user (person) preferences  Dynamically updated with connection bandwidth, user updates  Application Profile stored in GXOS and modified by event stream specifies data delivered by GMS Adaptor (Personal Server) looks like a conventional client to GMS and adapts data to specified client/user specifications  If PDA ""small"", then SVG viewer on ""adaptor"" and ship framebuffer to PDA  ""Resize"" on PDA handled by adaptor, scrolling by PDA etc.  Adaptor can process complex XML queries 9/5/2001 doecomponentsjuly01 22   PowerPoint Shared Display PC to PDA  9/5/2001  doecomponentsjuly01  23"
GX031-90-12008400	A Distributed Collaboratory for High-Throughput Analysis and Annotation of Genomes                     Summary     The interpretation of the human genome represents the next grand challenge at the interface of computing and biology. The human and several microorganism genome sequencing projects will soon be producing data at a rate which exceeds current analysis capabilities. New methods and infrastructure need to be implemented for effective analysis and management of this data. Our overall objective is to design and implement a distributed computational framework for the genome community, which will provide users, genome centers, and this collaboratory, with services, tools and infrastructure for high-quality analysis and annotation of large amounts of genomic sequence data. The main components of the Analysis and Annotation Engine consist of a number of services, a broker that oversees the distribution of tasks, and a data warehouse, with services implemented using distributed object technology. We plan to use state-of-the-art computational technologies, algorithms, and data management techniques to provide biologists with as much information about a sequence as is feasible at any given time, and provide mechanisms to update the description of genomic regions over time. This framework will make maximal use of existing tools and database systems, and integrate services across many resources. Services for data input, analysis and gene modeling, sequence comparison, information retrieval, and data submission to central databases will be implemented within a flexible and extensible environment and configurable modes for high-throughput processing of large amounts of data will be supported. This framework will address issues of software sharing and reuse, generic interfaces to analysis tools, and methods for analysis system interoperation, which have not been adequately addressed in informatics developments community wide. We plan for a phased development in five areas over the initial three year time-frame of the project:  Task 1. Framework for the Analysis and Annotation Engine  deals with the design and construction of a genome analysis environment using distributed object technology and issues of interoperability;  Task 2. Data Input and Visualization Services  addresses data input issues for users and genome centers, data submission to public databases, and data visualization;  Task 3. Analysis Services  discusses the major methods and algorithms for sequence analysis we will initially deploy in our environment;  Task 4. Data Mining Services  deals with data mining;  Task 5. Data Warehouse  addresses the design and workings of the data management and storage facility. A collaboratory of central database designers, analysis tool builders, sequence data generators, and experimental biologists from 5 National Laboratories and 7 academic institutions, and with significant leveraging from existing informatics projects, will provide the expertise and tools necessary for this coordinated design and development effort. A Project Plan addresses the phased approach to implementation, plans for flow of data from genome centers to this project and to central databases, the collaboratory's plans to analyze and annotate significant amounts of public domain ``orphan'' data, the role of collaboratory members in implementation, and the organization of the collaboratory.        I. SPECIFIC OBJECTIVES     Our overall objective is to design, develop, and implement a distributed computational framework for the genome community which will provide users, genome centers, and this collaboratory, with services, tools and infrastructure for high-quality analysis and annotation for large amounts of genomic sequence data. Our specific objectives are as follows:              Implement an analysis system for DNA sequence data which will allow DOE funded projects to have consistent high-quality annotation, and through this, provide a model for the rest of the community.       Since large amounts of sequence are imminent and the analysis of these sequence data is critical, implement a working baseline system by the end of year 1.       Construct an extensible framework where multiple tools can be linked together and interoperate, where successful tools can be shared and easily accessed by the community, and which will serve as a focal point for future development of analysis tools.       Provide user access to multiple tools, state-of-the-art methods, specialized algorithms, high performance computing hardware, and many types of services without the user having to be a computer expert.       Provide users with data input, data analysis, data mining, data management, and data submission services all within a single easy to use environment.       Support large-scale batch processing modes using sophisticated algorithms, methods, and parallel computer hardware for large data providers (genome centers and databases) to meet the throughput requirements of the next phase of genome sequencing.       Provide a data model and the means to maintain and update the description of a genomic region. Users (individuals and large-scale producers) can specify recurrent analysis and data mining operations which continue over long time periods.       Provide mechanisms for the community to view (public domain) analysis results for genomic regions contained in the system by direct visualization using tools in the framework and through (user agreed) submission of annotation to central public databases.       Facilitate the analysis by this collaboratory of large amounts of public domain genome sequence data (through arrangements with the sequence producers) which might otherwise go unanalyzed.         To facilitate these objectives we envision an Analysis and Annotation Engine with the following components:              i.      Efficient and cross-cutting services and the corresponding agents for input of data from individuals, genome centers and from public database interfaces for purposes of generating analysis and annotation. These methods will be facilitated with the cooperation and assistance of genome centers and central databases.       ii.      A central body of data which will be stored in a warehouse, and analyzed and updated over time to provide a current best description of features at the sequence level for genomic regions which have been entered into the system. This description will be used to provide annotation for central public databases and be largely publicly available. A corresponding data model for analysis results and annotations (based on models compatible with GSDB, GDB(TM) and other central databases) will be used in the warehouse and to facilitate the submission of annotations to these databases.       iii.      A process manager which, based on an objective function, will activate data input, analysis, data mining and data submission services, schedule tasks to meet user requests, and continually update the data and its analysis state for users and within the warehouse.       iv.      Multiple pattern recognition tools and methods for feature detection and gene modeling. These will include several new hybrid methods which make integral use of pattern recognition, ESTs and protein homology to accurately recognize genes and to automate whole and partial gene model construction in fully or partially assembled sequence. In addition to providing the most accurate possible descriptions of genes and other features, these methods will also provide information of potential value to sequence assembly and finishing at genome centers.       v.      Multiple methods for sequence comparison, including specialized algorithms for frameshift tolerant alignment and sensitive comparison of long genomic regions. This will make integral use of parallel computers and specialized hardware systems created through the integration of high-performance computing resources at the ORNL, LBNL, ANL and at other collaborating sites.       vi.      Services and search agents for data mining (using CORBA agents and other methods, and using OPM, Kleisli, and Magpie data translators) to retrieve remote information relevant to the annotation of newly discovered genes and to provide inferencing relevant to a gene's biological role or significance.       vii.      Interfaces for access to services and data for individual users, from public databases, and from analysis environments constructed at genome centers. These interfaces will allow the configuration of multiple-step analysis protocols using available components. An API will be constructed to allow linkage of software at genome centers with the analysis capabilities in this project. This will provide widespread access to multiple tools and platforms for analysis. Specific linkage to DOE sequencing centers will be made in partnership with GSDB and GDB.       viii.      Portable scalable high-performance computer codes for compute intensive tasks which can be activated at multiple sites and used transparently during interactive or automated processing, and be configured in analysis protocols. This will provide needed cycles to genome centers and provide access to such capabilities by biologists with minimal computing expertise.       ix.      Services and corresponding agents which provide convenient mechanisms for the submission of data and analysis results to multiple public databases.             II. BACKGROUND AND SIGNIFICANCE     The human genome project, supported by DOE and NIH, is revolutionizing biology and biotechnology, providing important new emphasis on the biological sciences and their practical applications. Our increasing ability to analyze, manipulate, modify genes and biological macromolecules is creating new knowledge about fundamental biological processes, and providing numerous opportunities to apply this knowledge. There is significant new investment in the US, as companies new and old, seek to utilize the information for medicine and health care that stems from knowing all human genes, and the sequences of DNA from many humans.    At expected data rates, the finished (fully assembled) sequence generated each day will represent approximately 75 new genes (and their respective proteins). The information contained in these is of immeasurable value to medical research, biotechnology, the pharmaceutical industry and researchers in a host of fields ranging from microorganism metabolism, to structural biology. With only a small fraction of genes which cause human genetic disease identified, each new gene revealed by genome sequence analysis has the potential to have significant impact on human health. Timely development of diagnostics and treatments related to these is worth billions of dollars for the US economy, and computational analysis is a key component which can supply the necessary knowledge for this.     In addition to health-related biotechnology, other application areas of great importance to DOE include bioremediation, waste control, meeting energy fuel demands of the future and health risk assessment. Sequencing of microorganisms and other model organisms with significance for these biotechnology areas is also ramping up at a very rapid rate. The genomes for Haemophilus influenzae and yeast have just been fully sequenced, although the significance of many genes remains to be determined. The potential for the discovery of new enzymes and chemical processes important for biotechnology (for example - new types of degradative enzymes) as well as new insights into disease causing microbes makes these efforts highly valuable in both economic and social terms.     Annotation (the elucidation and description of biologically relevant features in the sequence) is an essential prerequisite before genome data can become useful. The quality with which annotation is done will have direct impact on the value of the sequence. A plain sequence is a meaningless string of characters, and one key to producing biological information and insight from this flood of data lies in effective and timely computation. At a minimum, this data must be annotated to indicate the existence of gene coding regions, control regions, and relationships between the sequence and other known sequences. In the last year or so significant growth of EST collections and new types of hybrid gene modeling methods, which integrate EST data with pattern recognition approaches, have become available. These can be used to produce very accurate analyses of genome sequence data in many cases. These methods require significant computational power, but if computing resources can be mustered, are capable of providing unprecedented accuracy for the localization of genes and other features in the sequence. Beyond coding region identification, finding features like simple and complex repeats, characterizing the organization of promoters and gene families, and tying together evidence for metabolic pathways are further annotation activities that add knowledge and value to a genome. Additionally important are statistical patterns such as the distribution of G+C content (isochore), codon usage, and correspondences between computed biochemical or structural properties and properties of expressed proteins measured experimentally. As complete genomes on the order of 2 to 3000 Megabases are sequenced, the length of DNA comparison strings has changed from single genes to entire genomes, with a concomitant expansion in the time to compute. In order to look at long range patterns of expression, syntenic regions on the order of 10's of megabases become of reasonable length for consideration. Significant work is required to develop the tools that will permit the analysis and visualization of long genomic regions needed for comparative genomic studies.     The recent funding of more than 10 major genome centers to begin high-throughput sequencing of the human genome has brought these analysis and annotation challenges into immediate focus. It has been estimated that on average from 1997 to 2003, approximately 2 million bases of newly finished DNA sequence will be produced every day and be made available on the Internet and in central databases. In addition, for many centers, sequence will be released for a given clone well before final sequence assembly, in the form of smaller sequence fragments (contigs) down to 1 kilobase (kb) in size. This means that at any given time, large amounts of partially assembled sequence will be available for analysis. We expect that the state of these sequences will be dynamic, changing day to day, and therefore, standard ``pipeline'' approaches which facilitate a single analysis pass are inadequate to deal with the temporal aspect of the problem.     Already, sequence is arriving at a rate and in forms which makes analysis and annotation very difficult. For example, several hundred thousand bases of human DNA sequence from chromosome 21 has appeared in the public sequence databases in 1-5 kb fragments rather than as a contiguous sequence. While this may meet the letter of informal international agreements to make sequence data available in a timely fashion, it is hardly useful to the broader biomedical community. Anyone who wishes to analyze this must ``re-assemble'' the sequence from these many small fragments - an absolutely ridiculous task. Large genomic clones are being routinely posted on the Internet and being deposited into public databases, with virtually no comment, analysis, or annotation, and mechanisms for their entry into public domain databases are in many cases inadequately defined. Valuable sequences are going unanalyzed because of the lack of methods and procedures for handling this data, and because current methods for doing so are so time consuming and inconvenient. And in real terms, the flow of data is just beginning.     At a very basic level, the primary question that can be asked of DNA sequence is what biologically relevant features can be associated with the DNA sequence and what can be inferred from these features? What features can and should be located and annotated for newly generated DNA sequence is presently a matter of discussion within the human genome community. During the spring of 1996 the National Center for Human Genome Research (NCHGR) at the NIH conducted an electronic workshop on the annotation of human DNA sequence to ask ``What annotation should be required before submission of the sequence to a central database?'' Examining the responses of the participants of this workshop can help to identify trends in the thinking of members of the genome community on the subject of sequence annotation.     The first trend that emerges is that there is no consensus on what constitutes appropriate initial annotation of DNA sequence. The range of opinion runs from ``no annotation is needed'', based on the observation that the sequence itself can be annotated later by individuals with different goals, to ``as much as possible'' (actually a list of more than 50 features or associated data). Also, the overall strategy for completing the DNA sequence of the human genome is still being worked out (see for example the commentary by Venter et al. (1996), and therefore the structure of the resulting data is still in flux.     There was consensus that certain metadata (discussed below) such as the origin of the clone which was sequenced, needs to be included and this has been taken into account in our data capture plan described previously. There was also general agreement that, what ever level of annotation is associated with the DNA sequence, the generation of the annotation cannot be allowed to become a bottleneck which slows down the release of the sequence data from the sequencing centers to the user community. This proposal is directed at alleviating this potential bottleneck.     It is clear that the information needed to make these data useful is not merely the sequence of a particular region of human DNA, but rather a detailed description of the biologically relevant features which are contained in that sequence. The ability of major sequencing centers to generate DNA sequence is rapidly outstripping their ability to provide comprehensive and timely annotation of the sequence. What follows is a comparison of current annotation from a high throughput sequencing center with what we envision as a prototype of automated annotation.     The cosmid HS314G4 (accession number Z69667, 31557bp) is from the teleomeric end of human chromosome 16 (16p13.3). The cosmid was generated at Los Alamos National Laboratory and was sequenced at the Sanger Center. The annotation of this 31kbp of DNA localizes 22 simple and complex (Alu and MER) repetitive DNA elements, 2 putative CpG islands (without specification of how they were detected) and 10 regions with homology to various, usually unspecified, expressed sequence tags (ESTs).  Table I  shows the annotation of HS314G4 from its GenBank(R) entry. Analysis of the this sequence using Xgrail_1.3 in conjunction with a variety of database search tools reveals a much richer picture of the biological implication of this sequence. Using different, but well documented methods, this analysis finds 41 simple and complex repeats and 8 CpG islands. The GRAIL analysis also reveals 38 potential protein coding exons (30 of them ``excellent'').  Figure 1  shows the Xgrail analysis of HS314G4.     Through a combination of gene modelling and database searching the GRAIL exons identify 5, or possibly 6, genes. Three of these putative genes have homologs in GenPept and ``complete'' cDNA sequences for two of these genes are also in the sequence databases. One gene, consisting of 11 exons, is identical to the gene for a pancreas specific protein disulfide isomerase (PDIp, Desilva et al., 1996) which has been mapped by somatic cell hybrids and FISH to human chromosome 16p13.3. The presence of a cDNA sequence for PDIp allows for the refinement of the computer generated gene model and the precise annotation of the genomic structure of this gene, which is currently undocumented. A second gene consisting of 7 exons is identified as a member of the GDP-dissociation inhibitor family by homology to a mouse rho-GDI (79% identity). Again the gene model for rho-GDI can be refined by using the cDNA sequence (MUSRHOG, L42463) which, even though it is heterologous, allows the precise identification of intron/exons boundaries and the annotation of this as yet undescribed human gene. It is also interesting to note that the PDIp and rho-GDI genes are very close together, the 3' end of rho-GDI and the 5' end of PDIp are separated by less than 300bp, and transcribed in the same direction.                      Another gene model containing 12 exons shows similarity to a number of G-protein signaling factors (BLAST P value <10-10) though the relationship here is less clear than in the two examples above. It is probable that with further analysis the gene represented by this model could be further characterized. A final gene model made up of 3 exons does not appear to have any close relatives in any of the protein sequence databases. It does, however, hit a number of ESTs in dbEST so it presumably represents a genuine transcriptional unit and its presence in cDNA libraries derived from several different tissues suggest that it may be widely expressed. The last transcriptional unit identified by this analysis is a single, excellent exon which is not represented in the protein sequence databases but which does hit a number of ESTs. ESTs corresponding to this exon are found in several cDNA libraries again suggesting a general expression pattern.    We do not imply that the above analysis is exhaustive, for example we do not report any of the bibliographic data related to these genes nor are any of the possible biochemical and/or structural data which may be relevant presented. Neither have descriptions of the gene families of these proteins nor the evolutionary relationships of these proteins been reported. Nor are the gene modeling methods as sophisticated as those we will apply in this project. Yet this preliminary analysis provides much more useful information than can be found in the current DNA sequence database entry for this cosmid. It should also be noted that this analysis took more than a day's work for a knowledgeable analyst. Clearly if even this minimal level of biological annotation is to be included in all of the sequence currently being generated at the major sequencing centers, a more streamlined methodology must be developed.     It is also important for a user to know what analysis was preformed on the data and when. It is just as important to know that if the sequence annotation reveals nothing of biological interest, there really is nothing there. In another cosmid from 16p13.3, similar analysis found a paucity of coding exons and it is important that a user knows the way in which the data were generated so that they that the absence of a feature doesn't merely reflect a lack of analysis.     This collaboratory recognizes the analysis of this data as a community-wide problem which needs a clearly defined plan and course of action. Sporadic manual methods, applied by interested individuals (as third party annotation) will not provide the consistent level of base annotation which is really needed, and such processes will not have the required throughput to keep up with data generation rates. Part of the rate limitation is due to the difficulty in capturing, organizing and assembling the data, the necessity to reformat the data for various analysis methods and for multiple database submission tools. In fact, in a workshop at the most recent VIIth Genome Sequencing and Analysis Conference in Hilton Head, SC, the most common complaint by biologists about analysis was the necessity to continuously reformat data to apply the next tool. Analysis tool designers have in general failed to achieve any significant level of interoperability between systems. Different tools are not designed to work with one another or be easily configured into any larger framework for analysis and annotation. This was also alluded to in a 1992 review of DOE informatics which stated:              Very little central direction is given to the DOE genome informatics effort. As a consequence, the individual centers and off-site investigators are operating in independent, often conflicting directions, with duplication of effort. For example, standardization of data interfaces for software tools was not mentioned as a goal at any of the centers (in the review). Many of the software tools include modular features (which) were being implemented as tightly coupled components of their respective laboratory information systems and not as components which could be easily transferable to any other site. This leads to an unfortunate duplication of effort. In addition, successes at any of the centers are not recognized and propagated to other centers.     The framework we propose to create using distributed object technology will provide the basis for interoperability, modularity, software sharing, component reuse, and analysis system growth that will be necessary for the next phase of the genome project.    Databases in general have also been slow to deal with both the magnitude and complexity of this analysis. This is partly because the analysis is not the primary mission of the databases, whose primarily job is to collect and manage the data. Some databases, such as GenBank, will not accept computer generated annotation at the present time (unless generated in-house using in-house tools) and in this model, analysis results must be regenerated every time an individual needs it. This is a very inefficient process, with significant inherent redundancy of effort, and it requires the user to have the expertise to facilitate the required analysis. This is generally not likely to produce optimal results. GSDB has taken the issue of linkage to analysis systems more seriously and is providing mechanisms to link through the database interface to tools. GSDB has also has taken steps to provide mechanisms for bulk data and annotation submission. However while enabling analysis from the database interface, this mechanism does not provide or define the means by which analysis or annotation is actually generated (what tools and methods are used and by whom). Therefore, the responsibility for large-scale analysis falls upon the bioinformatics community, which must address the infrastructure and provide the effort needed to facilitate annotation on a consistent and community-wide basis. We believe that by linking data generators, tool makers, database designers, and biologists together, we can implement the missing components of this infrastructure and provide a solution to the community at large.     In considering a large-scale analysis and annotation process, it is useful to consider models for this which have developed previously. Procedures for high-throughput analysis have been most notably applied to several microorganisms (Haemophilus influenzae (Fleischmann et al. 1995) and Mycoplasma genitalium (Fraser et al. 1995) using relatively simple methods designed to facilitate basically a single pass through the data (a pipeline which produces a one-time result or report). We believe however that this is too simple a model for the analysis of genomes in the long term. For one thing, the analysis of genomic regions needs to be updated continually through the course of the genome project - the analysis is never really done. On any given day, new information relevant to a sequenced gene may show up in a database, and new links to this information need to be generated. Secondly, the more complex structure of human genes, and the availability of new analysis methods provides both a necessity and an opportunity to carry out more sophisticated analysis on this data than was needed for on microorganisms. Additionally, our capabilities for analysis and the state of the sequence itself will change with time. We will be able to recognize many features (like regulatory regions) better in several years than we can now. There will be significant advantage in reanalyzing sequences and updating annotations continually as methods improve and databases with relevant information grow. In this model, annotation is a living thing which will develop richness and improve in quality over the years. The ``single pass-through pipeline'' is simply not the appropriate model for human genome analysis.     In addition few genome centers are applying state-of-the-art methods to their initial analysis, partly because of lack of computer power, partly because newer more accurate methods have not been widely deployed in the community or are not understood, and partly because proper analysis and annotation using current methods take a lot of time and effort. Genome centers are primarily sequence generators and are often content to leave the analysis to someone else. Center informatics groups have a very difficult local support mission and are often unable to deal with ``non-essential'' issues. So whose mission is it? How will we analyze 2 megabases a day in a consistent and high-quality manner? This collaboratory will work to ensure that this question is answered for DOE sequencing projects and implement a model for the rest of the community as well. We will also commit to analyze and annotate large amounts of ``orphan'' data which would otherwise go unanalyzed by the sequence generators (with their permission and help). Also, part of the reason that analysis and annotation has been placed on the back burner is that methods for many types of analysis are only partially accurate. A strategy to compensate for this is the ``shove all predictions from all tools into ACeDB'' method, which assumes that truth can be established at some later date by a human annotator. Better methods of analysis, better data management models, and better analysis models need to be applied.     Even though we have highly optimized methods for producing the sequence data, current manual processes for sequence input, analysis, comparison, information retrieval, and results submission represent a very wasteful and inconsistent process. As a community, we are relying on Internet posting, analysis by random individuals, and ad hoc one-pass pipelines which simply do not scale to high-throughput genome sequencing. We believe that, just as we have teams of experts for generating the sequence, we need to have teams of experts who help the community analyze and annotate the sequence. The members of this collaboratory represent such a team, and can provide services with impact community-wide. Through good engineering and high-quality services, we can make analysis and annotation much easier to generate, maintain and update, and make these important capabilities accessible to individuals and genome centers alike. It is not our mission to impose standards for how annotation should be done, but rather to make it easier to access and utilize a variety of methods which can add value to the sequence through high-quality analysis. It is essential that we apply the next generation of organization, methods and infrastructure to this problem.         III. APPROACH         III.1 Basic System Concept     The main components of the Analysis and Annotation Engine consist of (1) a number of services, (2) a broker that oversees distribution of tasks, and (3) a data warehouse. The services will be implemented using distributed object technology. Each provided service will have a well defined interface that facilitates integration with other processes. These components will be used to build and maintain a description of each genomic sequence region entered into the system and update these over time as new information or analysis can be facilitated.    Our data model uses a physical genomic clone as a basic information unit since most genome centers producing sequence data do this also, and this also makes it easy to link to entities in the GDB(TM) and GSDB databases. Basically each clone has map information associated with it and information about the contigs from it which have been sequenced. In some cases the sequence will be complete for the clone while in other cases, several contigs may have been sequenced with uncharacterized gaps and uncertain order.     Our system will input, construct and maintain a description of these reagents and link analysis results produced through pattern recognition, sequence comparison, etc. to this physical clone framework. To build and continually update the analysis associated with these clones, several types of servers and agents must work toward objectives which benefit this central data. We use the term servers to indicate systems which provide analysis and agents to indicate processes which interact with data sources such as genome centers or databases. For example, we view access to SWISS-PROT to get information about a protein as facilitated by an agent, while an in-house sequence comparison algorithm would be set up as a server. The multiple processes of analysis, update, input, etc. will be going on all the time asynchronously under the guidance of the service broker. We show these agents and servers schematically in  Figure 2 .     In this project, our workspace (contained in a data warehouse) is designed for members of the community to conduct analysis and manage analysis results. It is not a substitute for local data management at genome centers or for central public databases. What is maintained in the warehouse is a working copy of data which users (individuals, genome centers, central databases, and this collaboratory) place there for purposes of facilitating an ongoing analysis process. Computer-based agents will operate on the data, based on arrangements made by users or using default options provided by the system. Users can direct agents to facilitate one-time tasks or set up ``standing instructions'' which will trigger analysis events over time, either periodically or conditionally. An example of a conditional operation would be to submit analysis results to GSDB when a particular type of analysis has been done in the system. A periodic operation would be to ``check SWISS-PROT every 24 hours for any new proteins related to a gene in my sequence, and if so create a data link to the SWISS-PROT entry''.     Agents may be invoked to input data from particular sources, configure and carry out series of analysis steps using the available analysis servers, submit analysis results to databases, and many other tasks. For example we will construct agents to input sequence and clone metadata from genome centers, central databases, or individual users, agents for information retrieval (data mining) of remote databases and agents for submission of annotation and analysis results to public databases like GDB, GSDB, GenBank. We will construct or use existing servers for analysis operations such as pattern recognition, gene modeling, sequence comparison. Since this is a distributed system, servers may be physically remote. Unlike any other existing system, components for data input, analysis, storage, update and submission will all be linked in a single framework.                      Using this approach, a user can define a set of instructions for the Analysis and Annotation Engine that improve the analysis state of the data, recognize the existence of new relevant information, submit new findings to public databases, etc. over long time-frames. Unlike the one-pass analysis pipeline, this approach provides greater flexibility to configure analysis steps, triggers, conditions, and updates. Also unlike the pipeline approach, where steps must follow one another, individual processes for input, analysis, data mining, etc. in this system are effectively decoupled from one another and interact with one another only at the level of the data in the warehouse. This leads to full modularity of design with the accompanying advantages of flexibility and an ease of addition of new processes to the system. Using this approach the analysis of each genomic region entered into the system can remain current and we will be able to provide biologists as much information about a sequence as is feasible at any given time.        III.2 Interoperability, Flexibility, and Extensibility     The model we propose, which uses a broker between analysis tools or agents and the data warehouse, has many advantages in terms of being able to establish interoperability, arrange for flexible steps in analysis, and being able to extend the system to incorporate new tools and services. The broker deals with details of I/O to the warehouse and as a result agents and analysis servers do not need to know the details of data formats in the warehouse or where data is physically stored. The broker will get data from the warehouse as needed and package relevant parts of the data for specific agents or servers.    We believe that the ways the data is structured for presentation to analysis tools and agents can be relatively simple and standardized. For example many analysis programs use a segment of sequence and a set of parameters as input. It should be possible to create a standard interface formats where input data can be presented to such programs. We may likewise be able to define a limited set of standard ways or presenting analysis results of various kinds. For example, many analysis tools define a feature output similarly and the overall output could be the same sequence and an array of features. Simple features like a TATAA box or predicted exon would have a start and end position, quality parameters; an alignment would have start and end plus the name of the aligned sequence with coordinates. Agents and servers will return results such as feature objects to the service broker which will route them to the warehouse, the user interface for graphical display (in which the user service than assembles the features into lines and marks the sequence in an intelligent manner) or to a report generator, submission tool, etc.     By creating a modest set of standardized ways of representing typical data types, it becomes fairly easy for analysis steps to be linked together through the broker. A given tool (server) merely needs to make use of the existing formats and it can automatically be linked into a set of steps configured by a user. Existing tools and services can also be incorporated. For example, if we were to incorporate BLAST, we would build a wrapper that takes the input and constructs BLAST email, web request, or command line, and parses the output to generate the feature list which is returned to the broker. (The wrapper would likely be written to handle ASN.1 format to be more reusable.)     A great advantage to this system is its modularity and extensibility. Agents for new databases can be added and new analysis modes can be facilitated by new servers without undoing or significantly changing existing systems. Future developments are made easier by allowing developers to focus on writing good algorithms, while making use of the input and output services from the broker. This way the I/O is does not have to be duplicated for every new service and the tool is immediately compatible with other processes in a manner somewhat similar in spirit to the World Wide Web. This differs significantly from a tightly coupled pipeline approach where components are depend on one another in fixed and specific ways, and where slower operations, such as data mining, are difficult to include since they slow down the pipeline. In our model we have effectively decoupled the various processes from one another, but provided generic ways for them to interact as needed.     It is inevitable that changes in the data model (the representation of analysis results) may be needed over time to incorporate new types of information or analysis, but this can be done in ways which do not undo or conflict with previous parts of the model, and such changes should have a limited effect on the many component parts of this system. One of our goals is to be able to easily modify and adapt this framework to the changing analysis needs throughout the course of the genome project. We will make information available so servers can be added by other designers and tool builders. We expect this framework to act as a nucleation site for tool builders (described in  Task 3 ). Unlike the description of DOE informatics in the 1992 review, this model can achieve interoperation of tools, software reuse by multiple centers and a flexible, user defined coupling of processes.         III.3 Services     The model we have described provides the basis for several types of services for users. These include services for interactive access by individuals, batch processing modes for genome centers and the collaboratory, and services for analysis, data mining and data submission to central databases. A schematic of these services is shown in  Figure 3 . We describe these briefly here:                         Service Manager / Task Broker     The Service Manager is a central routing point in the system. There can be as many brokers as necessary to cope with the workload. Services that come on-line, have to register with the broker and unavailable services are marked as down. The broker also keeps track of which services have been requested and answered. An unanswered service will be forwarded to one other analysis server if the service is redundantly provided. If the request cannot be answered by the second server it will be forwarded to an operator. The service manager will deal with issues of prioritizing and task scheduling based on an objective function.        Large-Scale Data Input Services.     Sequence data from large producers, e.g., genome centers, databases, can be processed in an automatic manner. We will negotiate with the data producers an appropriate exchange mechanism for the data and help to configure the kinds of analysis that should be performed on the sequence. We envision building software agents that will fetch data from ftp sites and similar ``publication'' mechanisms and pipe the sequence data through a mutually agreed upon set of analysis routines. The results can be returned to the data providers, and if specified by the data provider, submitted to public genome sequence databases, and maintained in the warehouse.        Individual User Services.     The user input services will consist of graphical user interfaces to specify analysis tasks, submit sequences for analysis, and display results. Biologists will be able to select services they want applied to their sequence, specify parameters, and send the sequence to the service broker which will route requests to the appropriate service providers, e.g., a compute server that runs the requested analysis on the sequence. A special type of agent for submission of data to central databases will be provided based on the SubmitData system developed at LBNL (see  Appendix I ). Options for submission of data to central databases will be configurable by users.        Analysis Services.     Analysis services form one of the core components in the Analysis and Annotation Engine. Members of this collaboratory are developing new algorithms for sequence comparison, pattern recognition, and gene modeling as a result of current DOE and NIH-funded projects. Many of these, as well as other existing computational biology tools, will be incorporated into this framework. Through the use of a common interface it will be possible to add new services and build CORBA wrappers to integrate existing services. Because analysis services can be anywhere on the Internet, any respectable computational biologist will be able to offer a new service to the community by implementing the standard interface and registering it with the broker. Dedicated high-performance compute servers making use of supercomputer centers at ORNL, LBNL, and ANL will be able to carry most of the load, but additional compute servers can be added anytime, if there is a need.        Data Mining Services.     Many types of information with potential value for interpreting each newly sequenced genome region must be retrieved from more than a dozen remote databases. Automated methods to retrieve, collate, and fuse database information will be implemented to provide insight into a gene's biochemical function, pattern of expression, organism function, the corresponding protein's potential structure or structure class, functional family, functional motifs, metabolic role, and potential relationship to disease phenotypes. We will construct two kinds of agents: update agents and search agents. Update agents deal with databases, e.g., GenBank, and other data sources that produce data regularly and will automate maintenance of the data warehouse. Update agents will also be used to extract summary information, e.g., all references from SWISS-PROT to other databases. Search agents handle more specific information gathering tasks, e.g., where the source of the information is not certain. Information collected this way would be stored in the warehouse with a time stamp, and be available as annotation. Search agents will very often return pointers to relevant information in other databases. This way over time we can build a respectable repertoire of genome information without downloading the universe onto our disks. For search agents, a user would be able to specify which connections and what order to follow (in a manner similar to configuring a set of analysis tasks).        Data Warehouse     The data warehouse will be a distributed storage facility for sequence data, metadata, analysis results, data links, and parameters to run the analysis routines. We will evaluate the usability of more generic search engines, like IRx(R), Lycos, Inktomi, etc., to generate rigorous indexes of genome related information. Such an index would greatly facilitate the annotation. It would be possible to extract related information about a sequence by merely examining the index that contains very brief descriptions and links to public databases. The user interface or a report generator is left with the task of following each link and retrieving relevant information from the databases. The data retrieved by the intelligent agents or calculated by the Analysis and Annotation Engine must be efficiently stored in the warehouse for optimal access by the Engine as well as users. The terabyte storage facilities at the CCS and NERSC are available and could be used to handle the data warehousing needs of the project. Some data sources include multimedia (gene expression and anatomical objects which involve multidimensional data). The data warehouse component of the project will leverage components developed in previous DOE computing efforts and will need to optimize the access times by both the Analysis and Annotation Engine itself and by mining agents seeking specific calculated results.        III.4 Task Outline     We conceptually divide the project into five research and development tasks described in  Section IV. RESEARCH PLAN . The following is an outline of these sections:        Task 1. Framework for the Analysis and Annotation Engine          Building the Framework     Service Manager / Task Broker     Defining Object Interfaces        Task 2. Data Input and Visualization Services          Large-Scale Data Input Services     User Input Services     Visualization, Data Submission Tools, and Report Generators        Task 3. Analysis Services          Pattern Recognition Algorithms     Gene Modeling Systems     Sequence Comparison Systems     Providing Constraints for Sequence Assembly     Tools for Comparative Genomics     Protein Characterization Tools     Other Analysis Tools and Resources        Task 4. Data Mining Services          Data Mining Agents     Data Accessors and Translators        Task 5. Data Warehouse          The Data Model     Warehouse Databases        Project Plan  - Implementation, Organization, and Data Flow               i.     Detailed Implementation Plan       ii.     The Role of Collaboratory Members in System Implementation       iii.     Organization and Management of the Collaboratory       iv.     Large-Scale Analysis and Annotation Plan by the Collaboratory                 IV. RESEARCH PLAN     The Analysis and Annotation Engine incorporates a number of functions that will work in parallel and be distributed among the members of the collaboratory. The scenario somewhat resembles existing web services, in particular, the BCM Search Launcher (Smith et al. 1995) which presents a common interface to a number of sequence analysis tools on a web page, forwards the query to an appropriate web server executing the analysis programs, and enhances the results by inserting hypertext links to databases. But instead of providing a common, easy-to-use front end to biologists, we intend to take a more active role in establishing tools and in acquiring and analyzing genome information. We propose to build a more general tools framework that will use state-of-the-art Distributed Object technology.    The main process steps are given below and illustrated in  Figure 4 :               i. Data Input Agents poll Internet sites of participating genome centers to collect any new data that has been posted. New sequences and metadata are captured, placed in the analysis queue. Central community databases with interfaces which support analysis, like GSDB, can access the system by posting data to be analyzed in the queue. Individual users may use other interfaces, e.g., web interfaces, email, or special graphical user interfaces, to submit sequences to the analysis queue. An overall process manager maintains lists of available services, servers, and resources.       ii. The Analysis Queue feeds a series of Analysis Servers which execute tools for sequence similarity searches, pattern recognition, hybrid pattern recognition, and sequence comparison based gene modeling, etc., in a number of separate processes. These analysis servers are running continuously polling the queue maintained by the process manager. Multiple servers which perform the same function will compete for tasks and achieve approximate load balancing. Implementations of analysis algorithms for parallel machines and specialized sequence comparison hardware will be integrated as available services. The planned analysis services are described in  Task 3 .       iii. Upon completion of the analysis, Analysis Results, such as gene models, promoters, and repetitive DNAs, will be placed in the Data Warehouse and linked to the clone or clones on which these features appear, updating the description of this genomic region.       iv. Data Mining Agents make use of analysis results such as gene models to find information at remote sites which may be relevant to the analysis. Information returned by data mining agents is placed in the warehouse in the appropriate attributes of the data model. In some cases inferencing related to data mining may provide information which triggers new analysis tasks. Each data mining agent will be designed with a particular information retrieval goal (to get a particular type of information or result). One or several data mining agents may be designed for a given database and some agents may facilitate cross-database query. These agents may make use of existing systems such as Kleisli, OPM, or Magpie which are designed to facilitate translation and multiple database query or may have to use other and potentially ad hoc methods. Data mining agents are described in  Task 4 .       v. Data Submission Agents submit new results to participating genome databases, with each submission agent tailored to the types of data appropriate for the target database. Depending on the database, the source of the original sequence and arrangements made with sequencing centers, the sequence itself may or may not be part of the submission. A special type of submission agent will be constructed to return results of analysis to the genome center responsible for the data. Data submission agents are described in  Task 2 .                          While we have described these events in a somewhat linear order, it is important to realize that the many processes for capture, analysis, mining and submission are going on continually and asynchronously. An overall objective function will be used to prioritize tasks in the several queues and between queues so that the most time critical steps are done expediently. We view our warehouse somewhat like a real warehouse of perishable items, where expiration dates and consumer demand determine the replenishment policy. The objective function is designed to facilitate the most essential tasks first and prevent problems, bottlenecks or spoilage. More detail about the warehouse, the objective function, and overall framework for the task management is described in  Task 1  and  Task 5 .    In our warehouse we must necessarily keep a brief description of clones, genes, etc. It is the responsibility of central databases, however, to provide this information to the community. We view our system as a ``staging ground'' for data and analysis which is designed to provide the basis for information in public databases or feedback to data producers or other users. By mirroring the structure of data in GSDB and GDB in our data model we expect to be able to transfer results to these databases without significant difficulty and also provide links to data which will only reside in these databases.         Task 1. Framework for the Analysis and Annotation Engine         Task 1.1 Building the Framework     Designers of computer software have been searching for a rigorous, building-block approach to the design and construction of programs for many decades. While early concepts of these building blocks, e.g., subroutines in COBOL and FORTRAN, showed promise to assemble complex software from smaller parts, they were soon replaced by better, more powerful techniques, e.g., structured programming, inheritance, polymorphism. Each successive step has incorporated lessons learned from the previous technology, kept the parts that work, and added new concepts. Today's modern Object Technology promises reduced development cycles through extensive reuse by encapsulating state and behavior into objects. Objects are defined by classes which can be grouped into hierarchies. Frameworks and Design Patterns (Gamma et al. 1995) define the complex interplay of classes and objects at various levels of granularity. While an object-oriented framework defines the actual static and dynamic parts of a program, a design pattern gives an abstract model for reusing programming concepts. The Object Management Group(R) (OMG(R)) is addressing the problems of even wider reuse by building a set of standards for framework interoperability. Their Common Object Request Brokerage Architecture (CORBA(R)) technology defines how objects and their interfaces can be dynamically created and destroyed within a heterogeneous distributed network of object-oriented software systems. An Object Request Broker(R) (ORB(R)) controls and manages interfaces and facilitates interoperation among the connected client and server objects. Distributed object technology promises to bring plug-and-play software componentry, interoperability of objects, portability of objects independent of operating systems and hardware platforms, and coexistence with legacy application through wrappers. While CORBA is not the only choice for implementing distributed objects, it is certainly farthest along in the development of tools and implementations. Microsoft's OLE/COM(R) (Object Linking and Embedding / Component Object Model) technology remains tied to the Windows operating system and does not support distributed components, i.e., it lacks remote method invocations and distributed objects.    We propose to use CORBA technology to build a general, reusable framework for sequence analysis tools and related services. The CORBA standard was first published by the Object Management Group (OMG) in 1991 and addresses the need for a standardized framework for application integration and interaction across diverse architectures and environments. OMG, with over 600 members, is the worlds largest software consortium dedicated to fostering interoperability and portability of application software. The technology has been implemented by about two dozen software companies, many of which are working on their third release of a CORBA(TM) compliant product, an indication of the maturity of the technology.     A key feature of the CORBA(TM) model is the isolation of the client and server by a well-defined interface that allows the client application to invoke functionality on the server without knowing implementation details. This affords the software developer total freedom in the way the service is implemented, e.g., the programming language, underlying hardware. Communication between the client and server is enabled by an Object Request Broker(R) (ORB(R)) that acts as a software bus. The encapsulating interface is defined using IDL (Interface Definition Language) which can be compiled to generate client stubs and server skeletons in a number of programming languages, e.g., C, C++, Smalltalk, Ada, and more recently, Java(TM). The standard defines both a Static Invocation Interface (SII) for predefined communication interfaces and a Dynamic Invocation Interface (DII) that allows a client to learn about available functions on a particular server. The DII would allow the agent to dynamically adjust to changing data structures on the server. At least two companies are working to improve performance over high speed ATM networks, an important feature in the context of this proposal. The OMG(R) also defined standards for common object services, CORBAservices(TM), that provide standard functionality for 16 application areas, ranging from providing persistent storage, externalizing data, querying databases, to copying, moving, naming services, to more sophisticated trading and transaction services.     Implementations of the CORBA architecture are available from a number of vendors and for a broad range of platforms and operating systems. A number of vendors have announced Java(TM) bindings to CORBA(TM) and Manfred Zorn, one of the P.I.s, has tested the interoperability of the BlackWidow/Java implementation with other CORBA implementations, e.g., Orbeline/C++ and HP Distributed Smalltalk.     A general overview of the framework was shown in  Figure 3  on page 19 . As described in  Section III. APPROACH , a Service Manager/Task Broker that relates requests for services to the service providers. Service requests will come primarily from Data Input Agents that routinely contact public Internet sites of collaborating Genome Centers to retrieve new sequence information. These agents will launch a standard analysis and annotation request from the system. We anticipate that the bulk of the throughput will be handled in this automated fashion. Individual users will be able to access User Services of different kinds to either launch analysis jobs or view results of completed annotation runs. Biologists will be able to select the services they want applied to their sequence, specify parameters, and submit the sequence to the service broker which will forward the request to the appropriate service provider, i.e., a compute server that runs the requested analysis on the sequence. The Analysis Services bind the analysis servers, i.e., the computers running analysis software, to the framework. Through the use of a common interface it will be possible to add new services and build CORBA wrappers to integrate existing services. The analysis servers can be anywhere on the Internet, any computational biologist will be able to offer a new service to the community by implementing the standard interface and registering it with the broker. Dedicated high-performance compute servers, e.g., massively parallel computers and large workstation farms, will be able to carry most of the load, but additional compute servers can be added anytime if there is a need. In order to support the analysis service it is necessary to collect sequence information, annotation, etc. We will develop Data Mining Agents that will search databases, retrieve information, and stock the Data Warehouse. Since there are many more data sources available than we can possibly keep up-to-date and on-line in our warehouse, the agents will have an evaluation strategy or objective function, that will govern which databases to update, which information to replace. We plan to incorporate existing tools to work as data mining agents, e.g., OPM for GDB, Kleisli, Magpie, and develop new agents if necessary.                      Figure 5  shows a more specific view of this architecture: Using the Internet as the backbone, distributed client and server objects will communicate via an Object Request Broker (ORB). The ORB is shown in the figure as a continuous piece, but in reality, each client and each server will incorporate vital parts that together embody the ORB. Some vendors have additional stand-alone daemons representing ORB functions, e.g., the osagent used by ORBeline, while others use run-time libraries to represent important ORB functions, e.g., the Interface Repository. Via an ORB, distributed client and server objects are able to communicate with each other, e.g., a client may invoke a function in a server object. These functions are expressed in an Interface Description Language (IDL) and stored in the repository. The IDL interface definitions can be compiled into client stubs and server skeletons that are incorporated into the client and server implementations. We will define the relevant interfaces for the proposed services. Using IDL, services can be implemented in a number of programming languages and hardware configurations. It is possible to add services while the system is operational. It should be noted here that this model represents a departure from the existing monolithic software model that is widely employed in bioinformatics. Instead we propose to build a set of interconnected services that cover graphical user interfaces, access to databases, and data processing. Future developments are facilitated by concentrating on specific services and plugging them into the framework, i.e., developers can focus on writing a good algorithm, would be able to get the input data and sequence from our framework, and return the results back to it. Time consuming development of existing functions can be offset by reusing existing services.        Task 1.2 Service Manager / Task Broker     The service manager or task broker is a central routing point in the framework. There can be as many brokers as necessary to cope with the workload. Services that come on-line, register with the broker, unavailable services are marked as down.    The CORBA standard specifies currently 16 CORBAservices, some of which will be useful in building the framework. Since many of the analysis services require significant resources, e.g., compute time, data storage, client requests may not be handled in short order, but instead put in a processing queue, an EventChannel. The CORBA Event Service allows objects to dynamically register or unregister their interest in specific events, e.g., requests for a particular service. An EventChannel supports both push and pull type operation, i.e., a request by a user agent may trigger a reaction from the appropriate analysis service (push) or an analysis service may periodically check the EventChannel for new requests (pull). The broker maintains an EventChannel for each of the services and keeps track of which services have been requested and answered. An unanswered service will be forwarded to one other analysis server if the service is redundantly provided. If the request cannot be answered by the second server it will be forwarded to a human operator to determine the cause of the problem.     The broker will be responsible for authenticating users that access the system and authorizing the use of system resources. Current CORBA implementations have only very limited support for the CORBA Security service that should handle these issues, but are compatible with existing technology that might be used instead, e.g., OSF Kerberos or Sun NIS+.         Task 1.3 Defining Object Interfaces     A key feature to the proposed tools framework is being able to plug in new analysis tools. In order to accomplish that it is necessary to provide a standard interface that is general enough to allow interoperability and yet specific enough for a particular analysis tools to still be useful. The interface has to define input and output parameters to achieve interoperation. A number of existing software packages demonstrate the feasibility of such a common interface:        GCG     The GCG package (Genetics Computer Group URL) contains a number of programs for many applications in molecular biology spanning from sequence analysis, assembly, project management, to graphical display tools. The programs in the package are derived from a set of useful tools and new tools developed by the community continue to be added. The programs exhibit a common command line interface that allows users to specify input and output parameters in a consistent format and aids the user to cope with the initially overwhelming complexity of these tools. This common format can be used to string tools together and pipe results from one program into another. This interoperation is achieved by rewriting the tools extensively to fit the common interface model, i.e., replacing the original I/O with code that use calls to a common library of input and output routines that conforms to the package guidelines. While this approach is acceptable for a software company, it cannot be seen a general model where a diverse community develops software on heterogeneous hardware platforms, languages, etc.        GDE     The Genetic Data Environment (GDE) (Smith, S. 1993) is built around a core sequence editor that displays any number of sequences. Tools can be invoked on a set of sequences to perform various kinds of analysis. Analysis programs can be integrated into the GDE environment by describing the input and output parameters in a descriptive language. The description of a program is used to interrogate the user about required input and output parameter, generate a graphical window in which the user can alter default settings of program parameters, and formulate a command line string that can be executed by the operating system to perform the selected analysis operation. In order to show the results of some of the tools, a generic text window is used to display the textual output, i.e., for some sequence similarity search tools the program output is not parsed and displayed in a graphical user interface, but instead the familiar text format is presented in a terminal emulator.        ace     The ace format is supported in many labs that use the ACeDB data management system for public and in-house data. The C. elegans consortium has embraced the.ace format and put considerable effort into producing translators to and from ace format. It is read and interpreted by the ACeDB data managers (and error checked at the same time), but it can just as easily be read by other non-ace codes. The ace format is a tag value format, where all the information that pertains to one object is collated in one paragraph. A blank line separates data from different objects. The first tag in the paragraph is the name of the object that is referenced. Since the name is a plain English word, the format is entirely human readable and self-explanatory. Every object is addressed using its common name, but it is quite easy to associate an internal key to those names to make the ace format compatible with databases that do not use object names as keys.    Learning from these and other software integration projects we will attempt to build a framework using modern distributed objects technology. Most sequence analysis tools require three types of input parameters:               a single sequence or a set of sequences that need to be annotated. Many standard formats exist already. Popular formats include plain sequence, FASTA format, GenBank format. Some of these need to be defined better before they can be used as standards, but in essence, there seems to be agreement in the field that these are valid standards.       a set of parameters for the algorithm to modify program behavior. Each algorithm has a different set of parameters, but these sets are well known and it is possible to define a default set. Most researchers use a default set already and, since the algorithms are well characterized, a standard set of parameter defaults could be created for different purposes, e.g., sensitive, specific, etc., to make it easier for non-experienced users.       one or more databases that will be used to search against. The latter only applies for algorithms that include homology searches. However, many genefinding methods now include built-in sequence comparison searches as well.         We will develop a Parameter object that will be used to define program parameters, and that will be handed over to all the server objects involved in performing an analysis function. Program output can be treated in a similar manner by defining a sequence based metric and placing features on the sequence. Thus program output would have to be modified or existing output parsed to generate an AnnotatedSequence object that contains a set of AnnotationFeatures. For simple features, e.g., a sequence signal like a TATAA box, the feature object would specify the start and end possibly end of the feature, quality parameters, and the name and short description of the feature. An alignment would additionally have the name and spanning coordinates of the aligned sequence. An important aspect is to capture the feature and disregard any assumptions on implementation or display the features. A client receiving such an AnnotatedSequence would then use this information to either create a graphical display, write a detailed report, or feed the data into a database or further analysis program. Such an approach makes it possible to integrate analysis tools into the framework and provides the opportunity to use features constructively in the analysis.    An object specification of a Genome Exchange Model (GEM) in OMG IDL(TM) is shown in  Appendix II .         Goals for  Task 1. Framework for the Analysis and Annotation Engine :         Year 1                      Refine framework concept through discussion with collaboratory members        Construct initial Service Manager / Task Broker framework        Define initial object interfaces                  Year 2                      Continue implementation of Service Manager / Task Broker        Define comprehensive set of object interfaces        Extend control interfaces to automate operation of the Analysis and Annotation Engine        Incorporate additional CORBAservices                  Year 3                      Finish implementation of tools framework        Define object interfaces for additional specialty objects        Advanced control functions in the Service Manager                  Task 2. Data Input and Visualization Services         Task 2.1 Large-Scale Data Input Services     We expect to implement several methods for sequence data capture and input:        Genome Centers     We will negotiate with Genome Centers to set up mechanisms for accessing their finished or partially assembled daily sequence data. Data input agents will routinely access anonymous ftp sites to search for new sequence data and feed them into the Analysis and Annotation Engine. Initially these agents will be implemented using simple scripts, but will later be replaced with CORBA based agents that will be fully integrated in the tools framework.        Sequence Databases     The Analysis and Annotation Engine will be used to annotate finished sequence clones which have been submitted to central sequence databases such as GSDB (curated by collaboratory participants Fields, Keen and Schad - NCGR). Both automated and interactive procedures for interoperation with the GSDB Annotator interface tool (Keen et al. 1996) will be facilitated to allow individual users or the GSDB staff to access the Analysis and Annotation Engine from within a GSDB session or during the data submission process.    Clone metadata will include identifiers assigned by the GDB central mapping database (Genome DataBase, a collaboratory participant) (Fasman et al. 1996), and possibly additional data about the state of the sequence assembly, e.g., known sequence gaps, known fragment order or partial order, information about data quality and redundancy, and information related to the underlying physical map. Standards for defining the structure of such information will be established with the genome centers and with the advice of the database design teams for GDB (Fasman, Cottingham, Kingsbury) and GSDB (Fields, Keen, Schad), who are participants in this project, and where detailed analysis results will eventually be archived. The sequence data and its annotations (analysis results) will be posted at this project's web site, where it will be publicly available via HTTP connection, either as static ``pages'' or by invoking common gateway interface (CGI) processes. Procedures for returning information to each respective genome center will also be facilitated using the web and HTTP exchanges as well. We will participate in arrangements between sequence generators and the GSDB and GDB databases, to input analysis generated in this project into these databases together with their sequence submissions.         Task 2.2 User Input Services     Direct input services are important for both the occasional biologist user and members of the collaboratory to test services or other maintenance procedures. For individual users who want to analyze and annotate sequence we will develop simple clients that are capable of submitting sequence data for analysis and are integrated into the CORBA framework. These clients will initially be web-based clients similar to the BCM Search Launcher web pages. We will define HTML forms pages on this project's web server which allow users to select analysis tasks. We will define standard sets of parameters for the analysis services to facilitate access and usability. Within the second year we expect to implement a CORBA-based client that is fully integrated into the tools framework. Since it is possible to hide a CORBA client underneath an HTML interface, users with only a web browser, e.g., Netscape, may continue to access the Analysis and Annotation Engine. The main focus of the development and production of the Analysis and Annotation Engine is, however, on large scale sequence annotation in collaboration with the producers of such data.        Task 2.3 Visualization, Data Submission Tools, and Report Generators     An important component of the user services is providing visualization tools to display analysis results. The volume and complexity of the analyzed information and results generated will require an extremely sophisticated approach to data access and visualization. Users need to interface to the raw data, the analysis process, the resulting synthesis of gene models, features, patterns, map data, and to the work of collaborators.        Visual Collaboratory User Interface     Data visualization will allow the scientist to explore the data and metadata generated from the Analysis and Annotation Engine together with data from genome community databases. The wealth of visual displays from the user community will need to be interoperate with the system. Toward this end, collaborative work will be pursued to integrate views such as the Java-based Interactive Genome Browser (Helt and Rubin, University of California, Berkeley) with the tools framework through agent delivered data objects.    The Java-based Interactive Genome Browser is based on earlier work using CD-ROM and web dynamic image creation technologies to present FlyBase data. A prototype browser has been developed using BioTkperl, a high level set of widgets specifically designed to support development of bioinformatics GUI components (Helt, unpublished, Searls, 1995). This prototype (see  Figure 6 ) displays features along the physical map of Drosophila chromosome 2 from band 34-36, as well as sequence annotations for DS02740, an 83kb P1 clone located cytologically at 35E6-35F5, and sequenced at the Berkeley Drosophila Genome Project. The upper part of  Figure 6  represents a portion of this Drosophila genome. The black numbered boxes near the top represent cytogenetic bands, the blue bars at the next level denote regions covered by P1 contigs and the thinner green lines show the position of the individual P1 clones which make up the contigs. The black lines represent portions of this chromosome that have been sequenced and can be found in the various sequence databases. Finally the small red boxes represent the position of P-element insertions. One can increase the level of magnification for this browser. The lower portion of  Figure 6  displays some of the features found in the DNA sequence of one of the P1 clones which spans the junction of chromosomal band 35D and 35E. In this display the know genes are in black, the maroon boxes represent BLASTX matches to sequences in public databases, green represents genes predicted by the program Genefinder and the purple boxes are protein coding regions predicted by GRAIL. A number of other types of information can be accessed through this browser. It is important for visualization tools to allow the user multiple views of the data at various levels of resolution. When completely converted to the Java environment and by using data communication middleware, this front end browser is likely become an integral part of the visualization solutions available to the genome community.                      Other community visual rendering paradigms include MapViewer, a helper application for viewing genomic maps from the Genome DataBase (GDB) (Fasman et al., 1996), and ACeDB (Durbin and Thierry-Mieg), a data management and visualization environment widely used in the genome community.  Figure 7  shows an ACeDB display of physical and genetic mapping data from mouse chromosome 7 found in a local database maintained at ORNL. One of the reasons that ACeDB has enjoyed wide popularity in the genome community is that the code is open and freely accessible. It also makes it easy to incorporate a wide range of multimedia data, in this case an image of the phenotype of mice with a mutation at the P (pink-eyed dilute) locus (the light colored mice), compared to their normal littermates. Other useful interfaces to genomic data include the GSDB Annotator, which is an interactive browser and editor client for GSDB (Keen et al., 1996), and Entrez from the National Center for Biotechnology Information (NCBI). An approach to designing and building interface tools is to use OPM together with the Genera software developed by one of the project participant's (Stan Letovsky). Genera automatically generates form-based Web interfaces from OPM metadata. Markowitz et al. are currently also extending OPM with data visualization facilities in another project on collaboratories.                     bioWidget (URL) is a domain-specific widget set designed to facilitate rapid prototyping of graphical user interfaces. It extends the bioTk project initiated by D. Searls (Searls 1995b) by implementing a platform independent, WWW deliverable set of tools in the Java programming language. The overarching philosophy behind bioWidget is the creation of adaptable, reusable modules that are easily incorporated in a variety of applications and promote interaction between those applications. The widgets encapsulate recurring themes in graphical objects and their behaviors, relieving the programmer of many tedious details. In addition to general support and help widgets, the bioWidget package includes: map.class, a module supporting the creation of various forms of abstract sequence schematics, genome maps, and map objects; multimap.class, an extension of map.class that simultaneously displays and coordinates multiple maps; sequence.class, a scrolling window of sequence data and support for domain operations, e.g., annotation. bioWidget has already proved very successful in support of GAIA, a genome annotation project under development at U.Penn., and is now being adopted by a wider community of bioinformatics researchers and developers as part of a consortium to extend its capabilities.    We will participate in community-wide widget development efforts, e.g., BioWidget, in order to leverage complementary efforts and encourage compatibility with our proposed framework. Graphical user interfaces implemented with a common widget set should be able to display results from the Analysis and Annotation Engine. We will work with interface developers to extend existing tools, and if necessary, develop new user interfaces to satisfy the need for rich graphical displays of sequence analysis results and annotation.         Data Submission Tools     In collaboration with sequence databases we will work on integrating the annotation output with submission tools to facilitate direct submission to public genome databases. Candidates include SubmitData (Zorn et al. and  Appendix I ) developed by project participant Manfred Zorn. It is a framework for submission to public genome databases, that supports a number of protocols already and can be integrated into a CORBA-based tool framework. SubmitData uses database specific parsers to convert database definitions from their native format into a general object definition which control a form-based user interface generator and direct the submission process. By performing many consistency checks at the site of the data generator, SubmitData helps to produce timely and accurate submissions.  Figure 8  shows some of the windows involved in preparing a submission to GSDB.                     The output generated by the Analysis and Annotation Engine can possibly be converted into ASN.1 format which would allow the use of SeqIn, a tool developed by Kans et al. at the National Center for Biotechnology Information, to submit data to the GenBank database. The GSDB Annotator will be available to submit sequences to the GSDB database. We will work with GDB to ensure that important mapping information will be submitted to GDB. Procedures for returning information to each respective genome center will also be facilitated using the web and HTTP exchanges as well. We will participate in arrangements between sequence generators and the GSDB and GDB databases, to input analysis generated in this project into these databases with their sequence submissions.        Web Collaboration and Conferencing Tools     Web-based technologies are developing at an incredible pace. Technologies such as chat rooms (Chatting) and whiteboards, groupware (HyperNews) and electronic notebooks (see Electronic Notebook Workshop reference) will change the way researchers interact. As these communication technologies mature, they will be incorporated into the primary interface of the framework to place a wide range of options at the fingertips of researchers. Concentration on web-based solutions provides for portability to all platforms, and leverages the work of labs, universities and industry. The Collaborative Management Environment (CME) is a DOE funded, joint research project between Ames Laboratory and Oak Ridge National Laboratory to establish a framework for a robust, scalable, and secure virtual management system that could ultimately become the de facto standard management system for DOE. This system will provide sophisticated search and cross-cut capabilities within a single site or across multiple sites for finance and project information. CME research is divided into two functional components that will support a web-based information system: intelligent agents at each site and data analysis and programming tools. The major ORNL participants in this project are also developers in the CME project. We view this type of technology as not only important to community users, but also for communication within this collaboratory.        Report Generators     Unfortunately most existing tools that perform sequence analysis return long lists of information. Sorting through the hits is often tedious. Probability scores are often poor predictors of the biological relevance of hits found by sequence similarity searches. We plan to evaluate existing technology to develop report generators that would focus on specific topics of interest to a user. A key concept is to keep the annotation report well structured and largely free from user interface aspects. It should be up the reporting tool, e.g., the graphical user interface or a report writer, to format the analysis and annotation results according to its own specifications. Similar tools are currently being developed for Internet searching. The rationale is very similar: a search by Lycos or Yahoo returns too many hits and the high scoring ones are not necessarily the interesting ones. Cell biologists have other interests than evolutionists, and they again differ from protein chemists, i.e., what is relevant to one group may be irrelevant to another. We plan to develop filtering tools that will allow a user to customize the analysis and annotation results.        The following summarizes our goals for  Task 2. Data Input and Visualization Services :         Year 1                      Construct key agents for input, and submission        Construct prototype individual user interface        Establish interfaces for major genome center access        Establish data input processes from participating genome centers        Establish access methods to posted sequences from agreeing non-participating centers        Establish baseline viewer for examining analysis and annotation results        Data submission tools and procedures for multiple databases        Establish data flow from major genome centers        Establish interoperation with GSDB                  Year 2                      Deploy individual graphical user interface        Implement viewer for browsing the warehouse        Integrate data submission tools fully into the framework                  Year 3                      Deploy full individual graphical user interface for data input and visualization        Improve viewer for browsing the data warehouse        Advanced protein viewing tools with threading and homology modeling by incorporating public domain tools into the framework                      Task 3. Analysis Services     In this section we describe the analysis servers which will be attached to the Analysis and Annotation Engine. These include tools for (1) pattern recognition, (2) gene modeling, (3) sequence comparison, (4) providing constraints for sequence assembly, (5) methods for comparative genomic analysis, and (6) protein characterization. In addition to our initial set of tools, we expect other tool builders to attach tools to the framework over time.        Task 3.1 Pattern Recognition Algorithms     Pattern based methods for sequence feature identification take advantage of statistical variations in the sequence of a given feature when compared to the base distribution in ``bulk'' DNA. Often, several statistical measures are calculated and used to train an artificial intelligence-based system such as a neural network to recognize the feature of interest. The features which can be identified by these methods can be small, like a splice donor junction which is on the order of 10 base pairs, or very large, for example the isochore defined by the regional G+C content of the DNA, and which may be hundreds of thousands of base pairs in length.    A number of biologically useful features can be localized computationally using pattern recognition methods. These include: protein coding exons, tRNAs, splice junctions, CpG islands, isochore ([C+G]), and simple and complex repetitive DNAs. Methods for identifying other features of biological interest, such as regions which regulate gene expression are also being developed. In many cases several methods are available to locate a given feature and we will give the user a choice of the best available methods.     The goal of pattern recognition is to decorate the sequence with various informative features so that the functional organization of a genomic region can be understood. For example,  Figure 9  illustrates a number of biologically relevant features which GRAIL recognizes in a DNA sequence and which are presented to a user in the XGRAIL interface. The central grey bar reflects the local concentration of G and C nucleotides which, in human DNA, correlates with the density of genes (the particular region represented in this figure has a high percentage of G+C and is relatively gene rich). Two other features are superimposed on the central grey bar: The magenta boxes mark the locations of CpG islands (Gardiner-Garden and Frommer 1987), regions with a locally high concentration of the dinucleotide CG, that are thought to be associated with genes and the regulation of their expression. The yellow boxes indicate the presence of various DNA elements which are highly repeated in the human genome and are often referred to as ``junk'' DNA, though in some cases they may have unknown functions. The peaks above and below the central grey bar are regions of the sequence which the programs predicts as protein encoding regions (exons) which are presumably parts of genes. Genes can be found on either strand of a DNA helix which is why there are peaks both above and below the central bar. The colored bars immediately above the various peaks give an indication of the confidence level of the predictions for each exon. Green bars represent very likely exon candidates (>90%) while exons marked with blue bars are weaker (50%) and those marked with red bars are the least likely (about 20%). In the central region of the figure there are a series of cyan boxes linked together by yellow lines. These represent a group of exons which the analysis predicts belong to the same gene. The concatenation of the sequence represented by these cyan boxes forms a gene model, that is, the portion of the DNA sequence which encodes the protein product of the gene. None of these features are obvious by casual inspection of the DNA sequence, but rather are found by examining the sequence with the various algorithms that make up the GRAIL system.                      Several of the best feature recognition methods will be included in this framework. We describe some of these in more detail:        Protein Coding Regions.     A number of systems will be included to locate protein coding exons. Many of these, such as the ORNL GRAIL exon scoring system have a hybrid structure which involves the calculation of a set of individual statistical measures for each sequence region, followed by the fusion of the results using a neural network or other method for final prediction or feature scoring (Uberbacher and Mural 1991, Xu et al. 1994a, 1996b, 1996e). Similar methods are used in the LBNL/Haussler Hidden Markov Model method and Pevzner's system for coding exon detection which will be described later.        Splice Sites.     Locating splice-junctions is important for determining intron/exon junctions which must be accurately located in order to make proper gene models and arrive at protein translations. Several systems have been developed for splice-junction recognition and the three gene modeling systems (ORNL, Haussler, and Pevzner) have systems for this which will be incorporated into the Analysis and Annotation Engine.        CpG Islands     The location of CpG islands, regions with a locally high concentration of the dinucleotide CG, which are thought to be associated with genes and control of gene expression, can be determined statistically (Gardiner-Garden and Frommer 1987). It has been estimated that there as many as 60,000 CpG islands in the human genome (Antequera and Bird 1993) and they are considered to be indicators of genes in the region. CpG islands found at the beginning, middle, and end of genes may have different properties but this is still a research issue.        tRNAs.     Several methods have been developed to recognize regions which encode tRNA molecules, including the use of grammars, GenLang (Dong and Searls 1994) and statistical methods (Fichant and Burks 1991; Eddy and Durbin 1994). One or more tRNA finding systems will be incorporated in the framework.        Repetitive DNAs.     Human DNA contains many interesting complex and simple perfect and imperfect repeating motifs. Locating these repeats is not only of intrinsic biological interest, but identifying and masking such repeats is critical before database searching because the presence of repeats in the query sequence and the presence of repeats in the target sequences dominates sequence comparison, obscuring useful results. Methods for identifying such repeats involve statistical comparison against a complex repeat reference library (Jurka et al. 1992) as well as fast methods for identifying arbitrary simple repeats (Milosavljevic and Jurka 1993, Guan and Uberbacher, 1996b). A rapid method for identifying simple repeats has been designed at ORNL and will be used in the Analysis and Annotation Engine (Guan and Uberbacher 1996b). It is described in detail in a reprint in  Appendix III . We will also incorporate Jurka's Censor server (Jurka et al., 1996) (through a CORBA wrapper) for complex repeats as well as a BLAST/Smith-Waterman hybrid system constructed at ORNL.        Regulatory Regions.     A number of systems are under development for detection of regulatory regions including systems at ORNL and LBNL. Matis et al. 1996 (ORNL) have constructed a multiple sensor neural network system for TATA containing promoters and are extending this to include a host of other transcription factor binding sites and promoter types. A system to detect PolyA sites has also been constructed. A promoter prediction system using time-delay neural networks has been constructed by Reese and others at LBNL (Kulp et al. 1996). Both of these systems have produced mixed results, but in the longer term, we expect several useful promoter prediction systems to be included in this framework. This remains an area of intense study.        Detection of Sequencing Errors.     Dynamic programming based algorithms for detecting errors in DNA sequence data based on statistical measures have been developed at ORNL (Xu et al. 1996a, 1996d) and will be made available for users. In particular, coding region frameshift information is critical when attempting to recognize and model genes in the sequence. A paper describing this method in detail is contained in  Appendix III . This type of information is particularly important for genome centers who will wish to go back and examine the raw data underlying potential errors. In some cases such apparent errors in frame are actually present in the sequence and represent an important loss of function of a gene through evolution (a pseudogene).        Calculation of Isochore Parameters.     It has long been recognized that base composition of human DNA is not uniform over the entire genome. Rather, the genomes of humans and other mammals, are a mosaic of large regions, several hundred thousands of base pairs, with locally uniform base composition (Bernardi et al. 1985, Bernardi 1993). These large regions of relatively uniform base composition are referred to as isochores. Isochores differ in their gene density and presumably, in components of gene regulatory processes (such as what types of regulatory elements are likely to be present). Determination of isochore from sequence data is rather straight forward but we believe the having knowledge of local isochore properties will become increasingly important for understanding genome organization, packaging, gene regulation, and gene expression patterns.        Long Range Statistical Correlations and Fractal Sequence Properties     Participating researchers at LBNL are undertaking a systematic study of long-range statistical correlations in genomic DNA sequence as well as an examination of fractal properties. Work at ORNL has involved the measurement of Markov chain properties of various DNA domains (Xu et al. 1994a, 1994d) and the elucidation of statistical and periodic patterns by Fourier transform methods related to chromosomal packaging and nucleosome formation (Uberbacher et al. 1988a, 1988b, 1989). Methods for extracting such sequence properties will be included in the framework as they are developed and shown to be useful.        Task 3.2 Gene Modeling Systems     The recognition of genes and modeling of multiple genes within genomic sequence represents one of the most essential core services we will provide. The technology of gene finding has improved steadily over the last five years to a level where most genes can be recognized with good but usually imperfect fidelity. Recent growth of the public domain EST collections provides complementary information which can be used in gene finding systems. Methods which combine pattern recognition and EST comparison methods can provide much more accurate gene models than either method alone. We expect to implement at least three such gene modeling systems in the framework, which make use of a combined pattern recognition and EST/protein homolog approach for detecting and computing the structure of genes. These include the ORNL Gene Modeling method (an outgrowth of GRAIL), Generalized hidden Markov model system created by Haussler in collaboration with LBNL, and Pevzner's homology-based gene modeling system. Additionally, GeneParser and GeneID systems will be considered. Participants from TIGR will aid in the development of EST-based gene finding methods and provide access from this framework to EST collections at TIGR.        The ORNL Gene Modeling method.     Since its initial development (Uberbacher and Mural, 1991), the GRAIL system at ORNL has become a standard for predicting protein coding regions (exons) and modeling genes in DNA sequences. The gene modeling method which will be implemented in this project is a new development (Xu et al. 1996c / reprint in  Appendix III ) and is considerably more complex and sophisticated than the on-line GRAIL system. This gene modeling method is capable of using protein homologs and ESTs to refine gene structures found by pattern recognition methods.    The problem is approached as an optimization based on features detected and weighted constraints, and is solved using a dynamic programming algorithm. The basic algorithm scans through possible gene coding regions from left to right and constructs an optimal gene structure over the sublist which is consistent with a given reference set of constraints from homology calculations. The algorithm runs in time and space, where k is the maximum number of reference models for an exon candidate and n is the number of possible exon candidates.     This system is capable of recovering exons missed in pattern recognition, removing false exons, recognizing non-coding exons, and automatically and accurately modeling complete or partial genes in a sequence (when EST or protein homology information is available). Significant computing power is required and this will be provided using the facilities at the ORNL Center for Computational Sciences (CCS).     Extension of the gene modeling algorithms described above are being made to process multiple genes in an automated fashion (Xu et al. 1996b). Currently in the standard GRAIL system, although single genes can be modeled semiautomatically, analysis of longer sequences require significant manual intervention and trial and error model building. Changes in the objective function used by the gene modeling algorithms and additional bookkeeping are necessary to accomplish multiple gene modeling in an automated mode. The availability of EST or protein homolog information helps the accuracy of this process significantly.                      An example of fully automated multiple gene modeling is shown in  Figure 10 . The X-axis represents the sequence axis. The bars with connecting lines on the top represent the predicted gene structures (five genes are predicted); the hollow rectangles in the middle represent predicted exon candidates where the height of an rectangle represents the probability of a predicted exon being an actual exon. Horizontal lines at the bottom represent genes homologous to the corresponding predicted exons. The system initially uses GRAIL to predict exon candidates on a given DNA sequence, as shown in the middle section of the figure. Then homology search is done for each predicted exon candidate in both EST and protein databases. Reference gene models are formed based on the identified homologous proteins, as shown in the bottom of the figure. Gene structures are predicted, using predicted exon candidates, in such a way that is most ``consistent'' with the homologous genes and the probabilities of the predicted exons, as shown in the top of the figure. By comparing to reference gene models, falsely predicted exons can be removed, exons missed by GRAIL prediction can be identified and located, and exons can be parsed into separate gene models automatically. This type of technology, applied here and in the two subsequent methods, should make gene modeling highly accurate.        Generalized Hidden Markov Models for Gene Model Construction (LBNL/Haussler).     This method involves a combination of neural network predictions with ``generalized'' hidden Markov model parameters in a complex gene parser. Hidden Markov Models (HMMs) for DNA can be viewed as generative stochastic models of sequences that go though a sequence of hidden states, and in each hidden state they generate a single letter in the alphabet {A,C,G,T} according to certain probabilities associated with that state (Krogh et al. 1994a, Krogh et al. 1994b). The sequence of hidden states forms a Markov chain, in the sense that which state generates the nth letter depends only on which state generated the n-1st letter. This contrasts with (non-hidden) Markov models of sequences, in which the sequence of letters itself forms a Markov chain, i.e. the nth letter depends only on the n-1st letter, or on the letters at positions n-k,... n-1 in the case of a kth order Markov model.    In a generalized HMM, each state can generate a string of one or more letters according to a probability distribution specified by some arbitrary mechanism, particular to that state. The only thing demanded of this mechanism is that the probability, i.e., likelihood, can be efficiently calculated of any string under the distribution defined by the mechanism. Models of this type were described in Stormo and Haussler (1994), for the case of only two possible states, exons and introns, and the Markov chain for the states is trivial, in the sense that it alternates back and forth between these two states with probability 1. Each time such a model is in the exon state, it generates a string according to the probability distribution associated with exon strings, and each time it is in the intron state it generates a string using the intron distribution. The output is the concatenation of these generated strings. To use such a generative model for recognition of introns and exons in a DNA sequence, a dynamic programming method can be used to ``invert the generative process'' and find the most likely sequence of individual strings and their states that were concatenated to make the sequence. This is referred to as ``parsing'' the sequence (constructing the best gene model). Recently, this model has been extended to include more than 2 states, with general Markov transition probabilities between states. This is the basis of ``generalized'' HMMs.     This method for gene modeling divides the problem into two parts. First, it recognizes potential coding regions, intronic regions and acceptor/donor splice junctions (signals are combined using simple neural networks), respectively. Then it parses the recognized exon/intron/splice-junction signals into a single gene structure using a pre-trained transition diagram, called a hidden Markov model. The transition diagram consists of states and transition probabilities among states. Each state may represent a recognized signal or a utility-state, which can be used, for example, to enforce the reading frame consistency between adjacent exons. A dynamic programming-based optimization algorithm finds a most probable path going through the states for a given DNA sequence, which corresponds to an optimal exon/intron structure parsing of the sequence (Kulp et al. 1996).     The flexibility of generalized HMMs allows easy addition of other capabilities to the gene modeling system, such as the ability to incorporate homology information discovered by searches of a protein database, and to find promoters, RNA genes, known repetitive DNA sequences etc., as soon as states for these have been defined with appropriate probability distributions. Once these states are defined one can ``wire them in'' to the existing HMM architecture by modifying the Markov chain transition probabilities to include the new states.     Continued development of the generalized hidden Markov model approach is funded in a separate grant from DOE and will be leveraged for this project.         Pevzner's Homology-Based Gene Modeling Method.     (collaboratory participant Pevzner at USC) (Gelfand et al. 1996a, 1996b) This homology-based gene modeling algorithm combines multiple similarities to protein homologs and ESTs (in progress) to construct a gene model. Sequence level signals (like potential splice sites) are recognized statistically. This method uses a new combinatorial approach for gene modeling, which uses related proteins to derive the correct exon-intron structure. Instead of employing statistical properties of exons, the method attempts to solve the combinatorial problem of finding a set of segments in a genomic sequence whose concatenation (splicing) resembles a known protein.    The approach is based on the following idea: given a genomic sequence, it first finds a set segments containing all true exons. This can be done by selecting all segments between possible acceptor and donor sites (statistically recognized edge signals) with further filtering of this set (in a way that does not lose the true exons). The resulting set of segments, of course, may contain many false exons. Then, all possible segment assemblies are explored to find an assembly with the highest similarity score to each given similar known target protein. The number of different segment assemblies is, of course, enormous, but the spliced alignment algorithm, which is the key ingredient in this method, scans all of these possibilities in polynomial time. In this algorithm, the exon assembly problem is reduced to the search for the optimal path in a graph. Vertices in this graph correspond to the segments, arcs correspond to potential transitions between segments, and the path weight is defined as the weight of the optimal alignment between the concatenated segments of this path and the target sequence.     The three gene modeling methods just described have different structures, but in many basic respects share common characteristics and needs for underlying statistical, pattern recognition, and sequence comparison algorithms. Therefore, these gene modeling servers should be able to share underlying servers for component operations.         Gene Modeling in Partially Assembled Sequence.     One of the added complexities, which has not been fully explored, is modification of these algorithms to deal with the incomplete nature of the target genomic sequence. Since in many cases, multiple contigs (sequence fragments) will be present which have gaps between them and indeterminate ordering, genes may only be partially present with parts missing in these gaps. Furthermore parts of a gene may exist on several fragments, although this may be unknown to the original sequencing laboratory.                     Basically in a large genomic clone (perhaps 30000 to 150000 DNA bases long), small overlapping fragments of the sequence generated randomly are assembled into contigs, whose overall order and position is not initially known and which have gaps between them. Many segments of the sequence data, unknown at the outset, will have emerging importance to one another as the analysis proceeds, and these relationships need to be discovered and exploited within the overall analysis process. The presence and structure of genes and other signals in the sequence, and the structure of the sequence assembly itself, are being determined simultaneously.    The system will input any existing information about the order of these contigs, any characterization of gaps between them, and other physical map-related metadata. Available information about order in the assembly will be used by the system to consider genes which span gaps. Homology information and data mining information will be used in an integral way to detect and model genes, identify genes which cross gaps, infer additional order between contigs based on database information, and help determine what parts of genes are missing in gaps or off the end of a contig or clone. This is illustrated schematically in  Figure 11 . Gene model information will be used to help collapse related EST assemblies which in many cases cover separate parts of the same gene. The identification of genes and their extent can be used to decide which gaps are important to close with high quality sequence at the experimental genome centers. Sequence quality or redundancy information from the assembly (if available) can be used to localize regions where sequence quality is low and indel detection system may be useful to apply. The majority of this information would not be discovered using the standard approach.     The gene modeling algorithms can be modified to compensate for the partial or gapped nature of the gene models since these phenomena violate constraints used in current gene modeling algorithms. However, the gene modeler must know when a gene is partially missing and where, in order to apply the proper algorithm in the proper way. Such information can be obtained from homolog or EST data and can also contribute information which may relate contigs in a genomic clone (and provide sequence assembly constraints). This is discussed below in  Task 3.4 . An expert system to make these types of determinations is under construction at ORNL and could also potentially be used by all three gene modeling methods.         Task 3.3 Sequence Comparison Systems     Calculation of similarity between newly obtained sequence and archives of various types of information is perhaps the most valuable tool for obtaining biological knowledge. A range of algorithms is available or under development to solve somewhat different sequence comparison problems. Each available method has particular strengths and specialized uses. A full range of algorithms needs to be used for various tasks, and our intent is to provide or access a wide range of general methods such as Blast, FASTA, and Smith-Waterman, and additionally specialized methods for long DNA comparisons and frame-tolerant DNA-protein alignment. A number of sequence comparison systems are available as Internet servers (such as the NCBI BLAST server) and, where possible, we will incorporate these into our framework by building CORBA wrappers. We have considerable high-performance computer hardware available at ORNL, LBNL, and ANL for support of community-wide services of this type, and we may also utilize specialized hardware boards based on expertise at LANL.    A very brief overview of some of the types of methods we will bring into the analysis and annotation framework is provided below:         Dynamic Programming / Smith-Waterman.     The Smith-Waterman (SW) algorithm (Smith and Waterman 1981, Gotoh 1982) is a dynamic programming algorithm, which can be conveniently described in a grid-like graph. One sequence is placed vertically to the left of the graph, and the second sequence is placed on top of the graph. Each cell (i,j) of this matrix contains a score based on the similarity of the ith element in the horizontal sequence to the jth element in the vertical sequence and the scores of the diagonally preceding cells. Diagonal edges represent matches or substitutions, and the vertical and horizontal edges represent insertions and deletions. The algorithm starts at the upper left corner, and tries to find a lowest scoring path between the upper left corner and the lower right corner (which corresponds to an optimal global alignment of the two sequences). With proper initialization, local alignments can be found in a similar way. The complexity of the SW algorithm is , where m and n are the lengths of the two sequences compared.    For reasons of sensitivity and gap tolerance, global comparisons of cDNAs or EST assemblies against long genomic regions, or long DNA-DNA comparisons often use this algorithm. Also comparing long sequence regions against each other requires significant memory space, and special algorithms (described later) have been designed which dramatically reduce space requirements (see also Guan and Uberbacher,  Appendix III ). We will implement Smith-Waterman servers at ORNL, LBNL and ANL as part of this project.         FASTA.     FASTA (Pearson and Lipman 1988) is one of the many heuristic algorithms proposed to speed up sequence comparison. The basic idea is to add a fast prescreen step to locate the highly matching segments between two sequences, and then extend these matching segments to local alignments using more rigorous algorithms such as Smith-Waterman. FASTA starts its prescreen process by building a look-up table from one sequence in linear time, and then scans the second sequence to identify the matching segments by recognizing segments of bases having the same offset. The prescreen step reduces the search space to a small portion of the database and thus decreases the search time significantly. Depending on how the matching segments are extended to local alignments, the complexity of the algorithm is between and , assuming . A modified version of FASTA allows several matching segments to be connected to form a local alignment, thus allowing gaps in the final alignment. FASTA has reduced sensitivity compared to Smith-Waterman and can therefore miss important but weak similarities.    The ORNL genQuest system provides a FASTA server which will be incorporated into this project.         BLAST and BLAST2.     This heuristic search algorithm is based on mathematical results that allow the statistical significance of matching sequence segments to be estimated under an appropriate random sequence model. In BLAST (Altschul et al. 1990), a maximal segment pair (MSP) is the highest scoring pair of identical length segments chosen from two sequences. Recent results allow the estimate of the highest MSP score at which chance similarities are likely to appear. BLAST minimizes the search time by concentrating on only those sequence regions whose similarity with the query sequence exceeds the chance similarity score. The BLAST algorithm consists of three steps: compiling a list of highly-scoring words from the query, scanning the database for hits (Maximal Segment pairs - MSPs) and extending hits to local alignments. The complexity of the BLAST algorithm is , where w is the number of words generated, n is the database size, and a, b, c are constants. BLAST is faster than FASTA, but it doesn't allow gaps in its alignments and is less sensitive. As part of this project, a new version of BLAST called BLAST2 which contains increased sensitivity, will be implemented as a server at ORNL in collaboration with its author, Warren Gish of the Washington University Genome Center, St. Louis.    The NCBI and ORNL genQuest system provide servers for BLAST which will be implemented in the project framework.         BEAUTY.     (BLAST Enhanced Alignment Utility) (Worley et al. 1995) is a tool developed at Baylor College of Medicine which uses BLAST to search several custom databases and incorporates sequence family information, location of conserved domains and information about any annotated sites or domains directly into the BLAST query results. The conserved site and domain information reported by BEAUTY comes form the Entrez database (NCBI), the PROSITE database (Bairoch et al. 1996), the Blocks database (Pietrokovski et al. 1996) and the PRINTS protein motif fingerprint database (Attwood and Beck, 1994). These results, along with the BLAST analysis are presented to the user in a simple graphical form. With the help of the Baylor participants we will incorporate BEAUTY into the Analysis and Annotation Engine and explore the techniques used in BEAUTY for presenting other forms of analysis to the user.        Frameshift-Tolerant Dynamic Programming Sequence Alignment Algorithm.     As experimental data, DNA sequences are subject to error, and frameshift errors usually weaken homology recognition between sequences. ORNL (Guan and Uberbacher 1995) has developed an algorithm to find the optimal alignment in the presence of sequence errors (reprint in  Appendix III ). This algorithm compares a DNA sequence translated in three frames with a protein sequence. In the standard Smith-Waterman algorithm, a score matrix cell (i,j)'s value can depend on three other matrix cells: , , and . The new alignment algorithm considers not only the three cells in the same matrix, but also the same three cells in the other two frames' matrices. That is, when computing the alignment for a given frame of translation, the algorithm also considers whether there is a better partial alignment in either of the other frames prior to this point that can be continued by shifting the frame to the one under consideration. The algorithm's complexity is , but several times slower than Smith-Waterman, and must make use of available high-performance computing hardware. Searching all sequence with this algorithm has significant utility for detecting errors in the sequence (important to genome centers) and locating potential pseudogenes (genes which were disrupted by evolutionary accidents) based on homologs. There are currently no publicly available servers which support this type of method and we will implement such a server as part of this project.        Linear Space Smith-Waterman for Comparison of Long Genomic DNAs     Dynamic programming algorithms are often used to find the similarity of sequences as well as to deliver the actual alignment of two sequences. But space is often the limiting factor when aligning long sequences using dynamic programming methods. Comparison of long DNAs using Smith-Waterman requires the calculation of a very large matrix which is sometimes too large for computer memory. For example, a comparison of requires 1012 matrix terms. Special algorithms have been designed to dramatically reduce space requirements (see Guan and Uberbacher,  Appendix III ). A linear space algorithm for computing maximal common subsequences, proposed by D. S. Hirschbert, was modified by E. W. Myers and Webb Miller to deliver optimal alignment in linear space. We have improved the Myers and Miller algorithm by introducing a new divide and conquer technique that reduces the running time to about half while maintaining the linear space property. An example of this is shown in the bottom of  Figure 12  which displays a small portion of the total alignment. We expect these types of comparisons to become increasingly useful for examining large duplications and evolutionary relationships between long sequence domains. Currently there are no publicly available methods for this type of sequence alignment and a server for this will be implemented as part of this project.        Matrix Comparison Tools for Long Genomic Regions     Dot matrix calculation and a linear space alignment algorithm provide tools for studying the overall relationship of long sequences.We have developed an X-Windows based package for analyzing long sequences.  Figure 12  shows a comparison of the T-cell receptor alpha and delta loci from human (HUMTCRADCV, 97,634bp) and mouse (MUSTCRA, 94,647bp). The upper left panel displays a dot matrix comparison of these sequences (described in next section). The right panel is a detail of the boxed region of the left panel. The first horizontal panel (with vertical colored bars) is a representation of the region compared in the upper right panel, while the lower panel shows a portion of the actual sequence alignment. All windows are scrollable. Colors represent regions of identity levels, red for greater than 69% identity, orange denotes 60-69% identity, yellow 50-59%, green 40-49%, and blue 30-39% identity.    The dot matrix calculation is done using an offset technique used in a number of sequence comparison packages including FASTA. Basically, each segment of a sequence is compared with every segment of the second sequence, and the similarity the two segments is determined. The similarities of the two sequences are plotted in a window according to the thresholds set for the length of the step and the similarity cutoff score. The similarities are also displayed in the link-analysis window that shows the sequence relationship in a different way. This dot matrix calculation and link analysis can be applied to any selected region, allowing detailed analysis of a sub-region. The results of the dot matrix calculation for a sub-region is displayed in the subsequence-dot-plot window. Tools for visually examining long-range relationships between genomic regions will become increasingly valuable as more sequences are generated.         Tools for Multiple Sequence Alignment.     The ability to perform multiple sequence alignments is the basic prerequisite for defining gene families and for studying the evolutionary relationships among genomes. A number of methods for multiple sequence alignment have been developed and we will make these accessible through our system. Some examples of the kinds of multiple alignment programs that we include are: CLUSTAL W (Thompson et al., 1994) a general purpose program for multiple alignments of DNA and protein sequences; PIMA (Smith and Smith, 1992) which performs multiple alignments using a covering pattern construction algorithm; and MAP (Huang, 1994) which computes a multiple global alignment using an iterative pairwise method. These programs can be accessed in a number of ways including through the BCM Search Launcher (Baylor College of Medicine) which, with the help of the Baylor participants, will be connected to the Analysis and Annotation Engine.        Task 3.4 Providing Constraints for Sequence Assembly     The assembly of sequence contigs into a completed contiguous sequence for a clone is one of the most difficult processes in genomics and ``closing'' the gaps in the sequence is perhaps the most time consuming part of experimental sequencing. Improvements in the basic technology associated with sequence assembly algorithms could have a dramatic effect on the cost of genome sequencing. Errors and uncertainties in the sequence, as well as many repeated sequence patterns make it very difficult to reliably determine the overlap of individual sequence contigs. Current algorithms which attempt assembly without human intervention have only mixed success and in most cases require significant intervention by a human expert to arrive at the correct sequence assembly result. This type of process does not scale well for the high throughput stage of genome sequencing.                     Identification of genes in the sequence and determining that the same gene is common to more than one contig provides independent information which can be used to link portions of a sequence assembly together (see  Task 2 ). The most widely used assembly algorithm, Phil Green's PHRAP (personal communication) could potentially be modified to add additional constraints imposed by knowledge of the extent of individual genes. Such information should be routinely available based on analysis of partially assembled sequence in this project. The Ace.mbly package (J. Thierry-Mieg - personal communication) has just recently been modified to allow the use of these types of constraints in the assembly of sequence. Our intent is to collaborate with the developers of assembly algorithms so that the assembly state information obtained through our analysis can be used expeditiously at experimental sequencing centers.        Task 3.5 Tools for Comparative Genomics     With the completion of the genomic sequences of Haemophilus influenzae, Mycoplasma genitalium and Saccharomyces cerevisiae the area of comparative genomics is reaching a new, and even more important phase. In addition, the completion of nearly half of the genomic sequence of Caenorhabditis elegans and rapid progress in the sequencing of other model organisms will enhance our understanding of the genome structure and evolution of higher eukaryotes. A number of databases which will be accessible through our data warehouse, YPD (the yeast protein database), FlyBase, and MGD (the mouse genome database), to name only a few, provide important comparative data for attempting to elucidate the function of newly discovered human genes. As well as providing tools for multiple sequence alignments (see above), we will also implement services for phylogenetic analysis (Phylip, for example) and provide visualization interface for aiding in the interpretation of the output from such analyses. As more data become available, we, in particular, Terry Gaasterland, will also develop methods to increase the utility of metabolic databases, by integrating information on how pathways are modified cross-species.        Task 3.6 Protein Characterization Tools     A number of methods are in development for learning about the structure and function of new proteins based on their sequences. In particular links from this framework to structural biology are very important. We anticipate several types of methods in the Analysis and Annotation Engine including:        AI-Based Structural Classification.     Methods for protein structural classification based on prediction using AI are in development which can provide an indication of the structural type of a protein without reliance on homology information. This is valuable for new proteins which do not have known homologs and can sometimes provide an general idea of function (Craven et al. 1995).        Methods for Protein Threading.     A number of methods for protein threading, finding the ``best'' fit of the sequence of a newly identified protein to currently known protein structures, are currently under development using dynamic programming as well as more computationally intensive methods. While not currently particularly accurate, these methods are undergoing rapid development and it is likely that they will soon be producing useful results. Dynamic programming methods could be implemented in this framework at the present time, but more accurate methods which treat energies more rigorously are on the way. Rick Lathrop (UCSF) has agreed to help us implement his tools at ORNL, although suitable improvements in the technology which would make these useful for routine use by the community is probably some time in the future. ORNL also has a research effort and has developed new threading algorithms (Xu et al.  Appendix III ) in this area and hopes to provide on-line services within the time frame of this proposal.        Protein Structure Viewers.     Rasmol and other public domain viewers provide the capability to link a protein sequence with a structure in PDB. Much can be learned about a new protein sequence by viewing the structure of a close homolog. Additional structure viewing tools are likely to be incorporated for threading and homology modeling systems in years 2 and 3.        Task 3.7 Other Analysis Tools and Resources     The open nature of the interface to this system will not only allow developers of new tools to make them easily available to the system, but will also allow us to build links to the large number of currently existing tools which are available over the world wide web. One popular list of molecular biology related analysis tools and data resources:         (http://www.public.iastate.edu/~pedro/research_tools.html)     lists over 175 programs and data sources which provide information ranging from the prediction of protein secondary structure to servers which perform multiple sequence alignments. We will build connections to the most useful of these systems, with the assistance of the service provider whenever possible, and provide links to others so as to give users maximum flexibility in generating the type of analysis that they desire.            The following summarizes our goals for  Task 3. Analysis Services :         Year 1                      Implement baseline pattern recognition systems        Basic Gene Modeling Methods        Sequence Comparison Systems        Implement basic protein structure viewing tools        Implement tRNA gene finders                  Year 2                      Genome comparison tools        Suite of protein characterization tools        Sequence Comparison Servers        Implement automated partial and multiple gene modeling algorithms        Create algorithms and constraints to exploit unfinished sequence data, and links to sequence assembly tools        Advanced protein viewing tools for threading and homology modeling                  Year 3                      Genome comparison tools        Suite of protein characterization tools        Sequence Comparison Servers        Implement automated partial and multiple gene modeling algorithms        Tools for structure effects genomic sequences (bending, nucleosome placement, chromosome packaging signals)        Analysis tools for long range statistical patterns in genomic sequence                  Task 4. Data Mining Services     The kinds of information which need to be gathered and brought to bear on the analysis are diverse, widely distributed, semantically complex, and often interrelated in non-obvious ways. This part of the proposal will involve developing data-mining resources with intelligent agents to identify and query the appropriate data resources, assemble the information for feedback to pattern recognition and gene modeling programs, and summarize the biological function of the sequence of interest into a report for biologists.    A brief, hypothetical example, can give an indication of the complexity and richness of the analysis paths which may be followed when retrieving the data relevant to describing a DNA sequence. The protein predicted to be encoded by a newly discovered human gene may have, as its closest known relative, a protein from the nematode C. elegans, and though no function has been discovered for this gene in the worm is part of a gene family with a well characterized member in yeast and another member from E. coli whose 3D structure has been solved by X-ray crystallography. No less than five separate databases would have to be queried to assemble this information and several of these queries would have been dependent on the success of a previous query. Often, as in the above example, the best way to present the data may be an image, for instance a visualization of the 3D structure of a protein. Developing multimedia presentations of the data will be critical which underlines the importance of visualization in  Task 2.  Input from a number of experts will be critical to designing and implementing the data mining and inference portion of the Analysis and Annotation Engine.     Another example of data mining involves using metadata from dbEST to suggest an expression profile for a newly identified gene. If a gene has multiple hits in the EST database then one can take advantage of the fact that the sequences in this database come from many cDNA libraries made from mRNA from many different tissues. If a gene is represented by multiple cDNA clones from only one library, one might infer a tissue specific expression pattern for that gene. Conversely, finding homologous cDNAs in libraries from multiple tissues would suggest a more ubiquitous pattern of expression. The presence of homologous cDNAs in non-normalized libraries can also give a rough estimate of expression level by comparing the number of hits for the gene of interest to the total number of cDNA sequenced from the library. It should be noted that obtaining this kind of analysis requires information which is contained in multiple databases. This is usually not information that can be retrieved by a simple query, since it requires manipulation of data received after searching the database.     World-wide there are a wide range of databases covering many aspects of molecular biology and genomics. These range from large, well established and widely used public data bases such as GDB (Fasman et al., 1996) and SWISS-PROT (Bairoch and Apweiler, 1996) to small specialized databases like the androgen receptor gene mutation database (Gottlieb et al., 1996). In addition there are a number of privately maintained proprietary databases. A recent issue of Nucleic Acids Research (vol 24, no.1, 1996) listed over 50 databases relevant to genomics and molecular biology. We will maintain satellite copies of the large, widely-used public databases ( Table II ) in our data warehouse to facilitate the frequent database searches which will take place as part of the analysis and annotation process. Smaller, more specialized databases ( Table III ) will be accessed by retrieval agents when appropriate and/or links to these databases may be provided for the user to follow and determine the relevance of the information for their purposes. Because we will build an open interface to our analysis and annotation system, we will be able to include generic data retrieval agents which can be customized by users to extract pertinent data from local databases and include it in their analysis.                     Table II : Databases potentially supported as satellites in the data warehouse.                                             Database        Reference                     GSDB        (Keen et al. 1996)                    GenBank        (Benson et al. 1996)                    PIR        (George et al. 1996)                    SWISS-PROT        (Bairoch and Apweiler, 1996)                    GDB        (Fasman et al. 1996)                    EcoCyc        (Karp et al. 1996)                    EMP        (Selkov et al.1996)                    YPD        (Garrels, 1996)                    FlyBase        (The FlyBase Consortium, 1996)                    MGD        (http://www.informatics.jax.org/)                    PROSITE        (Bairoch et al. 1996)                    Blocks        (Pietrokovski et al. 1996)                                    Table III : Examples of other potential data sources for the Analysis and Annotation Engine                                             Database        Reference                     Small RNA database        (Gu and Reddy, 1996)                    RDP        (Maidak et al. 1996)                    MITOMAP        (Kogelnik et al. 1996)                    Androgen Receptor Mutation DB        (Gottlieb et al.1996)                    Glucocorticoid Receptor Resource        (Danielsen and Martines, 1996)                    Part of the necessary information is already captured in a number of genome databases and we rely on our collaborators at GSDB (NCGR), GDB (JHU), and the biology community to continue the compilation of high quality genome information. The recent database issue in Nucleic Acid Research (January 1996) provides a good overview of the current status and number of public molecular biology data resources.        Task 4.1 Data Mining Agents     Building and maintaining such a complex dataset can become quite time and resource consuming. We propose to develop a set of intelligent agents that would assist in this task. These agents will contact database servers, ftp sites, web pages, etc., to extract the necessary information, and populate the data warehouse. The agents will need to select and retrieve only relevant data, allowing for fault tolerance for temporary network or database dropouts. The agents will need to be intelligent enough to handle variation in the underlying data structures, use inferencing to combine facts into higher-level knowledge and affect overall process flow decision-making.    We envision building a set of modular agents to collect information from the various data sources. An overview of the architecture is given in  Figure 13 . Various data resources, e.g., molecular biology databases, ftp sites, web servers, will be accessed by the Data Mining Agents using either database specific tools, e.g., OPM, generic interrogation systems, e.g., Kleisli, or custom software programs to retrieve relevant information and store it in the data warehouse. The data warehouse keeps track of a minimal amount of information to identify a sequence and link it to relevant information in public databases necessary to construct annotation. By storing these links in a local data warehouse we can alleviate potential problems associated with timely collection of information from distributed sources over the net. It is equally important that the high-performance analysis not be hampered by slow or difficult access to a number of databases in order to complete the annotation process.     We propose three kinds of agents:         Update agents     These agents will deal with public databases, e.g., GenBank, GSDB, that produce data regularly. A GenBank agent would contact the ftp site, look for new daily updates and retrieve them. If there is a new complete release (every two months) it would start the complete download and unpacking of GenBank. It is expected that such an automated system will not work smoothly all the time, therefore if need be (an error) an operator has to step in and finish the downloading manually. Update agents could also be used to extract summary information, e.g., all references, links from SWISS-PROT to other databases.        Search agents     Search agents deal with more specific information, e.g., find all connections with SOD1. These agents would go to GDB, retrieve all about SOD1 which includes GenBank accession numbers, retrieve GenBank information, follow links there, look into other databases. This type of agents will be invoked by the Analysis and Annotation Engine to add specific annotation to a sequence and will work on a case by case basis. The information collected this way would nevertheless be stored in the warehouse with an expiration date, and used immediately for the annotation. This way over time we compile a repertoire of genome information without first going out and downloading the universe onto our disks. For search agents, a user will be able to specify which connections to follow: check PDB because s/he is interested in the structures, omit GenBank and use GSDB instead.        Generic search engines     We will evaluate more generic search engines, such as web based search engines, e.g., Lycos, Inktomi, or AltaVista, to tabulate genome information and create indices in a rigorous manner. The analysis returns a hit with some other sequences, and we will be able to extract a list of related data by looking into our index, with short descriptions and links of this sequence. The user interface or report generator is left with the task of following each link and retrieving relevant information from the databases.        Task 4.2 Data Accessors and Translators     The overriding design requirement is to perform any translations from a site-specific data format only once, either at that site or at a middle-tier server site. The translation process itself depends upon the mechanisms chosen for data exchange and the format of the provided data and will range from relatively trivial to very tedious. For example, data already available in a DBMS server supporting SQL, e.g., built using OPM, or an object-oriented query language may be retrieved rather easily using OPM. Filters and/or parsers will be necessary for translating data into a common format. Through using OPM for the design of the database, many of the translators needed for central databases such as GDB and GSDB can be built automatically. However, this does not hold true for a number of other databases which have been built using other methods. For example, translators for OMIM (human disease genes) and metabolic database will have to be built from scratch. Two additional systems for querying multiple remote sites and producing data translations (Kleisli and MAGPIE, see  Appendix I ) use different methods and have different strengths. Most notable in the Kleisli system is the inherent ability to deal with non-relational targets.                     The public genome databases GDB and PDB have been implemented using the Object-Protocol Model (OPM) data management tools. These tools provide facilities for efficiently constructing, maintaining, and exploring Molecular Biology Databases (MBD), using application-specific constructs on top of commercial database management systems (DBMSs). The OPM tools also provide facilities for reorganizing MBDs and for exploring seamless multiple heterogenous MBDs. The OPM data management tools have been highly successful in developing new genomic databases, such as GDB 6.0 (released in January 1996) and the relational version of PDB, and in constructing OPM views and interfaces for existing genomic databases such as GSDB. The OPM data management tools are currently used by over ten groups in USA and Europe. OPM and the OPM tools are currently being adapted to work in the CORBA framework, i.e., providing a translation from an OPM schema to an IDL definition and developing tools to implement Persistence services on top of OPM style databases.    The OPM tools can be used to design a data model which describes biological objects which are consistent with representations in central databases such as GDB and PDB, which have used the OPM model. Most importantly, OPM has tools (including translators) for both generating and querying databases, as well as for defining OPM views on existing databases. This method has been used previously for constructing views of central databases such as GSDB, GenBank (ASN.1), and one could use these tools for bringing all the relevant data from remote databases into a common format. We may need to extend OPM and the tools according to emerging requirements, however the existing tools provide a good starting point and year one activities would involve creating the metadata infrastructure required by the agents for data mining. The LBNL OPM team has already done work on how metadata would be organized for multiple genome databases and are quite advanced on developing translators for accessing/querying multiple heterogeneous genome databases.     The CPL/Kleisli system addresses the problem of integrating multiple, distributed heterogeneous data sources and application programs. One of the strengths of Kleisli is its ability to deal with nontraditional sources, such as data exchange formats, rather than mainstream databases, with the data exchange formats commonly employ complex, nested data structures composed of collection types such as sets, multi-sets, variants, records, lists, and arrays. Furthermore, relational query languages are notably deficient in their ability to query lists and sequences, precisely the data structures used to represent BioSequences information.     Kleisli uses general-purpose query system, CPL/Kleisli, that provides access to a variety of flat files (GenBank), custom systems (ACeDB, ASN.1), application programs (BLAST), and relational databases (GDB, GSDB). It features a uniform query interface across heterogeneous data sources, a modular and extensible architecture, and most significantly for dealing with the Internet environment, a programmable optimizer.     Kleisli is capable of complex data manipulation such as structural mediation - a complex data ``join'' between structures that come from different sources - and structural wrapping type transformations involving nesting/unnesting plus generalized selections and projections. Kleisli has been shown to be efficient in composing and executing queries that were considered difficult, if not unanswerable, without first either building a monolithic database or writing highly application-specific integration code. Detail on the system architecture can be found in  Appendix I . The system is organized into three layers: (1) a CPL query interpreter; (2) an optimizer and application programming interface; (3) Data drivers, modular interfaces that mediate between Kleisli and external data sources.     The basic query interface to Kleisli is the CPL query language (Collection Programming Language) developed at the University of Pennsylvania by Chris Overton, one of our collaborators. CPL uses the native operations associated with records, variants, sets, lists and multi-sets as the basis of a complete query language for complex types. CPL currently uses a comprehension syntax, and can be thought of as SQL extended to a richer type system. Within the context of the Kleisli system, it should be thought of as relatively low-level glue language on top of which user views of an integrated data system can be developed.     The types of data sources currently compatible with Kleisli include Sybase, ACeDB, ASN.1 as well as BLAST; the drivers are generic rather than source specific, meaning that once a Sybase driver has been written any Sybase database can be supported. Because communication with the drivers is facilitated through UNIX pipes, drivers can be written in any language; we have used C, perl, as well as Prolog. In addition, a flexible printing routine allows data to be converted to a variety of formats for use in displaying (e.g., HTML) or reading into another programming language (e.g., perl). We expect that integrating Kleisli into a CORBA-based agent will be straightforward.     MAGPIE (see  Appendix I ) is an automated system for carrying out genomic sequence analysis. MAGPIE (Multipurpose Automated Genome Project Investigation Environment) is designed and implemented to meet the challenges that arise with the generation of complete microbial genome sequences, during and beyond the lifetime of a genome sequencing project. In many ways MAGPIE is a model for methods of analysis and data mining which could become part of the much larger scale processing proposed in this project.     Another tool for building accessors and indexes for a broad variety of molecular biology databases is included in the Sequence Retrieval System (SRS) at EMBL Heidelberg (Etzold et al.). It includes a generic parser to parse the text format of a database and an object-oriented query language. SRS provides access to 36 sequence and sequence-related databases.     In this project we propose to develop and implement a framework, where the most appropriate tool can be used to access data sources. We will start with a few, and gradually evolve the system by adding translators and databases. One of our data mining goals is not to summarily input data from external sources, but to extract high-level summary information, and to create and maintain active links to the underlying data at the remote data sources. We plan to use a hypertexting mechanism to establish these links within the analysis results document and access the Web interface to the remote data sources to utilize the links.         Goals for  Task 4. Data Mining Services  include:         Year 1                      Establish OPM, Kleisli data mining agents for most essential databases        Collect parameter and defaults files in BioParameter database        Establish BioSequence as comprehensive sequence collection                  Year 2                      Establish update agents for specialty databases        Implement BioIndex database                  Year 3                      Establish data mining agents for niche and new databases        Institute BioIndex as a query service to the genome community        Include syntenic links to multiple organism databases                  Task 5. Data Warehouse     We propose to build a data warehouse to support our data management needs. The data warehouse will need to satisfy four criteria, efficient storage of data, high speed communication to the Analysis and Annotation Engine, full access by agents for data exchange with external databases, and extensibility for the future data needs (including multimedia objects) for this project. The proposed Analysis and Annotation Engine is designed to process large amounts of sequence information. In order to achieve the high-throughput operation, we cannot rely on external database servers and network connections to supply the necessary data. We have to build a local sequence storage that can be accessed and scanned rapidly. The data retrieved by the Data Mining agents from the distributed database repositories or calculated by the Analysis and Annotation Engine must be efficiently stored in a local repository for optimal access. This local repository will be replicated among participating collaboratory sites for optimal throughput of the Engine and synchronized at regular intervals. Information collected by the Data Mining agents and analysis results will be compiled into an index to provide rapid access to existing sequence feature annotation.    While other warehouse efforts in Bioinformatics, e.g., the Integrated Genome Database (IGD) (Ritter et al. 1994) or the GenomeTopographer project at CSHL (Marr et al. URL), attempt to physically integrate data sources, we restrict the content of the warehouse to the immediate needs of the Analysis and Annotation Engine. The Integrated Genomic Database (IGD) is an international project to develop an information management system for human genome researchers which interconnects existing molecular biology databases and analysis tools. It is a joint project between DKFZ, Heidelberg (Germany), CNRS, Montpellier (France), ICRF, London (UK), LBNL, Berkeley (USA), MRC, London/Cambridge (UK), and WIS, Rehovot (Israel). It integrates a number of molecular biology databases by downloading the data and translating the information into a unified database schema. Building and maintaining such a database, particularly the definition of the unified schema, integration of numerous differing data formats, access methods, etc., is a monumental task. The GenomeTopographer presents a workspace for biologists that includes tools, local data, and access to a number of public databases. We do not intend to duplicate their efforts and do not propose to develop a unified schema for genome information. By limiting the scope to collecting sequence information and to building a genome-specific index, we drastically reduce the complexity in building the data warehouse.     This genome-specific index will be modeled after recently developed Internet search engines, e.g., Lycos, Inktomi. In the past, database indexes have been largely limited to indexing the contents of one particular database. Sequence databases have been distributed since their inception with flat file indexes that relate database structures with the corresponding entries, e.g., the GenBank  author.idx  file lets you find an entry by the name of it's author. More sophisticated tools like IRx(R) (Information Retrieval eXperiment, Lister Hill National Center for Biomedical Communications at the National Library of Medicine) permit forming complex queries with boolean operators to search the database. NCBI recently added a text searching capability using IRX for their GenBank database. Multidatabase indexes are less common. Examples are the Entrez system at NCBI, the Mouse Genome Database (MGD, see URL) at the Jackson laboratory, and the WAIS Wide Area Information System that can be used to index reams of text documents, gopher sites, data files, and much more.     Entrez (Entrez URL) is an integrated database retrieval system which accesses DNA and protein sequence data, related MEDLINE references, a collection of genome data and 3-D structures from MMDB. The DNA and protein sequence data are integrated from a variety of sources, including GenBank, EMBL, DDBJ, dbEST, dbSTS, GSDB, PIR, SWISS-PROT, Protein Research Foundation (PRF), PDB, and patents. The DNA sequence, protein sequence, MEDLINE, genome and 3-D structure data are linked to provide easy traversal among the datasets. Some of the links are simple cross-references, for example, between a sequence and the abstract of the paper in which the sequence was reported, or between a protein sequence and its corresponding DNA sequence. Other links, however, are based on computed similarities among the sequences or among the textual documents. The precomputed `neighbors' allow very rapid access for browsing groups of related records.     We plan to evaluate some of these index building technologies and approaches. This genome-specific index is intended to provide entry points for further exploration in conjunction with annotated features on a sequence.         Task 5.1 The Data Model                      The ways in which users from the biological community access and interact with the data generated by this project will be a major determinant of the success of the project. Behind the analysis and interfaces which will be built as a part of this project, it is important to have a rich and robust data model. The major data being analyzed in this project, nucleotide sequence, can be viewed as the finest level of resolution of a physical map. In genomics, maps both genetic and physical, are relatively simple, one-dimensional objects, yet they can communicate a wealth of biological information and can serve as a framework for links to more complex types of information. Descriptions of chromosomes can be viewed as a series of hierarchical maps proceeding from the banding pattern seen in the light microscope to the actual DNA sequence. Within the genome community a number of data management structures have been created which capture the essential richness of genomic maps and can serve as a model for organizing and presenting the type of information which will be generated by this project. It should also be clear from the previous discussion that the annotation process is rather fluid, that is not all users want the same annotation and, because our knowledge of biology is incomplete, we cannot assume that all of the features which would be useful to annotate have even been discovered. In fact it seems a virtual certainty that entirely new classes of features will be discovered and become part of our analysis within the time-frame of this proposal. It is important that the data model is sufficiently robust to accommodate the plastic nature of the annotation process.    Information generated in this project will also migrate to a number of public databases which will necessitate the development of export tools and translators, and a compatibility with these community resources is essential. Since there is great variation in the way data are stored and organized at the various genome centers, it is desirable to establish as much commonality as possible in representing and accessing similar data types when and where possible and feasible. Thus, considerable effort will be put toward establishing a data model which standardizes common information provided by the various centers while retaining the ability to represent data specific to a site. The starting points for this effort are the models for existing molecular databases, such as the Genome DataBase, the Genome Sequence DataBase, and the Protein Data Bank.     Beyond the types of data models in the community databases, this project will analyze new types of data and therefore poses new challenges. For example since we will examine unfinished sequences (partially sequenced clones, sets of contigs with order and gaps, unordered contig sets, partial and gapped gene models), implementation of several new concepts related to how sequence needs to be represented will be required. These developments may impact the community database schema as well.     A preliminary data model with explicit focus on capturing links to other databases is shown in  Figure 14 . The central part of the data model is the object Sequence which characterizes a particular sequence, usually a name and the nucleotide or amino acid sequence. Relationships among sequences will be captured through subclasses of Relationships, e.g., to establish a relationship between a nucleotide sequence and it's amino acid translation or 3D structure. Annotation that can be extracted from public databases and those generated by the analysis routines will be handled by the Feature object that references a set of sequence objects. Each Feature identifies the span to which the annotation applies and has a Link to an existing data resource, i.e., only pointers or accession numbers will be stored in the warehouse. In case of new sequences collected from web sites, and the like, we will have to keep additional information to ensure proper identification of the sequence, e.g., clone names, producer, time-stamps.     We do not want to duplicate existing efforts but rather integrate existing knowledge by building a common sequence based index. The sequence will be used as the key to access all references. Instead of following hierarchies of relationships, e.g., a gene is similar to a known protein that occurs in a transcription factor database and is referenced by GDB to point to a human disease tabulated in OMIM, we will attempt to construct a flat reference profile: once the gene is identified all connections will be available to be included in a report or displayed on a visualization system. The goal is to provide as much information up front in order to facilitate the interpretation of the results. The details of the links can be found by accessing the data resources that originated the annotation.         Task 5.2 Warehouse Databases     We will evaluate a number of commercial database management systems for their ability to provide fast access to a large amount of information. Two of the principal laboratories (ORNL and LBNL) have Sybase licenses that can be used to set up a preliminary storage system. The Data Management Group at LBNL (V. Markowitz) has the necessary expertise to advise us on selection criteria and performance issues. We can also draw upon the experience of public database providers, GDB(TM) and GSDB, that did extensive evaluations before choosing a database management system. We will also investigate current capabilities of object-oriented databases and their fitness into our object-oriented framework.    Table IV  shows potential data sources and the corresponding components of the warehouse. Some databases may contain data that will end up in more than one component.                     Table IV : Databases organized by information type.       These databases represent the types of information and potential data sources for the data warehouse. Initial targets are indicated with bold type.                                             Information types        Databases                     Sequence        ( BioSequence )        EMBL, EMNEW                    GenBank , GenBankUpdates                    GSDB                    PIR                    SWISS-PROT                    TREMBL                    GenPept                    NRL3D                    Structure        ( BioSequence,        BioIndex )        PDB                    NDB                    HSSP                    DSSP                    ALI                    FSSP                    Sequence related        ( BioIndex )        PROSITE , PROSITEDOC                    EPD , YPD                    ECDC                    GDB                    OMIM                    MIMMAP                    ENZYME                    REBASE                    PRODOM, SWISSDOM                    PIRALN                    FlyBase                    BLOCKS                    TFSITE, TFFACTOR                        BioSequence     We plan to maintain an up-to-date set of nucleic acid and protein sequence databases and related information. The sequences will be transformed into one or more standard formats used in the Analysis and Annotation Engine. Initially we will use the sequence data as they are distributed by the database provider in order to get the service components up and running as quickly as possible. In the following years we plan to integrate sequences from various sources and build a non-redundant, non-overlapping set of sequences to reduce redundancy in the analysis and annotation. A compound identifier will be used to mark the source database, data type, and the original identifier similar to the identifiers used by public genome databases.        BioIndex     The BioIndex will provide direct links from the sequence identifier to relevant related information. The browsing model, i.e., looking up references that provide further insights and more references that the user may follow (e.g., the Entrez neighbors that can be followed or hypertext linked web pages), is very powerful for direct user interaction. However, for the development of an automated annotation system it would require decision making capabilities that complicate the development of autonomous agents. Implementing the proper heuristics proves sometimes to be quite difficult to implement. We propose an indexing model where all relevant links and references are collapsed to one level, i.e., given a sequence the index reveals all connections of this sequence with other sequences, structures, genes, gene products, and more. The graphical interface to the ACeDB database demonstrates this concept very nicely: the display is bursting with information, invisible lines separate BLAST hits from GeneFinder predictions, etc., but the information is visible at once. The user does not need to switch to separate windows to see the concerted annotation. Such an interface is quite different from hypertext-linked web pages where more information is always a mouse click away (and the user gets sometimes lost in cyberspace). The BioIndex will concentrate information and leave it up to the visualization, post-processing, or the user to make the decision about the relative importance of each data item. This approach allows the development of a multitude of user interface client programs that receive the very same output from the Analysis and Annotation Engine, but will be able to highlight different properties to different users.             All users are equal, but some users are more equal.     And they should be allowed to customize their interface. The BioIndex will be a significant component in providing such a capability to the Analysis and Annotation Engine.    The development of this index will start with compiling obvious connections, e.g., compiling references from databases and among databases. Many databases already have links to other information, e.g., SWISS-PROT references PIR, OMIM, EMBL, and others. We will begin extracting these links and creating a composite index. As an alternate approach we plan to evaluate generic indexing tools: the Internet index inktomi is a program resulting from the NOW (Network Of Workstations) project at the University of California at Berkeley and indexes web pages; IRX as a more traditional text retrieval system; WAIS, a network-based text retrieval and indexing system.         BioParameter     This warehouse component provides a common access point for parameter and default files used in the Analysis and Annotation Engine. Examples of such files are the PAM and BLOSUM matrices, codon usage tables, base tuple frequencies, default parameter settings, etc. In the future documentation and on-line help facilities will be added.        The following summarizes our goals for  Task 5. Data Warehouse :         Year 1                      Design and implement base schema        Build baseline warehouse        Include major analysis systems for features and gene modeling        Install and integrate satellites of major central databases in warehouse        Populate warehouse with first year data plus legacy sequence                  Year 2                      Build fully implemented data warehouse        Design and implement extended schema        Include all analysis features        Incorporate additional satellites                  Year 3                      Build fully equipped data warehouse        Regular distribution of data warehouse within collaboratory                          Last Modified: 04:00pm PDT, July 25, 1996
GX012-81-1573129	ICC :: Software                BioSig : June 17, 2003            Presentation and Annotation     Data import and annotation for biological experiments is a relatively  complicated process involving input from multiple staff members. Significant effort has been made towards clarifying this workflow  through simple, conceptual operations. We work with  our users on a regular basis to develop more effective web interfaces while  maintaining the goal of leveraging open, free software.  This free software includes Tomcat 5, Cocoon 2, JAI (Java Advanced Imaging),  and the latest in Java XML tools.     For presentation, we are using the Adobe SVG ( Scalable Vector Graphics ) plug-in. This plug-in works in  Mozilla, Netscape, IE, and other web browsers. We use SVG to good effect in  developing interactive graphical views that facilitate understanding of  experimental parameters and design, and computed feature-based representations.            Importing      XML and Java are used for configuration of an extensible import process.  This process validates dataset completeness and parameters.   A web-accessible import interface will be added soon.        Imaging      JAI has the benefit of leveraging native C-code based acceleration for common operators.  Image processing in BioSig includes color composite generation,  segmented image generation, and region-adjacency graph generation. Raw thumbnails are also created from the images, thereby allowing for rapid re-scaling on an image collection basis.         Current work      We are in the process of migrating to PostGreSQL from our current proprietary database system.   We are building a web service infrastructure that is informed by current trends  in online biological databases. In conjunction with these web services, we are creating semantic markup  based on feature representations.                   June 5, 2002     All components of BioSig have been upgraded to use Java 1.3. All Tomcat servers have been upgraded to version 4.x. Currently, both Cocoon 1, and Cocoon 2 are used.  The Java Advanced Imaging was upgraded to 1.1.1.          Dec 10, 2001     API javadoc for database-related classes is available. It directly models the classes, fields, and heirarchy from the data model.         BioSig utilizes an  SSL -secured  Apache  web server with TCP connectors to multiple  Tomcat  servlet engines.      Security   Connecting to this web server requires one of our signed digital certificates to be   imported into the client's local web browser certificate database. A certificate  can be made available by PGP-encrypted mail to concerned parties. Please contact   gvfontenay@lbl.gov in this regard. User id and password authentication are also required   once the client-side certificate authentication is achieved.       XML/XSLT   BioSig leverages XML/XSLT functionality by using  Cocoon , an  Apache  XML-based servlet component.   For the database component, BioSig uses an object-oriented database,  ObjectStore  for Java.     ObjectStore uses persistent Java classes to represent the database schema, and BioSig generates  this Java code from an XML-base model using XSLT. OO features such as encapsulation and composition facilitate the  design of this object-based data model.       XML representations of the database objects are generated at request time  to enable content generation and presentation at the browser level.   XSP ( eXtensible Server Pages ), part of the Apache Cocoon project, consist   of XML-based pages with embedded Java code.     More information about XSP can be found  at the XML Apache site. HTML and SVG presentation is then achieved from the XML through various XSL stylesheets.        Java applet and servlet components   On the client side, BioSig utilizes Java 1.2 applets which use the https protocol, so the  Java 1.3 plugin  is required.    On the server side, there are various servlets in use, each with their own session connection to the database.  These lightweight servlets provide database navigational and annotation information as well as various image   collections. We use  JAI  ( Java Advanced Imaging ) for image presentation and processing.   gvfontenay@lbl.gov, x2262
GX008-24-6611077	"Supported Graphics Devices                                  Introduction                         Dataplot supports a number of graphics device drivers.  Some       of these (e.g., Postscript) are built-in directly and are thus       available on all implementations of Dataplot.  Other drivers       require local installation (typically, this just means linking       with an appropriate graphics library) and may or may not be       available on a given implementation.  Certain types of graphics       output may be post-processed by external software.                Chapter 7 of Volume I        of the online Reference Manual discusses the commands for       specifying the graphics devices.  The        Frequently Asked Questions  discusses       the issues of printing graphs and importing graphs into word       processors in the PC Windows environment.                                  Built-in Device Drivers                         DATAPLOT supports the following built-in device drivers:                    Tektronix - most models (4010, 4014, 4105, 4113, 4027,              4663, and related devices)                          REGIS - for DEC terminals (VT-240, VT-340)                          HP-GL - Hewlett-Packard plotters (widely emulated by many              other plotter vendors, can use with the LaserJet III)                          HP 2622 - Hewlett-Packard terminal, also includes many              related models (2623, 2647, and others)                          POSTSCRIPT - used by many laser printers (includes              encapsulated Postscript), both black and white and              color Postscript supported                          SVG (Scalable Vector Graphics) - this is the new XML              based graphics protocol.  It's primary use is for              web applications.  However, the SVG format is an              editable and I expect many graphics programs (such as              Adobe Photoshop, Corel Draw, etc.) to support SVG import              in the future.  That is, you could import a Dataplot              SVG graph into a sophisticated graphics editor.                             Although this is still a new and developing format,              with the increasing importance of XML I expect this              to be an important format over the next few years.                          QUIC - protocol used by QMS (and some Talaris) laser              printers (obsolete)                          HP 7221 - Hewlett-Packard 7221 plotter                          GENERAL - DATAPLOT specific metafile                          CGM - Computer Graphics Metafile (ANSI standard              metafile).  DATAPLOT currently only supports the clear              text encoding.  CGM never really seemed to catch on,              so I never got around to implementing the binary              encoding (I may, but this is a fairly low priority).                          DISCRETE - if you do not have a screen device available,              using DISCRETE will generate a line printer type graphic              to the screen.                        Many devices support either Tektronix, Postscript, or HP-GL       emulation.                                  Device Drivers That May Require Some Local Installation                         In addition, the following devices are available, but may       require some local installation (usually linking the proper       device library).  The installation notes give instructions for       installing these devices (when the appropriate vendor library is       available).                            X11 - MIT windowing system, supported on most Unix based              workstations.  Has been tested on Sun, SGI, HP-9000, VAX              workstation, IBM RS-6000, Linux, Cray, Convex, MAC OSX.                             Unix installations (including MAC OSX) will include the              X11 driver when they are built.  Windows installations              will not.  For non-Unix, non-PC platforms, you may need to              investigate whether your system supports X11 before              building Dataplot.                          QWIN - available only for the PC version built with the              Microsoft PowerStation Fortran compiler or the Compaq              (now Intel) Visual Fortran compiler.  These compilers              are currently used to build the command line version              for the Windows 95/98/ME/NT 4/2000/XP platform.                         LAHEY - available only for the PC version built with the              LAHEY compiler.  Note that this was built using the              version of the compiler for DOS/Windows 3.1.  It is              obsolete for the Lahey F90 and Lahey F95 compilers.                             The graphics library for the current version of the              Lahey compilers (LF90 and LF95) is Winteractor.  Although              I have done some testing with this library, there are              some problems.  Specifically, Winteractor combines              the graphics and GUI.  As we use Tcl/Tk for the GUI,              this presents some compatiblity problems.  The Lahey              compiler is used for the GUI version under Windows.              Screen graphics are generated using Tcl/Tk.  There is              currently no screen graphics if running the Lahey              version independently of the GUI.                          VGA - available for the PC version built with the OTG              compiler only.  As we no longer support this compiler              with Dataplot, this is an obsolete driver.                          GD <PNG/JPEG> - creates PNG and JPEG format              files using the GD library of Thomas Bouttel.  This is              the library used by Perl (and a number of other popular              freeware programs).                             PNG and JPEG are primarily used to support web              applications.  Almost all web browsers support JPEG              graphics and most of them now support PNG as well.  These              are alternatives to the GIF format.  Note that there are              patent/royalty issues with the GIF format.  For this              reason, freeware programs such as Dataplot do not              typically support GIF.                             The PNG driver is currently available for the              pre-built Unix executables (including MAC OSX).  I              am currently working on porting this to the PC.              The situation is the same for the JPEG driver with the              exception that JPEG does not work on a few specific              Unix platforms.                             PNG and JPEG can also be useful as an alternative format              for importing into word processors and page publishing              programs.  Although they do not provide the high              resolution quality obtained by importing Postscript,              they are sometimes more convenient to work with.                          Calcomp - uses the standard Calcomp library.  Many vendors,              particularly plotters, support this library.                             Although this is essentially an obsolete driver, note that              there are graphics packages that still operate with a              Calcomp interface.  This means that you could possibly use              the Calcomp driver to link to a graphics library that              might support a device that Dataplot does not support              directly.                          Zeta - uses a slightly modified version of the Calcomp              library for Zeta devices (dashed lines handled              differently).                             This is essentially an obsolete device.                                         Sun CGI - available on the Sun only.  Uses the CGI              library and runs in a gfxtool or suntool window.  Sun no              longer supports the CGI library.  Use the X11 device if              you run Open Look or Solaris Common Desktop Environment.                             SunView is obsolete.  You would only build this version if              you are running a very old Sun that is running SunView.              To use it, do a global replace of ""CSUN"" to ""    "" in the              files dp37.f, dp38.f, and dp39.f and then link in the              needed CGI libraries.                                           Adding New Device Drivers                         I have a number of devices that I plan to add support for in       Dataplot.  Feel free to send me requests for additional       device support.  My criteria for deciding to add a device       are:                           Availability - the most basic criterion is simply              whether or not I have a device (and related, the              documentation) to do the testing.           Usefulness - I have limited time/resources to develop              device drivers for Dataplot.  Therefore, device              drivers with wide applicability will take precedence              over a device driver for a specific, narrowly              available device.  For example, Postscript and X11              have extremely wide applicability (essentially all              Unix environments support X11, many offline devices              use Postscript).  On the other hand, a device driver              for a specific printer is unlikely to get written.           Device drivers for specific devices are good              candidates for user contributed code.  I (Alan Heckert)              am willing to provide guidance.                       The device drivers I am currently considering are:                           OpenGL - the main purpose for supporting OpenGL is              to provide a foundation for improved high performance              3d graphics.  I believe OpenGL provides the best              balance between high performance and portability              (i.e., it is available on the major platforms:              Unix, Windows, MacIntosh).                          GDI - graphic device interface for Microsoft Windows.              The purpose of this would be to provide generic printer              support in Dataplot under Windows.                             This one is complicated by the fact that graphics              under Microsoft is typically mixed with graphical              interfaces.  Our use of Tcl/Tk for the Dataplot              GUI probably prohibits the use of this driver              with the GUI version of Dataplot.  However, it might              be possible to implement this for the command line              version.                             As alternatives, I am also looking into using the              ghostscript library.  This would not be as general              as a native GDI driver, but it would support many              common printers in both the PC and Unix environments.              Another alternative is a GDI Tcl/Tk extension.  This              would only apply to the GUI version for PC's, but it              might be a way around the window compatibility issues              in this environment.                             NOTE: See the NOTE in the Ghostscript/Ghostview section              below.  This provides a Ghostscript interface to GDI for              the PP command.  For this reason, I have lowered the              priority for this device driver.                          Quartz - this is the native mode graphics library for              MAC OSX.  Quartz outputs PDF format files.  My initial              implementation will probably be for file output              (i.e., a PDF format output file).  The next step              would be to generate screen output.  This step will              require my obtaining the Absoft MAC OSX              compiler first (Quartz does not provide the windowing).              The advantage of this would be to allow a version              of Dataplot for MAC OSX that does not require              installing an X11 server.  However, as with the GDI              driver for Windows, there is intermixing of              graphics/windows issues.  This means the quartz screen              driver would probably be limited to the command              line version.  The Tcl/Tk base GUI would still need              to be run in X11 mode.                          Latex using EEPIC package - this will be a fairly              specialized driver.  Its main purpose would be for              generating high quality presentation graphics for              publication.  It will primarily be of interest to              those already familiar with Latex who would like              to incorporate some of Latex's capabilities into              Dataplot graphs.                                                  Ghostscript/        Ghostview                                 Using the popular and          freely downloadable  Ghostscript/Ghostview programs can       greatly extend the list of supported devices on the Unix       and Microsoft Windows platforms.  Ghostscript/Ghostview can       read Postscript files and view them on the screen or convert       them to many other common formats.  In particular, the most       common use of Ghostscript/Ghostview is to print Postscript       files on non-Postscript printers.               NOTE: Recent enhancements (as of 1/2003) to Dataplot now invoke       Ghostview or Ghostscript automatically.  Specifically,                   Under Windows, the SET GHOSTSCRIPT PRINTER ON command uses              the Ghostview program GSPRINT (this is installed when              Ghostview is installed) to implement the PP command (PP              prints the most recent graph).  See the               GHOSTSCRIPT              PRINTER  command for details.  GSPRINT uses the              generic Windows printer driver, so most Windows printers              should now be supported.                          Under Windows and Unix, the SET POSTSCRIPT CONVERT command              can be used to invoke ghostscript to automatically              convert Dataplot Postscript output to JPEG, TIFF,              PDF (Portable Document Format), or any of the four              PBM formats (PBM, PGM, PPM, and PNM).  This provides              additional options for formats that can be imported into              external programs (e.g., word processors).  See the               POSTSCRIPT              CONVERT  command for details.                                          Using PC as Terminal                         If you are using a PC as a terminal for a version of       DATAPLOT on another host, there are 2 basic approaches:                           find a communications package that provides either              Tektronix, REGIS, or HP 26xx emulation.           If Dataplot is running on a Unix host, you can use an              X11 software package for the PC.  As a technical note,              the X11 driver in Dataplot is built using only the ""xlib""              library (not Xt or Motif or one of the other toolkits).              This means just about any X11 server software should              work with Dataplot (e.g., on my own PC, I use a free              X11 package that works just fine for Dataplot).                                          Dataplot Post Processor                         Many years ago I wrote a post-processor for DATAPLOT.  This       will read either DATAPLOT metafiles (i.e., the GENERAL device)       or Tektronix 4014 format files.  There are currently 2 versions       available.  One uses the Disspla subroutine library while the       other uses the Template subroutine library.  If you have one of       these commercial libraries available, this is a way to provide       support for additional graphics devices.  This works fairly well       for off-line devices such as film recorders or plotters, but is       less useful for terminals.                With the availability of Ghostview/Ghostscript and the       emergence of Postscript, I don't really find any particular       need for this anymore.  However, the source is available       upon request (the most likely use is to adapt it to a local       graphics library).                If you are interested in the post processor, contact        Alan Heckert .                The CGM metafile can be used if you have a local post-processor       that reads CGM format files.  DATAPLOT currently only generates       clear text ecoded CGM files.  Many post-processors only read       binary encoded CGM files.                                                 Date created: 6/5/2001        Last updated: 2/13/2002        Please email comments on this WWW page to        sedwww@cam.nist.gov .                                                          [  Dataplot  |            Dataplot Downloading  |            Documentation  ]"
GX033-56-2288925	Appendix I. Methods, Tools and Databases         The GRAIL Gene Recognition system         The MAGPIE System         The Kleisli System         The Collaborative Management Environment (CME)         The NCGR, the GSDB Database, and Annotator         The Object-Protocol Model and Tools         Generalized Hidden Markov Models for Gene Model Construction         The High Performance Storage System (HPSS)         SubmitData - Data Submission to Public Genome Databases         BioPOET - A parallel processing framework for workstation farms                    The GRAIL Gene Recognition System     GRAIL is a modular system which supports the recognition of gene features and gene modeling for the analysis and characterization of DNA sequences. GRAIL uses multiple hybrid statistical and neural network-based pattern recognizers and a dynamic programming approach to constructing gene models. GRAIL recognizes protein coding regions (exons), poly-A addition sites, potential promoters, CpG islands and repetitive DNA elements. XGRAIL also has a direct link to the genQuest server allowing characterization of newly obtained sequences by homology based methods through accessing a number of databases using a number of comparison methods including: FASTA, BLAST and a parallel implementation of the Smith-Waterman algorithm which utilizes the DEC cluster at ORNL CSMD. Following an analysis session the user can use an annotation tool to generate a ``feature table'' describing the current sequence and it properties. All of this information is presented to the user in graphic form in the X-window based client-server system XGRAIL.    Since its development in 1991 (Uberbacher and Mural, 1991), the GRAIL system at ORNL has become the world standard for predicting protein coding regions (exons) and modeling genes in DNA sequences. From its inception GRAIL has been accessible over the network in a variety of ways including e-mail, a X-based client-server system and through various web browsers over the world wide web. The experience with GRAIL at ORNL gives us an understanding of the needs of the genomic / biomedical research community. The GRAIL system currently analyzes about 17 million bases of DNA sequence per month (using methods which are simpler and less comprehensive than what is proposed in this GC project). In addition the ORNL Informatics Group maintains a public server, genQuest, which allows investigators to query a number of public sequence databases to establish whether a newly determined sequence has any known homologs. The genQuest server generally processes about 2500 database search requests per month. Combined, GRAIL and genQuest tax the computational power of a 16 DEC-Alpha workstation cluster maintained to support these servers.    GRAIL is the most widely used of the currently available systems for recognizing the portions of a sequence which have the potential to encode a protein. Since GRAIL became available as an e-mail server in 1991, it has processed over 200 million bases of DNA sequence (X. Guan and M. Shah, personal communication) and currently processes 2000 transactions per month. GRAIL can be accessed in four different ways: (a) through an e-mail server ( grail@ornl.gov ), (b) through an X-windows based client-server (the client is available by anonymous ftp from  arthur.epm.ornl.gov ), (c) Through the World Wide Web (URL  http://avalon.epm.ornl.gov/ ), and (d) as a stand-alone commercial package.        The MAGPIE System     MAGPIE, an automated system for carrying out genomic sequence analysis, has recently been introduced. MAGPIE (Multipurpose Automated Genome Project Investigation Environment) is designed and implemented to meet the challenges that arise with the generation of complete microbial genome sequences, during and beyond the lifetime of a genome sequencing project. In many ways Magpie is a model for methods of analysis and data mining which could become part of the much larger scale processing proposed in this Grand Challenge project.    When whole microbial genomes are analyzed, large numbers of remote and local analysis tool requests, each depending on changing remote and local conditions, must be initiated. Decision modules must monitor and obey user preferences and combine evidence from multiple sources to formulate credible hypotheses about sequence function. The data volume that needs to be analyzed in a genome project prohibits the use of ``manual'' techniques and even discourages semi-automatic analysis approaches, because these are not efficient enough to keep up with the pace of sequence production. One megabase of microbial genome sequence contains on the order of 1000 genes, in G+C rich organisms, the number of open-reading frames is much higher than the number of genes due to the lack of artificial stop codons. Each open reading frame must be examined by an array of tools and searched against multiple databases. Thus, on the order of 100000 database searches must be performed and analyzed for each megabase of genome sequence data. The results of an automated genome analysis must be served in logical units that allow researchers to access the data in the most efficient way. Researchers must be able to interact with the automated system in order to verify, recombine or refute the automatically generated information.    MAGPIE operates as a local system within a particular genome project. Using techniques based on active database and intelligent agents, MAGPIE monitors sequence generation, automates the collection and update of analysis data, and makes initial decisions about genome features based on the combined analysis data. It facilitates human validation and editing of automatically assigned features. It also allows updates to those features as a genome project carries out wet-lab verification or refutation. The current system is designed to handle large contiguous sequences that range in state from early assembled trace data to finished cosmids to finished microbial genomes. It runs on Unix workstations with Perl, Prolog, and C. The system is scalable: changing one configuration file enables it to run on a single workstation, on a local network of workstations, or on a multiprocessor parallel system (e.g. the IBM SP). It is configurable to invoke analysis tools or query locally or remotely. A new tool is added to the system by editing configuration files and adding an output parser to the MAGPIE bin. The current default configuration includes the BLAST and FASTA families of tools, MP-Search, BLOCKS, PROSEARCH, GENEMARK, tRNAscan-SE, and predict-protein. The output is in the form of queryable tables and browsable html files. Each genome feature is connected to its supporting evidence and to relevant public database resources including SwissProt, the EMBL Nucleic Acids Database, EMP (Enzyme and Metabolic Pathways database), the Blocks database, the Enzyme databank, Prosite, and MedLine through public database integration resources including SRS, ExPASY, Entrez, and PUMA.    Three microorganism genomes have been analyzed using the MAGPIE system: Sulfolobus solfataricus, Mycoplasma genitalium, and Rhodobacter capsulatus. The most significant limiting factor for a MAGPIE project is the amount of disk space for storing domain data. A one megabase pair genome in the finished phase, with about 25 to 30 different analysis tools employed, fills 1 gigabyte of disk. Another bottleneck is the performance of community-shared remote tool servers. Response times can be up to several hours for a particular tool request. This makes it impossible to quickly request the hundreds or thousands of responses needed for a megabase of DNA. Both of these problems should be alleviated in the present project through use of high performance computing and terabyte storage capabilities.        The Kleisli System     The CPL/Kleisli system addresses the problem of integrating multiple, distributed heterogeneous data sources and application programs. One of the strengths of Kleisli is its ability to deal with non-traditional sources, such as data exchange formats, rather than mainstream databases, with the data exchange formats commonly employ complex, nested data structures composed of collection types such as sets, multi-sets, variants, records, lists, and arrays. Furthermore, relational query languages are notably deficient in their ability to query lists and sequences, precisely the data structures used to represent biosequence information.    Kleisli uses general-purpose query system, CPL/Kleisli, that provides access to a variety of flat files (GenBank), custom systems (ACeDB, ASN.1), application programs (BLAST), and relational databases (GDB, GSDB). It features a uniform query interface across heterogeneous data sources, a modular and extensible architecture, and most significantly for dealing with the Internet environment, a programmable optimizer. Kleisli is capable of complex data manipulation such as structural mediation --a complex data ``join'' between structures that come from different sources--and structural wrapping--type transformations involving nesting/unnesting plus generalized selections and projections. Kleisli has been shown to be efficient in composing and executing queries that were considered difficult, if not unanswerable, without first either building a monolithic database or writing highly application-specific integration code. The system is organized into three layers: (1) a CPL query interpreter; (2) an optimizer and application programming interface; (3) Data drivers, modular interfaces that mediate between Kleisli and external data sources.    Kleisli is an extensible query system whose integration capabilities lie somewhere in the middle of the typical ARPA Intelligent Information Integration (I3) architecture. Below it we have components that do the actual source access, perhaps over a network, that may pipeline the data, and that may do some dumb, lexical data format translation. Kleisli's terminology calls such components data drivers. Above it are the ``intelligent'' components, that do ``semantic integration'', that are capable of ``reasoning'', for example in order to deal with redundant information, semantic reconciliation, and even choosing an optimal query plan when a query can be answered in several ways each involving a different set of sources.    The basic query interface to Kleisli is the CPL query language (for Collection Programming Language) developed at Penn. CPL uses the native operations associated with records, variants, sets, lists and multi-sets as the basis of a complete query language for complex types. CPL currently uses a comprehension syntax, and can be thought of as SQL extended to a richer type system. Within the context of the Kleisli system, it should be thought of as relatively low-level glue language on top of which user views of an integrated data system can be developed.    Crucial to the success of the Kleisli system is its ability to optimize CPL queries across multiple data sources. Many of the optimizations fall out naturally from the theoretical underpinnings of CPL, and generalize to this richer, complex-value type system many of the well known optimizations for relational databases. In addition, basic operations such as joins have multiple evaluation strategies; rules in the optimizer specify conditions under which to use each strategy. The optimizer also uses lazy evaluation and parallelism whenever possible to reduce response time and total execution time. Although the optimizer is quite powerful, it does not have statistical information and access to indices at the underlying sites. For relational databases, it therefore recognizes the largest local sub-query that can be performed by the relational server and migrates it to that server for evaluation. This takes advantage of the powerful local optimizers available at most relational data sources and has proven to dramatically reduce response time.    Kleisli is currently written entirely in ML. Routines within Kleisli manage optimization, query evaluation, and I/O from remote and local data sources.    Once registered in Kleisli, ``data drivers'' perform the task of logging into a specific data source, sending queries in the native form for that source, returning results to Kleisli in internal Kleisli value syntax, and logging out from the data source when the user session terminates. The types of data sources currently registered include Sybase, ACeDB, ASN.1 as well as BLAST; the drivers are generic rather than source specific, meaning that once a Sybase driver has been written any Sybase database can be supported. Because communication with the drivers is facilitated through UNIX pipes, drivers can be written in any language; we have used C, perl, as well as Prolog. In addition, a flexible printing routine allows data to be converted to a variety of formats for use in displaying (e.g., HTML) or reading into another programming language (e.g., perl).    The Morphase system complements CPL/Kleisli by providing a declarative constraint language, based on Horn-clause logic, that is used to specify full database transformations. Morphase is useful for specifying transformations from one or more input databases to an output database, as is done when designing user views, sharing data between heterogeneous data sources, or as is most often the case in our work, in creating a data warehouse by extracted subsets of information from several community, transforming and installing it in our local databases. The benefit of a declarative interface is that it is extremely easy to modify as schemas of the underlying data sources and targets evolve. BioTk is a domain-specific widget set designed to make it easy to rapidly prototype graphical user interfaces. The overarching philosophy behind bioTk is the creation of adaptable, reusable software, deployed in modules that are easily incorporated in a variety of applications, and in such a way as to promote interaction between those applications. Many genome centers create such custom software when existing frameworks do not address their requirements. Largely because of the need for rapid development, the degree of customization of the tools, the availability of local support, the pressures to move on to the next application, and the lack of incentive to ``productize'', such software is legendary for its failure to transport well to other environments. Thus, large genome centers have done surprisingly little in the way of software sharing and reuse. One of our main concern is the support of rapid prototyping of applications by bioinformatics professionals in larger research centers.    The widgets in bioTk encapsulate recurring themes in graphical objects and their behaviors, relieving the programmer of many tedious details. In addition, it achieves a common ``look-and-feel'' by way of features like a standard menubar and a common, context-sensitive help system. In addition to the general support and help widgets, the bioTk package includes:, a canvas item that draws chromosomes and supports various useful operations upon them; a system supporting the creation of various forms of genome maps and map objects on canvases; a widget that creates a scrolling window of sequence data and again supports various domain-specific operations, especially annotation. The menubar along the top is a bioTk standard, and is created with a single command that contains nested cascading menus in a compact data structure. A standard file box is shown, one of several types of dialogs available. At the bottom is the context-sensitive help window, and one of a library of standard icons. bioTk has already proved very successful in support of EpoDB and the Genome Center for Chromosome 22, and it is now being adopted by a wider community of bioinformatics researchers and developers as part of a consortium which is planning to extend it along a number of paths. The master version is implemented in tcl/Tk, a free software package, but parts of it have already been ported to Perl/Tk and Java for distribution over the WWW.        The Collaborative Management Environment (CME)     The Collaborative Management Environment is a joint research project between Ames Laboratory and Oak Ridge National Laboratory and is funded by the U. S. Department of Energy (DOE). The objective is to establish the framework for a robust, scalable, and secure virtual management system that could ultimately become the de facto standard management system for the DOE. This system will provide sophisticated search and cross-cut capabilities within a single site or across multiple sites for finance and project information. The research is divided into two functional components that will support a web-based information system: intelligent agents at each site and data analysis and programming tools.    The research tasks include evaluation of the proposal submission and project management process to identify critical features; defining functionality for data analysis and programming tools that support the web-based interface; defining the meta descriptor and functions of the intelligent agents. In addition, much effort is focused on security: authorization and authentication; archival, and interface design.    The initial prototype is based on expertise gained in the Financial Automated On-line User System at Oak Ridge National Laboratory and the Environmental Restoration Integrated Information System at Ames Laboratory.        The NCGR, the GSDB Database and Annotator         GSDB.     The Genome Sequence DataBase (GSDB) is a complete, public database of DNA sequences and associated annotation. GSDB is an outgrowth of the original U. S. DNA sequence database project, initiated at Los Alamos National Laboratory in 1979. GSDB development is currently supported by the U.S. Department of Energy under Cooperative Agreement DE-FC03-95ER62062 through 1999.    The GSDB system comprises a relational database, an overlying in-memory object-oriented data representation, and a set of client user interfaces and tools. GSDB is a client-server system, in which multiple clients with their own local object-oriented representations of data currently being acted upon communicate with a common remote relational server. The development platforms are currently the Sybase relational database management system (Sybase, Inc.), the C++ object-oriented programming language, and the Galaxy multi-platform interface development tool (Visix, Inc.).    GSDB is designed to meet the needs of the human, model-organism, and microbial genome research communities for acquisition, analysis, and management of DNA sequence data and associated structural and functional annotation. GSDB supports multiple sequencing strategies, including whole-genome shotgunning, rapid low-pass genome sampling, expressed sequence tag (EST) analysis, PCR amplicon sequencing, and traditional gene or cDNA sequencing. GSDB supports assembly of representative sequences from multiple components obtained by different researchers, as well as distributed analysis and annotation carried out by a community of researchers over an extended period. The current GSDB data model treats DNA sequences and annotations assigned to those sequences as independent objects with their own unique, permanent accession numbers and owners. This model is a radical departure from the entry-based data model used by GenBank and the other archival databases, and by earlier versions of GSDB. Aligned sets of DNA sequences, and discontiguous sets of sequences related by order, orientation, and distance constraints are also basic objects in the data model. The GSDB schema is fully specified in a document available on  http://www.ncgr.org/gsdb . This schema relates sequences and features to genes, gene products, clonal sources, organismal sources, links to external databases or World-Wide Web sites, and standard metadata.        GSDB Annotator.     A multi-platform, graphic user interface for browsing, manipulating, and editing sequences and features in GSDB, the GSDB Annotator, is currently under development for fall, 1996 release to the public. The Annotator will display sequences simultaneously at up to four scales ranging from the 100 Mb range down to single base resolution, and allow selection and editing of features of any scale. The interface can manipulate whole microbial genomes or eukaryotic chromosomes, and can display discontiguous structures such as Sequence-Tagged Site (STS) maps as single entities. It supports the simultaneous display of genomic sequences, sequence variants, transcribed messages, protein products, and DNA- and RNA-level features.    The Annotator is being implemented using the Galaxy multi-platform tool on Macintosh PowerPC and Sun SparcStation simultaneously. The system will be ported to Windows NT and a variety of Unix platforms.    Fully-automated bulk data input and output from GSDB are supported by a tag-value file format, GSDB Input/Output or GIO format. This format is fully specified in a document available from  http://www.ncgr.org/gsdb . The GIO format supports all data types supported by the GSDB schema, and allows for data additions as well as new submissions to the database.    A relational tracking database maintains metadata records of all inputs to GSDB as well as all distributions of data to the public ftp site. This database also tracks all automated quality-control processing, including error logging, and all manual intervention in the input-processing stream.        NCGR Capabilities.     NCGR brings expertise and experience in biotechnology, bioinformatics, and information system development to the Collaboration.    NCGR maintains the Genome Sequence DataBase (GSDB), a complete database of DNA sequences and annotation, in a Cooperative Agreement with the US Department of Energy. The GSDB system includes an underlying relational database (implemented in Sybase), an in-memory object-oriented data representation (implemented in C++), and a set of user-interface clients, including a browser-editor (implemented in Galaxy) capable of manipulating multi-base sequences with associated functional annotation. GSDB can be accessed via  http://www.ncgr.org .    NCGRs software development team has expertise in large-scale relational and object-oriented database development and maintenance, data input and output interfaces, graphic user interfaces, intelligent system design, software engineering, testing, and project management. Software development is managed by a well-defined software engineering process. Development is supported by full-time software engineering, systems analysis, configuration management, and testing personnel in addition to hardware and software systems administrators.    NCGRs bioinformatics team has expertise in sequence analysis tools and methods, large-scale sequence assembly, gene structure prediction, PCR primer design, systematics, and data curation.    Senior NCGR personnel have expertise in development and maintenance of DNA sequence and sequencing laboratory databases, in sequence analysis tool development, pathogen characterization by sequencing and other techniques, and high-throughput sequencing laboratory development and support.        The Object-Protocol Model and Tools     The Object-Protocol Model (OPM) data management tools provide facilities for constructing and maintaining efficiently molecular biology databases (MBDs) on top of commercial database management systems (DBMSs), and for exploring single as well as multiple heterogeneous MBDs. OPM is an object data model whose object non-versioned part is closely related to the ODMG-93 standard for object-oriented data models. In addition, OPM supports object versioning and a protocol construct for modeling scientific (e.g., sequencing) experiments. The OPM query language (OPM-QL) follows the ODMG-93 standard for object-oriented query languages.    The OPM tools have been used for developing new MBDs, such as the Genome Data Base (GDB) at Johns Hopkins School of Medicine ( http://gdbgeneral.gdb.org/gdb/ ) and the new version of the Protein Data Bank (PDB) at Brookhaven National Laboratory ( http://terminator.pdb.bnl.gov:4148 ), and for constructing OPM views and interfaces for existing genomic databases such as the Genome Sequence Data Base (GSDB) at the National Center for Genome Resources. Detailed OPM documentation and examples are available at  http://gizmo.lbl.gov/opm.html         The Object-Protocol Model and Query Language     Objects in OPM are uniquely identified by object identifiers (oids), are qualified by attributes, and are classified into classes. A subset of the attributes associated with a class is specified as the external object identifier. A class can be defined as a subclass of other (super) classes, where a subclass inherits the attributes of its superclasses. OPM supports multiple inheritance in class hierarchies.    Attributes can be simple or consist of a tuple (aggregation) of simple attributes. A simple attribute can have a single value, a set of values, or a list of values, and can be primitive, if it is associated with a system-provided data type, or abstract, if it takes values from object classes. The attributes of an object class can be partitioned into non-versioned and versioned attributes: non-versioned attributes represent stable object properties while versioned attributes represent evolving object properties of an object.    Protocol classes in OPM are used to model scientific experiments. OPM supports the recursive specification (expansion) of protocols, where a protocol can be specified in terms of alternative subprotocols, sequences of subprotocols, and optional protocols. A protocol class can be associated with regular as well as input and output attributes that are used for representing input-output protocol connections.    OPM supports the specification of derived attributes using derivation rules involving arithmetic expressions, aggregate functions, and attribute composition. OPM also supports two types of derived object classes: derived subclasses and derived superclasses. A derived subclass is defined as a subclass of another derived or non-derived object class with an optional derivation condition. A derived superclass is defined as a union of two or more derived or non-derived object classes.    OPM-QL follows the ODMG-93 standard for object-oriented query languages. An OPM query involves local, inherited, derived and system attributes and path expressions starting with these attributes. An OPM query can involve conditions consisting of and-or compositions of atomic comparisons, and can contain an order-by clause, which specifies an attribute whose values are used for sorting (in ascending or descending order) the class instances returned by the query.        The Core OPM Tools     The core OPM data management toolkit includes tools for building, managing and querying OPM databases, and for building OPM views on top of existing databases.    OPM schema editing and browsing tools are provided for specifying and examining an OPM schema for a particular application. The OPM schema translator can be then used for generating automatically the complete definition of the underlying relational (Sybase or Oracle) database, including the rules and constraints required for maintaining data integrity. A mapping dictionary records the correspondences between the classes and attributes of an OPM schema and the underlying relational tables, and is used in translating OPM queries and updates into their relational (SQL) correspondents.    The OPM query translator processes ad hoc OPM-QL queries. Two alternative approaches to OPM-QL translation are supported: (i) using stored procedures, which provides maximum efficiency for fixed-form queries against a native OPM database, and (ii) generating SQL queries on the fly, which is suitable for free-form queries and for querying pre-existing (non-OPM) databases.    Application programs can interact with OPM-QLT in two ways: (1) Access OPM-QLT via a C++ wrapper: metadata representing the OPM database is loaded at runtime through dynamic linkage; the OPM-QL query input, specified as a string, is translated into a series of SQL statements that re sent and executed through the DBMS API; the DBMS API returns a relations as query results, which in turn are converted into OPM data objects represented using C++ data-structures. (2) OPM-QLT is employed as a stand-alone application, and temporary ascii files are used for data-exchange; this approach can be used for example with PERL scripts implementing web-based query interfaces for OPM. Other alternatives that are currently considered include embedding OPM QLT inside a scripting language such as PERL, rather than just running it as an external utility as mentioned in (2), and interacting with OPM-QLT via a generic CORBA compliant OPM interface.    Pre-existing, non-OPM databases can be retrofitted with an OPM view (schema) using the OPM retrofitting tools. Retrofitting involves generating first a canonical OPM schema from the native database schema, and then refining, and thus semantically enhancing, this OPM view via a series of schema restructuring manipulations, such as renaming and/or removing classes and attributes, merging and splitting classes, adding or removing subclass relationships, defining derived classes and attributes, and so on.    The retrofitting tools can be used for constructing multiple OPM views for a single (OPM or non-OPM) database. The retrofitting tools generate a mapping dictionary, that can be used in conjunction with the other OPM tools in order to browse or query the underlying database. Retrofitting tools are currently available for relational and ASN.1 databases, with versions of the tools for other databases planned.    In addition the core OPM toolkit includes tools for publishing OPM schemas in a variety of formats, including HTML, PostScript and LaTeX, and for constructing Web form-based interfaces for querying OPM databases.        The OPM Multidatabase Tools     The multidatabase OPM (OPM*) toolkit, provides tools for constructing multidatabase systems consisting of heterogeneous databases, and for exploring (browsing, querying) such multidatabase systems. This toolkit is built on top of the core OPM toolkit and includes tools for: (1) assembling component databases into an OPM-based multidatabase system, while documenting their schemas and inter-database links; (2) processing ad hoc multidatabase queries via uniform OPM interfaces; and (3) assisting scientists in specifying and interpreting multidatabase queries.    Incorporating an MBD into an OPM multidatabase system involves constructing one or more OPM views of the MBD, and entering information about the MBD and its views into a multidatabase directory. The multidatabase directory stores information necessary for accessing and formulating queries over the component MBDs, including: (1) general information describing each MBD accessible in the system, and the information required for accessing the MBD; (2) structural information on the schemas of each MBD, including semantic descriptions of the physical or real world concepts represented by the schemas, synonyms and keywords for identifying differences in terminology and for establishing potential correspondences between components of different MBD schemas, and sample data illustrating how the schema constructs are for representing application data; (3) information on known links between different MBDs, including semantic descriptions of links, the nature of the correspondence represented by links, and data-manipulations, such as reformatting of accession numbers, that need to be performed in order to traverse the link.    Queries in an OPM-based multidatabase system are expressed in the OPM multidatabase query language (OPM*QL). OPM*QL extends the single-database OPM query language, OPM-QL, with constructs needed for querying multiple databases. These extensions include the ability to query multiple classes, possibly from distinct databases; constructs that allow navigation between the classes of multiple databases following inter-database links; and the ability to rename fields of a query in order to resolve potential naming conflicts between multiple databases.    Processing OPM multidatabase queries involves generating OPM-QL queries over individual databases in the multidatabase system, and combining the results of these queries using a local query processor. The stages of generating OPM-QL queries and manipulating data locally may be interleaved depending on the particular query evaluation strategy being pursued.        Generalized Hidden Markov Models for Gene Model Construction     Hidden Markov Models (HMMs) for DNA can be viewed as generative stochastic models of sequences that go though a sequence of hidden states, and in each hidden state they generate a single letter in the alphabet {A,C,G,T} according to certain probabilities associated with that state (Krogh et al. 1994a, Krogh et al. 1994b). The sequence of hidden states forms a Markov chain, in the sense that which state generates the nth letter depends only on which state generated the n-1st letter. This contrasts with (non-hidden) Markov models of sequences, in which the sequence of letters itself forms a Markov chain, i.e. the nth letter depends only on the n-1st letter, or on the letters at positions n-k,... n-1 in the case of a kth order Markov model.    In a generalized HMM, each state can generate a string of one or more letters according to a probability distribution specified by some arbitrary mechanism, particular to that state. The only thing we demand of this mechanism is that we can efficiently compute the probability (i.e. likelihood) of any string under the distribution defined by the mechanism. Models of this type were described in (Stormo and Haussler 1994) for the case that there are only two possible states, Exon and Intron, and the Markov chain for the states is trivial, in the sense that it alternates back and forth between these two states with probability 1. Each time such a model is in the exon state, it generates a string according to the probability distribution associated with exon strings, and each time it is in the intron state it generates a string using the intron distribution. The output is the concatenation of these generated strings. To use such a generative model for recognition of introns and exons in a DNA sequence, a dynamic programming method can be used to ``invert the generative process'' and find the most likely sequence of individual strings and their states that were concatenated to make the sequence. We call this ``parsing'' the sequence. In collaboration with LBL, we have extended this model to include more than 2 states, with general Markov transition probabilities between states. We call these generalized HMMs.    One advantage of having more than two states is that now we can explicitly model conservation of the codon frame between consecutive exons. We do this by having nine different states for different kinds of internal exons, one for each combination of the codon frame at the beginning of the exon and the codon frame at the end of the exon. For the first exon in the gene, we need only three different states, each representing a possible codon frame at the end of the first exon, and analogously, three states are needed for the last exon in a gene. Three types of intron states are also used, depending on the codon frame at the point were the intron breaks the coding sequence. Only transitions between exon and intron states that preserve the correct codon frame are allowed. Many gene-finding systems impose similar constraints in their model, but here they can be imposed in a simple declarative manner, by specifying states and transitions, rather than being deeply embedded in the dynamic programming code, where they are difficult to modify. Indeed, the dynamic programming methods we use to parse with generalized HMMs are quite general, and work for any Markov chain for the states without modification.    Another advantage to the flexibility of generalized HMMs is that it is easy to add other capabilities to the gene-finding system, such as the ability to incorporate database hits discovered by BLAST searches of a protein database, and to find promoters, RNA genes, known repetitive DNA sequences etc., as soon as states for these have been defined with appropriate probability distributions. You just \Q\Qwire them in'' to the existing HMM architecture by modifying the Markov chain transition probabilities to include the new states.    In the last year we have built a gene-finder, called Genie, based on generalized hidden Markov modelling methods. Experiments on our own internal database of human genes, as well as on the benchmark database of vertebrate genes used by Guigo in his comparison of Genefinder, show that this method has some advantages over currently available gene finders for human DNA. In particular, it is more accurate than other programs on the Guigo dataset without using homologies found by BLAST, and is able to further improve its performance by incorporating such homologies (Kulp et al. 1996). Nomi Harris at LBL has built an integrated system to accept human DNA fragments and display the results of various gene-finding methods on them, including GRAIL, GenMark, Genie and others. As no one genefinder is ever perfect in its predictions, her system can also combine the predictions of several gene finders using a kind of ``majority vote'' mechanism, and thereby improve over the performance of any single genefinder. This seems a particularly promising direction for further research in DNA annotation.        The High Performance Storage System (HPSS)     The High Performance Storage System is software for high rate access and management of digital data within very large storage environments. HPSS is intended to address the needs of very large high performance computing and data management environments. HPSS will be of interest in situations having present or future scalability requirements that are very demanding in terms of total storage capacity, data rates, number of objects stored, and number of users.    HPSS is a cooperative development project, originated by IBM government systems and four Department of Energy laboratories, LLNL, LANL, SNL, and ORNL. Cornell University under NASA Lewis Research Center sponsorship, and NASA Langley Research Center have also contributed to the development of HPSS.    A central technical goal of HPSS is to move large data files between storage devices and parallel or clustered computers at speeds many times faster than today's commercial storage systems software products, and to do this in a way that is more reliable and manageable than is possible with current systems. In order to accomplish this goal, HPSS employs the following concepts:        A network-centered architecture.     The focus of HPSS is the network, not a single server processor as in conventional storage systems. HPSS provides ``servers'' and ``movers'' that can be distributed across a high performance network to provide scalability and parallelism. The basis for this architecture is the IEEE Mass Storage Systems Reference Model, Version 5.        A design based on standard components.     HPSS runs on Unix with no kernel modifications and is written in ANSI C. It uses the OSF Distributed Computing Environment and Encina as the basis for its portable, distributed, transaction-based architecture. These components are offered on many vendors' platforms and will enable the eventual porting of HPSS to many of those environments. Transaction management and Kerberos security enable a reliable design that protects data both from unauthorized use and from corruption due to lost pointers. Having accepted DCE as the system infrastructure, HPSS can leverage other DCE or DCE-based services in the future        Parallel operations     built in HPSS supports both parallel clients and parallel storage devices as well as sequential clients and storage where the number of data sources and destinations are different. Parallel data transfer is vital in situations that demand quick access to very large files.        Multiple hierarchies and classes of service.     HPSS can concurrently handle many classes of service that correspond to hierarchies that may be as simple as a single tape or that have the complexity of multiple levels of caching and migration through disk, disk array, local tape, and remote tape. Classes of service are limited only by the need of the user and the system management goals of the service provider.        Centrally managed storage.     Although physically distributed in its architecture, HPSS offers a logically centralized framework for management of storage. A graphical user interface is supported. HPSS uses the managed objects framework os the ISO OSI system management model.        Growth potential.     Collaborators plan to support DFS (Distributed File System) and most popular disks, tapes, robotic servers, and computational platforms, and plan other ongoing enhancements.        SubmitData - Data Submission to Public Genome Databases     Direct author submission accounts for a majority of the submissions of genomic information, e.g., sequences, maps, etc., to genome databases for distribution to the scientific community and the general public. Involving authors in the data submission process produces better entries. Their expertise is called upon to help create more meaningful and correct annotations. They are entitled, however, to get assistance to make the task as easy as possible. SubmitData\DB is an object-oriented framework developed by Manfred Zorn at LBNL to provide the user with a tool for direct author submissions. It enables the user to:                  prepare a single direct submission to a number of public databases using a graphical interface that assists the user by offering menu choices for controlled vocabularies and compliance with the database requirements.       submit bulk quantities of data using a previously defined template that is merged with the actual data.       prepare data to be submitted to multiple databases without entering repeated information using a common user interface.       submit data transparently from within other applications.       adapt the submission tool to changing data submission protocols          Versions of SubmitData\DB have been developed for GSDB using the Transaction Protocol and GDB 5 forms. Current work is being done on a version to work with the new GDB 6 format and GSDB's new GIO protocol. The work on SubmitData has been presented on numerous conferences and workshops. The data submission tools are implemented using the Smalltalk language and the ParcPlace VisualWorks\Smalltalk development environment. Submission protocols are stored as Smalltalk objects using the inherent Smalltalk parsing capabilities. The user interface is created by assembling user interface objects defined in the VisualWorks toolkit.    The model used here is a template that defines constant information and is merged with a data stream to generate output in the appropriate data submission format. Variables in the template are exchanged for corresponding values in each record of the data stream. The SubmitData framework defines a set of classes that support the development of such submission tools. It consists of three major parts: a kernel that handles protocol specific operations, i.e., the data exchange format of a particular database, a template editor to create and modify templates, and a database interface to handle the actual data submission to the database(s).    Kernel classes. The kernel classes represents the data submission protocol of a particular database. The protocol defines, what kind of information is required or optional by the database; specifies data types for values, lists controlled vocabularies, and defines the relationship between data items. In order to make the submission tool independent of a particular database's data exchange format, a specific Parser interprets the protocol definitions and generates more generic EntityDefinitions and FieldDefinitions. EntityDefinitions represent the objects, e.g., locus, clone, entry, and have a set of attributes, so called fields. A FieldDefinition describes a single attribute in terms of its name, possible alternate names, data type, default values, ranges (numerical ranges or sets of values), description, etc. Values entered by the user are validated against these definitions. Unspecified conventions that reflect common uses in the user community or traditions within the database can be specified as conventions and applied to the data values. Triggers and conditions handle dependencies among fields or modify a field's behavior in relation to other fields.    User and application interface layer. For the template editor a standard user interface is an automatically generated form based on the EntityDefinitions. Each form displays a single entity. References to subentities are represented through buttons or lists that open the respective forms. Controlled vocabularies define menus from which the user may select valid values. Error messages provide feedback to the user on processing errors. Customized user interfaces can easily be built on top the standard user interface exploiting and reusing functions already defined in the standard user interface. This layer also handles the interaction with other applications, e.g., sequence analysis tools.    Database interaction and data submission. In the simplest case, this layer formats the data according to the respective protocol and sends them to the database via electronic mail or other network capabilities. Separation of the database access layer from the kernel functions, however, allows to exchange the communication module. For single transactions with a single database sending electronic mail or transferring the datafiles using the ftp network protocol is sufficiently fast and easy. Submissions to multiple databases with mutual cross references require more sophisticated interactions.    The framework gets more refined with every new database it is applied to shortening development times for each new target database considerably. We will be able to use this experience for developing data mining and extraction agents and the interaction with genome databases.        BioPOET - A parallel processing framework for workstation farms         POET (Parallel Object-Oriented Environment and Toolkit)     The goal of the POET (Parallel Object-Oriented Environment and Toolkit) approach is to design well defined mappings between the representations of physical phenomena in terms of mathematical structures and the computational algorithms for modeling the phenomena. The approach to POET is similar in design methodology to the Xt toolkit. A high level object-oriented framework isolates a physical model description from the code that implements the parallel algorithm and data flow. Through this object-oriented interface, direct integration of existing application codes are implemented without affecting the parallel computation algorithms. As such, a scientist need only be concerned with application specific code not the details of parallel computation.    POET development by J. Macfarlane, LBNL and R. Armstrong, Sandia National Laboratory, initially concentrated on two specific areas: implicit and explicit finite difference problems and independent task analysis problems. The first category of problems covers many areas of physics and engineering. Examples of explicit PDE problems are compressible computational fluid dynamics, heat and mass transfer, and unbounded wave mechanics. Examples of implicit problems include incompressible fluid dynamics, transport problems involving fast (stiff) chemical reactions and bounded wave mechanics. Examples of the second category of problems are human genome sequence comparisons and Monte Carlo simulations.    Sequence similarity searches can be seen as a database filtering problem, i.e., the comparison of a query sequence against the very large set of existing biological sequences a database. Each comparison is a completely independent task. These comparisons are correlated into a hitlist on the host processor after the comparison has been completed. We have completed the development of an object in POET that will manage the distribution of independent tasks across multiple processors. Initial test results show a linear inverse relationship between the number of processors used and the processing time.    The human genome application and the combustion modeling examples demonstrate the flexibility of the software design methodology captured in the POET software. The intelligence associated with distributing the problem over multiple processors is embedded in the objects defined in POET. As such, a user interface that is customized to the specific scientific application can provide easy access to supercomputing power to scientists who would otherwise be overwhelmed by the complexity of using supercomputing resources. With this added capability, problems that are currently unapproachable in these disciplines will be within reach.    The purpose of the project was to develop a unique approach to scientific computing on massively parallel computing platforms. The goal of the POET (Parallel Object-Oriented Environment and Toolkit) approach is to design well defined mappings between the representations of physical phenomena in terms of mathematical structures and the computational algorithms for modeling the phenomena on high-performance parallel computing platforms. Using this approach, we identify representations that solve classes of scientific problems. Thus, once the representation is defined for a particular problem area the mapping into the computing algorithm is handled automatically by the POET architecture. We demonstrated the benefits of this approach by application to three scientific computing problems.        BioPOET     The best known rigorous method for biological sequence comparison, the algorithm by Smith and Waterman, computes in quadratic time the highest scoring local alignment of two sequences.    Within the POET framework M. Zorn, J. Macfarlane, and M. Cooper added functionality to handle a large number of repeated small tasks, Bag-Of-Tasks. A master process controls the bag of tasks and distributes each one of them to a worker process. The communication with among the processes is handled through the PVM message passing system. Fault tolerance and error recovery have been implemented at the relatively coarse level of a task. Since each task can be accomplished in short time, i.e., in the order of CPU minutes and hours, aborted tasks are best restarted on another worker process. Because of the huge number of individual tasks, performance differences among various platforms even out and yield a nicely load-balanced environment.    A task can be specified as a callback routine that the framework invokes to process the task. In the sequence analysis application, a task constitutes the comparison of one database sequence with the query sequence. Results of the task are returned to the master process for book keeping and producing the final output of the application.    A prototype system, BioPOET, performs sequence analysis on a workstation farm integrated into a friendly user interface. We also developed a graphical user interface, developed in Parcplace Smalltalk, that allows parameter specification for several analysis options and launches the analysis program. A graphical display presents the final results to the user.    Future work will focus on integration of existing software modules into both the BioPOET parallel processing environment combined with ongoing efforts to generate user interfaces in a more automatic and transparent way to create a plug-and-play environment. Within this Grand Challenge application we plan to update the BioPOET framework for use with the Parallel Distributed Systems Facility at NERSC to perform less compute-intensive computational biology algorithms and as a testbed for evaluating different implementations.        Appendix II. Preliminary CORBA Interface Definitions         Genome Exchange Model - OMG IDL implementation     The Genome Exchange Model (GEM) is the result of a Genome Informatics Workshop held at the San Diego Supercomputing Center, San Diego, in August 1995, with the goal to define a minimal data exchange model for maps and sequences. Manfred Zorn implemented the GEM map model in HP Distributed Smalltalk and translated the class definitions into OMG IDL interface definition language. A module defines interfaces that belong together. Each interface defines an object that could be accessable from other Object Request Brokers (ORBs). For convenience the top GEM object, GEMObject, is subclassed from DomainModel, but that should not be of any concern. The various # pragma  statements can safely be ignored. They tell about the Smalltalk methods that are represented by the access methods and provide an abstract class Id for the repository. The method body is still very scarce and needs more work.        Short glossary of IDL tags         module     Defines a logical group of interfaces in the Interface Repository        interface     Describes the possible set of operations and abstract behavior that a client may request of an object.        typedef     Declares new data type names        attribute     Shorthand mechanism for defining a pair of accessor functions to get and set the value of an attribute. Attribute values are recomputed every time. The pair of operation defined by attribute cannot raise exceptions.        operation     Defines a service that a client can request from an instance of a given object.        Inheritance     Interfaces can inherit from other interfaces. The interface is separated from its parent(s) by a single colon. Multiple inheritance is indicated by a comma separated list after the colon. sequence subtype specification        enum     Construbcted data type. Values take on one of a set of specified values.        Genome Exchange Model: IDL specification         // GenomeExchangeModel          // This module defines various objects in the Genome Exchange Model          //           module GenomeExchangeModel  {                  // This interface defines the behavior of GEMObject objects                  //                   #pragma  IDENTITY = 70846387-4e65-0000-0280-03c45a000000                  interface GEMObject : DomainModel {                          //is this a measure?                  boolean         isMeasure();                          };                         //GEMMapElement                 //  ------------------------------------------------------                 //MapElement:                  //A MapElement may be an interval or a point, and may be simple or composite.                  //In the simple case, the element has no internal                 //structure that we care to describe. In the composite case, the element is a                  //map in its own right.                  //  ------------------------------------------------------                  //Instance Variables:                  //      start                   <Float>                           //      stop                    <Float>                  //                  // This interface defines the behavior of GEMMapElement objects                  //                   #pragma  IDENTITY = 70846387-4e68-0000-0280-03c45a000000                  interface MapElement : GEMObject {                                  attribute               string          name;                          attribute               string          owner;                          attribute               Date            date;                          attribute               string          description;                          attribute               GEMObject       model;                          attribute               float           start;                          attribute               float           stop;                                  //size of GEM map element                          float size();                  };                                  //GEMMap                  // ------------------------------------------------------                  //Map:                  //A Map is a collection of MapElements and MapFacts about those elements.                  // ------------------------------------------------------                  //Instance Variables:                  //      elements    <Collection of: GEMMapElement>        set of map elements                  //      facts       <Collection of: GEMMapFact>           set of facts about the                  //                                                                 map elements                  //                  // This interface defines the behavior of GEMMap objects                  //                   #pragma  IDENTITY = 70846387-4e6b-0000-0280-03c45a000000                  interface Map : MapElement {                                  attribute sequence <MapElement>         elements;                          attribute sequence <MapFact>            facts;                  };                                  //GEMMapFact                  // ------------------------------------------------------                  //MapFact:                  //Each MapFact is a statement of a geometric or spatial nature about one or more  MapElements.                  // ------------------------------------------------------                  //Instance Variables:                  //      fact       <MapFacts>       stated fact, must be one of the allowed facts                  //      assertion  <GEMMeasure>    value of the stated fact                  //      about      <GEMMapElement | Array of: GEMMapElement> elements joined by  the fact                  //                  //Class Variables:                  //      MapFacts   <Array>  List of allowed facts: 7 or 13 interval relations                  //                                        plus extra map relations                  //                                              #before, [#after,]                  //                                              #contains, [#contained,]                  //                                              #starts,                   //                                              #finishes,                  //                                              #overlaps,                  //                                              #meets (= #abuts), [#met_by]                  //                                              #equals,                  //                                              #order,                  //                                              #distance,                  //                                              #position,                  //                                              #orientation                  //                   // This interface defines the behavior of GEMMapFact objects                  //                   #pragma  IDENTITY = 70846387-4e6c-0000-0280-03c45a000000                  interface MapFact : GEMObject {                                  enum MapFacts {before, after, contains, starts, finishes, overlaps,                                           meets, equals, order, distance, position, orientation};                                  attribute MapFacts                      fact;                          attribute Measure                       assertion;                          attribute sequence <MapElement>         about;                  };                                  //GEMMeasure                  // ------------------------------------------------------                  //Magnitude:                  //A Magnitude is an object used to represent distances and sizes.                   //It encapsulates units of measure and certain aspects of uncertainty.                  // ------------------------------------------------------                  //Instance Variables:                  //      unit            <Symbol>             allowed units of measurement                  //                   // This interface defines the behavior of GEMMeasure objects                  //                   #pragma  IDENTITY = 70846387-4e6d-0000-0280-03c45a000000                  interface Measure : GEMObject {                                  attribute string        unit;                                  //Answer whether the receiver is less than or equal to the argument.                          boolean         less_equal  (in Measure aMeasure);                                  //Answer whether the receiver is greater than the argument.                          boolean         greater  (in Measure aMeasure);                                  //Answer whether the receiver is greater than or equal to the argument.                          boolean         greater_equal  (in Measure aMeasure);                                  //is this a measure?                          boolean         isMeasure();                  };                          //GEMBinaryMeasure                  // ------------------------------------------------------                  // Measure to hold binary measures: true-false, yes-no, 0-1, etc.                  // Instance Variables:                  //      value                   <Boolean>               binary value                  //                   // This interface defines the behavior of GEMBinaryMeasure objects                  //                   #pragma  IDENTITY = 70846387-4e71-0000-0280-03c45a000000                  interface BinaryMeasure : Measure {                                  attribute boolean       value;                  };                          //GEMErrorBarMeasure                  // ------------------------------------------------------                  //ErrorBarMagnitude:                  //An ErrorBarMagnitude is the same as a RangeMagnitude, but is defined by                   //a center-point and an error-bar, e.g., x +/- y.                  // ------------------------------------------------------                  //Instance Variables:                  //      mean            <Number>        Mean or center point                  //      deviation       <Number>        error or deviation from the center-point                  //                  // This interface defines the behavior of GEMErrorBarMeasure objects                  //                   #pragma  IDENTITY = 70846387-4e72-0000-0280-03c45a000000                  interface ErrorBarMeasure : Measure {                                  attribute float         deviation;                          attribute float         mean;                                  //Answer whether the receiver is less than the argument.                          boolean         less (in Measure aMeasure);                                  //Answer whether the receiver is equal the argument.                          boolean         equal (in Measure aMeasure);                                  //convert Measure to SimpleMeasure                          SimpleMeasure           asSimpleMeasure();                                  //lower boundary                          float           lower();                                  //upper boundary                          float           upper();                  };                          //GEMRangeMeasure                  // ------------------------------------------------------                  //RangeMagnitude:                  // A RangeMagnitude represents a size or distance that lies within a defined                  // range (with some assumed probability function -- I                  //imagine this is generally normal, centered on the middle of the range).                   //It consists of two numbers and a unit of measure.                  // ------------------------------------------------------                  //Instance Variables:                  //      start   <Number>        start of the range                  //      stop    <Number>        end of the range                  //                   // This interface defines the behavior of GEMRangeMeasure objects                  //                   #pragma  IDENTITY = 70846387-4e70-0000-0280-03c45a000000                  interface RangeMeasure : Measure {                                  attribute float         start;                          attribute float         stop;                                  //Answer whether the receiver is less than the argument.                          boolean         less (in Measure aMeasure);                                  //Answer whether the receiver is equal the argument.                          boolean         equal (in Measure aMeasure);                                  //convert Measure to SimpleMeasure                          SimpleMeasure           asSimpleMeasure();                  };                          //GEMSimpleMeasure                  // ------------------------------------------------------                  //SimpleMagnitude:                  //A SimpleMagnitude represents a size or distance with no uncertainty.                   //It consists of a number and a unit of measure, e.g., cM, cR,                  //base-pairs, etc.                  // ------------------------------------------------------                  //Instance Variables:                  //      value                   <Number>                        measured value                  // This interface defines the behavior of GEMSimpleMeasure objects                  //                   #pragma  IDENTITY = 70846387-4e73-0000-0280-03c45a000000                  interface SimpleMeasure : Measure {                                  attribute float         value;                                  //Answer whether the receiver is less than the argument.                          boolean         less (in Measure aMeasure);                                  //Answer whether the receiver is equal the argument.                          boolean         equal (in Measure aMeasure);                                  //convert Measure to SimpleMeasure                          SimpleMeasure           asSimpleMeasure();                  };          };          Appendix III. Reprints            The reprints are not available on the web server.            Last Modified: 03:27pm PDT, July 23, 1996
GX016-01-11654762	"Setting Your Graphics Devices and Printing Graphics                                 Introduction                         Normally, one of the first things you need to do in Dataplot       session is to set the appropriate        graphics devices .               Dataplot provides three graphics devices that are set by the       commands                  DEVICE 1 <name>           DEVICE 2 <name>           DEVICE 3 <name>                These devices work independently of each other.  That is, you       can have 0, 1, 2, or all 3 devices active at the same time.               The DEVICE 1 output is generally the ""terminal"" graphics       device.  DEVICE 2 and DEVICE 3 are generally for writing       graphics output to file for later display or printing.                                                                      DEVICE 1 Output                DEVICE 1 is used to identify your terminal device.  It defaults       to a Tektronix 4014 terminal.  You can use the        Dataplot startup files  to change the       default screen device.                                   Unix Platforms                          On Unix platforms,  X11         is almost always the preferred terminal device when running        the command line version of Dataplot.  Enter the command                    DEVICE 1 X11                 to activate the X11 device driver.                 If you are running the graphical interface version, you should        not specify the DEVICE 1 X11 command yourself.  The GUI will        generate the command automatically and it appends some        window id information to the command (this is so the Tcl/Tk        scripts can control the graphics window).  The GUI allows        you to alternatively select to have the graphics drawn by        Tcl/Tk.  The primary advantage of the X11 driver is that        it is more efficient.  The primary advantage of the Tcl/Tk        driver is that automatic restoring of the graphics window        (after menu operations have covered it up) works better.        Basically, this comes down to a personal preference.                                   Windows Platforms                         If you are running the command line version built using the       Compaq (formerly Microsoft) compiler, i.e., DATAPLOT.EXE,       then use the following command:                   DEVICE 1 QWIN                If you do not see any text in the text window when you       initiate this command, then this means that your PC is       probably set to ""true color"" mode.  Add the ""-true"" option       when you invoke Dataplot.  For example,                  C:\DATAPLOT\DATAPLOT.EXE  -true  -large               This can be set either in the Properties menu of the       shortcut or in the ""DPCOMM.BAT"" batch file (DPCOMM.BAT is       used if Dataplot was not installed in the default       C:\DATAPLOT directory).               If you are running the graphical interface version, you do       not specify a DEVICE 1 command.  In the GUI, the screen graphics       are generated by the Tcl/Tk scripts.               The final case is if you are running the executable created with       the Lahey compiler (DPLAHEY.EXE).  This is the executable used       by the GUI.  The primary reason for running this executable       directly is to run Dataplot in a DOS mode.  This version does       not support any screen graphics.  Instead, enter the command                  DISCRETE               This generates line printer type graphics to the screen.       Alternatively, you can turn off the screen graphics       altogether by entering                  DEVICE 1 OFF                                           Other Platforms                          For non-Unix, non-Windows platforms, the available        alternatives are:                                                               DEVICE 1 REGIS                                                Use this if you are using some type of DEC VT terminal.                 This might be the case if you are running Dataplot                 on a Vax/VMS system.                                                                        DEVICE 1 HP 2622                   DEVICE 1 HP 2647                                                Use this if you are using an HP 2622 or HP 2647                 terminal.  Note that other HP terminals may be                 compatible with these.                                                                        DEVICE 1                    TEKTRONIX 4014                                                Use this if you are using a Tektronix 4014 terminal.                 Several other Tektronix models are supported as well.                                                                        DISCRETE                                                Use this if your screen does not support graphics                 or the type of graphics is not one of the available                 choices in Dataplot.                                                     Note that although Tektronix, Regis, and HP terminals are        increasingly rare, they still have some use as ""emmulator""        devices.  That is, communications software often provides        for some type of device emulation for graphics.  The        Tektronix, Regis, and HP terminals are the most commonly        emulated devices.                 If you are unable to generate screen graphics, this does not        prohibit you from generating high quality graphics to        DEVICE 2 and DEVICE 3.  That is, you can use the DISCRETE        command to obtain crude graphics to the screen while still        generating high quality Postscript output to file.                                                       DEVICE 2 Output                                    DEVICE 2 Off By Default                         DEVICE 2 is off by default.  When you initialize device       2 (e.g., DEVICE 2 POSTSCRIPT), all subsequent plots are       written to the file ""dppl1f.dat"" in the current directory       until you enter a DEVICE 2 OFF or a DEVICE 2 CLOSE command.       Note that there is a distinction between DEVICE 2 OFF and       DEVICE 2 CLOSE.  DEVICE 2 OFF suspends printing of graphics       to the ""dppl1f.dat"" file, but it does not close the file.       You can enter DEVICE 2 ON to resume printing the plots to       ""dppl1f.dat"".  DEVICE 2 CLOSE suspends printing, but it       additionally closes the file.  To resume printing, you       need to re-initialize the device (e.g., DEVICE 2 POSTSCRIPT).               In summary, DEVICE 2 ON/OFF is used to toggle whether or not       graphics are sent to a currently open ""dppl1f.dat"" file and       can be entered as many times as desired.  This can be useful       in an interactive session where you may want to pick and choose       which graphs will be saved for later printing.  On the other       hand, DEVICE 2 <device-name> is used to open the       ""dppl1f.dat"" file (this will overwrite any previous contents       of ""dppl1f.dat"") and intialize the device.  DEVICE 2 CLOSE can       then be used to close the ""dppl1f.dat"" file.  Closing the       ""dppl1f.dat"" is necessary if you want to print the ""dppl1f.dat""       file without exiting Dataplot.               Entering a DEVICE 2 <device-name> if the DEVICE 2 file       is already open can have unpredictable results.  For some       devices, the effect is benign.  However, for other devices       the subsequent output can be harmed.  In particular,       Postscript output will be messed up (this is because       Postscript performs certain intitialization code and entering       this code a second time results in harmful consequences).                                   Common Choices                         The most useful choices for DEVICE 2 are as follows.                                                          DEVICE 2                   POSTSCRIPT                    DEVICE 2                   POSTSCRIPT ENCAPSULATED                                             This generates Postscript output.  There is a                distinction between regular Postscript and                encapsulated Postscript.  Use regular Postscript                if you simply want to print your grapphics.  Use                encapsulated Postscript if you want to import                your graphics into another program such as Word                or Power Point.  For more discussion about importing                graphics into Word/Power Point, see the                 FAQS  entry.                                                                   DEVICE 2                   HPGL                    DEVICE 2                   HPGL LASER                                             HP-GL is the protocol used by HP penplotters.  If you                have a Laser Jet III, or higher model, that does not                support Postscript, you can use the built-in HP-GL                emulation that these printers provide.  There are a                few quirks in the HP-GL emulation in these printers.                Specifying DEVICE 2 HPGL LASER contains a few                modifications to the basic HPGL driver to account                for these quirks.  If you omit the LASER option,                the HPGL file will probably not print correctly on                these laser jet printers.                                                                   DEVICE 2                   GD PNG                    DEVICE 2                   GD JPEG                                             These drivers generate PNG (Portable Network                Graphics) and JPEG files.  These drivers may not                be available on all implementations of Dataplot                (they should be supported on most Unix platforms,                they are not available under Windows as of 8/2002).                PNG and JPEG are bit-mapped graphics formats that                are primarily useful for web applications.  Most                web browsers support these formats using the                HTML IMG tag.  They can also be useful for importing                graphics into other programs or as input formats                to image conversion programs.                                                                   DEVICE 2                   SVG                                             Scalable Vector Graphics (SVG) is an XML based                graphics format.  As XML becomes an increasingly                important standard for web development, it is                anticipated that SVG will also become an                increasingly important graphics format.  SVG is                intended primarily for web development.  However,                Adobe now provides a free stand alone viewer for                SVG format files.  In addition, many graphics editing                programs (e.g., Photoshop, Corel Draw) support, or are                adding support, for the importing of SVG format                graphics.  SVG is still not supported in                some of the major web browsers (as of 8/2002),                although this will probably change in the next                year or so.                                                Dataplot does not currently support dot matrix printers       or deskjet/inkjet style printers.  For these type of printers,       you may want to investigate the Ghostview/Ghostscript programs.       These ares freely available program that can display Postscript       files and print them on various common output devices.       Ghostscript is the engine that contains the Postscript       translator and Ghostview is the wrapper program that you       actually run to display and print the Postscript files.       The Dataplot ftp site contains a Windows version of Ghostview       and Ghostscript.  It is common for Ghostivew/Ghostscript to       be installed on Unix platforms.               The current versions of the Unix and Windows versions of       Ghostscript/Ghostview can be        downloaded from       the Web .                                                                      DEVICE 3 Output                                    DEVICE 3 Used to Store Most Recent Plot                         Dataplot uses DEVIVCE 3 to save the most recently       generated plot in the file ""dppl2f.dat"" in the current       directory.  Dataplot opens/closes the device in the       background when needed.  By default, Postscript output is       generated.  The  PP        command can be used to plot the DEVICE 3 output from within a       Dataplot session.                                   Non-Postscript Output                         If you do not want Postscript output, then enter the commands                  DEVICE 3 CLOSE            DEVICE 3 <device-name>                 to define the desired output format.  For example,                  DEVICE 3 CLOSE            DEVICE 3 HPGL LASER                 can be used if you have a LaserJet printer that supports       HP-GL emulation but not Postscript.                                   Printer Setup                         The PP command sends the ""dppl2f.dat"" file to the default       printer.               On Unix platforms, the PP command sends an ""lpr dppl2f.dat""       command to print the file.  To define the default printer,       enter the following c-shell command before initiating       Dataplot:                  setenv PRINTER <printer-id>               There is a comparable command for those who use the Bourne       shell.               Under Windows, the default is for the PP command to send       the plot to the local printer (i.e., PRN:) in Postscript       format.  This means that there are two issues to consider:                   If you want to send the graph to a network printer,              use the SET PRINTER command to define the name of              the printer:                                               SET PRINTER <printer-id>                                            You will have to ask your local system adminstrator              for the appropriate printer-id.  I recommend testing              this on a small ASCII test file independent of Dataplot              (i.e., in a DOS prompt window) before trying to use the              PP command.  That is:                                               COPY <file-name> <printer-id>                                            If this works, then the PP will likely work as well.              If this does not work, then do not use the PP command              within Dataplot.  As the network printer-id can be              rather cumbersome and hard to remember, I recommend              putting the SET PRINTER command in the               Dataplot start-up file .                          Dataplot supports a limited number of printer types              for Windows.  In addition to Postscript, it supports              HP-GL emulation for HP Laser Jet (Model III and              higher) and Laser Jet compatible printers.  To              utilize this format, enter the commands:                                               DEVICE 3 CLOSE                   DEVICE 3 HPGL LASER                                              Again, I recommend putting these commands in your               Dataplot start-up file .                             For other types of printers, you will have to go              through Ghostview.  One trick is to open Ghostview              concurrently with Dataplot.  When you want to print              the current graph, enter a DEVICE 3 CLOSE command              and read the current ""DPPL2F.DAT"" file into Ghostview              and print it from there.  You can also use a Windows              screen dump, but be aware that you will be getting              a ""screen mode"" level of resolution (also, I recommend              using a white background if you plan on using screen              dumps to prevent excessive toner usage).  The              ""File/Print"" menu on the command line version is              simply a screen dump (these menus are the default              compiler menus and they are not modified by Dataplot).                             Note that the ""Print"" button in the graphics window              of the Dataplot GUI is actually implementing a              Dataplot PP command.  Both of the issues above (i.e.,              accessing network printers, non-Postscript printers)              still apply in this case.                             The issue of printing under Windows will be given a              further look in the future.  Basically, properly              implementing printers in Dataplot requires going              to a full blown Windows application (as a technical              note, the command line version is built as a ""QuickWin""              application, the GUI utilizes a ""console"" application).              This involves basic design issues beyond just printing,              so this type of change will not happen quickly.  There              are other alternatives that we may consider as well.              For now, those with printers that do not support              either Postscript or HPGL emulation should consider              Ghostview to be the Dataplot printer.               If you want to turn off the DEVICE 3 output (e.g., you are       generating some complex graphs and want to minimize the drawing       time), do the following                  DEVICE 3 CLOSE           DEVICE 3 NULL                                                                Closing Devices                                    Selectively Saving Plots                         Sometimes when you are generating lots of plots interactively, you       may want to save a selective subset of these only.  You can do this       via                  DEVICE 2 POSTSCRIPT           <generate plots you want to save>           DEVICE 2 OFF           <generate plots you do not want to save>           DEVICE 2 ON           <generate plots you want to save>                Dataplot makes a distinction between turning a device on and off       and opening and closing the device.  When you enter DEVICE 2 OFF,       subsequent plots will not be written to DPPL1F.DAT.  However, the       file is not closed.  To resume writting the plots to this file,       enter DEVICE 2 ON.  When you enter DEVICE 2 CLOSE, this also       closes the file.  To reactivate the device, you enter       DEVICE 2 POSTSCRIPT (or whatever device is appropriate).  Note       that reactivating the device will overwrite the contents of       the DPPL1F.DAT file.  Turning the device on and off is the       proper technique if you are selectively saving plots.  Closing       (and re-opening) the device is the proper technique if you       want to perform some action on the file.  This action may       be to print DPPL1F.DAT or the copy the file to another name.       In any event, the desired action is usually performed with       the  SYSTEM  command.                                                                            Printing the Graphics File                                            Printing Graphics Under Unix                                 Printing the graphics files dppl1f.dat or dppl2f.dat is       performed in the standard way for your operating system.       For example, on Unix you would enter the Unix command                  lpr -P<printer id>  dppl1f.dat               If you are not sure how to print files on your operating system,       check with your local system administrator.               Under Unix, Dataplot can generate either Postscript       (DEVICE 2 POSTSCRIPT) or HPGL (DEVICE 2 HPGL LASER).  If you       have a non-supported printer (e.g., a DeskJet or InkJet type       printer), then investigate Ghostview/Ghostscript.  First, check       the Ghostview/Ghostscript documentation to see if your printer       is supported.  If so, then check to see if Ghostview/Ghostscript       is already installed on your system.  If not, you need to       download and install it (hopefully, your local system       administrator will be willing to help).               Note that in Unix, there is not a common ""graphics device""       interface for printers.  The protocol for a given printers       has to be explicitly supported.  For this reason, Postscript       is the preferred protocol for printers in the Unix world       and the list of supported printers in Ghostview may be       smaller in the Unix implementation than the Windows       implementation.  This is more likely to be an issue for       PC based Unix/Linux platforms than for workstation based       platforms.                                           Printing Graphics Under Windows                                 We will distinguish three classes of printers on Windows.                   Postscript printers           Laser printers that support HP-GL emulation           Other printers (e.g., Desk Jet, Ink Jet, and dot              matrix printers)               As discussed above, Dataplot maintains three graphics devices.       These can all be used simultaneously and independently and       are controlled by the DEVICE 1, DEVICE 2, and DEVICE 3 commands.       We will frame the following discussion in terms of DEVICE 2       since this is the one typically used for generating graphs       for the printer (the issues for DEVICE 3 are similar).                                   Window Printing - Postscript                         If you have a Postscript printer, then enter the command                     DEVICE 2 POSTSCRIPT               All subsequent plots will be written to       the file dppl1f.dat in the default directory.  If you initiate       Dataplot from a shortcut, then the default directory can be       set from the ""Properties"" menu (the ""Start-In"" directory).               You can print this file directly by entering the following       command from a DOS Prompt window:                     COPY DPPL1F.DAT PRN:               You may need to CD to the default directory or put the       full path name in for DPPL1F.DAT.  Windows is not case       sensitive for file names.               If your printer is a network rather than a local       printer, then replace PRN: with the network name for the       printer (this will be system dependent).               If you want to print the graphs from within the Dataplot       session, then enter the commands                  DEVICE 2 CLOSE            SYSTEM COPY DPPL1F.DAT PRN:            DEVICE 2 POSTSCRIPT                 For network printers, substitute the network printer id for       PRN: (see your local system administrator for the id).               If you prefer to avoid entering DOS commands, you can       alternatively read the DPPl1F.DAT file into Ghostview       (Ghostview is a freely downloadable program for displaying       and printing Postscript files).  Ghostview can print the       Postscript file on either Postscript or non-Postscript devices.                                   Windows Printing - HPGL Emulation                         If you have a printer that supports HP-GL emulation (i.e., most       HP Laser Jet and compatible printers), then enter the command                  DEVICE 2 HPGL LASER               Note that the ""LASER"" option is required for laser printers.       This adds some special codes that work around some quirks in       the HPGL emulation in the laser printers.               All subsequent plots will be written to       the file dppl1f.dat in the default directory.  If you initiate       Dataplot from a shortcut, then the default directory can be       set from the ""Properties"" menu (the ""Start-In"" directory).               You can print this file directly by entering the following       command from a DOS Prompt window:                     COPY DPPL1F.DAT PRN:               You may need to CD to the default directory or put the       full path name in for DPPL1F.DAT.  Windows is not case       sensitive for file names.               If your printer is a network rather than a local       printer, then replace PRN: with the network name for the       printer (this will be system dependent).               If you want to print the graphs from within the Dataplot       session, then enter the commands                  DEVICE 2 CLOSES            SYSTEM COPY DPPL1F.DAT PRN:            DEVICE 2 POSTSCRIPT                 For network printers, substitute the network printer id for       PRN: (see your local system administrator for the id).               Alternatively, you can read the file into NotePad (or WordPad)       and use the Print utilities from within these programs.                                   Window Printing - Unsupported Printers                         If you have a printer that supports neither Postscript or       HP-GL, then you should download the         Ghostscript/Ghostview  program.  Ghostscript is a freely       downloadable Postscript translator and Ghostview is a Windows       viewer built on top of Ghostscript that allows you to view       Postscript files on the screen and print them on most common PC       printers.  I keep a Windows copy of the Ghostview/Ghostscript       installation files on the Dataplot ftp site (to ensure that       you obtain the most recent versions, go to the Ghostview       web site).               Once you install Ghostscript/Ghostview, then in Dataplot       enter the command                  DEVICE 2 POSTSCRIPT               You can then import the dppl1f.dat file into Ghostview.       Ghostview allows you to print Posctscript files on most       common PC printers.               Dataplot does not support a standard Windows print menu       for graphics output.  Instead, Dataplot uses Ghostview as       its generic Windows printer.               Note that Ghostview provides the command GSPRINT.EXE which       can be used to print Dataplot graphs from within a Dataplot       session.  For example,                  DEVICE 2 POSTSCRIPT              ....   Generate on or more plots ...            DEVICE 2 CLOSE            SYSTEM  C:\GHOSTGUM\GHOSTVIEW\GSPRINT.EXE  DPPL1F.DAT            DEVICE 2 POSTSCRIPT                 This will print the graphs in DPPL1F.DAT on the default       Windows printer.               NOTE (11/2002): The PP command can be used to print the most       recently generated graph.  If you enter the command                  SET GHOSTSCRIPT PRINTER ON               Dataplot will use the GSPRINT command to generate the plot.       If your default printer is not Postscript, we recommend adding       this command to your ""dplogf.tex"" file.  GSPRINT should support       most Windows printers.                                                                      Incorporating Dataplot Graphics Into External Programs                                    Import Procedure in the External Program                         It is common to import Dataplot graphics into external       programs for the purposes of writing reports and giving       presentations.               To import graphics into Word/Excel/Power Point, there are       several points to consider.                   What is the procedure in Word/Excel/Power Point for              importing graphics?                             Word, Excel, and Power Point all utilize the same              procedure for importing graphics.  Mark your cursor where              you want the graph to be inserted and then do the              following:                                 select the ""Insert"" menu                  select the ""Picture"" menu                  select the ""From File"" option                  enter the name of the file containing the graph                                         What graphic formats do Word/Excel/Power Point support?                             The supported graphics formats include:                                 Windows metafile and Windows bitmap                  JPEG                  PNG (portable network graphics)                  GIF                  MacIntosh PICT                  PC Paintbrush                  CGM (computer graphics metafiles)                  FPX                  CorelDraw                  Kodak Photo CD                  Word Perfect Graphics                  TIFF                  Encapsulated Postscript                                            This list is subject to change as new versions of              Microsoft Office are released (and some formats may not              be installed by default).  The most common formats are              Windows bitmap/metafile, JPEG, PNG, GIF, and encapsulated              Postscript.               Other Office Software programs will have similar procedures.       However, the list of supported import formats may be different.       For these other software programs, you will need to check the       program documentation to determine the procedure for importing       external graphics and the list of supported import formats.                                   Dataplot Issues                         There are several issues for Dataplot graphics.                   The first issue is that each graph to be imported              should reside in a separate file.  There are several              ways to approach this.                                                You can generate each graph in a separate Dataplot                     session.  Although easy, this can be more time                     consuming than needed.                                        You can redefine the IPL1NA variable.  For                     example,                                                                    SET IPL1NA PLOT1.EPS                        DEVICE 2 POSTSCRIPT ENCAPSUALTED                          ORIENTATION LANDSCAPE WORDPERFECT                             ... generate plot ....                          DEVICE 2 CLOSE                        SET IPL1NA PLOT2.EPS                        DEVICE 2 POSTSCRIPT ENCAPSUALTED                          ORIENTATION LANDSCAPE WORDPERFECT                             ... generate plot ....                          DEVICE 2 CLOSE                                                                 Repeat the above sequence as often as needed.                                        Alternatively, you can use the SYSTEM command:                                                                    DEVICE 2 POSTSCRIPT ENCAPSUALTED                          ORIENTATION LANDSCAPE WORDPERFECT                             ... generate plot ....                          DEVICE 2 CLOSE                        SYSTEM COPY DPPL1F.DAT  PLOT1.EPS                        DEVICE 2 POSTSCRIPT ENCAPSUALTED                          ORIENTATION LANDSCAPE WORDPERFECT                             ... generate plot ....                          DEVICE 2 CLOSE                        SYSTEM COPY DPPL1F.DAT  PLOT2.EPS                                                                 Repeat the above sequence as often as needed.                                         The second issue is in deciding what is the best              graphics format to use with Dataplot.  My preference              is to use encapsulated Postscript whenever possible.              The primary advantage is quality (you maintain the high              resolution of the Postscript graph when printing and              you can utilize the typeset quality Postscript fonts).              Bitmap graphics are typically generated at screen              resolution.  The quality issue is typically more              important for written reports than for Power Point              style presentations (since the presentation is              shown on a computer monitor anyway, screen resolution              for the Dataplot graphics should be adequate).  Although              encapsulated Postscript does provide higher quality,              there are some special considerations when importing              encapsulated Postscript files.  These considerations              are discussed further below.                             In addition to Postscript, Dataplot can generate              PNG and JPEG bitmap graphics on most Unix platforms              (this is being ported to Windows, but is not available              as of 9/2002).  Dataplot can also generate HPGL              format graphics (this is the HP penplotter protocol).              PNG and JPEG are supported by most Windows Office              programs.  HPGL is supported in older versions of              Microsoft Office (support seems to have been dropped              at the Office 2000 release) and may be supported in              other Windows Office software.  Also, you may be              able to save screen dumps in an appropriate format              on some systems for some external programs.                             Another alternative is to generate either Postscript              or encapsulated Postscript and then use one of the              many image conversion programs (some are free, some              are commercial) to generate a bitmap format of your              choice.  Note that Postscript is a language rather              just a bit-map format, so many image conversion              programs do not support Postscript as input.  That is,              converting between bit-map formats is typically a              straightforward process. Converting Postscript is not.              Be sure to check carefully as many conversion programs              support Postscript as an output format, but not as              an import format.  Image conversion programs can also              be used to convert Dataplot PNG and JPEG files to other              bit-map formats.  Note that PNG and JPEG are likely              to be supported by a wide range of image conversion              programs.               NOTE (1/2003): Dataplot now supports an alternative method       for generating bitmapped graphics.  Specifically, it invokes       Ghostscript automatically to convert Postscript output to       one of:                   JPEG           PDF (Portable Document Format)           TIFF           PBM (Portable Bitmap, supports black and white only)           PGM (Portable Greymap, supports grey scale)           PPM (Portable Pixmap, supports color)           PNM (Portable Anymap, supports PBM, PGM, and PPM)               This capability is supported on Unix and Windows platforms.       Between Postscript and the above formats, it should be possible       to generate Dataplot graphis in a format acceptable to most       external programs (the JPEG and PBM formats are accepted by       most image conversion programs).  Enter the commmand       HELP POSTSCRIPT CONVERT for details.                                   Special Issues for Encapsulated Postscript Files                          Note that there are a number of special considerations        when importing encapsulated postscript files:                     There is a distinction between encapsulated postscript               and regular postscript.  Encapsulated postscript is a               special form of Postscript that is intended               specifically for importing postscript graphics into               another program.  When you are creating the               postscript graphic in your application software, you               need to be aware whether or not you are creating               regular or encapsulated Postscript.  If you know               that the graphic is intended for importing into               another program such as Word or Power Point, then               I recommend that you create it as an encapsulated               postscript file.  Note that an encapsulated postscript               file may print as a blank page on your printer.  This               is an intentional design feature, not a bug.                            Programs such as Word and Power Point handle               encapsulated Postscript files differently than they               do other graphics formats.  Typically, imported               graphics are first converted to a common internal               format.  However, encapsulated Postscript files               are typically not converted.  Instead, they are               simply ""passed on"" when the file is displayed or               printed.  The reason for this is that Postscript               is actually a full blown computer language, not just               a device protocol.  Unless the importing program               has licensed a Postscript interpreter (not               common for non-Adobe software), it will not be able               to translate Postscript.  Note that Adobe products               will typically translate imported Postscript graphs               correctly (this is reasonable since Postscript was               developed by Adobe).                            The above bullet has an important implication.               If the imported graphic is displayed on a               non-Postscript device, it will typically display               as an empty box (some programs will print a               sentence to the effect that ""a Postscript graph               goes here"").  This inability to display encapsulated               Postscript files can be addressed in several ways.                                                   For printed output, simply be sure to print on                      a Postscript printer.  Note that the application                      program (i.e., Word, Power Point) must know that                      you are printing on a Postscript printer.  Many                      printers support both a native mode format                      (e.g., PCL) and Postscript.  Word and Power Point                      (and most Windows applications) by default assume                      the native word format.  The solution is to                      install both the native mode version and the                      Postscript version of the printer.  Then be sure                      to select the Postscript version of the printer                      when you print a file containing imported                      encapsulated Postscript files.                                          To address this issue of non-Postscript devices,                      encapsulated Postscript allows for an optional                      ""bit-map preview"".  This is a bit map of the                      encapsulated Postscript graph that will be used                      to display on non-Postscript devices.  The                      bit-map preview is ignored on Postscript                      devices.  Even if your encapsulated Postscript                      contains a bit-map preview, I recommend                      printing to a Postscript printer when one is                      available (i.e., it is preferrable to print                      the original Postscript rather than the                      bit-map preview).                                          Bit-map previews are optional and Dataplot does                      not support it.  However, you can use                      the Windows version of Ghostview to create the                      bit-map preview.  That is, import the Dataplot                      encapsulated Postscript file into Ghostview,                      add a bit-map preview, save the file, and                      then import this saved file (which contains the                      bit-map preview) into your Word (or Power Point,                      etc.) program.  Note that you can only                      add a bit-map preview to an encapsulated                      Postscript file, not a regular Postscript file.                                          From within Dataplot, use the following commands                      to create the encapsulated Postscript file:                                                                       DEVICE 2 POSTSCRIPT ENCAPSULATED                           ORIENTATION LANDSCAPE WORDPERFECT                                                                      The order is important.  That is, initialize                      the device first, then set the orientation.                      This orientation sets a landscape orientation                      on a portrait page.  If you use this                      orientation, you should not have to rotate or                      scale the graph once you import it (you will                      have to rotate and scale if you use the default                      landscape orientation).                                               Given the above, it is reasonable to ask ""why bother               with importing Postscript?"".  The reason is image               quality.  Most of the other import formats are               essentially bit maps that are generally created               at ""screen"" resolution (typically 72 dots per inch).               Postscript graphics are generally created at much               higher resolution (300, 600, or 1200 dots per inch               is typical).  This can result in much sharper               looking graphs in printed documents.                                                           Date created: 6/5/2001        Last updated: 9/16/2002        Please email comments on this WWW page to        sedwww@cam.nist.gov .                                                          [  Dataplot  ]"
GX245-93-1024892	"Louisiana                    State Census Data Center                                                                 Census 2000 Redistricting Files Documentation   README File for Census 2000 Redistricting Files Delivered via FTP    Note:  Users processing these FTP files in a Windows environment should read carefully the File   Information section of this document.     About the FTP Application   This FTP (File Transfer Protocol) application is intended for experienced users of census data,    compressed files, and spreadsheet/database software. It provides quick access to data users, such as   State Data Centers and news media, who need to begin their analysis immediately upon data release.   Due to the size of the files, the FTP user should have a fast file transfer capability. Each state   directory provides all files available for the identified state. Once uncompressed, the data are   in a flat ASCII format.  The geographic file is in a fixed-field format; the two data files are in   comma delimited format. No software is provided. Users of the FTP application need to unzip the   compressed file after downloading, then import it into the spreadsheet/database software of their   choice for data analysis and table presentation.   Other Sources of the Data   The Census Bureau releases most Census 2000 data on a state-by-state basis. Tables are available in   American FactFinder (factfinder.census.gov) upon release of the designated state file. Within American   FactFinder, individual tables can be downloaded in a text delimited or comma delimited format.     For users without immediate need for the data, CD-ROMs containing the data and access software are   scheduled for shipping shortly after the state file release.  They can be ordered from the Census   Bureau's Customer Services Center at 301-457-4100.     FTP Directory   The FTP directory is at http://www2.census.gov/census_2000/datasets/ .  When the Census 2000   redistricting data are added to their respective directories, each state directory has three data  files, reflecting the three data segments.  See below for more information on the data segments.          File Information   Once uncompressed, these files are in flat ASCII format. The geographic header file (see below) contains   fixed fields while the data files (File01 and File02, see below), including the geographic link fields,   are in comma-delimited format.  These files have been constructed in a UNIX environment. They use an   ASCII linefeed, chr(10), to indicate a new record.   For successful use with many programs running in a Windows environment, these files need to be modified   to use the ASCII carriage return/linefeed sequence, chr(13) + chr(10) as a record terminator. This is an  easy step in the UnZIP process using any UnZIP software which offers the conversion option.  We tested   PKZIP for Windows, version 4.00 following the steps outlined below.  This PKZIP shareware can be   downloaded from www.pkware.com.     After installing PKZIP, do the following:    --Select the file     --Select the Extract option on the tool bar    --Select the options button at the bottom of the Extract page     --Under the Miscellaneous section, select the ""DOS - convert to CR/LF""    The resulting file will meet the ANSI MS-DOS/Windows standard used by Access 97 and other   MS Windows-based programs.  If the data are being processed in a UNIX environment, they can   be unzipped using any standard  ZIP/UnZIP package.   These FTP data are available as compressed files at the 90% (approximately) file compression ratio.   We estimate that an average state FTP download (at 56K bps) of the redistricting data will take   approximately 2 hours. Larger states, of course, will take longer. Our estimate for an FTP download   for California is approximately 8 hours at the 56K bps speed.  If you are using a modem/telephone line   link to the Internet, we do not recommend using the FTP option.   Segmented Data    The data in the redistricting files and other Census 2000 summary files are segmented. This is done   so that individual files will not have more than 255 fields, facilitating exporting into spreadsheet   or database software. In short, to get the complete data set for the redistricting files, users   must FTP all three files in the state directory.      These test files contain:    Geographic Header file   File01 (Tables 1 and 2)   File02 (Tables 3 and 4)   It is easiest to think of the file set as a logical file.  However, this logical file consists of three   physical files:   the geographic header file  file01  file02   This structure is a change from previous decennial census files.       The explanation below for linking the three redistricting test files requires specific location information   for the geographic header.  These are located in Chapter 7 of the Technical Documentation   http://www.census.gov/prod/www/abs/pl94-171.pdf  .  A unique logical record number  (LOGRECNO in the geographic header) is assigned to all files for a specific geographic entity;   all records for that entity can be linked together   across files.  Additional identifying fields are also carried over from the geographic header file   to the table files.  These are file identification (FILEID), state/U.S. abbreviation (STUSAB),   characteristic iteration (CHARITER), characteristic iteration file sequence number (CIFSN).     The geographic header record layout is identical across all electronic data products from Census 2000.    Since the redistricting data files are quite simple, some of the fields, including some geographic header  fields that appear in all three files (geographic header, tables 1/2, and tables 3/4) are not used.  For example, the character iteration (CHARITER) field is only used in SF2/SF4.  In the redistricting   data file, it is always coded as 000.   File Record Layout   For a layout of the individual tables for each file, see http://www.census.gov/prod/www/abs/pl94-171.pdf  .    Select Chapter 6, Summary Table Outlines.    Estimated File Sizes    State  Geo file  File 1        File 2    unzipped  zipped unzipped  zipped unzipped  zipped    Louisiana 71M   5M  56M    2M  56M   2M"
GX251-92-2522976	"DHS Webmasters' handbook   Text-only print version     Table of contents    1.  An overview    -  Site goals   2.  Accessibility  -  Accessibility links   3.  FAQ    4.  Library  -  Miscellaneous resources and reference material  -  Internet development  -  Intranet development   5.  Links and resources     Accessibility     Favorite examples of good design     Government sites with good design     Graphics for the web     Search     Style     Technical tips :     -  CSS     -  HTML     -  JavaScript     -  XML    6.  Setting up your site: file structure   Migrating files    7.  Templates     Customizing navigation template    Customizing content templates    8.  Tools & tips     Code snippets (redirects, date)     Image libraries     Metadata samples   Optimizing graphics for the Web  See also the DHS policy regarding  Web Architecture and Design Standards  (www.dhs.state.or.us/policy/admin/is/070_012.htm)    1. An overview   This handbook is for DHS Webmasters. It assumes that you know basic HTML and   are using the DHS OIS standard software application, Macromedia Dreamweaver, for creating Web pages.    If you do not have this application, you should talk to your manager about   getting it. You may also need some training to use it effectively. An excellent   tutorial comes with the software package. There are also Dreamweaver classes   available in house through DAS ( HRSD  at   www.hr.das.state.or.us/hrsd/trod/training.htm and  IRMD's   STEPS  (training.das.state.or.us/), and outside the agency through  New   Horizons  (www.newhorizons.com/retail/)and  Chemeketa   Online  (bbs.chemeketa.edu/).    The DHS Web leaders, under the direction of Dan Postrel, Communication   Administrator, are:       Mike Cooksey ( email       Mike , mike.d.cooksey@state.or.us) -  Technology infrastructure     Ed Kramer ( email Ed , ed.kramer@state.or.us) -  Content     Julee Syverson ( email   Julee , julee.syverson@state.or.us) -  Design and development       Our server administrator at CRM is Gary Barr ( email     Gary , gary.e.barr@state.or.us).    The DHS Web site is organized by topic instead of by division or program.   Each topic area has an ""owner,"" or a primary Webmaster, who has overall   responsibility for the topic area. The primary Webmasters for each cluster   is:       Pam Rouske (email  Pam,  pam.g.rouske@state.or.us)      - Administrative Services     Theresa Norman ( email         Theresa , theresa.norman@state.or.us)  - Children, Adults & Famililes,         CAF Field, Finance & Policy Analysis     Julee Syverson ( email         Julee , julee.syverson@state.or.us)  - Director's Office     Rocke Klockner ( email         Rocke , rocke.p.klockner@state.or.us)  - Health Services     Becki Trachsel ( email         Becki , becki.b.trachsel@state.or.us)  - Seniors & People with Disabilities                          ""If each Agency site looks and feels different from every other one and is organised uniquely, the customer faces a confusing and frustrating hunt for information. No matter how good any individual site may be, if there is no consistency or coherence among the multitude of sites the customer must search, the overall effect is one of complexity and confusion."" -             The IBM Global Services Report, 2001                     Site goals for Web developers   You will help your program or cluster by presenting timely and accurate information   on your site, and you will help the department by keeping your pages consistent   in appearance and function with the rest of the site. We want the DHS site   to be clean, uncluttered and standardized in appearance. Remember, your pages   on the site are a reflection of the agency as a whole, not just your program.    Our goal as DHS Webmasters is to create pages that express professionalism   and consistency in the use of  design elements ,  page   layout ,  navigation and function , and  file   maintenance .     First goal: Professionalism and consistency     in the use of design elements    We have designed a series of  graphic     elements  (www.dhs.state.or.us/web/library/elements.html) that tie     in with our design that you are welcome to use on your pages. We define ""design     elements"" as     headers, bars, bullets, and other graphics ready for you to use on your Web     pages. The Web developers' library includes     graphic text buttons such as ""PDF,"" ""Word"" etc. (Let     us know if you need other such buttons and we will make them for you.) We     also have provided a series of  headers   (www.dhs.state.or.us/web/library/headers.html)     to title your pages.    Use design elements consistently and intelligently, not just to ""decorate"" your   page. Use them only if they serve the content; in other words, they make your   material easier to find or your message easier to comprehend.     Use design elements sparingly. Don't clutter your pages with unnecessary   art. Use art only if it enhances your navigation or illustrates your message   in a professional manner. Avoid low-quality clip art and cartoons, jokes, animated   gifs, non-standard fonts, flashing or scrolling text or other Web clichés.      Second goal: Professionalism and consistency     in page layout    Use the Dreamweaver templates we've provided, located at the root directory   of our site in the /Templates/ directory. The templates refer to a Cascading   Style Sheet (CSS), located at the root in the /style/ folder. We want the DHS   site to look integrated, well structured and uniform; we don't want the user   to think he/she has left the DHS site at any point. (This standardization in   look-and-feel does not include Web applications at this time. OIS may adopt   look-and-feel and application function standards in the near future.)     Third goal: Professionalism and consistency     in navigation and function    The function of various buttons and navigation elements should look and act   the same on every page. Every page, for example, has:   Breadcrumbs .  This is Web slang for the navigation string   that resides below the header and above the body copy. Breadcrumbs lead users   page by page back to the DHS home page.     Headers and footers.  Every page is contained by a header and   footer.   The header identifies Oregon DHS; some also include the section title of the   page. The footer has your address and contact information.     Structure.  Your navigation should be well defined and logical,   so your content is easy to locate. If you are having problems structuring your   site, contact the Communication Office   for help.     Fourth goal: Professionalism and consistency     in file maintenance    You probably won't be the only one using your folders or updating your pages.   Make your HTML code clean and easy to maintain and your file structure streamlined   and logical. Don't add unnecessary functions or coding to your pages. We want   all the pages of the site to look and act the same (please email any requests   for exceptions to  Mike Cooksey ,   mike.d.cooksey@state.or.us).     2. Accessibility       ""The power of the Web is in its universality.         Access by everyone regardless of disability is an essential aspect.""      - Tim Berners-Lee, W3C Director and inventor of the World Wide Web      Web accessibility is an important goal for our department. We need   do everything possible to make the site accessible to those who have disabilities.   Our template has been tested with the JAWS screen reader.   Using header tags.  Header tags not   only format your text for easy readability on the screen, but they also establish   an outline   of your information that enables screen readers such as JAWS to build   an accurate table of contents for blind users. You should therefore use your  <h1>  through <h6> tags   not just to size your text, but to structure your information in a logical   way. Our CSS (cascading style sheet) already has the formatting for this structure   in place for you. The text on your pages will be well organized and consistent   as long as you use the   <h1>  through  <h6>  tags   instead of absolute values for your text sizes and styles (an example of an   absolute value is the HTML tag  <font   size=""4""> ; a relative   value is the HTML tag  <font size=""+1""> ).   Problems with spacing.  Many of us work   around the layout limitations of HTML by using transparent *. gifs as ""spacers""   to design the placement images and text on our pages. Using spacers, however,   can make it tedious for   people   with   screen readers,  as most readers read each  <img   src>  tag aloud.   To get around this recital of unnecessary information, make sure your alt   tag   for   spacers is   set for  <alt=""""> .   This is the only way to make most screen readers skip the spacer entirely   and move on to more illuminating content.      Using alt tags.  Make sure you use alt   tags to identify all important photos and graphics.      Alt tags for photos.  Use a short sentence or two to describe the photos,   similar to what you would find  under a newspaper photo caption.     Alt tags for data.  Describe the outcomes or results of your data     charts as clearly as possible. For complex material, it would be a good idea     to have     the researcher     who provided   the material write a short narrative description for you to use in the alt   tag. For complex data, you may have to use the  longdesc  (www.w3.org/TR/REC-html40/struct/objects.html#adef-longdesc-IMG)   attribute.       Alt tags for illustrations.  Use your best judgment when deciding what   to describe and what to leave off. For example, if you are using an illustration   with your content that is primarily for decorative purposes, don't describe   it if it will mean very little to your blind user. Instead, code your alt tag   as follows:  <alt=""""> .     Alt tags for graphic elements.  Don't use descriptive alt tags for   graphic elements like bars, bullets, borders, or transparent gifs that aren't   necessary   to the flow of the content. Don't leave the alt tags out, either, as some screen   readers will say something like ""unidentified graphic element"" every   time they hit  <img src=>  on   your Web page that doesn't have an alt tag. Instead, code your alt tag with   double quotation marks  <alt="""">.  This   attribute makes most screen readers skip over the graphic entirely.   Blockquotes.  Try to avoid using blockquotes   or indentations to control indention. Both are common workarounds   used by   Web   page builders to format text and create attractive page layouts; however, accessibility   software may interpret and deliver information a certain way because of   the   tag. In the case of a blockquote, traditionally used to cite sources   and quotations, a text-to-voice reader might interpret the information   as a quote and read it accordingly when, in fact, you were just trying to indent a paragraph.     Text sizing.  Don't use absolute values   to format text for your various titles, subtitles or body text. (An example   of an absolute font tag is:  <font size=""5"">. )   Use relative tags instead. For example, use ""default"" for   your text size setting, so folks who have their browsers set to a larger pitch   font because   of sight disabilities will see your body text at a size better suited for their   needs. When you want your text to be larger or smaller than your body text   for emphasis   or other reasons, but don't want to use header tags, use relative   formatting like  <font   size=""+1"">  or  <font   size=""-1""> .   Difficult elements for screen readers.  You   need to provide alternative content if you're creating pages with certain elements   that are   hard for screen   readers to read. Examples are detailed maps, complex graphics, frames (which   we don't use in our current design), and older PDFs (Adobe's Portable Document   Format). If you are including PDFs on your site, try to use ones that have   been produced in Acrobat 5.0, which has many accessibility features lacking   in earlier   versions. A booklet on making accessible PDFs is available on the  Adobe   accessibility site  (access.adobe.com).    For accessibility reasons, don't use any form of scripting to produce content   that may appear or disappear based on the user's actions, unless you provide   a text-only version on the same page. For example, drop-down menu items coded   in Javascript on an HTML page will not read with a JAWS screen reader, leaving   the blind user unable to navigate further. You would need to recreate the navigation   in straight HTML somewhere else on the page so your users could proceed.   A rule of thumb to see if your page is accessible is to read through your   code from top to bottom; that's the way a screen reader will read your page   to a blind user. By reading it through yourself, you may find images, image   maps and other information out of sequence and missing alt tags. By repairing   and checking   your pages carefully before posting them, you will make your site more accessible   even if you don't have access to a screen reader to test them on. (Note: OIS   has JAWS set up on a testing station available to you in the Technology   and Strategy group, HSB 5th floor. Bring your own headphones).    Ten quick tips to make Web sites accessible  (from     the World Wide Web Consortium)     1. Images & animations.  Use the alt attribute to describe the   function of each visual.   2. Image maps.  Use a client-side map and     text for hotspots.      3. Multimedia.  Provide captioning and transcripts of audio, and descriptions   of video.      4. Hypertext links.  Use text that makes sense when read out of context.   For example, avoid ""click here."" Some of your users may not be using   a mouse.     5. Page organization.  Use headings, lists, and consistent structure.   Use CSS for layout and style where possible.      6. Graphs & charts.  Summarize or use the  longdesc  (www.w3.org/TR/REC-html40/struct/objects.html#adef-longdesc-IMG) attribute.      7. Scripts, applets, & plug-ins.  Provide alternative content in   case active features are inaccessible or unsupported.      8. Frames.  Use the noframes element and meaningful titles.      9. Tables.  Make line-by-line reading sensible. Summarize.      10. Check your work.  Validate. Use the  W3c   guidelines  (www.w3.org/TR/WCAG) to find out more about Web accessibility     © W3C (MIT, INRIA, Keio) 2001/01. For complete guidelines & an     electronic copy of this checklist, see the  Web     Accessibility Initiative  (www.w3.org/WAI).      Accessibility links         The Access Board    www.access-board.gov/indexes/technicalindex.htm         Accessible.org      accessible.org         ADA Accessibility Requirements    www.skally.net/ada.html       American Council for     the Blind  www.acb.org/accessible-formats.html     Blindness Resource Center      www.nyise.org/speech/access.htm      Center   for Applied Special Technology  (CAST)    www.cast.org         CNET     Builder.com: Accessibility    builder.cnet.com/webbuilding/pages/Authoring/Accessibility/ss01.html         HTML Writers Guild's AWARE  (Accessible Web Authoring Resources and Education)   Center    aware.hwg.org         Information about Section 508 from Government Computer News    www.gcn.com/sect508/         Information Technology     and Technical Assistance Training Center  (ITTATC), Center for Assistive     Technology and Environmental Access, Georgia Institute of Technology      www.ittatc.org/laws/stateLawAtGlance.cfm   International Center     for Disability Resources      www.icdri.org/             National Federation of the Blind:         Web Accessibility      www.nfb.org/tech/webacc.htm             Royal National Institute         of the Blind  (UK)      www.rnib.org.uk/digital/hints.htm              Section 508  www.section508.gov       Sitepoint.com             article ""Design & Layout:         Accessibility""      www.sitepoint.com/subcat/83             Viewable with Any         Browser Campaign: Web Accessibility      www.anybrowser.org/campaign/abdesign.html             Webable Solutions      www.webable.com               World Wide Web Consortium References on Web Accessibility      www.w3.org/WAI/References/             World Wide Web Consortium Web       Content Accessibility Guidelines      www.w3.org/TR/WAI-WEBCONTENT/       Note:   To see more articles and reports on accessibility, check the   Civic Resource Group research site  (www.civicresource.com/briefs/briefs_accessibility.html)       3. Frequently asked questions   06/26/03  Q:  What is the DHS policy for Web site design and development?   A: The policy is on the DHS Web site at  www.dhs.state.or.us/policy/admin/is/070_012.htm .   05/13/03    Q:  What is the difference between XML and HTML, and will we need to be XML-compliant   on the DHS Web site?      A: Yes, we will need to consider XML compliance in the future. Dreamweaver   already has a built-in ""convert to XML""   function under the ""File"" menu. For more details, see the  information     about XML  the Communication Office and OIS T&S  have been compiling.     04/23/03         Q:  I just upgraded        from Dreamweaver 4 to MX, and the MX interface is very different.        I'd like it to look more like Dreamweaver 4 until I'm used to MX. Is there        a way to do this?    A: Yes; Under the preferences         menu in Dreamweaver, pick General, then click the ""Change Workspace"" button.         This will take you to a menu page with screen shots of each interface. Pick the ""Dreamweaver 4 workspace."" You can always change it back later by going back to this menu and choosing ""Dreamweaver MX workspace.""                 03/25/03               Q:  Awhile ago, we were told             the OIS T&S lab was getting JAWS in order to test our Web pages             for accessibility on screen readers. Is that testing station available             yet?            A: OIS has JAWS set up on a testing     station available to you in the Technology and Strategy group, HSB 5th floor.     Both Internet Explorer and Netscape Navigation are loaded on this machine,     labeled ""JAWS."" Please bring your own headphones.    01/15/03              Q:  My pages look different           in the Netscape 7 than they do in Internet Explorer 6,           especially the navigation tables, which seem to have black borders       in some of the face icon cells. How do I fix this?   A: Check the first         line of your source code, the  <doctype>  tag.         If it is in lower-case letters, that's the problem, because this format         causes table cell errors. Please reformat the sentence as follows:        <!DOCTYPE HTML PUBLIC ""-//W3C//DTD           HTML 4.0 Transitional//EN"" ""http://www.w3.org/TR/html4/loose.dtd"">         Another problem might be that this   <doctype>  tag has         drifted to line 2 of your page, instead of the very first line. If you         copy the text above and make         sure it's on line 1, your table cell errors should disappear.   12/19/02          Q:  How do I add or correct             links to the indexes of site-wide index pages like ""data,"" ""training"" or ""publications""?        A:  Contact the Webmaster in       charge of that folder and send your new links or revisions to them.    Data:  send links to the Communication Office         Publications:  send links to the Communication Office         Training:  send links to Susan Blanche-Kappler      Send your input via email, and make sure to include the URL of your link.       Example:                   Please add the  Community Guide to Assisted Living Handbook  (www.dhs.state.or.us/seniors/publications/assisted.pdf)           to the Publications page under the topic ""Seniors"" and also under the           topic ""People           with Disabilities.""                 You may have publications that should be cross-reference on both the         data and publications index pages. In that case, note that          with         your request.                10/25/02           Q:  Where do              I get graphics like colored bullets, rules, and buttons?                  A:  Look in the Web developers' library library          for a page of  graphic          elements           (located at www.dhs.state.or.us//web/library/elements.html) that         have already been designed for the site. We've made buttons, bullets,         dividers, topic bars, and         arrows. Choose the color         and type         of bullet         or button from the /images/ directory at the root level that suits your       needs. If you need other graphics, contact the Communication Office.         Note regarding text buttons like ""MORE"" and ""PDF"" buttons:         to keep them from floating above the baseline of your text and causing         problems                  with line spacing, use the following indication in your  <img       src>  code:           align=""absbottom""         For example, the whole string of code for your ""more"" button          should be:           <img src=""/images/buttons/button_more.gif""            width=""46"" height=""15"" align=""absbottom""            border=""0"" alt=""more"">          10/22/02           Q:  I'm confused;         when do I use a navigation template and when do I use a content template?          A: The navigation template has          navigation buttons on the left side, and are for pages that need extra                  levels  for searching deeper into the particular content         of the page. An example would be a  the home page         for  Human           Resources  (www.dhs.state.or.us/admin/hr/). Another page that           should have the navigation template are pages at a level high enough           that           the user           would benefit           by having navigation        at hand to other high level areas.              The content templates are for content pages, those at the lower levels         of the site structure. You could think of them as source or ""target""         pages. An         example          would be a  news release          (sample at www.dhs.state.or.us/news/2003news/2003-0428.html). There          may be links up through the navigation or outside the site from the         news         release, but it is         at the lowest level of the content navigation string.         09/23/02           Q:  What do I put for the Webmaster contact information in the footer of my Web pages?     A: The generic language for the          footer found on the main template is as follows:          If you have questions about DHS, problems getting DHS services, or            comments about this site, email us:  DHS            Information . DHS Groupwise users, address email to dhs.info@state.or.us            The email address dhs.info@state.or.us sends messages to the Governor's        Advocacy Office, who will forward the Web-related enquiries for the       main site on to the Communication Office. However, for your Web pages         comments about your site should be directed to you. You could edit the   generic paragraph as follows:                       If you have questions about DHS or problems getting DHS services,            email us:  DHS Information .            DHS Groupwise users, address email to dhs.info@state.or.us            If you have comments about this site, email us:  Webmaster .           DHS Groupwise users, address email to (your email account name)@state.or.us          For the Webmaster link, we recommend getting a Groupwise account specific        to your Web site (for example, ""contracts.web@state.or.us"") instead        of using your individual state address. This way, your privacy is protected        since your name is no longer associated with the site, and if your job duties        include someone else at some point, the privileges to read and write to        the Web Groupwise account can be shared. Get this account by contacting        the DHS help desk.         Note:  The size of the footer text is  <h6>.                      09/23/02           Q:  What do         I  put in the four subfolders in my directory titled ""data,"" ""publications,""          ""images"" and ""archive?"" I noticed there are four         folders  at the root level named the same.          A: You put statistics, surveys          and other data in your ""data"" folder. Publications like online          brochures, newsletters and handbooks go in your ""publications""          folder. All graphics (JPEGs and GIFs) go in your ""images"" folder.          You put last year's newsletters, old surveys and old HTML pages in the          ""archives"" folder. The criteria you use to determine whether         to throw out material or archive it is this: if you think it would be         useful for research, historical record or analysis, keep it. If the information         is wrong or outdated, discard it.         You put your own statistics, pubs, graphics, and older material in your          own ""data,"" ""publications,"" ""images"" and          ""archive"" folders. The ones at the root-level are for department-wide          items. For example, our DHS annual report would go in the publications          folder at the root level.         09/12/02           Q:  Now that          I have a unix account as a DHS Webmaster, what are my next steps to         migrate to the new Web site?           A: If you haven't already, talk          to your  content editor  (see         the roster at www.dhs.state.or.us/web/content/roster.html) and         go over your site inventory together. Between the two of you, decide         which         content from your existing site is ready to move over to the new site          and where it should go. You'll be coming up with a navigation structure                  together as well. You'll turn this information into your navigation links          in the right-hand table on the template.                 You will also          need to set up your access to the new site via Dreamweaver. More         discussion on this is in the previous FAQ.         You will need to use the master templates to  make           your own topic template         in Dreamweaver next.        Finally,  migrate  your old pages         and put them into the new template you've created.                 09/10/02           Q:  In Dreamweaver,          how do I set up access to the new site?                   A: First, contact the Communication Office,          who administers the  DHS          Webmaster permission list  (Microsoft Word file at www.dhs.state.or.us/web/library/permissions.doc)          and maintains the site  file          structure  (Microsoft Word file at www.dhs.state.or.us/web/library/file_structure.doc).          They will contact CRM, who host our site, and ask you to send CRM your          RACF ID and a password.                After CRMreceives the notification from         the Communication Office and the RACF ID and password from you, they         will email you that your account has been established.                 After you've received CRM's confirmation, open Dreamweaver, and from         the ""Site"" menu,         pick ""New          Site"". The most important screens are the first two, local site          setup  (the working version of the site on your hard drive), and remote          site          setup (where you set up FTP access and use your new login and password).          Note: The remote site folder is /project/dhs/                  4. Library   Miscellaneous resources and reference material   Links   Site file structure  (Microsoft   Word file)  (www.dhs.state.or.us/web/library/file_structure.doc)   Web content committee list    (www.dhs.state.or.us/web/content/roster.html)   Webmaster staff list  (www.dhs.state.or.us/web/library/webmasters.html)   Web site access permission list  (Microsoft Word file)  (www.dhs.state.or.us/web/library/permissions.doc)   Internet development   DHS logos   (www.dhs.state.or.us/images/logo/)   Graphic elements  (www.dhs.state.or.us/web/library/elements.html)  Headers      (www.dhs.state.or.us/web/library/headers.html)  Navigation icons - faces      (www.dhs.state.or.us/web/library/faces.html)  Templates: navigation          (www.dhs.state.or.us/web/library/templatenavigation.html)   Templates: content-1                (www.dhs.state.or.us/web/library/templatecontent1.html)      Templates: content-2          (www.dhs.state.or.us/web/library/templatecontent2.html)         Intranet development   DHS logos   (www.dhs.state.or.us/images/logo/)   Graphics elements & navigation     icons      (intranet.dhs.state.or.us/dev/inelements.html)   Headers        (intranet.dhs.state.or.us/dev/inheaders.html)    Templates: navigation                (intranet.dhs.state.or.us/dev/intemplate_nav.html)   Templates: content-1            (intranet.dhs.state.or.us/dev/intemplate_content1.html)   Templates: content-2              (intranet.dhs.state.or.us/dev/intemplate_content2.html)           Templates: content-3              (intranet.dhs.state.or.us/dev/intemplate_content3.html)                          5. Links and resources   Accessibility   (See   links under ""Accessibility""  above )   Favorite examples of good design   - Interesting interfaces       New Yorker online      (www.newyorker.com/)        Ray of light productions  (PC only)    (www.rayoflight.net/)       7rings.com      (www.7rings.com/)        Slate magazine      (slate.msn.com/)        - Good advice       Web Pages that Suck      (www.webpagesthatsuck.com/)      Molly.com     www.molly.com/articles/webdesign/webdesign.php)     Government sites with good design       Human Services Inc.      (www.humanservicesinc.org/)        Maui, Hawaii      (www.co.maui.hi.us/)        My Florida      (www.myflorida.com/portal/Government)        New York State Dept.       of Health        (www.health.state.ny.us/home.html)        State of       California portal        (www.state.ca.us/state/portal/myca_homepage.jsp)        Texas Dept. of Human Services      (www.dhs.state.tx.us/)        US Dept. of Health & Human Services      (www.os.dhhs.gov/)        Washington State Dept. of Health      (www.doh.wa.gov/)        Graphics for the web       Internet.com's       Optimizing Web Graphics    (webreference.com/dev/graphics/photoshop.html)       JPG FAQ      (www.faqs.org/faqs/jpeg-faq/)        Lynda Weinman's Browser-friendly       Palette      (www.lynda.com/hex.html)       NCSA's       Image Map Tutorial  (National Center for Supercomputing Applications)        (hoohoo.ncsa.uiuc.edu/docs/tutorials/imagemapping.html)        Portable Network Graphic (PNG)       Format        (www.libpng.org/pub/png/)      Scalable Vector Graphics (SVG) Format      (http://www.adobe.com/svg/main.html)        WDG (Web Design Group)       Use of ALT Tags in Images        (www.htmlhelp.com/feature/art3.htm)        World Wide Web Consortium PNG       Specification        (www.w3.org/Graphics/PNG/)      World Wide Web Consortium SVG Specifications    (www.w3.org/Graphics/SVG/Overview.htm8)     Optimizing graphics for the Web   See  optimizing graphics links  in  Tools       & tips  section at end of handbook   Search tips       Search tips from Google    (http://www.google.com/help/refinesearch.html)     Advanced search tips from Yahoo    (http://help.yahoo.com/help/us/ysearch/basics/basics-08.html)     Style guides       Jack Lynch's       Guide to Grammar and Style        (www.andromeda.rutgers.edu/~jlynch/Writing/)          Usability: Jakob Nielsen      (www.useit.com/)       What you need to know about...Web       Design        (webdesign.about.com/)        - Corporations       IBM Web       Design Guidelines        (www-3.ibm.com/ibm/easy/eou_ext.nsf/Publish/572)        Internet2 Company Style       Guide        (www.internet2.edu/styleguide/)     Tyson Foods Graphics       Standard and Logo Guide        (www.tyson.com/logoguide/manual.asp)        - Academia       Arizona State University       Graphics Standards Manual        (www.asu.edu/ia/webdevelopment/gsm/)        Creighton University       Graphics Standards Manual        (www.creighton.edu/PubRel/gfxstd/index.html)        Memorial University of       Newfoundland        (www.mun.ca/univrel/g-main.html)        Rochester Institute       of Technology Library: Corporate Identify    (wally.rit.edu/pubs/guides/corpid.html)       San Francisco       State University Graphics Standards Manual    (www.sfsu.edu/~puboff/standards/welcome.htm)       University of Connecticut       Graphics Standards Manual        (www.logo.uconn.edu/grphstnd.htm)        University of Missouri Graphics       Standards and Style Guide        (www.umkc.edu/ucomm/standards/)        University of Texas Health       Sciences Center Graphics & Editorial Standards        (www.uth.tmc.edu/graphicguide/)        - Government       Access Washington style       guide        (www.wa.gov/dis/tools/awstyleguide/)     Queensland Web Centre      (www.qld.gov.au/web/cue/overview/)        Texas       Parks & Wildlife        (www.tpwd.state.tx.us/admin/policies/styleguide/)        - Publishers       Wiley Publishers Corporate       Identity Manual        (www.wiley.co.uk/about/corpident/)        Yale Web Style Guide      (www.info.med.yale.edu/caim/manual/)     Technical tips:   Builder.com    (builder.com.com/)      Computing terminology        (foldoc.doc.ic.ac.uk/foldoc/)        Dictionaries      (www.dictionary.com/)        Internet.com      (www.internet.com/home-d.html)        Internet FAQ Consortium      (www.faqs.org/)        Internet terms      (www.matisse.net/files/glossary.html)        Lynda Weinman      (www.lynda.com/)        Microsoft Internet Explorer Home Page      (www.microsoft.com/)        NetLingo: the Internet Dictionary      (www.netlingo.com/)        Netscape Home Page      (www.netscape.com)        Search     Engine Watch      (searchenginewatch.com/)        SitePoint      (www.sitepoint.com/)        Tom Boutell's FAQs      (www.boutell.com/faq/)        World Wide Web Consortium (W3C)      (www.w3.org/)        ZDNet      (www.zdnet.com/)        - ColdFusion        ColdFusion Developer's Journal      (www.sys-con.com/coldfusion/)        ColdFusion       introduction: why go dynamic?     (www.macromedia.com/software/coldfusion/resources/get_started/articles/godynamic.html)     ColdFusion   scripting tips    (builder.cnet.com/webbuilding/pages/Programming/ScriptMagic/ss01.html?tag=st.bl.3882.dir1.ScriptMagic_1)     ColdFusion       tutorial        (www.macromedia.com/support/coldfusion/tutorial_index.html)         - CSS       World Wide Web Consortium CSS Specifications      (www.w3.org/Style/CSS/)        WDG (Web Design Group)       CSS Guide        (www.htmlhelp.com/reference/css/)     Sitepoint.com article: Client       side coding: CSS        (www.sitepoint.com/subcat/90)        - HTML         Garvick.com: Beginner's       tutorial to HTML        (www.garvick.com/webdesign/tutorial.htm)        Getting started with HTML (W3C)    (www.w3.org/MarkUp/Guide/)       History of HTML      (www.w3.org/MarkUp/historical)        iBoost   Journals HTML Tips    (www.iboost.com/build/programming/html/index.html)        NCSA   (The National Center for Supercomputing Applications) HTML Primer    (archive.ncsa.uiuc.edu/General/Internet/WWW/HTMLPrimer.html)        St. Mary's   University Intermediate HTML Tutorial    (library.stmarytx.edu/acadlib/doc/html/inter.htm)        WDG (Web Design Group) HTML Help      (www.htmlhelp.com/)        WDG HTML Validator      (www.htmlhelp.com/tools/validator/)        World Wide Web Consortium (WC3)       HTML 4.01 Specifications        (www.w3.org/TR/REC-html40/)        WC3 HTML Home   Page    (www.w3.org/MarkUp/)        WC3 Markup       Validation Service        (validator.w3.org/)        - JavaScript       Scriptsearch.com    (/www.scriptsearch.com/JavaScript/)       Builder.com      (builder.cnet.com/webbuilding/0-3882.html)        - XML       Articles and resources      (www.dhs.state.or.us/web/handbook/xml.html)        World Wide Web Consortium (WC3): Introduction       to XML    (www.w3.org/XML/)        6. Setting up your site: File structure   The top-level file structure of the site is set up on the new     remote site and ready for your subfolders and files. See the file structure   of the site,  sorted   by topic folder  (Word document at www.dhs.state.or.us/web/library/file_structure.doc)       or see the web files and folders  sorted       by Webmaster .   (Word document at www.dhs.state.or.us/web/library/permissions.doc).    Four common folders.  Folders with the common   names ""archive,"" ""data,"" ""images,"" and ""publications"" are   already set up for you within each main topic folder. Don't rename these folders,   or we won't know where to look for your material. You may, however, delete   them if they aren't applicable.   What goes in these four folders?        Put all graphics (such as JPG and GIF files) in your topic  images  folder         Put       HTML publications and all downloadable documents (such as Word     files) in your topic  publications  folder         Put all data (such as           Excel files) in your topic  data  folder.  Note:  sometimes           a file could conceivably belong in more than one folder.         However, don't put it in more than one place, just keep it in the most           logical folder in your file structure, and make sure it's cross-referenced           on the both publication and index pages.         Put all archive material           (such as back issues of newsletters, reference material, etc.) in your topic      archive  folder       Remember,     Dreamweaver templates should not reside inside your subtopic folder.  In     order for the templates and style sheets to work properly, you must keep     your templates in the ""Templates"" folder at the root directory.      Adhering to this structure will assist our search engine in finding and logging   in your pages, as well as keeping the overall site well organized.    Publications and data indexes.  These     main pages reside at the top level of the site structure and contain links     to all the various publications throughout the site. They are maintained     by the Communication Office, but we rely on you to let us know what publications   and data you have that you want listed there. Let us know when you have     a new link to add to one       of these top-level       indexes. Email the Communication Office with Publication or Data   listings. In your email, tell us what text you want us as your link       (like the name of your publication or data), the URL of the link, and what       section       you want   the link to appear in.    Here's an example of how your email to us could look:   ""Please add  Survey of Adoption Programs  (www.dhs.state.or.us/children/publications/survey.html)     to the Children section of the Publication index page.""       Subfolders.  You will most likely     be adding folders of your own within your main topic folder. They may in     turn also need one or more     of     these subfolders     in them     (for example, Human Resources will have a publication folder, and a safety & wellness     folder. The safety and wellness folder will need it's own publications folder     to store the ""Safety Spot"" newsletters.)    Tip:  In   collaboration with your content person, try to keep your file structure as   flat as possible so material isn't buried too deep. In other words, avoid   too many folders within folders. We would like our information to be available   in as few ""clicks"" of   the user's mouse button as possible from the home page.       Tip:  Make   sure your Web site's file structure on your local drive is exactly mirrored   on your remote site.   Launch pages.  Each of your subtopics should   have a folder of its own, and each folder needs a ""launch"" (main) page. This main page must be called ""index.html"" or ""index.htm"" for the search engine to find and log it properly.   Access rights to the server.  The consolidated     DHS site is at www.dhs.state.or.us. We've given our server administrator,     Gary     Barr at CRM a list of all the Webmasters  and   the folders they   have permission to access. We've notified all of you, and Gary has set up your   accounts. Note: Information about setting up your site in Dreamweaver can be   found both in the software manual and in   the  FAQ  section of this site.   Transferring files.  Download your files   to the correct topic folder on the local site (usually your hard drive). Go   to the remote site (www.dhs.state.or.us) and copy the /style/   and   /images/   directories   to your root directory. Also get the files called ""template.dwt,"" template_content1.dwt   and template_content2.dwt from the remote site. You will need to rename these   file for your topic before saving them back to the remote site (example: seniors_content1.dwt).   Setting up your site: Migrating     files from your current server to the consolidated server   If you are migrating existing material already in Dreamweaver templates to   the new template and new site, the process of applying the revised template   is simple. From the ""Modify"" menu, choose ""Apply Template to   Page""/""Select Template."" Select the new template you have made.   This applied the new template to your old pages.     If your existing material does not already have a Dreamweaver template applied,   the cleanest and fastest procedure is:      1. Copy your body copy from the source HTML file       2. Paste it into a blank Dreamweaver page        3. Check the body copy and make sure you delete all references to body       text font and font size (the style sheet will take care of all of that).       Retain only your HTML paragraph  <p></p>,  line       breaks  <br>  and heading       tags  <h2>, <h3>,  etc.        4. From the ""Modify"" menu choose ""Apply Template"" to       apply your customized template to the page        5. Save it in the appropriate folder on the new site     Note:  If you get a message asking ""Include dependent files?"" choose ""No.""     7. Templates   Two types of templates.  We have created two basic types of Dreamweaver   templates for your Web pages. One is a navigation template, the other a content template.     Description of the navigation       template.  The navigation template is used for high-level pages       in the site. Navigation buttons down the left side of the pages lets the       user move around through the main topic areas of the site. The purpose       of navigation pages is to allow the user to get quickly to the information       he/she is after, and move easily both back to the higher-level pages or       forward to more specific target or destination pages where the content       resides.   Using the navigation template.  Use   the navigation template for most index.htm or ""home"" pages.   Description of the content template.  The   content pages are the target pages, the pages where the actual material resides.   The content template doesn't have the left-hand navigation menu since the content   page is at the lowest or target level of the site. (That doesn't mean that   the content pages have no navigation of their own; some content pages may have   table of contents links, links to references on other sites, links to more   specific explanations or links to glossaries or other related material).   We have designed two content templates for your use, one with a generic header   called  template_content1  (at   www.dhs.state.or.us/web/library/templatecontent1.html)   and a second, called  template_content2  (at   www.dhs.state.or.us/web/library/templatecontent2.html) with   a customized header providing navigation to main areas of the site. Both templates   provide a navigation string (""breadcrumbs"") below the header that   steps the user back through the higher-level pages all the way home to the   DHS index page. These templates are located in the Templates folder   Using the content templates.  The   template_content1.dwt template is a ""bare bones"" format for your   content, with a generic header that says only ""Oregon Department of Human   Services."" You can use this for content that needs little in the way of   topic headings or additional navigation. The template_content2.dwt template   has a topic-specific header, a search field and additional navigation across   the top of the header to get to other major areas of the ""Inside DHS"" site.    Note: You don't need to apply any of the templates to pages with their own   formatting, such as news releases, publications, policies, etc., but you must   make sure you have links back to pages higher in the navigation structure.   We don't want the user to feel stranded in your content.   Cascading Style Sheets (CSS).  Your   template gets its formatting information from CSS.   This is a style sheet that specifies various font sizes and styles used in   HTML documents, and gives our Web pages a consistent look and feel. Style sheets   also reduce the amount of format coding needed on individual pages, and decrease   the use of  deprecated   HTML code  (more information about deprecated code is at the W3C Web site   at: www.w3.org/TR/html4/conform.html#deprecated.  More   info about CSS   is also available in the  links and resources  section of this handbook).    A line of code in the content and navigation templates ties the document   to the DHS style sheet. You do not have to program this yourself. Note: The   style sheet your template refers to is located in the root level directory   called /style/.    Your pages will be using this style sheet to set heading size and color for   your body text, titles, subtitles, etc. Your body text will most likely be   set to default, which is  <p>.  When   you use subtitles or topic titles, you need to use standard HTML heading tags  (<h1>, <h2>, <h3>, <h4>, <h5>, or  <h6>) instead   of hard-coding font styles yourself. For example, when you coding the title   of your page:   Instead of:       <font face=""Verdana, Arial,   Helvetica, sans-serif"" color=""#330066"" size=""+2"">Your   title</font>      Use:       <h2>Your title</h2>      The style sheet will determine what font size, color, and style the  <h2>  tag   should be in the example above. The text color for links has also been set   in CSS. Links appear green, active links should appear orange, and visited   links will be purple. To see what the style sheet heading tags look like applied   to text, see the  sample   navigation template  (www.dhs.state.or.us/web/library/templatenavigation.html).   Customizing navigation template   Naming the navigation template.  Open   the master Dreamweaver navigation template (""template.dwt"" in the   Templates directory on the root level). Rename the file, and save it back to   the same Templates directory. If you are using Dreamweaver's ""check in/check   out"" feature, make sure when you are done copying or cloning templates you check the masters back to the remote site so someone else can use them.     Naming files and folders  (these   conventions apply throughout the site):      Use only lower case letters (no capital letters)    Don't use any spaces    Don't use any symbols, special characters like number signs (#) or slashes   (/), or punctuation (commas, periods)    Don't create file names longer than 20 characters (not including the extension)     Editable template areas.  You have   six editable areas on your template to customize before adding your body text:   1.  Metadata   2.  Title   3.  Header   4.  Navigation string  (breadcrumbs)   5.  Navigation table :  topics ,  face     icons ,  rows   6.  ""Hot Topics""   7.  Footer   1. Fill in the metadata.  Metatags   are part of the HTML code for a Web page, and are not normally visible to your   viewers. Metatags contain information that search engines use to understand   the Web site. The template already has the metadata subject areas outlined   and ready for you to enter your topical information.    The meta information includes "" description "" and "" keywords "" as   well as some other data areas used by the Oregon.gov search feature. The better   your metatags, the easier it is for search engines to find and index your site.     Metatags are placed in the HTML document in the <head> section. Your   template will already have an editable area for metadata.     "" Description "" metatags   give a bit more information about your page. The user might read this to decide   if the page has the specific information he/she is looking for. An example   of a description metatag is ""Immunization guidelines for Oregon schoolchildren   under the age of 5.""    A typical search engine's entry for your page would display both the title   and the description found in your metadata. For the examples used above, your   viewer would see:         Oregon DHS: Immunization      Immunization guidelines for Oregon schoolchildren under the age of 5      This hopefully gives your viewer enough useful information to decide whether   or not this page is what is needed.      ""Keyword""  metatags tell search engines what specific words   apply to your HTML page. List as many specific keywords as possible; don't   use general keywords like ""Oregon public health,"" ""Oregon"" or ""DHS"" as   keywords on any but top-level pages.     Though many search engines unconstrained by processing speed can scan your   entire document and automatically generate a list of keywords, you need to   accommodate older search engines as well. By supplying these specific keywords,   you allow older search applications to find and index your page accurately.     A comma separates each keyword. Typical keywords for the Immunization page   in the example listed above could be ""immunization, shot, vaccination,   inoculation."" Most search engines can understand variations of your keywords   (using the example above, like: ""immunize, vaccine, vaccinate, shots,   and inoculate""). Older search applications won't find these extrapolated   terms, though. To be more inclusive, you might want to combine both these lists   for your keywords.      2. Write an accurate page title:  Residing   inside the header tag below the metadata, the page title (also called ""doctitle"")   needs to be accurate and specific to the content on your page, because the   title you pick will show up on the top bar of your user's browser. Also when   your page comes up in most search engine lists, the title is the first thing   the user will see, and should tell him/her right away if that's the page they   are looking for.    Please construct your pages with titles that start with ""Oregon DHS:"" as   in the following example:       ""Oregon DHS: Immunization""      For an explanation of the other metadata already outlined in your template,   see the guidelines from the Oregon State Library  FindOr  (www.osl.state.or.us/findor/)   project.   3. Choose your header.  Find   the header that fits your topic from the  headers  (www.dhs.state.or.us/web/library/headers.html)   in the Web developers' library library. If you need help picking the right   one, or feel you need   a specific one for a subtopic, ask the  content   committee member  for your topic area (see the roster at www.dhs.state.or.us/web/content/roster.html).   4. Don't forget ""breadcrumbs.""  Put   a navigation string above the navigation table on every page. The format for   your breadcrumbs should be: "" DHS home  |  Your topic  |  Your   subtopic  | Your page name."" Note that the page you are actually on   is not a link, since ""you are there."" Example:        DHS home  |  Web developers  |  Library  |       Headers & footers      5a.       Navigation table: List your topics.  The list of topics in your       navigation table at the left side of the page should have already evolved       from discussions between you and your content person. The standards for       the topics in the table are as follows:        Keep your navigation to one line if possible, but no more than two to keep     the table coding intact         As you will throughout your site, use initial capitalization for all but     proper nouns (in other words, ""Oregon Health Plan"" would be upper-lower     case, but ""Medicaid information"" would be initial cap only)           Alphabetize the navigation topics in the table, unless the sequence     is essential.            Sample exceptions:                       Main topic pages (like ""Children"" or ""Policy"")             have for their first navigation item ""An overview."" Though ""An             overview"" may not be alphabetically be first, it still needs             to be in the first row of your navigation table.              Processes or procedures that need to be in a specific order, or             items of higher importance than others whose topics can't be forced             into alphabetical terms.              Online publications whose table of contents is topic-based, not             alphabetical.             Archives can generally be placed at the end of the list, even though           the word alphabetically may at or close to the top of the list.                   5b. Navigation table: choose the       face icons.  Select the appropriate graphic from the  faces       library  (at www.dhs.state.or.us/web/library/faces.html). If       you need help in choosing faces appropriate for your uses, call the Communication       Office and someone will       assist you.       Do  not  design       your own buttons; you must use the images we've created, to keep the DHS       standard look-and-feel. Note that the background of the cells that hold       the icons is black and the alignment is to the right.   5c. Navigation table: rows.  Try   to keep to 10 or fewer items in your left navigation menu, as studies have   shown more than 10 navigation items are confusing. If you need fewer than the   10 rows provided, delete the unnecessary rows.      Note:  The total width of the navigation table should be 177 pixels.   Each row in the navigation table should be 28 pixels in height. If your navigation   table doesn't look right, check the height of the rows and width of the table.   Note also that the background of the face cell is black (#000000) and the background   of the topic area is blue-gray (#F3F4FF).     To add a row:  Select the the place   where you want to add the new row. (You can select a row by placing your mouse   to the left of the navigation table. When a right-pointing arrow appears, click.   Make sure just the row is selected, not the entire table.) When the row is   selected go to the ""Modify"" menu, select ""Table""/""Insert   Row.""   To delete a row:  Select the   row you want to remove. Hit the delete key.   6. Add ""Hot Topics.""  Your   upper-level topic pages might need shortcuts to pages of special interest with   heavy traffic or timely pages (like a monthly food drive page). Use the ""Hot   Topics"" area for these links. If you don't have any hot topics to link   to, you can delete this table. If you need it later, you can always copy it   again from the main template.   7. Revise the template footer.  The   generic language for the footer found on the main template is as follows:        If you have questions about DHS, problems getting DHS services, or comments     about this site, email us:  DHS     Information . DHS Groupwise users, address email to dhs.info@state.or.us      The email address dhs.info@state.or.us sends messages to the Governor's Advocacy   Office, who will forward the Web-related enquiries for the main site on to the   Communication Office. However, for your topic-based Web pages, comments about   your site should be directed to you. You could edit the generic paragraph as   follows:       If you have questions about DHS or problems getting DHS services, email     us:  DHS Information . DHS     Groupwise users, address email to dhs.info@state.or.us      If you have comments about this site, email us:  Webmaster .     DHS Groupwise users, address email to (your email account name)@state.or.us    For the Webmaster link, we recommend getting a Groupwise account specific to your Web site (for example, ""seniors.web@state.or.us"") instead of using your individual state address. This way, your privacy is protected since your name is no longer associated with the site, and if your job duties include someone else at some point, the privileges to read and write to the Web Groupwise account can be shared. Get this account by contacting the DHS HelpDesk.  Besides giving the link, spell out your email address in GroupWise-friendly   terms in the footer. In other words, give out the entire email address as in   the example above. Note: The size of the footer text is  <h6>.     Also using the  <h6>  size,   add your unit, program or cluster address and phone numbers. Use the following format:   Oregon Department of Human Services   (same on all addresses, bold)    Administrative Services  (your cluster or program)    500 Summer St. NE, E94, Salem, OR 97301-1097  (your cluster or program's   address, suite, and zip+four)    Phone: (503) 945-5733  (your cluster or program's main phone number)    Fax: (503) 378-2897  (your cluster or program's main fax number)    TTY: (503) 947-6214  (your cluster or program's main TTY phone number)   Final steps: ""freeze"" your       template.  Remember to make the areas you have customized into uneditable       areas before you start applying it to any pages. Areas you'll want to make       uneditable probably include the header, footer, and (most importantly)       your left menu navigation table. This doesn't preclude you from adding       or removing topics on the template later, but makes global changes possible       to pages that have the template applied. For example, if you leave the       left menu as an editable area and make a change to the navigation later       on, you will have to manually make the same change on the left menu of       each page that uses the template, which defeats the whole purpose.      To make a section uneditable:  on your customized template page (in   Dreamweaver MX), click on the editable area you want to make uneditable, and   from the ""Modify"" menu, select ""Templates,"" then ""Remove   Template Markup.""   To make a section editable:  on your customized template page (in Dreamweaver   MX), select the entire area you want to make editable, and from the ""Insert"" menu,   select ""Template Objects,"" then ""Editable Region.""   At this point, the navigation template is ready for body copy. If you're not   ready to start populating it, save the template and close the file.      Test,     test, test!  You should be testing your pages in both Internet Explorer     and Netscape Navigator to see how if they look and function properly in each     browser. If possible, you should also test on both IBM-compatible and Macintosh     platforms.   Customizing content templates   Naming the content template.  Open   one of the two master Dreamweaver content templates, "" template_content1.dwt "" (more   info at   www.dhs.state.or.us/web/library/templatecontent1.html) or "" template_content2.dwt "" (more   info at www.dhs.state.or.us/web/library/templatecontent2.html) in the   Templates directory on the root level. Rename the file, and save it back   to the same Templates directory. If you are using Dreamweaver's""check   in/check out"" feature, make sure when you are done copying or cloning   templates you check the masters back to the remote site so someone else can use them.     Naming files and folders  (these   conventions apply throughout the site):     Use only lower case letters (no capital letters)   Don't use any spaces   Don't use any symbols, special characters like number signs (#) or slashes   (/), or punctuation (commas, periods)   Don't create file names longer than 20 characters (not including the extension)     Editable template areas.  You have   five editable areas on your template to customize before adding your body text:    1.  Metadata   2.  Title    3.  Header   4.  Navigation string  (breadcrumbs)    5.  Footer   1. Fill in the metadata.  Metatags   are part of the HTML code for a Web page, and are not normally visible to your   viewers. Metatags contain information that search engines use to understand   the Web site. The template already has the metadata subjects outlined and ready   for you to enter your topical information.    The meta information includes "" description "" and "" keywords "" as   well as some other data areas used by the Oregon.gov search feature. The better   your metatags, the easier it is for search engines to find and index your site.     Metatags are placed in the HTML document in the <head> section. Your   template will already have an editable area for metadata.     "" Description "" metatags   give a bit more information about your page. The user might read this to decide   if the page has the specific information he/she is looking for. An example   of the description metatag might be ""Immunization guidelines for Oregon   schoolchildren under the age of 5.""    A typical search engine's entry for your page would display both the title   and the description found in your metadata. For the examples used above, your   viewer would see:         Oregon DHS: Immunization      Immunization guidelines for Oregon schoolchildren under the age of 5      This hopefully gives your viewer enough useful information to decide whether   or not this page is what is needed.      ""Keyword""  metatags tell search engines what specific words   apply to your HTML page. List as many specific keywords as possible; don't   use general keywords like ""Oregon public health,"" ""Oregon"" or ""DHS"" as   keywords on any but top-level pages.     Though many search engines unconstrained by processing speed can scan your   entire document and automatically generate their own list of keywords, you   need to accommodate older search engines as well. By supplying these specific   keywords, you allow older search applications to find and index your page.     A comma separates each keyword. Typical keywords for the Immunization page   in the example listed above could be ""immunization, shot, vaccination,   inoculation."" Most search engines can understand variations of your keywords   (using the example above, like: ""immunize, vaccine, vaccinate, shots,   and inoculate""). Older search applications won't find these extrapolated   terms, though. To be more inclusive, you might want to combine both these lists   for your keywords.     2. Write an accurate page title:  Residing   inside the header tag below the metadata, the page title (also called ""doctitle"")   needs to be accurate and specific to the content on your page, because the   title you pick will show up on the top bar of your user's browser. Also when   your page comes up in most search engine list, the title is the first thing   the user will see, and should tell him/her right away if that's the page they   are looking for.    Please construct your pages with titles that start with ""Oregon DHS:"" as   in the following example:       ""Oregon DHS: Immunization""      For an explanation of the other metadata already outlined in your template,   see the guidelines from the Oregon State Library  FindOr  (www.osl.state.or.us/findor/   )project.   3. Choose your header.  Find   the header that fits your topic from the  headers  at   www.dhs.state.or.us/web/library/headers.html. If you need help picking   the right one, or feel you need a specific one for   a subtopic, ask the  content   committee member  for your topic area (see the roster at www.dhs.state.or.us/web/content/roster.html).   4. Don't forget ""breadcrumbs.""  Put   a navigation string above the navigation table on every page. The format for   your breadcrumbs should be: "" DHS home  |  Your topic  |  Your   subtopic  | Your page name."" Note that the page you are actually on   is not a link, since ""you are there."" Example:        DHS home  |  Web Developers  |  Library  |       Headers & footers     5.  Revise the template       footer.  The generic language for the footer found on the main template       is as follows:        If you have questions about DHS, problems getting DHS services, or comments     about this site, email us:  DHS Information . DHS Groupwise users, address email to dhs.info@state.or.us      The email address dhs.info@state.or.us sends messages to the Governor's Advocacy   Office, who will forward the Web-related enquiries for the main site on to   the Communication Office. However, for your topic-based Web pages, comments   about   your site should be directed to you. You could edit the generic paragraph as   follows:       If you have questions about DHS or problems getting DHS services, email     us:  DHS Information . DHS     Groupwise users, address email to dhs.info@state.or.us      If you have comments about this site, email us:  Webmaster .     DHS Groupwise users, address email to (your email account name)@state.or.us    For the Webmaster link, we recommend getting a Groupwise account specific to your Web site (for example, ""seniors.web@state.or.us"") instead of using your individual state address. This way, your privacy is protected since your name is no longer associated with the site, and if your job duties include someone else at some point, the privileges to read and write to the Web Groupwise account can be shared. Get this account by contacting the DHS HelpDesk.  Put your email address in GroupWise-friendly terms in the footer. In other   words, spell out the entire email address-don't just create an email link from   a name in the footer. (Example: ""Questions or comments on this site: Health   Webmaster. DHS GroupWise users, address email to health.info@state.or.us"").   Note: The size of the footer text is  <h6>.     Also using the  <h6>  size,   add your unit, program or cluster address and phone numbers. Use the following format:   Oregon Department of Human Services   (same on all addresses, bold)    Administrative Services  (your cluster or program)    500 Summer St. NE, E94, Salem, OR 97301-1097  (your cluster or program's   address, suite, and zip+four)    Phone: (503) 945-5733  (your cluster or program's main phone number)    Fax: (503) 378-2897  (your cluster or program's main fax number)    TTY: (503) 947-6214  (your cluster or program's main TTY phone number)   Final steps: ""freeze"" your       template.  Remember to make the areas you have customized into uneditable       areas before you start applying it to any pages. Areas you'll want to make       uneditable probably include the header, footer, and (most importantly)       your left menu navigation table. This doesn't preclude you from adding       or removing topics on the template later, but makes global changes possible       to pages that have the template applied. For example, if you leave the       left menu as an editable area and make a change to the navigation later       on, you will have to manually make the same change on the left menu of       each page that uses the template, which defeats the whole purpose.      To make a section uneditable:  on your customized template page (in   Dreamweaver MX), click on the editable area you want to make uneditable, and   from the ""Modify"" menu, select ""Templates,"" then ""Remove   Template Markup.""   To make a section editable:  on your customized template page (in Dreamweaver   MX), select the entire area you want to make editable, and from the ""Insert"" menu,   select ""Template Objects,"" then ""Editable Region.""   The content template is ready for body copy. Save the template and close the   file.    Test, test, test!  You should be testing your pages in both Internet Explorer and Netscape Navigator to see how if they look and function properly in each browser. If possible, you should also test on both IBM-compatible and Macintosh platforms.      8. Tools & tips   Code snippets   Here are some common bits of useful code. (Please contact the Communication   Office to contribute to this section):   Redirects:   To redirect people from the old DHS site to the new one, put this code in   your metadata:       <META http-equiv=""refresh"" content=""0;       URL=http://www.dhs.state.or.us/(your topic location)/"">     The         number ""0; in the code above should be replaced with the number         of seconds you decide the user should wait to get to the new page. If         you         want the user to go to the new site immediately, you would use ""0;         however, if you want the user to have time to read your redirect and         find out that he/she should bookmark the new page, 20 seconds or so allows         a little more reading and comprehension time.   You can use a sentence like:       The Oregon Department       of Human Service site has moved. Our new home page is at  http://www.dhs.state.or.us .       The page that you have selected is now located at http://www.dhs.state.or.us/xxxx.  (xxxx       would be where you would complete the URL to get the user to your new page)  You       may click on this link to go there now, or be automatically redirected       to our new page in 20 seconds.     We suggest you bookmark the new page. This redirect will expire December 31, 2003.      Today's date:       <SCRIPT language=""JavaScript"">  <!---      document.write(dayNames[day] + "", "" + monthNames[month] + "" "" +     date + "", "" + year)      //--->  </SCRIPT>     Note: be aware that later versions of Netscape (such as version 7.01) do   not read JavaScript correctly. You may end up with the wrong date on all   pages using this code. It might be advisable to use this script sparingly if   at all.   See also  HTML tutorial links   Image libraries   Graphics for the Web site are available from the following download pages:      DHS logos  (at www.dhs.state.or.us/images/logo/)     Navigation icons  (at www.dhs.state.or.us/web/library/faces.html      for the navigation table)    Headers  (at www.dhs.state.or.us/web/library/headers.html    for the top of page)      Graphic elements  (at www.dhs.state.or.us/web/library/elements.html      for arrows, buttons, bullets, dividers, bars, etc.)     Metadata samples   Here's a sample of the minimum metadata you should have on each page to allow   people using our State Library search engine, FindOR, locate your material:         <meta name=""description"" content=""Guest Opinion: Report helps community leaders   achieve goals"">  <meta name=""originatorJurisdiction"" content=""State of Oregon"">  <meta name=""createDate"" content=""2002/04/09"">  <meta name=""dateofLastModification"" content=""2002/04/12"">  <meta name=""keywords"" content=""DHS guest opinion, DHS outcomes, DHS goals, DHS accountability, DHS performance measures, state managers, county commissioners, community leaders"">  <meta name=""subjects"" content=""Social and Family Issues and Programs"">       Please note, in order to allow the state's government locator feature to find   your page, you should use the  metadata   specifications  provided by the State Library on their FindOR site at www.osl.state.or.us/findor/,   especially noting their  subject   tree  (www.osl.state.or.us/findor/gilstree.html). The State Library also   offers metatag training (email FindOR trainer  Jey   Wann . GroupWise users: jey.a.wenn@state.or.us).  A word on dates:  Be careful with the content format of the date related   tags. Dates are expressed as YYYY/MM/DD.   Examples:       <meta name=""createDate"" content=""2002/11/01"">  <meta name=""dateofLastModification"" content=""2003/05/30"">     Note: Unless you have the dates  in YYYY/MM/DD format, a user using the correct   date format to search for a file in FindOR won't find your document.   Optimizing graphics for the Web   When creating images for the Web, keep file size in mind. Large graphic files   take a long time for users with the minimum 28-baud modems to download. Waiting   too long for pages to load can make users frustrated with the site before they've   had a chance to really explore it.   To avoid this, produce illustrations and photos with the minimum   resolution, size and color depth necessary. You can do this manually, but programs   like  ImageReady  (bundled with  Photoshop)  can be used to automate   the process of minimizing your graphic file sizes.   Web page file size limit   Try to keep your Web page no larger than 64K, including all graphics. This   way, viewers with older modems can see your pages and get to your information   without waiting around too long for pages to load. 64K may seem like an impracticably   small size, but there are workarounds if you have pages that really need lots   of graphics.   For example, if you have large detailed graphic such as maps, rather than   slowing down the loading of your entire page, you could show tiny snapshot   of the maps with a link to see each one in a larger size on a separate page.   This way, the user has a choice whether or not to click for a more detailed   view, and will probably be willing to wait if it's exactly the information   he or she needs.   Another way to make a graphic load faster is to specify the height and width   in the HTML code (example:  <img   src=""art/masthead.gif"" height=""38"" width=""193"" border=""0"" alt=""Currents   Online""> ). By specifying the height and width of the graphic,   the page will load with the proper amount of space ""reserved"" for   each graphic prior to displaying the graphic. This makes for a faster load   and also keeps the page layout from sizing and resizing itself in an annoying   fashion as the viewer waits for it to display.   Graphics file formats     There are two choices of Web graphics file formats in popular use,   *.jpg (Joint Photographic Experts Group) and *.gif (Graphics Interchange Format).   There   will hopefully   be more formats to use in the future (like the much-anticipated  Portable   Network Graphics  [PNG] format and  Scalable Vector Graphics  [SVG] format).   Things to remember about both file formats:  Either file format   works for image maps (graphics with clickable areas). Note: There is an   excellent  NCSA   tutorial  for making image maps at hoohoo.ncsa.uiuc.edu/docs/tutorials/imagemapping.html.   Both formats compress your image and lose data that can't be recovered.   To avoid problems with this limitation, keep your master graphic in *.PSD   format (if you've used Photoshop with multiple layers) or in *.TIF format   (if the graphic is all on one layer). This way you always have a full-resolution   master to go back to when you need to make corrections or revisions.   GIF file format   You should use the GIF format for most of your Web graphics. Use the GIF format   for:       Simple illustrations, logos, diagrams and charts     Graphic elements, like arrows and bars     Images that need a transparent background (called the GIF89a format. In  Photoshop,  you will need the GIF89a plug-in to create these)     Animated images (called the GIF89 format)       Things to remember about GIFs:  A GIF file contains only 256   colors (also called ""8-bit"" or ""indexed"" color). You really   have only 216 colors (also called ""Web safe"" or ""browser safe"" colors)   if you are building for both Mac and PC browsers with old 8-bit video cards   (see  ""browser friendly"" palette info    at www.lynda.com/hex.html).   However, since such cards have been obsolete for 5 years now, it is not as   important as it once was to stick to this palette.   The GIF file format also allows one of the 256 colors to be transparent in   what's called the GIF89a format. A transparent channel allows you to create   Web graphics that can be used on a colored background on a Web page. Note:   To create these graphics, make the background layer in  Photoshop  approximately   the same color as your Web background, so when you make the background transparent,   the image will be anti-aliased to the right color. (We've all seen graphics   with fuzzy halos on Web pages, and that's because the graphic artist who   created them didn't realize this, or else the HTML coder changed the background   color on the Web site without asking for a new graphic anti-aliased to the   new color.)   Images with lots of tiny detail (like the DHS logo) may need to be saved at   300 dpi or greater, but try to restrict most of your GIF images to 72 dpi to   save on file size. After all, most monitors only display at approximately that   resolution, so your viewer won't be missing much.    Tip:  Use   the ""interlace"" option when saving GIFs in  Photoshop.  That   way the image will begin building on the Web page and slowly evolve, instead   of showing a ""loading graphic"" symbol until the image is downloaded.   JPEG file format   Use the JPEG file format for:       Photos, either black-and-white or color     Images for the Web that have lots of detail     Images that don't work well as GIFs, like images with many colors or gradiants     Things to remember about JPGs:  JPEGs, named after the committee   that invented it, was designed for compressing full-color or gray-scale images,   mainly photographic. Unlike GIFs, which are limited to 256 colors, JPEGs can   contain millions of colors. Because you can select from 12 degrees of compression,   you can moderate the file size and control degree of detail you are willing   to lose. Try to restrict JPG images to 72 dpi; in most cases, it will be sufficient.   Note you can't make transparent JPGs; if you need a transparent graphic,   you will have to make it a GIF. ( More   about JPEGS  can be found at www.faqs.org/faqs/jpeg-faq/)   PNG & SVG: Web graphic file formats of the future   PNG stands for ""Portable Network Graphic."" PNG is a file format   for raster images, like GIF and JPG, but the compression is ""lossless"" instead   of ""lossy""; in other words, no data is lost when the graphic is saved   as a PNG. It also can contain much more than 256 colors (8-bit indexed color),   unlike GIF. It supports thousands of grays (16-bit grayscale) and millions   of colors (24- and 36-bit truecolor).   PNG came about around a number of years ago when it looked like CompuServe   was going to charge for the use of its proprietary GIF format. Programmers   got   busy with   an alternative format for GIFs, and improved it both in compression capabilities   and number of colors. PNG was approved by the  WWW   Consortium  (www.w3c.org) in 1996, but hasn't had widespread graphics application   support or browser support yet (for example, Netscape 7.0 and lower don't   support it).    PNG can also substitute nicely for TIF format as well. It handles indexed-color,   grayscale, and truecolor images equally well, and allows transparent images.   It doesn't offer animated images or photos yet, so it isn't ready   to replace animated GIFs or JPGs completely.   PNG has competition, however, Seeing how unpopular it's decision to charge   royalties for the GIF format was with users, CompuServe retracted its move   in that direction. Instead, it started developing a new compressed graphics   format, called GIF24. GIF24 was supposed to be a public domain format that   can support 24-bit images (unlike the current 8-bit limit on GIFs). As of this   writing, however, it looks like CompuServe is going to support the PNG file   format instead (source:  WWW   Consortium PNG Web site  at www.w3.org/Graphics/PNG/CS-950214.html).   SVG stands for ""Scalable Vector Graphic."" SVG is an XML-based graphics language   from  W3C specifications .    SVGs are vector images that scale well in a variety   of displays, from desktop monitors to PDAs to wireless phones.    SVG is text-based, so it is accessible to screen readers. It was developed   collaboratively  ( Adobe  [which has   a  downloadable   SVG viewer ] and  Sun , among     others).   Optimizing graphics references       Boutell.com    www.boutell.com     Common Internet File       Formats  (archival)    www.matisse.net/files/formats.html       Internet FAQ Consortium    www.faqs.org     Lynda.com    www.lynda.com         World Wide Web Consortium (W3C)      www.w3c.org"
GX002-38-12425783	NIST Special Databases and Software from the Image Group   This is a listing of test data produced by the Image  Group for use in evaluating automated OCR, fingerprint classification/matching, and face recognition systems. Documentation files are in postscript format compressed with the UNIX compress utility. The approximate sizes of the compressed files are indicated in square brackets.   [ OCR ] [ Fingerprints ] [ Mugshots/Face ]        Newest Items          Special Database 30  -                Dual Resolution Images from Paired Fingerprint Cards.                                  documentation   [807K]               OCR Databases          Special Database 1  -                 !**! Superseded by Special Database 19 !**!                 [was NIST Binary Images of Printed Digits, Alphas, and Text.]                 Cancelled December 96.           Special Database 2  -                NIST Structured Forms Reference Set of Binary Images.                                  documentation   [321K] ,                The file  append_a.tar.Z   [3,119K]                 should also be retrieved.          Special Database 3  -                 !**! Superseded by Special Database 19 !**!                 [was Binary Handwritten Segmented Chars]                 Cancelled Mar 95.           Special Database 6  -                NIST Structured Forms Reference Set 2 of Binary Images.                                  documentation   [420K] , The file                 append_a.tar.Z   [3,119K]                 should also be retrieved.          Special Database 7  -                 !**! Superseded by Special Database 19 !**!                 [was NIST Test Data 1 Binary Handprinted Chars]                 Cancelled Mar 95           Special Database 8  -                NIST Machine-Print Database of Gray Scale and Binary Images.                                  documentation   [32K]           Special Database 11  -                NIST Binary Image Training Database of Census Miniforms           Special Database 12  -                NIST Binary Image Training Database of Census Miniforms 2           Special Database 13  -                NIST Binary Image Testing Database of Census Miniforms           Special Database 19  -                NIST Handprinted Forms and Characters Database.                                  documentation   [295K]           Special Database 20  -                NIST Scientific and Technical Document Database.                                  documentation   [231K]           Special Software 1  -                NIST Scoring Package Release 1.0.           Public Domain OCR  -                NIST FORM-BASED HANDPRINT RECOGNITION SYSTEM  (Release 2.2)           Special Database 25 Volume 1  -                Federal Register Document Image Database.                                  documentation   [2,196K]                                  source code   [329K]          Fingerprint Databases          Special Database 4  -                NIST 8-bit Gray Scale Images of Fingerprint Image Groups.                                  documentation   [509K]           Special Database 9  -                NIST 8-Bit Gray Scale Images of Mated Fingerprint Card Pairs.                                  documentation   [1,046K]           Special Database 10  -                NIST Supplemental Fingerprint Card Data (SFCD) for NIST                Special Database 9.                                  documentation   [1,076K]           Special Database 14  -                NIST Mated Fingerprint Card Pairs 2.                                  documentation   [1,020K]           Special Database 24  -                Digital Video of Live-Scan Fingerprint Data.                                  documentation   [773K]           Special Database 27  -                Fingerprint Minutiae from Latent and Matching Tenprint Images.                                  documentation   [684K]                                  sample data   [1230K]                                  source code   [400K]           Special Database 29  -                Plain and Rolled Images from Paired Fingerprint Cards.                                  documentation   [825K]           Special Database 30  -                Dual Resolution Images from Paired Fingerprint Cards.                                  documentation   [807K]           Public Domain PCASYS  -                NIST Pattern-level Classification Automation System for                Fingerprints. Updated version included on NFIS CDROM           Public Domain NFIS  -                NIST Fingerprint Image Software.                  Software Updates:                                   updates.tar  or                                 updates.zip                 Refer to the                                 README  file                for information about updates (including date of last update).                                  Document Update:                                   New Section 2.1               Mugshot/Face Databases          Special Database 18  -                NIST Mugshot Identification Database.                                  documentation   [32K]        Checkout  Standard Reference Data Program's  WWW page for information on other standard reference data products available from NIST.       Created May 22, 1996.  Last modified April 9, 2003.  Contact   webmaster@magi.nist.gov  with corrections/comments.
GX239-44-6960118	"NISTIR 7030  Picture Password:  A Visual Login Technique for Mobile Devices Wayne Jansen Serban Gavrila Vlad Korolev Rick Ayers Ryan Swanstrom   NISTIR 7030  Picture Password: A Visual Login Technique for Mobile Devices Wayne Jansen Serban Gavrila Vlad Korolev Rick Ayers Ryan Swanstrom  COMPUTER  SECURITY  Computer Security Division Information Technology Laboratory National Institute of Standards and Technology Gaithersburg, MD 20988-8930  July 2003  U.S. Department of Commerce  Donald L. Evans, Secretary  Technology Administration  Phillip J. Bond, Under Secretary of Commerce for Technology  National Institute of Standards and Technology  Arden L. Bement, Jr., Director   Reports on Computer Systems Technology The Information Technology Laboratory (ITL) at the National Institute of Standards and Technology (NIST) promotes the U.S. economy and public welfare by providing technical leadership for the Nation's measurement and standards infrastructure. ITL develops tests, test methods, reference data, proof of concept implementations, and technical analysis to advance the development and productive use of information technology. ITL's responsibilities include the development of technical, physical, administrative, and management standards and guidelines for the cost-effective security and privacy of sensitive unclassified information in Federal computer systems. This Interagency Report discusses ITL's research, guidance, and outreach efforts in computer security, and its collaborative activities with industry, government, and academic organizations.  National Institute of Standards and Technology Interagency Report 16 pages (2003)  Certain commercial entities, equipment, or materials may be identified in this document in order to describe an experimental procedure or concept adequately. Such identification is not intended to imply recommendation or endorsement by the National Institute of Standards and Technology, nor is it intended to imply that the entities, materials, or equipment are necessarily the best available for the purpose.  i   Table of Contents Introduction ..................................................................................................................................... 1 Overview ......................................................................................................................................... 3 Image Selection............................................................................................................................... 5 Password Formation and Reuse ...................................................................................................... 6 Password Strength........................................................................................................................... 8 Mechanism Protection .................................................................................................................... 9 Implementation ............................................................................................................................... 9 Related Work ................................................................................................................................ 12 Summary ....................................................................................................................................... 14 References ..................................................................................................................................... 14  ii   Picture Password: A Visual Login Technique for Mobile Devices Abstract: Adequate user authentication is a persistent problem, particularly with handheld devices such as Personal Digital Assistants (PDAs), which tend to be highly personal and at the fringes of an organization's influence. Yet, these devices are being used increasingly in corporate settings where they pose a security risk, not only by containing sensitive information, but also by providing the means to access such information over wireless network interfaces. User authentication is the first line of defense for a lost or stolen PDA. However, motivating users to enable simple PIN or password mechanisms and periodically update their authentication information is a constant struggle. This paper describes a generalpurpose mechanism for authenticating a user to a PDA using a visual login technique called Picture Password. The underlying rationale is that image recall is an easy and natural way for users to authenticate, removing a serious barrier to compliance with organizational policy. Features of Picture Password include style dependent image selection, password reuse, and embedded salting, which overcome a number of problems with knowledge-based authentication for handheld devices. Though designed specifically for handheld devices, Picture Password is also suitable for notebooks, workstations, and other computational devices.  Introduction The trend toward a highly mobile workforce has spurred the acquisition of handheld devices such as Personal Digital Assistants (PDAs) at an ever-increasing rate. These devices offer productivity tools in a compact form and are quickly becoming a necessity in today's business environment. Manufacturers produce handheld devices using a broad range of hardware and software. Handheld devices are characterized by small physical size, limited storage and processing power, and the means for synchronizing data with a more capable notebook or desktop computer. Unlike desktops and notebook computers, handheld devices typically support a set of interfaces that are oriented toward user mobility. Usually they come equipped with a touch screen and a microphone, but lack a keyboard. One or more wireless interfaces, such as infrared or radio, (e.g., Bluetooth, WiFi, GSM/GPRS) are also built-in for wireless communication over limited distances to other devices and network access points. Most handheld devices can also send and receive electronic mail and browse the Internet via both wired and wireless interfaces. While such devices have their limitations, they are nonetheless extremely useful in managing appointments and contact information, reviewing documents, corresponding via electronic mail, delivering presentations, and accessing corporate data. Moreover, because of their relatively low cost, they are becoming ubiquitous within most organizations. From an authentication perspective, several issues loom over the use of such device, including the following items:  1     While handheld devices increasingly retain sensitive information over time and become networked to access wireless services and organizational intranets, some users may not recognize the associated security implications. Because of their small size, handheld devices may be left unattended temporarily, lost, or stolen. User authentication may not be enable, a common default mode, exposing the contents of the device to anyone who possesses it. Even if user authentication is enabled, the authentication mechanism may be weak (e.g., a four-digit PIN) or easily circumvented [Kin01]. Once authentication is enabled, changing the authentication information for knowledge-based mechanisms (e.g., PIN) periodically as its lifetime expires is seldom done on the initiative of the user.       Adequate user authentication is the first line of defense for protecting the resources of a handheld device. Currently, many handheld devices come with a four-digit Personal Identification Number (PIN) and a numerical entry pad consisting of the digits 0-9 as a means for user authentication. Because of their limited length and alphabet, PINs may be susceptible to shoulder surfing or systematic trial-and-error attacks. Passwords offer a significant improvement over PINS in both length of entry string and size of alphabet. Some handheld devices, such as PDAs, support the character-by-character input of traditional alphanumeric passwords via the touch screen, using either handwriting recognition or a virtual keyboard window. The strength of password mechanisms lies in the large set of combinations of character strings possible, from which an intruder has to identify the exact one needed to impersonate an authorized user. For example, for an eight-character string populated from the set of 95 printable ASCII keyboard characters, the number of possible character strings is 958. While passwords are an improvement over PINs, they can be difficult to remember and prone to input errors when entered via a touch screen. Thus, users tend to use easily remembered character strings such as ""password"" to simplify authentication. When the password expires, its replacement is often very similar (e.g., p@ssword) [Lee01]. These tendencies significantly reduce the password space and allow an intruder to deduce passwords quickly by systematically applying dictionaries of commonly used strings and password reuse patterns (e.g., password1, password2, etc.) [Mor79, Kle90]. To avoid weak or easily broken passwords, organizational policy and procedures compel users to include special, upper case, and numeric characters in their password string, to avoid common or easily guessed strings, and to update passwords regularly (e.g., every 90 days) with completely different strings. Policy and procedures may also be backed up by technical controls that force periodic updates, and either screen out unacceptable passwords selected by users or supply acceptable passwords automatically for users [Spa92]. Unfortunately, the measures put in place to ensure strong, but typically complex and meaningless passwords, frequently result in users writing them down and keeping them near the computer system to 2   recall quickly. This behavior is fueled further by the numerous systems that require passwords for authentication. The mechanism described in this paper authenticates a user to a PDA using a visual login technique called Picture Password. Picture Password authenticates a user through the selection of images displayed on a handheld device. As seen with screen savers, graphic screen backgrounds, or application skins, products that employ visual content appeal to a large class of users. Having the ability to tailor the display interface with personal images, gives users a sense of freedom and control over what might otherwise be considered an imposition. Thus, an image-based authentication technique, if designed carefully, has the potential to engage users to employ the mechanism and indulge periodic updates of the authentication information.  Overview For any authentication mechanism to gain user acceptance, it must be convenient to use and match the capabilities of the device. Difficulties due to cumbersome attachments, slow performance, or error-prone user interfaces are typically not tolerated. The aim then is to devise authentication mechanisms for PDAs that are well suited to the typical interfaces and capabilities supported by such devices. Our work has focused on higher-end expandable devices aimed at corporate users: the Compaq/HP iPAQ H series of devices running the Familiar Linux distribution and Opie and the Sharp Zaurus SL-5X00 series of devices with Lineo's embedded Linux and Qtopia. Both families of devices are approximately the same dimensions as a pocket-size agenda, equipped with a one-quarter VGA touch screen, use processors running at 200 MHz and higher, and have comparable amounts of read only flash memory (32MB or more) and random access memory (64MB or more). Linux distributions are supported on a number of other PDAs including the CDL Paron, IBM e-LAP, and Yopy Gmate. The Picture Password authentication mechanism has two distinct parts: the initial password enrollment and subsequent password verification. During enrollment, a user selects a theme identifying the thumbnail photos to be applied and then registers a sequence of thumbnail images that are used to derive the associated password. When the device is powered on or booted up, the user must enter the currently enrolled image sequence for verification to gain access to the device. After a successful authentication, the user may change the password, selecting a new sequence and/or theme. Picture Password offers benefits over PINs and textual passwords, especially for the visually inclined user. As with textual passwords, a similar password length and alphabet size is used. However, instead of having to memorize and enter a string of random-like alphanumeric characters, a sequence of thumbnail images must be selected and retained. Experimental results suggest that human visual memory is well suited to such visual and cognitive tasks [Mel01, Gol71]. Moreover, an image sequence that has some meaning to the individual user (e.g., logos of sport's league teams in order of preference, one's family members in order of birth or vacation spots in order visited) can be used. If forgotten, the sequence may be reconstructed from the inherent visual cues. The display interface presents images in an easyto-select size, reducing error entries. The underlying mechanism, which handles random  3   character code assignment to images, password composition, enrollment, and verification, is completely hidden from the user. The presentation of images to the user for selection is based on tiling a portion of the user's graphical interface window. Various ways exist to tile a surface with both regular and irregular patterns. Picture Password uses squares of identical size (40 x 40 pixels), grouped into a 5 x 6 matrix of elements. Cells of this size provide a clear recognizable image that is easily selectable for most users. Figure 1 illustrates the PDA screen image for the Cats & Dogs theme, one of three predefined themes. The message area at the top of the window guides the user's actions, while the display area in the center displays thumbnail images selectable with a single tap of the stylus. The controls at the bottom allow the user to clear out any incorrect input entered or submit the entered image sequence for verification. Selecting and submitting the correct sequence of thumbnail images authenticates the user to the device.  Figure 1: Picture Password Cats and Dogs Theme  Picture Password allows users flexibility in choosing a predefined theme that suits their personality and taste or providing their own set of images for display. All thumbnail images must be in a predefined digital format, which can be created using an image manipulation tool such as Photoshop or GIMP. Besides a random layout of individual thumbnail images, several thumbnail images may be structured to compose a single composite image as in a mosaic, where each thumbnail image contributes a portion to some larger image. Figure 2 illustrates the Sea & Shore theme, where all 30 thumbnail images in the display area form a single contiguous image.  4   Figure 2: Sea & Shore Theme  Image Selection A perplexing problem faced in Picture Password was ensuring that its password space would be comparable to that of alphanumeric passwords. The size of the image matrix limits the effective alphabet size to only 30 elements, assuming a one-to-one mapping, which in turn results in weak passwords. For example, an eight-entry image sequence, the number of possible password strings would be only 308. Therefore, several ways to increase the alphabet size were considered. They included allowing passwords to be composed with thumbnail elements from all of the three available themes (90 elements total) and providing more images per theme, by either using smaller-sized images, or adding a feature to zoom up larger composite images from each thumbnail image. Each of these approaches had serious drawbacks. Using thumbnail images from all three themes would require more difficult navigation for the user. A denser set of images would mean less tolerance for selections and a higher rate of input errors. Zooming up a thumbnail image to a larger composite image would require more user interaction when selecting images and greater complexity in creating and handling themes. The main criterion for selecting among various alternatives was to maintain the simplicity of the user interface, keeping it as easy to use as possible. Our solution was to add a second method or style for choosing thumbnail elements. Besides selecting individual thumbnail elements as before, one could now select two thumbnail elements together to compose a new alphabet element. The concept is akin to using a shift key to select uppercase or special characters on a traditional keyboard, but in this context each thumbnail element serves as a shift key for every other element, including itself. With this addition, the resulting alphabet size expands from 30 elements (i.e., singly selected keys) to 930 elements (i.e., 30 singly selected keys plus 30 x 30 composite keys), which compares favorably to the 95 printable ASCII characters available from a traditional keyboard. Several ways exist to select a pair of 5   buttons and link them in composing an alphabet element. Drag-and-drop is perhaps the most obvious method, but not typically supported by all handheld device windowing systems. Another, more generic selection method is choosing the first thumbnail image by picking and holding the stylus there, highlighting the selection, and then completing the pair by picking the second button image in the normal fashion. Having someone observe the user entering a password and using that information to gain entry is a concern with any password system. Fortunately, the screens of PDAs and most handheld devices have a narrow viewing angle. That property, combined with their small size, makes it relatively easy to shield data entry with one's body. Nevertheless, observation is a concern. As a safeguard, Picture Password gives users the option to have images shuffled automatically between authentication attempts, where appropriate. Supporting two different styles of selection also is a safeguard, since it makes it difficult for an observer to glean both the entire image sequence and the selection style for each image in the sequence.  Password Formation and Reuse Organizational policies typically require users' passwords to expire and be changed completely after some period of use. This practice keeps a persistent intruder from cracking a password over some indefinite lifetime of use. Though effective, password expiration is also a nuisance for the user, who follows this practice on numerous systems and accounts, and continually must forget old and memorize new passwords. The user would instead prefer to continue using the same image sequence indefinitely. One solution for password reuse is to allow the same image sequence to be used after it expires, but have the image sequence generate a completely new password value. By decoupling images from alphabet, numerous distinct mappings between those respective sets of elements are possible. To enable password reuse, the authentication mechanism has only to select a mapping that results in a different password value to be generated for the same image sequence. As shown in Figure 3, during initial enrollment or a subsequent reenrollment, for each thumbnail element of the image matrix, Picture Password randomly assigns a distinct value from the full range of possible alphabet values to form a value matrix with the same dimensions. While the set of image elements is fixed at 30, the set of basic alphabet values from which the 30 needed are drawn can be significantly larger. Thus, the elements of the value matrix contain the basic alphabet used to compute the password, but are independent from the image matrix. The mapping of thumbnail element to value element remains constant from one authentication attempt to another and changed only during reenrollment. Because values are randomly associated with each thumbnail element of the image matrix during reenrollment, selecting the same theme and sequence of thumbnails repeatedly should produce a completely different password value. As an added measure, mappings that produce the same password value as the one previously enrolled can be rejected during reenrollment.  6   Figure 3: Image and Value Matrices  The sequence of thumbnail elements selected by the user in either an enrollment or authentication attempt governs password formation. The mapped value of a single image selection can be directly applied, while the two mapped values of a paired image selection must first be composed into a single value. For example, if single-byte, non-zero, unsigned integers comprise the set of 30 basic alphabet values, a single image selection could be the pair of bytes (0, VMj), and a paired image selection could be the pair of bytes (VMk, VMj), where VMj represents either the alphabet value in the value matrix for a single image selected or the first image selected in a paired image selection, and VMk represents the alphabet value for the second image in a paired image selection. Once the thumbnail images for an image sequence have their alphabet values resolved, those values are concatenated together, in the sequence the images were selected, to form the clear text password. Picture Password then applies a one-way cryptographic hash to the resulting string iteratively to form the password. The NIST Secure Hash Algorithm (SHA) is used to compute the cryptographic hash and results in a 20-byte binary value. The number of iterations to apply the hash algorithm is controlled by a variable to allow the work effort to be adjusted to the level of security needed. The user's password is never maintained in unencrypted form on the device. Instead, only the hash result is retained during enrollment and used later during verification to compare against the hash result from any subsequent authentication attempt. While a visual login technique by its very nature avoids dictionary attacks associated with textual passwords, it may be possible for an intruder to compile commonly used set of image selections (e.g. location-based sequences such as the four corners or main diagonal of the image matrix) and use them in an attack. As a countermeasure to an intruder directly applying a dictionary of commonly used passwords, the clear text password value may be prepended with a random value, commonly referred to as a salt, before the hash is iteratively applied. This step significantly increases the work factor for the intruder, in relationship to 7   the size of the salt value that is used and whether both a public and a secret salt are involved [Man96, Aba97]. One additional use for the value matrix is to hold individual salt values for each element of the basic alphabet. Rather than prepending the resulting clear text value of the password with a collective salt value, salting can be done continuously as entries in the value matrix are used to generate a password value. This method of salting takes advantage of any unused memory within the value matrix, in situations where the memory allocated for each value matrix element is sufficient to hold both an alphabet value and its associated salt value. Otherwise, additional memory can be allocated to hold the salt component, which can be treated simply as the prefix of an alphabet value. Each time a new password is enrolled, the salt components are populated with random values. This procedure, in effect, creates a new way of salting the password through the embedding of salt values within the alphabet value entries of the value matrix.  Password Strength As mentioned earlier, with 30 thumbnail images to choose, the effective size of the alphabet is 930, (30 + (30*30)). Passwords formed with so large an alphabet space are quite strong. Thus, 7-entry long passwords have 9307 possible values for a password space of approximately 6.017009e+20, which is an order of magnitude greater than that for 10character long, alphanumeric passwords formed from the 95 printable ASCII character set, which is 9510 or approximately 5.987369e+19. The general strength relationship between visual passwords formed from a 30-element matrix versus textual passwords formed from the 95 printable ASCII characters is approximately Npp = 2/3 * Ntp , where Ntp is the required character length for textual password input, Npp is the corresponding input sequence length required for Picture Password, and x is the ""ceiling"" function. In simple terms this means that image sequences formed with dual selection styles require approximately one-third less length than that of a traditional alphanumeric password. This presumes, of course, that just as additional keystrokes are needed to select special and capital characters on a keyboard, a comparable number of additional strokes are used when forming an image sequence involving paired image selections. Table 1 gives a comparison of input lengths between the two mechanisms for a range of sizes of password elements. Note that the values in the table presume that just as additional keystrokes are needed to select special and capital characters on a virtual keyboard, a comparable number of additional strokes are used when forming an image sequence involving paired image selections. Table 1: Input Length Comparison  Textual Password Length Image Sequence Length  6 4  7 5  8 6  9 6  10 7  11 7  12 8  8   Mechanism Protection Picture Password relies primarily on two forms of authentication information: the cryptographic hash of the password string computed from the enrolled image selection, and the value matrix that maps selected thumbnails to their underlying alphabet values, each containing an embedded salt. The confidentiality and integrity of both pieces of information must be protected by the underlying operating system. At a minimum, this information is safeguarded through strict file access control settings. However, should read access to this information be gained somehow, the authenticating image sequence is inherently resistant to discovery, requiring a difficult and exhaustive brute force effort to uncover. Access controls alone may not provide sufficient protection for all handheld device environments. Other, more subtle, ways exist that an intruder might use to foil the authentication mechanism. The following items list some common threats that should be safeguarded against to minimize the possibility of a successful attack on an implementation of Picture Password:  Personnel Information Management (PIM) or other applications that run as root by default may be exploited as a potential avenue for gaining access to the authentication information, as well as other information. Program binaries may become compromised and replaced with Trojan versions that capture user input or intermediate clear text forms of the password. Program interfaces, system resources, and device interfaces may be manipulated to cause the mechanism to be bypassed completely or to fail in a way such that it does not perform the password computation procedure correctly and is compromised. Spoofing may be used to grab user input either when images are being selected or when the image sequence is being handled. Savaging or sniffing may be used to obtain user input either when images are being selected, when the image sequence is being handled, or after the authentication mechanism terminates execution.        Implementation Picture Password was implemented in C++ for a Linux iPAQ PDA, and for the Open Palmtop Integrated Environment (Opie), an open source implementation of the Qtopia graphical environment of TrollTech. The design of the authentication solution involves three main types of components: kernel modifications, authentication handlers, and user interface (UI) components. Figure 4 illustrates the different parts of the solution and the flow of data between them. Note that the design supports multiple authentication mechanisms running in series, whereby each mechanism comprises a matching pair of user interface component and authentication handler. The discussion in this section, however, focuses solely on operating a single authentication mechanism, Picture Password.  9   Figure 4: Design Overview  The responsibility for determining when authentication is required, by monitoring sleep/wakeup events and signals from the Opie plug-in module, falls to the kernel. The Linux kernel was patched to initiate user authentication through a set of registered authentication handlers each time the device is rebooted or powered on, starting and suspending each handler in sequence as needed. The kernel was also modified to block the I/O ports on the device and lock down other means to bypass the authentication process until the user successfully completes authentication. One byproduct of these modifications is that the power key also takes on the role of a trusted path mechanism for asserting the authentication mechanism user interface. The kernel patches needed to support device lockdown were developed earlier as part of a general scheme to enforce corporate policies on handheld devices [Jan03]. Policy controls restrict access to authentication information to the appropriate handler and also prevent the code for the plug-in, user interface components and handlers from being deleted or replaced. The policy controls apply equally to both root and non-root processes, and also encompasses all communications and peripheral attachment interfaces. Another kernel enhancement periodically checks whether the authentication handlers are running, and restarts them if they were terminated, which makes the implementation quite robust and able to accommodate failure conditions that might otherwise cause the authentication mechanism to malfunction or be bypassed. The user interface for an authentication mechanism is implemented as a component within a plug-in module developed specifically for Opie. As the name implies, the function of the user interface component is to interact with the user under the control of its associated handler. For example, in Picture Password, the user interface displays the image matrix and obtains the image sequence entered by the user, which it returns in a response to the handler. The plug-in module supports a socket interface to receive commands from the authentication handler 10   components that run as separate processes, and route the commands to the correct user interface component within the plug-in. Similarly, the reverse response process is also supported between components and the module. Communication between the plug-in module and the various user interface components is done using Qte's signal and slot facility. The user interface module, as a plug-in to the desktop environment, is loaded automatically by Opie upon system boot up and share its address space. Handlers embody the core mechanism that performs the actual authentication. They interact with the user interface components to tell them to bring up the specific screens, accept input, display messages, etc. Handlers also have responsibility for interactions with tokens, smart cards, the file system, etc., needed to perform the authentication. In the case of Picture Password, the handler has exclusive access to a file containing the theme identifier, value matrix, and the password hash, which it uses to enroll a user's password and to verify authentication attempts. Handlers communicate with the kernel module, listening when to initiate authentication, and reporting if the authentication was successful. The process startup and synchronization among components proceeds as follows:  On system boot-up, the kernel loads and enforces its default policy, which blocks I/O ports on the device, hardware keys, and access to the authentication handler's code, as well as restricts access to authentication information within the file system exclusively to the appropriate authentication handler. The Linux proc file system (/proc) provides a communication channel between user space processes (UI components and handlers) and the kernel module. The kernel registers a file in the /proc file system for user space processes to trigger actions in the module. The system startup script tells the kernel (through the /proc/policy file) the filenames of the handler and any other related programs that need to be active. The kernel sees that the handler programs are not running and starts them. Upon startup, each handler program performs all necessary initialization and then reads from the /proc file entry, which causes their execution to be suspended. Opie and its plug-ins are also loaded during boot-up. The UI plug-in module signals the kernel via the /proc file entry that the device should be locked and retrieves the list of registered handlers with which it can communicate. At this point all the components of the system are running and the default set of least privileges are being enforced. The kernel wakes up the first authentication handler, Picture Password, to resume processing. The Picture Password handler reads the authentication information from the file system and signals its user interface component via a socket interface with the identity of the theme to display. 11               The user interface component displays the theme, accepts the image sequence, and returns that information to the handler. The handler uses the image to alphabet mapping to compute and verify the password. If the authentication attempt is successful, it reports success to the kernel module via the /proc interface and removes the authentication window from the screen. If unsuccessful, it continues to use the user interface component to have the user retry until a successful authentication is completed. When the kernel receives an indication of success from the handler, it suspends it, and initiates any other registered handlers. If this is the last handler, the kernel unlocks the device.    Picture Password has also been ported to the Pocket PC 2002 operating environment. For this implementation, existing procedures and interfaces for substituting a custom password mechanism for the default alphanumeric password mechanism could be followed [Mic03]. The main differences from the Opie/Linux implementation are that a single Windows applet module embodies both the user interface and handler portions of Picture Password; the programming interface takes care of storing and checking password values and asserting the mechanism at power on; and some device registry settings are used in addition to the information kept within the file system.  Related Work United States Patent 5,559,961 [Blo96] describes a system and method for applying graphical passwords. Rather than using a distinct matrix of thumbnail images as in Picture Password, the mechanism displays the image areas or cells that make up a single graphical image. The user selects predetermined areas of an image in a correct sequence, as a means of entering a password. The password is composed during enrollment by allowing the user to position selected cells from the image in a location and sequence within the display interface. The mechanism stores the sequence of cells from the image as a password. The cells are removed from the display when enrollment is completed, leaving only the original image. No discussion is given of how the image cells are used to form a password value or the security of the purposed scheme. One drawback appears to be that the cells, which in effect form the alphabet for composing a password, offer a significantly smaller sized alphabet than that available for both alphanumeric passwords and Picture Password. Draw-a-Secret (DAS) [Jer99] is a scheme for graphical password selection and input, targeted for PDAs. The user draws a design on a display grid from the interior of one cell to another, which is used as the password. Each continuous stroke is represented as the sequence of cell grids encountered. Strokes can start anywhere and go in any direction, but must occur in the same sequence as the one enrolled for the user. The size of each cell must be sufficiently large to allow the user a degree of tolerance when drawing a graphical password. Each continuous stroke is mapped to a sequence of coordinate pairs by listing the cells through which it passes, in the order in which the stroke traverses the cell boundary. The grid sequences for each stroke that composes a drawing are concatenated together in the order they were drawn to form a password. The size of the password space for graphical passwords 12   formed using this scheme was shown to be, generally speaking, larger than that of textual passwords. Let-Me-In, an example password replacement mechanism from Microsoft, works in a similar fashion to DAS, using a grid of points rather than distinct cells, whereby the user enters a pattern of connecting grid points to form a password [Mic03]. While the example was done mainly to illustrate how to implement a replacement mechanism within the Pocket PC environment, it also suggests an alternative user interface that could be used for the DAS framework. Dj Vu, a project at the University of California Berkeley, also involves using a set of images for user authentication [Dha00]. Rather than using real-life images, abstract images are generated randomly using a hash visualization technique [Per99]. During enrollment, the user selects a set of images that makes up his authentication base. A training phase is then used to improve a user's recognition of the abstract images within his authentication base. The authentication mechanism is an n-out-of-m recognition scheme, whereby the user must identify a selection of the images from the authentication base when presented to him within a much larger challenge set containing decoy images. A trusted server stores the authentication base for each user and provides the challenge set for each attempted user authentication, which make this scheme unsuitable for handheld devices, which may have only intermittent network connectivity. The server must be tightly secured to guard the confidentiality of the authentication information or the scheme fails entirely. To counter shoulder surfing, different sets of images, both legitimate and decoy, may appear in random positions of the display for each authentication attempt. Passface, a commercial user authentication system from Real User, is a challenge-response mechanism somewhat similar to Dj Vu, but uses the faces of individuals instead of abstract images [Rea01]. A commercial product called visual Key [sfr00], from sfr GmbH in Cologne Germany, uses cells of a single predefined image as the password elements. The visual Key software forms a selection matrix by dividing a single image into cells and dynamically adjusting the grid so that cell centers align with the touch point during selection. A user must select a specific sequence of cells from the display to be granted access to the device. The strength of the password depends on the number of cells that make up the image, since they are used to determine the range of the password alphabet. Approximately 85 distinct cells with a size of 30 x 30 pixels can fit on a standard size 240 x 320 pixel display of a PDA, which results in an alphabet size smaller than the 95 printable ASCII characters available with both alphanumeric passwords and Picture Password. Cells comprised of 30 x 30 pixels or less are a bit small, which can contribute to selection errors. Another drawback is that during selection the cells are not made visible, requiring user to remember which part of an object in the image to select (e.g., the upper left corner of a door or window), if the object encompasses more than one cell. In contrast, Picture Password uses distinct buttons 40 x 40 pixels in size, instead of cells, so that user selections are clearly registered, making it more likely that the user enters the password quickly and correctly on the first attempt. PointSec for Pocket PC is a commercial product that includes several authentication-related components that can be managed centrally [Poi02]. PicturePIN is a graphical counterpart to a numeric PIN system that uses pictograms rather than numerics, for entering the PIN via a keypad-like layout of 10 keys. The symbols, which can be tailored, are intended to form a mnemonic phrase, such as the four-symbol sequence of - men / - love / - to listen / 13   to music. The sequence of symbols can be between 4 and 13 symbols long, and to increase security against ""shoulder surfing,"" the symbols are scrambled at each login. As an added usability feature, QuickPIN enables fast access to mobile devices within a specified number of minutes, between 30 and 300 seconds, after last power off. QuickPIN relies on a minimum of two pictogram symbols to allow users access to their PDA. Both the PicturePIN and QuickPIN systems can be set to lock out a user after three to an infinite number of unsuccessful attempts. PicturePIN is somewhat similar to Picture Password, but supports only a limited alphabet size and a single selection style, making it a far less powerful mechanism in and of itself. Moreover, Picture Password can be configured with themes composed of pictogram symbols to support mnemonic password phrases. SafeGuard PDA is another commercial product whose Symbol PIN authentication option works very similarly to PicturePIN and with similar limitations [Uti03].  Summary Picture Password is a visual login technique that matches the capabilities and limitations of most handheld devices and provides a simple and intuitive way for users to authenticate. Besides user authentication, Picture Password may also be used in other security applications where conventional passwords have been used traditionally. For example, password-based encryption, whereby a password value is transformed into a cryptographic key suitable for encrypting files or other information could rely on keys derived by the image selection technique of Picture Password. The mechanism is relatively straightforward and flexible, and one that is suitable for many users, organizations, and types of devices. The approach provides a simple and hopefully entertaining way for users to authenticate to a device, which should remove much of the burden associated with employing an authentication mechanism. Moreover, with style dependent image selection, password reuse, and embedded salting, the mechanism is superior to using traditional ASCII passwords of comparable length. While the solution is particularly well suited for handheld devices, Picture Password can also be used in a wide range of platforms, from appliances having single embedded processors, to large-scale multi-processor computers.  References [Aba97] Martin Abadi, T. Mark A. Lomas, and Roger Needham, Strengthening Passwords, SRC Technical Note 1997  033, digital Systems Research Center, December 1997. Greg E. Blonder; Graphical password, US Patent 5559961, Lucent Technologies Inc., Murray Hill, NJ, August 30, 1995. Rachna Dhamija and Adrian Perrig, Dj Vu: A User Study Using Images for Authentication, Proceedings of the 9th Usenix Security Symposium, August 2000. Alvin Goldstein and June Chance, Visual Cognition for Complex Configurations, Perception and Psychophysics, 9, 1971, pp. 237-241.  [Blo96] [Dha00] [Gol71]  14   [Jan03]  Wayne Jansen, Tom Karygiannis, Michaela Iorga, Serban Gavrila, and Vlad Korolev, Security Policy Management for Handheld Devices, The 2003 International Conference on Security and Management (SAM'03), June 2003. Ian Jermyn, Alain May, Fabian Monrose, Michael Riter, and Avi Rubin, The Design and Analysis of Graphical Passwords, Proceedings of the 8th USENIX Security Symposium, August 1999. Kingpin and Mudge, Security Analysis of the Palm Operating System and its Weaknesses Against Malicious Code Threats, USENIX Security Symposium, August 2001. Daniel Klein, Foiling the Cracker: A Survey of, and Improvements to, Password Security, 2nd USENIX Unix Security Workshop, August 1990, pp. 5-14. Jennifer 8. Lee, And the Password Is . . . Waterloo, The New York Times, Circuits, Thursday, December 27, 2001, Late Edition - Final, Section G, Page 1, Column 1,  . Udi Manber, A Simple Scheme to Make Passwords Based on One-Way Functions Much Harder to Crack, Computers & Security, 15(2), 1996, pp. 171-176. Let Me In: Pocket PC User Interface Password Redirect Sample, Microsoft Knowledge Base Article  314989, Microsoft Corporation, July 2003,  . David Melcher, The persistence of visual memory for scenes, Nature, 412(6845), p. 401(July 2001). Robert Morris and Ken Thompson, Password Security: A Case History, Communications of the ACM, Vol. 22, No. 11, November 1979, pp. 594-597. Adrian Perrig and Dawn Song, Hash Visualization: a way to improve real world security, International Workshop on Cryptographic Techniques and E-Commerce, CrypTEC '99, 1999. Pointsec for Pocket PC, Pointsec Mobile Technologies, November 2002,  . The Science Behind Passfaces, Document Revision 2, Real User Corporation, September 2001,  . visual Key  Technology, sfr GmbH, 2000,  . 15  [Jer99]  [Kin01]  [Kle90] [Lee01]  [Man96] [Mic03]  [Mel01] [Mor79] [Per99]  [Poi02] [Rea01]  [sfr00]   [Spa92] [Uti03]  Eugene Spafford, OPUS: Preventing Weak Password Choices, Computers & Security, Vol. 11, No. 3, May 1992, pp. 273-278. SafeGuard PDA, Utimaco Safeware AG, March 2003,  .  16"
GX016-82-9730407	"NIST Form-Based Handprint Recognition System     The Image Group in ITL’s Information Access Division has been distributing public domain handprint recognition software since 1994.  Release 2 of the NIST Form-Based Handprint Recognition System was made available in 1997, and since that time, over 700 copies have been shipped all around the world.    In July 2000, a new release (2.1), was made available which includes updated and more robust numerical methods used to perform eigenvector-based feature extraction, and additional compilation scripts that support GNU ""gcc"" and ""gmake"" ( www.gnu.org ) and are targeted, but not limited, to the Linux operating system ( www.linux.org ).  This release may also be compiled to run on computers running the family of Win32 operating systems by first installing the Cygwin library and associated port of GNU tools (sourceware.cygnus.com/cygwin).    NIST announced this new release to previous software recipients on July 7, 2000, and within one week, nearly 100 requests were received, with half from US-based industry and universities, and half international.  After 6 years, the interest in this NIST software remains high.  It is available free of charge on CD by emailing a letter of request to Michael Garris (mgarris@nist.gov).    CONTACT:  Michael Garris, ext. 2928."
GX024-29-16331751	"DOE2000 Electronic Notebook Project Summary     Project:  DOE2000 Electronic Laboratory Notebooks   Development Partners: ORNL, LBNL, PNNL           Table of Contents     Introduction   Purpose   Approach   Progress     DOE2000 Notebook Framework   Notebook Implementations     EMSL Electronic Laboratory Notebook   Platform Support   Features     Work in Progress     Plans   Resources          Introduction     Laboratory notebooks are at the heart of scientific research. They contain plans, data, and the interpretation of data, providing a record of the experiment process. Notebooks allow researchers to plan their projects and organize their experiments. Aiding a researcher, or research group, in this manner is one of the notebooks primary functions. A second primary function is to be a long term, legally defensible, record of the research. Ideally, it provides enough information to allow an experiment to be duplicated ab initio, and is a resource to plan future projects. The signed and time-stamped details provided in notebooks become evidence that work was done and that the conclusions reached are well founded. A good notebook strikes a balance between utility for the researcher and utility for the organization.   Electronic Laboratory Notebooks (ELNs) are digital analogs of paper notebooks. ELNs are designed to serve the same purposes as paper notebooks, with improved functionality. ELNs offer a variety of advantages in terms of:      group use (multiple simultaneous users, users at multiple locations),    organization (searching, hierarchical organization in chapters, subchapters)    multimedia (displaying text, images, zoom-able graphs, rotatable molecular structures, etc.),    process integration (entries can be made directly by instruments, and from within analysis, visualization, and office applications)    workflow (email or other notification of new entries, requests for witnessing, automatic collection and archiving, etc.)    While ELNs are more complex than pencil and paper, they are still relatively simple to use. They also have many benefits relative to paper notebooks. Typically, text entries are typed or cut-and-pasted from other applications. Advances in handwriting and voice recognition may soon improve this. Images can be captured directly from the computer screen (or scanned in), replacing the print-and-tape cycle for paper notebooks. Files can be imported directly and displayed in easily understood forms. For instance, files that list the coordinates of the atoms in a molecule can appear in the notebook as 3D molecular visualizations. Sketches can be entered using a mouse or graphics tablet. Links can be made from instruments allowing automated entries as data is taken and to analysis software allowing the analysis software to be started and loaded with the current data with a click on the relevant notebook entry. The Table of Contents, and search indexes can be automatically generated. Entries can be signed, witnessed, and time-stamped automatically according to policy.   Most of the advantages mentioned above accrue to the researcher and his/her group; the effort required to create, share, and search an ELN is much less than for the paper notebook. Additional benefits accrue to the organization, in terms of records management. The multimedia capabilities of an ELN, and the possibilities for automatically generating notebook entries during experiments promise to increase the accuracy and completeness of ELNs relative to paper notebooks. Automated indexing should make searching archival notebooks faster and more effective. Routing ELNs is more efficient than with paper and storage less costly. Public key based digital signatures and time-stamps provide an improved foundation for defending the creation date/time and authorship of ELN entries. Together, these features represent significant cost savings for ELN management compared to paper notebooks.   (return to top)        Purpose      Laboratory notebooks are at the heart of scientific research, which allow researchers to plan their projects and organize their experiments.  Aiding researchers on a day-to-day basis is one of the notebooks primary functions. A second primary function is to be a long term, legally defensible, record of the research. The signed and time-stamped details provided in notebooks become evidence that work was done and that the conclusions reached are well founded. An ELN needs to be a seamless part of the experimental process.     The goals of the project are to:      Develop flexible mechanisms to integrate the ELN with Problem Solving Environments (PSE), open data/metadata management systems, scientific workflow systems, and other Grid applications.   Further investigate the issues in using ELNs as official, legally-defensible records and develop records management functionality   Investigate and prototype the use of mobile devices for notebook input and display.     Investigate informatics-based approaches to organizing, searching, and summarizing data and notes in 106+ entry notebooks to support high-throughput research    Iteratively deploy new ELN versions that incorporate features from the above research and that enhance the overall usability, security, and functionality of the ELN to continue engaging the research and education communities in the development and use of electronic notebooks      (return to top)         Approach      The DOE2000 Electronic Notebook project has been tremendously successful in developing the concept of electronic notebooks and in demonstrating their utility in research and education. The benefits of an ELN, including enhanced collaboration, automation of data entry, and more complete, multimedia research records, are being realized by a rapidly growing, enthusiastic, and diverse user base. However, PNNL has identified a variety of areas for research and development that are necessary for ELNs to fully replace paper notebooks and for ELNs to evolve to support new trends in research including high-throughput methodologies and the increasing role of computational modeling in science.    New technologies and standards that have developed during the last 3 years make it possible to address these issues and to develop a new generation of advanced Electronic Notebooks. The maturation of Java, CORBA, and the Web, and the emergence of standards such as XML, and WebDAV provide a ubiquitous, cross platform, multimedia, and development environment. Resource management, communications, and security technologies being developed in companion DOE2000 R&D projects, the growth of Grid technologies and standards, and advancing commercial technologies for secure communications, digital signatures, and document management provide a powerful base for the development of advanced ELN capabilities. Further, the success of current electronic notebooks has helped create an interested and active community that is providing requirements for advanced capabilities and developing national standards for the use of ELNs as legally defensible records.   Our efforts to develop an Advanced ELN will be based on the current PNNL ELN and DOE2000 electronic notebook standards. We will continue to work with users at the national laboratories, in academia, and industry, to refine the requirements for an Advanced ELN. The project will continue its membership in the Collaborative Electronic Notebook Systems Association (CENSA), a consortium of chemical, pharmaceutical, and software companies promoting electronic notebook technologies and will work with existing and new partners developing GRID, PSE, informatics, and other relevant technologies to investigate the research issues cited above and to both leverage and assure compatibility with other scientific software developments.  This project will significantly advance the state-of-the-art in electronic notebooks and should serve as a new baseline, in both design and functionality, for future Electronic Notebook research efforts.      (return to top)        Technical Progress        ELN Framework   DOE2000 ELN Framework: Working with partners at Lawrence Berkeley and Oak Ridge National Laboratories, we have defined a DOE200 Electronic Notebook Framework.  The object definitions, application programming interfaces (APIs), data formats, and components currently available are described here.        Notebook Object (NOb) Definition -- Notebook Object (NOb) Definition: We have defined an extensible data object that is used by all DOE2000 notebooks. Standard meta-data such as author, creation date/time, MIME type of the data, etc. are defined as required fields. New meta-data fields can be defined as needed. Both Perl and Java implementations of NObs exist.     Notebook Archive MIME Transport and File Format : Notebook Objects can be transferred via http, email, or as files using a MIME-based DOE2000 standard definition. This allows data to be exchanged between any two DOE2000 compliant notebook systems.    Editor API  - We've created an application interface that all the notebooks use to allow end users to generate editors and insert them into the system. This interface allows for dynamic additions of new editors to any DOE2000 compliant notebook.      Available Editors : PNNL has developed several basic editors that implement the DOE2000 Editor API. Some were developed from scratch. Others were developed by wrapping existing applications/applets/components.    Text    HTML    File Upload    Image Capture (wrapped form of the EMSL Televiewer screen capture utility)    Rich Text (wrapped form of the Chemical Publisher, developed by Chris Parkinson, PNNL)    LaTeX Equations (wrapped for of the HotEqn applet from the  Virtual Control Lab )   Whiteboard (wrapped, single user version of the  NCSA Habanero  whiteboard )   Forms (User defined HTML forms for repetitive entries)       Signing Format:   PNNL has developed a digital signature format for using Entrust Certificates to digitially sign NObs   Viewer API (PNNL Standard Only) : Viewers for more than 18 file types have been developed/integrated with the ELN, including viewers for molecular structures, spreadsheets, rich text, nuclear magnetic resonance parameter lists, and an XY Graph viewer from the Diesel Combustion Collaboratory.    (return to top)         Notebook Implementations:   Details concerning the ORNL and LBNL notebook implementations are available as links from the  DOE2000 Electronic Notebook Website         EMSL DOE2000 Electronic Laboratory Notebook (ELN) The ELN has been well accepted by scientists and researchers around the country. Over 400 users from academia, government, and industry have registered for the ELN. The Environmental Molecular Sciences Laboratory (EMSL) Collaboratory already hosts more than 25 notebooks supporting the research of EMSL staff and users. Notebooks are also being used to support education projects by a variety of organizations and as simple personal notebooks. For example, a National Science Foundation-supported partnership, managed through Northwestern University's Department of Chemical Engineering, is using PNNLs ELN to link with industrial partners.  Six major corporations, including Allied Signal and Dow Chemical Company, are using 20 copies of the ELN to maintain a record of their research and support close interactions between graduate students at Northwestern and their industrial mentors. The EMSL's Virtual Nuclear Magnetic Resonance (NMR) Facility is using both the ELN and its programming interfaces to provide custom NMR Spectroscopists notebooks that accept data sent directly from the NMR spectrometer software and display NMR specific data such as protein structures.         The PNNL notebook implementation consists of several components:      ELN Interactive Web Client    ELN Server    ELN Wizard (scriptable, semi-automated data entry)    ELN Editor and Viewer Software Development Kits - SDKs for creating editors and viewers for the notebook. There is example code that compiles and runs and documentation for wrapping current code into an editor and/or viewer.   ELN Website: Download/Help/FAQ/Documentation: The EMSL Collaboratory website supports fully automated registration and download of ELN components. Live links to EMSL hosted notebooks are also available. A support form linked to the EMSL Collaboratory support queue allows users to get personal help using the notebook or setting up servers. The notebooks themselves contain links to online help, FAQ's, and other documentation on our web site.  Import/Export: allowing for sections of the notebook or any compliant notebook implementation to share and move data.   ELN Website: Download/Help/FAQ/Documentation : The  EMSL Collaboratory website  supports fully automated registration and download of ELN components. Live links to  EMSL hosted notebooks  are also available. A support form linked to the EMSL Collaboratory support queue allows users to get personal help using the notebook or setting up servers. The notebooks themselves contain links to online help, FAQ's, and other documentation on our web site.    (return to top)         Platform Support      ELN Client, SDKs:     Any platform using Netscape 4.51+  (tested on Solaris, Irix, Linux, MacIntosh and Windows 95/98/NT)     Image Capture Utility:   256 color capture utility available for SunOS 4.11, Solaris/Sparc, Irix, or Windows 95/98/NT    ELN Server:   Netscape and Apache servers on Unix and Windows 95/98/NT (tested on Solaris, Windows 98/NT)   Note : Requires Perl 5      ELN Wizard:  Programmatic interface for automating notebook entries from instruments, analysis tools, and office programs   (return to top)         Version 4.11 features:   ELN Client:   Local client with one-click install - for fast access to notebooks    Signed applet version always available   Digital Signatures capabilities and secure access using SSL and Entrust Certificates    Integrated ELN with problem solving environment (e.g. ECCE), laying the foundation for Collaborative Problem Solving Environments   Default Entry Editors:   Text    HTML    Rich Text   Screen Image Capture    File Upload   LaTeX Equations   Whiteboard/Sketchpad     Default Entry Viewers:    Text   HTML   Rich Text   GIF (includes whiteboard output), JPG   LaTeX Equations   MS Office files (Word, Excel, etc.) (Viewer consists of a clickable icon that can launch the local application - we cannot view Office files directly)    Spreadsheet Comma Separated Value files (displayed as HTML table)    Protein Structures (Brookhaven PDB format)    Molecular Structures (XYZ format) (new viewer displays bonds)    NMR Parameters (Varian file format)   Mass Spectroscopy XY Graphs (PNL file format)     Hierarchical storage (chapters/pages/notes) - organize your thoughts the way you would like to    Dynamic Table of Contents      expand and collapse chapter and page contents (as in a file system browser)    easily work with larger notebooks      Import/Export sections of the notebook to and from local files that can be emailed to colleagues    Full Text Search Capability   Fully Automatic Author/Date/Time stamping of entries   Hide/display entries (to mark entries as obsolete without deleting them)    Display entries inline in the browser or as links to save space.    Delete entries (restricted to administrators)       Server:   Simplified server installation (via HTML form and install script combination)    Apache 1.3.4 support as well as Netscape Enterprise Server   Windows 95/98/NT support    Linux support   Full logging of activities (login, logout, uploads, deletes, downloads, help requests, etc.) to log file and optionally an Oracle database (query tools in development)    Web-based access control (ie. AFSWeb/DFSWeb)   Secure web server access automatic when URL is https       Editor and Viewer Software Development Kits:     Extend the notebook without recompiling - drag and drop new editors and viewers into the appropriate server directories and they are automatically available   Add support for new data types,    Utilize existing Java applets to expand your notebooks display capabilities.        ELN Wizard Interface:     Non-browser based, lightweight programmatic interface for automating notebook entries from instruments, analysis tools, and office programs (new beta available upon request) . The Wizard is a stand-alone application that accepts data for the notebook and sends it to the server - without the need for a browser or the user. The Wizard accepts all parameters from the command line or will ask the user for any necessary information not provided on the command line. The Wizard has been used to allow EMSL NMR spectrometers to send their parameters directly to the notebook, and to create Office macros for adding ""File/Save to Notebook"" entries in the Word and Excel menus.      (return to top)         Work in Progress:      Fined Grained Access Control    Support development of new editors and viewers by other projects (ie. Forms input, ...)   Edit capabilities    Various usability features/enhancements   Internet Explorer support   (return to top)         Plans:    Although the project was initially planned to end in FY2000, Electronic Notebooktechnologies are continuing to emerge, and we propose to continue to advance the overall concept of Electronic Notebooks and the underlying technologies that the ELN uses, as follows.    ELN Integration:   The process of doing scientific research is becoming ever more automated.  With the emergence of Collaborative PSEs, Grid computing, and increasing laboratory automation the ELN must provide mechanisms to integrate with other programs, services, and software agents. We propose to develop integration mechanisms in the following areas:       ELN as a Grid/Collaborative Problem Solving Environment (CPSE) Service:  Scientific applications and environments will require the ability to interact with the ELN. Based on our current work on the ELN Wizard to allow scientific instruments and data analysis programs to automatically send entries to the notebook, we propose to develop full, programming language independent, two-way capabilities for applications to interact with the notebook. This includes allowing applications to request the notebook's table of contents, submit queries, register to be notified of certain events (new analysis results entered), register as editors or viewers of specific data types, etc. We plan to work with the developers of CPSE and Grid applications to incorporate ELN functionality into their products. We also plan to demonstrate use if this interface to provide synchronized notebook browsing via integration with the separately proposed real-time collaboration multi-agent system.     ELN use of external services:  The current ELN makes use of an external directory service for storing information about authors and he DOE2000 notebook architecture defines an extensibility mechanism to support storage of the contents of notebook entries in external data management systems. The continuing maturation of commercial and research implementations of such external services is making further ELN use of external services possible. We propose to implement mechanisms for the Advanced ELN to use external security and directory services, external data and metadata repositories, event logging and collaboration services, etc. as they become available, and guided by the needs of users and developers making use of the ELN.   Emerging Standards and Technologies:   We will also continue to monitor and participate in the development of emerging notebook-enabling standards. XML, the Web Digital Authoring and Versioning (WebDAV), Open Documents Management Architecture and other standards will allow DOE2000 notebooks to take advantage of commercial components to enhance their capabilities and to integrate more effectively with other DOE2000 and commercial tools.  Where appropriate we will integrate these standards into our own designs and implementations.         Records Management Functionality:   To satisfy legal and regulatory requirements, and to protect intellectual property, users of paper laboratory notebooks follow a variety of procedures to make their notes legally defensible.  Through our involvement with CENSA, we have been helping to translate these procedures into the electronic world and to develop the functional requirements a notebook must satisfy.  We propose to extend the ELN and its digital signature capabilities (in development) to support legal records by investigating and developing functionality for:       Signed audit trails  Biometric authentication  Signature migration strategies  Records management/administration capabilities      Mobile Use:   The need for a full computer and a synchronous network connection are major drawbacks of today's electronic notebooks relative to paper notebooks.  Researchers working in the field, on travel, or simply moving around in a research laboratory, are hampered by the limited mobility and cumbersome keyboard-and-mouse focused input of today's computer-centric ELNs.  We propose to investigate mechanisms to extend the DOE2000 electronic notebook architecture and support:    Network-detachable ELNs on small, lightweight devices such as PDAs and Palmtops  Multi-modal wireless input devices - New technologies and devices for voice recognition, handwriting input, etc. Wireless reporting by instruments and sensors via personal area networks (PAN) to the ELN      High-Throughput, Informatics based notebook:   The volume of research data is rapidly growing and will require new means for researchers to organize and comprehend results.  Notebooks that present data only via a chronological or hierarchical view will not scale to support this high-throughput paradigm.  Informatics-aware notebooks will be necessary to maintain the links between large amounts of automatically generated and stored data and human generated notes, plans, and discoveries.  We propose to investigate a variety of mechanisms to support researcher's need to organize and comprehend massive amounts of data including:     Process-based notebook organization  Advanced searching  Integration with feature extraction /summary tools  Integration with reference databases      Expanding the ELN's impact on Scientific Research:  Iterative deployment of new ELN versions that incorporate features from the above research and that enhance the overall usability, security, and functionality of the ELN are vital to engaging the research and education communities in the development and use of electronic notebooks. In addition to the work outlined above, PNNL proposes to develop enhanced ELN functionality in the following areas, guided by feedback from the user community:     Usability - Usability is the key to any software system but is especially important when replacing current practices.  As Electronic Notebooks begin to replace their paper counterparts, their ease-of-use and robustness become critical.  PNNL will continue to deploy notebooks, monitor their use through automated tracking systems, questionnaires, and personal interactions with users, and use thisinformation to prioritize developments such as the addition of drag-and-drop file uploads, user preferences for editors and viewers, etc.  Security -- We will continue to refine our integration of the ELN with commercial public key certificate systems and emerging Grid security services to provide authentication, encryption, and non-repudiation (digital signatures and timestamps). We will continue to develop notebook level authorization based on accesscontrol lists (ACL), roles, or the DOE2000 Akenti service. We will also continueto define requirements for, and then implement fine-grained access control (at the level of individual notebook entries).   New hardware/software platforms -- ELNs must be available on the many hardware and software platforms used in research and education.  As these evolve, and new hardware, operating systems, web servers, etc. gain acceptance, we plan to work with partners identify important platforms and to port, test, and deploy the ELN on these new systems.  Collaboration support -- In addition to their use as research records, ELNs are emerging as important collaboration and teaching tools. Requirements for these uses often differ from those for the use of notebooks as records in areas such as editing, re-arranging, and deleting entries. PNNL plans to add ELN functionality in these areas, and to provide mechanisms for administrators to configure the ELN as appropriate for the notebook's intended use.  Enhance the range of available editors and viewers - The need for more input types and viewable data types is growing.  PNNL plans to continue expanding therange of options available and to support third-party development of domain-specific editors and viewers for the ELN.      (return to top)         For More Information, Contact:   EMSL Collaboratory Support      Disclaimer      Last updated 5 May 2000"
GX008-51-16383532	"Services         Publications          ITL Homepage        NIST Homepage          ITL Products on the Web           For more information click on the URLs below Documents, Websites on   Year 2000 Problem         Mathematical and Computational Sciences  Division  (891)        Fortran 90 Bindings for OpenGL       Guide to Available Mathematical Software   (GAMS),  a cross-index and virtual repository of mathematical and statistical software components       Java Numerics Tools            Matrix Market A repository of matrix test data for use in comparative studies of algorithms       Micromagnetic Modeling Software       NIST Sparse BLAS Sparse matrix computational kernels and source code generation service        OOF:  Object Oriented Finite Element Software for Materials Science         SciMark       Template Numerical Toolkit (TNT)           Advanced Network Technologies Division  (892)             ATM ABR Service Traffic Management Conformance Test Tool       ATM Network/ HFC Network Simulator        ATM Private Network-Network Interface (PNNI) Simulator        IPsec WWW-based Interoperability Tester (IPsec-WIT)       NIST Network Emulation Tool       NIST Integrated Services Protocol Instrument (RSVP/RTP Testing)        NIST Cerberus: An IPSec Reference Implementation              Computer Security Division  (893)            Advanced Encryption Standard for Round 2: AES CD-3, CD-ROM       Computer Security Resource Clearinghouse  (CSRC)       Common Criteria (CC), Version 2.01, ISO IS 15408         Cryptographic Modules and Algorithms:  Specifications, Tests, and Validated Implementations       National Information Assurance Partnership   (NIAP), CC Validated Products List           Information Access and User Interfaces Division  (894)            ANSI/NIST-ITL 1a-1997(pdf)       Best Practice Recommendation for the Capture of Mugshots or Facial Images       Databases for Mugshot/ Face Identification, Fingerprint Classification/ Matching, and OCR          Mugshot/Face Databases       Fingerprint Databases         NIST Form-Based Handprint Recognition System (Release 2.0)         NIST Spoken Language Benchmark Tests       Public Domain Pattern Level Classification Systems       Speech Processing Evaluations and Benchmark Tests           Spoken Language Scoring and Evaluations Software       Text REtrieval Conference (TREC) Proceedings       Translation of Deneb Robotics formats to VRML (source code)         TREC  Test Collections on CD-ROM       Webmetrics  Tool Suite       Working Model 3D Translator to VRML             High Performance Systems and Services Division  (895)        MultiKron Series of Instrumentation Boards and Toolkits Links to publications and software source code       S-Check A tool for assaying and improving performances of parallel and networked (PVM-type) programs       MPI Data-Type Tools        Web Submit           Distributed Computing and  Information Services Division  (896)          The Distributed Computing and Information Services Division provides the information technology resources, supporting infrastructure, applied research, and assistance to NIST staff, collaborators and clients for application in the conduct of scientific, engineering and administrative applications and in the dissemination of information.                Software Diagnostics and Conformance Testing Division  (897)          CGM  Version 4 Test Files         Cobol85 Test Suites        Fortran78 Test  Suites        JAVA   Conformity Assessment and Diagnostics       PHIGS Test Suites       POSIX Test Suites        RDA Test Suite       RBAC   Role Based Access Control       SQL Test Suite        Unravel Computes ""slices"" of C programs and makes it possible to reduce the effort to debug or test a program       VMView   (Java Diagnostic Tool)       VRML   Conformance Tests and Viper Reference Parser           Statistical Engineering Division  (898)          Dataplot Statistical Software       NIST/SEMATECH   Engineering Statistics Internet Handbook       StRD   Statistical Reference Datasets        Omnitab 80   Spreadsheet for Statistical Analysis       RECIPE   REGression Confidence Intervals for PErcentiles                   YEAR 2000 PRODUCTS AND RESOURCES         Documents on Year 2000 Problem      Find Date        Information on How to Compute Leap Year       Test Assertions for Year 2000        Year 2000 Reference Data              ITL Publications ,  with link to the complete list of FY 1999 ITL  publications       To Top       Date Created:  1996  Last Updated:  May 17, 2000      For further information about this web site and its contents, contact  ITL"
GX020-79-10927559	1    Introduction to Realtime Programming   A realtime application is one in which the correctness of the application depends on the timeliness and predictability of the application as well as the results of computations. To assist the realtime application designer in meeting these goals, DIGITAL UNIX provides features that facilitate efficient interprocess communication and synchronization, a fast interrupt response time,  asynchronous input and output (I/O),  memory management functions, file synchronization, and facilities for satisfying timing requirements. DIGITAL UNIX provides realtime facilities as part of the standard DIGITAL UNIX kernel and optional subsets.  Realtime applications are becoming increasingly important in our daily lives and can be found in diverse environments such as the automatic braking system on an automobile, a lottery ticket system, or robotic environmental samplers on a space station. The use of realtime programming techniques is rapidly becoming a common means for improving the predictability of our technology.  This chapter includes the following sections:    Realtime Overview,  Section 1.1     DIGITAL UNIX Realtime System Capabilities,  Section 1.2     Process Synchronization,  Section 1.3     POSIX Standards,  Section 1.4     Enabling DIGITAL UNIX Realtime Features,  Section 1.5     Building Realtime Applications,  Section 1.6                         1.1    Realtime Overview     Realtime applications provide an action or an answer to an external event in a timely and predictable manner. While many realtime applications require high-speed compute power, realtime applications cover a wide range of tasks with differing time dependencies.  Timeliness  has a different definition in each realtime application. What may be fast in one application may be slow or late in another. For example, an experimenter in high-energy physics needs to  collect data in microseconds while a meteorologist monitoring the environment might need to collect data in intervals of several minutes. However, the  success of both applications depends on well-defined time requirements.  The concept of  predictability  has many connotations, but for realtime applications it generally means that a task or set of tasks can always be completed within a predetermined amount of time. Depending on the situation, an unpredictable realtime application can result in loss of data, loss of deadlines, or loss of plant production. Examples of realtime applications include process control, factory automation robotics, vehicle simulation, scientific data acquisition, image processing, built-in test equipment, music or voice synthesis, and analysis of high-energy physics.  To have control over the predictability of an application, the programmer must understand which time bounds are significant. For example, an understanding of the  average  time it takes for a context switch does not guarantee task completion within a predictable timeframe. Realtime programmers must know the  worst-case  time requirements so that they can design an application that will always meet worst-case deadlines.  Realtime systems also use techniques to reduce the hazards associated with a worst-case scenario. In some situations, a worst-case realtime deadline may be significantly faster than the non-realtime, average time.  Realtime applications can be classified as either hard or soft realtime. Hard realtime applications require a response to events within a predetermined amount of time for the application to function properly. If a hard realtime application fails to meet specified deadlines, the application fails. While many hard realtime applications require high-speed responses, the granularity of the timing is not the central issue in a hard realtime application. An example of a hard realtime application is a missile guidance control system where a late response to a needed correction leads to disaster.    Soft realtime applications do not fail  if a deadline is missed. Some soft realtime applications can process  large amounts of data or require a very fast response time, but the key  issue is whether or not meeting timing constraints is a condition for success. An example of a soft realtime application is an airline  reservation system where an occasional delay is tolerable.  Many realtime applications require high I/O throughput and fast response time to asynchronous external events. The ability to process and store large amounts of data is a key metric for data collection applications. Realtime applications that require high I/O throughput rely on continuous processing of large amounts of data. The primary requirement of such an application is the acquisition of a number of data points equally spaced in time.  High data throughput requirements are typically found in signal-processing applications such as:    Sonar and radar analysis    Telemetry    Vibration analysis    Speech analysis    Music synthesis      Likewise, a continuous stream of data points must be acquired for many of the qualitative and quantitative methods used in the following types of applications:    Gas and liquid chromatography    Mass spectrometry    Automatic titration    Colorimetry      For some applications, the throughput requirements on any single channel are modest. However, an application may need to handle multiple data channels simultaneously, resulting in a high aggregate throughput. Realtime applications, such as medical diagnosis systems, need a response time of about one second while simultaneously handling data from, perhaps, ten external sources.  High I/O throughput may be important for some realtime control systems, but another key metric is the speed at which the application responds to asynchronous external events and its ability to schedule and provide communication among multiple tasks. Realtime applications must capture input parameters, perform decision-making operations, and compute updated output parameters within a given timeframe.  Some realtime applications, such as flight simulation programs, require a response time of microseconds while simultaneously handling data from a large number of external sources. The application might acquire several hundred input parameters from the cockpit controls, compute updated position, orientation, and speed parameters, and then send several hundred output parameters to the cockpit console and a visual display subsystem.  Realtime applications are usually characterized by a blend of requirements. Some portions of the application may consist of hard, critical tasks, all of which must meet their deadlines. Other parts of the application may require heavy data throughput. Many parts of a realtime application can easily run at a lower priority and require no special realtime functionality. The key to a successful realtime application is the developer's ability to accurately define application requirements at every point in the program. Resource allocation and realtime priorities are used only when necessary so that the application is not overdesigned.                    1.2    DIGITAL UNIX Realtime System Capabilities   The DIGITAL UNIX operating system supports facilities to enhance the performance of realtime applications. DIGITAL UNIX realtime facilities make it possible for the operating system to guarantee that the realtime application has access to resources whenever it needs them and for as long as it needs them. That is, the realtime applications running on the DIGITAL UNIX operating system can respond to external events regardless of the impact on other executing tasks or processes.  Realtime applications written to run on the DIGITAL UNIX operating system make use of and rely on the following system capabilities:      A preemptive kernel    Fixed-priority scheduling policies    Realtime clocks and timers    Memory locking    Asynchronous I/O    File synchronization    Queued realtime signals    Process communication facilities        All of these realtime facilities work together to form the DIGITAL UNIX realtime environment. In addition, realtime applications make full use of process synchronization techniques and facilities, as summarized in  Section 1.3 .                    1.2.1    The Value of a Preemptive Kernel     The responsiveness of the operating system to asynchronous events is a critical element of realtime systems. Realtime systems must be capable of meeting the demands of hard realtime tasks with tight deadlines. To do this, the operating system's reaction time must be short and the scheduling algorithm must be simple and efficient.  The amount  of time it takes for a higher-priority process to displace a lower-priority process is referred to as  process preemption latency . In a realtime environment, the primary concern of application designers is the maximum process preemption latency that can occur at runtime, the worst-case scenario.    Every application can interact with the operating system in two modes:  user mode and kernel mode. User-mode processes call utilities, library functions, and other user applications. A process running in user mode can be preempted by a higher-priority process. During execution, a user-mode process often makes system calls, switching context from user to kernel mode where the process interacts with the operating system. Under the traditional timesharing scheduling algorithm, a process running in kernel mode cannot be preempted.    A preemptive kernel guarantees that a higher-priority process can quickly interrupt a lower-priority process, regardless of whether the low-priority process is in user or kernel mode. Whenever a higher-priority process becomes runnable, a preemption is requested, and the higher-priority process displaces the running, lower-priority process.                    1.2.1.1    Nonpreemptive Kernel     The standard UNIX kernel is a nonpreemptive kernel; it does not allow a user process to preempt a process executing in kernel mode. Once a running process issues a system call and enters kernel mode, preemptive context switches are disabled until the system call is completed. Although there are context switches, a system call may take an arbitrarily long time to execute without voluntarily giving up the processor. During that time, the process that made the system call may delay the execution of a higher-priority, runnable, realtime process.    The maximum process preemption latency for a nonpreemptive kernel is the maximum amount of time it can take for the running, kernel-mode process to switch out of kernel mode back into user mode and then be preempted by a higher-priority process. Under these conditions it is not unusual for worst-case preemption to take seconds, which is clearly unacceptable for many realtime applications.                    1.2.1.2    Preemptive Kernel     A preemptive kernel, such as the DIGITAL UNIX kernel with realtime preemption enabled, allows the operating system to respond quickly to a process preemption request. When a realtime user process engages one of the fixed-priority scheduling policies, the DIGITAL UNIX kernel can break out of kernel mode to honor the preemption request.    A preemptive kernel supports the concept of process synchronization with the ability to respond quickly to interrupts while maintaining data integrity. The kernel employs mechanisms to protect the integrity of kernel data structures, and defines restrictions on when the kernel can preempt execution.    The maximum process preemption latency for a preemptive kernel is the exact amount of time required to preserve system and data integrity and preempt the running process. Under these conditions it is not unusual for worst-case preemption to take only milliseconds.                    1.2.1.3    Comparing Latency     Figure 1-1  and  Figure 1-2  illustrate the process preemption latency that can be expected from a nonpreemptive kernel and a preemptive kernel. In both figures, a higher-priority realtime process makes a  preemption request, but the amount of elapsed time until the request is honored depends on the kernel. Latency is represented  as the shaded area.  Figure 1-1  shows the expected latency of a nonpreemptive kernel. In this situation, the currently running process moves back and forth between user and kernel mode as it executes. The higher-priority, realtime process advances to the beginning of the priority process list, but cannot preempt the running process while it runs in kernel mode. The realtime process must wait until the running process either finishes executing or changes back to user mode before the realtime process is allowed to preempt the running process.  Figure 1-2  shows the expected latency of a preemptive kernel. In this situation the running process is quickly  preempted and the higher-priority, realtime process takes its place on the run queue.    Figure 1-1:  Nonpreemptive Kernel       Figure 1-2:  Preemptive Kernel                       1.2.2    Fixed-Priority Scheduling Policies     The scheduler determines how CPU resources are allocated to executing processes. Each process has a priority that associates the process with a run queue. Each process begins execution with a base priority that can change as the application executes depending on the algorithm used by the scheduler or application requirements.    The algorithm or set of rules that governs how the scheduler selects runnable processes, how processes are queued, and how much time each process is given to run is called a scheduling policy. Scheduling policies work in conjunction with priority levels. Generally speaking, the higher a process's priority, the more frequently the process is allowed to execute. But the scheduling policy may determine how long the process executes. The realtime application designer balances the nature of the work performed by the process with the process's priority and scheduling policy to control use of system resources.    If the realtime subset is installed on your system, the DIGITAL UNIX operating system supports two distinctly different scheduling interfaces: the  nice  interface and the realtime interface. The  nice  interface provides functions for managing nonrealtime applications running at nonrealtime priority level. The  nice  interface uses  the timesharing scheduling policy, which allows the scheduler to dynamically adjust priority levels of a process. You have access to the realtime scheduling interface only if you have installed the realtime subset.    The DIGITAL UNIX realtime interface supports a nonrealtime (timesharing) scheduling policy and two fixed-priority, preemptive  scheduling policies for realtime applications. Under the timesharing scheduling policy, process priorities are automatically adjusted by the scheduler. Under the fixed-priority scheduling policies (round-robin and first-in, first-out), the scheduler will never automatically change the priority of a process. Instead, the application designer determines when it is appropriate for a process to change priorities.  The realtime interface provides a number of functions to allow the realtime application designer to control process execution. In addition, realtime scheduling policies are attached to individual processes, giving the application designer control over individual processes.    POSIX scheduling policies have overlapping priority ranges: The highest priority range is reserved for realtime applications, the middle priority range is used by the operating system, and the lowest priority range is used for nonprivileged user processes. Realtime priority ranges loosely map to the  nice  priority range, but provide a wider range of priorities for a realtime process.  Figure 2-4  illustrates the priority ranges for both the  nice  and realtime scheduling interfaces.    Not all realtime processes need to run in the realtime priority range. When using the realtime interface, each process begins execution under the timesharing scheduling policy with an associated timesharing priority. The application designer determines which processes are time-critical and under what circumstances processes should run at an elevated priority level. The application designer calls P1003.1b functions to set the appropriate priority and scheduling policy.  Under the first-in first-out (SCHED_FIFO) scheduling policy, a running process continues to execute if there are no other higher-priority processes. The user can raise the priority of a running process to avoid its being preempted by another process. Therefore, a high-priority, realtime process running under the first-in first-out scheduling policy  can use system resources as long as necessary to finish realtime tasks.    Under the round-robin (SCHED_RR) scheduling policy,  the highest-priority process runs until either its allotted time  (quantum) is complete or the process is preempted by another, higher-priority process. When a process reaches the end of its quantum, it takes its place at the end of the run queue for processes that have the same priority. Processes at that priority continue to execute as long as the waiting processes are lower-priority. Therefore, high-priority processes running under the round-robin scheduling policy can share the processor with other time-critical processes.  When a process raises its priority and preempts a running process, the scheduler saves the runtime context of the preempted process so that context can be restored once the process is allowed to run again. The preempted process remains in a runnable state even though it was preempted.  For information on using priority and scheduling policy functions, refer to  Chapter 2 .                    1.2.3    Realtime Clocks and Timers     Realtime timers often schedule tasks and events in time increments considerably smaller than the traditional one-second timeframe. Because the system clock and realtime timers use seconds and nanoseconds as the basis for time intervals, the resolution for the system clock, realtime timers, and the  nanosleep  function has a fine granularity. For example, in a robotic data acquisition application, information retrieval and recalculation operations may need to be completed within a 4-millisecond timeframe. Timers are created to fire every 4 milliseconds to trigger the collection of another round of data. On expiration, a timer sends a signal to the calling process.    Realtime timers must be flexible enough to allow the application to set timers based on either absolute or relative time. Furthermore, timers must be able to fire as a one-shot or periodic timer. The application creates timers in advance, but specifies timer characteristics when the timer is set.  Realtime applications use timers to coordinate and monitor the correctness of a realtime application. Some applications may require only one per-process timer; others may require multiple timers. Each timer is created and armed independently, which means that the application designer controls the action of each timer.  The DIGITAL UNIX system clock provides the timing base for realtime per-process timers, and is the source for timer synchronization. This clock maintains user and system time as well as the current time and date. An option is also available for using a high-resolution clock (see  Section 6.1.5 ).  Clock and timer functions allow you to retrieve and set the system clock, suspend execution for a period of time, provide high-resolution timers, and use asynchronous signal and realtime signal notification.  For information on using clock and timer functions, refer to  Chapter 6 .                    1.2.4    Memory Locking     Memory locking is one of the primary tools available to the DIGITAL UNIX realtime application designer for reducing latency. Without locking time-critical processes into memory, the latency caused by paging would introduce involuntary and unpredictable time delays at runtime.  A realtime application needs a mechanism for guaranteeing that time-critical processes are locked into memory and not subjected to memory management appropriate only for timesharing applications. (In a virtual memory system, a process may have part of its address space paged in and out of memory in response to system demands for critical space.)  The P1003.1b memory-locking functions allow the application designer to lock process address space into memory. The application can lock in not only the current address space, but also any future address space the process may use during execution.  For information on using memory-locking functions, refer to  Chapter 4 .                    1.2.5    Asynchronous I/O     DIGITAL UNIX asynchronous I/O allows the calling process to resume execution immediately after an I/O operation is queued, in contrast to synchronous I/O. Asynchronous I/O is desirable in many different applications ranging from graphics and file servers to dedicated realtime data acquisition and control systems. The process immediately continues execution, thus overlapping operations.  Often, one process simultaneously performs multiple I/O functions while other processes continue execution. For example, an application may need to gather large quantities of data from multiple channels within a short, bounded period of time. In such a situation, blocking I/O may work at cross purposes with application timing constraints. Asynchronous I/O performs nonblocking I/O, allowing simultaneous reads and writes, which frees processes for additional processing.    Notification of asynchronous I/O completion is optional and can be done without the overhead of calling signal functions by using the  aiocb  data structure, providing faster interprocess communication.  For information on using asynchronous I/O functions, refer to  Chapter 7 .                    1.2.6    Synchronized I/O     Synchronized I/O may be preferable to asynchronous I/O when the integrity of data and files is critical to an application. Synchronized output assures that data that is written to a device is actually stored there. Synchronized input assures that data that is read from a device is a current image of data on that device. For both synchronized input and output, the function does not return until the operation is complete and verified.  Synchronized I/O offers two separate options:    Ensure integrity of file data and file control information    Ensure integrity of file data and only that file control information which is needed to access the data      For information on using synchronized I/O features, refer to  Chapter 8 .                    1.2.7    Realtime Interprocess Communication     Interprocess communication (IPC) is the exchange of information between two or more processes. In single-process programming, modules within a single process communicate by using global variables and function calls with data passing between the functions and the callers. In multiprocess programming with images running in separate address space, you need to use additional communication mechanisms for passing data.  DIGITAL UNIX interprocess communication facilities allow the realtime application designer to synchronize independently executing processes by passing data within an application. Processes can pursue their own tasks until they must synchronize with other processes at some predetermined point. When they reach that point, they wait for some form of communication to occur. Interprocess communication can take any of the following forms:      Shared memory ( Chapter 3 ) is the fastest form of interprocess communication. As soon as one process writes data to the shared memory area, it is available to other processes using the same shared memory. DIGITAL UNIX supports P1003.1b shared memory.      Signals ( Chapter 5 ) provide a means to communicate to a large number of processes. Signals for timer expiration and asynchronous I/O completion use a data structure, making signal delivery asynchronous, fast, and reliable. POSIX 1003.1b realtime signals include:    A range of priority-ordered, application-specific signals from SIGRTMIN to SIGRTMAX.    A mechanism for queueing signals for delivery to a process.    A mechanism for providing additional information about a signal to the process to which it is delivered.    Features that allow efficient signal delivery to a process when a POSIX 1003.1b timer expires, when a message arrives on an empty message queue, or when an asynchronous I/O operation completes.    Functions that allow a process to respond more quickly to signal delivery.          Semaphores ( Chapter 9 ) are most commonly used to control access to system resources such as shared memory regions. DIGITAL UNIX supports P1003.1b semaphores.      Messages ( Chapter 10 ) can be used by cooperating processes that communicate by accessing system-wide message queues. The message queue interface is a set of structures and data that allows processes to send and receive messages to a message queue.      Some forms of interprocess communication are traditionally supplied by the operating system and some are specifically modified for use in realtime functions. All allow a user-level or kernel-level process to communicate with a user-level process. Interprocess communication facilities are used to notify processes that an event has occurred or to trigger the process to respond to an application-defined occurrence. Such occurrences can be asynchronous I/O completion, timer expiration, data arrival, or some other user-defined event.  To provide rapid signal communication on timer expiration and asynchronous I/O completion, these functions send signals through a common data structure. It is not necessary to call signal functions.                    1.3    Process Synchronization   Use of synchronization techniques and restricting access to resources can ensure that critical and noncritical tasks execute at appropriate times with the necessary resources available. Concurrently executing processes require special mechanisms to coordinate their interactions with other processes and their access to shared resources. In addition, processes may need to execute at specified intervals.  Realtime applications synchronize process execution through the following techniques:    Waiting for a specified period of time    Waiting for semaphores    Waiting for communication    Waiting for other processes      The basic mechanism of process synchronization is waiting. A process must synchronize its actions with the arrival of an absolute or relative time, or until a set of conditions is satisfied. Waiting is necessary when one process requires another process to complete a certain action, such as releasing a shared system resource, or allowing a specified amount of time to elapse, before processing can continue.    The point at which the continued execution of a process depends on the state of certain conditions is called a  synchronization point . Synchronization points represent intersections in the execution paths of otherwise independent processes, where the actions of one process depend on the actions of another process.  The application designer identifies synchronization points between processes and selects the functions best suited to implement the required synchronization.  The application designer identifies resources such as message queues and shared memory that the application will use. Failure to control access to critical resources can result in performance bottlenecks or inconsistent data. For example, the transaction processing application of a national ticket agency must be prepared to process purchases simultaneously from sites around the country. Ticket sales are transactions recorded in a central database. Each transaction must be completed as either rejected or confirmed before the application performs further updates to the database. The application performs the following synchronization operations:    Restricts access to the database    Provides a reasonable response time    Ensures against overbookings      Processes compete for access to the database. In doing so, some processes must wait for either confirmation or rejection of a transaction.                    1.3.1    Waiting for a Specified Period of Time or an Absolute Time     A process can postpone execution for a specified period of time or until a specified time and date. This synchronization technique allows processes to work periodically and to carry out tasks on a regular basis. To postpone execution for a specified period of time, use one of these methods:    Sleep functions    Per-process timers        The  sleep  function has a granularity of seconds while the  nanosleep  function uses nanoseconds. The granularity of the  nanosleep  function may make it more suitable for realtime applications. For example, a vehicle simulator application may rely on retrieval and recalculation operations that are completed every 5 milliseconds. The application requires a number of per-process timers armed with repetition intervals that allow the application to retrieve and process information within the 5-millisecond deadline.  Realtime clocks and timers allow an application to synchronize and coordinate activities according to a predefined schedule. Such a schedule might require repeated execution of one or more processes at specific time intervals or only once. A timer is set (armed) by specifying an initial start time value and an interval time value. Realtime timing facilities provide applications with the ability to use relative or absolute time and to schedule events on a one-shot or periodic basis.                    1.3.2    Waiting for Semaphores     The semaphore allows a process to synchronize its access to a resource shared with other processes, most commonly, shared memory. A  semaphore  is a kernel data structure shared by two or more processes that controls metered access to the shared resource.  Metered access  means that up to a specified number of processes can access the resource simultaneously. Metered access is achieved through the use of counting semaphores.  The semaphore takes its name from the signaling system railroads developed to prevent more than one train from using the same length of track, a technique that enforces exclusive access to the shared resource of the railroad track. A train waiting to enter the protected section of track waits until the semaphore shows that the track is clear, at which time the train enters the track and sets the semaphore to show that the track is in use. Another train approaching the  protected track while the first train is using it waits for the signal to show that the track is clear. When the first train leaves the shared section of track, it resets the semaphore to show that the track is clear.  The semaphore protection scheme works only if all the trains using the shared resource cooperate by waiting for the semaphore when the track is busy and resetting the semaphore when they have finished using the track. If a train enters a track marked busy without waiting for the signal that it is clear, a collision can occur. Conversely, if a train exiting the track fails to signal that the track is clear, other trains will think the track is in use and refrain from using it.  The same is true for processes synchronizing their actions through the use of semaphores and shared memory. To gain access to the resource protected by the semaphore, cooperating processes must lock and unlock the semaphore. A calling process must check the state of the semaphore before performing a task. If the semaphore is locked, the process is blocked and waits for the semaphore to become unlocked. Semaphores restrict access to a shared resource by allowing access to only one process at a time.  An application can protect the following resources with semaphores:    Global variables, such as file variables, pointers, counters, and data structures. Synchronizing access to these variables means preventing simultaneous access, which also prevents one process from reading information while another process is writing it.    Hardware resources, such as tape drives. Hardware resources require controlled access for the same reasons as global variables; that is, simultaneous access could result in corrupted data.    The kernel. A semaphore can allow processes to alternate execution by limiting access to the kernel on an alternating basis.      For information on using shared memory and semaphores, refer to  Chapter 3  and  Chapter 9 .                    1.3.3    Waiting for Communication     Typically, communication between processes is used to trigger process execution so the flow of execution follows the logical flow of the application design. As the application designer maps out the program algorithm, dependencies are identified for each step in the program. Information concerning the status of each dependency is communicated to the relevant processes so that appropriate action can be taken. Processes synchronize their execution by waiting for something to happen; that is, by waiting for communication that an event occurred or a task was completed. The meaning and purpose of the communication are established by the application designer.  Interprocess communication facilitates application control over the following:    When and how a process executes    The sequence of execution of processes    How resources are allocated to service requests from the processes      Section 1.2.7  introduced the forms of interprocess communication available to the realtime application designer. For further information on using interprocess communication facilities refer to  Chapter 3 ,  Chapter 5 ,  Chapter 9 , and  Chapter 10 .                    1.3.4    Waiting for Another Process     Waiting for another process means waiting until that process has terminated. For example, a parent process can wait for a child process or thread to terminate. The parent process creates a child process which needs to complete some task before the waiting parent process can continue. In such a situation, the actions of the parent and child processes are sometimes synchronized in the following way:    The parent process creates the child process.    The parent process synchronizes with the child process.    The child process executes until it terminates.    The termination of the child process signals the parent process.    The parent process resumes execution.      The parent process can continue execution in parallel with the child process. However, if child processes are used as a form of process synchronization, the parent process can use other synchronization mechanisms such as signals and semaphores while the child process executes.  For information on using signals, refer to  Chapter 5 , and for information on using semaphores, refer to  Chapter 9 .                    1.3.5    Realtime Needs and System Solutions     Table 1-1  summarizes the common realtime needs and the solutions available through P1003.1b functions and the DIGITAL UNIX operating system. The realtime needs in the left column of the table are ordered according to their requirement for fast system performance.    Table 1-1:  Realtime Needs and System Solutions             Realtime Need   Realtime System Solution           Change the availability of a process for scheduling   Use scheduler functions to set the scheduling policy and priority of the process       Keep critical code or data highly accessible   Use memory locking functions to lock the process address space into memory       Perform an operation while another operation is in progress   Create a child process or separate thread, or use asynchronous I/O       Perform higher throughput or special purpose I/O   Use asynchronous I/O       Ensure that data read from a device is actually a current image of data on that device, or that data written to a device is actually stored on that device   Use synchronized I/O       Share data between processes   Use shared memory, or use memory-mapped files       Synchronize access to resources shared between cooperating processes   Use semaphores       Communicate between processes   Use messages, semaphores, shared memory, signals, pipes, and named pipes       Synchronize a process with a time schedule   Set and arm per-process timers       Synchronize a process with an external event or program   Use signals, use semaphores, or cause the process to sleep and to awaken when needed                           1.4    POSIX Standards     The purpose of standards is to enhance the portability of programs and applications;  that is, to support creation of code that is independent of the hardware or even the operating system on which the application runs. Standards allow users to move between systems without major retraining. In addition, standards introduce internationalization concepts as part of application portability.    The POSIX standards and draft standards apply to the operating system. For the most part, these standards apply to applications coded in the C language. These standards are not mutually exclusive;  the DIGITAL UNIX realtime environment uses a complement of these standards.    POSIX is a set of standards generated and maintained by standards organizations -- they are developed and approved by the Institute of Electrical and Electronics Engineers, Inc. (IEEE) and adopted by the International Organization for Standardization  (ISO) and the International Electrotechnical Commission (IEC). DIGITAL's POSIX implementations follow the standards and drafts defined by the POSIX standards.  Formal standards to date include POSIX 1003.1 for basic system  interfaces, and POSIX 1003.13 for assertions a vendor must test to claim conformance to POSIX 1003.1. Draft standards are not formal standards. They are working documents that will evolve over time into formal standards.  POSIX standards for the programming interface (P1003.1), POSIX threads (P1003.1c), and realtime programming extensions (P1003.1b) are supported by DIGITAL UNIX.    POSIX 1003.1 defines the standard for basic system services on an operating system, and describes how system services can be used by POSIX applications. These services allow an application to perform operations such as process creation and execution, file system access, and I/O device management.    POSIX 1003.1c defines a set of thread functions that can be used in the design and creation of  multithreaded realtime applications in the DIGITAL UNIX environment.    POSIX 1003.1b provides support for functions that support the needs of realtime applications, such as enhanced interprocess communication, scheduling and memory management control, asynchronous I/O operations, and file synchronization.      As DIGITAL adds support for evolving and final standards, customers should modify their POSIX applications to conform to the latest version of these standards. Because draft standards are working documents and not formal standards, the level of backward compatibility and formal support for older versions (drafts) will be less than that normally expected from a stable DIGITAL product.  An application that strictly conforms to any combination of these standards can be developed on one system and then ported to another system that supports the same POSIX standards. (A strictly conforming application uses only the facilities within the applicable standards.) Similarly, an application developed on a non-DIGITAL platform, if it strictly conforms to the POSIX standards and drafts supported by DIGITAL systems, can be ported and run on a DIGITAL system on which the POSIX software is installed.    It is the source code of an application that is portable. Most applications written for a POSIX environment use the C programming language. Each system that supports a POSIX environment includes POSIX runtime libraries as well as C runtime libraries. A portable application that requires an executable image must be compiled and linked on a system after being ported. It is important that you compile and link your POSIX applications against the runtime libraries on the system where they will run.    The POSIX standards are based on the UNIX environment. However, POSIX specifies an interface to an operating system, not the operating system itself. Additional information on POSIX standards is contained in the  IEEE Standard Portable Operating System Interface for Computer Environments  manuals, published by the Institute of Electrical and Electronics Engineers, Inc.                    1.5    Enabling DIGITAL UNIX Realtime Features     The files that make up the realtime facility are included with the base system software, and are installed when you choose the realtime option during installation. This provides extended features such as realtime and symmetric multiprocessing.    Note   If you install DIGITAL UNIX with the default options, realtime preemption is disabled. See the  Installation Guide  for complete installation instructions.                      1.6    Building Realtime Applications     To build a DIGITAL UNIX realtime application you must first define the POSIX environment, then compile the application with the appropriate compile command switches. These steps draw POSIX header information and realtime libraries into your code.                    1.6.1    Defining the POSIX Environment     Realtime applications should include the  unistd.h  header file before any other header files are included in the application. This header file defines the standard macros, for example _POSIX_C_SOURCE, that are required to compile programs containing POSIX 1003.1b functions. If you need to exclude any of the standards definitions provided by the  unistd.h  header file, you should explicitly define those standards macros in the source file or on the compilation command line.  As a general rule, use specific definitions in your application  only  if your application must  exclude  certain definitions related to other unneeded standards, such as XPG3. For example, if you defined _POSIX_C_SOURCE ( #define _POSIX_C_SOURCE 199506L ) in your application, you would get  only  the definitions for POSIX 1003.1b and other definitions pulled in by that definition, such as POSIX 1003.1.    The following example shows the code you would include as the first line of code in either your local header file or your application code:  #include <unistd.h>      Because the  unistd.h  header file defines all the standards needed for realtime applications, it is important that this  #include  is the first line of code in your application.                    1.6.2    Compiling Realtime Applications     You must explicitly load the required realtime runtime libraries when you compile realtime applications. The  -l  switch forces the linker to include the specified library and the  -L  switch indicates the search path for the linker to use to locate the libraries. You can specify the shareable realtime library,  librt.so , or the nonshareable library,  librt.a .  To find the realtime library, the  ld  linker expands the command specification by replacing the  -l  with  lib  and adding the specified library characters and the  .a  suffix. Since the linker searches default directories in an attempt to locate the realtime archive library, you must specify the pathname if you do not want to use the default.  The following example specifies that the realtime archive library,  librt.a , is to be included from the  /usr/ccs/lib  directory.  #  cc -non_shared myprogram.c -L/usr/ccs/lib -lrt         When you compile an application that uses asynchronous I/O, include the threads library on the compile command line. The following example shows the specification required if your application uses asynchronous I/O.  #  cc -non_shared myprogram.c -L/usr/ccs/lib -laio -pthread       The realtime library uses the  libc.a  library. When you compile an application, the  libc.a  library is automatically pulled into the compilation.    Most drivers allow you to view the passes of the driver program and the libraries being searched by specifying the  -v  option on the compile command.  If, for some reason, you want to just link your realtime application, you must explicitly include the  libc.a  library. Since files are processed in the order in which they appear on the link command line,  libc.a  must appear after  librt.a . For example,  you would link an application with the realtime library,  librt.a , as follows:  #  ld -non_shared myprogram.o -L/usr/ccs/lib -lrt -lc       If your application fails to compile, you may need to check your programming environment to make sure that the realtime options are installed on your system. The lack of the realtime software and its function library will cause your program to fail.
GX025-82-12749116	"Workstations:     Hearing      Sight     Mobility      Cognitive                              Service Request Form        Contact Us      Assistive Technology Accommodations    This is a list of all the AT software and hardware available at ATC.      Vision Accommodations      Braille Embosser  - Output device used to produce the raised Braille dots on paper.             Juliet Braille Embosser     Braille Translation - Software used to convert text documents into Braille.             Duxbury Braille Translator     Large Print Keyboard  - A quality PC compatible keyboard with bold large print legends for easy use.             Keytronic Large Print Keyboard      Large Monitor  - A monitor larger than standard size used to increase character size in proportion to the monitor dimensions.              Gateway VX 1120  22"" Monitor     Optical Character Recognition Reading System  - An integrated computer system consisting of a scanner, screen reader, sound card (or voice synthesizer) with software that can convert scanned text into recognizable characters which are read out loud by a synthesized voice.              Open Book Ruby Edition      Reading Machine  - Hardware device that combines advanced speech synthesis, intelligent character recognition, and a portable scanner in a portable machine.              A Kurzweil Reader, The Reading Edge     Refreshable Braille Display  - Output device with Braille cells that dynamically change (refresh) as the user scrolls through an electronic document.              Alva Braille Terminal     Screen Magnification  - Software that enlarges text and graphics on the computer screen.              Zoom Text Level 2     Screen Reader  - Software that provides visual information in audio format for computer users.              JAWS 3.7              Zoom Text Level 2         Speech Synthesizer  - Hardware or Software used to produce audio output for use with screen readers.              DecTalk              Eloquence      Video Magnifier (CCTV) - Hardware device that uses a video camera connected to a computer or a TV monitor to enlarge documents or objects that are placed under the camera.              Optelec 700 Clearview       See the Vendor List for Vision Accomodations             Mobility Accommodations     Abbreviation Expansion  - Software, which allows the use of abbreviations for frequently used words and phrases and for instant speech.  Simply type the abbreviation and EZ Keys automatically substitutes it with the complete word or phrase.              EZ Keys              WiVik2 Scan              Link - Augmentative Communication Device     Alternative Input Devices  - A variety of devices that take the place of a mouse.  Examples include, head pointing, eye movement tracking systems and touch sensitive monitor screens.              Tracker 2000      Alternative Keyboards  - A variety of keyboards that take the place of a standard Qwerty keyboard.              WinMini              Ergologic Split Keyboard              Microsoft Natural Elite Keyboard              BAT Keyboard     On-Screen Keyboards  - Software that displays a picture of a keyboard.  A user simply points and clicks on the picture of various keys displayed as a keyboard on the computer screen.              Screen Doors 2000              WiVik2 Scan       Scanning Program  - Software that, when used with a switch, a highlight moves over a picture of a keyboard.  Select the switch to choose the desired key and the scanning program sends it to the application being used.              Dragger 32              EZ Keys               WiVik2 Scan     Speech Recognition System  - Software that, when used with a microphone, allows the computer user to use speech as an alternative input method.               Dragon Naturally Speaking Professional     Switches  - Input devices that function in an on or off state used to operate a computer by some part of a person's body in which they have control.               Big Buddy Switch              IBM Switch Interface Box     Word Macro Program  - Software that can execute a series of prerecorded keystrokes to increase input rate.              WiVik2.5     Word Prediction Program  - An input acceleration method, which reduces the keystrokes required by creating a list of possible words from which to choose.              Kurzweil 3000              WiVik 2.5              Screen Doors 2000              EZ Keys for Windows     Voice Command and Control  - Software similar to speech recognition but is limited to menu-type functions and limited dictation.              Dragon Dictate         See the Vendor List for Mobility Accomodations           Hearing and Speech Accommodations     Assistive Listening Devices (ALD's)  - Small personal electronic devices (transmitter and receiver) used to amplify sounds to help a person hear better.  ALD's come in three categories: FM, infrared and wired systems.              Companion FM System - Wireless          Augmentative Communication Devices  - A device, which assists speech impaired, or non-verbal individuals with communication through synthesized or recorded speech.              Link - Transportable Augmentative Communication Device      Chat Software  - Programs that allow typing of messages back and forth between computer users in real time.              Nxi Text Services Server Software             NexTalk for Network User Software     Email  - Electronic text messages (mail) sent over a Local Area Network or the Internet.              Christine_E_Louton @nbc.gov              www.doi.gov/atc/     TTY/TDD Software  - A program that allows a computer to be used as a TTY.              Nxi Text Services Server Software              NexTalk for Network User Software     TTY or TDD Machines  - Hardware devices with a keyboard and display used to communicate over the telephone system by typing text.                Ultratec Superprint TTY              Ultratec Comapct TTY        See the Vendor List for Hearing Accomodations        Cognitive Accommodations     Scanner  - Hardware device that is used to transfer text and color images to your computer for document or web page reading.  Used in conjunction with OCR or Text Reader Software (Open Book Ruby Edition or Kurzweil 3000).             Hewlett Packard Scan Jet 6300c      Text Reader  - Software used with a sound card to read in a synthesized voice the text that is on a computer screen.              Kurzweil 3000      See the Vendor List for Cognitive Accomodations"
GX017-82-12484924	"Applications Performance Under OSF/1 AD and SUNMOS  on the Intel Paragon XP/S-15 *   by Subhash Saini and Horst D. Simon   NASA Ames Research Center, Moffett Field, CA 94035-1000   ISSN 1063-9535. Copyright (c) 1994 IEEE All Rights Reserved.  Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes,or for creating new collective works for resale or redistribution must be obtained from the IEEE. For information on obtaining permission,send a blank email message to info.pub.permission@ieee.org  By choosing to view this document, you agree to all provisions of the copyright laws protecting it.    Abstract   On the Paragon, two operating systems are available: (a) OSF/1 AD, and (b) SUNMOS. The chief drawbacks of OSF/1 AD are (a) OSF/1 AD takes about 8 MB of memory on each node of the Paragon, (b) messages can be sent only at a bandwidth of 30-35 MB per second compared to 200 MB per second peak advertised rate, (c) latencies are on the order of 100 microseconds using Intel NX calls under OSF1/ AD. All these drawbacks can be minimized by using SUNMOS. SUNMOS takes only 250 KB of memory on each node and can send messages at bandwidth of 170 MB per second with latencies of 70 microseconds. We have measured the performance of applications under OSF/1 AD and SUNMOS and found that under OSF/1 AD, performance does not scale as the number of nodes increases, whereas under SUNMOS it seems to scale because of higher communication bandwidth.      1:  Introduction  The Numerical Aerodynmical Simulation (NAS) Systems Division received an  Intel Touchstone Sigma  prototype model  Paragon XP/S-15  in February 1993 .  It was found that performance of many applications including the assembly coded single node  BLAS 3  routine DGEMM [1] was lower than the performance on  Intel iPSC/860 . This finding was quite puzzling since the clock of the microprocessor  i860 XP  used in the  Paragon  is  25%  faster than the microprocessor  i860 XR  used in the  Intel iPSC/860  [2]. It was also found that the performance of the  NAS Parallel Benchmarks (NPB)  [3-5] is enhanced by about  30%  if they are run for second time in a DO loop. Furthermore, the performance of DGEMM was identical for the first run and the second run on a service node, but on a compute node the performance of the second run was about  40%  better than the first run. These anomalies in the performance on the  Paragon  led us to investigate the problem in more detail. This, in turn, led us to propose a method of dynamic allocation of memory that increases the performance of the applications by about  30%  to  40%  [15-16].  By November 1993, it was realized that the performance of the applications is very much limited by two mains factors (a) high latency (120 microseconds), and (b) low communications bandwidth (30 - 35 MB per second). The optimal use of the Paragon was also limited by the fact that the micro kernel and Open Software Foundation (OSF)/1 AD [6-7] server takes 8 MB per node, thereby leaving only 8 MB for the user application. On the other hand, there is another operating system available for the Paragon, tailored to the needs of applications requiring a large volume of communication: the Sandia University of New Mexico operating system (SUNMOS, [8-9]). The latency under SUNMOS is 70 microseconds and bandwidth is 170 MB per second. Also, SUNMOS needs only 250 KB of memory per node, thereby making 15.8 MB of memory available for the user application. Additionally, there is no degradation in performance associated with using static allocation of memory. In view of this, it was decided to port, test and evaluate the performance of SUNMOS on the NAS Paragon. In January 1994, memory per node was upgraded from 16 MB to 32 MB.  In Section 2 we give a brief overview of the Paragon system. Section 3 gives some details on operating systems available on Paragon. Section 4 gives the description of the applications we have studied under OSF/1 AD and SUNMOS. Section 5 describes the methodology used. Section 6 presents results and discussion. Lastly, Section 7 contains the conclusions of the paper.     2:  Overview of the Paragon   2.1:  The i860 XP microprocessor   The  Paragon  system is based on the  64  bit  i860 XP TM   microprocessor [2] by Intel. The  i860 XP TM   microprocessor has  2.5  million transistors in a single chip and runs at  50 MHz . The theoretical speed is  100 MFLOPS  in  32  bit floating point and  75 MFLOPS  for  64  bit for floating point operations. The  i860 XP TM  features  32  integer address registers with  32  bits each. It has  32  floating point registers with  32  bits each. The floating point registers can also be accessed as  16  floating point registers with  64  bits each or  8  floating point registers with  128  bits each. Each floating point register has two read ports, a write port and two-bidirectional ports. All these ports are  64  bits wide and can be used simultaneously. The floating point registers serve as input to the floating point adder and multiplier. In vector computations, these registers are used as buffers while the data cache serves as vector registers. The  i860 XP TM   microprocessor has  16 KB  of instruction cache and  16 KB  of data caches. The data cache has a  32  bit path to the integer unit and  128  bit data path to the floating point unit. The  i860 XP TM  has a number of advanced features to facilitate high execution rates. The  i860 XP TM  microprocessor's floating point unit integrates single-cycle operation,  64  bit   and  128  bit data paths on chip and a  128  bit data path to main memory for fast access to data and transfer of results. Floating point add, multiply and fetch from main memory are pipelined operations, and they take advantage of a three-stage pipeline to produce one result every clock for  32  bit add or multiply operations and  64  bit   adds. The  64  bit   multiplication takes two clocks.    2.2:  NAS Intel Paragon XP/S-15  A single node of the  Paragon XP/S-15  [10] consists of two  i860 XP TM  microprocessors: one for computation and the other for communication. The compute processor is for computation and the communication processor handles all message-protocol processing thus freeing the computation processor to do computations. Currently, the communication processor is  not  used in the  NAS   Paragon . Each compute processor has   32  MB  of local memory but at  NAS  only   about   24  MB  is available for applications, the rest being used for the micro kernel,  OSF  server and system buffers.  The  NAS   Parago n has  256  slots for nodes. Slots are given physical node numbers from  0  through  255 . Slots are physically arranged in a rectangular grid of size  16  by  16.  There are  8  service nodes; four of them have  16 MB  of memory each and the other four have  32 MB  of memory each. Column  0  and column  14  have no physical nodes. The service partition contains  8  nodes in the last column. One of these service nodes is a boot node. This boot node has  32 MB  of memory and is connected to a  Redundant Array of Independent Disks-1 (RAID-1 ). The compute partition has  208  nodes which occupy columns  1  through  13 . Compute processors are given logical numbers  0  through  207 . Compute processors are arranged in a  16  by  13  rectangular grid. The  227  nodes are arranged in a two-dimensional mesh using wormhole routing network technology. The four service nodes comprise the service partition and provide an interface to the outside world, serving as a  front end  to the  Paragon  system. Besides running jobs on the compute nodes, the service nodes run interactive jobs, such as  shells  and  editors . They appear as one computer running  UNIX .   Theoretical peak performance for  64  bit floating point arithmetic is  15.6 GFLOPS  for the  208  compute nodes. Hardware node-to-node bandwidth is  200 MB  per   second in full duplex.  The nodes of the  NAS   Paragon  are organized into groups called partitions [10]. Partitions are organized in a hierarchical structure similar to that of the  UNIX  file system. Each partition has a  pathname  in which successive levels of the tree are separated by a periods ("".""), analogous to ""/"" in the  UNIX  file system. A subpartition contains a subset of the nodes of the parent partition.   Currently, on the  NAS Paragon  there are no subpartitions of  .compute  or  .service . The root partition (denoted by ""."") contains all  227  nodes of the  Paragon . There are two subpartitions of the root partition: the compute partition, named  .compute , contains  208  nodes to run parallel applications. The service partition, named  .service , contains four nodes devoted to interactive jobs. The remaining eight nodes are not part of a subpartition and serve as disk controllers and are connected to the  RAID  for  I/O . The four nodes of the service partition appear as one computer. In summary, the  NAS Paragon  system has  208  compute nodes, 3  HiPPI  nodes,  1  boot node,  8  disk nodes,  4  service nodes of which  1  is a boot node and  4  nodes are not used at this time, for a total of  227  nodes. When a user logs onto the  Paragon , the  shell  runs on one of the four service nodes. In the current release of the  Paragon OS , processes do not move between service nodes to provide load balancing. However, the load leveler decides on which node a process should be started. In principle, partitions and subpartitons may overlap. For instance, there could be a subpartition called  .compute.part1  consisting of nodes  0-31  of  .compute , and another subpartition called  .compute.part2  consisting of nodes  15-63  of  .compute . However, in the current release of the operating system on the  NAS Paragon , there are two problems which restrict the use of subpartitions. First, running more than one application on a node (either two jobs in the same partition or jobs in overlapping partitions) may cause the system to crash. Second, the existence of overlapping partitions sometimes causes jobs to wait when they need not. For these two reasons, there are currently no subpartitions of the  .comp ute partition. All jobs run directly on the  .compute  partition.   3:  Operating Systems on Paragon  On NAS Paragon the following two operating systems are available.   3.1:  Open Software Foundation (OSF/1 AD)  The  UNIX  operating system was originally designed for sequential computers and is not very well suited to the performance of massively parallel applications. The  Paragon  operating system is based upon two operating systems: the  Mach  system from  Carnegie Mellon University  and the  Open Software Foundation's OSF/1   AD  distributed system for multicomputers [7,8]. The  Paragon' s operating system provides all the  UNIX  features including  virtual memory ;  shell ,  command s and  utilitie s;  I/O  services; and networking support for  ftp, rpc  and  NFS . Each  Paragon  node has a small microkernel irrespective of the role of the node in the system. The  Paragon  operating system provides programming flexibility through virtual memory. In theory, virtual memory simplifies application development and porting by enabling code requiring large memory to run on a single compute node before being distributed across multiple nodes. The application runs in virtual memory which means that each process can access more memory than is physically available on each node. At NAS, OSF/1 AD runs on 144 compute nodes and on all service nodes.  The  Paragon OS  used in this study is version  R1.1 . and the  Fortran  compiler is  4.1  [10]. The compiler options used are the f77 -O4 -Mvect -Knoieee abc.f -lkmath and the compilation was done on the service node. There is a compiler option by which one may set the size of the portion of the cache used by the vectorizer to  numbe r bytes. This  number  must be a multiple of  16,  and less than the cache size 16384 of the microprocessor  i860 XP . In most cases the best results occur when  number  is set to  4096 , which is the default. In view of this we decided to choose the default size  4 KB  and the highest optimization level of  4  was used. This level of optimization generates a basic block for each  Fortran  statement and scheduling within the basic block is performed. It does perform aggressive register allocation for software pipelined loops. In addition, code for pipelined loops is scheduled several ways, with the best way selected for the assembly file. The option -Knoieee was used, which produces a program that flushes denormals to  0  on creation (which reduces underflow traps) and links in a math library that is not as accurate as the standard library, but offers greater performance. This library offers little or no support for exceptional data types such as  INF  and  NaN , and will not trap on such values when encountered. If used while compiling, it tells the compiler to perform real and double precision divides using an in-line divide algorithm that offers greater performance than the standard algorithm. This algorithm produces results that differ from the results specified by the  IEEE  standard by no more than three units in the last place  (ulp) .   3.2:  SUNMOS  The chief drawbacks of OSF/1 AD are (a) OSF/1 AD takes about 8 MB of memory on each node of the Paragon, (b) messages can be sent at a bandwidth of 30-35 MB per second compared to 200 MB per second peak advertised rate, (c) latencies are of the order of 120 microseconds using Intel NX calls under OSF/1 AD [6, 7]. All these drawbacks can be minimized by using a new operating system called Sandia University of New Mexico Operating System (SUNMOS) [8, 9]. SUNMOS was originally developed and ported to nCUBE-2 in 1991. SUNMOS was ported to Intel Paragon in 1993. SUNMOS takes only 250 KB of memory on each node of the Paragon and can send messages at bandwidth of 170 MB per second with latencies of 70 microseconds. However, SUNMOS does not provide a complete implementation of Intel's NX message-passing library. It only supports hostless programs and does not support host-node programs. In addition to these limitations, SUNMOS has very limited support for I/O and absolutely no support for parallel I/O. NAS Paragon runs SUNMOS on 64 compute nodes and these nodes do not appear under the compute partition. Furthermore, jobs running under SUNMOS get a fixed amount of heap, stack, and communication space at load time. SUNMOS does not support virtual memory Figure 1 shows the typical installation of SUNMOS on Paragon. SUNMOS runs only on the compute nodes. Comparative performance of operating systems OSF/1 AD and SUNMOS is given in Table 1. It is possible to run SUNMOS either on all the compute nodes or on a subset of them. One may not notice any difference when SUNMOS is running on part of compute nodes and OSF/1 AD running on the remaining compute nodes other than the fact that there are fewer compute nodes in the compute partition. SUNMOS never runs on the service nodes of the service partition.      3.2.1:  The utility YOD:   When SUNMOS runs on part of the compute nodes, a program called  yod  also runs on the service node/nodes allocated to compute partition running SUNMOS. It is illustrated in Figure 2. The utility  yod  [8] is used to allocate a partition of the SUNMOS to a portion of the mesh and load the executable. This utility runs in the service partition and handles all requests from the SUNMOS compute nodes that it controls. Aborting a job under control of  yod  by KILL -9 leaves the nodes allocated and pr the use of these nodes in subsequent runs until the system is rebooted. Among others, there are three arguments to  yod  which need careful attention. These are  comm ,  heap  and  stack . The argument  stack  reserves the space for stack. In many examples studied, inadequate allocation of stack gave run time errors and the benchmark could not be run. The switch  comm  sets aside space that is used for buffering messages for which no receive has been posted. The default size for  comm  is 256 KB. If the communication buffer overflows during execution of the application it causes an unrecoverable error and sometimes the system hangs and needs to be rebooted. The argument  heap  reserves the space for heap. The default is to allocate the remaining memory left on each node after the  comm ,  stack , program (text and data) and OS space have been allocated. Currently, the size of the heap cannot be more than 16 MB. When the application needs more than 16 MB per node, specifying the heap to be 16 MB will not run the application and gives the message that not enough space is available for running the application and sometimes the system hangs and needs to be rebooted. The argument  heap  reserves the space for heap. The default is to allocate the remaining memory left on each node after the  comm ,  stack , program (text and data) and OS space have been allocated. Currently, the size of the heap cannot be more than 16 MB. When the application needs more than 16 MB per node, specifying the heap to be 16 MB will not run the application and gives the message that not enough space is available for running the application. The application can be       still run up to 25 MB per node if the  heap  argument is not used. Occasionally, the application hangs or the system crashes. The application always hangs the system or crashes it if the application needs more than 25 MB per node. To run        Table 1: Comparative performance of operating systems OSF/1 AD and SUNMOS.  --------------------------------------------------------------------------                            OSF/1 AD                  SUNMOS                      -------------------------------------------------------------------------- Microkernel               5 MB                    0.25 MB                    Server                    3 MB on compute node    None                       Memory for application    24 MB per node          31.75 MB per node          Virtual memory            Yes                     No                         Latency                   120 micro seconds       70 microseconds            Bandwidth                 35 MB per second        170 MB per second          I/O - READ                8 MB per second         2 MB per second            I/O - WRITE               11 MB per second        3 MB per second            Support                   Intel                   Sandia Nat. Laboratories   Technology                Mixture of OSF,         Sandia National Labora                               LOCUS and Intel         tories and Univ. of New                                                      Mexico                     Reliability               3 crashes per day       Undetermined               Allocation of heap and    By OSF/1 AD             By the user                stack                                                                        Time sharing              Yes                     No                         Nodes on which runs       Compute & Service   Only on compute nodes                                nodes                                              Parallel file system      Yes                     No                         Availability of debugger  Yes                     No                         Reliability of results    High                    Intermittently wrong                                                         results if more than 16                                                      MB per node is used        Functionality             High                    Low                        Memory bandwidth          Low                     High                       Scalability               Low                     High                       Applications performance  Low                     Moderate                                                                                                                                                                             --------------------------------------------------------------------------   the application successfully one has to be extra careful in allocating heap and a stack.   3.2.2 The utility FYOD:    fyod  is a utility that starts a SUNMOS file server [8]. Typically, it runs on an I/O node with a disk attached to it in the service partition. All input/output for an application is routed through  yod  utility. The purpose of  fyod  is to remove this bottleneck and distributes the work load among several I/O nodes in the service partition. The use of  fyod  is transparent to the user. It improves the performance of applications that write to many files simultaneously  SUNMOS can run under three modes:   (a) mode 0:  Second processor is not used.   (b) mode 1:  Second processor is used as a communication processor.   (c) mode 2:  Second processor is used for computation.   4:  Applications used   4.1:  BLAS   BLAS 1, 2  and  3  are the basic building blocks for many scientific and engineering applications. For example, the dot product (BLAS 1) is a basic kernel in  Intel's ProSolver Skyline Equation Solver (ProSolver-SES)  [11], a direct solver using skyline storage, useful for performing Finite Element Structural analysis in designing aerospace structures . BLAS 3   (matrix-matrix)  kernels are basic kernels in  Intel's ProSolver Dense Equation Solver (ProSolver-DES)  [12], a direct solver that may be applied in solving computational electromagnetics  (CEM ) problems using  Method of Moments (MOM). BLAS 2  and  BLAS 3  are basic kernels in  LAPACK  [1]. In the present paper, we have used a  BLAS 3  routine called DGEMM to compute  C = A*B , where  A  and  B  are real general matrices. The DGEMM is a single node assembly coded routine [17] and as such involves no interprocessor communication   4.2:  Fast Fourier Transforms  The FFT is a basic tool in various scientific and engineering applications ranging from artificial intelligence to oil exploration. At NAS, distributed three-dimensional FFT is used to solve the Poisson partial differential equation. We have measured the performance of radix-2, -3 and -5 complex to complex FFT on Paragon. We have used (a) 1-D single node, and (b) 3-D distributed FFTs to study the impact of data cache usage and scalability issues under OSF and SUNMOS on Paragon. Intel supplies only radix-2 1-D FFTs on Paragon [17].    4.3:  NAS Parallel Benchmarks  The  NPB  [3-5] were developed to evaluate the performance of highly parallel supercomputers. One of the main features of these benchmarks is their  pencil and paper  specification, which means that all details are specified algorithmically, thereby avoiding many of the difficulties associated with traditional approaches to evaluating highly parallel supercomputers. The  NPB  consist of a set of eight problems each focusing on some important aspect of highly parallel supercomputing for computational aerosciences. The eight problems include five kernels and three simulated computational fluid dynamics  (CFD)  applications. The implementation of the kernels is relatively simple and straightforward and gives some insight into the general level of performance that can be expected for a given highly parallel machine. The other three simulated  CFD  applications need more effort to implement on highly parallel computers and are representative of the types of actual data movement and computation needed for computational aerosciences. The  NPB  all involve significant interprocessor communication with the exception of the Embarrassingly Parallel  (EP)  benchmark which involves almost no interprocessor communication.    4.4:  NAS Kernels  This set of computational kernels comes from applications at NASA Ames. It demonstrates the compiler's ability to vectorize floating point operations as well as processor speed [14].   5:  Procedure for 1st Run and 2nd Run  It was found that the performance of  NPB  codes is enhanced by about  30%  if they are run for a second time in a DO loop. Furthermore, the performance of DGEMM was identical for the first run and second run on a service node but on a compute node the performance of the second run was about  40%  better than the first run. In our numerical results section we will present results for a first run and a second run of each application. The procedure to obtain first run and second run for a given application is illustrated in Table 2. In this table, a DO loop index i running from  1  to  2  is inserted just before the section of the code we want to time for benchmark purposes. In this table the  first run  corresponds to  i=1  and the  second run  corresponds to  i=2  as shown in Table 2. The overhead in calling the function DCLOCK was estimated to be about  1.5x10 -6 second [13, 15-16].   Table 2: Procedure for obtaining first run and second run.  ---------------------- PROGRAM abc              ...                      DO i = 1, 2              t0 = DCLOCK()            t1 = DCLOCK              CALL DGEMM( ,..., ...)   t2 = DCLOCK()            time = t2 - (t1 - t0)    ENDDO                    ...                      END                      ----------------------    6:  Results and Discussion  The results were obtained under OSF/1 AD 1.1 and SUNMOS S1.1. Figure 4(a) shows the results for the assembly coded BLAS 3 routine DGEMM for a matrix size of 1024x1024 on one compute node for the first and second run. The performance is 27 MFLOPS for the first run and 46 MFLOPS for the second run.  The performance obtained by the second run is about 40% better than the performance obtained by the first run. This degradation in performance is not acceptable since users will always run their code once. The left of the Figure 4(b) shows the performance of DGEMM on four compute nodes. The MFLOPS rate has decreased from 27 MFLOPS to about 6 MFLOPS. This problem can be eliminated by using dynamic allocation of memory. The performance of DGEMM using dynamic allocation of memory is shown on the right side of Figure 4(b). For details see reference [13, 15-16]. The performance of DGEMM as a function of the size of the matrix is shown in Figure 5. SUNMOS results are about 5% better than corresponding OSF results probably due to a better memory access mechanism. However, under SUNMOS, for a matrix size larger than 1024 the system either hangs or crashes and, therefore, results could not be obtained. Under OSF we could run our matrix beyond 32 MB per node but with 40% decrease in performance.   Figure 6(a) shows the performance of assembly coded 1-D FFT [17]. Performance is much better when twiddle factors are in cache. The performance is a maximum at x=512, corresponding to a of 4 KB data cache size. The other peaks reflect higher harmonics at multiple of 512. Figures 7(a) and 7(b) are similar to Figure 6 but are for Fortran coded 1-D FFT. Notice that the performance does not decrease after x=512 but remains constant due to better cache management. Also Fortran coded 1-D FFT is for radix-2, -3 and -5 whereas assembly coded 1-D FFT supplied by the Intel and used in Figure 3 is radix-2. Figure 8(a) shows the performance of NPB under OSF for 128 nodes. Performance is under 1 GFLOPS except for benchmarks EP, FT and BT. The benchmark EP involves almost no communication. The kernel FT uses assembly coded 1-D FFT and BT uses an assembly coded block tridiagonal solver for most of the computations. Figure 8(b) shows the performance in MFLOPS per node for NPB. The average performance is about 5 MFLOPS except for EP, FT and BT for the same reasons as discussed before. High performance of FT (9 MFLOPS) and BT (10 MFLOPS) is due to the use of assembly coded routines.  Figure 9(a) shows the performance in MFLOPS of 3-D FFT as a function of the number of compute nodes for a fixed problem size of  256x256x128 . Under OSF, performance does not scale, whereas under SUNMOS it seems to scale because of higher communication bandwidth. Figure 9(b) shows the performance of 3-D FFT as a function of the size of the FFT for a fixed system size (128 nodes) for OSF and SUNMOS. Here also the scalability under SUNMOS is better than OSF/1 AD.    7:  Conclusions:   (1)   In SUNMOS, loading of data from memory to the processor is much faster than under OSF. This is clearly shown by the better performance of the first iteration of the 1-D FFT kernel.   (2)   In SUNMOS, one can not use more than 24 MB of memory per node although SUNMOS needs only 250 KB of memory per node. This means that on a 32 MB per node Paragon about 7.5 MB memory is wasted due to the hardware problem.   (3)   In SUNMOS, there is no paging effect,  i.e ., performance of the first iteration and the second iteration are always the same. Under OSF, the dynamic allocation of memory enhances the performance of applications.             (4)   In SUNMOS, there is no virtual memory. Even in the absence of the Paragon's hardware problem, the maximum memory per node that can be utilized by the application will never exceed 31.5 MB. Currently, using 24 MB per node hangs or crashes the system.   (5)   In SUNMOS, to run the application successfully either for a fixed problem size and varying number of nodes or for a fixed number of nodes and varying size problem, one has to adjust some or all of the following: (a) the size of the communication buffer, (b) the size of the heap, (c) the size of the stack. Choosing any one of them incorrectly either hangs or crashes the system or causes the system to be unusable until it is rebooted.   (6)   In SUNMOS, the performance of the applications is generally (but not always) better than that under OSF.    (7)   In SUNMOS, some enhancement of the applications' performance is attributed to the ability of SUNMOS to allocate the user's partition as close to a ""square"" as possible.    (8)   On 128 nodes of the Paragon, only two NPB codes (FT and BT) exhibit performance of more than 1 GFLOPS. This high performance is due to use of optimized assembly routines for the 1-DFFT in FT benchmark and block tridiagonal solver in BT benchmark.    (9)   For most of the NPB codes the performance is less than 5 MFLOPS per node, except for that of EP, FT and BT. The high performance of 12 MFLOPS for EP is due to it's having almost no communication. Message passing is used only to collect the results from different nodes. The use of optimized assembly routines (1-D FFT in benchmark FT and block tridiagonal solver in BT) enhance the performance.    (10)   In OSF, the 3-D FFT kernel does not scale as the number of nodes are increased from 32 to 256.     8:  Acknowledgment:  The authors wish to thank Thanh Phung of Intel SSD for useful discussions.  * This work is supported through NASA contract NAS 2-12961.   [1]  E. Anderson et al.,  LAPACK Users' Guide , SIAM, Philadelphia, 1992.   [2]   Overview of the i860TM XP Supercomputing Microprocessor , 1991, Intel Corporation.   [3]  D. Bailey et al., eds,  The NAS Parallel Benchmarks , Technical Report RNR-91-02, NAS Ames Research Center, Moffet Field, California, 1991.   [4]  D. Bailey et al., eds, The NAS Parallel Benchmark Results 394,Technical Report RNR-94-06, NAS Ames Research Center, Moffet Field, California, 1994.   [5]  D. Bailey et al., The NAS Parallel Benchmark Results, IEEE Parallel & Distributed Technology, 43-51, February 1993.   [6]  R. Zajcew et al. ""An OSF/1 Unix for Massively Parallel Multicomputers"", in  Proceedings of the 1993 Winter USENIX Conference , January 1993, pp. 37-55.   [7]  K. Loeppere, ""OSF Mach: Kernel Principles"", Open Software Foundation and Carnegie Mellon University, February 1993.   [8]  B. Maccabe, K. S. McCurley and R. Rissen, SUNMOS for Intel Paragon: A Brief user Guide, November 29, 1993.   [9]  K. S. McCurley, Intel NX compatibility under SUNMOS, Sandia National Laboratories, Albuquerque, Technical Report No. SAND 93-2618, Nov. 29, 1993.   [10]  Paragon OSF/1, User Guide, Intel Corporation, 1994.   [11]   iPSC/860 ProSolver-SES Manual , May, 1991, Intel Corporation.   [12]  i PSC/860 ProSolver-DES Manual , March 1992, Intel Corporation.   [13]  S. Saini and H.D. Simon, ""Performance of BLAS and NAS Parallel Benchmarks on NAS Intel Paragon XP/S-15"" in Proceedings of Intel Supercomputing User's Group Meeting, Oct. 3-6, 1993, St. Louis, Missouri, USA.   [14]  D.H. Bailey and J. Barton, ""The NAS Kernel Benchmarks Program"", Report Number 86711, August 1985, NASA Ames Research Center.    [15]  S. Saini and H.D. Simon, ""Performance of BLAS 1, 2 on NAS Intel Paragon XP/S-15"" in Proceedings of Scalable Parallel Libraries Conference organized by IEEE, Oct. 6-9, 1993, Mississippi State University, Starkville, Mississippi, USA.   [16]  S. Saini and H.D. Simon, ""Enhancing Applications Performance on Intel Paragon through Dynamic Memory Allocation"", Report RNR-93-017, November 1993, NAS Systems Division, NASA Ames Research Center, Moffett Field, California 94035, USA.   [17]  CLASSPACK, Basic Math Library User's Guide, Kuck & Associates, Release 1.3, 1992.   ISSN 1063-9535. Copyright (c) 1994 IEEE All Rights Reserved.  Personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes,or for creating new collective works for resale or redistribution must be obtained from the IEEE. For information on obtaining permission,send a blank email message to info.pub.permission@ieee.org  By choosing to view this document, you agree to all provisions of the copyright laws protecting it."
GX009-94-9488381	"Skip Navigation links                                           Workstations:       Hearing       Sight      Mobility       Cognitive      Section 508       Ergonomic                                Service Request Form        Contact Us     Privacy Statement        Assistive Technology Accommodations    This is a list of all the AT software and hardware available at ATC.      Vision Accommodations      Braille Embosser  - Output device used to produce the raised Braille dots on paper.             Juliet Braille Embosser     Braille Translation - Software used to convert text documents into Braille.             Duxbury Braille Translator     Large Print Keyboard  - A quality PC compatible keyboard with bold large print legends for easy use.             Keytronic Large Print Keyboard      Large Monitor  - A monitor larger than standard size used to increase character size in proportion to the monitor dimensions.              Gateway VX 1120  22"" Monitor     Optical Character Recognition Reading System  - An integrated computer system consisting of a scanner, screen reader, sound card (or voice synthesizer) with software that can convert scanned text into recognizable characters which are read out loud by a synthesized voice.              Open Book Ruby Edition      Reading Machine  - Hardware device that combines advanced speech synthesis, intelligent character recognition, and a portable scanner in a portable machine.              A Kurzweil Reader, The Reading Edge     Refreshable Braille Display  - Output device with Braille cells that dynamically change (refresh) as the user scrolls through an electronic document.              Alva Braille Terminal     Screen Magnification  - Software that enlarges text and graphics on the computer screen.              Zoom Text Level 2     Screen Reader  - Software that provides visual information in audio format for computer users.              JAWS 3.7              Zoom Text Level 2         Speech Synthesizer  - Hardware or Software used to produce audio output for use with screen readers.              DecTalk              Eloquence      Video Magnifier (CCTV) - Hardware device that uses a video camera connected to a computer or a TV monitor to enlarge documents or objects that are placed under the camera.              Optelec 700 Clearview       See the Vendor List for Vision Accomodations             Mobility Accommodations     Abbreviation Expansion  - Software, which allows the use of abbreviations for frequently used words and phrases and for instant speech.  Simply type the abbreviation and EZ Keys automatically substitutes it with the complete word or phrase.              EZ Keys              WiVik2 Scan              Link - Augmentative Communication Device     Alternative Input Devices  - A variety of devices that take the place of a mouse.  Examples include, head pointing, eye movement tracking systems and touch sensitive monitor screens.              Tracker 2000      Alternative Keyboards  - A variety of keyboards that take the place of a standard Qwerty keyboard.              WinMini              Ergologic Split Keyboard              Microsoft Natural Elite Keyboard              BAT Keyboard     On-Screen Keyboards  - Software that displays a picture of a keyboard.  A user simply points and clicks on the picture of various keys displayed as a keyboard on the computer screen.              Screen Doors 2000              WiVik2 Scan       Scanning Program  - Software that, when used with a switch, a highlight moves over a picture of a keyboard.  Select the switch to choose the desired key and the scanning program sends it to the application being used.              Dragger 32              EZ Keys               WiVik2 Scan     Speech Recognition System  - Software that, when used with a microphone, allows the computer user to use speech as an alternative input method.               Dragon Naturally Speaking Professional     Switches  - Input devices that function in an on or off state used to operate a computer by some part of a person's body in which they have control.               Big Buddy Switch              IBM Switch Interface Box     Word Macro Program  - Software that can execute a series of prerecorded keystrokes to increase input rate.              WiVik2.5     Word Prediction Program  - An input acceleration method, which reduces the keystrokes required by creating a list of possible words from which to choose.              Kurzweil 3000              WiVik 2.5              Screen Doors 2000              EZ Keys for Windows     Voice Command and Control  - Software similar to speech recognition but is limited to menu-type functions and limited dictation.              Dragon Dictate         See the Vendor List for Mobility Accomodations           Hearing and Speech Accommodations     Assistive Listening Devices (ALD's)  - Small personal electronic devices (transmitter and receiver) used to amplify sounds to help a person hear better.  ALD's come in three categories: FM, infrared and wired systems.              Companion FM System - Wireless          Augmentative Communication Devices  - A device, which assists speech impaired, or non-verbal individuals with communication through synthesized or recorded speech.              Link - Transportable Augmentative Communication Device      Chat Software  - Programs that allow typing of messages back and forth between computer users in real time.              Nxi Text Services Server Software             NexTalk for Network User Software     Email  - Electronic text messages (mail) sent over a Local Area Network or the Internet.              Christine_E_Louton @nbc.gov              www.doi.gov/atc/     TTY/TDD Software  - A program that allows a computer to be used as a TTY.              Nxi Text Services Server Software              NexTalk for Network User Software     TTY or TDD Machines  - Hardware devices with a keyboard and display used to communicate over the telephone system by typing text.                Ultratec Superprint TTY              Ultratec Comapct TTY        See the Vendor List for Hearing Accomodations        Cognitive Accommodations     Scanner  - Hardware device that is used to transfer text and color images to your computer for document or web page reading.  Used in conjunction with OCR or Text Reader Software (Open Book Ruby Edition or Kurzweil 3000).             Hewlett Packard Scan Jet 6300c      Text Reader  - Software used with a sound card to read in a synthesized voice the text that is on a computer screen.              Kurzweil 3000      See the Vendor List for Cognitive Accomodations"
GX029-21-11585315	"Text REtrieval Conference (TREC)   System Description                            Organization Name:    University of Limerick         Run ID:               DLT02QA02                          Section 1.0 System Summary and Timing                             Section 1.1 System Information                                    Hardware Model Used for TREC Experiment:    Dell OptiPlex GX200                 System Use:                         DEDICATED                 Total Amount of Hard Disk Storage:  66.73 Gb                 Total Amount of RAM:                256 MB                 Clock Rate of CPU:                  733 MHz                                Section 1.2 System Comparisons                                    Amount of developmental ""Software Engineering"":    ALL                 List of features that are not present in the system,  but would have been beneficial to have:   Larger gazetteer and list of person names, more extensive query categorisation, more named entities, refined matching                 List of features that are present in the system, and  impacted its performance, but are not detailed within this form:     Query categorisation, Named Entity Recognition, Target Term Recognition,                                 Section 2.0 Construction of Indices, Knowledge Bases, and Other Data Structures                                     Length of the stopword list:   words                Type of Stemming:                            Controlled Vocabulary:                       Term weighting:                                             Additional Comments on term weighting:                                     Phrase discovery:                                           Kind of phrase:                                             Method used:                                                               Type of Spelling Correction:                 Manually-Indexed Terms:                      Proper Noun Identification:                  Syntactic Parsing:                           Tokenizer:                                   Word Sense Disambiguation:                   Other technique:                             Additional comments:                                           Section 3.0 Statistics on Data Structures Built from TREC Text                                     Section 3.1 First Data Structure                                     Structure Type:                                                       Type of other data structure used:                                    Brief description of method using other data structure:                     Total storage used:                                    Gb                 Total computer time to build:                          hours                 Automatic process:                                                    Manual hours required:                                 hours                 Type of manual labor:                                                 Term positions used:                                                  Only single terms used:                                               Concepts (vs. single terms) represented:                                  Number of concepts represented:                                                          Type of representation:                                               Auxilary files used:                                                      Type of auxilary files used:                                                           Additional comments:                                                                        Section 3.2 Second Data Structure                                         Structure Type:                                                        Type of other data structure used:                                     Brief description of method using other data structure:                      Total storage used:                                     Gb                 Total computer time to build:                           hours                 Automatic process:                                                     Manual hours required:                                  hours                     Type of manual labor:                                                  Term positions used:                                                   Only single terms used:                                                Concepts (vs. single terms) represented:                                               Number of concepts represented:                                                                       Type of representation:                                                Auxilary files used:                                                       Type of auxilary files used:                                                            Additional comments:                                                                    Section 3.3 Third Data Structure                                            Structure Type:                                                        Type of other data structure used:                                     Brief description of method using other data structure:                     Total storage used:                                     Gb                 Total computer time to build:                           hours                 Automatic process:                                                     Manual hours required:                                  hours                    Type of manual labor:                                                  Term positions used:                                                   Only single terms used:                                                Concepts (vs. single terms) represented:                                               Number of concepts represented:                                                                       Type of representation:                                                Auxilary files used:                                                                   Type of auxilary files used:                                                                        Additional comments:                                                                      Section 4.0 Data Built from Sources Other than the Input Text                                       Internally-built Auxiliary File                         File type:                                                 Domain type:                                               Total Storage:                      Gb                         Number of Concepts Represented:     concepts                         Type of representation:                                    Automatic or Manual:                                                                               Total Time to Build:                       hours                                 Total Time to Modify (if already built):   hours                                                          Type of Manual Labor used:                                    Additional comments:                                                          Externally-built Auxiliary File                          File is:                                   Total Storage:      Gb                          Number of Concepts Represented:   concepts                          Type of representation:                                   Additional comments:                                                   Section 5.0 Computer Searching                                  Average computer time to search (per query):    CPU seconds                                Times broken down by component(s):                                Section 5.1 Searching Methods                                      Vector space model:                            Probabilistic model:                           Cluster searching:                             N-gram matching:                               Boolean matching:                              Fuzzy logic:                                   Free text scanning:                            Neural networks:                               Conceptual graphic matching:                   Other:                                         Additional comments:                                          Section 5.2 Factors in Ranking                               Term frequency:                                          Inverse document frequency:                              Other term weights:                                      Semantic closeness:                                      Position in document:                                    Syntactic clues:                                         Proximity of terms:                                      Information theoretic weights:                           Document length:                                         Percentage of query terms which match:                   N-gram frequency:                                        Word specificity:                                        Word sense frequency:                                    Cluster distance:                                        Other:                                                   Additional comments:                                                      Section 6.0 Query Construction                                      Section 6.1 Automatically Built Queries for Ad-hoc Tasks                                 Topic fields used:                              Average computer time to build query                                    CPU seconds        Term weighting  (weights based on terms in topics) :           Phrase extraction from topics:                                       Syntactic parsing of topics:                                         Word sense disambiguation:                                           Proper noun identification algorithm:                                     Tokenizer:                                                                       Patterns which were tokenized:                                                              Expansion of queries using previously constructed data structures:                      Comment:                                                                                    Automatic addition of:                                                                            Section 6.2 Manually Constructed Queries for Ad-hoc Tasks                            Topic fields used:                                    Average time to build query?                   minutes        Type of query builder:                             Tool used to build query:                          Method used in intial query construction?                      If yes, what was the source of terms?                                         Total CPU time for all iterations:            seconds          Clock time from initial construction of query to completion of final query:                    minutes         Average number of iterations:                       Average number of documents examined per iteration:         Minimum number of iterations:                               Maximum number of iterations:                               The end of an iteration is determined by:                   Automatic term reweighting from relevant documents:         Automatic query expansion from relevant documents:                      Type of automatic query expansion:                                               Other automatic methods:                                                Other automatic methods included:                                               Manual methods used:                                                    Type of manual method used:                                                                        Send questions to  trec@nist.gov            Disclaimer:  Contents of this online document are not necessarily the official          views of, nor endorsed by the U.S. Government, the Department of Commerce, or NIST."
GX029-24-9308826	"Text REtrieval Conference (TREC)   System Description                            Organization Name:    University of Limerick         Run ID:               DLT02QA01                          Section 1.0 System Summary and Timing                             Section 1.1 System Information                                    Hardware Model Used for TREC Experiment:    Dell OptiPlex GX200                 System Use:                         DEDICATED                 Total Amount of Hard Disk Storage:  66.73 Gb                 Total Amount of RAM:                256 MB                 Clock Rate of CPU:                  733 MHz                                Section 1.2 System Comparisons                                    Amount of developmental ""Software Engineering"":    ALL                 List of features that are not present in the system,  but would have been beneficial to have:   Larger gazetteer and list of person names, more extensive query categorisation, more named entities, refined matching                 List of features that are present in the system, and  impacted its performance, but are not detailed within this form:     Query categorisation, Named Entity Recognition, Target Term Recognition, Target Term/Named Entity Matching                                 Section 2.0 Construction of Indices, Knowledge Bases, and Other Data Structures                                     Length of the stopword list:  289 words                Type of Stemming:             MORPHOLOGICAL                Controlled Vocabulary:        NO                Term weighting:               NO                               Additional Comments on term weighting:                                     Phrase discovery:             YES                               Kind of phrase:                              Named Entities               Method used:                                 SYNTACTIC                              Type of Spelling Correction:  NONE                Manually-Indexed Terms:       NO                Proper Noun Identification:   YES                Syntactic Parsing:            YES                Tokenizer:                    YES                Word Sense Disambiguation:    NO                Other technique:              NO                Additional comments:                                           Section 3.0 Statistics on Data Structures Built from TREC Text                                     Section 3.1 First Data Structure                                     Structure Type:                                       OTHER DATA STRUCTURE                 Type of other data structure used:                    Parsed & Annotated Text                 Brief description of method using other data structure:   Matching                  Total storage used:                                   0.1 Gb                 Total computer time to build:                         unknown hours                 Automatic process:                                    YES                 Manual hours required:                                 hours                 Type of manual labor:                                 NONE                 Term positions used:                                  NO                 Only single terms used:                               NO                 Concepts (vs. single terms) represented:              NO                     Number of concepts represented:                                                          Type of representation:                                               Auxilary files used:                                  NO                     Type of auxilary files used:                                                           Additional comments:                                                                        Section 3.2 Second Data Structure                                         Structure Type:                                        NONE                 Type of other data structure used:                                     Brief description of method using other data structure:                      Total storage used:                                     Gb                 Total computer time to build:                           hours                 Automatic process:                                                     Manual hours required:                                  hours                     Type of manual labor:                                  NONE                 Term positions used:                                                   Only single terms used:                                                Concepts (vs. single terms) represented:                                               Number of concepts represented:                                                                       Type of representation:                                                Auxilary files used:                                                       Type of auxilary files used:                                                            Additional comments:                                                                    Section 3.3 Third Data Structure                                            Structure Type:                                        NONE                 Type of other data structure used:                                     Brief description of method using other data structure:                     Total storage used:                                     Gb                 Total computer time to build:                           hours                 Automatic process:                                                     Manual hours required:                                  hours                    Type of manual labor:                                  NONE                 Term positions used:                                                   Only single terms used:                                                Concepts (vs. single terms) represented:                                               Number of concepts represented:                                                                       Type of representation:                                                Auxilary files used:                                                                   Type of auxilary files used:                                                                        Additional comments:                                                                      Section 4.0 Data Built from Sources Other than the Input Text                                       Internally-built Auxiliary File                         File type:                         OTHER                         Domain type:                       DOMAIN INDEPENDENT                         Total Storage:                      Gb                         Number of Concepts Represented:     concepts                         Type of representation:            NONE                         Automatic or Manual:               AUTOMATIC                                                                 Total Time to Build:                       hours                                 Total Time to Modify (if already built):  2 hours                                                          Type of Manual Labor used:         NONE                           Additional comments:               Gazetteer, list of person names, machine readable dictionary might come under this category.                                           Externally-built Auxiliary File                          File is:           NONE                         Total Storage:      Gb                          Number of Concepts Represented:   concepts                          Type of representation:          NONE                          Additional comments:                                                   Section 5.0 Computer Searching                                  Average computer time to search (per query):   79 CPU seconds                                Times broken down by component(s):   Unknown                             Section 5.1 Searching Methods                                      Vector space model:            NO                 Probabilistic model:           NO                 Cluster searching:             NO                 N-gram matching:               NO                 Boolean matching:              NO                 Fuzzy logic:                   NO                 Free text scanning:            YES                 Neural networks:               NO                 Conceptual graphic matching:   NO                 Other:                         YES                 Additional comments:                                          Section 5.2 Factors in Ranking                               Term frequency:                          YES                 Inverse document frequency:              NO                 Other term weights:                      NO                 Semantic closeness:                      NO                 Position in document:                                    Syntactic clues:                                         Proximity of terms:                                      Information theoretic weights:                           Document length:                                         Percentage of query terms which match:                   N-gram frequency:                                        Word specificity:                                        Word sense frequency:                                    Cluster distance:                                        Other:                                                   Additional comments:                                                      Section 6.0 Query Construction                                      Section 6.1 Automatically Built Queries for Ad-hoc Tasks                                 Topic fields used:                              Average computer time to build query                                    CPU seconds        Term weighting  (weights based on terms in topics) :           Phrase extraction from topics:                                       Syntactic parsing of topics:                                         Word sense disambiguation:                                           Proper noun identification algorithm:                                     Tokenizer:                                                                       Patterns which were tokenized:                                                              Expansion of queries using previously constructed data structures:                      Comment:                                                                                    Automatic addition of:                                                                            Section 6.2 Manually Constructed Queries for Ad-hoc Tasks                            Topic fields used:                                    Average time to build query?                   minutes        Type of query builder:                             Tool used to build query:                          Method used in intial query construction?                      If yes, what was the source of terms?                                         Total CPU time for all iterations:            seconds          Clock time from initial construction of query to completion of final query:                    minutes         Average number of iterations:                       Average number of documents examined per iteration:         Minimum number of iterations:                               Maximum number of iterations:                               The end of an iteration is determined by:                   Automatic term reweighting from relevant documents:         Automatic query expansion from relevant documents:                      Type of automatic query expansion:                                               Other automatic methods:                                                Other automatic methods included:                                               Manual methods used:                                                    Type of manual method used:                                                                        Send questions to  trec@nist.gov            Disclaimer:  Contents of this online document are not necessarily the official          views of, nor endorsed by the U.S. Government, the Department of Commerce, or NIST."
GX042-28-3186006	Microsoft Office XP: New Office-wide Features                              Description:                This learning path describes the key new features and feature enhancements contained in Microsoft Office XP.                                           Prerequisites:       A good working knowledge of Microsoft Office 2000                                         Audience:       End-users                                          Certfication:       None                                        Duration:       2 hours                                   New Features Review                                                                Learning        Objective :       To outline the key new features contained in Microsoft Office XP                                                       Learning Event:                                                   Learning Objects:                                         Learning Objective Type:                                                          User-support features                                 Installation and navigation in Office XP           Office XP's enhanced edit, help, and customization           Office XP's new copy and paste features                                               Instructional (interactive graphical)                                         Instructional (interactive graphical)                                         Software                                          User-input and reliability features                             Office XP speech recognition           Imaging and handwriting features in Office XP           Robustness and reliability in Office XP           Enhanced Office XP search functionality           Searching in Office XP                                                    Instructional (interactive graphical)                    Instructional (interactive graphical)                    Instructional (interactive graphical)                    Instructional (interactive graphical)                    Software                                            Learning Path Structure                                There are no further modules in this learning path
GX234-07-9112289	ACCESS 2002 COMPARED TO ACCESS  97       Access 2002's New Features Compared to Access 97       New Access 2002 format is faster and more efficient for working with large    databases     Designed to allow for future additional properties and events that caused    format changes in past versions     Access 2002 works in and modifies Access 2000 files without converting the    file format     Access 2000 is the default format in Access 2002 for new databases     Extended SQL Server support and integration     Multiple undo/redo     Allows batch updates using SQL Server     Conversion error logging     Smart Tags      Task Panes      Improved Compact and Repair options to compress and fix databases     XML support for better Internet support     Allows for digital signatures     Improved collaborating and reviewing features     PivotChart and PivotTable Views     Speech recognition     Handwriting recognition (as an upload from a PDA)     Enhanced Data Access Page HTML designer     Better integration with the other Office components     Better integration with the Internet     Allows databases to be converted to previous versions of Access     Conditional formatting        Access 97 => Access 2000 Conversion            There are some programming statements that have a    slightly different format in Access 2000 compared to Access 97.  There are    some programming statements that are not supported in Access 2000.  So there    might be some programming changes that will have to be done to enable the    forms or routines to run correctly.           Tool and Menu Bars might be in a different style         Access 2000 supports only 1,000 Visual Basic modules    while Access 97 supports 1,024 – so there may be an issue where that limit    might be reached         Label reports in databases that have been converted to    Access 2002 might display incorrectly if the field name is the same as an    Access reserved name or global keyword         Access 2000 => Access 2002 Conversion            Access 2002 is able to run and modify Access 2000    databases without converting them.  So there should be no changes required in    Access 2000 databases when people get converted to Access 2002.            Conversion Tips            Code compatibility    Access 2000 or later does not    support the Microsoft    DAO  2.5/3.x    compatibility library. If you attempt to convert an Access database in which    the code contains older versions of DAO objects, methods, and properties that    depend on the DAO 2.5/3.x compatibility library, you receive a message that    there were compilation errors during the conversion of the database. Before    you convert an Access database, update the code so that it does not depend on    the DAO 2.5/3.x compatibility library. If you still receive a message that    there were compilation errors during conversion, open the converted database    in Access 2002, remove the reference to the missing DAO 2.5/3.x compatibility    library, and then set a reference to the Microsoft DAO 3.6 Object Library.         If your Access database uses    add-ins  or    library databases     created in Access 97 or earlier, you must convert them as well. However, you    can use an add-in or library database created in Access 2000 with a file in    Access 2002 format.         DoMenuItem replaced with RunCommand   The DoMenuItem action is    replaced in Microsoft Access 2000 or later with the RunCommand action;    DoMenuItem is still supported for backwards compatibility.           Access WebPages    Microsoft’s Access Homepage:     http://www.microsoft.com/office/access/   MS Product Guide for Access (page allow you to download the  document):     http://www.microsoft.com/office/access/evaluation/guide.htm   MS Assistance Center Page for Access 2002:   http://search.office.microsoft.com/assistance/product.aspx?p=Access   MS Page Comparing Different Versions of Office:   http://www.microsoft.com/office/evaluation/indepth/compare.htm   Review of Access XP (2002):     http://www.activewin.com/reviews/software/apps/ms/officexp/access2002.shtml
GX009-17-16708162	ORNL Grail Form (v1.3)
GX007-36-14300895	Entrez   PubMed   Nucleotide   Protein   Genome   Structure   PMC   Journals   Books                                                               Search        PubMed   Protein   Nucleotide   Structure   Genome   Books   3D Domains   Domains   Gene   GEO   GEO DataSets   Journals   MeSH   NCBI Web Site   OMIM   PMC   PopSet   SNP   Taxonomy   UniGene   UniSTS            for                                                                                                                                                                                               Limits   Preview/Index   History   Clipboard   Details                                                                                                                                                                                          About Entrez                                                                                                                    Text Version   Entrez PubMed     Overview   Help |    FAQ   Tutorial   New/Noteworthy   E-Utilities     PubMed Services   Journals Database   MeSH Database   Single Citation Matcher   Batch Citation Matcher   Clinical Queries   LinkOut   Cubby     Related Resources   Order Documents   NLM Gateway   TOXNET   Consumer Health   Clinical Alerts   ClinicalTrials.gov   PubMed Central     Privacy Policy                                                                                          Enter one or more search terms, or click   Preview/Index  for advanced searching.      Enter  author names  as smith jc. Initials are optional.      Enter  journal titles  in full or as MEDLINE abbreviations. Use the  Journals Database  to find journal titles.                                             PubMed, a service of the National Library of Medicine, includes over 14 million citations for biomedical articles back to the 1950's.  These citations are from MEDLINE and additional life science journals. PubMed includes links to many sites providing full text articles and other related resources.                                              Bookshelf Additions                                     New PubMed Features                                                                                                                                                                  There are two new books now available                for interactive searches on the  Bookshelf :                                             1.  Genomes  by  T. A. Brown.                2.  Human Molecular Genetics  by  Tom Strachan and Andrew P. Read.                            MEDLINE citations and the MeSH database have been updated with 2004  MeSH vocabulary .                                                                                                                                                                 Write to the Help Desk   NCBI  |  NLM  |  NIH   Department of Health & Human Services   Freedom of Information Act  |  Disclaimer          Dec  1 2003 07:03:59
GX242-12-14398137	"Handheld Personal Computers  An Evaluation of HPC Models and Usefulness 584.W   Overview n n  Introduction and Background Basic Features     User Interface Office Applications Synchronization Email and Web  n n n n n  Extended Features  Connectivity, Voice, Printing, Video  Software Availability Models Evaluated Tips and Recommendations Trends   Introduction and Background Why did we do this and why are we talking about it? n  584.W initiated an evaluation of HPCs with several goals:  To learn about the devices and their usefulness for projects  Explore alternatives for laptops  cost  size/weight  battery life  Enhance employees connectivity / portability of office tools  schedules  data  applications  web  n  Several groups have expressed interest in the results  Managers, IT managers, travellers, tech-types   Introduction and Background Evaluation Assumptions n  A significant subset of laptop users carry them for reasons related to connectivity     Email Presentations Web access No heavy typing  n  Laptop functionlity is desireable at a lower weight and price point  $3000 is very normal, Office application licenses extra  Size DOES matter -- an extra carry-on is usually required  Discreteness in meetings is impossible  n  Not every laptop user could benefit   Basic Features So, what is an HPC (and what is it not)? n  An HPC is:       a ""real"" computer with CPU, keyboard, memory, connectivity light -- weighs from 12 - 22 oz. small -- ranging from 7""x3"" to 9""x5"" (all are about 1.3"" high) familiar -- desktop looks just like your Win95 or NT desktop fast -- 66-75Mhz CPUs common, applications are loaded in ROM flexible -- software applications are easy to find  n  An HPC is not:  a PalmPilot -- Palm Top Computers are a different class of system  no keyboard, primarly organizers, much less compute power,   easy to type on for long periods of time -- keyboards are small  a good storage device -- no hard drive, ususally 24-32Mb RAM   Basic Features User Interface (How do I use this thing?) n  Windows CE interface looks identical to ` or NT desktop 95  Icons are identical (files, folders, taskbar, start button)  Navigation is identical (Explorer, Recycle Bin, clicking, cut/paste..)  n n n n  Touchscreeens are the standard fare  A` stylus'is used rather than a mouse for interaction  Screens are 640 x 240 (about half pixel height of a desktop)  text is compressed but can be sized up or down using fonts  Letter keys are ` chicklet'sized  touch typing is not really an option  Almost all have hot function keys  one touch access to popular programs   Office Applications What are the standard software packages? (Microsoft strikes again) n  Pocket Word, Excel, PowerPoint  Reduced memory versions scaled for CE and ROM resident  PowerPoint is display only in current versions   Fewer fonts, insertable objects, and less overall flexibility  Identical ""look and feel"" with desktop versions n  Pocket Outlook and Schedule+  Appointment scheduling  Alarming  Notepad associated with each appointment for meeting notes/actions  n  Bfax Suite  Send and receive faxes using modem   Synchronization Interacting with your PC n n n  Remote Mounted Disk  serial cable, usually in conjunction with a docking cradle  Manual File Manipulation  click and drag files between computers  Active Synchronization    ` Synchronization Directory'contents automatically updated Upon completion, most current version is on both machines Automatic synchronization of schedule applications/cardfiles   Email and Web Access Staying connected on the road n n  Requires a modem (more later on modems) Email  MS Exchange for WinCE is included in Exchange Server  Downloads only sender/subject/size to conserve memory  User manually selects messages for full content download  Messages retained on server or not per individual settings   Third Party packages available  Email free using Web accounts (Yahoo, HotBot, ... ... )  When on travel filter/forward your mail to travel account for access n  Web Access  Pocket Internet Explorer included with WinCE  Virtually identical to standard version except for cacheing   Extended Features Cool extras worth having n  Connectivity via Modem  PC Card modems available  Use lots of power and are one more thing to lose   Built-in ` low power'modems in some models  33Kbps is standard and plugs into a standard phone jack n  Voice  Voice recorders almost a standard feature  Record notes to yourself, or save as a file an email as an attachment  Usually accessible with external button (no need to open or power up)  n  Printing  Infrared print port works with IrDA compatible printers (most HP)   Extended Features More extras maybe worth having n  Video Camera  PC Card Digital Camera Unit  HPC memory used to store images captured  Useful for capturing whiteboard info or ` is'installations... ... as  n  Video Drivers  PC Card to VGA connector  HPC can drive standard PC monitors / overhead projectors  Useful for giving presentations   Software Availability More neat stuff that doesn' require more hardware t n  Many applications available on-line  Business, drawing, connectivity, maps, games, special interest  Several packages come bundled with systems  Special purpose software can be created with existing tools  n  Specific applications evaluated  CalliGrapher Handwriting Recognition software  learns your block or cursive writing and reduces keyboard use   Quicken Traveler  Tracks expenses for travel or projects   On Schedule  Enhanced Scheduler   Models Evaluated The fun part! n  HP 620/660 ($800.00)    16Mb RAM upgradeable, color screen, bundled s/w, cradle Main Strengths: viewability, color screen, bundled software Main Weaknesses: price, size, no modem 24Mb RAM upgradeable, b/w screen, modem, cradle, bundled s/w Main Strengths: price, modem, size, battery life Main Weaknesses: viewability, keyboard usability 16Mb RAM, color screen, modem, (optional camera for $300.00) Main Strength: price with color screen, size, modem, camera Main Weakness: lack of RAM upgradeability, keyboard  model 5600 ($800.00) upgradeable to 32Mb  n  Phillips Velo 500 ($500.00)     n  Sharp Mobilion 4500 ($600.00)      Tips and Recommendations Out on a limb n  Tips          Don' get an HPC and expect to be able to type normally t Get the handwriting recognition software (and use it) If you will use an HPC in non-office lighting, get a color screen Search for downloadable software before you buy software Buy an extra stylus or two and never use your finger on the screen In a pinch, almost all HPCs can run on 2 AA batteries for 4 hours Use synchronization often, don' accumulate data t Look around to find the nearest IrDA capable printer Save some money, buy 3 or 4 HPCs instread of one laptop  n  Recommendations  If prime consideration is price or size, buy a Phillips Velo  If prime consideration is viewability, buy an HP 660  If prime consideration is anything else, buy a Sharp Mobilion 5600   Trends A guess (educated and otherwise) at what the future holds n n n n n n  PowerPoint will be able to create/modify slides Additional memory/storage will be available in card form  IBM microdrive, PC slot card flash storage  Color screens will become standard Integrated wireless modems will become popular (Nokia) Assistive technology applications will proliferate  project management tools, personal assistants  Prices will stabilize at $600 to $700 depending on features   In Closing... ... ... . n  n  n  n  Your feedback on the effectiveness/usefulness of this session/ presentation would be appreciated. Email comments to thomas.j.pittman.1@gsfc.nasa.gov If you found this session/presentation useful, would like more information, or to try one of the three models tested, contact Jay Pittman at WFF extension 1506 or by email at thomas.j.pittman.1@gsfc.nasa.gov If you think presentations on similar (or even wildly different) Information Systems topics would be useful, send your ideas to thomas.j.pittman.1@gsfc.nasa.gov Thanks for your attention"
GX010-81-13483098	"Disclaimer/Privacy                                                                  HIV Sequence Database: Other Tools        Links to other software resources:      Phylogenetics           MEGA    MEGA is a versatile, user-friendly program that does phylogenetic analysis and bootstrapping. PC-Windows.      Tree-Puzzle    ""TREE-PUZZLE is a computer program to reconstruct phylogenetic trees from molecular sequence data by maximum likelihood.  It implements a fast tree search algorithm, quartet puzzling, that allows analysis of large data sets and automatically assigns  estimations of support to each internal branch."" PC-windows, UNIX, Mac, VMS.      TreeFinder    A very fast ML tree program. ""TREEFINDER computes phylogenetic trees from nucleotide sequences using Maximum Likelihood and supports six popular models of sequence evolution up to the general time reversible model with Gamma distributed rates  among sites. All model parameters including the rate heterogeneity can be estimated from the data."" PC-windows, UNIX, Mac.      Treeview    Treeview displays treefiles; more flexible and easy to use than Drawtree/Drawgram. PC-windows, Mac, Linux/UNIX.        Modeltest    ""Modeltest helps a user to choose the model of DNA substitution that best fits his/her data, among 56 possible models."" PC-windows, UNIX, Mac.      Phylogenetic Analysis    A comprehensive list of programs for creating phylogenetic trees, maintained by Joe Felsenstein at the University of Washington.        Multiple Sequence Alignment Tools            BioEdit     is a new alignment editor for PC-Windows that allows switching from nucleotide to amino acid view and aligning both simultaneously. It comes with various alignment programs (e.g. Clustal) and tree-building programs (e.g. fastDNAML) built in. Very nifty and up-to-date.       Hidden Markov Models     This is a link to the HMMER programs developed by Sean Eddy. We now use HMMs to dynamically generate alignments for our  search interface .         CLUSTALX   CLUSTALX is distibuted as executables for DOS/Windows, Mac and UNIX operating systems.               Se-Al     Se-Al is a very user-friendly alignment editor that does codon-based alignments  (i.e. alignments that do not destroy the reading frame). This program is only available for Macs.         Multiple Sequence Alignment    A collection of alignment programs such as CLUSTALW, for aligning nucleic acid or amino acid sequences.  Maintained by the  Department of Genetics  at the University of Washington,  Seattle.      (SAM) - Sequence Alignment and Modeling Programs   Similar to HMMER, this is a package of tools for building and using Hidden Markov Models of multiple sequence alignments.  SAM  includes programs to convert between the formats for SAM and HMMER.        Other software                 Simplot           A tool for recombination analysis by Stuart Ray from Johns Hopkins University; it does both similarity plots and bootscan analysis. This tool is by far the most widely used for recombination analysis in HIV research.           HIV Subtyping using BLAST           This website allows subtyping of a new sequence by comparing it to a  set of reference sequences using the BLAST local similarity search algorithm. Try the advanced tool for more options.      Sequence Submission to Databases     SEQUIN and BANKIT are tools developed by NCBI for automating         and error-checking database submissions.    Recombination detection and analysis programs         This page of links is maintained by David Robertson at Oxford University.                                                                    Questions or comments? Contact us at  seq-info@t10.lanl.gov                                                                                                                                Operated by the  University of California               for the US  Department of Energy                Copyright © 2001 UC  |               Disclaimer/Privacy"
GX036-02-13273022	"HMMERSEARCH     [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]      Table of Contents      FUNCTION   DESCRIPTION   EXAMPLE   OUTPUT   INTERPRETING OUTPUT   INPUT FILES   RELATED PROGRAMS   RESTRICTIONS   ALGORITHM   CONSIDERATIONS   COMMAND-LINE SUMMARY   ACKNOWLEDGEMENT   LOCAL DATA FILES   PARAMETER REFERENCE                       FUNCTION    [   Top  |  Next  ]          HmmerSearch uses a profile hidden  Markov model as a query  to search a sequence database  to find  sequences similar to the family  from which the profile HMM  was built.  Profile HMMs  can be created  using HmmerBuild.        DESCRIPTION    [  Previous  |  Top  |  Next  ]          HmmerSearch provides a Wisconsin Package  interface to the hmmsearch program  of Dr. Sean Eddy's  HMMER package.  It allows  you to access most of  hmmsearch's parameters from the Wisconsin  Package command line.    HmmerSearch uses a profile hidden  Markov model, which represents a  group of aligned sequences, as  a  query to search a sequence  database for related sequences.   The alignments of the profile  HMM to the  best-scoring sequences are displayed in  the output.           EXAMPLE    [  Previous  |  Top  |  Next  ]          Here is a session using  HmmerSearch to search the PIR  protein sequence database with a  profile HMM  generated from a group of  aligned 70kd heat shock and  heat shock cognate protein sequences.   The  profile HMM was created in  the example session from the  HmmerBuild program and calibrated in  the  example session from HmmerCalibrate.          %  hmmersearch    HMMERSEARCH using what profile HMM as the query ?   hsp70.hmm_g    Search for query in what sequence(s) ?   PIR1:*    What should the output file be called (* hmmersearch.hmmersearch *)?   Creating temp file for input to hmmsearch.   Calling hmmsearch to perform analysis ...  hmmsearch - search a sequence database with a profile HMM HMMER 2.1.1 (Dec 1998) Copyright (C) 1992-1998 Washington University School of Medicine HMMER is freely distributed under the GNU General Public License (GPL). - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - HMM file:                 /package/share/10.2/gcghelp/docdata/hsp70.hmm_g  [hsp70] Sequence database:        PIR1:* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -            1 Sequences                        105 aa searched  PIR1:CCHU         101 Sequences                     10,897 aa searched  PIR1:S00034         201 Sequences                     28,069 aa searched  PIR1:CCBO11         301 Sequences                     56,257 aa searched  PIR1:S25953         401 Sequences                     73,034 aa searched  PIR1:S47288         501 Sequences                    118,925 aa searched  PIR1:A31854          ////////////////////////////////////////////////////////////////       20,201 Sequences                  7,921,432 aa searched  PIR1:S58884      20,301 Sequences                  7,971,437 aa searched  PIR1:S69204      20,401 Sequences                  8,008,087 aa searched  PIR1:S69334  %              OUTPUT    [  Previous  |  Top  |  Next  ]          Here is part of the  output file:        !!SEQUENCE_LIST 1.0  Query HMM: hsp70||   [HMM has been calibrated; E-values are empirical estimates]  Scores for complete sequences (score includes all domains): Sequence Description                                    Score    E-value  N -------- -----------                                    -----    ------- --- HHXL70   dnaK-type molecular chaperone - African claw  1723.6          0   1 HHUM7B   dnaK-type molecular chaperone - lettuce down  1691.0          0   1 HHKW7A   dnaK-type molecular chaperone hsp70A - Caeno  1687.1          0   1  ////////////////////////////////////////////////////////////////////////////  S21801   myosin heavy chain, neuronal [similarity] -   -404.3        8.4   1 GNNYEB   genome polyprotein - encephalomyocarditis vi  -406.2        9.9   1  [no more scores below E threshold]  Parsed for domains: Sequence --------    Domain  seq-f seq-t    hmm-f hmm-t      score  E-value    ------- ----- -----    ----- -----      -----  -------  .. PIR1:HHXL70 Begin:2 End:647 !!   1/1       2   647 .]     1   677 []  1723.6        0 PIR1:HHUM7B Begin:4 End:675 !!   1/1       4   675 .]     1   677 []  1691.0        0 PIR1:HHKW7A Begin:1 End:640 !!   1/1       1   640 []     1   677 []  1687.1        0  /////////////////////////////////////////////////////////  PIR1:S21801 Begin:497 End:1032 !!   1/1     497  1032 ..     1   677 []  -404.3      8.4 PIR1:GNNYEB Begin:1049 End:1615 !!   1/1    1049  1615 ..     1   677 []  -406.2      9.9 \\End of List  Alignments of top-scoring domains: HHXL70: domain 1 of 1, from 2 to 647: score 1723.6, E = 0                    *->kvkgkaiGIDLGTTYSCVgvfqngkveIIANdqGNRtTPSyVAFTDt                       ++kg a+GIDLGTTYSCVgvfq+gkveIIANdqGNRtTPSyVAFTDt       HHXL70     2    ATKGVAVGIDLGTTYSCVGVFQHGKVEIIANDQGNRTTPSYVAFTDT 48                     ERLIGdaAKnQvAmNPqNTVFDaKRLIGRkFnDpeVQsDmkhwPFkvisk                    ERLIGdaAKnQvAmNPqNTVFDaKRLIGRkFnDp+VQ D+khwPF+v+s       HHXL70    49 ERLIGDAAKNQVAMNPQNTVFDAKRLIGRKFNDPVVQCDLKHWPFQVVS- 97        //////////////////////////////////////////////////////////////////                     elgmpggapggmqgapkggsssGptiEeVD<-*                      gmpg+++g+ q++  +g +sGptiEeVD       HHXL70   623 --GMPGSSCGA-QAR--QGGNSGPTIEEVD    647        //////////////////////////////////////////////////////////////////  Histogram of all scores: score    obs    exp  (one = represents 2 sequences) -----    ---    ---  ///////////////////////////////////////////////////////////////////////////////   -465     50    135|=========================                                 *  -464     50    125|=========================                                 *  -463     57    115|=============================                            *  -462     50    106|=========================                           *  -461     54     97|===========================                     *  -460     44     90|======================                      *  -459     49     82|=========================               *  -458     39     76|====================                 *  -457     44     70|======================            *  -456     51     64|==========================     *  -455     40     59|====================         *  -454     50     54|========================= *  -453     29     49|===============         *  -452     39     45|====================  *  -451     37     42|=================== *  -450     31     38|================  *  -449     39     35|=================*==  -448     30     32|===============*  -447     28     29|==============*  -446     29     27|=============*=  -445     28     25|============*=  -444     34     22|==========*======  -443     26     21|==========*==  -442     24     19|=========*==  -441     24     17|========*===  -440     20     16|=======*==  -439     21     14|======*====  -438     27     13|======*=======  -437     15     12|=====*==  -436     12     11|=====*  -435     14     10|====*==  -434      9      9|====*  -433     11      8|===*==  -432     12      8|===*==  -431      6      7|===*  -430      2      6|= *  -429      6      6|==*  -428      6      5|==*  -427      3      5|==*  -426      3      4|=*  -425      6      4|=*=  -424      5      3|=*=  -423      1      3|=*  -422      4      3|=*  -421      3      3|=*  -420      2      2|*  -419      0      2|*  -418      3      2|*=  -417      0      2|*  -416      1      1|*  -415      2      1|* >-414     17      -|=========  % Statistical details of theoretical EVD fit:               mu =  -492.8923           lambda =     0.0880 chi-sq statistic = 13046.1133   P(chi-square)  =          0  Total sequences searched: 20405  Whole sequence top hits: tophits_s report:      Total hits:           29      Satisfying E cutoff:  13      Total memory:         19K  Domain top hits: tophits_s report:      Total hits:           29      Satisfying E cutoff:  29      Total memory:         82K              INTERPRETING OUTPUT    [  Previous  |  Top  |  Next  ]                   Sequence and Domain Scores          The first section of the  output is the list of  best sequences.  HmmerSearch lists  the sequences  with the best E-values based  on  all  domains in each  sequence that matched the profile  HMM.  The raw scores are expressed  as bit values.  If  the profile HMM matched more  than one place in  the sequence, the scores for  each matching domain contribute to  the total score.  The  number of  domains that matched the query  HMM are displayed in the  rightmost column of this list.   By  default, every sequence with an  E-value less than 10.0 is  listed in this output.    The second section of the  output is the list of  best domains.  It is  formatted as a GCG list  file, so  that the HmmerSearch output can  be used as input for  any GCG program that accepts  list files.  HmmerSearch lists the top-scoring domains  along with their raw scores  and E-values.  It  displays their begin and end  coordinates under the seq-f (""sequence-from"")  and seq-t  (""sequence-to"") headings.  It also  lists the begin and end  coordinates of the matching portion  of  the profile HMM (under the  headings hmm-f and hmm-t).    After each set of begin  and end coordinates is a  two-character code that tells you  if the alignment  is local or global with  respect to the sequence and  to the profile HMM.   In general, a left bracket  ([) means the alignment started  at the beginning of the  sequence or profile HMM, a  right bracket  (]), means the alignment ended  at the end of the  sequence or profile HMM, and  a period means  that the alignment started or  ended in the middle of  the sequence or profile HMM.    For example, in the following  line from a HmmerSearch output,                         !!   1/1       1   492 []   345   889 .]  1175.5        0            the sequence coordinates for the  alignment are 1-492, and the  [] code following 492 means  that  the alignment was global with  respect to the sequence --  it started at the beginning  of the  sequence and continued to the  end of the sequence.   The profile HMM coordinates are  345-889,  and the .] code after  889 means that the alignment  was local with respect to  the profile HMM --  it started somewhere after the  beginning of the profile HMM  and continued to its end.    If a sequence has more  than one domain that matched  the profile HMM, its name  may occur  more than once in this  list.  The number of  the domain is noted:  for example,  if a single domain  matched the query, the entry  is labeled 1/1;  if the domain  is the second of three  that matched, it  is labeled 2/3.  By  default, for every sequence with  an E-value less than 10.0,  every domain it  contains that has a non-zero  raw score is listed.        The Alignments          The next section of the  output displays the alignments between  the profile HMM consensus  sequence and the best-scoring domains.   These are displayed somewhat  differently than most  GCG alignments.    The top line is the  ""consensus"" sequence of the profile  HMM.  The residues shown  are the highest  probability residues at each position  according to the model.   (There is no attempt to  use an  ambiguous symbol to denote a  position that can contain more  than one type of residue,  so it isn't  a consensus in the commonly  used sense of the word.)  A  residue is printed as a  capital letter if it  is highly conserved, otherwise it  is printed in lowercase.   For protein models, highly conserved  amino acids are defined to  be those that have a  probability greater than 0.5;  for nucleic  acid  models, highly conserved nucleotides are  those with a probability greater  than 0.9.  If the  sequence contains positions not present  in the model, periods are  inserted into the profile HMM  consensus sequence to denote the  gap.    The center line of the  alignment is a representation of  the quality of the alignment.   A letter  appears at positions where the  sequence and the profile HMM  consensus are identical.  The  letter will be upper- or  lowercase in accordance with the  case of the profile HMM  consensus.  If  the residues at that position  are not identical but have  a positive score, a plus  sign is displayed,  and the relationship is considered  to be ""conservative"" according to  the HMM's view of this  particular position in the model  (not to be confused with  the usual definition of conservative  changes).  If the score  is not positive, a space  appears.    The third line of the  alignment shows the sequence itself.   In this line, gaps  are indicated with  hyphens rather than periods.        The Histogram and Statistical Information          Following the alignments is the  histogram of sequence scores, based  on the overall score for  each  sequence (not the scores for  individual domains).  Each row  displays the data for one  raw score:  how many of the sequences  had that score (obs), how  many were expected to have  that score  (exp), and a bar whose  length is proportional to the  number of sequences with that  score.  Equal  signs (=) are used to  represent the observed number of  scores, while an asterisk (*)  is placed at  the position corresponding to the  expected number of scores.    Beneath the histogram is statistical  information about the search: the  parameters for the  extreme value distribution of scores,  the number of sequences searched,  the number of sequences  and domains that satisfied the  E-value cutoff, etc.             INPUT FILES    [  Previous  |  Top  |  Next  ]          HmmerSearch requires as one of  its inputs a profile HMM  file.  You can create  profile HMM files from  a set of aligned sequences  using the HmmerBuild program.    The other input to HmmerSearch  is a sequence database or  a multiple sequence specification.   The  sequences must be of the  same type as the sequences  that were used to create  the profile HMM.    You can specify multiple sequences  in a number of ways:  by  using a list file, for  example   @project.list ;  by using an MSF or  RSF file, for example  project.msf{*} ;  or  by using a  sequence specification with an asterisk  ( * ) wildcard, for example  GenEMBL:* .    The function of HmmerSearch depends  on whether your input sequence(s)  are protein or nucleotide.  Programs determine the type of  a sequence by the presence  of either  Type: N  or   Type: P  on the last  line of the text heading  just above the sequence.   If your sequence(s) are not  the correct type, turn to  Appendix VI for information on how  to change or set the  type of a sequence.        RELATED PROGRAMS    [  Previous  |  Top  |  Next  ]           PileUp  creates a multiple sequence  alignment from a group of  related sequences.   LineUp  is  a multiple  sequence editor used to create  multiple sequence alignments.   Pretty   displays multiple sequence  alignments.     ProfileMake  makes a profile from  a multiple sequence alignment.    ProfileSearch  uses the profile to  search a database for sequences  with similarity to the group  of aligned sequences.   ProfileSegments   displays optimal alignments between each  sequence in the  ProfileSearch  output  list and the group of  aligned sequences (represented by the  profile consensus).   ProfileGap  makes  optimal alignments  between one or more sequences  and a group of aligned  sequences represented as a profile.    ProfileScan   finds structural and sequence motifs  in protein sequences, using predetermined  parameters to  determine significance.    HmmerBuild makes a profile hidden  Markov model from a multiple  sequence alignment.  HmmerAlign  aligns one or more sequences  to a profile HMM.   HmmerPfam searches a database of  profile HMMs  with a sequence query in  order to identify known domains  within the sequence.  HmmerSearch  uses a  profile HMM as a query  to search a sequence database  for sequences similar to the  original aligned  sequences.  HmmerCalibrate calibrates a  hidden Markov model so that  database searches using it as  a  query will be more sensitive.   HmmerIndex creates a binary  GSI (""generic sequence index"") for  a  database of profile HMMs.   HmmerFetch retrieves a profile hidden  Markov model by name from  an  indexed database of profile HMMs.   HmmerEmit randomly generates sequences  that match a profile  HMM.  HmmerConvert converts between  different profile HMM file formats  and from profile HMM to  GCG profile file format.     MEME  finds conserved motifs in  a group of unaligned sequences  and saves these motifs as  a set of  profiles.  You can search  a database of sequences with  these profiles using the  MotifSearch   program.        RESTRICTIONS    [  Previous  |  Top  |  Next  ]          The sequences in the search  set must be of the  same type as the sequences  that were used to create  the  profile HMM.        ALGORITHM    [  Previous  |  Top  |  Next  ]          See the Profile HMM Analysis  Essay for an introduction to  profile hidden Markov models and  the  terminology associated with them.             Aligning a Sequence and a  Profile HMM          Aligning a sequence to a  profile HMM is analogous to  aligning two sequences to each  other.  A  pairwise sequence alignment associates a  residue in one sequence with  a residue in the other.  An alignment between a sequence  and a profile HMM associates  a residue in the sequence  with a  match or insert state in  the model.    In both processes, many possible  alignments exist, so a method  must be devised to score  them.  Pairwise sequence alignments are scored  based on the values in  a scoring  matrix;  sequence-to-HMM alignments are scored based  on the probability parameters of  the  model.    Aligning two sequences can be  viewed as finding the best  path through the surface of  comparison;  aligning a sequence to a  profile HMM can be viewed  as finding a path through  the  model that generates the sequence.   For both types of  alignments, the path is found  using  dynamic programming methods:  in the case  of pairwise sequence alignments, these  include the  Smith-Waterman and Needleman-Wunsch-Sellers algorithms;  in the  HMMER programs, the  available algorithms are the Viterbi  algorithm and the forward algorithm.    When aligning a sequence to  a profile HMM, there is  usually more than one path  through the  model that can generate the  sequence.  The Viterbi algorithm  examines all paths through the  model that can generate the  sequence, chooses the single most  probable path, and reports its  score.  The forward algorithm  is similar, except that it  adds the probabilities for all  paths that  can generate the sequence and  reports this score.  The  Viterbi algorithm is used by  default.  While some researchers maintain that  the forward algorithm is more  sensitive than the Viterbi  algorithm for detecting remote sequence  homologs, Sean Eddy's experiments with  HMMER have  not confirmed this.        Significance of Scores          In addition to the score,  an E-value (or expectation) is  reported to give you an  idea of the  significance of the score.   Basically, an E-value is the  number of hits expected to  score  X  or  higher purely by chance when  searching a sequence database of  a given size.  If  you are using  calibrated profile HMMs, E-values of  0.1 or smaller represent significant  hits.  The E-value is  computed by multiplying the size  of the database by the  probability of a random sequence  getting  a score  X  when aligned  with the profile HMM.    When using a profile HMM  query to search a sequence  database (HmmerSearch), the database  size is normally set to  the actual number of sequences  in the database.  When  using a sequence  query to search a database  of profile HMMs (HmmerPfam), the  database size is arbitrarily set  to  59021, the size of release  34 of the SWISS-PROT database.   In either type of  search, you can  assign a different number by  means of the  -EVS eqnum  parameter.   This is useful if  you want to  compare E-values for separate searches  of databases of differing sizes.    To get an accurate estimate  of the probability of the  alignment score for a profile  HMM and a  random sequence, the profile HMM  should be calibrated with HmmerCalibrate  before  performing the search, otherwise a  less accurate probability is estimated  using an analytic upper  bound calculation.  (The search  will also be faster if  a calibrated profile HMM is  used.)    See the HmmerCalibrate program documentation  for more detailed information on  how the  E-values are computed.             CONSIDERATIONS    [  Previous  |  Top  |  Next  ]          The search is faster and  more likely to find remote  homologs if the profile HMM  has been calibrated  with HmmerCalibrate.    If you supply more than  one query profile HMM as  input (by giving a profile  HMM database as query  input), HmmerSearch will only use  the first profile HMM in  the profile HMM database for  its search.             Increasing Program Speed Using Multithreading          This program is multithreaded.   It has the potential to  run faster on a machine  equipped with  multiple processors because different parts  of the analysis can be  run in parallel on different  processors.  By default, the  program assumes you have one  processor, so the analysis is  performed using one thread.   You can use  -PROC essors  to  increase the number of threads  up to  the number of physical processors  on the computer.    Under ideal conditions, the increase  in speed is roughly linear  with the number of processors  used.  But conditions are  rarely ideal.  If your  computer is heavily used, competition  for the  processors can reduce the program's  performance.  In such an  environment, try to run  multithreaded programs during times when  the load on the system  is light.    As the number of threads  increases, the amount of memory  required increases substantially.  You may need to ask  your system administrator to increase  the memory quota for your  account if  you want to use more  than two threads.    Never use  -PROC essors  to set  the number of threads higher  than the number of physical  processors that the machine has  -- it does not increase  program performance, but instead uses  up  a lot of memory needlessly  and makes it harder for  other users on the system  to get processor  time.  Ask your system  administrator how many processors your  computer has if you aren't  sure.             COMMAND-LINE SUMMARY    [  Previous  |  Top  |  Next  ]          All parameters for this program  may be added to the  command line.  Use  -CHE ck   to view the summary  below and to specify parameters  before the program executes.   In the summary below, the  capitalized  letters in the parameter names  are the letters that you   must  type in order to  use the parameter.  Square brackets ([ and ])  enclose parameter values that are  optional.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.        Minimal Syntax: % hmmersearch [-INfile1=]hsp70.hmm_g [-INfile2=]PIR:* -Default    Prompted Parameters:    [-OUTfile=]hmmersearch.hmmersearch     names the output file    Local Data Files:  None    Optional Parameters:    -PROCessors=2            sets the maximum number of threads that the program                            will use to 2 -LIMit=10                displays alignments for only the 10 best scoring                            domains -EVCutoff=10.0           sets the E-value cutoff for the list of best sequences                            to 10.0 -DOMEVCutoff=2.0         sets the E-value cutoff for the list of best domains                            to 2.0 -EVSeqnum=100000         calculates the E-values as if the database had                            contained 100,000 sequences -BSCUtoff=-300           sets the bit score cutoff for the list of best                            sequences to -300 -DOMBSCutoff=10          sets the bit score cutoff for the list of best domains                            to 10 -FORWard                 uses the Forward algorithm instead of the Viterbi                            algorithm to determine the sequence scores -NULL2                   doesn't use the post hoc second null model -XNU                     filters target protein sequences with XNU to remove                            tandem repeats -NOFRAgments             uses whole sequences section as the list file instead                            of the best domain section -NOMONitor               doesn't display information about analysis                            parameters used -BATch                   submits program to the batch queue              ACKNOWLEDGEMENT    [  Previous  |  Top  |  Next  ]          The programs comprising the HMMER  package are designed and implemented  by Dr. Sean Eddy of the  Washington University School of Medicine,  St. Louis, Missouri.  The Wisconsin  Package front-end  programs were written by Christiane  van Schlun in collaboration with  Dr. Eddy.        LOCAL DATA FILES    [  Previous  |  Top  |  Next  ]          None.        PARAMETER REFERENCE    [  Previous  |  Top  |  Next  ]          You can set the parameters  listed below from the command  line.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.              Following some of the parameters  described below is a short  expression in parentheses.  These  are the  names of the corresponding parameters  used in the native HMMER  package.  Some of the  GCG  parameters are identical to the  original HMMER parameters, others have  been changed to fit GCG's  conventions.             -MON itor =100          updates the program monitor on  your screen every time 100  sequences are processed.  If  the  program is run on the  batch queue, this moniter is  written to the log file.   If your terminal is  connected to a slow modem,  the monitor can slow program  execution.  You can suppress  it with   -NOMON itor .        -PROC essors =2      ( --cpu 2 )         tells the program to use  2 threads for the database  search on a multiprocessor computer.   The  default is 1.        -LIM it =10      ( -A 10 )         displays alignments for only the  top 10 best scoring domains.   If  -LIM it  is set  to zero, no  alignments are displayed.        -EVC utoff =10.0      ( -E 10.0 )         sets the maximum E-value to  be displayed in the list  of best sequences to 10.0.   The default is  10.0 and it must be  a positive real number.        -DOMEVC utoff =2.0      ( --domE 2.0 )         sets the maximum E-value to  be displayed in the list  of best domains to 2.0.   This can be set  to  any positive real number permitted  by your machine.  By  default,all domains in the sequences  that passed the first threshold  ( -EVC utoff ) will be reported in  the second list, so that  the  number of domains reported in  the list of best sequences  is consistent with the number  that  appear in the list of  best domains.        -EVS eqnum =100000      ( -Z 100000 )         calculates the E-value scores as  if the search set had  contained 100,000 sequences.  The  default  is the actual number of  sequences in the search set.        -BSCU toff =-300      ( -T -300 )         sets the lowest bit score  to be displayed in the  list of best sequences to  -300.  This can be  set to  any real number permitted by  your machine.  By default  the number of hits displayed  is  controlled by the E-value and  not by the bit score.        -DOMBSC utoff =10      ( --domT 10 )         sets the lowest bit score  to be displayed in the  list of best domains to  10.  The value can  be any  real number.  By default  all domains in the sequences  that passed the first (best  sequences list)  threshold will be reported in  the list of best domains,  so that the number of  domains reported in  the list of best sequences  is consistent with the number  that appear in the list  of best domains.    Only one domain in a  sequence is controlled by this  parameter.  The second and  subsequent  domains in a sequence have  a defacto bit score threshold  of 0 because of the  details of how  HMMER works.  HMMER requires  at least one pass through  the main model per sequence;  to do  more than one pass (more  than one domain) the multidomain  alignment must have a better  score  than the single domain alignment,  and hence the extra domains  must contribute a positive score.        -FORW ard      ( --forward )         uses the forward algorithm instead  of the Viterbi algorithm to  determine the overall sequence  scores.  (Domain scores are  always determined by the Viterbi  algorithm.)        -NULL 2      ( --null2 )         turns the  post hoc  second  null model off.  By  default each alignment is rescored  by a  post-processing step that takes into  account possible biased composition in  either the profile  HMM or the target sequence.   This is almost essential  in database searches, especially when  the  profile HMM is a local  alignment model.  There is  a very small chance that  this post processing  might remove real matches, and  in these cases  -NULL 2  may  improve sensitivity at the expense  of reducing specificity by letting  through hits whose scores are  based partially on biased  composition.        -XNU      ( --xnu )         filters target protein sequences with  XNU to remove statistically significant  tandem repeats.  It  has no effect on nucleic  acid sequences, In trial experiments,   -XNU  appears to perform less  well  than the default  post hoc   null2 model.        -NOFRA gments          uses the whole sequence section  of the output as the  list file instead of the  best domains section.        -NOMON itor          suppresses the display of the  program's progress on the screen.        -BAT ch          submits the program to the  batch queue for processing after  prompting you for all required  user  inputs.  All output files  are written to your current  directory, unless you direct the  ouput to  another directory when you specify  the output file.                 Printed: January 9, 2002  13:45 (1162)           [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]       Technical Support:  support-us@accelrys.com  or  support-eu@accelrys.com      Copyright (c) 1982-2002 Accelrys Inc.  A subsidiary of Pharmacopeia, Inc.  All rights reserved.    Licenses and Trademarks Wisconsin Package is a trademark and GCG and the GCG logo are registered trademarks of Accelrys Inc.    All other product names mentioned in this documentation may be trademarks, and if so, are trademarks or registered trademarks of their respective holders and are used in this documentation for identification purposes only.       www.accelrys.com/bio"
GX035-16-7136392	"HMMERPFAM     [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]      Table of Contents      FUNCTION   DESCRIPTION   EXAMPLE   OUTPUT   INTERPRETING OUTPUT   INPUT FILES   RELATED PROGRAMS   RESTRICTIONS   ALGORITHM   CONSIDERATIONS   COMMAND-LINE SUMMARY   ACKNOWLEDGEMENT   LOCAL DATA FILES   PARAMETER REFERENCE                       FUNCTION    [   Top  |  Next  ]          HmmerPfam compares one or more  sequences to a database of  profile hidden Markov models, such  as  the Pfam library, in order  to identify known domains within  the sequences.        DESCRIPTION    [  Previous  |  Top  |  Next  ]          HmmerPfam provides a Wisconsin Package  interface to the hmmpfam program  of Dr. Sean Eddy's  HMMER package.  It allows  you to access most of  hmmpfam's parameters from the Wisconsin  Package  command line.    HmmerPfam searches a database of  profile hidden Markov models using  one or more sequences as  queries and displays the alignments  between the profile HMM and  matching domains in the sequence.        EXAMPLE    [  Previous  |  Top  |  Next  ]          Here is a session using  HmmerPfam to search the Pfam  (""Protein families"") profile HMM database  to  find matches to domains in  the Ygbyad protein sequence from  the PIR database:          %  hmmerpfam    HMMERPFAM with what query sequence ?   PIR:ygbyad                     Begin (* 1 *) ?                 End (*  1392 *) ?   Search for query in what HMM database (* Pfam.hmmdb *) ?   What should the output file be called (* hmmerpfam.hmmerpfam *)?   Creating temp file for input to hmmpfam.   Calling hmmpfam to perform analysis ...  hmmpfam - search a single seq against HMM database HMMER 2.1.1 (Dec 1998) Copyright (C) 1992-1998 Washington University School of Medicine HMMER is freely distributed under the GNU General Public License (GPL). - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - HMM file:                 /databases/hmm/Pfam.hmmdb Sequence file:            PIR:ygbyad - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  %              OUTPUT    [  Previous  |  Top  |  Next  ]          Here is part of the  output file:        Query:  YGBYAD  from: 1  to: 1392  L-aminoadipate-semialdehyde dehydrogenase   (EC 1.2.1.31) - yeast (Saccharomyces c  Scores for sequence family classification (score includes all domains): Model       Description                                 Score    E-value  N --------    -----------                                 -----    ------- --- AMP-binding AMP-binding enzyme                          271.0    1.6e-77   1 pp-binding  Phosphopantetheine attachment site           83.9    1.4e-21   1 adh_short   short chain dehydrogenase                   -77.6        1.8   1 3Beta_HSD   3-beta hydroxysteroid dehydrogenase/isome  -182.2       0.15   1 Epimerase   NAD dependent epimerase/dehydratase famil  -204.8        3.7   1  Parsed for domains: Model       Domain  seq-f seq-t    hmm-f hmm-t      score  E-value --------    ------- ----- -----    ----- -----      -----  ------- AMP-binding   1/1     271   729 ..     1   450 []   271.0  1.6e-77 pp-binding    1/1     850   916 ..     1    68 []    83.9  1.4e-21 adh_short     1/1     971  1182 ..     1   203 []   -77.6      1.8 Epimerase     1/1     973  1279 ..     1   359 []  -204.8      3.7 3Beta_HSD     1/1     962  1346 ..     1   425 []  -182.2     0.15  Alignments of top-scoring domains: AMP-binding: domain 1 of 1, from 271 to 729: score 271.0, E = 1.6e-77                    *->TYrELnerAnrLArhLrsekGvkpgdlVailmerSpemivaiLgilK                       TYr+ n+ +n  A++L+   G+k gd V i+  r ++++v+++g+lK       YGBYAD   271    TYRDINRTSNIVAHYLI-KTGIKRGDVVMIYSSRGVDLMVCVMGVLK 316        ///////////////////////////////////////////////////////////////////                     iDdQVKiRGyRIELGEIEaaLrllqhpgvkeAvV<-*                    +DdQVKiRG+RIELGEI++++   qhp v+e  +       YGBYAD   698 ADDQVKIRGFRIELGEIDTHIS--QHPLVRENIT    729  pp-binding: domain 1 of 1, from 850 to 916: score 83.9, E = 1.4e-21                    *->erlreiwaevLgvdpdeigiddnFfeDLGgDSLkavelvarleeelG                       +++r++w ++L   p  +++dd+Ff+ LGg+S+ a++++++l ++l+       YGBYAD   850    REVRDLWLSILPTKPASVSPDDSFFD-LGGHSILATKMIFTLKKKLQ 895                     velpdtdlfehpTiraLaeyl<-*                    v+lp+ ++f++pTi+a+a+ +       YGBYAD   896 VDLPLGTIFKYPTIKAFAAEI    916  //////////////////////////////////////////////////////////////////////////  3Beta_HSD: domain 1 of 1, from 962 to 1346: score -182.2, E = 0.15                    *->elsesldmaglsclVTGGgGFlGrhIVreLlregeslqevRvfDlrf                         s+ + ++++ + VTG  GFlG++I   Ll + ++++   vf  ++       YGBYAD   962    PNSAEGKTTIN-VFVTGVTGFLGSYILADLLGRSPKNYSFKVFAHVR 1007        ////////////////////////////////////////////////////////////////////                     EarakTieWiqele<-*                     ++  T e +++       YGBYAD  1333 NGIGVTPEEVGIYI    1346  //              INTERPRETING OUTPUT    [  Previous  |  Top  |  Next  ]                   Lists of Scores          HmmerPfam first lists the profile  HMMs that had the best  matches with the query sequence,  ranked by E-value.  The  raw scores are expressed as  bit values.  If the  profile HMM matched  more than one place in  the sequence, the score for  each matching domain contributes to  the total  score.  The number of  sequence domains that matched the  profile HMM are displayed in  the  rightmost column of this list.    Next HmmerPfam lists the top-scoring  domains, with their raw scores  and E-values.  They are  ordered by their position in  the sequence, not by their  scores.  HmmerPfam displays the  begin  and end coordinates for the  matching domains in the sequence  under the seq-f (""sequence-from"")  and seq-t (""sequence-to"") headings.   It also lists the begin  and end coordinates of the  matching  portion of the profile HMM  (under the headings hmm-f and  hmm-t).    After each set of begin  and end coordinates is a  two-character code that tells you  if the alignment  is local or global with  respect to the sequence and  to the profile HMM.   In general, a left bracket  ([) means the alignment started  at the beginning of the  sequence or profile HMM, a  right bracket  (]), means the alignment ended  at the end of the  sequence or profile HMM, and  a period means  that the alignment started or  ended in the middle of  the sequence or profile HMM.    For example, in the following  line from a HmmerPfam output:               AMP-binding   1/1     271   729 ..     1   450 []   271.0  1.6e-77            the sequence coordinates for the  match are 271-729 and the  two periods following 729 means  that the matching region was  within the sequence and did  not extend to either end.   The profile  HMM coordinates are 1-450 and  the two brackets following 450  means that the match spanned  the entire length of the  profile HMM.    If more than one sequence  domain matched the same profile  HMM, there will be a  separate line  for each domain.  The  domains are numbered:  for example, if  a single domain matched the  query, the entry is labeled  1/1;  if the domain is the  second of three that matched,  it is labeled  2/3.        The Alignments          The next section of the  output displays the alignments between  the profile HMM consensus  sequence and the best-scoring domains.   These are displayed somewhat  differently than most  GCG alignments.    The top line is the  ""consensus"" sequence of the profile  HMM.  The residues shown  are the highest  probability residues at each position  according to the model.   (There is no attempt to  use an  ambiguous symbol to denote a  position that can contain more  than one type of residue,  so it isn't  a consensus in the commonly  used sense of the word.)  A  residue is printed as a  capital letter if it  is highly conserved, otherwise it  is printed in lowercase.   For protein models, highly conserved  amino acids are defined to  be those that have a  probability greater than 0.5;  for nucleic  acid  models, highly conserved nucleotides are  those with a probability greater  than 0.9.  If the  sequence contains positions not present  in the model, periods are  inserted into the profile HMM  consensus sequence to denote the  gap.    The center line of the  alignment is a representation of  the quality of the alignment.   A letter  appears at positions where the  sequence and the profile HMM  consensus are identical.  The  letter will be upper- or  lowercase in accordance with the  case of the profile HMM  consensus.  If  the residues at that position  are not identical but have  a positive score, a plus  sign is displayed,  and the relationship is considered  to be ""conservative"" according to  the HMM's view of this  particular position in the model  (not to be confused with  the usual definition of conservative  changes).  If the score  is not positive, a space  appears.    The third line of the  alignment shows the sequence itself.   In this line, gaps  are indicated with  hyphens rather than periods.             INPUT FILES    [  Previous  |  Top  |  Next  ]          HmmerPfam requires as one of  its inputs a single or  multiple sequence specification.  You  can specify  multiple sequences in a number  of ways:  by using a list  file, for example  @project.list ;  by using  an MSF or RSF file,  for example  project.msf{*} ;  or by using  a sequence specification with an  asterisk ( * ) wildcard, for example   GenEMBL:* .    The function of HmmerPfam depends  on whether your input sequence(s)  are protein or nucleotide.  Programs determine the type of  a sequence by the presence  of either  Type: N  or   Type: P  on the last  line of the text heading  just above the sequence.   If your sequence(s) are not  the correct type, turn to  Appendix VI for information on how  to change or set the  type of a sequence.    The other input to HmmerPfam  is a profile HMM database.   You can create HMM  databases by  concatenating profile HMM files or  you can use existing HMM  databases.    Profile HMM databases supplied with  the Wisconsin Package are Pfam  and PfamFrag.  They each  contain profile HMMs for a  large number of protein families.   The profile HMMs in  these databases  were made from the same  sequence alignments, but with different  parameters:  the profile HMMs in  Pfam are built to perform  global alignments with respect to  the model, while the profile  HMMs in  PfamFrag are designed to perform  local alignments with respect to  the model.        RELATED PROGRAMS    [  Previous  |  Top  |  Next  ]           PileUp  creates a multiple sequence  alignment from a group of  related sequences.   LineUp  is  a multiple  sequence editor used to create  multiple sequence alignments.   Pretty   displays multiple sequence  alignments.     ProfileMake  makes a profile from  a multiple sequence alignment.    ProfileSearch  uses the profile to  search a database for sequences  with similarity to the group  of aligned sequences.   ProfileSegments   displays optimal alignments between each  sequence in the  ProfileSearch  output  list and the group of  aligned sequences (represented by the  profile consensus).   ProfileGap  makes  optimal alignments  between one or more sequences  and a group of aligned  sequences represented as a profile.    ProfileScan   finds structural and sequence motifs  in protein sequences, using predetermined  parameters to  determine significance.    HmmerBuild makes a profile hidden  Markov model from a multiple  sequence alignment.  HmmerAlign  aligns one or more sequences  to a profile HMM.   HmmerPfam searches a database of  profile HMMs  with a sequence query in  order to identify known domains  within the sequence.  HmmerSearch  uses a  profile HMM as a query  to search a sequence database  for sequences similar to the  original aligned  sequences.  HmmerCalibrate calibrates a  hidden Markov model so that  database searches using it as  a  query will be more sensitive.   HmmerIndex creates a binary  GSI (""generic sequence index"") for  a  database of profile HMMs.   HmmerFetch retrieves a profile hidden  Markov model by name from  an  indexed database of profile HMMs.   HmmerEmit randomly generates sequences  that match a profile  HMM.  HmmerConvert converts between  different profile HMM file formats  and from profile HMM to  GCG profile file format.     MEME  finds conserved motifs in  a group of unaligned sequences  and saves these motifs as  a set of  profiles.  You can search  a database of sequences with  these profiles using the  MotifSearch   program.        RESTRICTIONS    [  Previous  |  Top  |  Next  ]          All of the profile HMMs  in the database must have  been created from the same  sequence type (all  protein or all nucleic acid)  and the query sequence(s) must  also be of that type.    Unlike other HMMER programs, HmmerPfam  can't reliably determine the sequence  type because of  the order in which it  accesses data.  It assumes  protein data unless you use  the  -DNA  parameter.        ALGORITHM    [  Previous  |  Top  |  Next  ]          See the Profile HMM Analysis  Essay for an introduction to  profile hidden Markov models and  the  terminology associated with them.             Aligning a Sequence and a  Profile HMM          Aligning a sequence to a  profile HMM is analogous to  aligning two sequences to each  other.  A  pairwise sequence alignment associates a  residue in one sequence with  a residue in the other.  An alignment between a sequence  and a profile HMM associates  a residue in the sequence  with a  match or insert state in  the model.    In both processes, many possible  alignments exist, so a method  must be devised to score  them.  Pairwise sequence alignments are scored  based on the values in  a scoring  matrix;  sequence-to-HMM alignments are scored based  on the probability parameters of  the  model.    Aligning two sequences can be  viewed as finding the best  path through the surface of  comparison;  aligning a sequence to a  profile HMM can be viewed  as finding a path through  the  model that generates the sequence.   For both types of  alignments, the path is found  using  dynamic programming methods:  in the case  of pairwise sequence alignments, these  include the  Smith-Waterman and Needleman-Wunsch-Sellers algorithms;  in the  HMMER programs, the  available algorithms are the Viterbi  algorithm and the forward algorithm.    When aligning a sequence to  a profile HMM, there is  usually more than one path  through the  model that can generate the  sequence.  The Viterbi algorithm  examines all paths through the  model that can generate the  sequence, chooses the single most  probable path, and reports its  score.  The forward algorithm  is similar, except that it  adds the probabilities for all  paths that  can generate the sequence and  reports this score.  The  Viterbi algorithm is used by  default.  While some researchers maintain that  the forward algorithm is more  sensitive than the Viterbi  algorithm for detecting remote sequence  homologs, Sean Eddy's experiments with  HMMER have  not confirmed this.        Significance of Scores          In addition to the score,  an E-value (or expectation) is  reported to give you an  idea of the  significance of the score.   Basically, an E-value is the  number of hits expected to  score  X  or  higher purely by chance when  searching a sequence database of  a given size.  If  you are using  calibrated profile HMMs, E-values of  0.1 or smaller represent significant  hits.  The E-value is  computed by multiplying the size  of the database by the  probability of a random sequence  getting  a score  X  when aligned  with the profile HMM.    When using a profile HMM  query to search a sequence  database (HmmerSearch), the database  size is normally set to  the actual number of sequences  in the database.  When  using a sequence  query to search a database  of profile HMMs (HmmerPfam), the  database size is arbitrarily set  to  59021, the size of release  34 of the SWISS-PROT database.   In either type of  search, you can  assign a different number by  means of the  -EVS eqnum  parameter.   This is useful if  you want to  compare E-values for separate searches  of databases of differing sizes.    To get an accurate estimate  of the probability of the  alignment score for a profile  HMM and a  random sequence, the profile HMM  should be calibrated with HmmerCalibrate  before  performing the search, otherwise a  less accurate probability is estimated  using an analytic upper  bound calculation.  (The search  will also be faster if  a calibrated profile HMM is  used.)    See the HmmerCalibrate program documentation  for more detailed information on  how the  E-values are computed.             CONSIDERATIONS    [  Previous  |  Top  |  Next  ]          The search is faster and  more likely to identify remote  homologs if the profile HMM  database has been  calibrated with HmmerCalibrate.             Increasing Program Speed Using Multithreading          This program is multithreaded.   It has the potential to  run faster on a machine  equipped with  multiple processors because different parts  of the analysis can be  run in parallel on different  processors.  By default, the  program assumes you have one  processor, so the analysis is  performed using one thread.   You can use  -PROC essors  to  increase the number of threads  up to  the number of physical processors  on the computer.    Under ideal conditions, the increase  in speed is roughly linear  with the number of processors  used.  But conditions are  rarely ideal.  If your  computer is heavily used, competition  for the  processors can reduce the program's  performance.  In such an  environment, try to run  multithreaded programs during times when  the load on the system  is light.    As the number of threads  increases, the amount of memory  required increases substantially.  You may need to ask  your system administrator to increase  the memory quota for your  account if  you want to use more  than two threads.    Never use  -PROC essors  to set  the number of threads higher  than the number of physical  processors that the machine has  -- it does not increase  program performance, but instead uses  up  a lot of memory needlessly  and makes it harder for  other users on the system  to get processor  time.  Ask your system  administrator how many processors your  computer has if you aren't  sure.                COMMAND-LINE SUMMARY    [  Previous  |  Top  |  Next  ]          All parameters for this program  may be added to the  command line.  Use  -CHE ck   to view the summary  below and to specify parameters  before the program executes.   In the summary below, the  capitalized  letters in the parameter names  are the letters that you   must  type in order to  use the parameter.  Square brackets ([ and ])  enclose parameter values that are  optional.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.        Minimal Syntax: % hmmerpfam [-INfile1=]PIR:Ygbyad [-INfile2=]Pfam.hmmdb -Default    Prompted Parameters:    -BEGin1=1 -END1=100          sets the range of interest for each sequence    [-OUTfile=]ygbyad.hmmerpfam  names the output file    Local Data Files:  None    Optional Parameters: -PROCessors=2            sets the maximum number of threads that the program                            will use to 2 -RSF[=hmmerpfam.rsf]     saves the best scoring profile HMMs as features in                            an RSF file -DNA                     insists that the sequence(s) are nucleic acid -LIMit=50                displays alignments for the 50 best scoring domains -EVCutoff=10.0           sets the E-value cutoff for the sequence list to 10.0 -DOMEVCutoff=2.0         sets the E-value cutoff for the domain list to 2.0 -EVSeqnum=100000         calculates the E-values as if the database had                            contained 100,000 sequences -BSCUtoff=-300           sets the bit score cutoff for the sequence list                            to -300 -DOMBSCutoff=10          sets the bit score cutoff for the domain list to 10 -FORWard                 uses the Forward algorithm instead of the Viterbi                            algorithm to determine the sequence scores -NULL2                   doesn't use the post hoc second null model -XNU                     filters target protein sequences with XNU to remove                            tandem repeats -NOMONitor               doesn't display information about analysis                            parameters used -BATch                   submits program to the batch queue              ACKNOWLEDGEMENT    [  Previous  |  Top  |  Next  ]          The programs comprising the HMMER  package are designed and implemented  by Dr. Sean Eddy of the  Washington University School of Medicine,  St. Louis, Missouri.  The Wisconsin  Package front-end  programs were written by Christiane  van Schlun in collaboration with  Dr. Eddy.    Pfam - A database of  protein domain family alignments and  HMMs Copyright (C) 1996-2000 The  Pfam  Consortium.        LOCAL DATA FILES    [  Previous  |  Top  |  Next  ]          None.        PARAMETER REFERENCE    [  Previous  |  Top  |  Next  ]          You can set the parameters  listed below from the command  line.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.              Following some of the parameters  described below is a short  expression in parentheses.  These  are the  names of the corresponding parameters  used in the native HMMER  package.  Some of the  GCG  parameters are identical to the  original HMMER parameters, others have  been changed to fit GCG's  conventions.             -BEG in =1          sets the beginning position for  each query sequence to 1.   When beginning positions are  specified  for individual sequences in a  list file, HmmerPfam ignores the  value of  -BEG in .        -END=100          sets the ending position for  each sequence to 100.   When ending positions are specified  for  individual sequences in a list  file, HmmerPfam ignores the value  of  -END .        -PROC essors =2      ( --cpu 2 )         tells the program to use  2 threads for the database  search on a multiprocessor computer.   The  default is 1.        -RSF =hmmerpfam.rsf          writes an RSF (rich sequence  format) file containing the input  sequences annotated with  features generated from the results  of HmmerPfam.  This RSF  file is suitable for input  to other  Wisconsin Package programs that support  RSF files.  In particular,  you can use  SeqLab  to  view  this features annotation graphically.   If you don't specify a  file name with this parameter,  then  the program creates one using  hmmerpfam for the file basename  and .rsf for the extension.   For  more information on RSF files,  see ""Using Rich Sequence Format  (RSF) Files"" in Chapter 2  of  the User's Guide.  Or,  see ""Rich Sequence Format (RSF)  Files"" in Appendix C of  the  SeqLab   Guide.        -DNA      ( -n )         informs HmmerPfam that the sequences  and models are nucleic acid  instead of protein.  (Unlike  other HMMER programs, HmmerPfam can't  reliably determine the sequence type  because of the  order in which it accesses  data.)        -LIM it =50      ( -A 50 )         displays alignments for the 50  best scoring domains.  If   -LIM it  is set to zero,  no alignments are  displayed.        -EVC utoff =10.0      ( -E 10.0 )         sets the maximum E-value to  be displayed in the list  of best profile HMMs to  10.0.  The default is  10.0 and it must be  a positive real number.        -DOMEVC utoff =2.0      ( --domE 2.0 )         sets the maximum E-value to  be displayed in the list  of best domains to 2.0.   This can be set  to  any positive real number permitted  by your machine.  By  default,all domains in the sequences  that passed the first threshold  ( -EVC utoff ) will be reported in  the second list, so that  the  number of domains reported in  the list of best profile  HMMs is consistent with the  number that  appear in the list of  best sequence domains.        -EVS eqnum =100000      ( -Z 100000 )         calculates the E-value scores as  if the search set had  contained 100,000 sequences.  The  default  is arbitrarily set to 59021,  the size of release 34  of the SWISS-PROT database.        -BSCU toff =-300      ( -T -300 )         sets the lowest bit score  to be displayed in the  list of best profile HMMs  to -300.  This can  be set  to any real number permitted  by your machine.  By  default the number of hits  displayed is  controlled by the E-value and  not by the bit score.        -DOMBSC utoff =10      ( --domT 10 )         sets the lowest bit score  to be displayed in the  list of best domains to  10.  The value can  be any  real number.  By default  all domains in the sequences  that passed the first (best  profile HMMs  list) threshold will be reported  in the list of best  domains, so that the number  of domains  reported in the list of  best sequences is consistent with  the number that appear in  the list of best  domains.    Only one domain in a  sequence is controlled by this  parameter.  The second and  subsequent  domains in a sequence have  a defacto bit score threshold  of 0 because of the  details of how  HMMER works.  HMMER requires  at least one pass through  the main model per sequence;  to do  more than one pass (more  than one domain) the multidomain  alignment must have a better  score  than the single domain alignment,  and hence the extra domains  must contribute a positive score.        -FORW ard      ( --forward )         uses the forward algorithm instead  of the Viterbi algorithm to  determine the scores in the  list of  best profile HMMs.  (Domain  scores are always determined by  the Viterbi algorithm.)        -NULL2      ( --null2 )         turns the  post hoc  second  null model off.  By  default each alignment is rescored  by a  post-processing step that takes into  account possible biased composition in  either the profile  HMM or the query sequence.   This is almost essential  in database searches, especially when  the  profile HMM is a local  alignment model.  There is  a very small chance that  this post processing  might remove real matches, and  in these cases  -NULL2  may  improve sensitivity at the expense  of reducing specificity by letting  through hits whose scores are  based partially on biased  composition.        -XNU      ( --xnu )         filters target protein sequences with  XNU to remove statistically significant  tandem repeats.  It  has no effect on nucleic  acid sequences, In trial experiments,   -XNU  appears to perform less  well  than the default  post hoc   null2 model.        -NOMON itor          suppresses the display of the  program's progress on the screen.        -BAT ch          submits the program to the  batch queue for processing after  prompting you for all required  user  inputs.  All output files  are written to your current  directory, unless you direct the  ouput to  another directory when you specify  the output file.                 Printed: January 9, 2002  13:45 (1162)           [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]       Technical Support:  support-us@accelrys.com  or  support-eu@accelrys.com      Copyright (c) 1982-2002 Accelrys Inc.  A subsidiary of Pharmacopeia, Inc.  All rights reserved.    Licenses and Trademarks Wisconsin Package is a trademark and GCG and the GCG logo are registered trademarks of Accelrys Inc.    All other product names mentioned in this documentation may be trademarks, and if so, are trademarks or registered trademarks of their respective holders and are used in this documentation for identification purposes only.       www.accelrys.com/bio"
GX035-09-12738613	"HMMERINDEX     [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]      Table of Contents      FUNCTION   DESCRIPTION   EXAMPLE   OUTPUT   INPUT FILES   RELATED PROGRAMS   RESTRICTIONS   CONSIDERATIONS   COMMAND-LINE SUMMARY   ACKNOWLEDGEMENT   LOCAL DATA FILES   PARAMETER REFERENCE                       FUNCTION    [   Top  |  Next  ]          HmmerIndex creates an index for  a profile hidden Markov model  database so that profile HMMs  can be  retrieved from the database with  HmmerFetch.        DESCRIPTION    [  Previous  |  Top  |  Next  ]          HmmerIndex provides a Wisconsin Package  interface to the hmmindex program  of Dr. Sean Eddy's  HMMER package.  It allows  you to access most of  hmmindex's parameters from the Wisconsin  Package  command line.    In order to retrieve profile  HMMs from a database of  profile HMMs, the database must  first be indexed  with HmmerIndex.  The index  is a binary file referred  to as a GSI (""generic  sequence index"").  The  Pfam and PfamFrag databases distributed  with the Wisconsin Package are  already indexed, but if you  create your own profile HMM  database, you must index it  yourself.  Once the index  is created, you can  use HmmerFetch to retrieve individual  profile HMMs from the database,  much as you can use   Fetch  to  retrieve sequences from sequence databases.        EXAMPLE    [  Previous  |  Top  |  Next  ]          Here is a session using  HmmerIndex to index a small  profile HMM database called HSP.hmmdb.   This  database was created by using  HmmerFetch to retrieve four profile  HMMs (HSP20.hmm, HSP33.hmm,  HSP70.hmm, HSP90.hmm) from the Pfam  database, then using HmmerConvert with  the  -MEN u =E   parameter to concatenate the individual  profile HMMs into a single  file.          %  hmmerindex    HMMERINDEX which HMM database ?   HSP.hmmdb    Creating temp file for input to hmmindex .   Calling hmmindex to perform analysis ...  hmmindex -- create GSI index for an HMM database HMMER 2.1.1 (Dec 1998) Copyright (C) 1992-1998 Washington University School of Medicine HMMER is freely distributed under the GNU General Public License (GPL). - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - HMM file:                 /usr/users/share/smith/HSP.hmmdb - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  Determining offsets for /usr/users/share/smith/HSP.hmmdb, please be patient... Sorting keys... Complete. GSI /usr/users/share/smith/HSP.hmmdb.gsi indexes 8 keys (names+accessions)       for 4 H MMs in /usr/users/share/smith/HSP.hmmdb.  %              OUTPUT    [  Previous  |  Top  |  Next  ]          The output is a binary  file called HSP.hmmdb.gsi.        INPUT FILES    [  Previous  |  Top  |  Next  ]          HmmerIndex's only input is a  profile HMM database file.   You can create your own  profile HMM  database by concatenating profile HMM  files.  This can be  done in several ways.   Within the HMMER  package, you can append a  new profile HMM to an  existing one by using the   -APP end  parameter with  HmmerBuild or the append menu  option ( -MEN u =E ) in HmmerConvert.    You can also use UNIX  commands to append a profile  HMM to an existing one  or to concatenate  several profiles into a single  new file:               %  cat newprofile.hmm_g >> existing.hmm_g       %  cat profile1.hmm_g profile2.hmm_g > two_profiles.hmmdb               RELATED PROGRAMS    [  Previous  |  Top  |  Next  ]           PileUp  creates a multiple sequence  alignment from a group of  related sequences.   LineUp  is  a multiple  sequence editor used to create  multiple sequence alignments.   Pretty   displays multiple sequence  alignments.     ProfileMake  makes a profile from  a multiple sequence alignment.    ProfileSearch  uses the profile to  search a database for sequences  with similarity to the group  of aligned sequences.   ProfileSegments   displays optimal alignments between each  sequence in the  ProfileSearch  output  list and the group of  aligned sequences (represented by the  profile consensus).   ProfileGap  makes  optimal alignments  between one or more sequences  and a group of aligned  sequences represented as a profile.    ProfileScan   finds structural and sequence motifs  in protein sequences, using predetermined  parameters to  determine significance.    HmmerBuild makes a profile hidden  Markov model from a multiple  sequence alignment.  HmmerAlign  aligns one or more sequences  to a profile HMM.   HmmerPfam searches a database of  profile HMMs  with a sequence query in  order to identify known domains  within the sequence.  HmmerSearch  uses a  profile HMM as a query  to search a sequence database  for sequences similar to the  original aligned  sequences.  HmmerCalibrate calibrates a  hidden Markov model so that  database searches using it as  a  query will be more sensitive.   HmmerIndex creates a binary  GSI (""generic sequence index"") for  a  database of profile HMMs.   HmmerFetch retrieves a profile hidden  Markov model by name from  an  indexed database of profile HMMs.   HmmerEmit randomly generates sequences  that match a profile  HMM.  HmmerConvert converts between  different profile HMM file formats  and from profile HMM to  GCG profile file format.     MEME  finds conserved motifs in  a group of unaligned sequences  and saves these motifs as  a set of  profiles.  You can search  a database of sequences with  these profiles using the  MotifSearch   program.        RESTRICTIONS    [  Previous  |  Top  |  Next  ]          The profile HMM database to  be indexed must consist of  a single file.  All  of the profile HMMs in  the  file must be of the  same type (ASCII text or  binary).        CONSIDERATIONS    [  Previous  |  Top  |  Next  ]          If you add a new  profile HMM to a database,  you must re-index that profile  HMM database.           COMMAND-LINE SUMMARY    [  Previous  |  Top  |  Next  ]          All parameters for this program  may be added to the  command line.  Use  -CHE ck   to view the summary  below and to specify parameters  before the program executes.   In the summary below, the  capitalized  letters in the parameter names  are the letters that you   must  type in order to  use the parameter.  Square brackets ([ and ])  enclose parameter values that are  optional.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.        Minimal Syntax: % hmmerindex [-INfile1=]HSP.hmm -Default    Local Data Files:  None    Optional Parameters:    -NOMONitor               suppresses the screen monitor               ACKNOWLEDGEMENT    [  Previous  |  Top  |  Next  ]          The programs comprising the HMMER  package are designed and implemented  by Dr. Sean Eddy of the  Washington University School of Medicine,  St. Louis, Missouri.  The Wisconsin  Package front-end  programs were written by Christiane  van Schlun in collaboration with  Dr. Eddy.    Pfam - A database of  protein domain family alignments and  HMMs Copyright (C) 1996-2000 The  Pfam  Consortium.           LOCAL DATA FILES    [  Previous  |  Top  |  Next  ]          None.        PARAMETER REFERENCE    [  Previous  |  Top  |  Next  ]          You can set the parameters  listed below from the command  line.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.             -NOMON itor          suppresses the display of the  program's progress on the screen.                 Printed: January 9, 2002  13:45 (1162)           [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]       Technical Support:  support-us@accelrys.com  or  support-eu@accelrys.com      Copyright (c) 1982-2002 Accelrys Inc.  A subsidiary of Pharmacopeia, Inc.  All rights reserved.    Licenses and Trademarks Wisconsin Package is a trademark and GCG and the GCG logo are registered trademarks of Accelrys Inc.    All other product names mentioned in this documentation may be trademarks, and if so, are trademarks or registered trademarks of their respective holders and are used in this documentation for identification purposes only.       www.accelrys.com/bio"
GX034-49-5484195	"HMMERCONVERT     [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]      Table of Contents      FUNCTION   DESCRIPTION   EXAMPLE   OUTPUT   INPUT FILES   RELATED PROGRAMS   RESTRICTIONS   CONSIDERATIONS   COMMAND-LINE SUMMARY   ACKNOWLEDGEMENT   LOCAL DATA FILES   PARAMETER REFERENCE                       FUNCTION    [   Top  |  Next  ]          HmmerConvert converts profile hidden Markov  model files into different profile  formats.        DESCRIPTION    [  Previous  |  Top  |  Next  ]          HmmerConvert provides a Wisconsin Package  interface to the hmmconvert program  of Dr. Sean Eddy's  HMMER package.  It allows  you to access most of  hmmconvert's parameters from the Wisconsin  Package command line.    HmmerConvert allows you to manipulate  profile HMM files in several  ways.  By default, a  profile  HMM is created as an  ASCII text file, but it  can also exist in a  binary format, which can save  disk  space if you have a  large HMM database file.   HmmerConvert allows you to convert  your profile HMM  between these two formats.   It also allows you to  convert your profile HMM into  a standard profile,  which can be used as  input to programs such as   ProfileSearch  and  ProfileGap .  Lastly,  it allows you to  append a profile HMM file  onto an existing profile HMM  file, or to replace an  existing profile HMM file  with another.        EXAMPLE    [  Previous  |  Top  |  Next  ]          Here is a session using  HmmerConvert to convert the hidden  Markov model file created in  the  HmmerBuild example session into a  GCG profile:          %  hmmerconvert    HMMERCONVERT what profile HMM ?   hsp70.hmm_g    Into which type of file ?     A ASCII HMM format    B Binary HMM format    P Profile format    E Append this profile HMM to an existing file    O Overwrite an existing file with this profile HMM   Choose a type (* A *) :  p    Converting to GCG profile.   What should the output file be called (* hmmerconvert.prf *) ?   Creating temp file for input to hmmconvert.   Calling hmmconvert to perform analysis ...  hmmconvert - convert between profile HMM file formats HMMER 2.1.1 (Dec 1998) Copyright (C) 1992-1998 Washington University School of Medicine HMMER is freely distributed under the GNU General Public License (GPL). - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Input HMM file:           /usr/users/share/smith/hsp70.hmm_g Output HMM file:          /usr/users/share/smith/hmmerconvert.prf Converting to:            GCG Profile .prf - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -   - converted hsp70  1 HMM(s) converted and written to /usr/users/share/smith/hmmerconvert.prf  %              OUTPUT    [  Previous  |  Top  |  Next  ]          Here is some of the  output file:        !!AA_PROFILE 1.0 (Peptide) HMMCONVERT v2.1.1 Length: 677 hsp70||    Profile converted from a profile HMM using HMMER v2.1.1 emulation.    Use -nonor -noave -gap=10 -len=1 with profilesearch and friends       to get the closest approximation to HMMER bit scores.    WARNING: There is a loss of information in this conversion.       Neither the scores nor even the rank order of hits will be precisely       preserved in a comparison of HMMER hmmsearch to GCG profilesearch.       The profile score is an approximation of the (single-hit) HMMER score.  Cons    A     C     D     E     F     G     H     I     K     L ...  Gap   Len  ..  K     46  -155   -25    69  -179   -35     0  -148   115  -153 ...  100   100  V     19  -138   -35    50  -160   -50    -6  -126    27  -137 ...   66   111  /////////////////////////////////////////////////////////////////////////////////   E    -68  -172     1   270  -183  -138   -31  -137     2  -149 ...   62   111  V    -59   -73  -223  -200  -121  -177  -162    52  -177   -63 ...   62   111  D   -124  -248   348    21  -312   -28   -82  -308  -103  -306 ...   62   111  *   1450   151  1131  1249   603  1265   278  1040  1234  1320 ...              INPUT FILES    [  Previous  |  Top  |  Next  ]          HmmerConvert requires as its only  input a profile HMM file  containing one or more profile  HMMs.        RELATED PROGRAMS    [  Previous  |  Top  |  Next  ]           PileUp  creates a multiple sequence  alignment from a group of  related sequences.   LineUp  is  a multiple  sequence editor used to create  multiple sequence alignments.   Pretty   displays multiple sequence  alignments.     ProfileMake  makes a profile from  a multiple sequence alignment.    ProfileSearch  uses the profile to  search a database for sequences  with similarity to the group  of aligned sequences.   ProfileSegments   displays optimal alignments between each  sequence in the  ProfileSearch  output  list and the group of  aligned sequences (represented by the  profile consensus).   ProfileGap  makes  optimal alignments  between one or more sequences  and a group of aligned  sequences represented as a profile.    ProfileScan   finds structural and sequence motifs  in protein sequences, using predetermined  parameters to  determine significance.    HmmerBuild makes a profile hidden  Markov model from a multiple  sequence alignment.  HmmerAlign  aligns one or more sequences  to a profile HMM.   HmmerPfam searches a database of  profile HMMs  with a sequence query in  order to identify known domains  within the sequence.  HmmerSearch  uses a  profile HMM as a query  to search a sequence database  for sequences similar to the  original aligned  sequences.  HmmerCalibrate calibrates a  hidden Markov model so that  database searches using it as  a  query will be more sensitive.   HmmerIndex creates a binary  GSI (""generic sequence index"") for  a  database of profile HMMs.   HmmerFetch retrieves a profile hidden  Markov model by name from  an  indexed database of profile HMMs.   HmmerEmit randomly generates sequences  that match a profile  HMM.  HmmerConvert converts between  different profile HMM file formats  and from profile HMM to  GCG profile file format.     MEME  finds conserved motifs in  a group of unaligned sequences  and saves these motifs as  a set of  profiles.  You can search  a database of sequences with  these profiles using the  MotifSearch   program.        RESTRICTIONS    [  Previous  |  Top  |  Next  ]          HmmerConvert will successfully append a  binary format profile HMM file  to an ASCII text format  file,  by converting the binary profile  HMM into an ASCII format  profile HMM.  The resulting  profile HMM  database is valid.  But  it also will append an  ASCII text file to a  binary format file without converting  it, and the resulting file  will be unusable by other  programs in the HMMER package.   HmmerConvert  also lets you create mixed  nucleic and protein profile HMM  databases, which will be unusable  by other  programs in the HMMER package  as well.        CONSIDERATIONS    [  Previous  |  Top  |  Next  ]          When converting a profile HMM  into a GCG profile, information  is lost.  Therefore the  list of best hits  obtained from  ProfileSearch  using this  profile as a query may  differ from the list of  best hits obtained  from HmmerSearch using the original  profile HMM as the query.    If you are appending a  profile HMM file onto an  existing HMM file, make sure  that the files are in  the  same format (ASCII text or  binary).  Mixed format profile  HMM database files cannot be  used by other  programs in the HMMER package.    HmmerPfam searches a binary profile  HMM database more quickly than  the same database in ASCII  text format.           COMMAND-LINE SUMMARY    [  Previous  |  Top  |  Next  ]          All parameters for this program  may be added to the  command line.  Use  -CHE ck   to view the summary  below and to specify parameters  before the program executes.   In the summary below, the  capitalized  letters in the parameter names  are the letters that you   must  type in order to  use the parameter.  Square brackets ([ and ])  enclose parameter values that are  optional.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.        Minimal Syntax: % hmmerconvert [-INfile1=]hsp70.hmm_g -Default    Prompted Parameters:    [-OUTfile=]hmmerconvert.hmm     sets the primary output filename    -MENu=a      converts file to HMMER2 ASCII file       b      converts file to HMMER2 binary file       p      converts file to GCG profile format file       e      appends the file to the output file instead of creating a new file       o      overwrites the output file    Local Data Files:  None    Optional Parameters:    -NOMONitor   suppresses the screen monitor              ACKNOWLEDGEMENT    [  Previous  |  Top  |  Next  ]          The programs comprising the HMMER  package are designed and implemented  by Dr. Sean Eddy of the  Washington University School of Medicine,  St. Louis, Missouri.  The Wisconsin  Package front-end  programs were written by Christiane  van Schlun in collaboration with  Dr. Eddy.           LOCAL DATA FILES    [  Previous  |  Top  |  Next  ]          None.        PARAMETER REFERENCE    [  Previous  |  Top  |  Next  ]          You can set the parameters  listed below from the command  line.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.              Following some of the parameters  described below is a short  expression in parentheses.  These  are the  names of the corresponding parameters  used in the native HMMER  package.  Some of the  GCG  parameters are identical to the  original HMMER parameters, others have  been changed to fit GCG's  conventions.             -MEN u =A      ( -a -b -p -A -F )         specifies the action to perform.   You can convert the  file into a new file  in one of the following  formats:  HMMER 2 ASCII format (A),  HMMER 2 binary format (B),  GCG profile format (P).  You can also change an  existing file by appending the  input file to the existing  file (E) or by  overwriting the existing file (O).   Unless  -MEN u  is set  to E or O, HmmerConvert  will not alter  existing files.        -NOMON itor          suppresses the display of the  program's progress on the screen.                 Printed: January 9, 2002  13:45 (1162)           [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]       Technical Support:  support-us@accelrys.com  or  support-eu@accelrys.com      Copyright (c) 1982-2002 Accelrys Inc.  A subsidiary of Pharmacopeia, Inc.  All rights reserved.    Licenses and Trademarks Wisconsin Package is a trademark and GCG and the GCG logo are registered trademarks of Accelrys Inc.    All other product names mentioned in this documentation may be trademarks, and if so, are trademarks or registered trademarks of their respective holders and are used in this documentation for identification purposes only.       www.accelrys.com/bio"
GX032-97-2071593	FORESST-A HMM search       HMM search in FORESST   - Perform a search against a library of hidden Markov models of protein folds.              Report only matches below rank of :             Paste your predicted secondary structure query sequence(s) here in FASTA format with headers:                  E-mail Address:                       [Back to Main Foresst Page]   [Browse via Model]   [Pick Up via ID]
GX024-63-2858066	HMM-based Protein Sequence Analysis, SAM-T99           This page now uses browser-based delivery by default.      To received results by email, check the email-results-box at the bottom      of the options section.   Warning:   Results      files can be quite large, and may exceed the allocations or      capabilities of your e-mail system.                  email address (required):       Subject for e-mail (optional)        Either cut and paste your sequence in the box below or upload it from a file on your local system.  Sequences must be in a    readseq -compatible format---we recommend FASTA format.  You may also use a multiple alignment as a seed, which must be in   a2m  format.     Cut and paste your sequence here, ...        or specify the sequence-containing file on your system here.                     Further options appear below.        This page offers the ability to perform remote protein homolog searches and protein structure prediction using HMM technology. It is part of a larger suite of UCSC's   HMM applications  that are available on the web. More details on the methods used can be found in an  HMM tutorial , though that tutorial talks about the predecessor SAM-T98 method, which differs in several parameter choices. A simpler web page that just searches our HMM library with the query sequence and doesn't build a multiple alignment, is the  SAM-T99 model-library web page , which may provide more limited results much faster.    The PDB sequence database is updated weekly, but the template libraries are only updated sporadically.        SAM-T99 Options       return T99 alignment in format(s):       A2M       Pretty Align       HTML             return HMM        Search PDB (sequences updated weekly)                      Maximum E value:         Maximum number of alignments to include:         Pairwise alignment format(s):                       Pretty Align             A2M                             Pad A2M inserts                                return secondary structure prediction in format(s):             RDB       FASTA       email results                        Email     sam-info@cse.ucsc.edu     with questions and problems       UCSC Bioinformatics Group         SAM Home Page       Target 99 developed by Kevin Karplus,     karplus@cse.ucsc.edu       Page designed by Spencer Tu,     stu@cse.ucsc.edu        Last modified: November 9, 2001
GX023-86-7629626	Genome Informatics Section         DOE Human Genome Program Contractor-Grantee Workshop   VII      January 12-16, 1999  Oakland, CA                                   94. Probabilistic Basecalling         Terry Speed, Lei Li, Dave Nelson, and  Simon   Cawley      University of California, Berkeley      scawley@stat.berkeley.edu         Basecalling is the process of converting   raw data from automated DNA sequencing machines to a sequence of bases.   The process is typically subdivided into the tasks of color separation,   mobility shift correction, deconvolution and decoding. A probabilistic   model of the process is presented, at center of which lies an Hidden Markov   Model (HMM). The class of HMMs is chosen for its flexibility and for the   availability of efficient algorithms for training and decoding. Performance   of this approach to basecalling is compared with the standard available   basecalling algorithms.                              Home        Sequencing        Functional   Genomics                Author   Index        Sequencing   Technologies        Microbial   Genome Program                Search        Mapping        Ethical,   Legal, & Social Issues                Order   a copy        Informatics        Infrastructure
GX017-16-14187663	Pfam   :: Home       The Pfam database of protein families and HMMs           Pfam (St. Louis)  |  Pfam (Cambridge)  |  Pfam (Stockholm)  |  Pfam (France)  |  HMMER  |  WashU/Genetics      Home  |  Protein search  |  DNA search  |  Browse Pfam  |  Keyword search  |  Taxonomy search  |  SwissPfam  |  Help              Pfam 10.0 (July 2003, 6190 families)                 Pfam is a large collection of  multiple sequence alignments  and  hidden Markov models  covering many common protein families. Pfam version  10.0  (July 2003) contains alignments and models for  6190  protein families, based on the  Swissprot 41.10  and  SP-TrEMBL 23.15  protein sequence databases.                             HELP     More information on Pfam, using this site, and the changes between       Pfam releases.             PROTEIN SEARCH     Analyze a protein query sequence to find Pfam family matches.                      DNA SEARCH     Analyze a DNA query sequence to find Pfam family matches.          (Uses the GeneWise server at the Sanger Centre.)             BROWSE PFAM     View Pfam annotation and alignments.             KEYWORD SEARCH     Query Pfam by keywords.             TAXONOMY SEARCH     Find Pfam families by taxonomy.             BROWSE SWISSPFAM     View the domain organization of a SWISSPROT/TrEMBL sequence according to Pfam.             FTP access to Pfam                Pfam alignments, HMMs, and other files are also available by      FTP.                   Most large files are compressed with  GNU gzip , file extension      .gz .                           Browse the Pfam ftp site (St. Louis)               README               Release notes               Summary of changes         from release 9.0 to 10.0, computer parsable              Pfam_ls  - The PFAM HMM library, glocal alignment models.              Pfam_fs  - The PFAM HMM library, local alignment models.              Pfam-A.full   - The full alignments of the curated families.              Pfam-A.seed   - The seed alignments of the curated families.              Pfam-B   - PRODOM-generated alignments of sequence clusters in        SWISSPROT and TrEMBL that are not modelled in the curated part of Pfam.              Swisspfam   - The domain structure of SWISSPROT and TrEMBL        proteins according to Pfam.               Swissother   - Additional annotation of SWISSPROT and TrEMBL        proteins.               domain.pnh   - A pseudo-new hampshire format tree file of Pfam     families and sequences.              St. Louis Pfam server  - a portable package for mirroring        the St. Louis Pfam Web site (for instance, behind a corporate        firewall).              Copyright  notice for Pfam.     The full text of the                 GNU Library General Public License  that Pfam        is licensed under.                 Comments, questions, flames? Email    <webmaster@genome.nas.nasa.gov> .     Last modified:  Thursday, 24-Jul-2003 16:26:43 PDT
GX015-48-5900418	"Human Genome Program Report Part II    1996 Informatics Abstracts                          Sequencing     Mapping     Informatics     ELSI     Infrastructure     SBIR       FY '94-'95 Projects        Part I Index     Part II Index     Glossary         Acronyms              BCM Server Core    Daniel Davison  and Randall Smith   Baylor College of Medicine; Houston, TX 77030   713/798-3738, Fax: -3759,  davison@bcm.tmc.edu     http://www.bcm.tmc.edu     We are providing a variety of molecular biologyrelated search and analysis services to Genome Program investigators to improve the identification of new genes and their functions. These services are available via the BCM Search Launcher World Wide Web (WWW) pages which are organized by function and provide a single point-of-entry for related searches. Pages are included for 1) protein sequence searches, 2) nucleic acid sequence searches, 3) multiple sequence alignments, 4) pairwise sequence alignments, 5) gene feature searches, 6) sequence utilities, and 7) protein secondary structure prediction. The Protein Sequence Search Page, for example, provides a single form for submitting sequences to WWW servers that provide remote access to a variety of different protein sequence search tools, including BLAST, FASTA, SmithWaterman, BEAUTY, BLASTPAT, FASTAPAT, PROSITE, and BLOCKS searches. The BCM Search Launcher extends the functionality of other WWW services by adding additional hypertext links to results returned by remote servers. For example, links to the NCBI's Entrez database and to the Sequence Retrieval System (SRS) are added to search results returned by the NCBI's WWW BLAST server. These links provide easy access to Medline abstracts, links to related sequences, and additional information which can be extremely helpful when analyzing database search results. For novice or infrequent users of sequence database search tools, we have preset the parameter values to provide the most informative firstpass sequence analysis possible.    A batch client interface to the BCM Search Launcher for Unix and Macintosh computers has also been developed to allow multiple input sequences to be automatically searched as a background task, with the results returned as individual HTML documents directly on the user's system. The BCM Search Launcher as well as the batch client are available on the WWW at URL [url no longer available].    The BCM/UH Server Core provides the necessary computational resources and continuing support infrastructure for the BCM Search Launcher. The BCM/UH Server Core is composed of three network servers and currently supports electronic mail and WWW-based access; ultimately, specialized clientserver access will also be provided. The hardware used includes a 2048processor MasPar massively parallel MIMD computer, a DEC Alpha AXP/OSF1, a Sun 2-processor SparcCenter 1000 server, and several Sun Sparc workstations.    In addition to grouping services available elsewhere on the WWW and providing access to services developed at BCM and UH, the BCM/UH Server Core will also provide access to services from developers who are unwilling or unable to provide their own Internet network servers.    Grant Nos.: DOE, DEFG039SER62097/A000; National Library of Medicine, R01LM05792; National Science Foundation, BIR 9111695; National Research Service Award, F32HG0013301; NIH, P30HG00210 and R01HG0097301.        A Freely Sharable DatabaseManagement System Designed for Use in ComponentBased, Modular Genome Informatics Systems    Steve Rozen, 1  Lincoln Stein, 1  and  Nathan Goodman    The Jackson Laboratory; Bar Harbor, ME 04609   Goodman: 207/288-6158, Fax: -6078,  nat@jax.org    1 Whitehead Institute for Biomedical Research; Cambridge, MA 02139    http://www-genome.wi.mit.edu/informatics/workflow/     We are constructing a data-management component, built on top of commercial data-management products, tuned to the requirements of genome applications. The core of this genome data manager is designed to:    · support the semantic and object-oriented data models that have been widely embraced for representing genome data,    · provide domain-specific builtin types and operations for storing and querying bimolecular sequences,    · provide built-in support for tracking laboratory work flows, and admit further extensions for other specialpurpose types,    · allow core facilities to be readily extended to meet the diverse needs of biological applications    The core data manager is being constructed on top of Sybase, Oracle, and Informix Universal Server. The software is available free of charge and is freely redistributable.    We will be reporting progress on the core data manager's architecture and interface at the URLs above, and we solicit comments on its design.    DOE Grant No. DEFG0295ER62101.    Originally called Database Management Research for the Human Genome Project, this project was initiated in 1995 at the Massachusetts Institute of Technology­Whitehead Institute.        A Software Environment for Large-Scale Sequencing    Mark Graves    Department of Cell Biology; Baylor College of Medicine; Houston, TX 77030   713/798-8271, Fax: -3759;  mgraves@bcm.tmc.edu     http://www.bcm.tmc.edu        Our approach is to implement software systems which manage primary laboratory sequence data and explore and annotate functional information in genome sequence and gene products.    Three software systems have been developed and are being used: two sequence data managers which use different sequence assembly packages, FAK and Phrap, and a series of analysis and annotation tools which are available via the Internet. In addition, we have developed a prototype application for data mining of sequence data as it is related to metabolic pathways.    Products of this project are the following:    1. GRM a sequence reconstruction manager using the FAQ assembly engine (available since October 1995).    2. GFP a sequence finishing support tool using the Phrap assembly engine (available since March 1996).    3. A series of gene recognition tools (available since early 1996).    4. A tool for visualizing metabolic pathways data and exploring sequence data related to metabolic pathways (prototype available since August 1996).    DOE Grant No. DE-FG03-94ER61618.        Generalized Hidden Markov Models for Genomic Sequence Analysis    David Haussler , Kevin Karplus, 1  and Richard Hughey 1    Computer Science Department and  1 Computer Engineering Department; University of California; Santa Cruz, CA 95064   408/459-2105, Fax: -4829,  haussler@cse.ucsc.edu     http://www.soe.ucsc.edu/research/compbio/        We have developed an integrated probabilistic method for locating genes in human DNA based on a generalized hidden Markov model (HMM). Each state of a generalized HMM represents a particular kind of region in DNA, such as an initial exon for a gene. The states are connected by transitions that model sites in DNA between adjacent regions, e.g. splice sites. In the full HMM, parametric statistical models are estimated for each of the states and transitions. Generalized HMMs allow a variety of choices for these models, such as neural networks, high order Markov models, etc. All that is required is that each model return a likelihood for the kind of region or transition it is supposed to model. These likelihoods are then combined by a dynamic programming method to compute the most likely annotation for a given DNA contig. Here the annotation simply consists of the locations of the transitions identified in the DNA, and the labeling of the regions between transitions with their corresponding states.    This method has been implemented in the genefinding program Genie, in collaboration with Frank Eeckman, Martin Reese and Nomi Harris at Lawrence Berkeley Labs. David Kulp, at UCSC, has been responsible for the core implementation. Martin Reese developed the splice site models, promoter models, and datasets. You can access Genie at the second www address given above, submit sequences, and have them annotated. Nomi Harris has written a display tool called Genotater that displays Genie's annotation along with the annotation of other genefinders, as well as the location of repetitive DNA, BLAST hits to the protein database, and other useful information. Papers and further information about Genie can be found at the first www address above. Since the ISMB '96 paper, Genie's exon models have been extended to explicitly incorporate BLAST and BLOCKS database hits into their probabilistic framework. This results in a substantial increase in gene predicting accuracy. Experimental results in tests using a standard set of annotated genes showed that Genie identified 95% of coding nucleotides correctly with a specificity of 88%, and 76% of exons were identified exactly.    DOE Grant No. DE-FG03-95ER62112.        Identification, Organization, and Analysis of Mammalian Repetitive DNA Information    Jerzy Jurka    Genetic Information Research Institute; Palo Alto, CA 94306   415/3265588 Fax: -2001,  jurka@gnomic.stanford.edu      There are three major objectives in this project: organization of databases of mammalian repetitive sequences, development of specialized software for analysis of repetitive DNA, and sequence studies of new mammalian repeats.    Our approach is based on extensive usage of computer tools to investigate and organize publicly available sequence information. We also pursue collaborative research with experimental laboratories. The results are widely disseminated via the internet, peer reviewed scientific publications and personal interactions. Our most recent research concentrates on mechanisms of retroposon integration in mammals (Jurka, J., PNAS, in press; Jurka, J and Klonowski, P., J. Mol. Evol. 43:685689).    We continue to develop reference collections of mammalian repeats which became a worldwide resource for annotation and study of newly sequenced DNA. The reference collections are being revised annually as part of a larger database of repetitive DNA, called Repbase. The recent influx of sequence data to public databases created an unprecedented need for automatic annotation of known repetitive elements. We have designed and implemented a program for identification and elimination of repetitive DNA known as CENSOR.    Reference collections of mammalian repeats and the CENSOR program are available electronically (via anonymous ftp to ncbi.nih.gov; directory repository/repbase). CENSOR can also be run via electronic mail (mail ""help"" message to censor@charon.lpi.org).    DOE Grant No. DEFG03-95ER62139.        *TRRD, GERD and COMPEL: Databases on Gene-Expression Regulation as a Tool for Analysis of Functional Genomic Sequences    A.E. Kel, O.A. Podkolodnaya, O.V. Kel, A.G. Romaschenko, E. Wingender, 1  G.C. Overton, 2  and  N.A. Kolchanov    Institute of Cytology and Genetics; Novosibirsk, Russia   Kolchanov: +7-3832/353-335, Fax: -336 or /356-558,  kol@benpc.bionet.nsc.ru      1 Gesellschaft für Biotechnologische Forschung; Braunschweig, Germany   2 Department of Genetics; University of Pennsylvania School of Medicine; Philadelphia, PA 19104-6145    The database on transcription regulatory regions in eukaryotic genomes (TRRD) has been developed [1]. The main principle of data representation in TRRD is modular structure and hierarchy of transcription regulatory regions. TRRD entry corresponds to a gene as entire unit. Information on gene regulation is provided (cellcycle and cell type specificity, developmental stage-specificity, influence of various molecular signals on gene expression). TRRD database contains information about structural organization of gene transcription regulatory region. TRRD contains description of known promoters and enhancers in 5', 3' regions and in introns. Description of binding sites for transcription factors includes nucleotide sequence and precise location, name of factors that bind to the site, experimental evidences for the binding site revealing. We provide crossreferences to TRANSFAC database [2] for both sites and factors as well as for genes. TRRD 3.3 release includes 340 vertebrate genes.    The Gene Expression Regulation Database (GERD) collects information on features of genes expression as well as information about gene transcription regulation. The current release of GERD contains 75 entries with information on expression regulation of genes expressed in hematopoietic tissues in the course of ontogenesis and blood cells differentiation. COMPEL database contains information about composite elements which are functional units essential for highly specific transcription regulation [3]. Direct interactions between transcription factors binding to their target sites within composite elements result in convergence of different signal transduction pathways. Nucleotide sequences and positions of composite elements, binding factors and types of their DNA binding domains, experimental evidence confirming synergistic or antagonistic action of factors are registered in COMPEL. Crossreferences to TRANSFAC factors table are given. TRRD and COMPEL are provided by crossreferences to each other. COMPEL 2.1 release includes 140 composite elements.    We have developed a software for analysis of transcription regulatory region structure. The CompSearch program is based on oligonucleotide weight matrix method. To collect sets of binding sites for the matrixes construction we have used TRANSFAC and TRRD databases. The CompSearch program takes into account the fine structure of experimentally confirmed NFATp/AP1 composite elements collected in COMPEL (distances between binding sites in composite elements, their mutual orientation). By means of the program we have found potential composite elements of NFATp/AP1 type in the regulatory regions of various cytokine genes. Analysis of composite elements could be the first approach to reveal specific patterns of transcription signals encoding regulatory potential of eukaryotic promoters.    References    1. Kel O.V., Romaschenko A.G., Kel A.E., Naumochkin A.N., Kolchanov N.A. Proceedings of the 28th Annual Hawaii International Conference on System Sciences [HICSS]. (1995), v.5, Biotechnology Computing, IEE Computer Society Press, Los Alamos, California, p. 42-51.    2. Wingender E., Dietze P., Karas H., and Knuppel R. TRANSFAC: a database on transcription factors and their DNA binding sites (1996). Nucl. Acids Res., 1996, v. 24, pp. 238-241.    3. Kel O.V., A.G. Romaschenko, A.E. Kel, E. Wingender, N.A. Kolchanov. A compilation of composite regulatory elements affecting gene transcription in vertebrates (1995). Nucl. Acids Res., v. 23, pp. 4097-4103.    Recent Publications    Kel, A., Kel, O., Ischenko, I., Kolchanov, N., Karas, H., Wingender, E. and Sklenar, H. (1996). TRRD and COMPEL databases on transcription linked to TRANSFAC as tools for analysis and recognition of regulatory sequences. Computer Science and Biology. Proceedings of the German Conference on Bioinformatics (GCB'96), R. Hofestadt, T. Lengauer, M. Löffler, D. Schomburg (eds.). University of Leipzig, Leipzig 1996, pp. 113-117.    Wingender, E., Kel, A. E., Kel, O. V., Karas, H., Heinemeyer, T., Dietze, P., Knueppel, R., Romaschenko, A. G. and Kolchanov, N. A. (1997). TRANSFAC, TRRD and COMPEL: Towards a federated database system on transcriptional regulation. Nucleic Acids Res., in press.    Ananko E.A., Ignatieva E.V., Kel A.E., Kolchanov N.A (1996). WWWTRRD: Hypertext information system on transcription regulation. Computer Science and Biology. Proceedings of the German Conference on Bioinformatics (GCB'96), R. Hofestadt, T. Lengauer, M. Löffler, D. Schomburg (eds.). University of Leipzig, Leipzig 1996, pp. 153-155.    A.E. Kel, O.V. Kel, O.V. Vishnevsky, M.P. Ponomarenko, I.V. Ischenko, H. Karas, N.A. Kolchanov, H. Sklenar, E. Wingender (1997). TRRD and COMPEL databases on transcription linked to TRANSFAC as tools for analysis and recognition of regulatory sequences. (1997) LECTURE NOTES IN COMPUTER SCIENCE, in press.    Holger Karas, Alexander Kel, Olga Kel, Nikolay Kolchanov, and Edgar Wingender (1997). Integrating knowledge on gene regulation by a federated database approach: TRANSFAC, TRRD and COMPEL. Jurnal Molekularnoy Biologii (Russian), in press.    Kel A.E., Kolchanov N.A., Kel O.V., Romaschenko A.G., Ananko E.A., Ignatyeva E.V., Merkulova T.I., Podkolodnaya O.A., Stepanenko I.L., Kochetov A.V., Kolpakov F.A., Podkolodniy N.L., Naumochkin A.A. (1997). TRRD: A database on transcription regulatory regions of eukaryotic genes. Jurnal Molekularnoy Biologii (Russian) in press.    O.V. Kel, A.E. Kel, A.G. Romaschenko, E. Wingender, N.A. Kolchanov (1997). Composite regulatory elements: classification and description in the COMPEL data base. Jurnal Molekularnoy Biologii (Russian), in press.        Data-Management Tools for Genomic Databases    Victor M. Markowitz  and  IMin A. Chen    Information and Computing Sciences Division; Lawrence Berkeley National Laboratory; Berkeley, CA 94720   510/486-6835, Fax: -4004,  vmmarkowitz@lbl.gov       The Object-Protocol Model (OPM) data management tools provide facilities for constructing, maintaining, and exploring efficiently molecular biology databases. Molecular biology data are currently maintained in numerous molecular biology databases (MBDs), including large archival MBDs such as the Genome Database (GDB) at Johns Hopkins School of Medicine, the Genome Sequence Data Base (GSDB) at the National Center for Genome Resources, and the Protein Data Bank (PDB) at Brookhaven National Laboratory. Constructing, maintaining, and exploring MBDs entail complex and timeconsuming processes.    The goal of the Object-Protocol Model (OPM) data management tools is to provide facilities for efficiently constructing, maintaining, and exploring MBDs, using applicationspecific constructs on top of commercial database management systems (DBMSs). The OPM tools will also provide facilities for reorganizing MBDs and for exploring seamlessly heterogenous MBDs. The OPM tools and documentation are available on the Web and are developed in close collaboration with groups maintaining MBDs, such as GDB, GSDB, and PDB.    Current work focuses on providing new facilities for constructing and exploring MBDs. The specific aims of this work are:    (1) Extend the OPM query language with additional constructs for expressing complex conditions, and enhance the OPM query optimizer for generating more efficient query plans.    (2) Develop enhanced OPM query interfaces supporting MBDspecific data types (e.g., protein data type) and operations (e.g., protein data display and 3D search), and assisting users in specifying and interpreting query results.    (3) Provide support for customizing MBD interfaces.    (4) Extend the OPM tools with facilities for managing permissions (object ownership) in MBDs, and for physical database design of relational MBDs, including specification of indexes, allocation of segments, and handling of redundant (denormalized) data.    (5) Develop OPM tools for constructing and maintaining multiple OPM views for both relational and nonrelational (e.g., ASN.1, AceDB) MBDs. For a given MBD, these tools will allow customizing different OPM views for different groups of scientists. For heterogeneous MBDs, this tool will allow exploring them using common OPM interfaces.    (6) Develop tools for constructing OPM based multidatabase systems of heterogeneous MBDs and for exploring and manipulating data in these MBDs via OPM interfaces. As part of this effort, the OPMbased multidatabase system which consists currently of GDB 6.0 and GSDB 2.0, will be extended to include additional MBDs, primarily GSDB 2.2 (when it becomes available), PDB, and Genbank.    (7) Develop facilities for reorganizing OPM-based MBDs.The database reorganization tools will support automatic generation of procedures for reorganizing MBDs following restructuring (revision) of MBD schemas.    In the past year, the OPM data management tools have been extended in order to address specific requirements of developing MBDs such as GDB 6 and the new version of PDB.    The current version of the OPM data management tools (4.1) was released in June 1996 for Sun/OS, Sun/Solaris and SGI. The following OPM tools are available on the Web at [url no longer available]:    (1) an editor for specifying OPM schemas;    (2) a translator of OPM schemas into relational database specifications and procedures;   (3) utilities for publishing OPM schemas in text (Latex), diagram (Postscript), and Html formats;    (4) a translator of OPM queries into SQL queries;    (5) a retrofitting tool for constructing OPM schemas (views) for existing relational genomic databases;    (6) a tool for constructing Webbased form interfaces to MBDs that have an OPM schema; this tool was developed by Stan Letovsky at Johns Hopkins School of Medicine, as part of a collaboration.    The OPM data management tools have been highly successful in developing new genomic databases, such as GDB 6 (released in January 1996) and the relational version of PDB, and in constructing OPM views and interfaces for existing genomic databases such as GSDB 2.0. The OPM data management tools are currently used by over ten groups in USA and Europe. The research underlying these tools is described in several papers published in scientific journals and presented at database and genome conferences.    In the past year the OPM tools have been presented at database and bioinformatics conferences, including the International Symposium on Theoretical and Computational Genome Research, Heidelberg, Germany, March 1996, the Workshop on Structuring Biological Information, Heidelberg, Germany, March 1996, the Meeting on Genome Mapping and Sequencing, Cold Spring Harbor, May 1996, the International Sybase User Group Conference, May 1996, the Bioinformatics Structure Conference, Jerusalem, November 1996, and the Pacific Symposium on Bioinformatics, January 1997.    The results of the research and development underlying the OPM tools work have been presented in papers published in proceedings of database and bioinformatics conferences; these papers are available at [url no longer available].    DOE Contract No. DE-AC03-76SF00098.        The Genome Topographer: System Design    S. Cozza, D. Cuddihy, R. Iwasaki, M. Mallison, C. Reed, J. Salit, A. Tracy, and  T. Marr    Cold Spring Harbor Laboratory; Cold Spring Harbor, NY 11724   Marr: 516/367-8393, Fax: -8461,  marr@cshl.org  or  marr@cb.cshl.org     Genome Topographer (GT) is an advanced genome informatics system that has received joint funding from DOE and NIH over a number of years. DOE funding has focused on GT tools supporting computational genome analysis, principally on sequence analysis. GT is scheduled for public release next spring under the auspices of the Cold Spring Harbor Human Genome Informatics Research Resource. GT has 17 major existing frameworks: 1. Views, including printing, 2. Default manager, 3. Graphical User Interface, 4. Query, 5. Project Manager, 6. Workspace Manager, 7. Asynchronous Process Manager, 8. Study Manager, 9. Help, 10. Application, 11. Notification, 12. Security, 13. World Wide Web Interface, 14. NCBI, 15. Reader, 16. Writer, 17. External Database Interface. GT Frameworks are independent sets of VisualWorks (client) or SmallTalkDB (GemStone) classes which interact to perform the duties required to satisfy the responsibilities of the specific framework. Each framework is clearly defined and has a welldefined interface to use it. These frameworks are used over and over in GT to perform similar duties in different places. GT has basic tools and special tools. Basic tools get used many times in different applications, while special tools tend to be special purpose, designed to do fairly limited things, although the distinction is somewhat arbitrary. Tools typically use several frameworks when they get assembled. Basic Tools: 1. Project Browser, 2. Editor/Viewer, 3. Query, 4. NCBI Entrez, 5. File reader/writer, 6. Map comparison, 7. Database Administrator, 8. Login, 9. Default, 10. Help. Special Tools: 1. Study Manager, 2. Compute Server, 3. Sequence Analysis, 4. Genetic Analysis. These frameworks and tools are combined with a comprehensive database schema of very rich biological expression linked with plugable computational tools. Taken together, these features allow users to construct, with relative ease, online databases of the primary data needed to study a genetic disease (or genes and phenotypes in general) from the stage of family collection and diagnostic ascertainment through cloning and functional analysis of candidate genes, including mutational analysis, expression information, and screening for biochemical interactions with candidate molecules. GT was designed on the premise that a highly informative, visual presentation of comprehensive data to a knowledgeable user is essential to their understanding. The advanced software engineering techniques that are promoted by using relatively new object oriented products has allowed GT to become a highly interactive and visuallyoriented system that allows the user to concentrate on the problem rather than on the computer. Using the rich data representational features characteristic of this technology, the GT software enables users to construct models of realworld, complex biological phenomena. These unique features of GT are key to the thesis that such a system will allow users to discover otherwise intractable networks of interactions exhibited by complex genetic diseases.    The VisualWorks development environment allows the development of code that runs unchanged across all major workstation and personal computers, including PCS, Macintoshes and most Unix workstations.   DOE Grant No. DE-FG0291ER61190.        A Flexible Sequence Reconstructor for LargeScale DNA Sequencing: A Customizable Software System for Fragment Assembly    Gene Myers  and Susan Larson   Department of Computer Science; University of Arizona; Tucson, AZ 85721   602/621-6612, Fax: -4246,  gene@cs.arizona.edu     http://www.cs.arizona.edu/faktory     We have completed the design and begun construction of a software environment in support of DNA sequencing called the ""FAKtory"". The environment consists of (1) our previously described software library, FAK, for the core combinatorial problem of assembling fragments, (2) a Tcl/Tk based interface, and (3) a software suite supporting a modest database of fragments and a processing pipeline that includes clipping and vector prescreening modules. A key feature of our system is that it is highly customizable: the structure of the fragment database, the processing pipeline, and the operation of each phase of the pipeline are specifiable by the user. Such customization need only be established once at a given location, subsequently users see a relatively simple system tailored to their needs. Indeed one may direct the system to input a raw dataset of say ABI trace files, pass them through a customized pipeline, and view the resulting assembly with two button clicks.    The system is built on top of our FAK software library and as a consequence one receives (a) highsensitivity overlap detection, (b) correct resolution to large highfidelity repeats, (c) near perfect multialignments, and (d) support of constraints that must be satisfied by the resulting assemblies. The FAKtory assumes a processing pipeline for fragments that consists of an INPUT phase, any number and sequence of CLIP, PRESCREEN, and TAG phases, followed by an OVERLAP and then an ASSEMBLY phase. The sequence of clip, prescreen, and tag phases is customizable and every phase is controlled by a panel of usersettable preferences each of which permits setting the phase's mode to AUTO, SUPERVISED, or MANUAL. This setting determines the level of interaction required by the user when the phase is run, ranging from none to handson. Any diagnostic situations detected during pipeline processing are organized into a log that permits one to confirm, correct, or undo decisions that might have been made automatically.   The customized fragment database contains fields whose type may be chosen from TIME, TEXT, NUMBER, and WAVEFORM. One can associate default values for fields unspecified on input and specify a control vocabulary limiting the range of acceptable values for a given field (e.g., John, Joe, or Mary for the field Technician, and [1, 36] for the field Lane). This database may be queried with SQLlike predicates that further permit approximate matching over text fields. Common queries and/or sets of fragments selected by them may be named and referred to later by said name. The pipeline status of a fragment may be part of a query.    The system permits one to maintain a collection of alternative assemblies, to compare them to see how they are different, and directly manipulate assemblies in a fashion consistent with sequence overlaps. The system can be customized so that a priori constraints reflecting a given sequencing protocol (e.g. doublebarreled or transposon-mapped) are automatically produced according to the syntax of the names of fragments (e.g. X.f and X.r for any X are mates for doublebarreled sequencing). The system presents visualizations of the constraints applied to an assembly, and one may experiment with an assembly by adding and/or removing constraints. Finally, one may edit the multialignment of an assembly while consulting the raw waveforms. Special attention was given to optimizing the ergonomics of this timeintensive task.    DOE Grant No. DEFG0394ER61911.        The Role of Integrated Software and Databases in Genome Sequence Interpretation and Metabolic Reconstruction    Terry Gaasterland, Natalia Maltsev,  Ross Overbeek , and Evgeni Selkov   Mathematics and Computer Science Division; Argonne National Laboratory; Argonne, IL 60439   630/252-4171, Fax: -5986,  gaasterl@mcs.anl.gov    MAGPIE:  http://genomes.rockefeller.edu/research.shtml    WIT:  [url not available]     As scientists successfully sequence complete genomes, the issue of how to organize the large quantities of evolving sequence data becomes paramount. Through our work in comparative whole genome analysis (MAGPIE, Gaasterland) and metabolic reconstruction algorithms (WIT, Overbeek, Maltsev, and Selkov), we carry genome interpretation beyond the identification of gene products to customized views of an organism's functional properties.    MAGPIE is a system designed to reside locally at the site of a genome project and actively carry out analysis of genome sequence data as it is generated. 1,2  DNA sequences produced in a sequencing project mature through a series of stages that each require different analysis activities. Even after DNA has been assembled into contiguous fragments and eventually into a single genome, it must be regularly reanalyzed. Any new data in public sequence databases may provide clues to the identity of genes. Over a year, for 2 megabases with 4fold coverage, MAGPIE will request on the order of 100,000 outputs from remote analysis software, manipulate and manage the output, update the current analysis of the sequence data, and monitor the project sequence data for changes that initiate reanalysis.   In collaboration with Canada's Institute for Marine Biosciences and the Canadian Institute for Advanced Research, MAGPIE is being used to maintain and study comparative views of all open reading frames (ORFs) across fully sequenced genomes (currently 5), nearly completed genomes (currently 2) and 1 genome in progress (Sulfolobus solfataricus). Together, these genomes represent multiple archaeal and bacterial genomes and one eukaryotic genome. This analysis provides the necessary data to assign phylogenetic classifications to each ORF (e.g., ""AE"" for archaeal and eukaryotic). This data in turn provides the basis for validating and assessing functional annotations according to phylogenetic neighborhood (e.g., selecting the eukaryotic form of a biochemical function over a bacterial form for an ""AE"" ORF). 3     Once an automated functional overview has been established, it remains to pinpoint the organisms' exact metabolic pathways and establish how they interact.To this end, the WIT (What Is There) system supports efforts to develop metabolic reconstructions. Such constructions, or models, are based on sequence data, clearly established biochemistry of specific organisms, understanding of the interdependencies of biochemical mechanisms. WIT thus offers a valuable tool for testing current hypotheses about microbial behavior. For example, a reconstruction may begin with a set of established enzymes (enzymes with strong similarities in identified coding regions to existing sequences for which the enzymatic function is known) and putative enzymes (enzymes with weak similarity to sequences of known function). From these initial ""hits,"" within a phylogenetic perspective, we identify an initial set of pathways. This set can be used to generate a set of expected enzymes (enzymes that have not been clearly detected, but that would be expected given the set of hypothesized pathways) and missing enzymes (enzymes that occur in the pathways but for which no sequence has yet been biochemically identified for any organism). Further reasoning identifies tentative connective pathways.    In addition to helping curators develop metabolic reconstructions, WIT lets users examine models curated by experts, follow connections between more than two thousand metabolic diagrams, and compare models (e.g., which of certain genes that are conserved among bacterial genomes are found in higher life). The objective is to set the stage for meaningful simulations of microbial behavior and thus to advance our understanding of microbial biochemistry and genetics.   DOE Contract No. W31109Eng38 (ANL FWP No. 60427).    References    [1] T. Gaasterland and C. Sensen, Fully Automated Genome Analysis that Reflects User Needs and Preferences a Detailed Introduction to the MAGPIE System Architecture, Biochemie, 78(4), (accepted).    [2] T. Gaasterland, J. Lobo, N. Maltsev, and G. Chen. Assigning Function to CDS Through Qualified Query Answering. In Proc. 2nd Int. Conf. Intell. Syst. for Mol. Bio., Stanford U. (1994).    [3] T. Gaasterland and E. Selkov. Automatic Reconstruction of Metabolic Structure from Incomplete Genome Sequence Data. In Proc. Int. Conf. Intell. Syst. for Mol. Bio., Cambridge, England (1995).        Database Transformations for Biological Applications    G.Christian Overton ,  SusanB. Davidson , 1  and  Peter Buneman 1    Department of Genetics and  1 Department of Computer and Information Science; University of Pennsylvania;   Philadelphia, PA 19104   Overton: 215/5733105, Fax: -3111,  coverton@cbil.humgen.    upenn.edu    Davidson: 215/8983490, Fax: 0587,  susan@cis.upenn.edu    Buneman: 215/8987703, Fax: -0587, peter@cis.upenn.edu      We have implemented a generalpurpose query system, Kleisli, that provides access to a variety of ""nonstandard"" data sources (e.g., ACeDB, ASN.1, BLAST), as well as to ""standard"" relational databases. The system represents a major advance in the ability to integrate the growing number and diversity of biology data sources conveniently and efficiently. It features a uniform query interface, the CPL query language, across heterogeneous data sources, a modular and extensible architecture, and most significantly for dealing with the Internet environment, a programmable optimizer. We have demonstrated the utility of the system in composing and executing queries that were considered difficult, if not unanswerable, without first either building a monolithic database or writing highly application-specific integration code (details and examples available at URL above).    In conjunction with other software developed in our group, we have assembled a toolset that supports a range of data integration strategies as well as the ability to create specialized data warehouses initialized from community databases. Our integration strategy is based upon the concept of ""mediators"", which serve a group of related applications by providing a uniform structural interface to the relevant data sources. This approach is costeffective in terms of query development time and maintenance. We have examined in detail methods for optimizing queries such as ""retrieve all known human sequence containing an Alu repeat in an intragenic region"" where the data sources are heterogeneous and distributed across the Internet.   Transformation of data resources, that is the structural reorganization of a data resource from one form to another, arises frequently in genome informatics. Examples include the creation of data warehouses and database evolution. Implementing such transformations by hand on a case by case basis is time consuming and error prone. Consequently there is a need for a method of specifying, implementing and formally verifying transformations in a uniform way across a wide variety of different data models. Morphase is a prototype system for specifying transformations between data sources and targets in an intuitively appealing, declarative language based on Horn clause logic. Transformations specification in Morphase are translated into CPL and executed in the Kleisli system. The datatypes underlying Morphase include arbitrarily nested records, sets, variants, lists and object identity, thus capturing the types common to most data formats relevant to genome informatics, including ASN.1 and ACE. Morphase can be connected to a wide variety of data sources simultaneously through Kleisli. In this way, data can be read from multiple heterogeneous data sources, transformed using Morphase according to the desired output format, and inserted into the target data source.    We have tested Morphase by applying it to a variety of different transformation problems involving Sybase, ACE and ASN.1. For example, we used it to specify a transformation between the Sanger Center's Chromosome 22 ACE database (ACE22DB) and a Chromosome 22 Sybase database (Chr22DB), as well as between a portion of GDB and Chr22DB. Some of these transformations had already been handcoded without our tools, forming a basis for comparison.    Once the semantic correspondences between objects in the various databases were understood, writing the transformation program in Morphase was easy, even by a nonexpert of the system. Furthermore, it was easy to find conceptual errors in the transformation specification. In contrast, the handcoded programs were obtuse, difficult to understand, and even more difficult to debug.    DOE Grant No. DE-FG02-94ER61923.    Relevant Publications    P. Buneman, S.B. Davidson, K. Hart, C. Overton and L. Wong,""A Data Transformation System for Biological Data Sources,"" in Proceedings of VLDB, Sept. 1995 (Zurich, Switzerland). Also available as Technical Report MSCIS9510, University of Pennsylvania, March 1995.    S.B. Davidson, C. Overton and P. Buneman, ""Challenges in Integrating Biological Data Sources,"" J. Computational Biology 2 (1995), pp 557-572.    A. Kosky, ""Transforming Databases with Recursive Data Structures,"" PhD Thesis, December 1995.    S.B. Davidson and A. Kosky, ""Effecting Database Transformations Using Morphase,"" Technical Report MSCIS9605, University of Pennsylvania.    A. Kosky, S.B. Davidson and P. Buneman, ""Semantics of Database Transformations,"" Technical Report MSCIS9525, University of Pennsylvania, 1995.    K. Hart and L. Wong, ""Pruning Nested Data Values Using Branch Expressions With Wildcards,"" In Abstracts of MIMBD, Cambridge, England, July 1995.        Las Vegas Algorithm for Gene Recognition: Suboptimal and ErrorTolerant Spliced Alignment     SingHoi Sze and  Pavel A. Pevzner 1    Departments of Computer Science and  1 Mathematics;   University of Southern California; Los Angeles, CA 90089   Pevzner: 213/740-2407, Fax: -2424;   ppevzner@hto.usc.edu       Recently, Gelfand, Mironov, and Pevzner (Proc. Natl. Acad. Sci. USA, 1996, 90619066) proposed a spliced alignment approach to gene recognition that provides 99% accurate recognition of human gene if a related mammalian protein is available. However, even 99% accurate gene predictions are insufficient for automated sequence annotation in largescale sequencing projects and therefore have to be complemented by experimental gene verification. 100% accurate gene predictions would lead to a substantial reduction of experimental work on gene identification. Our goal is to develop an algorithm that either predicts an exon assembly with accuracy sufficient for sequence annotation or warns a biologist that the accuracy of a prediction is insufficient and further experimental work is required. We study suboptimal and errortolerant spliced alignment problems as the first steps towards such an algorithm, and report an algorithm which provides 100% accurate recognition of human genes in 37% of cases (if a related mammalian protein is available). For 52% of genes, the algorithm predicts at least one exon with 100% accuracy.    DOE Grant No. DEFG0397ER62383.        Foundations for a Syntactic Pattern- Recognition System for Genomic DNA Sequences: Languages, Automata, Interfaces, and Macromolecules    David B. Searls  and G. Christian Overton 1    SmithKline Beecham Pharmaceuticals; King of Prussia, PA 19406   610/270-4551, Fax: -5580,  searldb@sb.com    1 Department of Genetics; University of Pennsylvania; Philadelphia, PA 19104    Viewed as strings of symbols, biological macromolecules can be modelled as elements of formal languages. Generative grammars have been useful in molecular biology for purposes of syntactic pattern recognition, for example in the author's work on the GenLang pattern matching system, which is able to describe and detect patterns that are probably beyond the capability of a regular expression specification. More recently, grammars have been used to capture intramolecular interactions or longdistance dependencies between residues, such as those arising in folded structures. In the work of Haussler and colleagues, for example, stochastic contextfree grammars have been used as a framework for ""learning"" folded RNA structures such as tRNAs, capturing both primary sequence information and secondary structural covariation. Such advances make the study of the formal status of the language of biological macromolecules highly relevant, and in particular the finding that DNA is beyond contextfree has already created challenges in algorithm design.    Moreover, to date, such methods have not been able to capture relationships between strings in a collection, such as those that arise via intermolecular interactions, or evolutionary relationships implicit in alignments. Recently we have attempted to remedy this by showing (1) how formal grammars can be extended to describe interacting collections of molecules, such as hybridization products and, potentially, multimeric or physiological protein interactions, and (2) how simple automata can be used to model evolutionary relationships in such a way that complex modelbased alignment algorithms can be automatically generated by means of visual programming. These results allow for a useful generalization of the languagetheoretic methods now applied to single molecules.    In addition, we describe a new software packagebioWidgetfor the rapid development and deployment of graphical user interfaces (GUIs) designed for the scientific visualization of molecular, cellular and genomics information. The overarching philosophy behind bioWidgets is componentry: that is, the creation of adaptable, reusable software, deployed in modules that are easily incorporated in a variety of applications and in such a way as to promote interaction between those applications. This is in sharp distinction to the common practice of developing dedicated applications. The bioWidgets project additionally focuses on the development of specific applications based on bioWidget componentry, including chromosomes, maps, and nucleic acid and peptide sequences.    The current set of bioWidgets has been implemented in Java with the goal in mind of delivering local applications and distributed applets via Intranet/Internet environments as required. The immediate focus is on developing interfaces for information stored in distributed heterogeneous databases such as GDB, GSDB, Entry, and ACeDB. The issues we are addressing are database access, reflecting database schemas in bioWidgets, and performance. We are also directing our efforts into creating a consortium of bioWidget developers and endusers. This organization will create standards for and encourage the development of bioWidget components. Primary participants in the consortium include Gerry Rubin (UC Berkeley) and Nat Goodman (Jackson Labs).    DOE Grant No. DE-FG02-92ER61371.    Relevant Publications    D.B. Searls, ""String Variable Grammar: A Logic Grammar Formalism for DNA Sequences,"" Journal of Logic Programming 24 (1,2):73-102 (1995).    D.B. Searls, ""Formal Grammars for Intermolecular Structure,"" First International Symposium on Intelligence in Neural and Biological Systems, 30-37 (1995).    D.B. Searls and K.P. Murphy, ""AutomataTheoretic Models of Mutation and Alignment,"" Third International Conference on Intelligent Systems for Molecular Biology, 341-349 ( 1995).    D.B. Searls, ""bioTk: Componentry for Genome Informatics Graphical User Interfaces,"" Gene 163 (2):GC116 (1995).        Analysis and Annotation of Nucleic Acid Sequence    David J. States , Ron Cytron, Pankaj Agarwal, and Hugh Chou   Institute for Biomedical Computing; Washington University; St. Louis, MO 63108   314/3622134, Fax: 0234,  states@ibc.wustl.edu        Bayesian estimates for sequence similarity: There is an inherent relationship between the process of pairwise sequence alignment and the estimation of evolutionary distance. This relationship is explored and made explicit. Assuming an evolutionary model and given a specific pattern of observed base mismatches, the relative probabilities of evolution at each evolutionary distance are computed using a Bayesian framework. The mean or the median of this probability distribution provides a robust estimate of the central value. Bayesian estimates of the evolutionary distance incorporate arbitrary prior information about variable mutation rates both over time and along sequence position, thus requiring only a weak form of the molecularclock hypothesis.   The endpoints of the similarity between genomic DNA sequences are often ambiguous. The probability of evolution at each evolutionary distance can be estimated over the entire set of alignments by choosing the best alignment at each distance and the corresponding probability of duplication at that evolutionary distance. A central value of this distribution provides a robust evolutionary distance estimate. We provide an efficient algorithm for computing the parametric alignment, considering evolutionary distance as the only parameter.    These techniques and estimates are used to infer the duplication history of the genomic sequence in  C. elegans  and in  S. cerevisae . Our results indicate that repeats discovered using a single scoring matrix show a considerable bias in subsequent evolutionary distance estimates.    Model based sequence scoring metrics : PAM based DNA comparison metric has been extended to incorporate biases in nucleotide composition and mutation rates, extending earlier work (States, Gish and Altschul, 1993). A codon based scoring system has been developed that incorporates the effects biased codon utilization frequencies.    A dynamic programming algorithm has been developed that will optimally align sequences using a choice of comparison measures (noncoding vs. coding, etc.). We are in the process of evaluating this approach as a means for identifying likely coding regions in cDNA sequences.    Efficient sequence similarity search tools : Most sequence search tools have been designed for use with protein sequence queries a few hundred residues long. The analysis of genomic DNA sequence necessitates the use of queries hundreds of kilobases or even megabases in length. A memory and computationally efficient search tool has been developed for the identification of repeats and sequence similarity in very large segments of nucleic acid sequence. The tool implements optimal encoding of the word table, repeat filters, flexible scoring systems, and analytically parameterized search sensitivity. Output formats are designed for the presentation of genomic sequence searches.    Federated databases : A sybase server and mirror for GSDB are being developed to facilitate the annotation of repeat sequence elements in public data repositories.    DOE Grant No. DE-FG02-94ER61910.        Gene Recognition, Modeling, and Homology Search in GRAIL and genQuest     Ying Xu, Manesh Shah, J.Ralph Einstein, Sherri Matis, Xiaojun Guan, Sergey Petrov, Loren Hauser, 1  RichardJ. Mural, 1  and  EdwardC. Uberbacher     Computer Science and Mathematics and  1 Biology   Divisions; Oak Ridge National Laboratory; Oak Ridge, TN 37831   Uberbacher: 423/574-6134, Fax: -7860,  ube@ornl.gov     http://compbio.ornl.gov     GRAIL is a modular expert system for the analysis and characterization of DNA sequences which facilitates the recognition of gene features and gene modeling. A new version of the system has been created with greater sensitivity for exon prediction (especially in AT rich regions), more accurate splice site prediction, and robust indel error detection capability. GRAIL 1.3 is available to the user in a Motif graphical clientserver system (XGRAIL), through WWW-Netscape, by e-mail server, or callable from other analysis programs using Unix sockets.    In addition to the positions of protein coding regions and gene models, the user can view the positions of a number of other features including polyA addition sites, potential Pol II promoters, CpG islands and both complex and simple repetitive DNA elements using algorithms developed at ORNL. XGRAIL also has a direct link to the genQuest server, allowing characterization of newly obtained sequences by homologybased methods using a number of protein, DNA, and motif databases and comparison methods such as FastA, BLAST, parallel SmithWaterman, and special algorithms which consider potential frameshifts during sequence comparison.    Following an analysis session, the user can use an annotation tool which is part of the XGRAIL 1.3 system to generate a ""feature table"" report describing the current sequence and its properties. Links to the GSDB sequence database have been established to record computerbased analysis of sequences during submission to the database or as third party annotation.    Gene Modeling and ClientServer GRAIL : In addition to the current coding region recognition capabilities based on a multiple sensorneural network and rule base, modules for the recognition of features such as splice junctions, transcription and translation start and stop, and other control regions have been constructed and incorporated into an expert system (GAP III) for reliable computerbased modeling of genes. Heuristic methods and dynamic programming are used to construct first pass gene models which include the potential for modification of initially predicted exons. These actions result in a net improvement in gene characterization, particularly in the recognition of very short coding regions. Translation of gene models and database searches are also supported through access to the genQuest server (described below).    Model Organism Systems : A number of model organism systems have been designed and implemented and can be accessed within the XGRAIL 1.3 client including Escherichia coli, Drosophila melanogaster and Arabidopsis thaliana. The performance of these systems is basically equivalent to the Human GRAIL 1.3 system. Additional model organism systems, including several important microorganisms, are in progress.    Error Detection in Coding Sequences : Singlepass DNA sequencing is becoming a widely used technique for gene identification from both cDNA and genomic DNA sequences. An appreciably higher rate of base insertion and deletion errors (indels) in this type of sequence can cause serious problems in the recognition of coding regions, homology search, and other aspects of sequence interpretation. We have developed two error detection and ""correction"" strategies and systems which make lowredundancy sequence data more informative for gene identification and characterization purposes. The first algorithm detects sequencing errors by finding changes in the statistically preferred reading frame within a possible coding region and then rectifies the frame at the transition point to make the potential exon candidate frameconsistent. We have incorporated this system in GRAIL 1.3 to provide analysis which is very error tolerant. Currently the system can detect about 70% of the indels with an indel rate of 1%, and GRAIL identifies 89% of the coding nucleotides compared to 69% for the system without error correction. The algorithm uses dynamic programming and runs in time and space linear to the size of the input sequence.    In the second method, a Smith-Waterman type comparison is facilitated in which the frame of DNA translation to protein sequence can change within the sequence. The transition points in the translation frame are determined during the comparison process and a best match to potential protein homologs is obtained with sections of translations from more than one frame. The algorithm can detect homologies with a sensitivity equivalent to SmithWaterman in the presence of 5% indel errors.    Detection of Regulatory Regions : An initial Polymerase II promoter detection system has been implemented which combines individual detectors for TATA, CAAT, GC, cap, and translation start elements and distance information using a neural network. This system finds about 67% of TATA containing promoters with a false positive rate of one per 35 kilobases. Additionally a systems to detect potential polyA addition sites and CpG islands has been incorporated into GRAIL.    The GenQuest Sequence Comparison Server : The genQuest server is an integrated sequence comparison erver which can be accessed via email, using Unix sockets from other applications, Netscape, and through a Motif graphical clientserver system. The basic purpose of the server system is to facilitate rapid and sensitive comparison of DNA and protein sequences to existing DNA, protein, and motif databases. Databases accessed by this system include the daily updated GSDB DNA sequence database, SwissProt, the dbEST expressed sequence tag database, protein motif libraries and motif analysis systems (Prosite, BLOCKS), a repetitive DNA library (from J. Jurka), Genpept, and sequences in the PDB protein structural database. These options can also be accessed from the XGRAIL graphical client tool.    The genQuest server supports a variety of sequence query types. For searching protein databases, queries may be sent as amino acid or DNA sequence. DNA sequence can be translated in a user specified frame or in all 6 frames. DNADNA searches are also supported. User selectable methods for comparison include the SmithWaterman dynamic programming algorithm, FastA, versions of BLAST, and the IBM dFLASH protein sequence comparison algorithm. A variety of options for search can be specified including gap penalties and option switches for SmithWaterman, FastA, and BLAST, the number of alignments and scores to be reported, desired target databases for query, choice of PAM and Blosum matrices, and an option for masking out repetitive elements. Multiple target databases can be accessed within a single query.    Additional Interfaces and Access : Batch GRAIL 1.3 is a new ""batch"" GRAIL client allows users to analyze groups of short (300-400 bp) sequences for coding character and automates a wide choice of database searches for homology and motifs. A Command Line Sockets Client has been constructed which allows remote programs to call all the basic analysis services provided by the GRAILgenQuest system without the need to use the XGRAIL interface. This allows convenient integration of selected GRAIL analyses into automated analysis pipelines being constructed at some genome centers. An XGRAIL Motif Graphical Client for the GRAIL release 1.3 has been constructed using Motif with versions for a wide variety of UNIX platforms including Sun, Dec, and SGI. The email version of GRAIL can be accessed at grail@ornl.gov and the email version of genQuest can be accessed at Q@ornl.gov. Instructions can be obtained by sending the word ""help"" to either address. The Motif or Sun versions of XGRAIL, batch GRAIL, and XgenQuest client software are available by anonymous ftp from grailsrv.lsd.ornl.gov (124.167.140.21). Both GRAIL and genQuest are accessible over the World Wide Web (URL http://compbio.ornl.gov). Communications with the GRAIL staff should be addressed to GRAILMAIL@ornl.gov.    DOE Contract No. DEAC05840R21400.        Informatics Support for Mapping inMouseHuman Homology Regions    Edward Uberbacher , Richard Mural, 1  Manesh Shah, Loren Hauser, 1  and Sergey Petrov   Computer Science and Mathematics Division and  1 Biology Division; Oak Ridge National Laboratory; Oak Ridge, TN 37831   423/574-6134, Fax: -7860,  ube@ornl.gov     The purpose of this project is to develop databases and tools for the Oak Ridge National Laboratory (ORNL) MouseHuman Mapping Project, including the construction of a mapping database for the project; tools for managing and archiving cDNAs and other probes used in the laboratory; and analysis tools for mapping, interspecific backcross, and other needs. Our initial effort involved installing and developing a relational SYBASE database for tracking samples and probes, experimental results, and analyses. Recent work has focused on a corresponding ACeDB implementation containing mouse mapping data and providing numerous graphical views of this data. The initial relational database was constructed with SYBASE using a schema modeled on one implemented at the Lawrence Livermore National Laboratory (LLNL) center; this was because of documentation available for the LLNL system and the opportunity to maximize compatibility with human chromosome 19 mapping. (Major homologies exist between human chromosome l9 and mouse chromosome 7, the initial focus of the ORNL work.)    With some modification, our ACeDB implementation was modeled somewhat on the Lawrence Berkeley National Laboratory (LBNL) chromosome 21 ACeDB system and designed to contain genetic and physical mouse map data as well as homologous human chromosome data. The usefulness of exchanging map information with LLNL (human chromosome 19) and potentially with other centers has led to the implementation of procedures for data export and the import of human mapping data into ORNL databases.    User access to the system is being provided by workstation formsbased data entry and ACeDB graphical data browsing. We have also implemented the LLNL database browser to view human chromosome l9 data maintained at LLNL, and arrangements are being made to incorporate mouse mapping information into the browser. Other applications such as the  Encyclopedia of the Mouse , specific tools for archiving and tracking cDNAs and other mapping probes, and analysis of interspecific backcross data and YAC restriction mapping have been implemented.    We would like to acknowledge use of ideas from the LLNL and LBNL Human Genome Centers.    DOE Contract No. DEAC05840R21400.        SubmitData: Data Submission to Public Genomic Databases    Manfred D. Zorn    Software Technologies and Applications Group;   Information and Computing Sciences Division; Lawrence   Berkeley National Laboratory; University of California; Berkeley CA 94720   510/486-5041, Fax: -4004,  mdzorn@lbl.gov     http://www-hgc.lbl.gov/submitr.html     Making information generated by the various genome projects available to the community is very important for the researcher submitting data and for the overall project to justify the expenses and resources. Public genome databases generally provide a protocol that defines the required data formats and details how they accept data, e.g., sequences, mapping information. These protocols have to strike a balance between ease of use for the user and operational considerations of the database provider, but are in most cases rather complex and subject to change to accommodate modifications in the database.    SubmitData is a user interface that formats data for submission to GSDB or GDB. The user interface serves data entry purposes, checking each field for data types, allowed ranges and controlled values, and gives the user feedback on any problems. Besides onetime submissions, templates can be created that can later be merged with TABdelimited data files, e.g., as produced by common spreadsheet programs. Variables in the template are then replaced by values in defined columns of the input data file. Thus submitting large amounts of related data becomes as easy as selecting a format and supplying an input filename. This allows easy integration of data submission into the data generation process.    The interface is generated directly from the protocol specifications. A specific parser/compiler interprets the protocol definitions and creates internal objects that form the basis of the user interface. Thus a working user interface, i.e., static layout of buttons and fields, data validation, is automatically generated from the protocol definitions. Protocol modifications are propagated by simply regenerating the interface.    The program has been developed using ParcPlace VisualWorks and currently supports GSDB, GDB and RHdb data submissions. The program has been updated to use VisualWorks 2.0.    DOE Contract No. DEAC0376SF00098.       Note:  The proceedings of the 1997 DOE Human Genome Program Contractor-Grantee Workshop VI, which include updated research abstracts, can be found at:     http://www.ornl.gov/hgmis/publicat/97santa/santafe.shtml                                   Return to  Human Genome Project Information   Return to  HGP Research Home"
GX013-90-14387418	%  SAM: modelfromalign v2.2.1 (October 5, 1998) compiled 10/06/98_12:35:54. %  SAM:  Sequence Alignment and Modeling Software System %  (c) 1992-1998 Regents of the University of California, Santa Cruz %  http://www.cse.ucsc.edu/research/compbio/sam.html % % ------ Citations (HMMs, SAM) ------ % A. Krogh et al., Hidden Markov models in computational biology: %   Applications to protein modeling, JMB 235:1501-1531, Feb 1994. % R. Hughey, A. Krogh, Hidden Markov models for sequence analysis: %   Extension and analysis of the basic method, CABIOS 12:95-107, 1996. % ----------------------- %  Run start: Mon Mar  1 13:42:17 1999 %  Run name:  tmp-build-weighted-model-26437/tmp %  On host:   alpha %  In dir:    /auto/cse/guests/farmer %  By user:   farmer % -------------------------------------------------------------- %  /projects/compbio/lib/recode2.20comp has 20 priors on 20 characters. MODEL --  Model from alignment file /cse/guests/farmer/weight-alignment/input/23820.a2m alphabet protein LETTCOUNT 0.000000 0.000000 0.000000  0.000000 0.000000 0.000000  0.000000 0.000000 0.000000  0.091886 0.011822 0.067705 0.065556 0.042988  0.072004 0.031166 0.038152 0.034928 0.083826  0.026868 0.042988 0.045674 0.035465 0.065019  0.062869 0.047286 0.055347 0.026868 0.051585  0.091886 0.011822 0.067705 0.065556 0.042988  0.072004 0.031166 0.038152 0.034928 0.083826  0.026868 0.042988 0.045674 0.035465 0.065019  0.062869 0.047286 0.055347 0.026868 0.051585  FREQAVE 0.000000 0.000000 0.000000  0.000000 0.000000 0.000000  0.000000 0.000000 0.000000  0.087845 0.012189 0.068013 0.063648 0.042629  0.075538 0.032059 0.040927 0.039330 0.082046  0.027306 0.043612 0.045956 0.033658 0.060124  0.059327 0.049826 0.056655 0.027842 0.051469  0.087845 0.012189 0.068013 0.063648 0.042629  0.075538 0.032059 0.040927 0.039330 0.082046  0.027306 0.043612 0.045956 0.033658 0.060124  0.059327 0.049826 0.056655 0.027842 0.051469  Begin 0.000000 0.000000 0.000000  0.000000 0.000000 0.000000  0.000000 0.289149 0.749566  0.000000 0.000000 0.000000 0.000000 0.000000  0.000000 0.000000 0.000000 0.000000 0.000000  0.000000 0.000000 0.000000 0.000000 0.000000  0.000000 0.000000 0.000000 0.000000 0.000000  0.077886 0.016625 0.057273 0.065498 0.039808  0.062174 0.024292 0.060424 0.064466 0.082087  0.024578 0.047259 0.040293 0.041922 0.048780  0.068046 0.059894 0.072083 0.011730 0.034881     1 0.000000 0.147824 0.020374  0.000000 0.563026 0.230060  0.017716 0.003848 0.633785  0.020415 0.004154 0.083312 0.023611 0.013609  0.009616 0.011991 0.022310 0.029920 0.115915  0.442775 0.012867 0.008557 0.023658 0.098003  0.016898 0.019766 0.024879 0.004054 0.013689  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912     2 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.094983 0.001205 0.138189 0.442991 0.002623  0.012591 0.005730 0.004878 0.029347 0.007433  0.002856 0.016350 0.012117 0.024808 0.013394  0.021112 0.156701 0.008298 0.000932 0.003463  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912     3 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.093426 0.003379 0.093177 0.044205 0.009694  0.018541 0.011289 0.207763 0.039302 0.023664  0.008161 0.152911 0.014369 0.089881 0.023423  0.035203 0.095300 0.021434 0.003156 0.011722  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912     4 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.093956 0.001626 0.007958 0.081961 0.001280  0.759675 0.002351 0.001417 0.005822 0.002593  0.001018 0.008349 0.003662 0.003629 0.004179  0.010867 0.004211 0.003011 0.000711 0.001725  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912     5 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.008162 0.002888 0.001822 0.003794 0.545988  0.002763 0.004044 0.024853 0.005655 0.227129  0.014140 0.002908 0.003140 0.004687 0.084856  0.004816 0.005790 0.018486 0.006523 0.027558  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912     6 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.026937 0.006982 0.002546 0.004683 0.009663  0.004393 0.002373 0.053741 0.004808 0.281365  0.011990 0.003511 0.004500 0.003368 0.003960  0.008302 0.250617 0.309874 0.001445 0.004941  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912     7 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.017239 0.003554 0.183356 0.024567 0.481292  0.012269 0.009554 0.009962 0.013732 0.014866  0.004918 0.020311 0.007664 0.010569 0.009410  0.025654 0.102642 0.013173 0.004188 0.031082  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912     8 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.094347 0.004513 0.001287 0.002617 0.016288  0.003333 0.001893 0.041865 0.003406 0.659697  0.021192 0.002269 0.003125 0.002742 0.002845  0.004520 0.008699 0.119168 0.001641 0.004553  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912     9 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.172284 0.002121 0.495311 0.065648 0.003057  0.018080 0.007126 0.004184 0.025778 0.007152  0.002751 0.024194 0.011583 0.019713 0.087539  0.025286 0.015564 0.007015 0.001194 0.004423  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    10 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.022329 0.001144 0.222531 0.457331 0.002707  0.085052 0.005499 0.003922 0.020476 0.006014  0.002268 0.016335 0.011650 0.021162 0.009315  0.017824 0.012291 0.077614 0.000984 0.003552  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    11 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.005621 0.002531 0.000817 0.000938 0.011619  0.001299 0.001055 0.481253 0.002097 0.152757  0.169548 0.001180 0.001666 0.001468 0.001813  0.001907 0.005208 0.152032 0.001310 0.003881  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    12 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.023532 0.005969 0.005161 0.082228 0.090265  0.006286 0.005981 0.042258 0.009690 0.217045  0.016392 0.006315 0.006439 0.008063 0.008626  0.010525 0.018797 0.421787 0.003177 0.011465  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    13 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.005953 0.000489 0.004926 0.003444 0.002878  0.003181 0.504976 0.002424 0.004244 0.003149  0.000552 0.007892 0.426870 0.004993 0.004736  0.006780 0.004073 0.002902 0.000290 0.005250  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    14 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.012410 0.001598 0.179202 0.009501 0.001271  0.636115 0.003878 0.001506 0.008397 0.002680  0.000927 0.023348 0.004773 0.004839 0.004847  0.092446 0.006785 0.002470 0.000747 0.002260  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    15 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.104105 0.007122 0.003476 0.006324 0.013576  0.005530 0.003794 0.046436 0.006576 0.206138  0.013390 0.004463 0.005463 0.005061 0.005720  0.008515 0.019460 0.449255 0.077776 0.007822  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    16 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.096289 0.002116 0.021785 0.190802 0.003251  0.010377 0.009212 0.006285 0.056495 0.012794  0.005240 0.014938 0.009360 0.030063 0.478500  0.018813 0.017103 0.010662 0.001414 0.004500  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    17 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.003054 0.000817 0.000945 0.001351 0.018368  0.001944 0.001514 0.262844 0.001399 0.015724  0.003118 0.001003 0.001094 0.000863 0.002922  0.002176 0.002540 0.011723 0.653083 0.013519  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    18 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.020143 0.001265 0.592907 0.165164 0.002695  0.013168 0.005576 0.003710 0.017801 0.079474  0.002246 0.018751 0.010783 0.019484 0.008260  0.017134 0.011337 0.005481 0.001010 0.003612  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    19 0.935632 0.089095 0.176182  0.046652 0.907057 0.190034  0.013408 0.004198 0.633785  0.609272 0.007478 0.003621 0.005794 0.008561  0.019173 0.002587 0.019026 0.005552 0.216989  0.009684 0.003644 0.006534 0.004761 0.004416  0.024810 0.013462 0.028961 0.001309 0.004365  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    20 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.013627 0.002063 0.005564 0.013015 0.002851  0.008859 0.009770 0.006322 0.676920 0.013097  0.004366 0.013245 0.007726 0.021537 0.164006  0.012455 0.011595 0.007519 0.001221 0.004241  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    21 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.001952 0.001038 0.001565 0.001467 0.016367  0.001122 0.004697 0.001751 0.001475 0.003827  0.001059 0.001854 0.000597 0.000912 0.001565  0.002093 0.001566 0.002041 0.003093 0.949958  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    22 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.913384 0.004467 0.002688 0.003206 0.002009  0.014479 0.001134 0.002553 0.002648 0.004311  0.002191 0.002153 0.004038 0.002208 0.002146  0.018472 0.007281 0.008369 0.000444 0.001820  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    23 0.464930 0.006235 0.176182  0.521662 0.989567 0.190034  0.026103 0.003552 0.633785  0.025481 0.079931 0.005028 0.005687 0.003933  0.006396 0.002236 0.022804 0.005901 0.014671  0.005158 0.008830 0.005464 0.004301 0.004654  0.040346 0.640816 0.114496 0.000825 0.003041  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    24 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.157897 0.000717 0.000914 0.001401 0.098962  0.002114 0.001875 0.003154 0.001229 0.008536  0.001895 0.001002 0.001027 0.000872 0.002758  0.002411 0.002019 0.003126 0.691211 0.016879  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    25 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.006282 0.001868 0.772256 0.013226 0.000859  0.016400 0.005115 0.001611 0.008356 0.002506  0.000783 0.125955 0.004910 0.004585 0.002873  0.019125 0.008374 0.002021 0.000525 0.002372  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    26 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.096211 0.002311 0.035415 0.009492 0.001567  0.015243 0.004587 0.002358 0.009420 0.003916  0.001510 0.763865 0.004767 0.005857 0.005346  0.019426 0.011047 0.004187 0.000670 0.002802  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    27 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.004623 0.001978 0.000355 0.000705 0.720574  0.000984 0.001749 0.089717 0.000539 0.029465  0.006984 0.000609 0.002071 0.000756 0.001016  0.002539 0.002535 0.010803 0.009008 0.112989  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    28 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.012890 0.003252 0.006290 0.006969 0.002204  0.005701 0.003051 0.005078 0.012023 0.005770  0.002706 0.010590 0.004911 0.006518 0.088907  0.043163 0.768275 0.008529 0.000705 0.002467  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    29 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.010270 0.000983 0.005584 0.003730 0.000935  0.869407 0.001846 0.001036 0.004408 0.001851  0.000632 0.007230 0.072724 0.002391 0.003320  0.007304 0.002597 0.001821 0.000612 0.001319  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    30 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.018441 0.002520 0.009068 0.021572 0.003886  0.007958 0.007420 0.079812 0.608052 0.015504  0.005091 0.012289 0.007991 0.019728 0.049592  0.018439 0.090220 0.016476 0.001266 0.004675  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    31 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.140208 0.001325 0.006959 0.009480 0.002113  0.008655 0.002555 0.004168 0.009966 0.007656  0.001320 0.003814 0.697395 0.064971 0.006552  0.014788 0.008557 0.007036 0.000512 0.001968  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    32 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.010692 0.003507 0.000942 0.001298 0.007903  0.001586 0.000868 0.161538 0.001986 0.117227  0.008903 0.001175 0.001917 0.001209 0.001663  0.002296 0.008410 0.662566 0.001012 0.003302  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    33 0.905157 0.082238 0.176182  0.068739 0.914210 0.190034  0.017716 0.003848 0.633785  0.017684 0.001846 0.596121 0.064649 0.004025  0.015597 0.007897 0.003690 0.017670 0.006793  0.002685 0.026625 0.009681 0.093919 0.009644  0.020316 0.012071 0.005396 0.001436 0.082254  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    34 0.935632 0.089095 0.176182  0.046652 0.907057 0.190034  0.013408 0.004198 0.633785  0.011864 0.001173 0.006997 0.005060 0.001169  0.843297 0.002411 0.001262 0.005779 0.002387  0.000854 0.008815 0.003174 0.084624 0.004417  0.008805 0.003295 0.002202 0.000753 0.001662  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    35 0.464930 0.006235 0.176182  0.521662 0.989567 0.190034  0.026103 0.003552 0.633785  0.005797 0.003661 0.002808 0.003423 0.136228  0.003696 0.014484 0.006255 0.004113 0.013238  0.003650 0.004870 0.075533 0.002072 0.003664  0.006162 0.004570 0.006716 0.010482 0.688578  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    36 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.029970 0.001730 0.032568 0.427825 0.005581  0.009532 0.007270 0.012365 0.049276 0.078500  0.066346 0.015035 0.072707 0.091437 0.024327  0.023334 0.025172 0.018869 0.001692 0.006462  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    37 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.037087 0.006299 0.007403 0.012453 0.006556  0.086025 0.005184 0.028977 0.012393 0.023264  0.007719 0.007400 0.005984 0.081723 0.010393  0.014631 0.019052 0.619851 0.001716 0.005890  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    38 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.162609 0.002247 0.132901 0.015466 0.001339  0.019691 0.006169 0.002023 0.012039 0.003381  0.001144 0.579931 0.006577 0.006877 0.005303  0.024244 0.011304 0.002914 0.000731 0.003108  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    39 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.009038 0.001718 0.004091 0.009864 0.003104  0.005852 0.101570 0.004146 0.051357 0.009729  0.003732 0.010358 0.004793 0.018290 0.735301  0.008231 0.007493 0.005154 0.001213 0.004965  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    40 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.029051 0.152314 0.002287 0.003995 0.006471  0.004319 0.001705 0.552713 0.003821 0.030607  0.008303 0.003214 0.004182 0.002457 0.003074  0.009107 0.094355 0.083305 0.001003 0.003718  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    41 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.005719 0.002439 0.000802 0.000911 0.083383  0.001207 0.000946 0.232579 0.001928 0.206215  0.011366 0.001079 0.001569 0.001310 0.001674  0.001817 0.005334 0.434613 0.001254 0.003854  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    42 0.905157 0.082238 0.176182  0.068739 0.914210 0.190034  0.017716 0.003848 0.633785  0.023602 0.003247 0.005155 0.004940 0.005032  0.690767 0.002565 0.015087 0.005772 0.099177  0.005433 0.006506 0.003963 0.003707 0.004608  0.010471 0.008113 0.097390 0.001113 0.003354  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    43 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.012982 0.003234 0.008967 0.007723 0.004023  0.006410 0.199051 0.005600 0.008830 0.006592  0.002954 0.014010 0.005227 0.008396 0.007922  0.040105 0.642008 0.008914 0.001010 0.006041  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    44 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.016651 0.002939 0.016132 0.103096 0.017657  0.010118 0.012231 0.007307 0.340502 0.014862  0.005603 0.014395 0.007483 0.022170 0.032975  0.016222 0.013624 0.010147 0.004196 0.331690  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    45 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.238490 0.001467 0.140138 0.372926 0.002720  0.014630 0.005964 0.004254 0.025929 0.006752  0.002614 0.017465 0.012215 0.022928 0.012138  0.092174 0.015224 0.007311 0.000993 0.003668  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    46 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.092453 0.004417 0.001325 0.002648 0.016508  0.003015 0.002006 0.042483 0.003485 0.504699  0.099709 0.002349 0.003120 0.002813 0.002940  0.004141 0.008633 0.196828 0.001701 0.004727  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    47 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.640278 0.088610 0.003041 0.004703 0.004683  0.018583 0.001893 0.102895 0.004122 0.017169  0.006028 0.003092 0.006470 0.003080 0.003120  0.024098 0.016879 0.047062 0.000870 0.003323  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    48 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.095648 0.004357 0.022846 0.368286 0.079424  0.012255 0.010954 0.024533 0.030471 0.100012  0.011419 0.015106 0.012091 0.023181 0.020247  0.024124 0.093328 0.032283 0.004118 0.015316  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    49 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.435445 0.008367 0.004686 0.005548 0.003023  0.110570 0.002212 0.003198 0.004960 0.006448  0.003738 0.004375 0.007914 0.003901 0.003500  0.361201 0.014147 0.013112 0.000757 0.002899  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    50 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.003856 0.001465 0.000785 0.001039 0.009453  0.001032 0.000832 0.019222 0.001472 0.925091  0.011594 0.001083 0.001080 0.001329 0.001423  0.001490 0.002113 0.012372 0.000884 0.002382  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    51 0.935632 0.089095 0.176182  0.046652 0.907057 0.190034  0.013408 0.004198 0.633785  0.179098 0.003823 0.018001 0.116716 0.010232  0.011560 0.011698 0.017997 0.043474 0.328352  0.010636 0.015398 0.011096 0.031266 0.104761  0.022609 0.024194 0.024424 0.003334 0.011333  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    52 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.101420 0.001575 0.019810 0.127480 0.002685  0.010347 0.008620 0.008268 0.443449 0.014260  0.005264 0.017222 0.012066 0.035197 0.125764  0.023705 0.023713 0.014283 0.001007 0.003865  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    53 0.708107 0.006235 0.176182  0.278485 0.989567 0.190034  0.017716 0.003848 0.633785  0.765327 0.008396 0.004025 0.005124 0.003011  0.027619 0.001986 0.003388 0.004399 0.006526  0.003763 0.003556 0.007658 0.003569 0.003172  0.117560 0.013880 0.013497 0.000732 0.002813  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    54 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.096811 0.001113 0.022421 0.134079 0.002459  0.008193 0.006909 0.072735 0.326119 0.014823  0.005606 0.015847 0.012857 0.102919 0.101573  0.025428 0.028270 0.017789 0.000773 0.003278  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    55 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.095542 0.001411 0.128926 0.361916 0.003467  0.012514 0.006314 0.143241 0.034389 0.010238  0.003803 0.016621 0.012509 0.026730 0.016135  0.090372 0.019113 0.011210 0.001166 0.004385  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    56 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.025233 0.005754 0.009666 0.082595 0.019486  0.009868 0.077693 0.105688 0.017765 0.330405  0.017095 0.011210 0.010198 0.014177 0.015881  0.017962 0.025549 0.180436 0.005097 0.018243  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    57 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.748136 0.007559 0.003527 0.005324 0.005135  0.021803 0.002211 0.010641 0.004792 0.100272  0.005712 0.003294 0.006626 0.004163 0.003737  0.027964 0.012822 0.021902 0.000964 0.003417  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    58 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.495934 0.003589 0.010557 0.026171 0.003755  0.012812 0.009604 0.005497 0.046494 0.012964  0.005793 0.012513 0.007572 0.103190 0.192699  0.019479 0.014407 0.010350 0.001672 0.004948  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    59 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.027679 0.003711 0.090148 0.032812 0.007897  0.020127 0.010607 0.012362 0.034526 0.084398  0.006580 0.026468 0.081667 0.022143 0.087716  0.112601 0.308897 0.017096 0.002666 0.009897  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    60 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.027067 0.003993 0.023452 0.029975 0.010584  0.089115 0.081148 0.014097 0.033718 0.157818  0.008751 0.026812 0.013440 0.294080 0.025512  0.100777 0.024544 0.018102 0.003773 0.013243  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    61 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.011619 0.001151 0.005881 0.004074 0.001312  0.855007 0.002051 0.001677 0.004867 0.078603  0.000991 0.007661 0.002854 0.002735 0.003724  0.007953 0.002980 0.002553 0.000715 0.001591  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    62 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.008526 0.004098 0.004002 0.006492 0.137514  0.004816 0.015214 0.010156 0.006767 0.098828  0.006009 0.006305 0.003263 0.161664 0.006385  0.008142 0.007488 0.010895 0.010245 0.483190  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    63 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.016658 0.001673 0.007280 0.006563 0.001715  0.751406 0.002902 0.002489 0.007252 0.004056  0.001514 0.008696 0.003689 0.080042 0.005625  0.010660 0.005100 0.079622 0.000858 0.002201  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    64 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.008689 0.003080 0.001845 0.006456 0.015441  0.002765 0.004250 0.030995 0.006093 0.760252  0.020462 0.003330 0.002255 0.091317 0.006246  0.003719 0.005008 0.020908 0.001945 0.004945  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    65 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.009779 0.003473 0.000879 0.001632 0.015811  0.002115 0.001465 0.056731 0.002627 0.579567  0.019895 0.001692 0.002336 0.002101 0.002224  0.002838 0.006183 0.282878 0.001547 0.004225  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    66 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.007389 0.003021 0.000663 0.001376 0.101864  0.002008 0.001536 0.120810 0.002514 0.685556  0.024203 0.001664 0.002270 0.002172 0.002148  0.002609 0.004007 0.026827 0.001990 0.005372  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    67 0.935632 0.089095 0.176182  0.046652 0.907057 0.190034  0.013408 0.004198 0.633785  0.002319 0.000531 0.000958 0.001383 0.017666  0.002137 0.001953 0.002334 0.001217 0.007512  0.001547 0.001006 0.000937 0.000672 0.003207  0.002180 0.001898 0.002324 0.838921 0.109299  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    68 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.001513 0.000239 0.973307 0.004197 0.000546  0.002100 0.000768 0.000387 0.001585 0.000829  0.000238 0.005625 0.000796 0.001175 0.001034  0.002783 0.001478 0.000592 0.000090 0.000720  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    69 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.148143 0.089787 0.005608 0.005003 0.002200  0.669731 0.002250 0.002683 0.005116 0.004727  0.002392 0.006442 0.005615 0.003434 0.003786  0.022827 0.008528 0.008600 0.000774 0.002353  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    70 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.001952 0.001038 0.001565 0.001467 0.016367  0.001122 0.004697 0.001751 0.001475 0.003827  0.001059 0.001854 0.000597 0.000912 0.001565  0.002093 0.001566 0.002041 0.003093 0.949958  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    71 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.001503 0.000218 0.001319 0.001627 0.000703  0.000826 0.001103 0.000675 0.006959 0.001639  0.000530 0.001568 0.000619 0.002182 0.973900  0.001426 0.001294 0.000915 0.000169 0.000822  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    72 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.020177 0.001293 0.007387 0.009861 0.002366  0.009085 0.002905 0.004690 0.010681 0.008657  0.001365 0.003992 0.869765 0.005279 0.007048  0.015808 0.009244 0.007682 0.000563 0.002149  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    73 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.021755 0.002564 0.018485 0.031452 0.003976  0.016313 0.090397 0.005947 0.378442 0.013432  0.005311 0.101093 0.010924 0.186565 0.053091  0.025298 0.017943 0.009198 0.001820 0.005992  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    74 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.027700 0.002453 0.105411 0.045042 0.004170  0.022634 0.011540 0.006255 0.057694 0.011875  0.004349 0.030129 0.014699 0.101356 0.403192  0.109061 0.024184 0.010090 0.001729 0.006436  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    75 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.719691 0.009193 0.003749 0.005561 0.004268  0.024580 0.002116 0.014989 0.004794 0.013160  0.005378 0.003465 0.007615 0.003765 0.003528  0.031598 0.016326 0.121999 0.000880 0.003343  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    76 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.025777 0.005857 0.005551 0.014675 0.007368  0.005808 0.006553 0.039392 0.012909 0.030235  0.009270 0.006259 0.004596 0.191548 0.011398  0.009692 0.017470 0.587883 0.001883 0.005877  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    77 0.951285 0.097200 0.176182  0.035308 0.898602 0.190034  0.010785 0.004618 0.633785  0.012846 0.002845 0.268418 0.023276 0.002214  0.024026 0.008027 0.003773 0.016332 0.005673  0.001887 0.450707 0.008599 0.009687 0.007375  0.030442 0.015669 0.102688 0.001059 0.004457  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    78 0.960814 0.006859 0.176182  0.028401 0.988523 0.190034  0.010785 0.004618 0.633785  0.006950 0.830677 0.002078 0.003309 0.001840  0.003203 0.001892 0.002398 0.006973 0.003985  0.001722 0.003106 0.002211 0.004720 0.105465  0.005408 0.005251 0.006244 0.000609 0.001961  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    79 0.765204 0.006859 0.176182  0.224010 0.988523 0.190034  0.013408 0.004198 0.633785  0.099275 0.002964 0.001091 0.002284 0.639977  0.002765 0.002106 0.021192 0.002103 0.048138  0.098538 0.001503 0.003091 0.002563 0.002437  0.005033 0.005198 0.017977 0.008734 0.033031  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    80 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.008245 0.003295 0.000803 0.001735 0.116205  0.002261 0.001826 0.041888 0.002859 0.312611  0.454458 0.001899 0.002571 0.002621 0.002509  0.003047 0.004493 0.026528 0.002606 0.007539  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    81 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.024363 0.002748 0.097671 0.045792 0.005571  0.011741 0.011922 0.008999 0.054693 0.095538  0.007452 0.017711 0.010131 0.345316 0.195089  0.021626 0.020046 0.014063 0.002303 0.007225  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    82 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.003347 0.000721 0.001058 0.001658 0.017795  0.002286 0.001756 0.005195 0.001478 0.010212  0.002158 0.001105 0.001098 0.001070 0.003384  0.002461 0.002513 0.096846 0.828727 0.015131  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    83 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.527580 0.008109 0.008037 0.014573 0.004317  0.026631 0.003710 0.007350 0.013273 0.010851  0.005083 0.006985 0.009451 0.094106 0.008112  0.122787 0.019879 0.103641 0.001159 0.004365  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    84 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.596485 0.007278 0.012967 0.019415 0.003765  0.026884 0.004124 0.005452 0.016506 0.009307  0.004360 0.009135 0.105570 0.093777 0.010299  0.036924 0.017591 0.015087 0.001050 0.004023  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    85 0.708107 0.006235 0.176182  0.278485 0.989567 0.190034  0.017716 0.003848 0.633785  0.019935 0.080509 0.019208 0.022986 0.004975  0.014224 0.010323 0.006409 0.022379 0.012688  0.005929 0.098938 0.008030 0.482403 0.017934  0.037485 0.116247 0.010652 0.002152 0.006595  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    86 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.018857 0.001202 0.006883 0.009213 0.002203  0.008481 0.002710 0.004378 0.009982 0.008089  0.001271 0.003709 0.878395 0.004934 0.006584  0.014779 0.008631 0.007173 0.000523 0.002002  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    87 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.094122 0.001060 0.152621 0.605094 0.002559  0.012430 0.005231 0.003716 0.019986 0.005716  0.002189 0.014942 0.011523 0.021340 0.008907  0.016762 0.011796 0.005763 0.000928 0.003316  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    88 0.935632 0.089095 0.176182  0.046652 0.907057 0.190034  0.013408 0.004198 0.633785  0.017400 0.002729 0.226967 0.027214 0.003121  0.027449 0.009765 0.003317 0.022265 0.006108  0.002079 0.383639 0.094411 0.013837 0.012143  0.036016 0.017134 0.004739 0.083892 0.005777  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    89 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.026964 0.003414 0.039978 0.031286 0.005931  0.107427 0.012347 0.007442 0.034409 0.013079  0.004781 0.416225 0.014159 0.097559 0.022832  0.040740 0.024311 0.086135 0.002351 0.008630  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    90 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.097890 0.005118 0.009708 0.016844 0.022250  0.010442 0.012188 0.032567 0.023479 0.439906  0.017366 0.012130 0.009761 0.017328 0.096181  0.018218 0.022400 0.033810 0.005455 0.096958  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    91 0.708107 0.006235 0.176182  0.278485 0.989567 0.190034  0.017716 0.003848 0.633785  0.023509 0.003733 0.012890 0.028590 0.006298  0.009248 0.007698 0.013039 0.036802 0.018065  0.006823 0.014976 0.009484 0.092688 0.097480  0.038764 0.479832 0.090829 0.002037 0.007216  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    92 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.022212 0.002267 0.012036 0.029031 0.003735  0.009621 0.008231 0.009945 0.571317 0.015311  0.005109 0.013909 0.089667 0.023755 0.054625  0.018183 0.018286 0.086714 0.001276 0.004772  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    93 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.022064 0.001353 0.148043 0.519958 0.002705  0.088129 0.006257 0.003451 0.020746 0.005600  0.002103 0.021099 0.011950 0.020262 0.009924  0.093033 0.013106 0.005335 0.001047 0.003837  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    94 0.935632 0.089095 0.176182  0.046652 0.907057 0.190034  0.013408 0.004198 0.633785  0.025495 0.002716 0.026588 0.030111 0.004150  0.025302 0.012536 0.005382 0.209442 0.011050  0.003893 0.106229 0.014766 0.025706 0.121843  0.333841 0.024277 0.008138 0.001799 0.006734  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    95 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.007432 0.004410 0.003897 0.004821 0.062877  0.004798 0.106668 0.093323 0.005867 0.014880  0.004275 0.006631 0.002822 0.003340 0.005280  0.008040 0.006370 0.008699 0.011758 0.633811  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    96 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.104429 0.004339 0.004003 0.005046 0.054540  0.006291 0.014558 0.006818 0.005497 0.013571  0.004041 0.005868 0.002918 0.003629 0.004882  0.009465 0.006572 0.008946 0.010049 0.724537  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    97 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.017366 0.001160 0.007503 0.008922 0.002667  0.008142 0.165328 0.004325 0.009954 0.007664  0.001266 0.005491 0.714214 0.005554 0.007095  0.014342 0.008459 0.006792 0.000554 0.003201  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    98 0.951285 0.097200 0.176182  0.035308 0.898602 0.190034  0.010785 0.004618 0.633785  0.014233 0.002861 0.043555 0.023136 0.003210  0.019031 0.013572 0.003180 0.022515 0.008378  0.003797 0.645486 0.007489 0.120481 0.016468  0.025319 0.014976 0.005302 0.001592 0.005420  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    99 0.960814 0.006859 0.176182  0.028401 0.988523 0.190034  0.010785 0.004618 0.633785  0.007530 0.003121 0.001029 0.000982 0.010201  0.001327 0.000954 0.680605 0.002229 0.057256  0.010665 0.001161 0.001804 0.001326 0.001922  0.002100 0.007588 0.202591 0.001323 0.004286  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   100 0.960814 0.006859 0.176182  0.028401 0.988523 0.190034  0.010785 0.004618 0.633785  0.109508 0.001689 0.419317 0.189481 0.004091  0.017963 0.007630 0.005026 0.024266 0.008042  0.002983 0.022169 0.014186 0.024343 0.012070  0.024324 0.015539 0.007380 0.001470 0.088524  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   101 0.960814 0.006859 0.176182  0.028401 0.988523 0.190034  0.010785 0.004618 0.633785  0.014796 0.002650 0.006699 0.018555 0.003714  0.008995 0.012357 0.005941 0.075464 0.014899  0.005976 0.013743 0.006989 0.124349 0.645316  0.012592 0.011803 0.008050 0.001800 0.005313  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   102 0.960814 0.006859 0.176182  0.028401 0.988523 0.190034  0.010785 0.004618 0.633785  0.227119 0.008585 0.006353 0.009553 0.006863  0.010333 0.003500 0.128073 0.009490 0.025593  0.008369 0.008845 0.007592 0.006483 0.007041  0.035360 0.415698 0.068352 0.001447 0.005351  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   103 0.960814 0.006859 0.176182  0.028401 0.988523 0.190034  0.010785 0.004618 0.633785  0.020153 0.002713 0.048802 0.623321 0.008545  0.011189 0.011066 0.004861 0.019831 0.013326  0.006212 0.014465 0.008022 0.031435 0.014855  0.014820 0.011766 0.008246 0.114859 0.011515  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   104 0.960814 0.006859 0.176182  0.028401 0.988523 0.190034  0.010785 0.004618 0.633785  0.113509 0.004968 0.002331 0.005162 0.020726  0.005291 0.003474 0.044186 0.005945 0.222224  0.488161 0.003625 0.004114 0.005980 0.005270  0.007496 0.009950 0.038455 0.002357 0.006777  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   105 0.960814 0.006859 0.176182  0.028401 0.988523 0.190034  0.010785 0.004618 0.633785  0.006765 0.002945 0.001107 0.001134 0.107699  0.001401 0.001168 0.582123 0.002418 0.062841  0.011705 0.001302 0.001919 0.001569 0.002136  0.002284 0.007055 0.194818 0.001763 0.005846  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   106 0.960814 0.006859 0.176182  0.028401 0.988523 0.190034  0.010785 0.004618 0.633785  0.030713 0.004230 0.028785 0.116938 0.004377  0.021552 0.008777 0.007214 0.031297 0.010208  0.004243 0.029104 0.102790 0.020398 0.018592  0.391749 0.148968 0.012441 0.001603 0.006020  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   107 0.960814 0.006859 0.176182  0.028401 0.988523 0.190034  0.010785 0.004618 0.633785  0.016869 0.002352 0.021321 0.021231 0.003161  0.014411 0.010006 0.006036 0.628379 0.012073  0.004176 0.117566 0.009280 0.022027 0.060401  0.020633 0.015749 0.008036 0.001338 0.004954  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   108 0.960814 0.006859 0.176182  0.028401 0.988523 0.190034  0.010785 0.004618 0.633785  0.012113 0.001261 0.010092 0.005237 0.001203  0.826310 0.002635 0.001346 0.006120 0.002403  0.000811 0.100495 0.003520 0.003322 0.004404  0.010115 0.003774 0.002257 0.000788 0.001796  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   109 0.960814 0.006859 0.176182  0.028401 0.988523 0.190034  0.010785 0.004618 0.633785  0.007442 0.004047 0.008117 0.005777 0.054965  0.006084 0.019021 0.005956 0.006589 0.012466  0.003696 0.110703 0.002923 0.004141 0.005605  0.009322 0.006669 0.007085 0.010451 0.708941  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   110 0.765204 0.006859 0.176182  0.224010 0.988523 0.190034  0.013408 0.004198 0.633785  0.037270 0.008531 0.003297 0.005605 0.007796  0.006116 0.002227 0.057508 0.005473 0.034206  0.009415 0.003707 0.094746 0.003240 0.004257  0.009240 0.022539 0.679100 0.001220 0.004507  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   111 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.606582 0.008649 0.005027 0.007854 0.005462  0.021987 0.002960 0.017806 0.007455 0.104316  0.006463 0.005131 0.007944 0.005530 0.005465  0.031999 0.107804 0.035993 0.001182 0.004392  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   112 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.137654 0.006677 0.007845 0.009148 0.003728  0.015288 0.003275 0.009936 0.009393 0.009756  0.004503 0.011957 0.008036 0.006815 0.006794  0.484331 0.155162 0.105001 0.001008 0.003692  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   113 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.022046 0.002242 0.017323 0.028599 0.003515  0.093470 0.011026 0.006484 0.382997 0.012773  0.004383 0.022641 0.089148 0.102857 0.139509  0.026221 0.018626 0.009230 0.001473 0.005440  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   114 0.951285 0.006235 0.176182  0.035308 0.989567 0.190034  0.013408 0.004198 0.633785  0.043959 0.005336 0.018766 0.013727 0.003438  0.019152 0.005322 0.005655 0.014338 0.007672  0.003441 0.020471 0.111879 0.009036 0.009737  0.635533 0.055910 0.011373 0.001086 0.004168  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   115 0.708107 0.006235 0.176182  0.278485 0.989567 0.190034  0.017716 0.003848 0.633785  0.027413 0.003251 0.040991 0.024753 0.003694  0.103382 0.011007 0.003173 0.028493 0.006507  0.002469 0.113698 0.085901 0.017596 0.017446  0.468168 0.028247 0.005765 0.001658 0.006388  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   116 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.000293 0.000079 0.002269 0.000415 0.002722  0.000213 0.963409 0.001378 0.000356 0.000928  0.000149 0.007797 0.001707 0.004786 0.002749  0.002532 0.001456 0.000931 0.000101 0.005730  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   117 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.023077 0.003097 0.022467 0.104724 0.002489  0.012849 0.004517 0.003839 0.013316 0.005599  0.002554 0.017763 0.007148 0.010064 0.008500  0.709224 0.037346 0.007205 0.000884 0.003336  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   118 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.100550 0.003103 0.008766 0.016859 0.003544  0.011316 0.008175 0.007661 0.059272 0.012766  0.004642 0.013582 0.008284 0.018985 0.582963  0.023000 0.098955 0.011608 0.001320 0.004649  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   119 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.010282 0.000997 0.005748 0.003872 0.000981  0.937602 0.001945 0.001079 0.004612 0.001930  0.000650 0.007586 0.002722 0.002505 0.003495  0.007488 0.002611 0.001848 0.000658 0.001388  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   120 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.107668 0.004826 0.013053 0.014502 0.003304  0.014859 0.005057 0.006220 0.017155 0.007739  0.003642 0.018113 0.009217 0.010751 0.087365  0.513064 0.146900 0.011461 0.001091 0.004011  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   121 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.572033 0.007569 0.005308 0.006301 0.002982  0.022950 0.002321 0.004502 0.005932 0.006749  0.003740 0.006511 0.007619 0.004539 0.004262  0.124451 0.194989 0.013598 0.000764 0.002879  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   122 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.004306 0.002209 0.000758 0.000564 0.008892  0.000880 0.000747 0.577491 0.001726 0.129839  0.009442 0.000851 0.001307 0.001040 0.001507  0.001412 0.005191 0.247137 0.001127 0.003574  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   123 0.614319 0.005715 0.176182  0.367965 0.990437 0.190034  0.026103 0.003552 0.633785  0.000874 0.000137 0.984112 0.002255 0.000401  0.001192 0.000443 0.000240 0.000933 0.000564  0.000154 0.003416 0.000428 0.000668 0.000698  0.001669 0.000892 0.000379 0.000049 0.000496  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   124 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.006925 0.002800 0.000668 0.001193 0.015250  0.001723 0.001290 0.125985 0.002252 0.690975  0.019687 0.001438 0.001963 0.001823 0.001906  0.002258 0.004366 0.112238 0.001445 0.003815  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   125 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.003330 0.000820 0.002025 0.001587 0.000764  0.001294 0.000594 0.001335 0.001572 0.001500  0.000644 0.002703 0.001065 0.001171 0.001455  0.010812 0.964087 0.002333 0.000149 0.000760  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   126 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.006718 0.002733 0.000591 0.001276 0.098588  0.001814 0.001436 0.035170 0.002235 0.783983  0.021754 0.001497 0.002063 0.002009 0.001945  0.002388 0.003529 0.022012 0.002147 0.006113  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   127 0.905157 0.159201 0.176182  0.068739 0.837247 0.190034  0.013408 0.095163 0.822547  0.104429 0.004339 0.004003 0.005046 0.054540  0.006291 0.014558 0.006818 0.005497 0.013571  0.004041 0.005868 0.002918 0.003629 0.004882  0.009465 0.006572 0.008946 0.010049 0.724537  0.077870 0.016686 0.057300 0.065423 0.039827  0.062150 0.024303 0.060453 0.064390 0.082073  0.024537 0.047282 0.040312 0.042049 0.048804  0.068026 0.059870 0.072011 0.011735 0.034898   128 0.464930 0.006235 0.038311  0.521662 0.898602 0.139142  0.026103 0.003552 0.633785  0.021403 0.003855 0.075578 0.022084 0.012847  0.011195 0.139006 0.020460 0.040724 0.094788  0.010620 0.014624 0.010357 0.021310 0.352634  0.019665 0.022112 0.087845 0.004092 0.014802  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   129 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.015054 0.002845 0.160340 0.022136 0.009279  0.008980 0.007903 0.016272 0.025550 0.538146  0.009795 0.013740 0.006853 0.016093 0.092669  0.014045 0.013560 0.016204 0.002400 0.008135  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   130 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.087705 0.001128 0.536197 0.156334 0.002553  0.013081 0.005568 0.003588 0.021090 0.005752  0.002196 0.016230 0.011166 0.020518 0.076509  0.018127 0.012210 0.005643 0.000957 0.003450  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   131 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.018191 0.004504 0.009131 0.009810 0.004794  0.008384 0.075390 0.009218 0.011306 0.081986  0.004611 0.014495 0.007239 0.008220 0.008919  0.128140 0.575002 0.013795 0.001439 0.005426  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   132 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.009319 0.000936 0.006461 0.003750 0.000908  0.869176 0.001901 0.001009 0.004439 0.001801  0.000604 0.077935 0.002595 0.002399 0.003287  0.007264 0.002585 0.001701 0.000609 0.001320  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   133 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.020143 0.001537 0.054613 0.624201 0.002795  0.010489 0.007273 0.003622 0.023673 0.008068  0.003776 0.082991 0.009095 0.094783 0.013141  0.015777 0.012308 0.006673 0.001275 0.003766  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   134 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.007958 0.003019 0.000849 0.001661 0.017527  0.002137 0.001638 0.111762 0.002801 0.706330  0.022603 0.001814 0.075400 0.002305 0.002379  0.002855 0.004570 0.026451 0.001643 0.004296  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   135 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.080515 0.570425  0.028041 0.079228 0.001605 0.003378 0.007018  0.003681 0.001394 0.054987 0.003066 0.108541  0.009213 0.002225 0.003746 0.001975 0.002444  0.005043 0.017604 0.662474 0.000952 0.003383  0.077895 0.016638 0.057319 0.065444 0.039840  0.062170 0.024311 0.060472 0.064411 0.082153  0.024544 0.047297 0.040272 0.041956 0.048766  0.067941 0.059889 0.072034 0.011739 0.034909   136 0.905157 0.005275 0.092743  0.068739 0.914210 0.336831  0.026103 0.003552 0.633785  0.017047 0.001613 0.221818 0.018568 0.002045  0.013035 0.004281 0.003482 0.012282 0.006232  0.001374 0.018996 0.494077 0.007443 0.007031  0.149751 0.011955 0.005625 0.000678 0.002668  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   137 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.001105 0.000228 0.000826 0.000868 0.001415  0.000274 0.000294 0.001806 0.000621 0.004926  0.981291 0.000594 0.000146 0.000851 0.000850  0.000664 0.000678 0.001641 0.000182 0.000739  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   138 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.009493 0.000921 0.005315 0.003590 0.000908  0.942240 0.001805 0.000998 0.004279 0.001785  0.000601 0.007032 0.002524 0.002322 0.003244  0.006931 0.002410 0.001706 0.000611 0.001286  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   139 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.143636 0.006316 0.008655 0.008350 0.002869  0.169422 0.003379 0.003863 0.008747 0.006099  0.003275 0.010708 0.008045 0.006172 0.006008  0.480991 0.108429 0.011023 0.000845 0.003168  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   140 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.023655 0.002331 0.175074 0.104901 0.003525  0.091838 0.010756 0.002964 0.031111 0.006409  0.002325 0.165961 0.014429 0.020366 0.272939  0.039319 0.019354 0.005060 0.001593 0.006089  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   141 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.007295 0.003607 0.003309 0.004332 0.631196  0.003994 0.091650 0.085691 0.005328 0.025681  0.006048 0.005557 0.002731 0.003595 0.004916  0.006782 0.006256 0.012249 0.008416 0.081367  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   142 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.000874 0.000137 0.984112 0.002255 0.000401  0.001192 0.000443 0.000240 0.000933 0.000564  0.000154 0.003416 0.000428 0.000668 0.000698  0.001669 0.000892 0.000379 0.000049 0.000496  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   143 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.019748 0.002908 0.106733 0.185959 0.411305  0.010835 0.009726 0.012903 0.018169 0.087765  0.007175 0.013515 0.009491 0.019020 0.012554  0.016688 0.015669 0.015653 0.003734 0.020447  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   144 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.006950 0.002761 0.000659 0.001538 0.105708  0.001861 0.001574 0.034410 0.002340 0.186504  0.608051 0.001555 0.002167 0.002331 0.002124  0.002585 0.003771 0.022160 0.002695 0.008257  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   145 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.010457 0.002072 0.583775 0.022325 0.001575  0.018736 0.082515 0.002140 0.012536 0.003537  0.001202 0.045498 0.007004 0.008065 0.005678  0.173936 0.011829 0.002962 0.000776 0.003382  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   146 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.096286 0.001775 0.053348 0.529679 0.002627  0.014177 0.005666 0.004779 0.029411 0.007558  0.002960 0.015928 0.080013 0.022779 0.013989  0.088259 0.017458 0.008901 0.000920 0.003487  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   147 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.009961 0.001751 0.003428 0.007929 0.002746  0.005269 0.006039 0.007023 0.043905 0.010782  0.003484 0.007473 0.004308 0.012939 0.763488  0.007763 0.008023 0.089388 0.000993 0.003308  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   148 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.080515 0.437143  0.150695 0.006449 0.006380 0.006122 0.002685  0.020398 0.002316 0.003785 0.005826 0.005915  0.003220 0.007181 0.006824 0.004347 0.004201  0.719747 0.029129 0.011369 0.000708 0.002702  0.077846 0.016639 0.057322 0.065447 0.039842  0.062174 0.024312 0.060476 0.064414 0.082157  0.024546 0.047299 0.040274 0.041958 0.048769  0.067944 0.059892 0.072038 0.011740 0.034911   149 0.905157 0.005275 0.121518  0.068739 0.914210 0.441339  0.026103 0.003552 0.633785  0.009407 0.001477 0.010197 0.007162 0.004031  0.006326 0.695902 0.004260 0.009850 0.005350  0.001775 0.013336 0.089631 0.007306 0.008787  0.016105 0.095932 0.005628 0.000797 0.006741  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   150 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.171286 0.003519 0.027466 0.019814 0.005164  0.017815 0.519571 0.004111 0.019881 0.009744  0.004452 0.099439 0.007157 0.018603 0.015561  0.024201 0.014543 0.007556 0.001964 0.008155  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   151 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.331386 0.006054 0.008142 0.010519 0.087778  0.086770 0.008781 0.013136 0.011508 0.019764  0.007079 0.009394 0.008360 0.008623 0.009495  0.026463 0.155971 0.019662 0.004337 0.166779  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   152 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.080515 0.437143  0.647808 0.005874 0.005576 0.008775 0.019488  0.016438 0.082032 0.005659 0.008002 0.011129  0.004693 0.006405 0.005573 0.008598 0.007042  0.021861 0.010739 0.011832 0.004153 0.108322  0.077846 0.016639 0.057322 0.065447 0.039842  0.062174 0.024312 0.060476 0.064414 0.082104  0.024546 0.047299 0.040274 0.041958 0.048769  0.067944 0.059945 0.072038 0.011740 0.034911   153 0.905157 0.005275 0.121518  0.068739 0.914210 0.441339  0.026103 0.003552 0.633785  0.024414 0.002151 0.028011 0.035324 0.003473  0.021908 0.010488 0.004991 0.178176 0.009720  0.003466 0.280947 0.076819 0.213302 0.036566  0.034082 0.020865 0.008171 0.001480 0.005648  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   154 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.018914 0.001945 0.007999 0.005118 0.001341  0.754363 0.002375 0.001765 0.005820 0.002773  0.001165 0.009736 0.003838 0.003454 0.004165  0.086607 0.082534 0.003632 0.000674 0.001784  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   155 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.004009 0.002051 0.000698 0.000503 0.008060  0.000798 0.000671 0.536760 0.001574 0.119106  0.008518 0.000769 0.001197 0.000935 0.001375  0.001285 0.004857 0.302521 0.001030 0.003283  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   156 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.115748 0.004286 0.027824 0.091179 0.003940  0.161306 0.009503 0.003232 0.026643 0.007081  0.002979 0.028680 0.080842 0.017290 0.016521  0.365952 0.021501 0.007895 0.001582 0.006015  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   157 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.094141 0.274904 0.108153 0.022939 0.003265  0.023451 0.008015 0.003890 0.019980 0.006834  0.002387 0.103641 0.239633 0.012619 0.011765  0.033435 0.017943 0.006549 0.001320 0.005136  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   158 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.080515 0.851583  0.238638 0.003756 0.027473 0.105169 0.004612  0.017483 0.007242 0.010138 0.028591 0.013014  0.004968 0.349420 0.010734 0.020132 0.016156  0.029000 0.021884 0.084390 0.001539 0.005661  0.077809 0.016631 0.057347 0.065522 0.039876  0.062144 0.024301 0.060447 0.064437 0.082065  0.024534 0.047277 0.040255 0.042045 0.048852  0.067965 0.059863 0.072003 0.011734 0.034894   159 0.905157 0.005275 0.032043  0.068739 0.914210 0.116375  0.026103 0.003552 0.633785  0.166043 0.002354 0.049029 0.549827 0.005034  0.012261 0.006901 0.004873 0.019517 0.009023  0.003898 0.012749 0.009089 0.021714 0.011174  0.017548 0.012494 0.008609 0.001649 0.076212  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   160 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.608106 0.005937 0.006208 0.013346 0.003142  0.018533 0.004926 0.003390 0.009715 0.008332  0.004579 0.005429 0.005734 0.243399 0.008255  0.024255 0.011185 0.010944 0.001166 0.003419  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   161 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.088564 0.002601 0.007649 0.024891 0.003519  0.007253 0.011167 0.004277 0.046486 0.013141  0.006271 0.011301 0.005121 0.470116 0.261479  0.011252 0.010620 0.007525 0.001891 0.004875  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   162 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.005776 0.001222 0.018788 0.007360 0.001433  0.008240 0.005821 0.001740 0.015792 0.003895  0.001490 0.795375 0.003311 0.007298 0.099498  0.010811 0.006661 0.002446 0.000616 0.002428  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   163 0.905157 0.005275 0.176182  0.068739 0.991173 0.190034  0.026103 0.003552 0.633785  0.000855 0.000113 0.000918 0.000981 0.000480  0.000415 0.000604 0.000378 0.003721 0.000974  0.000306 0.000936 0.000314 0.001206 0.985063  0.000830 0.000745 0.000535 0.000087 0.000537  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   164 0.905157 0.082238 0.176182  0.068739 0.914210 0.190034  0.017716 0.003848 0.633785  0.095476 0.002292 0.016087 0.118417 0.004420  0.008651 0.010396 0.008266 0.055564 0.087840  0.006992 0.014496 0.009146 0.107359 0.394499  0.018891 0.019684 0.013939 0.001868 0.005717  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   165 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.015842 0.157902 0.006531 0.019018 0.009820  0.008032 0.167313 0.012577 0.039398 0.181147  0.009878 0.011616 0.006005 0.028151 0.269864  0.012196 0.013614 0.015579 0.003450 0.012067  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   166 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.003856 0.001465 0.000785 0.001039 0.009453  0.001032 0.000832 0.019222 0.001472 0.925091  0.011594 0.001083 0.001080 0.001329 0.001423  0.001490 0.002113 0.012372 0.000884 0.002382  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   167 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.009712 0.001650 0.008999 0.009908 0.002324  0.008030 0.008140 0.004055 0.051195 0.008809  0.003110 0.185150 0.005383 0.015011 0.648974  0.011007 0.009010 0.005028 0.000992 0.003515  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   168 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.187047 0.004518 0.016981 0.023924 0.003418  0.018541 0.006233 0.006058 0.171812 0.008696  0.003858 0.019836 0.010905 0.015786 0.016019  0.342981 0.125822 0.011979 0.001170 0.004415  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   169 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.112767 0.008779 0.001998 0.004269 0.006745  0.004669 0.001628 0.593581 0.003687 0.032999  0.009288 0.002707 0.004592 0.002285 0.002890  0.006420 0.021734 0.174363 0.000983 0.003616  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   170 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.001502 0.000325 0.000958 0.001083 0.001913  0.000394 0.000406 0.002581 0.000811 0.006927  0.974693 0.000730 0.000214 0.001113 0.001059  0.000859 0.000901 0.002316 0.000257 0.000955  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   171 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.026078 0.001457 0.050826 0.572387 0.002795  0.010349 0.007086 0.005648 0.037490 0.010137  0.004353 0.015192 0.011050 0.101186 0.018609  0.020672 0.089302 0.010556 0.001132 0.003693  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   172 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.112712 0.004071 0.034994 0.022274 0.003665  0.105902 0.009862 0.003141 0.025503 0.006555  0.002697 0.251552 0.013592 0.015942 0.015712  0.331850 0.025517 0.006932 0.001554 0.005974  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   173 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.188420 0.089046 0.005228 0.005881 0.003065  0.191762 0.002422 0.003321 0.005494 0.006514  0.003724 0.005205 0.008026 0.004227 0.003861  0.441322 0.015651 0.013040 0.000787 0.003006  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   174 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.010282 0.000997 0.005748 0.003872 0.000981  0.937602 0.001945 0.001079 0.004612 0.001930  0.000650 0.007586 0.002722 0.002505 0.003495  0.007488 0.002611 0.001848 0.000658 0.001388  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   175 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.005056 0.002015 0.000211 0.000624 0.778605  0.000893 0.000701 0.017791 0.000449 0.122328  0.008933 0.000369 0.002191 0.000885 0.000982  0.002385 0.002633 0.012908 0.008879 0.031163  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   176 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.035967 0.001314 0.024291 0.260402 0.003755  0.008183 0.007109 0.011743 0.129522 0.079011  0.006616 0.015944 0.013503 0.164070 0.031518  0.026862 0.092214 0.082263 0.001130 0.004582  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   177 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.415055 0.007751 0.007503 0.009653 0.003848  0.106557 0.003644 0.004828 0.010108 0.008509  0.004238 0.007680 0.009015 0.006858 0.085623  0.194581 0.016384 0.093027 0.001074 0.004066  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   178 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.006576 0.004043 0.003460 0.004230 0.058483  0.004309 0.098519 0.085724 0.005146 0.013141  0.003762 0.005988 0.002465 0.002863 0.004628  0.007195 0.005544 0.007528 0.010901 0.665493  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   179 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.029690 0.002607 0.033182 0.107936 0.004272  0.025636 0.011202 0.005641 0.046522 0.010344  0.003789 0.032121 0.086030 0.026301 0.159343  0.368713 0.028669 0.009612 0.001742 0.006649  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   180 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.018622 0.004817 0.008778 0.012631 0.182704  0.150008 0.014118 0.022956 0.014613 0.249753  0.011533 0.010869 0.008226 0.011132 0.013108  0.086787 0.018761 0.025091 0.008263 0.127230  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   181 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.002115 0.000156 0.006435 0.974153 0.000624  0.001037 0.000634 0.000435 0.001991 0.001078  0.000409 0.001677 0.000841 0.002387 0.001460  0.001677 0.001284 0.000777 0.000131 0.000700  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   182 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.001995 0.000371 0.000822 0.001194 0.014044  0.001903 0.001330 0.001950 0.001012 0.006560  0.001316 0.000790 0.000805 0.000572 0.002907  0.001847 0.001634 0.001938 0.944136 0.012874  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   183 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.001995 0.000371 0.000822 0.001194 0.014044  0.001903 0.001330 0.001950 0.001012 0.006560  0.001316 0.000790 0.000805 0.000572 0.002907  0.001847 0.001634 0.001938 0.944136 0.012874  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   184 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.000293 0.000079 0.002269 0.000415 0.002722  0.000213 0.963409 0.001378 0.000356 0.000928  0.000149 0.007797 0.001707 0.004786 0.002749  0.002532 0.001456 0.000931 0.000101 0.005730  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   185 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.005844 0.003643 0.002556 0.003152 0.315661  0.003464 0.013549 0.007707 0.003730 0.016316  0.004327 0.004489 0.002188 0.001939 0.003414  0.005907 0.004414 0.007564 0.011091 0.579045  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   186 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.034727 0.001525 0.090586 0.134234 0.003677  0.011664 0.007614 0.010304 0.186516 0.015567  0.005843 0.019298 0.014023 0.037934 0.029280  0.092960 0.093539 0.204764 0.001177 0.004768  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   187 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.016103 0.003730 0.006491 0.013377 0.013878  0.088086 0.007458 0.025663 0.014358 0.622326  0.017203 0.007887 0.004668 0.093535 0.013523  0.009893 0.010326 0.021095 0.002649 0.007749  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   188 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.099989 0.003982 0.014132 0.021227 0.009233  0.084130 0.009698 0.151768 0.037126 0.023472  0.007727 0.015777 0.188618 0.017533 0.233118  0.025331 0.021428 0.022186 0.002899 0.010624  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   189 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.016412 0.001792 0.606357 0.056799 0.002144  0.098045 0.006445 0.002780 0.016502 0.004670  0.001705 0.034887 0.009562 0.090934 0.007851  0.022572 0.011894 0.004080 0.000948 0.003619  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   190 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.087228 0.437143  0.168578 0.001589 0.053002 0.510057 0.002844  0.010693 0.007233 0.005051 0.033460 0.009694  0.004306 0.014472 0.010624 0.101598 0.016953  0.018859 0.016417 0.009629 0.001198 0.003742  0.077899 0.016639 0.057322 0.065447 0.039842  0.062174 0.024312 0.060476 0.064414 0.082104  0.024546 0.047299 0.040274 0.041958 0.048769  0.067944 0.059892 0.072038 0.011740 0.034911   191 0.935632 0.005715 0.121518  0.046652 0.907057 0.441339  0.017716 0.003848 0.633785  0.021443 0.001462 0.007699 0.009846 0.002428  0.073693 0.002940 0.004625 0.010711 0.072243  0.001516 0.004791 0.673550 0.005481 0.007101  0.080208 0.009677 0.007639 0.000610 0.002336  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   192 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.006408 0.003914 0.003081 0.003877 0.064081  0.004050 0.015381 0.007138 0.004592 0.014342  0.003976 0.005285 0.002329 0.002479 0.004161  0.006706 0.005154 0.086902 0.095396 0.660750  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   193 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.083308 0.001267 0.072130 0.010780 0.002203  0.008959 0.002733 0.004355 0.010342 0.008020  0.001318 0.004465 0.744000 0.005326 0.006716  0.015351 0.008922 0.007203 0.000537 0.002065  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   194 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.025120 0.003556 0.235762 0.030615 0.009272  0.025521 0.013217 0.011828 0.032439 0.086176  0.006664 0.235403 0.014452 0.021656 0.089824  0.037496 0.023652 0.014843 0.070203 0.012303  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   195 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.023859 0.004305 0.015816 0.021379 0.006134  0.013667 0.007150 0.010936 0.022800 0.086072  0.005641 0.019934 0.083976 0.086488 0.015022  0.269572 0.282152 0.015882 0.001972 0.007242  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   196 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.092429 0.004735 0.003871 0.005333 0.053451  0.005530 0.012857 0.092872 0.006179 0.022667  0.006181 0.005704 0.003656 0.003834 0.005463  0.009037 0.009532 0.020987 0.009035 0.626648  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   197 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.017456 0.004240 0.093456 0.018720 0.459104  0.012465 0.013151 0.017932 0.016786 0.103031  0.009292 0.091468 0.008582 0.013027 0.013432  0.019908 0.018493 0.020220 0.006208 0.043030  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   198 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.020764 0.001468 0.364091 0.153714 0.002606  0.016438 0.006573 0.003360 0.021049 0.005646  0.002142 0.170120 0.011477 0.165025 0.010183  0.022049 0.013136 0.005241 0.001054 0.003867  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   199 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.010827 0.003291 0.002862 0.005316 0.628523  0.003758 0.005930 0.022028 0.008085 0.037936  0.009333 0.004062 0.003874 0.005742 0.086533  0.006891 0.008475 0.100587 0.007736 0.038212  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   200 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.163180 0.002342 0.009661 0.011589 0.002758  0.013310 0.069362 0.004573 0.012422 0.008393  0.001945 0.007398 0.567223 0.006836 0.008167  0.086950 0.011829 0.008371 0.000760 0.002932  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912   201 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.017716 0.003848 0.633785  0.034608 0.085866 0.002036 0.004276 0.006466  0.004485 0.001679 0.132374 0.003720 0.030750  0.008904 0.002740 0.081800 0.002310 0.002948  0.006226 0.021841 0.562264 0.000998 0.003710  0.077850 0.016640 0.057325 0.065451 0.039844  0.062177 0.024314 0.060479 0.064418 0.082109  0.024547 0.047302 0.040276 0.041960 0.048771  0.067948 0.059895 0.072042 0.011740 0.034912    -1 0.935632 0.005715 0.176182  0.046652 0.990437 0.190034  0.025058 0.171589 0.795252  0.028946 0.003656 0.156908 0.036509 0.074365  0.023308 0.013079 0.014982 0.229125 0.023295  0.071685 0.028961 0.015362 0.024253 0.025545  0.165580 0.028328 0.019131 0.003535 0.013447  0.077862 0.016631 0.057294 0.065416 0.039823  0.062197 0.024354 0.060553 0.064437 0.082065  0.024534 0.047277 0.040308 0.041991 0.048745  0.067965 0.059917 0.072003 0.011734 0.034894  End 0.000000 0.000000 0.000000  0.974942 0.828411 0.204748  0.000000 0.000000 0.000000  0.000000 0.000000 0.000000 0.000000 0.000000  0.000000 0.000000 0.000000 0.000000 0.000000  0.000000 0.000000 0.000000 0.000000 0.000000  0.000000 0.000000 0.000000 0.000000 0.000000  0.000000 0.000000 0.000000 0.000000 0.000000  0.000000 0.000000 0.000000 0.000000 0.000000  0.000000 0.000000 0.000000 0.000000 0.000000  0.000000 0.000000 0.000000 0.000000 0.000000   ENDMODEL
GX005-26-4028723	"HMMERFETCH*     [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]      Table of Contents      FUNCTION   DESCRIPTION   EXAMPLE   OUTPUT   INPUT FILES   RELATED PROGRAMS   RESTRICTIONS   COMMAND-LINE SUMMARY   ACKNOWLEDGEMENT   LOCAL DATA FILES   PARAMETER REFERENCE                       FUNCTION    [   Top  |  Next  ]          HmmerFetch retrieves a profile hidden  Markov model (HMM) from a  database of profile HMMs that  has been indexed by HmmerIndex.        DESCRIPTION    [  Previous  |  Top  |  Next  ]          HmmerFetch provides a GCG interface  to the hmmfetch program of  Dr. Sean Eddy's HMMER package.  It allows you to access  most of hmmfetch's parameters from  the GCG command line.   The database  must have been previously indexed  with HmmerIndex.    Two profile HMM databases for  protein families are available with  the Wisconsin Package: Pfam and  PfamFrag.  Indexes for these  have already been created, so  they can be used with  HmmerFetch without  any further processing.        EXAMPLE    [  Previous  |  Top  |  Next  ]          Here is a session using  HmmerFetch to retrieve from the  Pfam database a profile HMM  representing a  heat shock protein family:        %  hmmerfetch    HMMERFETCH which profile HMM ?   HSP70    from which HMM database (* Pfam.hmmdb *) ?   What output name (* HSP70.hmm_g *)?   Creating temp file for input to hmmfetch .   Calling hmmfetch to perform analysis ...  %            OUTPUT    [  Previous  |  Top  |  Next  ]          Here is some of the  output file:      HMMER2.0 NAME  HSP70 ACC   PF00012 DESC  Hsp70 protein LENG  621 ALPH  Amino RF    no CS    no MAP   yes COM   hmmbuild -F HMM.ann SEED.ann COM   hmmcalibrate --seed 0 HMM.ann NSEQ  34 DATE  Tue May  4 18:13:41 1999 CKSUM 8575 GA    -80.0 -80.0 TC    -72.0 -72.0 NC    -83.0 -83.0 XT      -8455     -4  -1000  -1000  -8455     -4  -8455     -4 NULT      -4  -8455 NULE     595  -1558     85    338   -294    453  -1158  ...  -1998   -644 EVD   -531.700623   0.081970 HMM        A      C      D      E      F      G      H  ...      W      Y          m->m   m->i   m->d   i->m   i->i   d->m   d->d    b->m   m->e          -126      *  -3585      1   1571  -1709  -4201  -3697  -1975  -3272  -2660 ...  -2595  -2243     1      -   -149   -500    233     43   -381    399    106 ...  -294   -249      -     -6  -8606  -9649   -894  -1115   -701  -1378   -126      *      2   -645  -2273  -5213  -4741    224  -4752  -4004 ...  -3631  -3277     2      -   -149   -500    233     43   -381    399    106 ...  -294   -249      -     -6  -8606  -9649   -894  -1115   -701  -1378      *      *  ///////////////////////////////////////////////////////////////////////////////     619    406  -1186  -3444   -148  -1142  -2846  -1705 ...  -1640   1325   686      -   -149   -500    233     43   -381    399    106 ...  -294   -249      -     -6  -8562  -9604   -894  -1115   -701  -1378      *      *    620  -1249  -1701  -1826  -1260  -1730   -806    231 ...  -2069   3639   687      -   -149   -500    233     43   -381    399    106 ...  -294   -249      -     -6  -8562  -9604   -894  -1115   -701  -1378      *      *    621   1064  -2653     83   1302  -2973   -439   -803 ...  -2836  -2150   688      -      *      *      *      *      *      *      * ...      *      *      -      *      *      *      *      *      *      *      *      0 //            INPUT FILES    [  Previous  |  Top  |  Next  ]          HmmerFetch has two required inputs:  an  indexed database of profile HMMs  and the name of a  profile  HMM that is present in  that database.  Profile HMM  databases supplied with the Wisconsin  Package  are Pfam and PfamFrag.   They each contain profile HMMs  for a large number of  protein families.  The  profile HMMs in these databases  were made from the same  sequence alignments, but with different  parameters:  the profile HMMs in Pfam  are built to perform global  alignments with respect to the  model, while the profile HMMs  in PfamFrag are designed to  perform local alignments with respect  to  the model.        RELATED PROGRAMS    [  Previous  |  Top  |  Next  ]           PileUp  creates a multiple sequence  alignment from a group of  related sequences.   LineUp  is  a multiple  sequence editor used to create  multiple sequence alignments.   Pretty   displays multiple sequence  alignments.     ProfileMake  makes a profile from  a multiple sequence alignment.    ProfileSearch  uses the profile to  search a database for sequences  with similarity to the group  of aligned sequences.   ProfileSegments   displays optimal alignments between each  sequence in the  ProfileSearch  output  list and the group of  aligned sequences (represented by the  profile consensus).   ProfileGap  makes  optimal alignments  between one or more sequences  and a group of aligned  sequences represented as a profile.    ProfileScan   finds structural and sequence motifs  in protein sequences, using predetermined  parameters to  determine significance.    HmmerBuild makes a profile hidden  Markov model from a multiple  sequence alignment.  HmmerAlign  aligns one or more sequences  to a profile HMM.   HmmerPfam searches a database of  profile HMMs  with a sequence query in  order to identify known domains  within the sequence.  HmmerSearch  uses a  profile HMM as a query  to search a sequence database  for sequences similar to the  original aligned  sequences.  HmmerCalibrate calibrates a  hidden Markov model so that  database searches using it as  a  query will be more sensitive.   HmmerIndex creates a binary  GSI (""generic sequence index"") for  a  database of profile HMMs.   HmmerFetch retrieves a profile hidden  Markov model by name from  an  indexed database of profile HMMs.   HmmerEmit randomly generates sequences  that match a profile  HMM.  HmmerConvert converts between  different profile HMM file formats  and from profile HMM to  GCG profile file format.     MEME  finds conserved motifs in  a group of unaligned sequences  and saves these motifs as  a set of  profiles.  You can search  a database of sequences with  these profiles using the  MotifSearch   program.        RESTRICTIONS    [  Previous  |  Top  |  Next  ]          A profile HMM database must  be indexed with HmmerIndex before  it can be used with  HmmerFetch.  The index must be stored  in the same directory as  the database.    HmmerFetch differs from  Fetch  in  that it is case sensitive.   If a model is  named OmpA, you must type  its name as  OmpA .   HmmerFetch will not be able  to find it if you  type  ompa ,  ompA ,  Ompa , etc.    HmmerFetch can only retrieve a  single profile HMM model at  a time.  It does  not accept a wildcard  specification or a list of  models to be fetched.           COMMAND-LINE SUMMARY    [  Previous  |  Top  |  Next  ]          All parameters for this program  may be added to the  command line.  Use  -CHE ck   to view the summary  below and to specify parameters  before the program executes.   In the summary below, the  capitalized  letters in the parameter names  are the letters that you   must  type in order to  use the parameter.  Square brackets ([ and ])  enclose parameter values that are  optional.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.      Minimal Syntax: % hmmerfetch [-INfile1=]HSP70 [-INfile2=]Pfam.hmmdb -Default    Prompted Parameters:    [-OUTfile=]HSP70.hmm_g     sets primary output filename    Local Data Files:  None    Optional Parameters:    -NOMONitor               suppresses the screen monitor               ACKNOWLEDGEMENT    [  Previous  |  Top  |  Next  ]          The programs comprising the HMMER  package are designed and implemented  by Dr. Sean Eddy of the  Washington University School of Medicine,  St. Louis, Missouri.  The GCG  front-end programs were  written by Christiane van Schlun  in collaboration with Dr. Eddy.    Pfam - A database of  protein domain family alignments and  HMMs Copyright (C) 1996-2000 The  Pfam  Consortium.           LOCAL DATA FILES    [  Previous  |  Top  |  Next  ]          None.        PARAMETER REFERENCE    [  Previous  |  Top  |  Next  ]          You can set the parameters  listed below from the command  line.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.             -NOMON itor          suppresses the display of the  program's progress on the screen.                 Printed: February 5, 2001  11:36 (1162)           [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]       Documentation Comments:  doc-comments@gcg.com  Technical Support:  help@gcg.com      Copyright (c) 1982-2001  Genetics Computer Group  Inc.  A subsidiary of Pharmacopeia, Inc.  All rights reserved.    Licenses and Trademarks Wisconsin Package is a trademark of  Genetics Computer Group , Inc.  GCG and the GCG logo are registered trademarks of  Genetics Computer Group , Inc.    All other product names mentioned in this documentation may be trademarks, and if so, are trademarks or registered trademarks of their respective holders and are used in this documentation for identification purposes only.       www.gcg.com"
GX263-58-7822617	"Electronic Document Management Systems for the Arizona Courts  APPENDIX 1 GLOSSARY OF TECHNICAL TERMS AND ACRONYMS  On-Target Information Technology Consulting  6/13/00   Electronic Document Management Systems for the Arizona Courts  Glossary of Technical Terms and Acronyms  Word/Acronym AC AP Active-X AIIM AJIN ANSI AOC API Archiving AVI Bandwidth C Cache Caching Capture CAT 5 or CAT 6 Wiring CD or CD-ROM Client Client-side architecture CMS COLD COM Concurrent Users CPS DBMS Driver DVD E-commerce EDMS  Definition Arizona Court Automation Project. A case management system used by most Arizona trial courts. Formerly called FACTS. Microsoft's object-oriented programming technologies and tools. Association for Information and Image Management. EDMS standardssetting organization. Arizona Judicial Information Network. The Judicial Department's wide area network. American National Standards Institute. Standards setting organization Administrative Office of the Courts. The administrative arm of the Arizona Supreme Court. The specific methodology a programmer uses, when writing a program, to make requests of the operating system or another application. The process of storing documents or data off-line. Microsoft-specified audio video file format for W indows that uses plug-ins to play. The capacity of a telecommunication line. A high-level programming language used particularly in the Unix environment. Magnetic storage media. Storing data temporarily in memory. In an EDMS, the process of scanning a paper document. High capacity copper wiring used in local area networks. A high-capacity disk storage medium. The requesting program in a client/server system. Usually, the user's workstation is a client. The technical components employed at the desktop. Case Management System. Programs that assist a court to manage cases and perform case-related financial functions. Computer Output to Laser Disk. The process of capturing print streams to disk. Sometimes called ERM or Enterprise Report Management. Computer Output Microfilm. A technology that copies data from a computer in a format that can be written to microfilm. Users who are sharing the same software package at the same time. Child Protective Services. State agency charged with child welfare. Database Management System. Software that organizes and manages structure data. A piece of software that interfaces a software package to a piece of equipment such as a printer or scanner. Digital Video Disk. A popular disk format for video files. Various types are readable and/or writeable. Conducting business processes between customer and supplier using electronic communications. Electronic Document Management System. A set of integrated document  On-Target Information Technology Consulting  6/13/00   Electronic Document Management Systems for the Arizona Courts  E-Filing Engine Ethernet/Fast Ethernet Extranet Fail-over Firewall Full-text retrieval Gateway GB Granular Heavy client HSM Image-enabling Index Informix Internet Explorer Intranet ISO JPEG Jukebox LAN LDAP LOB MAPI Metadata MicroSoft NT MPEG MTS  management software modules including imaging, document management, workflow and COLD. The process of officially submitting electronic documents to the court for inclusion in the case file. A software component that ""drives"" a particular function. Common, non-proprietary communications protocol used in LANs A private network that provides access for selected external users such as commercial business partners. The process of transferring users from a failed component, such as a server, to a functioning component to continue uninterrupted computing. A piece of network equipment that authenticates users and prevents unauthorized access to a network. The process of finding a word or phrase in a text document that has been indexed for searching. A point in a network that acts as an entrance to another network, such as an email gateway that connects to the Internet and receives incoming email and sends outgoing email. Gigabyte. 1,024,000 bytes of digital information. A characteristic that permits low-level manipulation, such as granular security that allows fine tuned security restrictions. Programs that run on a user's desktop to perform the logical processes required by a computer application. The client (user software) is ""heavy"" because it is a larger program than a ""thin"" client. Hierarchical Storage Management. Automated techniques used to move data from one storage platform to another based on certain parameters, such as how often a document is accessed. The linking of documents to a data application so that the documents may be retrieved and displayed. The data elements describing the document. Used as a s ynonym for metadata. The DBMS used by the ACAP courts. A Microsoft desktop program included in W indows A private network that provides connectivity among an organization's internal users. International Standards Organization. A file format used for pictures. A high-capacity digital storage device housing many optical disks and drives that uses robotic mechanisms to mount disks in the drives for document retrieval. Local Area Network. A communications system that enables an organizations computers to communicate within a building or campus. Lightwieght Directory Access Protocol. A directory service used to locate users and resources on a network. Line of Business Application. A data application used in an organizations daily business, such as a case management system. An interface developed by Microsoft that provides messaging functions including addressing, sending, receiving and storing message. Data describing the context of the document. A popular network operating system. Motion Picture Experts Group. A file format used for streaming video. MicroSoft Transaction Server. A component of Microsoft's NT technologies.  On-Target Information Technology Consulting  6/13/00   Electronic Document Management Systems for the Arizona Courts  MVS Netscape Navigator Network administrator Network Backbone NOS O/S Object-oriented OCR ODBC PDF Plug-in Port Print stream Public/Private Key Encryption Queue RAID 5 Rendition Repository Roll back Router SA Search Engine Server-side architecture SLU SMTP SNMP SQL SQL Server Storage Media  IBM operating system An Internet browser by Netscape. The person who manages the W AN and/or LAN. The main cabling plant in a LAN or the main communication circuits in a W AN. Network Operating System. Programs that control the operations of a network. Operating system. A program that controls the computer hardware. A technology designed to work with objects. Optical Character Recognition. The process of converting printed documents into searchable text files. Open Database Connectivity. A standard method of interfacing an application to a DBMS. Adobe Acrobat's proprietary Portable Document Format. A file format used to exchange documents. Popular due to the free viewer. A software component that loads and installs automatically for the purpose of viewing a specific type of file. The communication connection on a piece of equipment. The data that is sent to a printer. The process of preventing unauthorized access to data or documents using two long numbers -- the public and private keys. The public key is publiushed while the private key is kept secret by its owner. The combination of the two keys authenticates the owner. Logical ""holding area"" for a digital item such as a document in a workflow queue. Redundant Array of inexpensive Disks. One of several levels of RAID which provides redundant data storage and allows corrupted files to be rebuilt without downtime. To convert a document from one file format to another, such as from PDF to TIFF. A store of electronic documents managed by an EDMS. The process of returning to an earlier state where all transactions are known to have been completed correctly. Used when a malfunction occurs to cause data corruption. W AN interface equipment. Systems administrator. The person who manages the technical environment and components. A software package or component that locates documents/web pages or other items based on matching user-supplied search criteria with document index values. The technical components used by the server. Single Licensed User. A FileNET term for a user license. Simple Mail Transport Protocol. The standard protocol used for I Internet email messages. Simple Network Management Protocol. The protocol governing network management and the monitoring of network devices and their functions. Standard Query Language. Microsoft's DBMS. Any of several types of physical components on which data are stored. See also W ORM, Cache, CD, DVD and RAID 5  On-Target Information Technology Consulting  6/13/00   Electronic Document Management Systems for the Arizona Courts  Switch Systems administration T1 TB  A piece of network equipment that connects a user to the network backbone and shared resource such as servers, modems and printers. The processes used to configure and manage computer systems. A communication line used in a wide area network. Terabyte. 1,024,000,000 bytes of digital information. The Transmission Control Protocol and the Internet Protocol, which together provide reliable end-to-end connections between applications over interconnected networks of different types, including the Internet. A client that has little or no installed software but has access to software that is managed and delivered by network servers that are attached to it. An action that causes another action to occur, such as when a DBMS passes information to another program that causes the second program to take an action. A document scanning standard developed by an industry consortium led by Hewlett Packard, IBM Caere and others. A popular operating system. Uniform Resource Locator. An address in a standard format that locates files (resources) on the Internet and the W eb. Uniform Resource Locator. An address in a standard format that locates files (resources) on the Internet. A piece of software that allows a user to access and view documents. An operating system W ide Area Network. A communication system that enables an organization's computers to communication over long distances between remote sites. Standard W indows file format used for digital sound files. A client program that initiates requests to a W eb server and displays the information that the server returns. Any document that can be accessed through a URL on the W eb r that is connected to the Internet and is dedicated to serving W eb pages. A W eb server that is managed by a single entity (an organization or an individual) and contains information in hypertext for its users, often including hypertext links to other W eb sites. Each W eb site has a home page. The process of enabling EDMS activities to be accessed and executed across a network, including intranets, extranets and the Internet. W rite Once Read Many. A type of storage media that cannot be overwritten but can be read many times. eXtensible Markup Language. A standard language that defines the structure of a set of electronic documents.  TCP/IP Thin client Trigger Twain Unix URL URL Viewer VMS WAN WAV Web browser Web page Web server  Web site Web support WORM XML  On-Target Information Technology Consulting  6/13/00   Electronic Document Management Systems for the Arizona Courts  APPENDIX 2 LIST OF INTERVIEWEES  On-Target Information Technology Consulting  6/13/00   Electronic Document Management Systems for the Arizona Courts  List of Interviews  1.  Arizona Supreme Court, The Administrative Office of the Courts  Maureen Haggerty, Mark Jensen, Ted Wilson, Carol Merfeld, Mohyeddin Abdulaziz, Will Tagart and On-Target team, 12/6/99. Meeting at AOC to review scope of project, goals and deliverables; progress reports; schedule and other administrative matters. Foster Care Review Board, 12/7/99 Bill Stanton, Program Manager, Al Vasek, Administrative Services and Bruce Johnson, Technology Coordinator. Reviewed scope and goals of project, received information and documentation on FCRB program and technical matters. Sat in on a board hearing to observe the Board's process and workflow. Michael Mucha, ITSD, 1/19/00. Telephone interview concerning the history and future of the JOLTS system from a technology perspective. Bobbie Chinsky, JJSD, 1/24/00. Telephone interview concerning the history and future of the JOLTS system from a business requirements perspective. Rod Franklin, Network Architect, ITD. Discussed the court system's existing statewide network and received information on network configuration. Stephanie Jauregui-Hidalgo, ACAP Training Coordinator, ITD. Discussed training methods and ACAP operations. Tim Lawler, ACAP Manager, ITD. Discussed ACAP project and future of system. Ted Wilson, Records Management. Developed the online electronic records retention scheule. Mark McDermott, Statistics Manager. Statewide statistical information. Debbie Olson, Adult Services. Discussed length of probation statistics available from Maricopa County 1996 audit. 2.  Appellate Court Court of Appeals Division II  Mohyeddin Abdulaziz, IT Director, 1/10/00. Discussed the history of automation of the COA, current automation, electronic filing, enhancements to the court's systems and the imaging system now in operation. Reviewed the IT platforms and software infrastructure. Judges Druke, Pelander, Espinosa and Howard; Staff Attorneys Jeff Handler and Marsha Lindler, 1/10/00. Discussed statewide policies on automation and electronic  On-Target Information Technology Consulting  A2-1  6/13/00   Electronic Document Management Systems for the Arizona Courts  filing and possible scenarios for implementation of e-filing and EDMS systems throughout the state. Discussed features and functions of an EDMS that would be useful to judges and staff attorneys in an appellate court. Itza French, Deputy Clerk, 1/10/00. Received a demonstration of the Altris EB imaging system, scanning and indexing documents. Discussed performance of the software, plusses and deficiencies, requirements for imaging and retrieval. Joyce A. Goldsmith, Clerk of the Court, 1/10/00. Discussed her goals for electronic court records, integration of various systems, e-filing, roll-out of the ALTRIS EB system to judges and chambers, and other technology issues. 3.  Superior Courts  Court Administration (incl. Juvenile Court) and Superior Court Clerk Maricopa County - Clerk of the Superior Court  Mark Jensen, Electronic Document Management Coordinator, Carol Schreiber, Associate Clerk, Customer Services, Will Tagart, Director, Information Technology Group, Grace Colosimo, Associate Clerk, Administrative Services, 12/6/99. Reviewed scope and goals of project, obtained information on the Clerk's Office imaging system, their goals for EDMS, and arranged meetings for next several . Mark Jensen, Electronic Document Management Coordinator, Lauri Thomas, Document Management Administrator, and Will Tagart Director, Information Technology Group, 12/8/99. Interviewed the supervisor and staff at the Probate Registrar's office, observed probate imaging system, procedures and workflow. Interviewed Probate file room supervisor Ed Morris and observed the use of imaging, file tracking and CARS systems. Toured computer room; received detailed information on the court's technology infrastructure and the Technology Group's responsibilities; discussed future IT plans. Mark Jensen, Electronic Document Management Coordinator, David Goodwin, Court Services Administrator, and Sue Fremouw, criminal courtroom clerk supervisor, 12/8/99. Reviewed criminal courtroom process and received information on MEEDS, electronic courtroom minutes. Also met with Barbara Smith, criminal incoming document supervisor and reviewed this unit's procedures and the flow of documents. Lauri Thomas, Document Management Administrator, Mark Jensen, Electronic Document Management Coordinator, and Anje Anderson, Family Services Administrator, 12/9/99. Clerk Cindy Wilborn showed us workflow and automation procedures including an MS Access tracking module. Clerk Gloria Weiss reviewed ATLAS the state child support system and Susan Score of Support Services reviewed temporary orders. Lauri Thomas took us through the distribution center and explained procedures for distributing and mailing copies of court minutes and documents. Mark Jensen, Electronic Document Management Coordinator, and Lauri Thomas, Document Management Administrator, Maureen Ramroth, Director of Customer Relations, and Ed Morris, Supervisor of File Pulling in the lower level file room,  On-Target Information Technology Consulting  A2-2  6/13/00   Electronic Document Management Systems for the Arizona Courts  12/9/99. Observed file and document flow, received a demonstration of the file tracking automated system, and observed microfilm and customer service procedures. Mark Jensen and Lauri Thomas also took us to the Exhibits Department where we interviewed Joan Bolt, supervisor of exhibits, and she reviewed the flow and procedures for sealed files, exhibits, transcripts, etc. Kim Johnson, Court Clerk Training Supervisor, 12/10/99 Recieved a demonstration of the MEEDS system (electronic court minutes) and discussed the distribution of minutes. Linda Hardaway, Court Operations Supervisor over appeals, dispositions and motor vehicle abstracts, 12/10/99. Clerk Arlene Pacheco demonstrated the disposition reporting system and Al Thomas and Michael Dick of Maricopa County IS discussed the technical aspects. Observed the workflow for appeals and it's Access Tracking System. Rose Crowley of the PSI desk discussed the process and document flow for post sentencing documents. In the Criminal section we met with the clerk handling the files and documents for the Early Disposition Court. Reviewed the process and document flow. Maureen Ramroth, Director of Customer Relations, 1/20/00. Interviewed her regarding marriage license processing, the marriage license application and workflow for the Clerk's Office and records management center.  Maricopa County IT  Cary Parker, Network Architect. Interview concerned the county-wide data network.  Maricopa County - Superior Court Administration  Marcus Reinkensmeyer, Chief Deputy Court Administrator, 12/6/99. Reviewed project and set up appointments with judicial officers and superior court staff for the coming week. Discussed Pretrial Services organization and functions. Judge Mark J. Armstrong, Family Court, 12/7/99. Discussed the manner in which a judge might use electronic case files, the benefits and drawbacks of using electronic documents and requirements for judges. Probate Commissioner Gary Donahoe, Maricopa Superior Court 12/9/99. Interviewed the only judicial officer currently using the probate imaging system. Received his opinions and thoughts for the future of the imaging system, problems using the system and strong points. Ken Crenshaw, Judicial Services Administrator 12/9/99. He is responsible for probate, mental health and civil administrative divisions. W e discussed probate calendaring and case review procedures and current imaging system. Mike Goss, Deputy Chief, Administrative Services, Adult Probation Office, 12/10/99. Discussed the new APETS system, how probation officers would use electronic documents, feasibility and limitations of electronic systems.  On-Target Information Technology Consulting  A2-3  6/13/00   Electronic Document Management Systems for the Arizona Courts  John Barrett, Judicial Information Services Director and Director of Research and Planning for the Juvenile Court 12/17/99 Demonstration of the Maricopa JOLTS system and discussion of the future plans for the system. Also discussed the feasibility/desirability of using electronic case files (legal and social) if the juvenile court setting. Maricopa Superior Court, Judicial Information Systems 12/17/99 Michael J. O'Hara, Deputy Court Administrator, Director Discussed use of electronic documents in administrative offices and requirements for EDM systems for records other than case files. Maricopa Superior Court, Adult Probation Office 12/17/99 Zachary Dal Pra, Deputy Chief, Assessment and Development Discussed the uses of electronic files in probation operations. Melody Tinsley, Director Juvenile Court Operations, 1/20/00. Discussed caseload, workflow and her views of benefits and potential problems with imaging systems, previous imaging system and its technical difficulties as well as cost issues.  La Paz County  Sheri Newman, Clerk of La Paz County Superior Court, 12/13/99. Reviewed and observed procedures, records management and workflow with Clerk and staff. Discussed future EDMS possibilities. Ms. Newman arranged meetings for us for the next day with the judge and other county departments. Superior Court Judge Michael Irwin, 12/14/99. Reviewed the purpose of the project and discussed feasibility of judicial use of EDMS in chambers and courtroom. Discussed FACTS implementation and past automation history. Lynn Farmer, Administrator of La Paz County Attorney's office, 12/14/99 Reviewed the purpose of the project and the role and flow of documents from other departments. Discussed local attitudes to electronic court case files and electronic filing, possible interface with County Attorney. John Dyess, Deputy Chief Adult Probation Officer, LaPaz Adult & Juvenile Probation Dept. 12/14/99. Reviewed the purpose of the project, the role of probation, their document flow and their information needs from the court. Discussed workflow and records in the Probation Office, EDMS opportunities and difficulties he forsees in using electronic probation case files.  Coconino County Clerk of Coconino County Superior Court and Debbie Young, erk, 12/15/99. Reviewed the purpose of the project, an overview of the organization and workload, records management issues, electronic case they might work in that environment.  Juli Carlson, Associate Cl Clerk's Office files and how  Mary Anne Linde, civil legal clerk, Kathy Roy, appeals clerk, Charlotte Treece, Account Clerk, Deanna Seyler, Court Technician, and Teresa Elliott, criminal clerk,  On-Target Information Technology Consulting  A2-4  6/13/00   Electronic Document Management Systems for the Arizona Courts  Coconino Superior Court Clerk's Office, 12/15/99. Reviewed file room procedures, inventoried case type files Superior Court Judge Van Wyck and his Judicial Asst., Carla Baber, 12/15/99. Discussed their file and document needs and possibilities for judicial and chambers use of EDMS. Frank A. Maiocco, Jr. Deputy Court Administrator, Coconino County Justice Courts, 12/15/99. Overview of Court Administration in Coconino County. Barbara Mullins, Caseflow Manager, Coconino Superior Court, 12/16/99. Discussed how electronic case files would assist her with research and quality control functions. Sandy Cox, Legal Secretary and Robin Boldizar, Office Manager, Coconino County Attorney's Office, 12/16/99. Discussed the CA Office's interaction with the court and the benefits and possible drawbacks of electronic filing, an electronic legal file and receiving electronic communications from the court. Mary Jo Anderson, Office Manager; Doug Jilg, Division Manager, Field; Sue Zanotto, Standard Field Officer, Coconino County Adult Probation Office, 12/16/99. Discussed the integrated CJIS project, organization, functions and workflow of the Probation Office, document flow and records management of the APO. Discussed possible benefits and drawbacks to electronic documents for field officers, and APETS. Bob Tomten, Division Manager, Coconino County Pretrial Services, 12/16/99. Discussed the organization, functions and workflow of the Pretrial Services Office, document flow and records management of the APO. Discussed possible benefits and drawbacks to electronic documents for field officers, and APETS. Sherry Linville, Juvenile Clerk's Office, Supervisor of Clerk's Office staff at Juvenile, 12/16/99. Received details on current and future procedures on delinquency and dependencies, and document and file flow. Tony Pawlicki, Secretary, discussed upcoming procedural changes and his administrative responsibilities for juvenile dependency cases. Jill Owens, Supervising Juvenile Probation Officer, Coconino Juvenile Probation Dept. 12/16/99. She took us through the entire juvenile process in Coconino County, showed us probation files and how they are compiled, and the workflow of probation officers, forms, and interaction with court and other agencies. Joe La Puma, Director and Eric Holm, Supervisor, Coconino Juvenile Detention Dept., 12/16/99. Reviewed the role of the detention facility, workflow, interaction with court and probation office. Discussed their role in the process and their information needs. Tony Pawlicki, Secretary, 12/16/99. Discussed the flow of juvenile dependency cases, case files, procedures, and docketing. Superior Court Presiding Judge Jeffrey Coker, 12/16. Reviewed the purpose of the project. Received his views on EDMS for judicial use.  On-Target Information Technology Consulting  A2-5  6/13/00   Electronic Document Management Systems for the Arizona Courts    Pima Superior Court Administration  Attended kickoff meeting at the Superior Court arranged by Carol Merfeld, Special Projects Manager, 1/5/2000. The purpose of the project was reviewed and questions were clarified. Interviews and imaging system demonstration were prearranged by Carol Merfeld. Doug Kooi, Financial Services Manager, Court Administration, 1/5/00. Discussed financial management, budget, procurements and other financial operations under his office, sources of automation and court funding, county financial problems, level of financial support, use of county financial systems and application of electronic files to finance operations. Terry Gobel, Supervisor of the Assessment Center, Teresa Springer, Division Director, Dispatch and Support Services, and Ed Espinoza, Assessment Division Director, Adult Probation Office, 1/5/00. Discussed the organization and functions of the Adult Probation Office, the costs, benefits and potential drawbacks of electronic case files for probation officers and Presentence investigation officers. Andrew C. Dowdle, Senior Criminal Justice Research Analyst, Karen Hoffman, Research Analyst and Caroline Farley, Research Assistant, Superior Court Administration, 1/5/00. Discussed court statistics and the uses of electronic files for research and quality control functions. Sue Wachter, Manager of Calendar Services, Pima Superior Court Administration, 1/5/00. Ms. W achter discussed procedures and workflow and demonstrated their access to the current imaging system. Steve Mulholland, Division Manager of Exhibits and Distribution. This unit picks up minute entries and court documents from court clerks and distributes them to appropriate parties. Donna Whitman, Manager of Interpreters, 1/5/00.. Ms. W hitman discussed their document needs and their creation of documents. Judge Munger, Pima Superior Court, 1/6/00 a member of the Judicial Council's Technology Committee. Reviewed purpose of the project, his information needs and views on EDM. Kim Holloway, Director Pretrial Services, 1/6/00. Discussed PTS organization, staffing, workflow, file, reports and potential use of electronic court files. Suzanne Bushman, Human Resources Manager, Court Administration, 1/6/00. Discussed personnel records, security requirements, uses for electronic records in the HR area. Mary Jo Gasparo, Unit Supervisor, and Betsy Jennings, Office Supervisor, Field Services Division of the Adult Probation Department, 1/6/00. Discussed the role of APO supervisor, the difficulty of viewing long documents on the screen, APETS and possible ways to use electronic documents in APO.  On-Target Information Technology Consulting  A2-6  6/13/00   Electronic Document Management Systems for the Arizona Courts  Karen Godzic, Director Court and Calendar Services of the Juvenile Court, 1/6/00. Reviewed the operations of CASA, Adoption, calendaring, records management, case load, workflow and procedures. Gary Sundell, Court Liaison, Department of Economic Security, Child Protective Services, 1/6/00. Reviewed file management and current document flow coming and going between CPS and court, size of files and active caseload v closed cases. Richard Buus, Division Manager of Juvenile Probation, 1/07/99. Reviewed organization and management of juvenile probation, the juvenile delinquency process flow, case files, potential uses for electronic records. Roxanne Dutton, Court Evaluation Supervisor, Juvenile Probation Office, 1/7/00. Discussed delinquency case flow and the possibility for using electronic case files. Judge Davis, Presiding Judge of the Juvenile Court, 1/7/00. Discussed electronic case file documents from a judicial perspective and how it would help the court after moving to a larger facility with greater need to transport documents to courtrooms.  Pima County Superior Court Clerk's Office  Cindy Linnertz, Probate Registrar and Ben Preston, Associate Clerk, Pima Clerk of Superior Court, 1/5/00. Received an overview of current automation and their Elvis imaging system and the workflow. Clerk Nelly Ouijada demonstrated probate process and document flow. Lianne London, Associate Clerk and Ed Bradford, Civil Supervisor. Pima Clerk of Superior Court, 1/6/2000. Observed document intake and flow in civil section and the interaction with the imaging system. Observed customer service procedures in legal records and inventoried case files. Ben Preston, Associate Clerk, and Sean Abrigo, Technology Manager, Pima Clerk of Superior Court, 1/6/00. Obtained detailed information on the court's technology, particularly the imaging system and future plans. Lianne London, Associate Clerk, Sean Abrigo, Technology Manager, and Jane Phillips, supervisor of Imaging, Pima Clerk of Superior Court 1/7/00. Observed document flow from the various units and the process for imaging and indexing. Jim Orr, Acting Division Mgr. for the Juvenile Court Clerk's Office, 1/6/00. Reviewed the file room, case filing statistics. 4.  Limited Jurisdiction Courts Pima Consolidated Justice Courts  Judge Castillo, Presiding Judge  discussed the pending Internet court for traffic and small claims trials. Discussed the current deployment of technology and his belief that his court is moving in the right direction.  On-Target Information Technology Consulting  A2-7  6/13/00   Electronic Document Management Systems for the Arizona Courts  Pat Jacobs, Justice Courts Administrator  discussed systems in use to include traffic imaging and small claims Internet e-file applications. Joe Teta, Court Executive  reviewed public counter operations. Shelly Fraiser, Courtroom Services Supervisor  reviewed preparation for walk-up court appearances. Pamela Jones, Customer Service Manager  provided demonstration of traffic scanning operation. Maria Daniels, Customer Service Supervisor  provided demonstration of processing small claims Internet filings. Sam Hickcox, Records Supervisor  discussed the flow of traffic documents from the active files to his archive area. John Wareing, Litigation support clerk  provided explanation of the extensive W ord Perfect document merge system he developed for court correspondence. Alma Martinez, IA Clerk  discussed her IA clerk functions in preparing calendars. Maryann Montoya, Small Claims Clerk  discussed her entry and processing of small claims. Sue Castaneda, MIS Supervisor  discussed imaging system operation. John Messing, Consultant for Small Claim Filing  discussed authentication method for small claims email receipt. Bill Klein, Consultant developer for traffic imaging system  discussed development of Touch Once application for traffic. Craig Lundberg, County APD - discussed interaction and coordination with Pima JP on orders for misdemeanor probation.  Phoenix Municipal Court  Ron Beguin, Court IT Director  plans for integration of imaging with court's CMS and the technology platform of their CMS. Cindy Allen, Records Archive Supervisor  reviewed their imaging system for archiving records. Michael Hise, Support Services Supervisor  reviewed the intake operation and long form processing. Margo George, Traffic Central Files Supervisor  reviewed flow of traffic documents received from central intake (Support Services).  On-Target Information Technology Consulting  A2-8  6/13/00   Electronic Document Management Systems for the Arizona Courts  Robin Brown, Criminal Central Files Supervisor  reviewed operations and flow of long form filings from Support Services. Larry Gordon, Supervisor of Warrants  reviewed processing of warrants operation. Tom Cody, Integres Systems Integrator  discussed workstation requirements, capabilities of Eastman Imaging Software, and implementation challenges.  Mesa Municipal Court  Kathryn Barrett, Court Administrator  reviewed all operations to include a detailed review of civil traffic. Discussed the recently declined request to participate in the existing FileNet Imaging system.  Peoria Municipal Court  Toni Hale, Court Administrator  reviewed all operations and discussed the role EDMS may play in improving the efficiency of operations for selected case types. Rose Baldizan, Judicial Assistant Supervisor  reviewed in detail civil violations.  Flagstaff Municipal Court  Don Jacobson, Court Administrator  reviewed operations and discussed criminal traffic workflow.  Flagstaff Justice of the Peace Court  Judge Slayton, IA Court Judge  need a better way to verify the identification of out-ofcustody defendants. He expressed concerns regarding the lack of a signature on certain documents for potential EDMS opportunities. Discussed his perceived need to link via video hook-up defendants in remote reservation areas. Frank Maiocco, Deputy Court Administrator  discussed jurisdiction case types and the areas of concern within the IA court operations that could benefit from EDMS. Identified the IA court scheduling, post-hearing workflow to include the release document, and bindovers to Superior Court. Christi Weigand, IA Clerk  discussed the her workflow in preparing calendars and post-hearing processes. Maia Brainard, Felony Clerk  reviewed her workflow for handling felony cases from IA Court.  On-Target Information Technology Consulting  A2-9  6/13/00   Electronic Document Management Systems for the Arizona Courts  5.  Contacts for Other EDM Systems  New Mexico AOC Jim Coberly, Project Manager 505 476 6903 JimC@nmcourts.com Eleventh District Court Greg Ireland, Court Administrator 505 334 6151 AZTDGTI@nmcourts.com Weldon Neff, Deputy Court Administrator 505 334 6151 AZTDW JN@nmcourts.com Orange County Jeannette McSkane, (original project manager) 714-834-5316 Rosa Holdeman, Systems Analyst 714-834-3281 Rholdeman@superior.co.orange.ca.us Los Angeles Sharon Tani 213-974-6261 (this is not her direct line but you can reach her from it) 213King Co. Washington Roger W inters, Project Manager 206 296 7838 Roger.W inters@metrokc.gov Riverside County Gary W hitehead, Deputy Court Administrator 909-955-0536  On-Target Information Technology Consulting  A2-10  6/13/00   Electronic Document Management Systems for the Arizona Courts  6.  Contacts for EDMS Software Vendors  Brian Christie, Altris Monique Broussard, Documentum Dee Cutler, Eastman Software Terrence Sciortino, FileNET Mark Gallagher, Hummingbird Autumn Tisko, Hummingbird JD Humpherys, Identitech Ken Reinheimer, Identitech Garry Gronke, Keyfile Anthony W ile, OIT Ian Llado, OIT Paul Bewley, Open Text David Alford, Optika Sean Driscoll, Optika  On-Target Information Technology Consulting  A2-11  6/13/00   Electronic Document Management Systems for the Arizona Courts  APPENDIX 3 COURT WORKFLOWS  On-Target Information Technology Consulting  6/13/00   Electronic Document Management Systems for the Arizona Courts  EDMS Workflow Examples This section presents some sample workflows, drawn from site visits in the courts and the FCRB. These examples show graphically how an EDMS might impact the workflow. These workflows are specific to the courts in which we found them, but it is likely that other courts of similar size would have similar workflows. At a more detailed level, the workflows in large and small courts were quite different. These diagrams are presented at a relatively high level and do not contain all detail that would be needed for designing a workflow application. All diagrams are positioned at the end of this chapter due to page layout considerations in the electronic version of this report. Example 1: Maricopa County Superior Court Clerk's Office Marriage License Processing Overview In Maricopa County, marriage licenses are issued at the marriage license division in the basement of the Old Courthouse in downtown Phoenix, at the Southeast courthouse in Mesa, at twelve JP courts and one municipal court throughout the county. Approximately 35,000 marriage licenses are issued in the county each year. Marriage licenses are two-part forms preprinted on parchment with bar coded numbers. Blocks of numbers are assigned to each issuing location by the Superior Court Clerk's Office each year. The top part of the form is kept by the couple after the ceremony, the bottom part or Certificate of Marriage is signed and returned to the Court's Records Management Center (RMC) in Phoenix by the officiator of the ceremony. The RMC manages all the paper files and makes copies of marriage licenses and abstracts when requested. According to the Records Retention and Disposition Schedule for the Superior Court,1 marriage licenses may be destroyed after they are microfilmed, but the microfilm must be kept permanently. Although the RMC does microfilm these records, it does not destroy the original paper copy of the Certificate of Marriage, due to the significance of the document and the difficulty of locating the microfilm image. Workflow The process begins when a couple completes an application for a marriage license. The clerk enters the information in the marriage license system and prints an affidavit from the system. The couple reviews and signs the affidavit, and the clerk witnesses it by signing. The couple pays the license fee. A clerk receipts the funds on the system and prints the actual two-part license for the couple. Each day, the clerk prints a batch list of all the licenses issued that day and sends it together with the affidavits and applications to the RMC. Upon receiving the batch, the RMC files the paperwork ion a pending file. W hen the Certificate of Marriage is returned, the RMC records the marriage on the system, pulls the original paperwork and attaches the Certificate of Marriage. Completed marriage licenses are filed in another area (apart from the pending files). After the marriage is recorded, the records (affidavit, application and Certificate of Marriage are microfilmed. 1  Administrative Order No. 91-13, April 30, 1991, Section 4. ""Records Created or Received by the Clerk's Office""  On-Target Information Technology Consulting  A3-2  6/13/00   Electronic Document Management Systems for the Arizona Courts  If a request for a copy of the marriage license is received, the clerk either creates a certified copy of the original from the microfilm or prints an ""abstract"" from the marriage license database. Arizona statutes now permit abstracts to be used in place of a certified copy, but many agencies, such as the Immigration and Naturalization Service require a certified copy, which is copied from the microfilm image, signed by a clerk and a seal is placed on it. EDMS Opportunity The EDMS opportunity here is to create an image database of marriage license paperwork for use in creating copies of the marriage license and for research purposes. The images could either replace or supplement the microfilm records, and they could also replace the paper records. The imaging system should be integrated with the marriage license database though a link to an index of documents to enable the staff to easily find, display and print documents through the marriage license system. The workflow would remain largely the same, except that a scanning and indexing steps would be added and all steps associated with microfilming could be eliminated. Copies of marriage licenses could be printed and certified at any of the Clerk's Office locations, assuming all had access to printing from the image system. The biggest benefit would be elimination of the time-consuming retrieval of microfilm to make copies. Clerks Office staff in other counties stated that it would be very helpful to the public if a database of marriage licenses was available statewide. Internet access to a statewide database or to individual counties' marriage license systems would be a logical step forward, with or without access to images. Example 2: Maricopa Superior Court Clerk's Office  Probate Division Court Administration  Probate Division Overview The probate division began an imaging pilot project on December 1, 1997 using the application ""Paperclip"". This section also images and dockets probate documents which are sent from the Southeast court in Mesa. There currently are five staff and two vacancies. Probate/mental health filings are estimated at 6,500 annually. Daily docketing runs from 600-800 per day. The average document is 3-4 pages. Most filings are from attorneys and are brought in by runners. Arizona statute permits informal (with original will) and formal probate (without an original will). Probate clerks are quasi-judicial and are appointed to handle informal probates. Workflow The following process occurs usually within 24 hours. a) Documents are received by counter staff, receipted, stamped, sorted and placed in baskets.  On-Target Information Technology Consulting  A3-3  6/13/00   Electronic Document Management Systems for the Arizona Courts  b) Then they are carried to the probate/merge/sort/docket area where new complaints are reviewed, and sorted in numerical order by case type. Subsequent documents are sorted further by document type. c) Documents are batched with a batch control form and are scanned. Scanned documents are counted, verified, numbered, routed electronically to a docketing clerk, and counted again by the system. d) Documents are then docketed from the image. e) Documents are audited At this time, the only other areas with terminals are the file room and the Commissioner. Court reviewers, investigators and accountants work in court administration in another location. At one time, they had a terminal but it was not being used and was removed. The fileroom uses the imaging system for making copies of documents. Images are often in before the file is received in the fileroom. Runners and attorneys accept imaging but only a small percentage of the general public will use it. Of the 25-35 daily customers, the majority wants to see the paper file. Thus only about 10% of copies made are coming from imaging. The file room also uses a File Tracking (FT) system that shows case number, and other pertinent information. If the case is microfilmed, when the number is entered in CARS the roll number and screen number appear. All microfilm rolls are on site and available for viewing but the current system does not supply imaging information. There are a total of about 20,000 files stored on site since 1991. Older files at RMC (Records Management Center). The file tracking system is effective but the room is not kept up to date on file movement so there are still many missing files. Probate and mental health files are sent off as soon as a case is closed. There are daily incoming runs and a 24 hour turnaround is promised. About 100 probate files back and forth daily and often a few are not received until a few days later. are file two go  Mental Health files are confidential, are not imaged, and are kept in a secured area in the Exhibits Department. Probate sealed files are not imaged and are also kept at Exhibits. W hen cases are sealed they are deleted from the case management system as there are no proper security access levels. Cases for Southeast court can be filed in central. There are two daily runs between courts. The numbering system for Southeast is 9000 series while central is 0001 EDMS Opportunities The opportunity exists to have a fully electronic probate case file. First, since the existing imaging system is not adequate it would have to be replaced with an EDM system with workflow, imaging, and other applications. Ideally, the current case management ACS would also be replaced with one that uses up-to-date technology and has increased functionality. Expansion of the target EDMS to Southeast Court in Mesa would improve accessibility and reduce movement of probate files.  On-Target Information Technology Consulting  A3-4  6/13/00   Electronic Document Management Systems for the Arizona Courts  Documents would be prepared, batched, scanned and docketed. Document images would be attached to the docket entry so that a click on an entry would bring up the image. After auditing, appropriate documents would be routed to reviewers, accountants, and investigators for processing. As needed, other supporting documents in a case would be available for viewing without pulling the hardcopy file. Output from reviewers, accountants and investigators would be scanned or otherwise electronically transmitted to the case file. It is then available to all staff, commissioners and judges for calendars or ex parte processing. After probate decisions are made, minute entries, orders, and other documents which emanate from those decisions would be scanned or otherwise electronically transmitted to the system and become available for all interested parties to access on-site or via the internet. Since the majority of probate filings are from attorneys and the court file is in electronic form, this may be a good area to begin an electronic filing project. Issues Some files may be sealed or contain confidential documents. Both the EDM and case management systems must have security levels that will allow confidential cases to be placed on the systems with access limitations at the case or document level. Reading long documents or jumping back and forth when comparing documents may present problems for Judicial officers, reviewers, accountants and investigators. Post-it notes  An investigator may wish to write a note to the Commissioner or the Commissioner may wish to keep case notes for himself. The system must support condifential and public notes. Systems should be sized so that images are available within a few seconds on an appropriately sized monitor. Slow systems and small monitors are impediments and keep the system from being used. If necessary, rule changes may be necessary to allow copies of imaged documents with judicial officer signatures, Clerk of Court signatures and court seals to be accepted as an original. Example 3: Pima County Superior Court Clerk's Civil Division Superior Court Administration, Calendar Services Division Overview Pima Superior Court is located in Tucson. It's the state's second largest court with 25 judges and 14 commissioners. To support the work of these judicial officers, the Superior Court Clerk's Office has 188 employees and Superior Court Administration has 255 for a total of 443 employees. Most business is conducted at the courthouse on 110 West Congress Street in Tucson, and for juvenile matters at the Juvenile Court Center, except for once-a-month hearings conducted at Ajo in the eastern part of Pima County. The court's automation was updated for Y2K compliance but the systems are fragmented and do not have full functionality. All non-criminal cases including probate are on the ""803"", which is the Clerk's Office civil system. The Clerk's Office enters new  On-Target Information Technology Consulting  A3-5  6/13/00   Electronic Document Management Systems for the Arizona Courts  probate cases and new Pima County attorney information into CACTIS. Calendar Services and the Judicial Divisions do the remaining data entry. The County Attorney, the Public Defender and the Legal Defender have access in CACTIS o update attorney assignments only. Court Administration uses CACTIS for case management and calendaring. Imaging is on ELVIS on an AS400 and the interim criminal system ""COATS"" is on a PC server and is used primarily to track fines and fees. The Clerk's Office also uses ATLAS, the state's child support collection system, and JOLTS, the juvenile system. There is no automated cash management other than the criminal fees and fines tracking. Workflow Currently all incoming and court-generated documents are processed by the criminal, domestic relations, probate and civil divisions of the Clerk's Office. In the civil division, copies are made of the first page of new complaints, cover sheets, documents for hearings, dispositions, judgments, proofs of service, answers, etc. and placed in baskets for pick up by Calendar Services staff from the ninth floor. These copies are retrieved at least twice daily, sorted and basic information is entered in CACTIS. Copies are then thrown away. At least one recycle basket is filled per week. Calendar Services has access to the current imaging system through one terminal in their office. It is rarely used as the images have poor resolution due to the age of the PC now in use. The current index system makes searching difficult, and users perceive the system to be slow to display and print images. The goal is to put imaging access on all newly installed Calendar Services PCs. EDMS Opportunities In the ideal world, the Clerk's Office, Superior Court Administration and the Superior Court Divisions would use the same automated case management system. This system would be fully functional with a register of actions (docket) at its core. The register of actions is a central place where all events and documents are listed for the case. Documents would be received at the civil division and prepared for scanning. After scanning the workflow function would route the documents to a clerk for indexing, auditing and integration with the court's case management system. Integration would allow documents to be viewed by users from the register of actions. One would just click on the title of a document and the image would appear. At this point, the paper documents are sent to the night crew for filing that night. The next step is to route appropriate documents electronically to Calendar Services in Court Administration for processing by a calendar clerk. This project would be of high value for the Clerk's Office, Court Administration and the Superior Court Divisions as, at the very least, copying and document handling costs would be reduced and the following steps would be eliminated : Copying thousands of pages weekly by the Civil, Criminal, Probate, Domestic Relations Divisions Placing documents in the basket by the Civil Division Picking up documents from baskets by Calendar Services  On-Target Information Technology Consulting  A3-6  6/13/00   Electronic Document Management Systems for the Arizona Courts  Sorting and distributing documents by Calendar Services Trashing of thousands of pages weekly by Calendar Services, Superior Court Divisions, JAAs and courtroom clerks In addition, a much desired plus is the ability to review documents in case files without retrieving the file. Calendar Services reviews the content of documents in the course of their work and currently pull many files. Issues  Court administration and the Clerk's Office might not be on the same case management system. In that case, a bridge would have to be built so that the imaging and workflow functions of EDMS work effectively. Workflow would have to be designed carefully and staffing would have to be adequate for the workload. Backup of work in the imaging department would create problems for Calendar Services, which is dependent on the output. If the EDM system is too slow, it will not be used. Spread the EDM system to as many users as possible to get the most usage. Example 4: Maricopa Superior Court Criminal Early Disposition Court Overview Early disposition court bypasses the lower court for first time drug offenses and other felonies. The goal of the court is to dispose of cases at the first appearance, if possible. The Clerk's Office handles the processes for this court in a separate section in the criminal division with two clerks and one backup person. At the present time, only the west side police agencies are working with the County Attorney and the Superior Court on this project. Workflow The early disposition court works as follows: The law enforcement agencies go to the County Attorney for issuance of complaints. After the complaints are issued, the police liaisons carry them to the Superior Court Clerk's Office, where the clerk logs the defendant's name in a book. The Liaison then takes the complaints to the Commissioner's office for signature. If the Commissioner is unable to sign at the time, the liaison is sworn, the complaints are left and they are signed later. After signature, the Judicial Assistant either calls the Clerk's Office to have the complaints picked up or has them delivered. The clerk then prepares the files and separates the cases into in-custodies and not in-custody. In-       On-Target Information Technology Consulting  A3-7  6/13/00   Electronic Document Management Systems for the Arizona Courts  custody defendants have priority and must be arraigned as soon as possible in the courtroom in the jail. After arraignment setting to the jail and the administration. The cour enters the information in calendar. of in-custodies, court administration sends a list of dates for jail selects the date. Jail paperwork is then sent to court t date is usually set within 4-5 days. Court administration the computer and the Judicial Assistant prints the court  The daily calendar contains three types of cases.  In-custody complaints  Direct complaint with summons  Direct complaint with warrant Cases with a summons are set 6 weeks ahead and there are usually 20 of these cases on the calendar. In addition there are in-custody cases including pick-ups on warrants. W hen a person is picked up on a warrant, the sheriff informs court administration and a court date is assigned. Usually there are 70-80 cases on calendar. The Clerk's Office holds the files until the first appearance when the Judicial Assistant or bailiff picks up the files. All cases are set for preliminary hearings but about 80-90% are disposed at first appearance. Should a preliminary hearing proceed, the Commissioner will hear it and, if appropriate, the case is bound over to another judge. EDMS Opportunities The goal of early disposition court is t as possible. The current procedure includes paper from place to place. Using a workflow accomplished quickly thereby expediting the o resolve uncomplicated cases as quickly several time-consuming steps moving application, this process can be process even further.  An additional reason for having a pilot project in this area is because early disposition court is a simplified representation of the criminal process. A successful project would give the court experience with EDM systems and provide the foundation for future expansion to the entire criminal division. Ideally, the first step would be the submittal in electronic form of the citation, arrest report, or other initiating documents by the law enforcement agency with the County Attorney. After approval, the next step would be the preparation and electronic transfer of the complaint to the court for the Commissioner's approval. Since the court has no control over the participation of these agencies, we will assume that the EDM process begins with the scanning of the complaints by the Clerk's Office after routing to the Commissioner for approval and signature. After scanning, complaints are routed to the Judicial Assistant for calendaring, and routed to the Clerk to complete docketing and prepare the hard copy file. The County Attorney receives notification of the acceptance of the complaints and the calendar date via email. The hard copy file is not pulled for court; the Commissioner uses the electronic file. Issues  On-Target Information Technology Consulting  A3-8  6/13/00   Electronic Document Management Systems for the Arizona Courts  The type of digital signature must be determined and the use of a digital signature authorized by Judicial rule and statute, otherwise the Commissioner's digital signature may be challenged by the Public Defender, the local criminal defense bar and the County Attorney's office, if they are not consulted beforehand. Criminal proceedings involve numerous external agencies. The sooner documents are transferred into electronic format, the great the benefits of EDMS. Can the court become the ""champion"" of this project and make it a cooperative effort? The judicial officer may find it difficult to work with electronic images as compared to the paper file. The system must be properly sized to provide immediate access if the judicial officer is to use on the bench. In criminal proceedings, the judicial officer and the defendant sign probation and sentencing orders. The defendant's fingerprint is also placed on these documents. The means of digitally signing a document and fingerprint capture must be addressed. Example 5: Foster Care Review Board Overview The Administrative Office of the Courts (AOC) administers the Foster Care Review Board, Court Appointed Special Advocate (CASA) and other family related programs. The Foster Care Review Board began 21 years ago but the process was only automated about four years ago. This program is administered from Tucson and Phoenix with a total of 28 staff including Program Specialists (PS) and support staff. The Phoenix office of the AOC supports 30 Maricopa county boards, which hold their meetings at the AOC in Phoenix; 13 Mesa boards, which meet at the juvenile court, and 14 rural boards, which meet at various locations. The Tucson office is responsible for southern Arizona and supports 19 Pima County boards and 10 rural boards. The number of boards is based upon state population and as population increases, so will the number of boards. Each board consists of five volunteer members for a total of 480 volunteers sitting on 87 boards throughout the state. A majority of boards meet monthly, review and make recommendations on about 10 cases each month. The court then reviews these findings and recommendations. Each active dependency case is reviewed every six months and contains one or more dependent children. There are currently approximately 6,800 foster children in this program (about 4,200 cases), which results in the annual review of 8,400 cases. Workflow Dependency cases begin with the filing of a petition by the Attorney General or a private party and include a court ordered investigation or an initial report from Child Protective Services. The AOC enters the case in their automated system, DCATS, assigns the case to a particular board, and schedules the case for review in five months. If subsequent documentation is received by the AOC indicating that the matter will not proceed, the case is dismissed. Otherwise, one-two weeks prior to the review date, staff  On-Target Information Technology Consulting  A3-9  6/13/00   Electronic Document Management Systems for the Arizona Courts  compiles and duplicates reports received from involved agencies and other necessary information and sends a ""packet"" for each case scheduled for review to the board members. Compiling, duplicating and mailing one packet to five board members can take one person at least two hours. On average, support staff spends about five hours per day, at least four days per week on the tasks of compiling, duplicating and mailing. Program specialists are assigned to selected boards and are responsible for preparing and reviewing cases for board meetings, overseeing the compilation and distribution of appropriate information (psychiatric and medical reports, CPS reports, drug testing of parents, etc.) to board members prior to meetings, recording board meetings, and compiling the board's findings and recommendations. Program specialists use a laptop in board meetings. This laptop has the DCATS tracking system on it with current information downloaded from the Rs 6000. The PS records proceedings at the meeting and uploads the data on their return to the office. Findings and recommendations are prepared by the PS and reviewed by the supervisor. After approval, they are sent to support staff for copying and distribution. About 250-500 cases are sent to storage every six months after they are closed. Sometimes cases are reopened and the files have to be retrieved. EDMS Opportunities A new system might be similar to the following: Upon opening a new file or receiving documents for an existing file, the documents are scanned and indexed for later retrieval. Documents could also be linked to the case in DCATS, but before this could be implemented, DCATS would have to be modified to provide a document index to which images could be linked. At first, the paper documents are kept and the hard copy file is updated with new documents. After a test period, which could be up to 2 years, the hard copy files are no longer maintained and paper documents are destroyed when the image has been verified. The program specialist prepares on-line for the next board hearing. Documents are retrieved by staff and viewed on-screen, routed electronically among staff within the office and printed only when required. Board members would receive documents to prepare for a review either on CD or in hard copy. Board members with computers could review documents on their PC or print out copies. Board members without computers would be sent hard copy, printed from the EDMS. After the board meeting, the program specialist prepares written findings and recommendations either in word processing or in another electronic format for routing using the workflow function. These findings are routed through workflow to the supervisor for review and, upon completion, to support staff for docketing, copying and distribution to interested parties. The distribution could be via CD or hard copy. The Internet is not recommended as a means of distributing documentation unless the Supreme Court revokes the prohibition against transmitting confidential files via the Internet. Conclusions The following benefits can be realized from this application, over time:  On-Target Information Technology Consulting  A3-10  6/13/00   Electronic Document Management Systems for the Arizona Courts         Storing documents in electronic form would eventually eliminate almost all paper file management tasks, such as creating file folders, pulling files, filing papers, reshelving and archiving files. To the degree that board members will accept their board packets on a CD, the cost, time and paper consumed in preparing board packets will be reduced. W e do not expect this to be a major impact in the beginning, but with increasing computer use in the home, we believe the percentage of those willing to use CDs will increase over the years. Preparing hard copy board packets will be easier and require less staff time because printing the copies from a document repository does not entail pulling files, removing and unstapling documents, operating a copier, reassembling and reshelving files. Printing large numbers of documents does entail some attendance to the printers, but not to the same degree as making copies. Support staff can be reassigned to assist program specialists with some of the more clerical aspects of their responsibilities thus freeing the program specialist to support the work of the boards in a different way.  The following may be issues or challenges to overcome with respect to this application:     Reports received from various agencies sometimes consist of many pages. Some board members and staff will have difficulty reading long documents online and will require a hard copy. Moving back and forth between pages and documents online may pose a problem for readers at times. Displaying multiple image windows may help to alleviate this problem. The minimum size for monitors on which images are viewed is recommended at 17""; otherwise reading is difficult. W ill board members have access to monitors 17"" and larger? (Most monitors that come with home systems are now 15"".) DCATS does not currently have an index of documents. Either DCATS would have to be enhanced to contain an index or documents would be retrieved through the native EDMS retrieval capabilities. This issue could cause either fragmentation of the user interface or extra expense in development costs for DCATS.  This application could have a high value for the FCRB, but it is not without challenges. Becoming accustomed to reading documents on screen, routing documents electronically and not having the physical file as a visual cue are some of the many changes staff would have to become accustomed to. There is no doubt this application would force changes in the organizational culture as staff must become more technologically sophisticated. The transition from paper to electronic documents will have to occur over time as document users become accustomed to new ways of working in an increasingly electronic office.  Example 6: Flagstaff Justice Court Initial Appearances Overview  On-Target Information Technology Consulting  A3-11  6/13/00   Electronic Document Management Systems for the Arizona Courts  Flagstaff Justice Court has criminal jurisdiction over misdemeanor crimes outside of the jurisdiction of municipal courts within the county along with jurisdiction over certain civil cases. It also conducts Initial Appearances for defendants charged with felony offenses as well as conducting preliminary hearings on a small percentage of felonies. Annual filings for the most recent year include felony at 2,519, Misdemeanor at 4,483, Traffic at 10,378, small claims at 455, and landlord/tenant at 982. It is considered a large court within the State of Arizona. The Court uses the ACAP case management system for all case types, with the exception of using the payment contracts and scheduling modules. Payments are entered into ACAP. Most data entry into ACAP is two to three weeks beyond the date of the transaction due to not having adequate staff for timely data entry. Court Administration is located in the Courthouse. Due to renovation of this facility, the Justice Court staff, judges and courtrooms have been temporarily relocated.. This relocation caused a discontinuance of the video feed to the Sheriff's Jail that has made it necessary to bring in-custody defendants to the court. Workflow On normal week days, the IA clerk picks up the Sheriff booking report on or before 8:00 am, in advance of the scheduled 10 am Initial Appearances. On holidays and weekends. IA court is held at 8:30am in the Flagstaff Municipal Court location using an audio-video feed with the existing County jail. A Justice of the Peace Pro Tempore presides over all Initial Appearances for the Flagstaff Justice and Municipal Courts and the W illiams Justice and Municipal Courts. The JP Pro Tempore also acts on behalf of the Superior Court and conducts release hearings for any juveniles held in the County detention facilities. Once a check as to the jurisdiction is completed, the IA clerk updates an in-custody worksheet that is a word processing sheet that lists the defendant, date & time of arrest, and other information. This is used as a calendar in court. The IA clerk will also receive the following information for each defendant that is used to prepare a package for court.       Booking sheet that is a printed computer report from the Sheriff's system. Probable cause form completed by the arresting officer. Defendant financial statement completed by Pretrial Services. If a victim is involved, a victim rights form. DPS disposition form. Pretrial Report, usually received 10 minutes prior to court.  The IA clerk prepares a Release Form that is a five part form to be signed by the judge upon determining release conditions. Once the judge has reviewed the case and completed the Release Form, the IA Clerk distributes the form in court; one copy to the defendant, one to the Sheriff D.O., one to the public defender, one to the county attorney, with one remaining in the defendant package. For felonies, the defendant package is delivered to the Felony Clerk along with a copy of the In-Custody worksheet. For defendants in-custody who do not have a complaint filed within 48 hours, a three-part jail release form is completed with one copy delivered to the jail.  On-Target Information Technology Consulting  A3-12  6/13/00   Electronic Document Management Systems for the Arizona Courts  For bind-overs to the Superior Court, the felony clerk calls periodically to request Superior Court case numbers. For indictments filed by the county attorney, the felony clerk records the Superior Court case on the release form and sends the file up to the Superior Court after retaining a copy of the release form. This release form is then used to enter the Superior Court case number into ACAP. For defendants who are not bound over or filed directly with the Superior Court, the case files are delivered to a calendar clerk who prepares preliminary hearing calendars. EDMS Opportunities This could initially involve facilitating a limited electronic filing pilot to improve the communication of internal forms used to control/document the release of defendants from jail. This would involve the development of an electronic messaging system that would be based upon a low to medium authentication method for attaching a nonreputable signature of the person sending the authorized transaction. The workflow would begin with the notification of booking from the Sheriff's booking application, this transaction would then be used to build the in-custody worksheet, that would in turn generate release conditions forms for the judge to update electronically. The electronic release form would then be used by the court to generate alerts as to exceeding statutory incarceration limits and update ACAP. The benefits would be as follows:      Eliminate printing and pickup of the booking report and provide the booking transaction at the completion of a booking. Eliminate the preparation of the In-custody worksheet. Booking transactions would build the report eliminating transcription errors and provide multiple locations access to the information. Eliminate the manual distribution of the release form with the exception of printing a defendant copy. Once the video connection with the jail is reestablished, the defendant copy would be printed at the jail. Eliminate the preparation of the release form for in-custody defendants released by the Felony Clerk. Provide electronic transactions to ACAP eliminating data entry and providing a more timely update of status to all ACAP users.  EDMS risks would be associated with the inability for the Sheriff's booking system to generate an EDI or XML based transaction for processing by ACAP, the inability of ACAP to send electronic transactions with some form of authentication to all agencies involved, and finally the inability of agencies to receive or accept an electronic message as a substitute for the paper. For the Flagstaff Justice Court, this could be a high value application to implement that would free-up resources for other critical processing that is not being performed in on a timely basis. Eliminating the ACAP data entry would provide more time to the Felony Clerk to monitor her process and organize her work so that defendants are not jailed beyond the statute limits. The electronic transaction could be passed on the existing County e-mail system that would not require a major investment.  On-Target Information Technology Consulting  A3-13  6/13/00   Electronic Document Management Systems for the Arizona Courts  Example 7: Flagstaff Municipal Court Criminal Traffic Citations Overview Flagstaff Municipal Court has criminal jurisdiction over misdemeanor crimes and petty offenses committed in the City of Flagstaff. Annual filing volumes were provided for criminal traffic and misdemeanors at 15,298, civil traffic at 12,774, and local noncriminal ordinances at 328. The bench consists of 3 judges and 3 Pro Tem judges. There are an additional 22 court administrative and clerical staff. The court is housed in one location and is considered a large court by Arizona standards. The Court uses the ACAP case management system for all case types. Payments are entered into ACAP with the exception of using the payment contracts and scheduling modules. The use of scheduling is planned for implementation this year. Workflow Criminal traffic citations are filed by the Flagstaff Police Department. The Court conducts the Initial Appearance for these cases on a daily basis over a closed circuit video system. On weekends, however, Initial Appearances are conducted using the Municipal Court's facilities by a Justice of the Peace Pro Tempore. In-custody hearings for defendants for the JP Courts are conducted with the defendant present due. Paper case files are used throughout this process. All active case files are returned to a central file area after each hearing unless the case has been terminated. A file jacket is prepared for each criminal traffic case. Case files are retrieved from the central file area during the process of combining case files for a calendar. EDMS Opportunities The EDMS opportunities for criminal traffic citations within the Court would involve the implementation of an EDMS with strong imaging workflow capabilities that could be interfaced with ACAP. Some of those benefits would include:     Eliminate the file jacket preparation steps and time to retrieve files from the central filing area. Prepare documents more quickly for each hearing and eliminate the redundant file collation steps between each hearing. Although lost files were not considered a problem, the EDMS would reduce any future risk of lost files. Provide multiple location access from any ACAP workstation.  As for risks, this would be one of the more extensive implementations for a municipal court as compared to small claims and civil traffic. Besides court administrative staff and judicial offers, access would be required for the city prosecutor and probation officer. Risks that may be applicable are identified below:   Availability of the required equipment by the city prosecutor and probation officer to access files. Developing an effective workflow system for the judicial officer during court.  On-Target Information Technology Consulting  A3-14  6/13/00   Electronic Document Management Systems for the Arizona Courts     The acceptance of using electronic documents on a PC workstation by the judicial officer. The increased effort of scanning and indexing documents may not be off-set by implementation of the EDMS.  This would only be a medium to low value application for consideration of EDMS as an initial pilot. This case type has to include considerations for the city prosecutor and the probation officer that will increase the risks associated with a successful implementation. These additional access users along with the need to possibly interface electronically with the city prosecutor system contribute to the low scoring for the potential application. Example 8: Mesa Municipal Court Civil Traffic Citations Overview of the Court Mesa Municipal Court has criminal jurisdiction over misdemeanor crimes and petty offenses committed in the City of Mesa. Annual filing volumes are approximated for criminal traffic at 11,000, civil traffic at 60,000, misdemeanor non-traffic at 12,000, and local non-criminal ordinances & orders at 3,000. The bench consists of 7 city magistrates, 1 hearing officer. There are an additional 70 court administrative and clerical staff. The court is located in one location and is considered a large court within the State of Arizona. The Court uses a case management system named Automated Court Information System (ACIST) that was initially purchased from Inslaw in 1985 and was rewritten in 1992 with a major enhancement implemented in 1998 to make it Y2K compatible. ACIST resides on the City mainframe that is an IBM compatible mainframe, the programming language is COBOL, and uses an IBM DB2 database. ACIST accepts electronic transactions from photo radar vendors through a modem interface and accepts traffic school completions electronically over the Internet. This system is shared by the Police Department and City Prosecutor for use in identifying court schedules for officers and attorneys. This use and the belief that the ACAP system is much slower for entry has contributed to not electing to participate in ACAP. A FileNet imaging system is currently operational within the City for the Police Department and other City Departments. A proposal for the 96-97 fiscal year had requested a multi-phase $1.5 million project to expand the FileNet system to the Police, Courts, and City Prosecutor. The Police Department was approved for expansion. As recently as this budgeting period, the Court and City Prosecutor had submitted their request again to be included but were denied. Workflow Analysis Civil Traffic Citations are received electronically from photo radar vendors as well as paper citations from the Mesa Police Department. Electronic Citation Initial Processing Photo radar citations are transferred electronically in daily batches to the court for staging in an electronic queue for manual acceptance by the court. The Police Department also receives the same daily batch to reject citations that they decide not to file. The Police department removes the citations from the printed file of citations that On-Target Information Technology Consulting A3-15 6/13/00   Electronic Document Management Systems for the Arizona Courts  they decide not to file and submits the approved batch of paper citations to the court. The court compares the approved paper batch of citations with the electronic batch of citations received from the photo radar vendors. Electronic citations with an associated paper citation are accepted for updating ACIST. The paper citation is then filed in the Civil Pending file for processing. Paper Citations Data Entry Citations are picked up at the Police Department each morning for entry into ACIST. Once entered, they are filed in the Civil Pending file. Payment of Citation The public has several payment methods if they enter a plea of responsibility for the citation. If they pay at the counter, they may choose to request a payment schedule that will require the completion of a Defendant's Financial Statement. This request for payments can be approved by the clerk at the counter. If approved, this confidential document is filed separately within the Civil Pending file and is not released over the counter unless it is approved by the defendant. The defendant also has the option to mail in their payment with check, money order, or credit card. They may also pay by telephone by calling the court and providing credit card information to a clerk. The Court is also developing an interactive telephone payment system to accept credit card payments. This system will also be used to create an Internet based payment system. Once payment is satisfied, the citation is pulled from the civil pending file and filed in the Terminated file where it will stay for an average of 3-4 months before being moved to offsite storage. Defensive Driving School Once the defendant elects to go to defensive driving school, they must elect to do so before the court appearance date. Once they notify the court, they attend the school and upon successful completion, the school transmit the completion over the Internet to a city email address. These completions are processed on a daily basis and will be included in a completions report used by the court to pull satisfied civil traffic citations from the Civil Pending file and place in the Terminated File. Fail to Appear For defendants fail to pay the citation or attend court, the ACIST system will produce a report two weeks after the court appearance date. This report will be reviewed with the citation pulled from the Civil Pending file to verify that there was not action by the defendant. The clerk will then update ACIST status to generate a judgement letter that will be mailed to the defendant. If not paid after a second letter in 30 days, the license will be suspended through an electronic transaction to the MVD that will also generate an intercept for state tax refund. EDMS Opportunities Several opportunities exist if the Court was approved to participate with the imaging system currently deployed to the Police Department. They include:  By eliminating the printing of citations by the photo radar company, delays in transferring paper documents between the police department and the courts are eliminated.  On-Target Information Technology Consulting  A3-16  6/13/00   Electronic Document Management Systems for the Arizona Courts     By scanning paper transactions by the police department, the court would eliminate the maintenance of the civil pending file, and the terminated file. Documents would be purged by status maintained by ACIST. Since a small percentage of citations go to court, the citation folder could be maintained or the magistrate could use a PC workstation to conduct the court hearings. Either way, there would be a significant improvement in reduced paper file handling and lost files. Example 9: Peoria Municipal Court City Ordinance Citations  Overview of the Court Peoria Municipal Court has criminal jurisdiction over misdemeanor crimes and petty offenses committed in the City of Peoria. Annual filing volumes are estimated to be for 98/99; criminal traffic 1,800, civil traffic 12,000, misdemeanor non-traffic at 3,500, and local non-criminal ordinances at 850. The bench consists of 2 judges, 1 court administrator 1 judicial assistant and 6 judicial assistants. Based upon filings of over 18,000, this court is considered a large court. There is only one court location. The Court uses the ACAP case management system. ACAP is used for all case types with the only comment being that it is more time consuming for data entry as compared to their previous system. They do not use the payment scheduling feature of ACAP and are using a manual system. Workflow City ordinance citations are filed by the Code Compliance Officer who delivers these citations to the court. The court will enter the citation into ACAP, create a file jacket, and file the case file by court date. The defendant may mail in the sanction of appear in court. If the defendant appears in court, they may request a civil hearing, pay an imposed sanction, provide proof of compliance to the court, which may result in a reduced sanction. Ninety percent of all ordinance citations filed result in a court appearance. If a fine is imposed, the defendant may be approved for a payment schedule that is setup in a manual filing system at the counter. If the defendant fails to appear, the court generates a notice to appear in 30 days. If no response is received after 30 days, the court notifies the Compliance Officer who will then decide whether to file a Petition for Default. Once a default is approved, the case will go to collections. Since enforcement is difficult for these types of citations, many default judgments or ordered sanctions go to collections. Since these citations are typically served by certified mail and are not signed by the defendant, this type of citation could be generated as an electronic original document and filed with the court electronically. Since 90% go to court with the case file containing primarily copies of city generated correspondence, the judicial officer hearing the case could use a PC workstation to review the case. This implementation of an EDMS could have the following benefits.  Eliminate the initial entry of the citation in ACAP.  On-Target Information Technology Consulting  A3-17  6/13/00   Electronic Document Management Systems for the Arizona Courts       Reduce the time it takes to file the citation with the court and eliminate the delivery of the document to the court by the Compliance Officer. Eliminate the preparation of file jackets and the subsequent physical housing and management of active and inactive files. Although lost files were not considered a problem, the potential for having lost files would be eliminated. Reduce the work required for preparing for court by eliminating the pulling of files and delivery of case files to the courtroom.  As for risks, the following could present potential problems.  Acceptance by the judicial officer of the electronic file as a substitute for the paper file. Since 90% involve a court hearing, a substantial cost and effort would be involved in printing copies of documents, if judicial officers did not use the citations on-line. The Compliance Officer may not have the computer equipment necessary to submit electronic files or even access an Internet based filing system. The officer may not have the time or staff to enter the information into a computer for transfer. The judicial officer may not accept the electronic authorization used by the Compliance Officer and may continue to require hand signatures. ACAP may not be able to support a limited workflow system using electronic documents. Scanning and indexing defendant-supplied documents may offset any time savings.       As for the value of having this case type as a potential EDMS application, it would have medium value. It could be easily developed into an electronic filing application due the high number of citations not having the defendant's signature. W hat brings down this rating is the high percentage of cases that appear in court. This will require significant cooperation by the bench to implement an efficient workflow process to avoid any major slowdowns during court. Example 10: Pima County Consolidated Justice Courts Small Claims Application Overview of the Court Pima County Consolidated Justice Courts have criminal jurisdiction over misdemeanor crimes outside of the jurisdiction of municipal courts within the county along with jurisdiction over certain civil cases. It also conducts Initial Appearances for defendants charged with felony offenses as well as conducting preliminary hearings on a small percentage of felonies. Annual filings for the most recent year include felony at 8,593, Misdemeanor at 15,477, Traffic at 129,334, General Civil at 4,923, small claims at 3,735, landlord/tenant at 11,490, and adult probation at 750. It is considered a large court within the State of Arizona. The Court uses a case management system initially developed by the Arizona Supreme Court in 1985 that currently operates on a DEC Alpha computer and is named the JP system for Justice of the Peace system. The JP system is used for all case types and has been integrated with an imaging application that retrieves stored images from CD-ROM servers. CD-ROMs for the imaging system are created using a system named  On-Target Information Technology Consulting  A3-18  6/13/00   Electronic Document Management Systems for the Arizona Courts  Touch Once. See the Traffic Imaging System report for a further description of Touch Once. The Court has two locations. The main courthouse houses court administration, courtrooms, and the public counters. The second location is called the Service Center that is used for receiving all traffic filings from agencies and for large filers such as attorney services and businesses. The Service Center also houses data entry operators for traffic citations and the Touch Once image scanning operation. Workflow Small claims are filed at public counters or over the Internet. Filings over the Internet accounted for 4% of all small claims filed in 1999. Internet Filing The public may access the Court's Internet site to file a small claim. After reading instructions, the first step is to provide a valid credit card for the fee associated with the filing. An online authorization is then performed by Cyber Cash, an Internet credit card processing company, which returns an approval or denial. If the transaction amount is approved, the user is then stepped through a form completion session. Upon completion of the form, the user is provided an emailed receipt that contains all of the text entered in the filing with an appended electronic signature that is unique to the text entered by the user. Simultaneously, an email is transmitted to a mailbox of a supervisor at the Service Center. The JP system and W eb server are also updated at this time. For more details, see the report Virtual Court Web Server Interface V2 Application & Database Design dated October 14, 1999. The bank and Internet processing fees are paid directly by the County.. Once the email notification of a small claim filing has been received by the court, the filing is printed. The printed copy of the filing is sent by certified mail, return receipts requested to the defendant by the Court. The document is then scanned into the Touch Once system. Public Counter Filing Small claims filings are accepted over the public counter along with any follow-up documents filed with the case. The first step is to enter data from documents into the JP system with the initial filing form being scanned into the Touch Once system prior to creating a file jacket. For court appearances, Hearing Officers require the use of paper files but it is hoped that they would use the electronic version once all documents of the case are scanned into Touch Once. In addition to small claims information available at the public counters, the public may access small claim data from the JP system over the Internet. There are no current plans to access images in the Touch Once system over the Internet although access over the Court's Intranet by staff and Hearing Officers is being planned. EDMS Opportunities Better use of the system would be achieved if the Hearing Officers could access the complete case file electronically and if they all could agree to use the electronic version instead of paper.  On-Target Information Technology Consulting  A3-19  6/13/00   Electronic Document Management Systems for the Arizona Courts  As for risks, the use of electronic versions of case files may reduce the productivity of Hearing Officers unless sufficient reengineering is incorporated into the implementation. Since the JP system would be the only interface, it may be difficult to simulate workflow and to provide sufficient access response time. The Internet filing component of this application has some elements that are worth considering for other e-filing applications. The approach to credit card authorization, signature authorization of the plaintiff along with the efficient and strong authentication method for the email receipt would provide an excellent way to eliminate the initial entry of small claim data. As for the CMS interface, the Court and vendor are developing plans to upgrade the system to use XML. Pat Jacobs, the Court Administrator, is the Chair of the Small Claims Committee for the NACM/COSCA initiative to develop a standard XML dictionary for courts.  On-Target Information Technology Consulting  A3-20  6/13/00   Electronic Document Management Systems for the Arizona Courts  Maricopa County Superior Court Marriage License Process couple completes application for marriage license clerk enters data in marriage license database couple reviews and signs affidavit, pays license fee clerk prints marriage license and receipts fee clerk prints batch index for marr. licenses issued * clerk sends index and affidavits to RMC *  clerk prints affidavit  marriage license and receipt completed affidavits marriage license database  to couple  marriage license batch index*  EDMS Opportunity: imaging the affidavits and routing via workflow application to RMC would eliminate steps marked with *  RMC receives affidavits and index  abstract prepaid? Yes RMC creates and sends abstract of marriage to couple  No  RMC updates database, files affidavits*  marriage officiator returns certificate of marriage  RMC records marriage  RMC files Certificate of Marriage with Affidavit**  RMC microfilms marriage licenses and affidavits  microfilm archive  Request for copy of marriage license, pay fee  certified copy required?  Yes  RMC clerk retrieves microfilm**  RMC clerk copies license, certifies  certified marriage license receipt  EMD Opportunity: Imaging the Certificate of Marriage would eliminate timeconsuming microfilm retrieval. Copies would be made from the EDMS**  No RMC clerk prints absract from database, receipts fee marriage license database  abstract receipt  to requestor  On-Target Information Technology Consulting  A3-21  6/13/00   Electronic Document Management Systems for the Arizona Courts  Pima County Consolidated Justice Courts Small Claims Workflow  Existing System EDMS Opportunities  Confirmation receipt to customer Plaintiff completes filing process Internet Filing EDMS Opportunity Eliminate the step of printing the electronic document for scanning at a later step. Create a COLD version that would include the electronic signature. Authorize credit card and complete form Small Claim Filing Scan Filing into Touch Once System  Email Notice to Service Center  Clerk retrieves filing and prints  Updated Touch Once Sys  Small Claim Filing  Updated JP  Updated Web Server  Initial Filing Initial Filing Enter into JP system Answers Other Documents Updated JP Initial Filing Scan into Touch Once System Answers Other Documents Prepare File Jacket Small Claim Case File Pending Small Claims  Public Counter Filing  Updated Touch Once Sys  On-Target Information Technology Consulting  A3-22  6/13/00   Electronic Document Management Systems for the Arizona Courts  Peoria Municipal Court City Ordinance Citations  Existing System EDMS Opportunities 2A Complaint  Complaint Form filed by compliance officer  Complaint entered into FACTS  Prepare file Jacket  Case File  Filed by Court Date  Updated FACTS  1A  Case File Inactive Files Yes If satisfied Updated FACTS Process Order No If Fail to Appear  No Active Files  Yes  Update FACTS  Updated FACTS  Updated Case File Prepare Petition to Default Notice to Ordninance officer If Fail to Appear after 30 days Add Copy of Notice to File Copy of Notice Prepare Defendant Notice  Yes  No Petition to Default 2A 1A  Defendant Notice  On-Target Information Technology Consulting  A3-23  6/13/00   Electronic Document Management Systems for the Arizona Courts  Civil Traffic - Mesa Municipal Court Data Entry of Complaints  Existing System EDMS Opportunity  Officer issues complaint Mesa Police Dept.  Court Copy of Complaint  Daily File  Officer is required to deliver complaints to station at end of shift. Court courier picks up the daily batches of complaints for data entry.  Def. Copy Citation Options Form  2A  Municipal Court  There is at most a two day backlog in the entry of complaints. Alll complaints are entered upon the closing of each month. From complaint issue to available in ACIST is a maximum of 4-5 days.  Enter Complaints in ACIST  Complaints  Civil Pending  Updated ACIST  On-Target Information Technology Consulting  A3-24  6/13/00   Electronic Document Management Systems for the Arizona Courts  Civil Pending Pull Complaint and enter into ACIS  Civil Traffic - Mesa Municipal Court Processing of Complaints Updated Complaint Terminated file  2A  If pay violation  Yes  Updated ACIST  End of Process  Complaints and any documentation are held on site for 3 to 4 months and then moved off site where they are held for one year after satisfaction. Court notifies vendor to destroy after this one year retention period  No ACIST Receipts  Accounting Receipt file  Defendant copy w/pay terms Civil Pending  If pay by payment  Yes  Defendant completes Financial Statement  Completed financial statement  Clerk Updates ACIST  Court Copy  No Traffic school transmits completion to court  Updated ACIST Yes Attend Traffic School Compl over Internt City Data Center Receives & updates ACIST Completion Pull List Pull Original from Pending file Completion Pull List Terminated file  If traffic school  No Case Log If attend Court Prepare notebook file for court Notebook of citations Attend Court Judge updates Citation & log Updated Case Log  Updated ACIST  Log File  Yes  Updated Notebook of citations  No FTA Defendant copy of Judgement  2A  Select for Judgement Processing  If def. Pays Yes 2A  Collections Proces  Updated ACIST  On-Target Information Technology Consulting  A3-25  6/13/00   Electronic Document Management Systems for the Arizona Courts  Flagstaff Justice Court Initial Appearance Court & Superior Court Bindover  Existing EDMS Opportunities  In-Custody worksheet Sheriff Booking Report Review for Jurisdiction If within jurisdiction Yes Prepare incustody woksdheet Booking report Crim. History Pretrial Report Release Cond. PCD form Prepare Defendant Package Initial Hearing Distribute Release Conditions  No Transfer  Proc. Misd.  Transfer to Misd. Clerk  No  If felony  In-Custody worksheet Preliminary Hearing Calendar for PH No If Indictment Yes If in-custody & Compl. Rec. 48 hrs Review Incustody for Complaint Received  Yes Case File FACTS entry & prep jacket Updated FACTS Transfer Def. Packet to Fel. Clerk  Case File  Yes  No Prepare Release form  Prepare file for transfer to Superior Transfer Case File  Release Form  Case File  Court Copies Defendant Released Enter into FACTS Inactive Case File  Inactive File  Court Copies End of process  Updated FACTS  On-Target Information Technology Consulting  A3-26  6/13/00   Electronic Document Management Systems for the Arizona Courts  MARICOPA SUPERIOR COURT - EARLY DISPOSITION COURT (CRIMINAL) Law Enforcement Agency goes to County Attorneyto issue complaint  Existing  EDMS Opportunity  County Attorney issues complaint  Police Liaison takes complaints to Clerk for logging  Police Liaison takes complaints to Commission for signature  Judge signs  Clerk gets complaints, prepares files  Files go to Court  The Law Enforcement Agency could file arrest reports/citations electronically with the County Attorney. The County Attorney could accept or reject electronically and issue complaints. *  Ideally, the complaint would be issued electronically by the County Attorney and it would be routed to the Clerk's office using workflow application. This would eliminate complaints having to be hand carried to the Clerk's office* *outside the court's control  Complaints scanned, indexed and routed electronically to Commissioner's in box  Law Enforcement Agency goes to County Attorneyto issue complaint  County Attorney issues complaint  Police Liaison takes complaints to Clerk for logging  EDMS Application  Case Management System  EDMS Opportunity: The goal of the early disposition court is quick case resolution. Electronic files eliminate manual processes and expedite resolution.  Judge accepts, affixes electronic signature, reroutes to JA for calendaring  JA routes to Clerk for docketing, preparation of hard copy file  Judge uses electronic case file before and during court  Minute entries, orders, other documents scanned  Available for on-site or internet viewing by all interested parties  On-Target Information Technology Consulting  A3-27  6/13/00   Electronic Document Management Systems for the Arizona Courts  AOC FOSTER CARE REVIEW BOARD Current Process Initiating documents filed by court, CPS, AG DCATS & paper case file opened/ updated 5 months later file retrieved and given to Program Specialist to prepare for Board hearing  Existing EDMS Opportunities  Notice to Board Program Specialist gives file to support staff to copy and mail packets to Board Members Files returned to Program Specialist DCAT download to laptop Files taken to Board Hearings  Other case documents  DCATS  Board reviews packets and handwrites notes at hearing  Board Decisions  Program Specialist prepares written Findings & Recommendations Upload to DCAT  Files given to support staff to copy and mail Findings  Files to file room Subsequent documents filed for six-month review Process begins again  New Process Initiating documents filed by court, CPS, AG Documents scanned, indexed, discarded. DCATS case opened,/updated 5 months later Program Specialist prepares on-line for Board hearing;  Hard copy Board Packet CD-ROM Board Packet Notice to Board  Board members review packets.  Board Decisions  Other case documents EDMS System DCATS Process begins again for 6 months review  Online retrieval and viewing  Program Specialist prepares written Findings & Recommendation, routes to supervisor for review  Supervisor reviews Findings  Findings indexed and stored in repository, printed, mailed. DCATS updated.  On-Target Information Technology Consulting  A3-28  6/13/00   Electronic Document Management Systems for the Arizona Courts  PIMA SUPERIOR COURT Documents received in Civil and Criminal Divisions Documents copied by Clerk's Office & picked up by Calendar Services Documents manually processed and entered in case tracking systems by Calendar Services  Existing  EDMS Opportunities  Imaging preps, sorts, scans, routes electronically to indexing  Audited, Rejected or Indexed  Night crew files documents  Documents received in Probate Division  Documents entered into CACTIS by Probate Clerk's Office  Case Tracking Systems CACTIS 803 and COATS Domestic Relations  Imaging database  Image retrieval and viewing  Papers sent to night crew for filing Electronically routed for auditing, indexing, docketing in case management system  EDMS Opportunity: Scanning documents at intake, routing via workflow application, integrating with case management system would give Calendar Services and others prompt access to documents (all case types)for processing, eliminate redundancies and allow viewing by interested parties.  Documents received in Civil, Probate and Criminal Divisions  Documents prepped, sorted, scanned  Electronic images routed to Calendar Services  Calendar Services accepts documents and calendars hearing  Public, attorney access for viewing and e-filing  On site access by court, clerk's office and public  EDMS database  Case Management System  Internet  On-Target Information Technology Consulting  A3-29  6/13/00   Electronic Document Management Systems for the Arizona Courts  APPENDIX 4 SPECIFICATIONS FOR LANs AND WANs  On-Target Information Technology Consulting  6/13/00   Electronic Document Management Systems for the Arizona Courts  SPECIFICATIONS FOR LANs AND WANs The following are standards that should be adopted as part of the EDMS project procurement and implementation. 0.1 National Electrical Code (NEC):    0.0. Article 250: Grounding Article 770: Optical Fiber Cable Article 800: Communications Circuits.  American National Standards Institute (ANSI):                C84.1: Standard Nominal AC System Distribution Voltage Ranges NFPA 70: National Electrical Code T1.617 Frame Relay Link Annex D Management Interface Async-Sync PPP automatic conversion X3.1: Synchronous signaling rates for data transmission X3.4: Code for information interchange X3.15: Bit sequencing of the American National Standard Code for Information Interchange in a serial-by-bit transmission X3.16: Character structure and character parity sense for serial-by-bit data communication in the American National Standard Code for Information Interchange X3.36: Synchronous high speed data signaling rates between data terminal equipment and data communication equipment Code extension techniques for use with 7-0 bit coded character set of American National Standard Code for Information Interchange X3.44: Determination of performance of data communication systems X3.66: Advanced data communication control procedures X3.79: Determination of performance of data communication systems that use bit-orientated control procedures X3T9.5 SNMP/SMT proxy X3T9/90 FDDI Station Management (SMT) Revision 6.2/7.3  0.3  American Society of Testing Materials (ASTM):  Materials testing specifications as required. ATM specifications and standards.  0.4  ATM Forum,       Data Exchange Specification LAN Emulation over IP (LANE) SVC UNI 3.0, 3.1 Anchorage Accord Specifications:  Core Foundations Specifications  Service Foundation Specifications Multiprotocol over ATM (MPOA)  On-Target Information Technology Consulting  A4-1  6/13/00   Electronic Document Management Systems for the Arizona Courts  0.5  CCITT Standards        X.21 DTE to DCE interface for synchronous operation X.21bis RS232 X.25 DTE to DCE interface for terminals V.25bis Automatic call/ answering signaling interface on general PSTN X.29 V.35 ISDN Signaling  North American National ISDN  AT&T 5ESS custom  Northern Telecom DMS 100  0.6  Electronic Industries Association (EIA):        RS-354: Standard Colors for Identification and Coding RS-363: Standard for specifying signal quality for transmitting and receiving data processing terminal equipment using serial data transmission at the interface with non-synchronous data communication equipment RS-366 A: Interface between data terminal equipment and automatic calling equipment for data communications RS-404: Standard for start-stop signal quality between data terminal equipment and nonsynchronous data communication equipment RS-422 A: Electrical characteristics of balanced voltage digital interface circuits RS-423 A: Electrical characteristics of unbalanced voltage digital interface circuits RS-449: General purpose 37-position and 9-position interface for data terminal equipment and data circuit-terminating equipment employing serial binary data interchange  0.7  Federal Communications Commission (FCC):  Rules and Regulations, 1979.  Part 68  0.8 0.9  Institute of Electrical and Electronic Engineers (IEEE): IEEE 802.X: Networking Stds.        802.1p/q VLAN/CoS 802.3 Ethernet 802.3p/q 802.3u Fast Ethernet 802.3z Gigabit Ethernet 802.4 Token Bus 802.5 Token ring  0.10  Internet Engineering Task Force (IETF):             RF RF RF RF RF RF RF RF RF RF RF RF C C C C C C C C C C C C 768 783 791 792 793 821 826 854 855 856 857 858 User Datagram Protocol (UDP) Trivial File Transfer Protocol (TFTP) Internet Protocol (IP) Internet Control Message Protocol (ICMP) Transmission Control Protocol (TCP) Simple Mail Transfer Protocol (SMTP) Ethernet Address Resolution Protocol (ARP) Telnet Telnet option specification Telnet binary transmission Telnet echo option Telnet suppress go ahead option  On-Target Information Technology Consulting  A4-2  6/13/00   Electronic Document Management Systems for the Arizona Courts                                                             RFC 894 IP datagrams over Ethernet networks RFC 903 Reverse ARP RFC 906 Bootstrap loading using TFTP RFC 919 Broadcast Internet datagrams RFC 922 Broadcast Internet datagrams in the presence of subnets RFC 950 Internet standard subnetting procedure RFC 951 Bootstrap Protocol (BootP) RFC 959 File Transfer Protocol RFC 1009 Requirements for Internet gateways RFC 1027 Proxy ARP RFC 1034/5 Domain names RFC 1042 IP datagrams over IEEE 802 networks RFC 1054 IP Multi-cast RFC 1058 Routing Information Protocol (RIP) RFC 1108 Revised U.S. DoD security options for IP RFC 1122 Requirements for Internet hosts (routers) RFC 1141 Incremental updating of the Internet checksum RFC 1155 Structure and identification of MIBs RFC 1156 MIB I RFC 1157 SNMP RFC 1188 IP datagrams over FDDI networks RFC 1191 Path MTU discovery RFC 1195 Use of OSI IS-IS for routing TCP/IP RFC 1209 Transmission of IP datagrams over SMDS RFC 1212 Concise MIB definitions RFC 1213 MIB II (with extensions) RFC 1215 (Trap Definition Conventions) RFC 1220 PPP extensions for bridging RFC 1231 Token Ring MIB RFC 1243 AppleTalk MIB RFC 1253 OSPF version 2 MIB (with extensions) RFC 1236 Defense Data Network (DDN) RFC 1256 ICMP router discovery RFC 1271 RMON MIB, alarm and event groups RFC 1284 Ethernet-like MIB RFC 1285 FDDI MIB (with extensions) RFC 1286 Bridge MIB (with extensions) RFC 1293 Inverse ARP RFC 1294 Multi-protocol interconnect over frame relay RFC 1304 SMDS MIB RFC 1315 Frame relay DTE MIB (with extensions) RFC 1332 PPP Internet Protocol Control Protocol (IPCP) RFC 1334 Password Authentication Protocol (PAP): Challenge Handshake Authentication Protocol (CHAP) RFC 1338 Supernetting CIDR RFC 1347 TCP and UDP with Bigger Addresses (TUBA) RFC 1350 TFTP revision 2 (obsoletes RFC 783) RFC 1354 IP forwarding MIB RFC 1356 Multiprotocol Interconnect on X.25 and ISDN in packet mode (obsoletes RFC 877) RFC 1376 PPP DECnet Phase IV Control Protocol RFC 1377 PPP for OSI network layer control RFC 1398 Ethernet MIB RFC 1463 Bridge MIB RFC 1490 3270 Emulation RFC 1512 SNMP/FDDI MIB RFC 1516 Repeater MIB RFC 1577 Classical IP over ATM RFC 1597 Private internet addresses RFC 1633 Integrated Services in the Internet Architecture  On-Target Information Technology Consulting  A4-3  6/13/00   Electronic Document Management Systems for the Arizona Courts                0.11  RFC 1661 PPP RFC 1717 Multilink PPP RFC 1771 Border Gateway Protocol-4 (BGP-4) RFC 1772 Application of BGP to the Internet RFC 1918 IP Address Allocation for Private Internets RFC 1824 IP Multi-cast RFC 1944 Benchmarking methodology for network Interconnect Devices (Bradner) RFC 1962 PPP Compression Control Protocol (CCP) RFC 1968 PPP Encryption Control Protocol (ECP) RFC 1973 PPP in Frame Relay RFC 1994 Password Authentication Protocol (PAP): Challenge Handshake Authentication Protocol (CHAP) RFC 2328 Open Shorted Path First (OSPF) V2 RFC 2427 Multiprotocol Interconnect over Frame Relay RFC 2453 RIP v2  ISO/OSI Standards            ISO ISO ISO ISO ISO ISO ISO ISO ISO ISO ISO 7498 OSI Reference Model 7498/Ad1 Addendum 1: connectionless-mode transmission 8208 X.25 packet level for DTEs 8348 Addendum 2 - NSAP Addressing 8473 Connectionless Network Protocol (CLNP) 8648 International Organization of the Network Layer 8802/2 Logical Link Control (LLC) 8802/3 Carrier Sense Multiple Access with Collision Detection (CSMA/CD) 8802/5 Token Ring access method 9542 End System to Intermediate System (ES-IS) 10589 Intermediate System to End System (IS-ES)  0.12  Occupational Safety and Health Administration (OSHA)  All safety rules and regulations.  0.13  Underwriters Laboratories, Inc. (UL):   All equipment furnished under this work shall be listed and exhibit the label of the Underwriters Laboratories, Inc., except for those equipment or systems for which the UL has not established listing criteria. UL 1950: Electronic Equipment Power Supplies.  0.14  Application Protocols/Languages:   TCP/IP, current Ver and IPng support SSL, Secure Sockets Layer (encrypted data over the Web)  On-Target Information Technology Consulting  A4-4  6/13/00   Electronic Document Management Systems for the Arizona Courts  APPENDIX 5 REQUEST FOR INFORMATION QUESTIONNAIRES SUPPLIED BY EDMS VENDORS  On-Target Information Technology Consulting  6/13/00   Electronic Document Management Systems for the Arizona Courts  Software Evaluation Company: Altris Software Inc. Person Interviewed: Bryan Christie Date: 3/13/00 Question            Public or private company Market focus/audience Govt. clients? Products Names and version number Release date of products Next release or new product date (timeframe) Licenses Worldwide Market Cap Employees License Prices References  govt. FEATURES 2  Altris Response            Public Regulatory, Engineering, Manufacturing, Government Yes: Local, County, State (inc. Courts) Altris eB v12  V 12.1 release due April Total licenses approx 250,000 57 Server 20 users $11k  1000 user $300k; client $49-$190 Salt Lake County; City of Winston Salem; Mesa County ALTRIS RESPONSE  FUNCTIONAL CATEGORY Document Management and Capture Electronic ""objects""      Import utilities     COLD XML Scanning      stores, manages, retrieves and displays wide variety of electronic objects within the same folders, including TIFF, MS Word, Word Perfect, XML, Adobe Acrobat PDF, MPEG, JPEG, AVI, WAV, ASCII text, raster scanned images, RTF, G3 and G4 fax and other common file formats supports document renditioning (e.g., from word processing to Adobe Acrobat PDF format or from TIFF to PDF or Word Processing to TIFF, etc.) import utilities to accept and incorporate documents not created or scanned through native EDMS software (e.g., COLD data, faxed documents, PDF or XML documents from efiling, etc.); ""drag and drop icon"" method for individual documents and batch import desirable captures print streams from application systems (reports, fee receipts, etc.) supports XML documents in repository and for data exchange scans bi-tonal, gray-scale, and color images  scans fingerprints and handwriting produces/uses standard TIFF V6 CCITT G4 files without modification    Yes  Fully supported    Yes  Some document renditioning is provided for. TIFF via OCR/FTR to ASCII/PDF Yes  Fully supported using eB Bulk Loader, eB COLD, XML support.         Yes  fully supported Yes  via eB COLD Yes  XML documents supported. XML strategy in development. Yes  Yes  dependant on scanner  Yes  2  Features are mandatory unless otherwise noted.  On-Target Information Technology Consulting  A5-1  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES    2  ALTRIS RESPONSE   Yes  dependant on scanner eB Capture is a batch scanning application built on Kofax Image Controls. Scanner support via Kofax. Yes  eB Capture Yes  Dependant on scanner Yes  dependant on scanner Yes  eB treats a document made up of multiple objects each may have differing resolutions Yes Yes Yes Yes  eB Capture allows documents to be forwarded via a workflow type activity to Indexing station/s Yes Yes Yes Yes Yes Yes Yes Yes  eB supports MDI so multiple pages can be displayed in separate windows and multi-page documents (PDF/TIFF) have tabs to move between pages and to first/last page. Not at this time Yes Yes Yes Yes  Kofax tools Yes Dependent on document quality Yes Yes           Image Enhancement and Viewing         supports simplex and duplex scanning supports wide variety of scanners from low speed (individual desktop units) to high-speed production scanners; flat-bed and page feed scanners supports batch scanning user-selectable scanning density adjustable on-the-fly from 200 dpi up bar code recognition document may contain pages of different dpi resolution 2 step scan/commit process for saving images delete, re-scan and insert pages into document before committing to disk display pages on screen during scanning quality control functions may be performed at scanning station or by another user before committing document to disk supports high-volume scanning (up to 25,000 pages per day) scanning operation is software-controlled deskew, reduce background ""noise"" (dots, smudges), cropping and other image clean-up and other enhancement techniques rotate images 90% and 180% zoom in/zoom out fit page to screen thumbnail views of document pages uses a variety of page display methods and supports user in moving through document in a variety of ways, such as: display pages one at a time, multiple pages on screen at once, select desired page easily, go to first/last page bookmark pages for viewing multiple document windows open at once supports viewing of common file formats without launching application that created them (viewers), including images can recognize and launch appropriate application for any object type for which software does not have viewer automatic forms detection and processing 32-bit recognition engine supports English (mandatory); other languages (optional) conversion achieves 99% or greater accuracy scan document once  dual output (to produce OCR and imaging files) support multiple indexes for different types of documents                           Indexing             OCR  On-Target Information Technology Consulting  A5-2  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES    2  ALTRIS RESPONSE   Yes  no limit Yes  support up to 10 index fields for documents Links main document and attachments for simultaneous/separate retrieval  Document Access Services Navigation      Mobile Support Searching               supports an organizational hierarchy that can be mapped to case type, case file, case file subsection, document, and page supports transparent user access to multiple, distributed document repositories across LANs and WANs3 personal bookmarks for frequently used items may be set, changed and removed by users supports hyper-text links within documents download files to a laptop and view documents off-line (read-only)4 uses a robust search engine such as Fulcrum or Verity search single document or document repository based on user-defined criteria (index attributes or full-text) transparent search across multiple repositories and servers provides a list of matching documents (repository search), listed by relevancy5 save document search queries for re-use documents may be searched by index values (document attributes) full text documents may be searched by phrases, word proximity search; wild cards and Boolean searches supports fuzzy searching (optional) highlight search phrase in text display software optimized for rapid search and retrieval on multiple very large document repositories (125 million pages or more)                  Yes  uses an Explorer style interface with a folder/document/page hierarchy Yes- eB is a full 3-tier architected system. Not at this time No via Checkout Yes - Fulcrum Yes  Combined search using Attributes and FTR Limited to FTR at this time Yes  FTR search only Yes Yes Yes Yes Not at this time. Due soon Yes  Document and Content Management Library services        check in/check out of documents version control lock documents version synchronization and history supports creating, viewing, printing, deletion        Ye Ye Ye Ye  s s s s  Annotation 3 4  Yes  A user need not know the physical or logical location of a document in order to access it. This feature would enable judges and others to take documents home via a laptop without having to remove the documents from the courthouse. 5 The likelihood of document being what the user wanted.  On-Target Information Technology Consulting  A5-3  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES  2  ALTRIS RESPONSE   Electronic Signature    Records Storage      and other manipulation of ""sticky notes"" on documents, pages and folders without altering content of documents, including ""read-only"" documents and images supports various security levels for notes (create, view, delete, modify, print, etc.) supports colored notes (optional) support for electronic approval process integrated with workflow capabilities support for third-party software supports encryption supports near-line (magnetic and WORM storage) and off-line storage (tape) supports Hierarchical Storage Management techniques using user-defined business rules supports various vendor's high capacity storage platforms  magnetic disk (native file systems), jukeboxes, network attached devices and SCSI devices (e.g.,CD-ROM tower) supports mirroring /RAID supports multiple repositories across LAN and WAN index replication and rollback           Yes Yes Yes  eB Workflow is built around Staffware. Yes  based on definition of requirements Yes Yes Yes  Uses 3rd party OTG HSM software Yes          Yes Yes Yes  eB is built around MS MTS and MSMQ for document rollback and uses SQL databases that support index rollback/replication Yes  via HSM tool Yes  eB Print Server Yes Yes  Subject to further clarification  Records Management Printing/Output       supports archiving/destruction (deleting) of records based on user-defined criteria (e.g., records purging and destruction schedules) supports remote print/fax services easy to print by page or by document or other object (case file?) supports output to COM (Computer-Output Microfilm)       Workflow Management Workflow           graphical and list-based user views of work items (tasks, folders, documents, etc.) supports structured, production workflow processes (light or medium complexity) database-driven product supports serial, parallel and alternative (if. . .then) routing of electronic objects work process management capabilities include: workflow role definition, task definition, task assignment, task assembly, tracking and monitoring of task status; production statistics supports sign off/approval process and electronic signature workflow across Intranet (required) or Internet        Yes  eB Workflow uses Staffware Yes Yes Yes Yes     Yes Yes  On-Target Information Technology Consulting  A5-4  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY Process Design/Modeling  FEATURES    2  ALTRIS RESPONSE         Workflow-Electronic Mail Integration      (optional) graphical modeling and design tool kit approach preferred supports light to medium complexity routing processes MS Outlook integration for messaging (mandatory) supports other common SMTP-based mail systems supports event notification via user-defined triggers easy end-user configuration/customization of user interface using graphical tools software includes prototypes, models and outof-the box applications that may serve as examples or be modified restrict access to viewing and printing documents at the page, document, case file and case type level based on user attributes6 provide an audit trail for viewing certain restricted documents ability to assign various document manipulation and viewing options to users (e.g., document add, modify, delete and view functions) support individual user, encrypted passwords and forced periodic change of password notify systems administrator of attempted security breaches log-off user after several incorrect password attempts can use O/S security schema (optional) supports multiple servers across a distributed network integrated back-end administration for all servers and document repositories on distributed network supports Microsoft NT on various Intel-based servers (mandatory) Supports other leading O/S such as AIX or Novell IBM PC and compatible desktop or laptop (mandatory) MS WIN95/98 and NT for fat clients support  Yes Yes Yes  optional Outlook client to view work items as well as using any MAPI client for messaging Yes Yes Yes Yes  Workflow Application Development     Document Security                       Yes Yes Yes Yes Not standard feature Yes Yes  MTS roles Yes Yes Yes  eB is built around MS Back Office Yes - eB requires NT as application server but can operate on any network that supports NT Servers Yes Yes  prefer minimum Win98  Servers        Clients and desktops     6  For example: (1) the judge who sealed a record may access the document (or case file) or may grant access to another user based on a court order; (2) adoption files and documents may be viewed only by a judicial officer or specified staff; (3) criminal histories are sealed in the file. Security must also be implemented in conjunction with the case management system security.  On-Target Information Technology Consulting  A5-5  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES   2  ALTRIS RESPONSE                              Yes Yes Yes Yes Yes Yes Yes N/A Yes Fault tolerance built around use of MTS and MSMQ Yes IP Yes No  minimum Oracle 8.05 or MS SQL Server 7.0 Yes Not at this time Yes Yes Yes  based on using MTS roles Using NT Yes Define further Yes Yes  via ODMA ODMA Yes No  MS direction No  COM and DCOM Yes  WfMC  System Architecture             Network Communications Protocols Databases Supported      Support for common browsers for thin clients client runs on any platform 32 bit application highly scalable from a few users to thousands of users across a distributed network intended for enterprise-wide use supports real-time distributed processing over frame relay circuits rapid retrieval can be expected to yield sub 2 second response time given appropriate infrastructure 3 tiered architecture (preferred) two-tiered (acceptable with plans for migration to three-tired within 1 yr. Product must be under development now) web server support fault-tolerant features such as replication, automatic cut-over on failure scalable to thousands of users and thousands of simultaneous processes TCP/IP (mandatory; others (optional) uses an ANSI SQL relational database (mandatory); supports Informix (optional)  Systems Administration       Integration  Standards Supported  unified systems administration for all modules browser-based administration tools (preferred) audit tracking capabilities convenient, robust user/group management functions (graphical tools preferred)  import/export of existing user/groups  session/intruder monitoring  robust, highly configurable user security features  screen-level integration with modern clientserver applications  API tool kit for application development and integration Integration with desktop office products  Supports ODMA or WebDAV for integration with desktop applications ODBC connectivity for use with reporting and data analysis tools (e.g., Crystal reports, ACCESS, Excel)  Supports DMA  Support CORBA  Other standards supported (WfMC, others??)  On-Target Information Technology Consulting  A5-6  6/13/00   Electronic Document Management Systems for the Arizona Courts  EDMS Software RFI Company: Documentum Person Contacted: Monique Broussard Date: 3/17 Question   Public or private company  Market focus/audience  Govt. clients?  Products Names and version number  Release date of products  Next release or new product date (timeframe)  Licenses Worldwide  Market Cap  Employees  License Prices  References  govt. FUNCTIONAL CATEGORY Document Management and Capture Electronic ""objects"" FEATURES  Documentum Response   Public  DCTM 74.5  Pharmaceutical/Business and Govt Services  See Attached.  4I, Iquality,   Most recent July 99 Due April `00     800 Global Customers 1.5 Billion 650 Employees $600 per seat See Attached    7  See Attached  stores, manages, retrieves and displays wide variety of electronic objects within the same folders, including TIFF, MS Word, Word Perfect, XML, Adobe Acrobat PDF, MPEG, JPEG, AVI, WAV, ASCII text, raster scanned images, RTF, G3 and G4 fax and other common file formats supports document renditioning (e.g., from word processing to Adobe Acrobat PDF format or from TIFF to PDF or Word Processing to TIFF, etc.) import utilities to accept and incorporate documents not created or scanned through native EDMS software (e.g., COLD data, faxed documents, PDF or XML documents from efiling, etc.); ""drag and drop icon"" method for individual documents and batch import desirable captures print streams from application systems (reports, fee receipts, etc.) supports XML documents in repository and for data exchange scans bi-tonal, gray-scale, and color images  scans fingerprints and handwriting       We Comply  Import utilities      We Comply   COLD XML Scanning          We Comply. Integration with Insci We Comply. We Comply. Third Party  7  Features are mandatory unless otherwise noted.  On-Target Information Technology Consulting  A5-7  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES     7  produces/uses standard TIFF V6 CCITT G4 files without modification supports simplex and duplex scanning supports wide variety of scanners from low speed (individual desktop units) to high-speed production scanners; flat-bed and page feed scanners supports batch scanning user-selectable scanning density adjustable on-the-fly from 200-600 dpi bar code recognition document may contain pages of different dpi resolution 2 step scan/commit process for saving images delete, re-scan and insert pages into document before committing to disk display pages on screen during scanning quality control functions may be performed at scanning station or by another user before committing document to disk supports high-volume scanning (up to 25,000 pages per day) scanning operation is software-controlled deskew, reduce background ""noise"" (dots, smudges), cropping and other image clean-up and other enhancement techniques rotate images 90% and 180% zoom in/zoom out fit page to screen thumbnail views of document pages uses a variety of page display methods and supports user in moving through document in a variety of ways, such as: display pages one at a time, multiple pages on screen at once, select desired page easily, go to first/last page bookmark pages for viewing multiple document windows open at once supports viewing of common file formats without launching application that created them (viewers), including images can recognize and launch appropriate application for any object type for which software does not have viewer automatic forms detection and processing 32-bit recognition engine supports English (mandatory); other languages (optional) conversion achieves 99% or greater accuracy scan document once  dual output (to produce OCR and imaging files)      We Comply.  We Comply. We Comply.           Image Enhancement and Viewing                          We Comply. We Comply. We Comply. We comply. We Comply. We Comply. We Comply. We Comply. We Comply We Comply. We Comply. We We We We We Comply. Comply. Comply. Comply. Comply.                    We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply.  OCR  On-Target Information Technology Consulting  A5-8  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY Indexing  FEATURES     7  support multiple indexes for different types of documents support up to 10 index fields for documents Links main document and attachments for simultaneous/separate retrieval      We Comply. We Comply. We Comply.  Document Access Services Navigation      Mobile Support Searching               supports an organizational hierarchy that can be mapped to case type, case file, case file subsection, document, and page supports transparent user access to multiple, distributed document repositories across LANs and WANs8 personal bookmarks for frequently used items may be set, changed and removed by users supports hyper-text links within documents download files to a laptop and view documents off-line (read-only)9 uses a robust search engine such as Fulcrum or Verity search single document or document repository based on user-defined criteria (index attributes or full-text) transparent search across multiple repositories and servers provides a list of matching documents (repository search), listed by relevancy10 save document search queries for re-use documents may be searched by index values (document attributes) full text documents may be searched by phrases, word proximity search; wild cards and Boolean searches supports fuzzy searching (optional)11 highlight search phrase in text display software optimized for rapid search and retrieval on multiple very large document repositories (125 million pages or more)                  We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply.  Document and Content Management Library services     check in/check out of documents lock documents     We Comply. We Comply.  A user need not know the physical or logical location of a document in order to access it. This feature would enable judges and others to take documents home via a laptop without having to remove the documents from the courthouse. 10 The likelihood of document being what the user wanted. 11 Less exact search method that relies on context interpretation to find probable ""matches."" Useful when user does not know exact matching string criteria. 9  8  On-Target Information Technology Consulting  A5-9  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY Annotation  FEATURES   7   Electronic Signature         Records Storage    Records Management Printing/Output      Workflow Management Workflow  supports creating, viewing, printing, deletion and other manipulation of ""sticky notes"" on documents, pages and folders without altering content of documents, including ""read-only"" documents and images supports various security levels for notes (create, view, delete, modify, print, etc.) supports colored notes (optional) support for electronic approval process integrated with workflow capabilities support for third-party software supports encryption supports near-line (magnetic and WORM storage) and off-line storage (tape) supports Hierarchical Storage Management techniques using user-defined business rules supports various vendor's high capacity storage platforms  magnetic disk (native file systems), jukeboxes, network attached devices and SCSI devices (e.g.,CD-ROM tower) supports mirroring /RAID supports multiple repositories across LAN and WAN index replication and rollback supports archiving/destruction (deleting) of records based on user-defined criteria (e.g., records purging and destruction schedules) supports remote print/fax services easy to print by page or by document or other object (case file?) supports output to COM (Computer-Output Microfilm)    We Comply.           We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply.          We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply.          Process Design/Modeling   graphical and list-based user views of work items (tasks, folders, documents, etc.) supports structured, production workflow processes (light or medium complexity) database-driven product supports serial, parallel and alternative (if. . .then) routing of electronic objects work process management capabilities include: workflow role definition, task definition, task assignment, task assembly, tracking and monitoring of task status; production statistics supports sign off/approval process and electronic signature workflow across Intranet (required) or Internet (optional) graphical modeling and design tool kit        We Comply. We Comply. We Comply. We Comply. We Comply.      We Comply. We Comply. We Comply.  On-Target Information Technology Consulting  A5-10  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES   7  Workflow-Electronic Mail Integration      Workflow Application Development     approach preferred supports light to medium complexity routing processes MS Outlook integration for messaging (mandatory) supports other common SMTP-based mail systems supports event notification via user-defined triggers easy end-user configuration/customization of user interface using graphical tools software includes prototypes, models and outof-the box applications that may serve as examples or be modified restrict access to viewing and printing documents at the page, document, case file and case type level based on user attributes12 provide an audit trail for viewing certain restricted documents ability to assign various document manipulation and viewing options to users (e.g., document add, modify, delete and view functions) support individual user, encrypted passwords and forced periodic change of password notify systems administrator of attempted security breaches log-off user after several incorrect password attempts can use O/S security schema (optional) supports multiple servers across a distributed network integrated back-end administration for all servers and document repositories on distributed network supports Microsoft NT on various Intel-based servers (mandatory) Supports other leading O/S such as AIX or Novell IBM PC and compatible desktop or laptop (mandatory) MS WIN95/98 and NT for fat clients support Support for common browsers for thin clients client runs on any platform 32 bit application         We Comply. We Comply. We Comply. We Comply. We Comply. We Comply.  Document Security                          We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply.  Servers       Clients and desktops      System Architecture 12    For example: (1) the judge who sealed a record may access the document (or case file) or may grant access to another user based on a court order; (2) adoption files and documents may be viewed only by a judicial officer or specified staff; (3) criminal histories are sealed in the file. Security must also be implemented in conjunction with the case management system security.  On-Target Information Technology Consulting  A5-11  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES           7  Network Communications Protocols Databases Supported Systems Administration             highly scalable from a few users to thousands of users across a distributed network intended for enterprise-wide use supports real-time distributed processing over frame relay circuits rapid retrieval can be expected to yield sub 2 second response time given appropriate infrastructure 3 tiered architecture (preferred) two-tiered (acceptable with plans for migration to three-tired within 1 yr. Product must be under development now) web server support fault-tolerant features such as replication, automatic cut-over on failure scalable to thousands of users and thousands of simultaneous processes TCP/IP (mandatory; others (optional) Uses an ANSI SQL relational database Supports Informix (optional) Unified systems administration for all modules Browser-based administration tools (preferred) Audit tracking capabilities Convenient, robust user/group management functions (graphical tools preferred) Import/export of existing user/groups Session/intruder monitoring Robust, highly configurable user security features Screen-level integration with modern clientserver applications  API tool kit for application development and integration  Integration with desktop office products  Supports ODMA or WebDAV for integration with desktop applications ODBC connectivity for use with reporting and data analysis tools (e.g., Crystal reports, ACCESS, Excel) Supports DMA Supports CORBA Other standards supported (WfMC, others??)                       We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We We We We We We Comply. Comply. Comply. Comply. Comply. Comply.  We Comply. We Comply. We Comply. We Comply.    We Comply. We Comply. We Comply. We Comply. We Comply. We Comply. We Comply.  Integration    Standards Supported           On-Target Information Technology Consulting  A5-12  6/13/00   Electronic Document Management Systems for the Arizona Courts  Software Evaluation EDMS RFI Company: FileNET Corporation Contacts: Suzanne Ernst sernst@filenet.com, Terrence Sciortino, Sales Representative and Steve Kelly, Systems Consultant 480-947-8400 Date: 3/2/2000  Question   Public or private company  Market focus/audience    Govt. clients?    Products Names and version number    Release date of products  FileNET Response   Public (NASDAQ: FILE)  FileNET Corporation is an industry leader in providing Web-based software solutions that help corporations and government organizations manage their business information and work processes more productively. Our Panagon line of products allows users to easily access, edit, process, organize, secure, store, and archive documents in any form in both Webbased and client/server environments. We have solutions in the following industries: Government, Finance, Insurance, Manufacturing, Utilities, Telecommunications, Pharmaceutical, Oil & Gas, Chemical, and AEC (Architectural, Engineering & Construction).  FileNET is installed in more than 400 government agencies worldwide. This list includes: the Industrial Commission of Arizona, the Orange County Superior Court, the State of Maryland, the US Postal Service, the Nuclear Regulatory Commission, the Australian Taxation Office, the Saudia Arabia Ministry of Public Works and Housing, the New York State Workers Compensation Board, the Kansas Division of Vehicles, Sacramento County, and the Tennessee Valley Authority.  Panagon IDM Image Services 3.5  Panagon IDM Content Services 5.1  Panagon IDM Web Services 3.0  Panagon IDM Desktop 3.0  Panagon IDM Capture Professional 2.03  Panagon IDM Capture Desktop 3.0  Panagon IDM Visual WorkFlo 3.02  Panagon IDM Report Manager 4.0  Panagon Web Publisher 4.0  Panagon IDM Image Services 3.5 (released 12/99; initial release 1984)  Panagon IDM Content Services 5.1 (released 12/99; initial release 1991)  Panagon IDM Desktop 3.0 (released 12/99; initial release 1998)  Panagon IDM Capture Professional 2.03 (released 7/99; initial release 1998)  Panagon IDM Capture Desktop 3.0 (released 12/99)  Panagon IDM Visual WorkFlo 3.02 (released 4/99; initial release 1994)  Panagon Report Manager 4.0 (released 12/99; initial release 12/98) Panagon IDM Web Services 3.0 (released 12/99; initial release 12/97) Panagon Web Publisher 4.0 (released 8/99; initial release 11/98)      Panagon Panagon Panagon Panagon Panagon IDM IDM IDM IDM IDM Image Services  Content Services Desktop  Target Capture  Target WorkFlo  Target Target Q4 2000  Target Q4 2000 Q4 2000 Q2 2000 Q3 2000    Next release or new product date (timeframe)  On-Target Information Technology Consulting  A5-13  6/13/00   Electronic Document Management Systems for the Arizona Courts      Licenses Worldwide Market Cap Employees License Prices  Panagon Web Publisher  Target Q3 2000    Note: All stated release timeframes are estimates and not firm.  1M+  $1.34B (3/1/2000)  1,700  $45,000 - IDM Services (Assumes Enterprise Edition, Qty 1)  $3,800 - IDM Services Dedicated SLU - User License (Qty 1)  $5,500 - IDM Services Concurrent SLU - User License (Qty 1)  $2,000 - Visual WF Prof. Desktop (Qty 1)  $600 - Visual WF Dedicated SLU - User License (Qty 1)  $900 - Visual WF Concurrent SLU - User License (Qty 1)  $15,000 - IDM Capture Professional (Assumes Medium Volume, Qty 1)  $6,000 - IDM Capture Desktop (scanning < 10,000 pages/day into Content Services Repositories, Qty 1)  $1,000 - Report Manager Dedicated SLU - User License (Qty 1)  $1,500 - Report Manager Concurrent SLU - User License (Qty 1) 1. 2. 3. 4. Prices based on list price; quantity discounts are not applied. Enterprise Edition of IDM Services includes IDM Image Services, IDM Content Services, Report Manager, and Visual WorkFlo server components. IDM Services SLU includes dedicated or shared access to IDM Image Services, IDM Content Services, Report Manager, and Visual WorkFlo repositories. Shared license ratios are determined in conjunction with FileNET. Report Manager SLU's allows for deployment in thick or thin client environments  Industrial Commission of Arizona  State of Maryland, Worker's Compensation Commission  State of Kansas, Department of Revenue    References  govt.  Note: Others available as needed.  FUNCTIONAL CATEGORY Document Management and Capture Electronic ""objects""  FEATURES  13  FILENET REPONSE      Import utilities    stores, manages, retrieves and displays wide variety of electronic objects within the same folders, including TIFF, MS Word, Word Perfect, XML, Adobe Acrobat PDF, MPEG, JPEG, AVI, WAV, ASCII text, raster scanned images, RTF, G3 and G4 fax and other common file formats supports document renditioning (e.g., from word processing to Adobe Acrobat PDF format or from TIFF to PDF or Word Processing to TIFF, etc.) import utilities to accept and incorporate documents not created or scanned through native EDMS software (e.g., COLD data, faxed documents, PDF or XML documents from e-    Yes  Supported. FileNET can store and manage virtually any electronic document including those listed here.      Yes  Supported. FileNET has an optional module called Rendition Services that supports transformation of electronic documents to PDF. Yes  Supported. FileNET supports the ability to add documents that were created from various sources to the repository individually or through a  13  Features are mandatory unless otherwise noted.  On-Target Information Technology Consulting  A5-14  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES    13  FILENET REPONSE   bulk load process. Yes  Supported. FileNET supports the ability to export documents and index data. Yes  Supported. FileNET allows users to drag and drop documents using our desktop interface. Our desktop interface is integrated with Windows Explorer so users can add documents to folders in the repository just like they would when adding documents to the Windows file system. Yes  Supported. FileNET supports the ability to capture ANSI and ASCII Line Print, DJDE/Metacode, and AFP print streams. FileNET also supports 3rd party products for capture of PCL line print data. Yes  Supported. FileNET can store and manage virtually any electronic document including XML. Yes  Supported. FileNET supports a wide range of scanners including those that support this requirement.  Yes  Supported. FileNET supports a wide range of scanners including those that support this requirement.  Yes  Supported Yes  Supported. FileNET supports a wide range of scanners including those that support this requirement. Yes  Supported. FileNET supports a wide range of scanners including those that support this requirement. Yes  Supported This is a function of the scanner selected. Yes  Supported This is a function of the scanner selected. Yes  Supported Yes  Supported Yes  Supported Yes  Supported Yes  Supported  filing, etc.); Export utilities ""drag and drop icon"" method for individual documents and batch import desirable  COLD    captures print streams from application systems (reports, fee receipts, etc.)    XML Scanning     supports XML documents in repository and for data exchange scans bi-tonal, gray-scale, and color images  scans fingerprints and handwriting         produces/uses standard TIFF files without modification supports simplex and duplex scanning supports wide variety of scanners from low speed (individual desktop units) to high-speed production scanners; flat-bed and page feed scanners supports batch scanning user-selectable scanning density adjustable on-the-fly from 200- dpi up bar code recognition document may contain pages of different dpi resolution 2 step scan/commit process for saving images delete, re-scan and insert pages into document before committing to disk display pages on screen during scanning quality control functions may be performed at scanning station or by another user before committing document to disk supports high-volume scanning (up to 25,000                         On-Target Information Technology Consulting  A5-15  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES   13  FILENET REPONSE   pages per day) scanning operation is software-controlled  Image Enhancement and Viewing             deskew, reduce background ""noise"" (dots, smudges), cropping and other image clean-up and other enhancement techniques rotate images 90% and 180% zoom in/zoom out fit page to screen thumbnail views of document pages uses a variety of page display methods and supports user in moving through document in a variety of ways, such as: display pages one at a time, multiple pages on screen at once, select desired page easily, go to first/last page bookmark pages for viewing multiple document windows open at once supports viewing of common file formats without launching application that created them (viewers), including images can recognize and launch appropriate application for any object type for which software does not have viewer automatic forms detection and processing         Yes  Supported. In addition, FileNET also supports hardware-based control for bar code reading, patch code detection, and document processing. Yes  Supported Ye Ye Ye Ye Ye s s s s s      Supported Supported Supported Supported Supported            Yes  Supported. FileNET supports ability to capture URLs and add to browser bookmarks for web retrieval. Yes  Supported Yes  Supported. FileNET IDM Desktop can view over 200 different file formats without requiring the native application. Yes  Supported Yes  Supported. This is supported through various FileNET software partners. In particular, Captiva Software and Datacap provide modules that plug into IDM Capture for automatic forms detection and processing. Yes  Supported. FileNET supports 32-bit OCR applications as part of the Capture Desktop application. FileNET also has an optional product called Rendition Services that can capture image documents, OCR, and convert to PDF. Yes  Supported. One caveat is that OCR accuracy is highly dependent on the document quality. Documents with varying quality will not result in high accuracy rates. Yes  Supported. OCR applications support dual output. Yes  Supported Yes  Supported. FileNET  OCR    32-bit recognition engine supports English (mandatory); other languages (optional)      conversion achieves 99% or greater accuracy     Indexing    scan document once  dual output (to produce OCR and imaging files) support multiple indexes for different types of documents support up to 10 index fields for      On-Target Information Technology Consulting  A5-16  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES  13  FILENET REPONSE supports up to 100 single custom property fields and up to 10 multivalued custom property fields. Yes  Supported. FileNET supports two types of Compound Documents (OLE documents and Relationship Objects) to maintain link relationships.  documents  Links main document and attachments for simultaneous/separate retrieval   Document Access Services Navigation    supports an organizational hierarchy that can be mapped to case type, case file, case file subsection, document, and page        supports transparent user access to multiple, distributed document repositories across LANs and WANs14 personal bookmarks for frequently used items may be set, changed and removed by users supports hyper-text links within documents      Yes  Supported. FileNET supports a hierarchical structure for storing documents. In addition, specific document hierarchy relationships are maintained through our implementation of compound document support. Yes  Supported Yes  Supported Yes  Supported. FileNET has an optional product called Panagon Web Publisher that creates linked web pages for documents stored in the repository. Yes  Supported Yes  Supported. FileNET embeds Fulcrum SearchServer for full-text indexing and searching. Also, Exaclibur, a FileNET business partner, has developed an application called RetrievalWare for Panagon that provides a high-end content retrieval solution. Yes  Supported. FileNET supports either attribute or full-text searching or a combination of both. Yes  Supported Yes  Supported. Relevancy determination is inherent to Fulcrum SearchServer. Yes  Supported. FileNET supports Stored Searches and Stored Search  Mobile Support Searching     download files to a laptop and view documents off-line (read-only)15 uses a robust search engine such as Fulcrum or Verity          search single document or document repository based on user-defined criteria (index attributes or full-text) transparent search across multiple repositories and servers provides a list of matching documents (repository search), listed by relevancy16 save document search queries for re-use       14 15  A user need not know the physical or logical location of a document in order to access it. This feature would enable judges and others to take documents home via a laptop without having to remove the documents from the courthouse. 16 The likelihood of document being what the user wanted.  On-Target Information Technology Consulting  A5-17  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES  13  FILENET REPONSE Templates to facilitate search query re-use. Yes  Supported Yes  Supported Yes  Supported. This is supported through RetrievalWare for Panagon. Also, the FileNET Find application supports ""wild card"" searches for content, attributes or a combination of these. Yes  Supported. This is supported through RetrievalWare for Panagon. Yes  Supported. FileNET back end server products are designed to scale from very small departmental applications to very large enterprise applications. This is accomplished through an innovative architectural design that takes advantage of client/server, symmetrical multiprocessing, and distributed processing technology. FileNET's products are designed to distribute server application services to multiple processors, multiple servers or multiple systems as your needs dictate.      documents may be searched by index values (document attributes) full text documents may be searched by phrases, word proximity search; wild cards and Boolean searches supports fuzzy searching (optional)17         highlight search phrase in text display software optimized for rapid search and retrieval on multiple very large document repositories (125 million pages or more)     Document and Content Management Library services Annotation       Electronic Signature    check in/check out of documents lock documents supports creating, viewing, printing, deletion and other manipulation of ""sticky notes"" on documents, pages and folders without altering content of documents, including ""read-only"" documents and images supports various security levels for notes (create, view, delete, modify, print, etc.) supports colored notes (optional) support for electronic approval process integrated with workflow capabilities      Ye Ye Ye for  s  Supported s  Supported s  Supported. This is supported most common image formats.      Yes  Supported Yes  Supported Yes  Supported. FileNET supports the ability to create workflow applications that govern an electronic approval process through its WorkFlo products. Through audit controls, the approval process can be monitored  17  Less exact search method that relies on context interpretation to find probable ""matches."" Useful when user does not know exact matching string criteria.  On-Target Information Technology Consulting  A5-18  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES   13  FILENET REPONSE  and reported as needed. Yes  Supported. FileNET has third party business relationships to provide electronic signatures. In particular, PenOp and Salinas are most notable. Yes  Supported. This is supported by third party providers. Yes  Supported Yes  Supported Yes  Supported  support for third-party software   Records Storage     supports encryption supports near-line (magnetic and WORM storage) and off-line storage (tape) supports Hierarchical Storage Management techniques using user-defined business rules supports various vendor's high capacity storage platforms  magnetic disk (native file systems), jukeboxes, network attached devices and SCSI devices (e.g.,CD-ROM tower) supports mirroring /RAID supports multiple repositories across LAN and WAN index replication and rollback supports archiving/destruction (deleting) of records based on user-defined criteria (e.g., records purging and destruction schedules)         Records Management         Yes  Supported Yes  Supported Yes  Supported Yes  Supported. FileNET has third party relationships to provide records management services. In particular, FileNET has been integrated with PSSoftware's RIMS and Provenance Foremost products to provide a records management solution. Yes  Supported Yes  Supported Yes  Supported. FileNET supports a technical architecture that allows you to build COM output applications.  Printing/Output      supports remote print/fax services easy to print by page or by document or other object (case file?) supports output to COM (Computer-Output Microfilm)      Workflow Management Workflow          graphical and list-based user views of work items (tasks, folders, documents, etc.) supports structured, production workflow processes (light or medium complexity) database-driven product supports serial, parallel and alternative (if. . .then) routing of electronic objects work process management capabilities include: workflow role definition, task definition, task assignment, task assembly, tracking and monitoring of task status; production statistics supports sign off/approval process and electronic signature        Yes  Supported Yes  Supported Yes  Supported Yes  Supported Yes  Supported    Yes  Supported. WorkFlo can be configured to require sign off before a work item can be routed to the next step. Also, FileNET has third party business relationships to provide  On-Target Information Technology Consulting  A5-19  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES  13  FILENET REPONSE electronic signatures. In particular, PenOp and Salinas are most notable. Yes  Supported Yes  Supported Yes  Supported Yes  Supported. FileNET supports SMTP based e-mail systems for integration. Yes  Supported. FileNET supports integration with Novell Groupwise. Yes  Supported Yes  Supported Yes  Supported   Process Design/Modeling   Workflow-Electronic Mail Integration    Workflow Application Development    workflow across Intranet (required) or Internet (optional) graphical modeling and design tool kit approach preferred supports light to medium complexity routing processes MS Outlook integration for messaging (mandatory) supports other common SMTP-based mail systems supports event notification via user-defined triggers easy end-user configuration/customization of user interface using graphical tools software includes prototypes, models and outof-the box applications that may serve as examples or be modified restrict access to viewing and printing documents at the page, document, case file and case type level based on user attributes18 provide an audit trail for viewing certain restricted documents ability to assign various document manipulation and viewing options to users (e.g., document add, modify, delete and view functions) support individual user, encrypted passwords and forced periodic change of password notify systems administrator of attempted security breaches log-off user after several incorrect password attempts can use O/S security schema (optional)           Document Security                  Yes  Supported Yes  Supported Yes  Supported Yes  Supported Yes  Supported. FileNET supports a robust audit tracking to track attempts at breaching system security. Yes  Supported Yes  Supported. FileNET supports NT Directory Synchronization to load user id, password and group security information. Yes  Supported Yes  Supported  Servers     supports multiple servers across a distributed network integrated back-end administration for all servers and document repositories on distributed network     18  For example: (1) the judge who sealed a record may access the document (or case file) or may grant access to another user based on a court order; (2) adoption files and documents may be viewed only by a judicial officer or specified staff; (3) criminal histories are sealed in the file. Security must also be implemented in conjunction with the case management system security.  On-Target Information Technology Consulting  A5-20  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES    13  FILENET REPONSE   Yes  Supported Yes  Supported. FileNET supports NT and HP/UX for IDM Content Services and NT, HP/UX, AIX, and Sun Solaris for IDM Image Services Yes  Supported Yes  Supported Yes  Supported Yes  Supported Yes  Supported. FileNET back end server products are designed to scale from very small departmental applications to very large enterprise applications. This is accomplished through an innovative architectural design that takes advantage of client/server, symmetrical multiprocessing, and distributed processing technology. FileNET's products are designed to distribute server application services to multiple processors, multiple servers or multiple systems as your needs dictate. Yes  Supported. FileNET back end server products are designed to scale from very small departmental applications to very large enterprise applications. Yes  Supported. FileNET supports a variety of network configurations including Frame Relay-based networks. Yes  Supported. Given an appropriately designed infrastructure (networks, servers and clients) then this requirement is achievable. Yes  Supported. FileNET supports a three tiered architecture for thin client deployment and a two-tiered architecture for thick client deployment. Yes  Supported. FileNET supports a three tiered architecture for thin client deployment and a two-tiered architecture for thick client deployment. Yes  Supported  supports Microsoft NT on various Intel-based servers (mandatory) Supports other leading O/S such as AIX or Novell IBM PC and compatible desktop or laptop (mandatory) MS WIN95/98 and NT for fat clients support Support for common browsers for thin clients client runs on any platform 32 bit application highly scalable from a few users to thousands of users across a distributed network  Clients and desktops            System Architecture       intended for enterprise-wide use      supports real-time distributed processing over frame relay circuits rapid retrieval can be expected to yield sub 2 second response time given appropriate infrastructure 3 tiered architecture (preferred)              two-tiered (acceptable with plans for migration to three-tired within 1 yr. Product must be under development now)      web server support    On-Target Information Technology Consulting  A5-21  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES   13  FILENET REPONSE  Yes  Supported. FileNET supports a variety of controls to support fault tolerance including replication, transaction logging, and normal database rollback/recovery operations. Hardware controls support for RAID systems and High Availability services from Microsoft and HP. Yes  Supported Yes  Supported. FileNET supports TCP/IP, HTTP, NFS among others. Yes  Supported. FileNET supports Oracle and Microsoft NT SQL Server. Not Supported FileNET supports administration tools for IDM Image Services, IDM Content Services and Visual WorkFlo. Each service has unique administration requirements. Not Supported Yes  Supported Yes  Supported Yes  Supported. FileNET provides NT Directory Synchronization services to facilitate account administration. Yes  Supported. FileNET's audit capabilities allow you to track many system events including login activity, object checkin and checkout and object modification. Yes  Supported Yes  Supported. FileNET is built on Microsoft's COM architecture. FileNET can integrate with client/server applications that adhere to Microsoft's COM architecture and use C and/or ActiveX Controls and Objects.  Yes  Supported. FileNET is built on Microsoft's COM architecture. FileNET offers API toolkits to develop custom applications as needed.  Yes  Supported. IDM Desktop is integrated with Microsoft Office, Microsoft Outlook, and Microsoft Explorer. In addition,  fault-tolerant features such as replication, automatic cut-over on failure   Network Communications Protocols Databases Supported      scalable to thousands of users and thousands of simultaneous processes TCP/IP (mandatory); others (optional) uses an ANSI SQL relational database supports Informix (optional) unified systems administration for all modules        Systems Administration       browser-based administration tools (preferred) audit tracking capabilities convenient, robust user/group management functions (graphical tools preferred) import/export of existing user/groups         session/intruder monitoring     Integration   robust, highly configurable user security features screen-level integration with modern clientserver applications       API tool kit for application development and integration    Integration with desktop office products  On-Target Information Technology Consulting  A5-22  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES  13  FILENET REPONSE FileNET has integrated with Microsoft Digital Dashboard and Lotus Notes. Panagon software is based on industry standards, including the Open Document Management API (ODMA), the Document Management Alliance (DMA) technical specification, and the Workflow Management Coalition (WfMC) interface specifications. Yes  Supported Yes  Supported. Panagon software is based on industry standards, including the Open Document Management API (ODMA), the Document Management Alliance (DMA) technical specification, and the Workflow Management Coalition (WfMC) interface specifications. Yes  Supported. IDM Content Services is CORBA compliant. Visual WorkFlo intends to support CORBA in a future release. Currently, customer requirement for this feature is minimal, but we envision this to change over the next 12 to 24 months. As this standard evolves and becomes more widely accepted, based on Visual WorkFlo's objectoriented nature, a CORBA compliant implementation will be both relevant and beneficial. FileNET was a founding member of the Workflow Management Coalition and continues to be a strong WfMC supporter.  Standards Supported    Supports ODMA or WebDAV for integration with desktop applications       ODBC connectivity for use with reporting and data analysis tools (e.g., Crystal reports, ACCESS, Excel) Supports DMA       Support for CORBA      Other standards supported (WfMC, others??)    On-Target Information Technology Consulting  A5-23  6/13/00   Electronic Document Management Systems for the Arizona Courts  Software Evaluation EDMS RFI Company: Eastman Software Persons Contacted: Mary Lou.Doyle@eastmansoftware.com Sales Support Rep for West Coast 978-313-7074; Bruce Miller 636-532-1900 in Missouri Western Regional Mgr. Date: sent 2/29/00 Question   Public or private company  Market focus/audience  Govt. clients?    Products Names and version number Release date of products Eastman Response   Wholly owned subsidiary of Kodak  Work Management Technologies  Yes (SSA, VBA, others at state & local level, Including Arizona State Comp Fund & Southwest Student Services, City of Phoenix)  Eastman Software Imaging for NT V 3.2  Eastman Software Workflow for NT V 3.2  Eastman Software Electronic Report Manager V 3.2 (COLD)  Current versions released 2nd half 1999 for Imaging/Workflow. January 2000 for COLD/ERM  New releases are scheduled for both the 1st and 2nd half of 2000    1,000,000+ including Imaging for Windows  300,000+ Imaging/Workflow/COLD  Next release or new product date (timeframe)  Licenses Worldwide    Market Cap Employees License Prices References  govt. FEATURES      300+ pricing varies depending upon the #seats purchased and Imaging, Workflow and COLD/ERM are priced separately  To be provided EASTMAN RESPONSE  FUNCTIONAL CATEGORY Document Management and Capture Electronic ""objects""  19      stores, manages, retrieves and displays wide variety of electronic objects within the same folders, including TIFF, MS Word, Word Perfect, XML, Adobe Acrobat PDF, MPEG, JPEG, AVI, WAV, ASCII text, raster scanned images, RTF, G3 and G4 fax and other common file formats supports document renditioning (e.g., from word processing to Adobe Acrobat PDF format or from TIFF to PDF or Word Processing to TIFF, etc.)      Virtually all electronic file formats can be stored and retrieved from the Imaging/Workflow system. Rendering non-image formats requires the native application or a conversion utility which can be called from the Image/Workflow system. Electronic Report Manager displays documents in PDF formats and does the conversion at retrieval time. Imaging displays TIFF formats, however does not include conversion  19  Features are mandatory unless otherwise noted.  On-Target Information Technology Consulting  A5-24  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY Import utilities  FEATURES   19  EASTMAN RESPONSE  utilities. As stated above, virtually all electronic formats can be managed by the system. There are a number of commercially available conversion utilities which could be incorporated into the application. No COLD/ERM accepts line data and APA formats. As stated above, the documents can be in any electronic format. Yes  Hard copy information can be captured and stored via scanner or fax  Yes Yes Yes  import utilities to accept and incorporate documents not created or scanned through native EDMS software (e.g., COLD data, faxed documents, PDF or XML documents from efiling, etc.); ""drag and drop icon"" method for individual documents and batch import desirable captures print streams from application systems (reports, fee receipts, etc.) supports XML documents in repository and for data exchange scans bi-tonal, gray-scale, and color images  scans fingerprints and handwriting produces/uses standard TIFFV6 CCITT G4 files without modification supports simplex and duplex scanning supports wide variety of scanners from low speed (individual desktop units) to high-speed production scanners; flat-bed and page feed scanners supports batch scanning user-selectable scanning density adjustable on-the-fly from 200 dpi up bar code recognition document may contain pages of different dpi resolution 2 step scan/commit process for saving images delete, re-scan and insert pages into document before committing to disk display pages on screen during scanning quality control functions may be performed at scanning station or by another user before committing document to disk supports high-volume scanning (up to 25,000 pages per day) scanning operation is software-controlled deskew, reduce background ""noise"" (dots, smudges), cropping and other image clean-up and other enhancement techniques rotate images 90% and 180% zoom in/zoom out fit page to screen thumbnail views of document pages uses a variety of page display methods and supports user in moving through document in a variety of ways, such as: display pages one at a time, multiple pages on screen at once,   COLD XML Scanning                          Image Enhancement and Viewing                          Yes Yes Yes  Yes Yes Yes Yes Yes Yes Yes Ye Ye Ye Ye Ye s s s s s  On-Target Information Technology Consulting  A5-25  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES     19  EASTMAN RESPONSE     select desired page easily, go to first/last page bookmark pages for viewing multiple document windows open at once supports viewing of common file formats without launching application that created them (viewers), including images     can recognize and launch appropriate application for any object type for which software does not have viewer automatic forms detection and processing     Yes Yes Image formats will be viewed by the system without benefit of the origination application. Alternate formats require either conversion to image format or the native application. Yes, file types can be associated with applications. Batch types can be defined for specific forms for zone capture and OCR. In addition, bar codes can be used to identify what batch types and input formats are being used. Eastman Software products use the Xerox Textbridge OCR software. 3rd party OCR can also be incorporated. Accuracy is dependent on the OCR software used and the quality and consistency of the input data. Yes Yes Yes Yes  OCR      32-bit recognition engine supports English (mandatory); other languages (optional) conversion achieves 99% or greater accuracy scan document once  dual output (to produce OCR and imaging files) support multiple indexes for different types of documents support up to 10 index fields for documents Links main document and attachments for simultaneous/separate retrieval         Indexing      Document Access Services Navigation      Mobile Support Searching      supports an organizational hierarchy that can be mapped to case type, case file, case file subsection, document, and page supports transparent user access to multiple, distributed document repositories across LANs and WANs20 personal bookmarks for frequently used items may be set, changed and removed by users supports hyper-text links within documents download files to a laptop and view documents off-line (read-only)21 uses a robust search engine such as Fulcrum or Verity         With proper indexing and customization, this type of hierarchy can be accomplished. Yes No Yes Yes Image and Workflow search is via SQL based queries. COLD/ERM searches are Boolean index based.  20 21  A user need not know the physical or logical location of a document in order to access it. This feature would enable judges and others to take documents home via a laptop without having to remove the documents from the courthouse.  On-Target Information Technology Consulting  A5-26  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES           19  EASTMAN RESPONSE          Yes Yes No No Yes No No Yes Yes  search single document or document repository based on user-defined criteria (index attributes or full-text) transparent search across multiple repositories and servers provides a list of matching documents (repository search), listed by relevancy22 save document search queries for re-use documents may be searched by index values (document attributes) full text documents may be searched by phrases, word proximity search; wild cards and Boolean searches supports fuzzy searching (optional)23 highlight search phrase in text display software optimized for rapid search and retrieval on multiple very large document repositories (125 million pages or more)  Document and Content Management Library services Annotation       Electronic Signature         Records Storage  check in/check out of documents lock documents supports creating, viewing, printing, deletion and other manipulation of ""sticky notes"" on documents, pages and folders without altering content of documents, including ""read-only"" documents and images supports various security levels for notes (create, view, delete, modify, print, etc.) supports colored notes (optional) support for electronic approval process integrated with workflow capabilities support for third-party software supports encryption supports near-line (magnetic and WORM storage) and off-line storage (tape) supports Hierarchical Storage Management techniques using user-defined business rules supports various vendor's high capacity storage platforms  magnetic disk (native file systems), jukeboxes, network attached devices and SCSI-2 devices supports mirroring /RAID supports multiple repositories across LAN and WAN      No Yes Yes           Yes Yes Yes Yes Yes Magnetic & WORM COLD/ERM Optical Disk Management System is a hierarchical storage management system Yes        Yes Yes  22 23  The likelihood of document being what the user wanted. Less exact search method that relies on context interpretation to find probable ""matches."" Useful when user does not know exact matching string criteria.  On-Target Information Technology Consulting  A5-27  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY Records Management Printing/Output  FEATURES       19  EASTMAN RESPONSE      Yes Yes Yes Yes No  index replication and rollback supports archiving/destruction (deleting) of records based on user-defined criteria (e.g., records purging and destruction schedules) supports remote print/fax services easy to print by page or by document or other object (case file?) supports output to COM (Computer-Output Microfilm)  Workflow Management Workflow        graphical and list-based user views of work items (tasks, folders, documents, etc.) supports structured, production workflow processes (light or medium complexity) database-driven product supports serial, parallel and alternative (if. . .then) routing of electronic objects work process management capabilities include: workflow role definition, task definition, task assignment, task assembly, tracking and monitoring of task status; production statistics supports sign off/approval process and electronic signature workflow across Intranet (required) or Internet (optional) graphical modeling and design tool kit approach preferred supports light to medium complexity routing processes MS Outlook integration for messaging (mandatory) supports other common SMTP-based mail systems supports event notification via user-defined triggers easy end-user configuration/customization of user interface using graphical tools software includes prototypes, models and outof-the box applications that may serve as examples or be modified restrict access to viewing and printing documents at the page, document, case file and case type level based on user attributes        Yes Yes Imaging & Workflow are SQL, ORACLE, SYBASE Yes Yes    Process Design/Modeling   Workflow-Electronic Mail Integration    Workflow Application Development              Yes Yes Yes Yes Yes With customization/integration Yes Task level scripting is graphical and can be user defined. Yes  Document Security     24  File level access can be controlled based on user and file type.  24  For example: (1) the judge who sealed a record may access the document (or case file) or may grant access to another user based on a court order; (2) adoption files and documents may be viewed only by a judicial officer or specified staff; (3) criminal histories are sealed in the file. Security must also be implemented in conjunction with the case management system security.  On-Target Information Technology Consulting  A5-28  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES        19  EASTMAN RESPONSE                           All system transaction information is recorded in log or history files. Yes Yes, through customization you could enforce your preferred logon/password scheme Yes, through customization you could create a notification system for security breaches. Yes Yes Yes Yes Yes AIX for Imaging and COLD/ERM Yes Yes Yes Yes Yes Yes Yes Yes No Yes Yes Yes Yes TCP/IP SQL, ORACLE, SYBASE No  provide an audit trail for viewing certain restricted documents ability to assign various document manipulation and viewing options to users (e.g., document add, modify, delete and view functions) support individual user, encrypted passwords and forced periodic change of password notify systems administrator of attempted security breaches log-off user after several incorrect password attempts can use O/S security schema (optional) supports multiple servers across a distributed network integrated back-end administration for all servers and document repositories on distributed network supports Microsoft NT on various Intel-based servers (mandatory) Supports other leading O/S such as AIX or Novell IBM PC and compatible desktop or laptop (mandatory) MS WIN95/98 and NT for fat clients support Support for common browsers for thin clients client runs on any platform 32 bit application highly scalable from a few users to thousands of users across a distributed network intended for enterprise-wide use supports real-time distributed processing over frame relay circuits rapid retrieval can be expected to yield sub 2 second response time given appropriate infrastructure 3 tiered architecture (preferred) two-tiered (acceptable with plans for migration to three-tired within 1 yr. Product must be under development now) web server support fault-tolerant features such as replication, automatic cut-over on failure scalable to thousands of users and thousands of simultaneous processes TCP/IP (mandatory), others (optional)  Servers       Clients and desktops      System Architecture             Network Communications Protocols Databases Supported     uses an ANSI SQL relational database  supports Informix (optional)  On-Target Information Technology Consulting  A5-29  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY Systems Administration  FEATURES         19  EASTMAN RESPONSE         Imaging and Workflow on NT have unified administration. No, but can be developed via API. Yes Yes Yes No Yes Yes      Yes Yes Yes Yes Eastman has been a key participant in development of the DMA standard. DMA access for ESI products has been prototyped, but is not commercially available. DMA is technically elegant, but does not have widespread vendor adoption. XML is beginning to emerge as a relevant technology that will supplant DMA and other standards. XML is also being adopted by the WfMC. WfMC has just released an XML Based Process Management standard called Wf-XML. Eastman will be watching this standard closely. Eastman software fully embraces and exploits NT. Therefore we support DCOM and not CORBA at this time. See above response on DMA  unified systems administration for all modules browser-based administration tools (preferred) audit tracking capabilities convenient, robust user/group management functions (graphical tools preferred) import/export of existing user/groups session/intruder monitoring robust, highly configurable user security features screen-level integration with modern clientserver applications  API tool kit for application development and integration  Integration with desktop office products  Supports ODMA or WebDAV for integration with desktop applications ODBC connectivity for use with reporting and data analysis tools (e.g., Crystal reports, ACCESS, Excel) Supports DMA  Integration    Standards Supported      Support for CORBA/DCORBA      Other standards supported (WfMC, others??)    On-Target Information Technology Consulting  A5-30  6/13/00   Electronic Document Management Systems for the Arizona Courts  Software Evaluation EDMS RFI Company: Hummingbird Person Contacted: Mark A. Gallagher, Autumn Tysko Date: 3/6/00  Question        Public or private company Market focus/audience Govt. clients? Products Names and version number      Release date of products Next release or new product date (timeframe)  Licenses Worldwide  Market Cap  Employees License Prices  References  govt. FEATURES  Hummingbird Response  Hummingbird  Public  Document and Knowledge Management  Yes, many  DOCSOpen Enterprise Suite (contains DOCS Imaging and DOCS Routing) 3.9, CyberDOCS 3.1, PowerDOCS 3.1, DOCS Unplugged 3.9  We have been releasing products in this line since 1988  Q2 2000     Over one million seats 250 Million 1400 $200-$500/seat depending on volume and options Arizona Attorney General's Office HUMMINGBIRD RESPONSE    FUNCTIONAL CATEGORY Document Management and Capture Electronic ""objects""  25    stores, manages, retrieves and displays wide variety of electronic objects within the same folders, including TIFF, MS Word, Word Perfect, XML, Adobe Acrobat PDF, MPEG, JPEG, AVI, WAV, ASCII text, raster scanned images, RTF, G3 and G4 fax and other common file formats      Import utilities    supports document renditioning (e.g., from word processing to Adobe Acrobat PDF format or from TIFF to PDF or Word Processing to TIFF, etc.) import utilities to accept and incorporate documents not created or scanned through native EDMS software (e.g., COLD data, faxed documents, PDF or XML documents from efiling, etc.);       25  Export utilities    Storage, management, and retrieval are default functionality. Viewer shipped with product views over 200 different file formats including many mentioned. Other formats such as PDF or WAV would use standard display or play methods such as Acrobat Reader or Sound player, etc. and can be easily launched from the system. While our software is not a publishing or translation tool, packages that do such can be used in conjunction with it. Both single document and batch import utilities exist to handle this as well as the ability to profile paper documents that never reside in the system. There are also COLD systems such as Maximal that have built integration with the document management products we offer. Documents and metadata may both  Features are mandatory unless otherwise noted.  On-Target Information Technology Consulting  A5-31  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES  25  HUMMINGBIRD RESPONSE be exported. The entire database structure is also documented. Drag and drop is a feature of our PowerDOCS client. We do not offer a COLD product, but have partners such as Maximal who integrate with our software. XML documents may be stored in our document management product. Additionally, The Hummingbird EIP (Enterprise Information Portal) uses XML as the base data and metadata exchange mechanism between the different EIP components We support scanners that do all this with our Imaging products.  The content of the TIFF file placed in the system does not matter. We are not a hardware vendor and do not provide specialized scanners. If you have files that contain this information they will be stored and viewed like any other image file.  Default functionality of Imaging products. This is a function of the hardware scanner. Our software supports scanners that have this capability. DOCS Imaging supports Image and Scanner Interface Specification (ISIS)-compatible scanners and TWAIN compatible scanners. This is scanner functionality. DOCS Imaging does allow for multipage documents to be scanned and profiled. This is scanner functionality, but these resolutions are supported by our software. DOCS Imaging does not do bar code recognition. If this is a requirement you can use one of our partner products like Kofax Imaging which supports bar codes. Supported by DOCS Imaging Supported by DOCS Imaging Supported by DOCS Imaging Function of scanner software, and all   COLD XML    ""drag and drop icon"" method for individual documents and batch import desirable captures print streams from application systems (reports, fee receipts, etc.) supports XML documents in repository and for data exchange      Scanning    scans bi-tonal, gray-scale, and color images  scans fingerprints and handwriting        produces/uses standard TIFF files without modification supports simplex and duplex scanning supports wide variety of scanners from low speed (individual desktop units) to high-speed production scanners; flat-bed and page feed scanners supports batch scanning            user-selectable scanning density adjustable on-the-fly from 200dpi up bar code recognition          document may contain pages of different dpi resolution 2 step scan/commit process for saving images delete, re-scan and insert pages into document before committing to disk display pages on screen during scanning       On-Target Information Technology Consulting  A5-32  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES    25  HUMMINGBIRD RESPONSE   that I have seen do this. This is really a process question. Yes, it can be done. DOCS Imaging is not a high volume package. Though depending on the scanner(s) you choose it can support this type of volume. Or, you can use a high end imaging partner package in conjunction with our products. Function of the scanner software. There is a ""clean up"" function that cleans up and erases stray marks around both text and graphics giving the image document a sharper appearance. Standard functionality of DOCS Imaging Standard functionality of DOCS Imaging Standard functionality of DOCS Imaging Standard functionality of DOCS Imaging Standard functionality of DOCS Imaging  quality control functions may be performed at scanning station or by another user before committing document to disk supports high-volume scanning (up to 25,000 pages per day)  Image Enhancement and Viewing     scanning operation is software-controlled deskew, reduce background ""noise"" (dots, smudges), cropping and other image clean-up and other enhancement techniques rotate images 90% and 180% zoom in/zoom out fit page to screen thumbnail views of document pages uses a variety of page display methods and supports user in moving through document in a variety of ways, such as: display pages one at a time, multiple pages on screen at once, select desired page easily, go to first/last page bookmark pages for viewing multiple document windows open at once supports viewing of common file formats without launching application that created them (viewers), including images can recognize and launch appropriate application for any object type for which software does not have viewer automatic forms detection and processing 32-bit recognition engine supports English (mandatory); other languages (optional) conversion achieves 99% or greater accuracy scan document once  dual output (to produce OCR and imaging files) support multiple indexes for different types of documents support up to 10 index fields for                      OCR    Indexing               You can't bookmark, but you can save searches You can have multiple viewer or application windows open, but only one copy of DOCS Imaging. We bundle a viewer that views over 200 formats including images. Standard functionality Forms support is handled via a partner package like Kofax We bundle Xerox Textbridge for OCR. This is dependent on the state of the source image for any vendor. Standard functionality Standard functionality Unlimited index fields supported  On-Target Information Technology Consulting  A5-33  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES   25  HUMMINGBIRD RESPONSE   documents Links main document and attachments for simultaneous/separate retrieval  Documents can be linked together in binders or folders.  Document Access Services Navigation      supports an organizational hierarchy that can be mapped to case type, case file, case file subsection, document, and page supports transparent user access to multiple, distributed document repositories across LANs and WANs26 personal bookmarks for frequently used items may be set, changed and removed by users      Standard functionality. Web browser client CyberDOCS can also be used to design a web navigation interface. Standard functionality Users can save searches and group items in to logical folders. Frequently used items are automatically indexed in a ""Quick Retrieve"" of the last 30 documents edited. We don't look inside documents or objects stored so hyperlinks are not altered. This is a capability of DOCS Unplugged We own Fulcrum and use our own search engine Standard functionality Standard functionality Standard functionality Standard functionality Standard functionality Standard functionality There is a ""sounds like"" fuzzy search Standard functionality Standard functionality   Mobile Support Searching             supports hyper-text links within documents download files to a laptop and view documents off-line (read-only)27 uses a robust search engine such as Fulcrum or Verity search single document or document repository based on user-defined criteria (index attributes or full-text) transparent search across multiple repositories and servers provides a list of matching documents (repository search), listed by relevancy28 save document search queries for re-use documents may be searched by index values (document attributes) full text documents may be searched by phrases, word proximity search; wild cards and Boolean searches supports fuzzy searching (optional)29 highlight search phrase in text display software optimized for rapid search and retrieval on multiple very large document repositories (125 million pages or more)               Document and Content Management 26 27  A user need not know the physical or logical location of a document in order to access it. This feature would enable judges and others to take documents home via a laptop without having to remove the documents from the courthouse. 28 The likelihood of document being what the user wanted. 29 Less exact search method that relies on context interpretation to find probable ""matches."" Useful when user does not know exact matching string criteria.  On-Target Information Technology Consulting  A5-34  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY Library services Annotation  FEATURES     25  HUMMINGBIRD RESPONSE    Standard functionality Standard functionality Annotation is a feature of DOCS Imaging.    Electronic Signature    Records Storage     check in/check out of documents lock documents supports creating, viewing, printing, deletion and other manipulation of ""sticky notes"" on documents, pages and folders without altering content of documents, including ""read-only"" documents and images supports various security levels for notes (create, view, delete, modify, print, etc.) supports colored notes (optional) support for electronic approval process integrated with workflow capabilities support for third-party software supports encryption supports near-line (magnetic and WORM storage) and off-line storage (tape) supports Hierarchical Storage Management techniques using user-defined business rules supports various vendor's high capacity storage platforms  magnetic disk (native file systems), jukeboxes, network attached devices and SCSI devices (e.g.,CD-ROM tower) supports mirroring /RAID supports multiple repositories across LAN and WAN index replication and rollback supports archiving/destruction (deleting) of records based on user-defined criteria (e.g., records purging and destruction schedules) supports remote print/fax services           Standard functionality. Color annotations are a feature of DOCS Imaging DOCS Routing supports this. There are a number of third party workflow packages that have integrated with us already. We do file name encryption. Other encryption methods and packages can be used with our software. Standard functionality. This is a function of the HSM system. We support the use of HSM systems with our software. We support the use of HSM systems with our software. This is a function of the device. We don't alter the way they work. Standard functionality. This is a function of the SQL database you are using. Standard functionality. You can print or fax to any device defined in Windows. You can also use products like RightFax which have built integration with our software. Standard functionality Not by default. We'd need to know more about this requirement.     Records Management Printing/Output            Workflow Management Workflow  easy to print by page or by document or other object (case file?) supports output to COM (Computer-Output Microfilm)        graphical and list-based user views of work items (tasks, folders, documents, etc.) supports structured, production workflow processes (light or medium complexity)     Standard Functionality of DOCS Routing. Depends on what you mean by this. We support serial and parallel routing  On-Target Information Technology Consulting  A5-35  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES     25  HUMMINGBIRD RESPONSE    and not decision trees. We use an SQL engine We support serial and parallel but not if/then We support role definition, task definition, task assignment, tracking and monitoring. Standard functionality We Expect to release Cyber Routing or internet routing package soon. It is currently in beta. To do graphic modeling you would need to use a partner workflow package. Standard functionality of DOCS Routing. Standard functionality In addition to email support routing has an internal messaging capability We do support event notification, but the triggers are not really userdefined. They are based on elapsed time or event completion. Routing does not have an interface customization tool, but the core document management system does. Routing does not have this, but the core document management system does. We can do this at the document level. Complete audit trails are provided for all objects in the system. Standard Functionality Standard Functionality Standard Functionality if Document Sentry Agent option for NT is purchased.    Process Design/Modeling   Workflow-Electronic Mail Integration     database-driven product supports serial, parallel and alternative (if. . .then) routing of electronic objects work process management capabilities include: workflow role definition, task definition, task assignment, task assembly, tracking and monitoring of task status; production statistics supports sign off/approval process and electronic signature workflow across Intranet (required) or Internet (optional) graphical modeling and design tool kit approach preferred supports light to medium complexity routing processes MS Outlook integration for messaging (mandatory) supports other common SMTP-based mail systems supports event notification via user-defined triggers easy end-user configuration/customization of user interface using graphical tools software includes prototypes, models and outof-the box applications that may serve as examples or be modified restrict access to viewing and printing documents at the page, document, case file and case type level based on user attributes30 provide an audit trail for viewing certain restricted documents ability to assign various document manipulation and viewing options to users (e.g., document add, modify, delete and view functions) support individual user, encrypted passwords and forced periodic change of password notify systems administrator of attempted security breaches          Workflow Application Development        Document Security              30  For example: (1) the judge who sealed a record may access the document (or case file) or may grant access to another user based on a court order; (2) adoption files and documents may be viewed only by a judicial officer or specified staff; (3) criminal histories are sealed in the file. Security must also be implemented in conjunction with the case management system security.  On-Target Information Technology Consulting  A5-36  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES    25  HUMMINGBIRD RESPONSE                Standard Functionality Standard Functionality Standard Functionality Standard Functionality Standard Functionality Support for Novell and Support for AIX SQL servers Standard Functionality Standard Functionality CyberDOCS supports browser client access Standard Functionality Standard Functionality Standard Functionality Standard Functionality Standard Functionality Standard Functionality for DOCSFusion line of products: CyberDOCS and PowerDOCS. DOCSOpen is Client/Server Standard Functionality for DOCSOpen Enterprise Suite Standard Functionality - CyberDOCS Replication is not supported but fail over is in the DOCSFusion line. Standard Functionality Standard Functionality Standard Functionality Not Currently Standard Functionality Administration tools are not browser based Standard Functionality Standard Functionality Standard Functionality  log-off user after several incorrect password attempts can use O/S security schema (optional) supports multiple servers across a distributed network integrated back-end administration for all servers and document repositories on distributed network supports Microsoft NT on various Intel-based servers (mandatory) Supports other leading O/S such as AIX or Novell IBM PC and compatible desktop or laptop (mandatory) MS WIN95/98 and NT for fat clients support Support for common browsers for thin clients client runs on any platform 32 bit application highly scalable from a few users to thousands of users across a distributed network intended for enterprise-wide use supports real-time distributed processing over frame relay circuits rapid retrieval can be expected to yield sub 2 second response time given appropriate infrastructure 3 tiered architecture (preferred)  Servers       Clients and desktops      System Architecture             Network Communications Protocols Databases Supported Systems Administration   two-tiered (acceptable with plans for migration to three-tired within 1 yr. Product must be under development now) web server support fault-tolerant features such as replication, automatic cut-over on failure scalable to thousands of users and thousands of simultaneous processes TCP/IP (mandatory), others (optional)                uses an ANSI SQL relational database  supports Informix (optional)  unified systems administration for all modules  browser-based administration tools (preferred)    audit tracking capabilities convenient, robust user/group management functions (graphical tools preferred) import/export of existing user/groups  On-Target Information Technology Consulting  A5-37  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES    25  HUMMINGBIRD RESPONSE    Available via Document Sentry Agent Standard Functionality Depends on the application. We are already integrated with many products and support ODMA.  Standard Functionality       Standard Functionality ODMA Supported Standard Functionality The DMA standard is still forming. If it becomes an industry standard we will consider supporting it. How do you want these supported?  Integration    session/intruder monitoring robust, highly configurable user security features screen-level integration with modern clientserver applications  API tool kit for application development and integration  Integration with desktop office products  Supports ODMA or WebDAV for integration with desktop applications ODBC connectivity for use with reporting and data analysis tools (e.g., Crystal reports, ACCESS, Excel) Supports DMA Supports CORBA Other standards supported (WfMC, others??)  Standards Supported      On-Target Information Technology Consulting  A5-38  6/13/00   Electronic Document Management Systems for the Arizona Courts  EDMS Software Evaluation EDMS RFI Company: Identitech (FYI Product Line) Person Interviewed: J.D. Humphreys 1-800-800-883-9503 x229 Date: February 17, 2000 Question  Public or private company  Market focus/audience  Govt. clients?  Products? Age of product? New product planned? IDENTITECH RESPONSE Private  Utilities and call centers; enterprise-wide  Yes. Courts in Brevard County, FL and Marion County Imaging: FYIScan, FYI MassScan and QAImport Workflow: FYI FloWorks Forms: SmartForms Integration Tools: FYI Power API Toolkit Web Support: NetFYI COLD: Yes, to be fully integrated in next release. Based upon concurrent use. Pricing: an enterprise wide license would offer the best value.  Name and phone, Agency 31       License Prices References  govt. FEATURES  FUNCTIONAL CATEGORY Document Management and Capture Electronic ""objects""  Identitech FYI Products      stores, manages, retrieves and displays wide variety of electronic objects within the same folders, including TIFF, MS Word, Word Perfect, XML, Adobe Acrobat PDF, MPEG, JPEG, AVI, WAV, ASCII text, raster scanned images, RTF, G3 and G4 fax and other common file formats supports document renditioning (e.g., from word processing to Adobe Acrobat PDF format or from TIFF to PDF or Word Processing to TIFF, etc.)    Yes, but need complete list of formats supported in folders and viewers/players    Import utilities    import utilities to accept and incorporate documents not created or scanned through native EDMS software (e.g., COLD data, faxed documents, PDF or XML documents from efiling, etc.);      Yes FYI also supports automatic document renditioning. This provides users the ability to create an archival copy of any document in an industry standard format such as PDF or TIF which can then be used as the default view for users on any client including those using web browser access. Yes: Has import utilities for ""any"" document creation software and other imaging systems. Import MSB image files from MassScan as standard TIFF. What other import formats are supported and how do they get stored after import? Can they be transformed during import to PDF or TIFF or something else?  31  Features are mandatory unless otherwise noted.  On-Target Information Technology Consulting  A5-39  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES    31  Identitech FYI Products       Yes: Export TIFF Group 4 using DDE Need more explanation. ? Yes: can be extracted and imported into FYI. FYI Supports ""bursted"" reports. ? Future support? Product component called SmartForm that is part of FloWorks is used to collect forms-based data. Supports photos, embedded graphics, other documents, text. Yes: color photos, gray scale  ? What dpi recommended?  Yes. Do you recommend 200 or 300 dpi for normal word processed documents?  Export utilities ""drag and drop icon"" method for individual documents and batch import desirable captures print streams from application systems (reports, fee receipts, etc.) supports XML for content exchange and process management  COLD XML     Scanning    scans bi-tonal, gray-scale, and color images  scans fingerprints and handwriting  produces/uses standard TIFF files without modification     simplex and duplex scanning  supports wide variety of scanners from low speed (individual desktop units) to high-speed production scanners; flat-bed and page feed scanners               Yes Yes: sounds like they support mostly Kodak scanners? Agfa BancTec (TDC) Bell & Howell Kodak Photomatrix InoTec Panasonic Fujitsu Ricoh Canon   supports batch scanning using bar code or blank page separators   user-selectable scanning density adjustable on-the-fly from 200dpi up  bar code recognition  document may contain pages of different dpi   Kodak Bookscanner Zeutschel Bookscanner  Yes: supports batch scanning with many features, bar code recognition supported. Either horizontal or vertical, as document separators or for data.  ? Should this go higher for photos, maps, etc?  Yes as data input and document separators; up to 9 per page can be read ?  On-Target Information Technology Consulting  A5-40  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES  31  Identitech FYI Products         resolution  2 step scan/commit process for saving images  delete, re-scan and insert pages into document before committing to disk  display pages on screen during scanning  quality control functions may be performed at scanning station or by another user before committing document to disk  supports high-volume scanning (up to 25,000 pages per day)  scanning operation is software-controlled  Sounds like it, but not sure Yes Yes Yes Yes: high volume scanning through MassScan  ""Highest"" ppm throughput  meaning? Supports SCSI interface scanners using DPU imaging cards and software drivers; supports Kodak image processing features Yes  all supported Ye Ye Ye Ye ? s s 25%-300% s s  Image Enhancement and Viewing   deskew, reduce background ""noise"" (dots, smudges), cropping and other image clean-up and other enhancement techniques  rotate images 90% and 180%  zoom in/zoom out  fit page to screen  thumbnail views of document pages  uses a variety of page display methods and supports user in moving through document in a variety of ways, such as: display pages one at a time, multiple pages on screen at once, select desired page easily, go to first/last page  bookmark pages for viewing  multiple document windows open at once  supports viewing of common file formats without launching application that created them (viewers), including images      can recognize and launch appropriate application for any object type for which software does not have viewer automatic forms detection and processing 32-bit recognition engine supports English (mandatory); other languages (optional) conversion achieves 99% or greater accuracy scan document once  dual output (to produce OCR and imaging files) support multiple indexes for different types of documents                   ? Yes Yes: ALLView multi-format viewer supports TIFF, text, spreadsheets, color photos, CAD drawings, video and audio files, G4 Yes ? ? ? Yes  FYI supports the ODMA standard fields as the default fields for each folder and document screen and also allows users to add an unlimited number of additional index fields. FYI allows each document class to have its own unique set of index fields.?  OCR  Indexing    On-Target Information Technology Consulting  A5-41  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES    31  Identitech FYI Products   Yes. What is limit? See above ?  support up to 10 index fields for documents Links main document and attachments for simultaneous/separate retrieval  Document Access Services Navigation       Mobile Support Searching               supports an organizational hierarchy that can be mapped to case type, case file, case file subsection, document, and page supports transparent user access to multiple, distributed document repositories across LANs and WANs32 screen-level integration with FACTS, APETS, JOLTS and other enterprise-wide applications for finding and retrieving documents personal bookmarks for frequently used items may be set, changed and removed by users supports hyper-text links within documents download files to a laptop and view documents off-line (read-only)33 uses a robust search engine such as Fulcrum or Verity search single document or document repository based on user-defined criteria (index attributes or full-text) transparent search across multiple repositories and servers provides a list of matching documents (repository search), listed by relevancy34 save document search queries for re-use documents may be searched by index values (document attributes) full text documents may be searched by phrases, word proximity search; wild cards and Boolean searches supports fuzzy searching (optional)35 highlight search phrase in text display software optimized for rapid search and retrieval on multiple very large document repositories (125 million pages or more)                   Yes Yes Can be built ? Yes Yes ? ? Yes ? Yes  Yes ? ? ?  Document and Content Management Library services 32 33    check in/check out of documents    Yes  A user need not know the physical or logical location of a document in order to access it. This feature would enable judges and others to take documents home via a laptop without having to remove the documents from the courthouse. 34 The likelihood of document being what the user wanted. 35 Less exact search method that relies on context interpretation to find probable ""matches."" Useful when user does not know exact matching string criteria.  On-Target Information Technology Consulting  A5-42  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY Annotation  FEATURES    31  Identitech FYI Products   Yes Yes   Electronic Signature         Records Storage    Records Management    lock documents supports creating, viewing, printing, deletion and other manipulation of ""sticky notes"" on documents, pages and folders without altering content of documents, including ""read-only"" documents and images supports various security levels for notes (create, view, delete, modify, print, etc.) supports colored notes (optional) support for electronic approval process integrated with workflow capabilities support for third-party software supports encryption supports near-line (magnetic and WORM storage) and off-line storage (tape) supports Hierarchical Storage Management techniques using user-defined business rules supports various vendor's high capacity storage platforms  magnetic disk (native file systems), jukeboxes, network attached devices and SCSI devices (e.g.,CD-ROM tower) supports mirroring of files supports multiple repositories across LAN and WAN index replication and rollback supports archiving/destruction (deleting) of records based on user-defined criteria (e.g., records purging and destruction schedules)            ? ? Yes ? Yes Yes  magnetic and WORM, CD Tape? Yes Need more info on this. We are considering magnetic storage using fault tolerant, raid disk arrays for active cases Yes Yes ? Yes  Uses HSM methods to move documents from on-line to archive storage or to another medium based on a time frame such as number of days, months, years or based on purge criteria such as case status (""closed"") that may come from a LOB application. Yes Yes Yes  supports HSM (see above)       Printing/Output      supports server and remote print services easy to print by page or by document or other object (case file?) supports output to COM (Computer-Output Microfilm) graphical and list-based user views of work items (tasks, folders, documents, etc.) supports structured, production workflow processes (light or medium complexity) database-driven product supports serial, parallel and alternative (if. . .then) routing of electronic objects work process management capabilities include: workflow role definition, task definition, task assignment, task assembly, tracking and monitoring of task status; production statistics supports sign off/approval process and      Workflow Management Workflow        FYI FLOWWORKS  Yes     Yes Yes Yes Yes      Yes, through PIN, raster scanned  On-Target Information Technology Consulting  A5-43  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES  31  Identitech FYI Products          image or combination. 3rd party electronic signature products supported? For example Pen Op? Yes Yes Yes Yes ? ? Yes ?  electronic signature  Process Design/Modeling   Workflow-Electronic Mail Integration    Workflow Application Development    workflow across Intranet (required) or Internet (optional) graphical modeling and design tool kit approach preferred supports light to medium complexity routing processes MS Outlook integration for messaging (mandatory) supports other common SMTP-based mail systems supports event notification via user-defined triggers easy end-user configuration/customization of user interface using graphical tools software includes prototypes, models and outof-the box applications that may serve as examples or be modified restrict access to viewing and printing documents at the page, document, case file and case type level based on user attributes provide an audit trail for viewing certain restricted documents  Document Security           36             ability to assign various document manipulation and viewing options to users (e.g., document add, modify, delete and view functions) support individual user, encrypted passwords and forced periodic change of password notify systems administrator of attempted security breaches log-off user after several incorrect password attempts can use O/S security schema (optional) supports multiple servers across a distributed network central back-end administration for all servers and document repositories on distributed network supports Microsoft NT on various Intel-based servers (mandatory) Supports other leading O/S such as AIX or  Yes ""Need to Know"" Security to the individual document and data field level. Yes Powerful audit trails and reporting tools for managing information access and use. Yes ? ? ? ? Yes ? Yes. Yes  Servers       36  For example: (1) the judge who sealed a record may access the document (or case file) or may grant access to another user based on a court order; (2) adoption files and documents may be viewed only by a judicial officer or specified staff; (3) criminal histories are sealed in the file. Security must also be implemented in conjunction with the case management system security.  On-Target Information Technology Consulting  A5-44  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY Clients and desktops  FEATURES     31  Identitech FYI Products                          System Architecture             Network Communications Protocols Databases Supported             Novell IBM PC and compatible desktop or laptop (mandatory) MS WIN95/98 and NT for fat clients support Support for common browsers for thin clients client runs on any platform 32 bit application highly scalable from a few users to thousands of users across a distributed network intended for enterprise-wide use supports real-time distributed processing over frame relay circuits rapid retrieval can be expected to yield sub 2 second response time given appropriate infrastructure 3 tiered architecture (preferred) two-tiered (acceptable with plans for migration to three-tired within 1 yr. Product must be under development now) web server fault-tolerant features such as replication, automatic cut-over on failure scalable to thousands of users and thousands of simultaneous processes TCP/IP (mandatory); others (optional) uses an ANSI SQL relational database for index (mandatory); supports Informix (optional) unified systems administration for all modules browser-based administration tools (preferred) audit tracking capabilities convenient, robust user/group management functions (graphical tools preferred) import/export of existing user/groups session/intruder monitoring robust, highly configurable user security features screen-level integration with modern clientserver applications  Supports ODMA or WebDAV for integration with desktop applications ODBC gateway for use with reporting and data analysis tools (e.g., Crystal reports, ACCESS, Excel) Supports DMA  Yes, as well as UNIX and MAC (thin client) Yes Yes. Netscape and Microsoft on WIN 95/98, NT, UNIX and MAC Yes Yes Yes ? Based upon system design Yes Yes Yes, need more information Yes Yes Yes  Network protocol- independent, can bridge to other network protocols Yes, many are supported Not specifically mentioned Yes No Yes, need more explanation of features ? ? ? ? Need detailed information Yes. Need more information on this issue, especially integration between LOB and workflow.  ODMA Yes ?  Systems Administration  Integration Standards Supported          On-Target Information Technology Consulting  A5-45  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES    31  Identitech FYI Products   ? ?  Supports CORBA Other standards supported  On-Target Information Technology Consulting  A5-46  6/13/00   Electronic Document Management Systems for the Arizona Courts  Software Evaluation EDMS RFI Company: Keyfile Person Interviewed: Carol Kernich carolK@keyfile.com, Corp Sales Rep. Date: March 2000 Qu e s t i o n   Public or private company  Market focus/audience  Govt. clients?    date     Products Names and version number Release date of products Next release or new product (timeframe) Licenses Worldwide Market Cap Employees License Prices References  govt. FEATURES KEYFILE RESPONSE   Private Company  Exchange Managers of Fortune 2000 companies  Yes, US Department of State, DOD, Navy, Coast Guard  Mult. Governors offices.  KeyFile Product Line: Imaging Active Document Workspace 6.1, Workflow Keyflow 4.1,  XML Keyforms, Records Mgt.  Original release 1989.. Produce 1 to 2 major releases for each product every year.  Active Document Workspace, Summer 00  Keyflow, Fall 00 ? ?  120  Workflow $125/seat... Imaging $ 200 - $300/seat  YES, given when appropriate. 37    FUNCTIONAL CATEGORY Document Management and Capture Electronic ""objects""  KEYFILE RESPONSE      Import utilities      COLD XML 37     stores, manages, retrieves and displays wide variety of electronic objects within the same folders, including TIFF, MS Word, Word Perfect, XML, Adobe Acrobat PDF, MPEG, JPEG, AVI, WAV, ASCII text, raster scanned images, RTF, G3 and G4 fax and other common file formats supports document renditioning (e.g., from word processing to Adobe Acrobat PDF format or from TIFF to PDF or Word Processing to TIFF, etc.) import utilities to accept and incorporate documents not created or scanned through native EDMS software (e.g., COLD data, faxed documents, PDF or XML documents from efiling, etc.); Export utilities ""drag and drop icon"" method for individual documents and batch import desirable captures print streams from application systems (reports, fee receipts, etc.) supports XML documents in repository and for     Yes to all of the above.. Please see attached doc for details.    YES    YES       YES  Incorporate third party packages. Keyforms works with both the  Features are mandatory unless otherwise noted.  On-Target Information Technology Consulting  A5-47  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY Scanning  FEATURES      37  KEYFILE RESPONSE  workflow and imaging products. ADW uses Kofax Accent.  ADW uses Kofax Accent.  YES YES Yes, via Kofax Accent           Image Enhancement and Viewing                 OCR  data exchange scans bi-tonal, gray-scale, and color images  scans fingerprints and handwriting produces/uses standard TIFF files without modification supports simplex and duplex scanning supports wide variety of scanners from low speed (individual desktop units) to high-speed production scanners; flat-bed and page feed scanners supports batch scanning user-selectable scanning density adjustable on-the-fly from 200dpi up bar code recognition document may contain pages of different dpi resolution 2 step scan/commit process for saving images delete, re-scan and insert pages into document before committing to disk display pages on screen during scanning quality control functions may be performed at scanning station or by another user before committing document to disk supports high-volume scanning (up to 25,000 pages per day) scanning operation is software-controlled deskew, reduce background ""noise"" (dots, smudges), cropping and other image clean-up and other enhancement techniques rotate images 90% and 180% zoom in/zoom out fit page to screen thumbnail views of document pages uses a variety of page display methods and supports user in moving through document in a variety of ways, such as: display pages one at a time, multiple pages on screen at once, select desired page easily, go to first/last page bookmark pages for viewing multiple document windows open at once supports viewing of common file formats without launching application that created them (viewers), including images can recognize and launch appropriate application for any object type for which software does not have viewer automatic forms detection and processing 32-bit recognition engine supports English (mandatory); other languages (optional) conversion achieves 99% or greater accuracy                      Yes, via Kofax Accent Yes, via Kofax Accent Yes Yes, via Kofax Accent Yes, via Kofax Accent Yes, via Kofax Accent Yes, via Kofax Accent Yes, via Kofax Accent Yes, via Kofax Accent Yes, via Kofax Accent Yes, via Kofax Accent Yes, via Kofax Accent Yes, via Kofax Accent and our viewer YES No Yes          Yes Yes Yes, we use INSO viewers Yes Yes Yes with third party products Not sure what is being asked?  On-Target Information Technology Consulting  A5-48  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES   37  KEYFILE RESPONSE     Yes Yes Yes, un-limited SQL based. Yes  Indexing      scan document once  dual output (to produce OCR and imaging files) support multiple indexes for different types of documents support up to 10 index fields for documents Links main document and attachments for simultaneous/separate retrieval  Document Access Services Navigation      Mobile Support Searching               supports an organizational hierarchy that can be mapped to case type, case file, case file subsection, document, and page supports transparent user access to multiple, distributed document repositories across LANs and WANs38 personal bookmarks for frequently used items may be set, changed and removed by users supports hyper-text links within documents download files to a laptop and view documents off-line (read-only)39 uses a robust search engine such as Fulcrum or Verity search single document or document repository based on user-defined criteria (index attributes or full-text) transparent search across multiple repositories and servers provides a list of matching documents (repository search), listed by relevancy40 save document search queries for re-use documents may be searched by index values (document attributes) full text documents may be searched by phrases, word proximity search; wild cards and Boolean searches supports fuzzy searching (optional)41 highlight search phrase in text display software optimized for rapid search and retrieval on multiple very large document repositories (125 million pages or more)                  Not sure what is being asked Yes Yes Yes Yes, Keyfile supports brief casing of files. Third party applications such as Fulcrum, Verity or Excalibur can be easily integrated with ADW. Yes Yes Yes Yes Yes Yes, with third party applications. Yes, with third party applications. Yes, with third party applications. Yes  Document and Content 38 39  A user need not know the physical or logical location of a document in order to access it. This feature would enable judges and others to take documents home via a laptop without having to remove the documents from the courthouse. 40 The likelihood of document being what the user wanted. 41 Less exact search method that relies on context interpretation to find probable ""matches."" Useful when user does not know exact matching string criteria.  On-Target Information Technology Consulting  A5-49  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY Management Library services Annotation  FEATURES     37  KEYFILE RESPONSE      Electronic Signature    Records Storage      check in/check out of documents lock documents supports creating, viewing, printing, deletion and other manipulation of ""sticky notes"" on documents, pages and folders without altering content of documents, including ""read-only"" documents and images supports various security levels for notes (create, view, delete, modify, print, etc.) supports colored notes (optional) support for electronic approval process integrated with workflow capabilities support for third-party software supports encryption supports near-line (magnetic and WORM storage) and off-line storage (tape) supports Hierarchical Storage Management techniques using user-defined business rules supports various vendor's high capacity storage platforms  magnetic disk (native file systems), jukeboxes, network attached devices and SCSI devices (e.g.,CD-ROM tower) supports mirroring /RAID supports multiple repositories across LAN and WAN index replication and rollback supports archiving/destruction (deleting) of records based on user-defined criteria (e.g., records purging and destruction schedules) supports remote print/fax services easy to print by page or by document or other object (case file?) supports output to COM (Computer-Output Microfilm)  Yes Yes Yes           Yes Yes Yes Yes, Keyfile has extensive API and SDK's. Yes with third party applications Yes Yes Yes    Records Management Printing/Output      Workflow Management Workflow          Yes Yes Yes Yes Yes Yes No        graphical and list-based user views of work items (tasks, folders, documents, etc.) supports structured, production workflow processes (light or medium complexity) database-driven product supports serial, parallel and alternative (if. . .then) routing of electronic objects work process management capabilities include: workflow role definition, task definition, task assignment, task assembly, tracking and monitoring of task status; production statistics supports sign off/approval process and        Yes Yes Yes, uses Exchange as the database and can leverage SQL. Yes Yes      Yes  On-Target Information Technology Consulting  A5-50  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES   37  KEYFILE RESPONSE          Process Design/Modeling     Workflow-Electronic Mail Integration      Workflow Application Development     electronic signature workflow across Intranet (required) or Internet (optional) graphical modeling and design tool kit approach preferred supports light to medium complexity routing processes MS Outlook integration for messaging (mandatory) supports other common SMTP-based mail systems supports event notification via user-defined triggers easy end-user configuration/customization of user interface using graphical tools software includes prototypes, models and outof-the box applications that may serve as examples or be modified restrict access to viewing and printing documents at the page, document, case file and case type level based on user attributes42 provide an audit trail for viewing certain restricted documents ability to assign various document manipulation and viewing options to users (e.g., document add, modify, delete and view functions) support individual user, encrypted passwords and forced periodic change of password notify systems administrator of attempted security breaches log-off user after several incorrect password attempts can use O/S security schema (optional)  Yes Yes Yes Yes Yes Yes Yes Yes  Document Security                       Yes Yes Yes Yes, Ke NT and Yes, Ke NT and Yes, Ke NT and Yes, Ke NT and YES YES YES YES, via POP3 XML interface. YES yflow leverages the security Exchange for Workflow. yflow leverages the security Exchange for Workflow. yflow leverages the security Exchange for Workflow. yflow leverages the security Exchange for Workflow. of of of of  Servers       Clients and desktops 42    supports multiple servers across a distributed network integrated back-end administration for all servers and document repositories on distributed network supports Microsoft NT on various Intel-based servers (mandatory) Supports other leading O/S such as AIX or Novell IBM PC and compatible desktop or laptop  For example: (1) the judge who sealed a record may access the document (or case file) or may grant access to another user based on a court order; (2) adoption files and documents may be viewed only by a judicial officer or specified staff; (3) criminal histories are sealed in the file. Security must also be implemented in conjunction with the case management system security.  On-Target Information Technology Consulting  A5-51  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES    37  KEYFILE RESPONSE                               YES ? YES  System Architecture             Network Communications Protocols Databases Supported Systems Administration             (mandatory) MS WIN95/98 and NT for fat clients support Support for common browsers for thin clients client runs on any platform 32 bit application highly scalable from a few users to thousands of users across a distributed network intended for enterprise-wide use supports real-time distributed processing over frame relay circuits rapid retrieval can be expected to yield sub 2 second response time given appropriate infrastructure 3 tiered architecture (preferred) two-tiered (acceptable with plans for migration to three-tired within 1 yr. Product must be under development now) web server support fault-tolerant features such as replication, automatic cut-over on failure scalable to thousands of users and thousands of simultaneous processes TCP/IP (mandatory); others (optional) uses an ANSI SQL relational database supports Informix (optional) unified systems administration for all modules browser-based administration tools (preferred) audit tracking capabilities convenient, robust user/group management functions (graphical tools preferred) import/export of existing user/groups session/intruder monitoring robust, highly configurable user security features screen-level integration with modern clientserver applications API tool kit for application development and integration Integration with desktop office products Supports ODMA or WebDAV for integration with desktop applications ODBC connectivity for use with reporting and data analysis tools (e.g., Crystal reports, ACCESS, Excel) Supports DMA Support for CORBA Other standards supported (WfMC, others??)  YES YES YES YES YES ? YES ? ? YES YES, Keyflow takes full advantage of Clustering. YES YES YES, for data analysis. Not at this time. YES Admin is via Outlook YES YES YES YES YES YES YES YES YES YES  Integration     Standards Supported        On-Target Information Technology Consulting  A5-52  6/13/00   Electronic Document Management Systems for the Arizona Courts  Software Evaluation EDMS RFI Company: OIT, Inc. Person Interviewed: Tony Wile Awile@opticaltech.com Date: February 29, 2000 Question      OIT RESPONSE   Private  Various commercial and govt.  Yes, bidding on PA Courts System  Enterprise System includes: OptiFlow, Optimage, Intraviewer, Optifiche (COLD) and API ToolKit  Objectprint: add-on module to support distributed print and fax services  Bar Code recognition: add-on module  Caere search engine  Approve It: Third Party Software for electronic signatures, encrypted signatures  last release in 1999  3 weeks (usually have one release per year)     OIT RESPONSE approx. 300,000 confidential 25 at HQ plus business partners around the USA  Public or private company Market focus/audience Govt. clients? Products Names and version number        Release date of products Next release or new product date (timeframe)  Licenses Worldwide  Market Cap  Employees License Prices  References  govt. FEATURES    FUNCTIONAL CATEGORY Document Management and Capture Electronic ""objects""  43      Import utilities       stores, manages, retrieves and displays wide variety of electronic objects within the same folders, including TIFF, MS Word, Word Perfect, XML, Adobe Acrobat PDF, MPEG, JPEG, AVI, WAV, ASCII text, raster scanned images, RTF, G3 and G4 fax and other common file formats supports document renditioning (e.g., from word processing to Adobe Acrobat PDF format or from TIFF to PDF or Word Processing to TIFF, etc.) import utilities to accept and incorporate documents not created or scanned through native EDMS software (e.g., COLD data, faxed documents, PDF or XML documents from efiling, etc.); Export utilities ""drag and drop icon"" method for individual documents and batch import desirable    Yes    Yes    Yes     Yes Yes. Windows, GUI user interface  43  Features are mandatory unless otherwise noted.  On-Target Information Technology Consulting  A5-53  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY COLD XML Scanning  FEATURES        43  OIT RESPONSE    Yes Yes Yes  Yes  Yes Yes Yes           Image Enhancement and Viewing         captures print streams from application systems (reports, fee receipts, etc.) supports XML documents in repository and for data exchange scans bi-tonal, gray-scale, and color images  scans fingerprints and handwriting produces/uses standard TIFF files without modification supports simplex and duplex scanning supports wide variety of scanners from low speed (individual desktop units) to high-speed production scanners; flat-bed and page feed scanners supports batch scanning user-selectable scanning density adjustable on-the-fly from 200 dpi up bar code recognition document may contain pages of different dpi resolution 2 step scan/commit process for saving images delete, re-scan and insert pages into document before committing to disk display pages on screen during scanning quality control functions may be performed at scanning station or by another user before committing document to disk supports high-volume scanning (up to 25,000 pages per day) scanning operation is software-controlled deskew, reduce background ""noise"" (dots, smudges), cropping and other image clean-up and other enhancement techniques rotate images 90% and 180% zoom in/zoom out fit page to screen thumbnail views of document pages uses a variety of page display methods and supports user in moving through document in a variety of ways, such as: display pages one at a time, multiple pages on screen at once, select desired page easily, go to first/last page bookmark pages for viewing multiple document windows open at once supports viewing of common file formats without launching application that created them (viewers), including images can recognize and launch appropriate application for any object type for which software does not have viewer                      Yes Yes Yes, w/ Add-on Bar Code Recognition software module ?? ?? ?? Yes Yes Yes Yes Yes Ye Ye Ye Ye Ye s s s s s            Yes Yes Yes Yes  On-Target Information Technology Consulting  A5-54  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY OCR  FEATURES      43  OIT RESPONSE         Yes Yes  English; Other Languages --?? ?? Yes Yes Yes, unlimited Yes  Indexing      automatic forms detection and processing 32-bit recognition engine supports English (mandatory); other languages (optional) conversion achieves 99% or greater accuracy scan document once  dual output (to produce OCR and imaging files) support multiple indexes for different types of documents support up to 10 index fields for documents Links main document and attachments for simultaneous/separate retrieval  Document Access Services Navigation      Mobile Support Searching               supports an organizational hierarchy that can be mapped to case type, case file, case file subsection, document, and page supports transparent user access to multiple, distributed document repositories across LANs and WANs44 personal bookmarks for frequently used items may be set, changed and removed by users supports hyper-text links within documents download files to a laptop and view documents off-line (read-only)45 uses a robust search engine such as Fulcrum or Verity search single document or document repository based on user-defined criteria (index attributes or full-text) transparent search across multiple repositories and servers provides a list of matching documents (repository search), listed by relevancy46 save document search queries for re-use documents may be searched by index values (document attributes) full text documents may be searched by phrases, word proximity search; wild cards and Boolean searches supports fuzzy searching (optional)47 highlight search phrase in text display software optimized for rapid search and retrieval on multiple very large document                  Yes, uses hierarchical folders Yes Yes Yes Yes Yes, uses Caere Yes Yes ?? Yes Yes Yes Yes Yes Yes  44 45  A user need not know the physical or logical location of a document in order to access it. This feature would enable judges and others to take documents home via a laptop without having to remove the documents from the courthouse. 46 The likelihood of document being what the user wanted. 47 Less exact search method that relies on context interpretation to find probable ""matches."" Useful when user does not know exact matching string criteria.  On-Target Information Technology Consulting  A5-55  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES  43  OIT RESPONSE  repositories (125 million pages or more) Document and Content Management Library services Annotation       Electronic Signature         Records Storage    Records Management Printing/Output      Workflow Management Workflow  check in/check out of documents lock documents supports creating, viewing, printing, deletion and other manipulation of ""sticky notes"" on documents, pages and folders without altering content of documents, including ""read-only"" documents and images supports various security levels for notes (create, view, delete, modify, print, etc.) supports colored notes (optional) support for electronic approval process integrated with workflow capabilities support for third-party software supports encryption supports near-line (magnetic and WORM storage) and off-line storage (tape) supports Hierarchical Storage Management techniques using user-defined business rules supports various vendor's high capacity storage platforms  magnetic disk (native file systems), jukeboxes, network attached devices and SCSI devices (e.g.,CD-ROM tower) supports mirroring /RAID supports multiple repositories across LAN and WAN index replication and rollback supports archiving/destruction (deleting) of records based on user-defined criteria (e.g., records purging and destruction schedules) supports remote print/fax services easy to print by page or by document or other object (case file?) supports output to COM (Computer-Output Microfilm)      Yes Yes Yes           Yes Yes Yes Yes, with third party software Yes Yes Yes Yes          Yes Yes Yes Yes Yes Yes, by any defined object Yes        graphical and list-based user views of work items (tasks, folders, documents, etc.) supports structured, production workflow processes (light or medium complexity) database-driven product supports serial, parallel and alternative (if. . .then) routing of electronic objects work process management capabilities include: workflow role definition, task definition, task assignment, task assembly, tracking and monitoring of task status; production statistics        Yes Yes Yes Yes Yes  On-Target Information Technology Consulting  A5-56  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES    43  OIT RESPONSE          Yes, w/Third Party Software Yes Yes Yes Yes Yes Yes Yes Yes  Process Design/Modeling     Workflow-Electronic Mail Integration      Workflow Application Development     supports sign off/approval process and electronic signature workflow across Intranet (required) or Internet (optional) graphical modeling and design tool kit approach preferred supports light to medium complexity routing processes MS Outlook integration for messaging (mandatory) supports other common SMTP-based mail systems supports event notification via user-defined triggers easy end-user configuration/customization of user interface using graphical tools software includes prototypes, models and outof-the box applications that may serve as examples or be modified restrict access to viewing and printing documents at the page, document, case file and case type level based on user attributes48 provide an audit trail for viewing certain restricted documents ability to assign various document manipulation and viewing options to users (e.g., document add, modify, delete and view functions) support individual user, encrypted passwords and forced periodic change of password notify systems administrator of attempted security breaches log-off user after several incorrect password attempts can use O/S security schema (optional) supports multiple servers across a distributed network integrated back-end administration for all servers and document repositories on distributed network supports Microsoft NT on various Intel-based servers (mandatory) Supports other leading O/S such as AIX or Novell IBM PC and compatible desktop or laptop  Document Security                       Yes, very granular security to the document/user/grouplevel Yes, can be set Yes Yes, can be set Yes Yes Yes Yes Yes Yes Yes Yes  Servers       Clients and desktops 48    For example: (1) the judge who sealed a record may access the document (or case file) or may grant access to another user based on a court order; (2) adoption files and documents may be viewed only by a judicial officer or specified staff; (3) criminal histories are sealed in the file. Security must also be implemented in conjunction with the case management system security.  On-Target Information Technology Consulting  A5-57  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES    43  OIT RESPONSE                              System Architecture             Network Communications Protocols Databases Supported Systems Administration          (mandatory) MS WIN95/98 and NT for fat clients support Support for common browsers for thin clients client runs on any platform 32 bit application highly scalable from a few users to thousands of users across a distributed network intended for enterprise-wide use supports real-time distributed processing over frame relay circuits rapid retrieval can be expected to yield sub 2 second response time given appropriate infrastructure 3 tiered architecture (preferred) two-tiered (acceptable with plans for migration to three-tired within 1 yr. Product must be under development now) web server support fault-tolerant features such as replication, automatic cut-over on failure scalable to thousands of users and thousands of simultaneous processes TCP/IP (mandatory); others (optional)  Yes Yes Yes Yes Yes Yes 2-3 second response time is standard, given appropriate infrastructure Yes N/A Yes Yes Yes Yes Yes Yes Yes Yes, with Intraviewer Yes Yes Yes Yes Yes Yes Yes Yes Yes  ODMA ? WebDav Yes Yes Yes ??  Integration  Standards Supported  uses an ANSI SQL relational database supports Informix (optional) unified systems administration for all modules browser-based administration tools (preferred) audit tracking capabilities convenient, robust user/group management functions (graphical tools preferred)  import/export of existing user/groups  session/intruder monitoring  robust, highly configurable user security features  screen-level integration with modern clientserver applications  API tool kit for application development and integration  Integration with desktop office products  Supports ODMA or WebDAV for integration with desktop applications  ODBC connectivity for use with reporting and data analysis tools (e.g., Crystal reports, ACCESS, Excel)  Supports DMA  Support for CORBA  Other standards supported (WfMC, others??)     On-Target Information Technology Consulting  A5-58  6/13/00   Electronic Document Management Systems for the Arizona Courts  EDMS Software Evaluation EDMS RFI Company: Open Text, Inc. Person Contacted: David Telenko Date: March 13, 2000 Qu e s t i o n      Public or private company Market focus/audience Govt. clients? Products Names and version number Release date of product  Next release or new product date (timeframe)  Licenses Worldwide  Market Cap  Employees  License Prices  References  govt. FEATURES Yes  stores, manages, retrieves and displays wide variety of electronic objects within the same folders, including TIFF, MS Word, Word Perfect, XML, Adobe Acrobat PDF, MPEG, JPEG, AVI, WAV, ASCII text, raster scanned images, RTF, G3 and G4 fax and other common file formats supports document renditioning (e.g., from word processing to Adobe Acrobat PDF format or from TIFF to PDF or Word Processing to TIFF, etc.) import utilities to accept and incorporate documents not created or scanned through native EDMS software (e.g., COLD data, faxed documents, PDF or XML documents from efiling, etc.); Export utilities ""drag and drop icon"" method for individual documents and batch import desirable captures print streams from application systems (reports, fee receipts, etc.) supports XML documents in repository and for data exchange scans bi-tonal, gray-scale, and color images OPEN TEXT RESPONSE            49  Public Fortune 2000/All Government bodies USAF, US NAVY Livelink 8.1.5 5/95 8.2 Mid Summer 3,600,000 1.2 Billion 800 $125,000 for 1 Server and 100 Named Users  FUNCTIONAL CATEGORY Document Management and Capture Electronic ""objects""  OPEN TEXT RESPONSE Capture functions handled via third party.  Yes.      Yes.  Import utilities      Yes.    COLD XML Scanning 49            Yes. Yes, through the Livelink Explorer module. No. Yes. Yes. Via Kofax or Input Accel  Features are mandatory unless otherwise noted.  On-Target Information Technology Consulting  A5-59  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES      49  OPEN TEXT RESPONSE    Yes. Via Kofax or Input Accel Yes. Via Kofax or Input Accel           Image Enhancement and Viewing                  OCR  scans fingerprints and handwriting produces/uses standard TIFF files without modification supports simplex and duplex scanning supports wide variety of scanners from low speed (individual desktop units) to high-speed production scanners; flat-bed and page feed scanners supports batch scanning using bar code or blank page separators user-selectable scanning density adjustable on-the-fly from 200 dpi up bar code recognition document may contain pages of different dpi resolution 2 step scan/commit process for saving images delete, re-scan and insert pages into document before committing to disk display pages on screen during scanning quality control functions may be performed at scanning station or by another user before committing document to disk supports high-volume scanning (up to 25,000 pages per day) scanning operation is software-controlled deskew, reduce background ""noise"" (dots, smudges), cropping and other image clean-up and other enhancement techniques rotate images 90% and 180% zoom in/zoom out fit page to screen thumbnail views of document pages uses a variety of page display methods and supports user in moving through document in a variety of ways, such as: display pages one at a time, multiple pages on screen at once, select desired page easily, go to first/last page bookmark pages for viewing multiple document windows open at once supports viewing of common file formats without launching application that created them (viewers), including images can recognize and launch appropriate application for any object type for which software does not have viewer automatic forms detection and processing 32-bit recognition engine supports English (mandatory); other languages (optional) conversion achieves 99% or greater accuracy scan document once  dual output (to produce    Yes. Via Kofax or Input Accel Yes. Via Kofax or Input Accel                   Yes. Via Kofax or Input Accel Yes. Via Kofax or Input Accel Yes. Via Kofax or Input Accel Yes. Via Kofax or Input Accel Yes. Via Kofax or Input Accel Yes. Via Kofax or Input Accel Yes. Via Kofax or Input Accel Yes. Via Kofax or Input Accel Yes. Via Kofax or Input Accel Yes. Via Kofax or Input Accel Yes. Via enhanced viewer Yes. Via enhanced viewer Yes. Via enhanced viewer Yes. Via enhanced viewer Yes. Custom Viewer dependent.           Yes. Yes. Yes. All through a browser. Yes. Yes. Custom Yes. Via Kofax or Input Accel No Yes. Via Kofax or Input Accel  On-Target Information Technology Consulting  A5-60  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY Indexing  FEATURES     49  OPEN TEXT RESPONSE     OCR and imaging files) support multiple indexes for different types of documents support up to 10 index fields for documents Links main document and attachments for simultaneous/separate retrieval  Yes Yes. Yes.  Document Access Services Navigation      Mobile Support Searching               supports an organizational hierarchy that can be mapped to case type, case file, case file subsection, document, and page supports transparent user access to multiple, distributed document repositories across LANs and WANs50 personal bookmarks for frequently used items may be set, changed and removed by users supports hyper-text links within documents download files to a laptop and view documents off-line (read-only)51 uses a robust search engine such as Fulcrum or Verity search single document or document repository based on user-defined criteria (index attributes or full-text) transparent search across multiple repositories and servers provides a list of matching documents (repository search), listed by relevancy52 save document search queries for re-use documents may be searched by index values (document attributes) full text documents may be searched by phrases, word proximity search; wild cards and Boolean searches supports fuzzy searching (optional)53 highlight search phrase in text display software optimized for rapid search and retrieval on multiple very large document repositories (125 million pages or more)                  Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes. Yes.  Document and Content Management Library services 50 51    check in/check out of documents    Yes.  A user need not know the physical or logical location of a document in order to access it. This feature would enable judges and others to take documents home via a laptop without having to remove the documents from the courthouse. 52 The likelihood of document being what the user wanted. 53 Less exact search method that relies on context interpretation to find probable ""matches."" Useful when user does not know exact matching string criteria.  On-Target Information Technology Consulting  A5-61  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY Annotation  FEATURES    49  OPEN TEXT RESPONSE   Yes. Yes   Electronic Signature         Records Storage    Records Management Printing/Output      Workflow Management Workflow  lock documents supports creating, viewing, printing, deletion and other manipulation of ""sticky notes"" on documents, pages and folders without altering content of documents, including ""read-only"" documents and images supports various security levels for notes (create, view, delete, modify, print, etc.) supports colored notes (optional) support for electronic approval process integrated with workflow capabilities support for third-party software supports encryption supports near-line (magnetic and WORM storage) and off-line storage (tape) supports Hierarchical Storage Management techniques using user-defined business rules supports various vendor's high capacity storage platforms  magnetic disk (native file systems), jukeboxes, network attached devices and SCSI devices (e.g.,CD-ROM tower) supports mirroring of files supports multiple repositories across LAN and WAN index replication and rollback supports archiving/destruction (deleting) of records based on user-defined criteria (e.g., records purging and destruction schedules) supports server and remote print services easy to print by page or by document or other object (case file?) supports output to COM (Computer-Output Microfilm)           No No Yes. Custom Yes. Yes. Yes. Custom Yes. Custom Yes.          Yes. Custom Yes. Custom Yes. Yes. Yes. Application dependent Yes. Application dependent Custom          Process Design/Modeling   graphical and list-based user views of work items (tasks, folders, documents, etc.) supports structured, production workflow processes (light or medium complexity) database-driven product supports serial, parallel and alternative (if. . .then) routing of electronic objects work process management capabilities include: workflow role definition, task definition, task assignment, task assembly, tracking and monitoring of task status; production statistics supports sign off/approval process and electronic signature workflow across Intranet (required) or Internet (optional) graphical modeling and design tool kit        Yes. Yes. Yes. Yes. Yes.      Yes. Yes. Yes.  On-Target Information Technology Consulting  A5-62  6/13/00   Electronic Document Management Systems for the Arizona Courts  FUNCTIONAL CATEGORY  FEATURES   49  OPEN TEXT RESPONSE        Workflow-Electronic Mail Integration      Workflow Application Development     approach preferred supports light to medium complexity routing processes MS Outlook integration for messaging (mandatory) supports other common SMTP-based mail systems supports event notification via user-defined triggers easy end-user configuration/customization of user interface using graphical tools software includes prototypes, models and outof-the box applications that may serve as examples or be modified restrict access to viewing and printing documents at the page, document, case file and case type level based on user attributes54 provide an audit trail for viewing certain restricted documents ability to assign various document manipulation and viewing options to users (e.g., document add, modify, delete and view functions) support individual user, encrypted passwords and forced periodic change of password notify systems administrator of attempted security breaches log-off user after several incorrect password attempts can use O/S security schema (optional) supports multiple servers across a distributed network central back-end administration for all servers and document repositories on distributed network supports Microsoft NT on various Intel-based servers (mandatory) Supports other leading O/S such as AIX or Novell IBM PC and compatible desktop or laptop (mandatory) MS WIN95/98 and NT for fat clients support Support for common browsers for thin clients client runs on any platform 32 bit application  Yes. Yes. Yes. Yes. Yes. Yes  Document Security                          Yes. Yes. Yes. Yes, but password aging custom No. Yes. Custom Yes Yes No. Yes. RDBMS Only. Livelink on NT, HP-UX and Solaris Browser. None. Thin client only Yes. Yes.  Servers       Clients and desktops      System Architecture 54    For example: (1) the judge who sealed a record may access the document (or case file) or may grant access to another user based on a court order; (2) adoption files and documents may be viewed only by a judicial officer or specified staff; (3) criminal histories are sealed in the file. Security must also be implemented in conjunction with the case management system security.  On-Target Information Technology Consul"
