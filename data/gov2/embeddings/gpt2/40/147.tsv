id	content
GX002-70-10498042	"HMMERBUILD*     [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]      Table of Contents      FUNCTION   DESCRIPTION   EXAMPLE   OUTPUT   INPUT FILES   RELATED PROGRAMS   RESTRICTIONS   SPECIFYING SEQUENCES FOR HMMERBUILD   ALGORITHM   CONSIDERATIONS   COMMAND-LINE SUMMARY   ACKNOWLEDGEMENT   PARAMETER REFERENCE                       FUNCTION    [   Top  |  Next  ]          HmmerBuild creates a position-specific scoring  table, called a profile hidden  Markov model (HMM),  that is a statistical model  of the consensus of a  multiple sequence alignment.  The  profile HMM can be  used for database searching (HmmerSearch),  sequence alignment (HmmerAlign) or generating  random  sequences that match the model  (HmmerEmit).        DESCRIPTION    [  Previous  |  Top  |  Next  ]          HmmerBuild provides a GCG interface  to the hmmbuild program of  Dr. Sean Eddy's HMMER package.  It allows you to access  most of hmmbuild's parameters from  the GCG command line.    HmmerBuild creates a profile hidden  Markov model from a group  of aligned sequences.  A  profile HMM  is a mathematical model that  represents the primary structure consensus  of a sequence family.   The  output from HmmerBuild is a  file that contains an ASCII  text representation of the profile  HMM.    This profile HMM file can  be used as input to  several other programs in the  HMMER package.  HmmerSearch uses the profile HMM  as a query to find  sequences in a database that  are similar to the  aligned sequences from which the  model was built.  HmmerAlign  uses a profile HMM as  a seed to  optimally align a group of  sequences related to the model.   HmmerEmit generates random sequences  that match the profile HMM.    Instead of creating a single  profile HMM as ouput, you  also can add the resulting  profile HMM directly  to an existing HMM database  by using parameter  -APP end .    The aligned sequences may be  specified to HmmerBuild with an  ambiguous file expression or in  a list  file similar to the input  for  Pretty  or  LineUp .   (See Chapter 2, Using Sequence  Files and Databases in  the User's Guide for more  information.)        EXAMPLE    [  Previous  |  Top  |  Next  ]          Here is a session using  HmmerBuild to make a profile  HMM from aligned 75 kd  heat shock and heat  shock cognate peptide sequences (these  sequences were aligned in the  example session for  PileUp ):        %  hmmerbuild    HMMERBUILD of what aligned sequences ?   hsp70.msf{*}    Type of alignments/searches model should lead to:     G Global    L Local    B Single global    C Single local   Choose a model (* G *) :   Setting model type to global.   What should the output file be called (* hsp70.hmm_g *)?   Creating temporary file for input to hmmbuild.   Calling hmmbuild to perform analysis ...  hmmbuild - build a hidden Markov model from an alignment HMMER 2.1.1 (Dec 1998) Copyright (C) 1992-1998 Washington University School of Medicine HMMER is freely distributed under the GNU General Public License (GPL). - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Training alignment:                hsp70.msf{*} Number of sequences:               25 Search algorithm configuration:    Multiple domain (hmmls) Model construction strategy:       MAP (gapmax hint: 0.50) Null model used:                   (default) Prior used:                        (default) Prior strategy:                    Dirichlet Sequence weighting method:         G/S/C tree weights - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Determining effective sequence number    ... done. [3] Weighting sequences heuristically        ... done. Constructing model architecture          ... done. Converting counts to probabilities       ... done. Setting model name, etc.                 ... done. [hsp70]  Constructed a profile HMM (length 677) Average score:     1633.25 bits Minimum score:     1328.99 bits Maximum score:     1777.86 bits Std. deviation:     131.34 bits  Finalizing model configuration           ... done. Saving model to file                     ... done.  [/usr/users/share/smith/hsp70.hmm_g]  %            OUTPUT    [  Previous  |  Top  |  Next  ]          Here is some of the  output file:      HMMER2.0 NAME  hsp70 LENG  677 ALPH  Amino RF    no CS    no MAP   yes COM   gcg_hmmbuild /usr/users/share/smith//hsp70.hmm__g hsp70.msf NSEQ  25 DATE  Fri Jul  9 14:09:29 1999 CKSUM 3252 XT      -8455     -4  -1000  -1000  -8455     -4  -8455     -4 NULT      -4  -8455 NULE     595  -1558     85    338   -294    453  -1158  ...  -1998   -644 HMM        A      C      D      E      F      G      H  ...      W      Y          m->m   m->i   m->d   i->m   i->i   d->m   d->d    b->m   m->e          -368      *  -2150      1    482  -1538   -242    709  -1777   -345     14 ...  -1783  -1160    27      -   -149   -500    233     43   -381    399    106 ...   -294   -249      -    -18  -6880  -7922   -894  -1115   -701  -1378   -386      *      2    209  -1369   -338    519  -1590   -486    -48 ...  -1681  -1096    28      -   -149   -500    233     43   -381    399    106 ...   -294   -249      -    -18  -6880  -7922   -894  -1115   -701  -1378      *      *  ////////////////////////////////////////////////////////////////////////////////     675   -664  -1701     33   2728  -1813  -1361   -295 ...  -1992  -1378   717      -   -149   -500    233     43   -381    399    106 ...   -294   -249      -    -24  -6511  -7553   -894  -1115   -701  -1378      *      *    676   -576   -717  -2213  -1989  -1191  -1755  -1601 ...  -1918  -1514   718      -   -149   -500    233     43   -381    399    106 ...   -294   -249      -    -24  -6511  -7553   -894  -1115   -701  -1378      *      *    677  -1248  -2485   3484    210  -3124   -286   -821 ...  -3039  -2364   719      -      *      *      *      *      *      *      * ...      *      *      -      *      *      *      *      *      *      *      *      0 //            INPUT FILES    [  Previous  |  Top  |  Next  ]          HmmerBuild accepts multiple sequences (one  or more) all of the  same type.  You can  specify multiple  sequences in a number of  ways:  by using a list file,  for example  @project.list ;  by using an  MSF or  RSF file, for example  project.msf{*} ;  or  by using a sequence specification  with an asterisk ( * )  wildcard, for example  GenEMBL:* .    The function of HmmerBuild depends  on whether your input sequence(s)  are protein or nucleotide.  Programs determine the type of  a sequence by the presence  of either  Type: N  or   Type: P  on the last  line of the text heading  just above the sequence.   If your sequence(s) are not  the correct type, turn to  Appendix VI for information on how  to change or set the  type of a sequence.        RELATED PROGRAMS    [  Previous  |  Top  |  Next  ]           PileUp  creates a multiple sequence  alignment from a group of  related sequences.   LineUp  is  a multiple  sequence editor used to create  multiple sequence alignments.   Pretty   displays multiple sequence  alignments.     ProfileMake  makes a profile from  a multiple sequence alignment.    ProfileSearch  uses the profile to  search a database for sequences  with similarity to the group  of aligned sequences.   ProfileSegments   displays optimal alignments between each  sequence in the  ProfileSearch  output  list and the group of  aligned sequences (represented by the  profile consensus).   ProfileGap  makes  optimal alignments  between one or more sequences  and a group of aligned  sequences represented as a profile.    ProfileScan   finds structural and sequence motifs  in protein sequences, using predetermined  parameters to  determine significance.    HmmerBuild makes a profile hidden  Markov model from a multiple  sequence alignment.  HmmerAlign  aligns one or more sequences  to a profile HMM.   HmmerPfam searches a database of  profile HMMs  with a sequence query in  order to identify known domains  within the sequence.  HmmerSearch  uses a  profile HMM as a query  to search a sequence database  for sequences similar to the  original aligned  sequences.  HmmerCalibrate calibrates a  hidden Markov model so that  database searches using it as  a  query will be more sensitive.   HmmerIndex creates a binary  GSI (""generic sequence index"") for  a  database of profile HMMs.   HmmerFetch retrieves a profile hidden  Markov model by name from  an  indexed database of profile HMMs.   HmmerEmit randomly generates sequences  that match a profile  HMM.  HmmerConvert converts between  different profile HMM file formats  and from profile HMM to  GCG profile file format.     MEME  finds conserved motifs in  a group of unaligned sequences  and saves these motifs as  a set of  profiles.  You can search  a database of sequences with  these profiles using the  MotifSearch   program.        RESTRICTIONS    [  Previous  |  Top  |  Next  ]          Hmmerbuild does not perform alignments.   It is your responsibility  to ensure that the sequences  input  to HmmerBuild are in alignment.    HmmerBuild  will  append the ASCII  text format HMM output to  a binary format file, when  using  parameter  -APP end , but the resulting  file will be unusable by  other programs in the HMMER  package.  It also lets  you create mixed nucleic and  protein profile HMM databases, which  will be  unusable by other programs in  the HMMER package as well.        SPECIFYING SEQUENCES FOR HMMERBUILD    [  Previous  |  Top  |  Next  ]          The sequences used to make  the profile HMM can be  specified in two ways.   (See Chapter 2, Using  Sequence Files and Databases in  the User's Guide for more  information.) A group of sequences  may be  named with an ambiguous expression  like  kf*.pep  or  pileup.msf{*} .   The sequences may also be  specified in a list file,  and a beginning and ending  position can be assigned to  each sequence in the list  with the  begin:  and  end:   sequence attributes, respectively.  (See   ""Using List Files""  in Chapter  2,  Using Sequence Files and Databases  in the User's Guide).   Make sure that the sequence  ranges you  specify will result in the  sequences being in alignment.   If you do not specify  beginning and ending  positions, the entire sequence is  used.    HmmerBuild has several built-in ways  of weighting the input sequences  (see the ALGORITHM topic  for more details).  If  you want to use your  own sequence weighting scheme, add  the appropriate  parameters to the list file,  MSF file, or RSF file  that is used as the  input file.  You must  also use the   -WEI ghting =N  parameter when invoking HmmerBuild  to turn off HmmerBuild's built-in  weighting  schemes so that yours will  take precedence.    If you are using a  list file to input your  files, you can add a  weight attribute to any line  in the list with a  text editor in order to  specify a weight for that  sequence (if no weight attribute  is present, the weight  defaults to 1.0).  For  example:             fa12.ugly    begin: 201       end: 250       weight: 0.5      fo1k.ugly    begin: 201       end: 250       weight: 1.0        You can assign weights to  sequences in an MSF file  by editing the MSF file  and modifying the weight  on the name line for  each sequence.  (See ""Using  Multiple Sequence (MSF) Files"" in  Chapter 2, Using  Sequence Files and Databases in  the User's Guide for a  complete description of MSF files.)              Name: Hs70Plafa       Len:   720  Check:  297  Weight:  0.50       Name: Hs70Thean       Len:   720  Check: 1483  Weight:  1.00        You can also edit RSF  files to add a weight  attibute to each sequence.   (See ""Using Rich Sequence  Format (RSF) Files"" in Chapter  2, Using Sequence Files and  Databases in the User's Guide  for a  complete description of RSF files.)             {      name  hs70plafa      descrip     PileUp  of: @Hsp70.List      type    PROTEIN      longname  hsp70.msf{Hs70Plafa}      checksum    297      weight 0.5      creation-date 08/08/2000 15:40:21      strand  1      sequence        [...]      }      {      name  hs70thean      descrip     PileUp  of: @Hsp70.List      type    PROTEIN      longname  hsp70.msf{Hs70Thean}      checksum    1483      weight 1.0      creation-date 08/08/2000 15:40:21      strand  1      sequence        [...]      }        You can use the  SeqLab   editor to assign weights to  sequences in MSF and RSF  files.  (See ""Viewing and  Editing Sequence Attribute and Reference  Information"" in Chapter 2, Editing  Sequences and  Alignments in the  SeqLab  Guide  for more information about modifying  the sequence weight attributes.)    Weights assigned in a list  file take precedence over weights  assigned within MSF or RSF  files that are  components of the list.        ALGORITHM    [  Previous  |  Top  |  Next  ]             See the Profile HMM Analysis  Essay for an introduction to  profile hidden Markov models and  the  terminology associated with them.             State Assignments          In constructing an HMM, HmmerBuild  must first determine which columns  in the alignment  should be assigned to a  match state and which to  an insert state.  The  profile HMM is then built  from this ""marked"" alignment.   By default, HmmerBuild uses maximum   a posteriori  (MAP)  construction:  a dynamic programming algorithm is  used to determine the maximum   a posteriori   choice of state for each  column in the alignment.   This algorithm can be tuned  to favor longer or  shorter models by means of  the  -ARCH prior  parameter, which can  be set to values between  0.0  and 1.0.  By default  this is set to 0.85.   To favor longer models,  set it higher;  to favor shorter  models, set it lower.    Like most dynamic programming algorithms,  MAP construction is fairly slow.   You can use a  faster heuristic method to ""mark""  the columns by specifying the   -FAS t  parameter.  The  heuristic method assigns a column  in the alignment to the  insert state if the column  contains  more than a certain fraction  of gap characters.  By  default, this fraction is 0.5.   You can change it  using the  -GAPS  parameter.    For more detailed information on  how MAP construction works, see  section 5.7, ""Optimal Model  Construction,"" in Chapter 5 of   Biological Sequence Analysis  by Richard  Durbin, et al. (Cambridge  University Press, 1998).        Probability Parameters and Pseudocounts          After determining the state assignments,  HmmerBuild must next assign the  probability  parameters for the model:  the transition  probabilities and emission probabilities.   If there are a  large number of sequences in  the alignment, this can be  done simply by counting up  the number  of times each transition or  emission is used and doing  a trivial calculation to get  the probability.  For example, if column 57  in an alignment of 100  protein sequences contains 60 L's,  10 I's, 9 V's,  two each of M, A,  T and S, and one  each of the remaining amino  acids, the emission probabilities  would be 0.6 for L,  0.1 for I, 0.09 for  V, 0.02 for M, A,  T, and S, and 0.01  for each of the remaining  13 amino acids.    Unfortunately, for alignments containing a  small number of sequences the  observed counts may  not be representative of the  family as a whole.   For example, an alignment containing  only 20 of  the sequences from the example  above may contain all L's  in column 57, resulting in  an  emissions probability of 1.0 for  L and 0.0 for all  other amino acids.  So  there must be a way  of  adjusting the probabilities to account  for unobserved data.    One approach is to add  pseudocounts to the observed counts  so that no zero probabilities  can  occur.  A simple way  is to just add one  to all counts.  More  accurate adjustments can be obtained  by using prior knowledge about  the behavior of sequence families  to adjust the counts.   Two ways  of applying prior knowledge are  substitition matrices and Dirichlet distributions.    The more intuitive method for  most biologists is the use  of substitution matrices.  With  this  heuristic method, entries in a  substitution matrix are converted into  conditional probabilities  that are used to derive  the pseudocounts.  However, the  default method used by HmmerBuild  is  to use a mixture of  Dirichlet distributions as the prior,  because this has a well-founded  theoretical basis.  This method  has been shown to create  good profile HMMs from alignments  containing as few as 10  or 20 sequences.  (Use  the  -MATR ix  parameter if you  want to override  the default and have HmmerBuild  use the substitution matrix method  rather than Dirichlet  priors.)    You can override the default  Dirichlet priors used by HmmerBuild  by providing your own prior  information in a file.   Use the  -DIRI chlet  parameter to  specify this file.  Files  containing the  default prior information are available  to use as models.   These are GenMoreData:amino.pri and  GenMoreData:nucleic.pri.  For a more  detailed description of the file  format, go to   http://hmmer.wustl.edu/hmmer-html/node34.html .    For more information on how  priors work, see section 5.6,  ""More on estimation of probabilities,""  in Chapter 5 of  Biological  Sequence Analysis  by Richard Durbin,  et al. (Cambridge University  Press, 1998).        Null model for profile HMMs          Alignments between profile HMMs and  sequences are scored by computing  a log-odds score  relative to a  null model   of random sequence composition.   The default null model contains  the  expected background occurrence frequencies of  each residue type plus a  parameter called  p1   that controls the expected length  of the randomly generated sequences.   When a profile HMM  is  built, HmmerBuild stores information about  the null model that was  used to create it along  with  the HMM itself.    For proteins, the frequencies for  each of the 20 amino  acids are set to their  observed frequencies  in release 34 of the  SWISS-PROT database and  p1  is  set to 350/351, which implies  that the  expected mean length of a  protein is about 350 residues.   For nucleic acid sequences,  each of the  four nucleotides is assigned a  frequency of 0.25, and  p1   is set to 1000/1001.    You can override this default  null model by providing your  own null model information in  a file.  Use the  -NUL lmodel  parameter to  inform HmmerBuild of the name  of the file.  Files  containing  the default null model information  are available to use as  models.  These are  GenMoreData:amino.null and GenMoreData:nucleic.null.  For  a more detailed description go  to   http://hmmer.wustl.edu/hmmer-html/node33.html .        Weighting the Sequences in the  Alignment          Usually one's sequence alignments do  not contain a good random  sample of all possible  sequences belonging to the family,  but instead may contain a  group of very closely related  sequences plus a number of  more distantly related sequences.   To account for this distorted  representation of a sequence family,  closely related sequences in the  alignment should have less  individual effect on the final  probability distribution than sequences highly  diverged from all  other sequences in the alignment.   For example, if the  same sequence occurs twice in  your  alignment, each instance of this  sequence should get only half  the weight of a single  sequence.  HmmerBuild provides several built-in weighting  schemes.    By default an algorithm proposed  by Gerstein, Sonnhammer, and Clothia  is used.  An  evolutionary tree of the sequences  in the alignment serves as  a guide to weight each  sequence.  Starting at the leaves of  the tree (level N), the  GSC algorithm assigns each sequence  a weight  equal to its distance to  its parent node at the  next higher level (level N-1)  in the tree.  At  level  N-1, the distance to the  parent node at level N-2  is shared among all sequences  in the subtree  below.  A fraction of  that distance, proportional to their  current weight, is added to  the weights  for each sequence.    Another available weighting scheme is  the BLOSUM filtering algorithm ( -WEI ghting =B ).   This  is based on the same  concept that was used to  create the BLOSUM substitution matrices.   The  sequences are clustered depending on  their percent identity; by default  using 62 percent identity  ( -CLUSTERL evel =0.62 ) as the cutoff for  each cluster (as for the  BLOSUM62 matrix).  Each  cluster is assigned a weight  of 1.0, which in turn  is distributed evenly among all  sequences in the  cluster.    The third algorithm is Krogh-Mitchison  maximum entropy weighting ( -WEI ghting =W ), which  is  a more robust version of  the older Eddy-Mitchison-Durbin algorithm.   The original algorithm  determines a weight at each  position of a sequence by  weighting the least common residue  at  that position in the alignment  most heavily, and the most  common residue least heavily.   These  positional weights are then averaged  to give an overall weight  for the sequence.  The  Krogh-Mitchison version doesn't compute a  simple average over the positional  weights, but  instead uses an entropy maximization  method.  It gives a  slight increase in sensitivity over  the  default GSC weighting method, at  the expense of increased computing  time.    A fourth weighting scheme uses  the Sibbald-Argos Voronoi weighting algorithm  ( -WEI ghting =V ).  The idea is  to picture how all sequences  from a family lie in  ""sequence space.""  Some sequences will lie close  together (be clustered) while other  ones will lie far apart  from any  other sequence.  Weights are  assigned proportional to the empty  space around each sequence.    Lastly you can choose to  disable all built-in weighting schemes  ( -WEI ghting =N ).  Normally you  would do this only if  you are providing your own  weights for the sequences.    For more information on the  built-in weighting schemes, see Section  5.8, ""Weighting training  sequences,"" in Chapter 5 of   Biological Sequence Analysis  by Richard  Durbin, et al. (Cambridge  University Press, 1998).        Alignment type incorporated in HMM          The HMMER programs differ from  commonly used sequence comparison and  alignment  programs in that the type  of alignment you want to  eventually perform with the profile  HMM  (global or local) must be  specified at the time the  model is built, rather than  at the time it is  used.  (Note that this  is with respect to the  model only; if the test  sequence is longer than the  model, the entire model may  align within the sequence and  thus be local with respect  to the  sequence and global with respect  to the model.)    For a global alignment to  a model, the entire profile  HMM is aligned with the  test sequence.  This is equivalent to aligning  the entire original sequence alignment  from which the model is  built to a segment within  the test sequence.  For  a local alignment, only part  of the profile HMM  need be aligned with the  sequence.  This is equivalent  to finding the best section  of the original  alignment that matches the test  sequence.    Another alignment characteristic that is  built into the model is  whether to find single or  multiple  domains in the test sequence.   If the profile HMM  is created for single hits,  only one domain per  sequence will be reported, even  if others are present.   Creating a model for multiple  hits means  that all matching domains in  a sequence will be sought  for and reported.    By default, HmmerBuild creates a  model which will allow multiple  global alignments of the  profile HMM and a sequence  ( -MEN u =g ).  You can build  a single global HMM by  specifying the   -MEN u =b  parameter.  Global models  provide maximum sensitivity at the  expense of only locating  complete domains in the test  sequence.    If you are looking for  domain fragments (only part of  the model might be found  in the test  sequence), build a model that  allows local alignments with respect  to the HMM.  Here  again you  can choose to find only  a single match with each  test sequence ( -MEN u =c ) or to  find multiple  matches ( -MEN u =l ).  There is  a slight loss of sensitivity  with the local models.    For creating local models you  can use the  -SWEN try  and   -SWEX it  parameters to favor which  end of the model should  match the test sequence.   By default these are both  set to 0.5 to indicate  no preference.  Setting  -SWEN try   to zero constrains the alignment  to start at the beginning  of  the model while setting it  to 1.0 prevents it from  starting at the beginning of  the model.  Similarly, setting  -SWEX it  to zero  means that the end of  the alignment must coincide with  the  end of the model, while  a value of 1.0 forces  it not to continue to  the end of the model.   So setting  both of these parameters to  zero is equivalent to changing  the model to a global  profile HMM.            For more information, see Eddy,  et al. (Curr. Opin. Struct. Biol., 6; 361-365 (1996)) and  the Eddy lab  website at  http://hmmer.wustl.edu/eddy/ .           CONSIDERATIONS    [  Previous  |  Top  |  Next  ]          If you use the default  Dirichlet mixture priors, you can  obtain a good profile HMM  with as few as ten  or  twenty aligned sequences.    You should calibrate a profile  HMM with HmmerCalibrate before using  it with HmmerSearch or  HmmerPfam.  This will ensure  a more sensitive search, with  better chances of finding distantly  related  homologs to your original sequences.    HmmerBuild, unlike the original hmmbuild  program, will overwrite existing profile  HMMs without  asking your permission.    When you specify option  -MATR ix   to use a heuristic substitution  matrix-based prior, the default  Dirichlet prior is unaffected.   Therefore in principle you could  use options  -DIRI chlet  and  -MATR ix   together, but this is not  recommended, since it has not  been tested.  (Option  -MATR ix   itself has not  been tested extensively.)        COMMAND-LINE SUMMARY    [  Previous  |  Top  |  Next  ]          All parameters for this program  may be added to the  command line.  Use  -CHE ck   to view the summary  below and to specify parameters  before the program executes.   In the summary below, the  capitalized  letters in the parameter names  are the letters that you   must  type in order to  use the parameter.  Square brackets ([ and ])  enclose parameter values that are  optional.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.      Minimal Syntax: % hmmerbuild [-INfile1=]hsp70.msf{*} -Default    Prompted Parameters:    [-OUTfile=]hsp70.hmm_g  names the output file    -MENu=g                 sets model type to multiple global       l                 sets model type to multiple local       b                 sets model type to single global       c                 sets model type to single local    Local Data Files:  None Optional Parameters:    -BEGin1=1 -END1=100     sets the range of interest for each sequence    -SWENtry=0.5            assigns the probability that a local alignment will                           begin at the leftmost end of the model (applies only                           if the model type is l or c) -SWEXit=0.5             assigns the probability that a local alignment will                           end at the rightmost end of the model (applies only                           if the model type is l or c) -PROtein                insists that the sequence alignment is amino acid -DNA                    insists that the sequence alignment is nucleic acid -ARCHprior=0.85         sets the architecture prior used by MAP construction                           algorithm -FASt                   determines model architecture quickly and heuristically                           by assigning columns with more than a certain                           fraction of gap characters to insert states   -GAPS=0.5             sets the minimum fraction of gaps for the -FASt option -NULlmodel=amino.null   uses the null model given in amino.null instead of the                           default null model -DIRIchlet=amino.pri    uses Dirichlet prior information from amino.pri in                           place of the default Dirichlet priors -MATRix=PAM30           uses a heuristic prior based on the PAM30 substitution                             matrix instead of the default Dirichlet priors   -MATWeight=20.0         sets the number of pseudocounts contributed by the                             substitution matrix-based prior -NOEffseqnum            uses the true number of sequences instead of the                           effective sequence number -WEIghting=B            uses the BLOSUM filtering algorithm to weight the                           sequences            M            uses the Krogh/Mitchison maximum entropy algorithm to                           weight the sequences            V            uses the Sibbald/Argos Voronoi sequence weighting                           algorithm to weight the sequences            N            turns off built-in sequence weighting -CLUSTERLevel=0.62      controls determination of effective sequence number and                            sets the clustering threshold when using the                            -WEIghting=B option -NAME=myhmm             sets the internal (not file) name of the profile HMM -APPend                 appends this profile HMM to an existing hmm file -BINary                 writes the profile HMM to hmm file in HMMER binary                           format instead of readable ASCII text -VERbose                prints extra information, such as the individual scores                           for each sequence in the alignment -NOMONitor              doesn't display information about analysis parameters                           used             ACKNOWLEDGEMENT    [  Previous  |  Top  |  Next  ]          The programs comprising the HMMER  package are designed and implemented  by Dr. Sean Eddy of the  Washington University School of Medicine,  St. Louis, Missouri.  The GCG  front-end programs were  written by Christiane van Schlun  in collaboration with Dr. Eddy.    Pfam - A database of  protein domain family alignments and  HMMs Copyright (C) 1996-2000 The  Pfam  Consortium.        PARAMETER REFERENCE    [  Previous  |  Top  |  Next  ]          You can set the parameters  listed below from the command  line.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.              Following some of the parameters  described below is a short  expression in parentheses.  These  are the  names of the corresponding parameters  used in the native HMMER  package.  Some of the  GCG  parameters are identical to the  original HMMER parameters, others have  been changed to fit GCG's  conventions.             -BEG in =1          sets the beginning position for  all sequences in the alignment.   When beginning positions are  specified for individual sequences in  a list file, HmmerBuild ignores  the beginning position set on  the command line.        -END=100          sets the ending position for  all sequences in the alignment.   When ending positions are  specified  for individual sequences in a  list file, HmmerBuild ignores the  ending position set on the  command line.        -MEN u =G      ( -g, -f, -s )         sets the model to be  configured to a specific type  of alignment to a target  sequence: multiple  global alignments (G), single global  alignment (B =  -g ), multiple  local alignments (matching  partial domains) (L =  -f ),  single local alignments (C =   -s ).             -SWEN try =0.5      ( --swentry 0.5 )         When  -MEN u =L  or  -MEN u =C , this  parameter gives you control over  the local  vs  global  alignment behavior at the left  (N- or 5'-terminal) side of  the model.  The default  value is  0.5 and the value may  range from 0.0 to 1.0,  inclusive.    Values greater than 0.5 increase  the penalty for matches that  start at the very beginning  of the model and thus  favor local matches on that  side of the model.   Values less than 0.5,  on the other hand, favor  global matches (those that start  at the very beginning of  the  model) on that side.   Thus setting  -SWEN try  to 0.0  constrains the alignment to start  at  the beginning of the model  and setting it to 1.0  constrains it not to start  at the beginning  of the model.        -SWEX it =0.5      ( --swexit 0.5 )         When  -MEN u =L  or  -MEN u =C , this  parameter gives you control over  the local  vs  global  alignment behavior at the right  (C- or 3'-terminal) side of  the model.  The default  value is  0.5 and the value may  range from 0.0 to 1.0,  inclusive.    Values greater than 0.5 increase  the penalty for matches continuing  to the very end of  the  model and thus favor local  matches on that side of  the model.  Values less  than 0.5, on the  other hand, favor global matches  (those that continue to the  very end of the model)  on that  side.  Thus setting  -SWEX it   to 0.0 means that the  end of the alignment must  coincide  with the end of the  model and setting it to  1.0 constrains it not to  end at the end of  the  model.             -PRO tein      ( --amino )         insists that the sequence alignment  is amino acid.  Normally  HmmerBuild autodetects whether  the sequences are protein or  DNA, but if the sequences  are too short, the autodetect  algorithm  may fail.        -DNA      ( --nucleic )         insists that the sequence alignment  is nucleic acid.  Normally  HmmerBuild autodetects whether  the sequences are protein or  DNA, but if the sequences  are too short, the autodetect  algorithm  may fail.        -ARCH prior =0.85      ( --archpri 0.85 )         sets the  architecture prior  used  by MAP architecture construction.   The default is 0.85 and  the  value may range from 0.0  to 1.0, inclusive.  This  parameter governs a geometric prior  distribution over model lengths.   Higher values mean longer models  are favored  a priori .   Lower  values require greater conservation in  a column before it is  regarded as a ""consensus"" match  column in the model architecture.        -FAS t      ( --fast )         determines the architecture of the  model heuristically by assigning all  columns with more than a  certain fraction of gap characters  to insert states.  This  is faster than using the  default MAP  algorithm.             -GAPS=0.5      ( --gapmax 0.5 )         sets the fraction of gap  characters in a column that  will cause that column to  be assigned  to the insert state when  the  -FAS t  parameter is used.   If a column contains  a higher  fraction of gap symbols than  this, it gets assigned to  an insert column.  The  value can lie  between 0.0 and 1.0, inclusive,  and is set to 0.5  by default.  Higher values  mean more  columns get assigned to the  match state, resulting in a  longer model;  with smaller values,  fewer columns are assigned to  the match state, and the  length of the model is  shorter.             -NUL lmodel =amino.null      ( --null amino.null )         reads null model data from  the file amino.null instead of  using the default null model.   By  default, protein sequences use the  amino acid frequencies from release  34 of the SWISS-PROT  database and  p1  = 350/351;  for nucleic acids each base  is assigned the frequency 0.25  and  p1  =  1000/1001.        -DIRI chlet =amino.pri      ( --prior amino.pri )         reads Dirichlet prior data from  a file named amino.pri, instead  of using the default Dirichlet  priors mixture.        -MATR ix =PAM30      ( --pam PAM30 )         specifies a substitution matrix to  use for a heuristic substitution  matrix-based prior in place of  the default Dirichlet priors mixture.   The matrix must be  in  BLAST  matrix format.   If  HmmerBuild can't find the matrix  you specified in your working  directory, it automatically looks  in the directory associated with  the logical name BLASTMAT.             -MATW eight =20.0      ( --pamwgt 20.0 )         the number of pseudocounts contributed  by the heuristic prior when  a substitution  matrix-based prior is specified with  the  -MATR ix  parameter.  Any  positive real number  may be used; the default  value is 20.0.  Very  high values can force the  scoring system to be  entirely driven by the substitution  matrix, making a profile HMM  behave similarly to a  Gribskov profile.             -NOE ffseqnum      ( --noeff )         turns off the effective sequence  number calculation, and uses the  true number of sequences  instead.  This will usually  reduce the sensitivity of the  final model.        -WEI ghting =B      ( --wblosum )         uses the BLOSUM filtering algorithm  to weight the sequences.   Sequences at a given percent  identity are clustered, and each  cluster is assigned a total  weight of 1.0, distributed equally  among the members of that  cluster.        -WEI ghting =M      ( --wme )         uses the Krogh-Mitchison maximum entropy  algorithm to weight the sequences.   This  supercedes the Eddy-Mitchison-Durbin maximum discrimination  algorithm, which gives almost  identical weights but is less  robust.  Maximum entropy weighting  seems to give a marginal  increase in sensitivity over the  default GSC weights, but takes  a fair amount of time.        -WEI ghting =V      ( --wvoronoi )         uses the Sibbald-Argos Voronoi sequence  weighting algorithm in place of  the default GSC  weighting.        -WEI ghting =N      ( --wnone )         turns off all sequence weighting.        -CLUSTERL evel =0.62      ( --idlevel 0.62 )         controls the determination of effective  sequence number and the behavior  of the  -WEI ghting =B   option.  The sequence alignment  is clustered by percent identity,  and the number of clusters  at  the set cutoff threshold is  used to determine the effective  sequence number.  Higher values  give  more clusters and higher effective  sequence numbers; lower values give  fewer clusters and lower  effective sequence numbers.  The  default is 0.62, corresponding to  the clustering level used in  constructing the BLOSUM62 substitution matrix,  and the value needs to  be between 0.0 and 1.0,  inclusive.        -NAME=myhmm      ( -n myhmm )         sets the internal name (not  file name) of the profile  HMM.        -APP end      ( -A )         appends this model to an  existing HMM file, specified by   -OUT file , rather than overwriting it.  Useful for building profile HMM  libraries (like Pfam).        -BIN ary      ( --binary )         writes the profile HMM to  an HMM file in HMMER  binary format instead of readable  ASCII  text.        -VER bose      ( --verbose )         prints additional information to the  screen, such as the individual  scores for each sequence in  the  alignment.        -NOMON itor          suppresses the display of the  program's progress on the screen.                 Printed: February 5, 2001  11:38 (1162)           [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]       Documentation Comments:  doc-comments@gcg.com  Technical Support:  help@gcg.com      Copyright (c) 1982-2001  Genetics Computer Group  Inc.  A subsidiary of Pharmacopeia, Inc.  All rights reserved.    Licenses and Trademarks Wisconsin Package is a trademark of  Genetics Computer Group , Inc.  GCG and the GCG logo are registered trademarks of  Genetics Computer Group , Inc.    All other product names mentioned in this documentation may be trademarks, and if so, are trademarks or registered trademarks of their respective holders and are used in this documentation for identification purposes only.       www.gcg.com"
GX237-13-11156634	"The JHU/APL HAIRCUT System at TREC-8 James Mayfield, Paul McNamee and Christine Piatko The Johns Hopkins University Applied Physics Laboratory 11100 Johns Hopkins Road Laurel, MD 20723-6099 USA James.Mayfield@jhuapl.edu Paul.McNamee@jhuapl.edu Christine.Piatko@jhuapl.edu  Goals The Johns Hopkins University Applied Physics Laboratory (JHU/APL) is a second-time entrant in the TREC Category A evaluation. The focus of our information retrieval research this year has been on the relative value of and interaction among multiple term types and multiple similarity metrics. In particular, we are interested in examining words and n-grams as indexing terms, and vector models and hidden Markov models as similarity metrics. Approach The Hopkins Automated Information Retriever for Combing Unstructured Text (HAIRCUT) system was built to explore the use of multiple term types, including words, stemmed words, multi-word phrases and character n-grams of various lengths. The system is implemented in Java for ease of development and portability. It supports both a vector model and a hidden Markov model (HMM) for comparing queries against documents. Under the vector model, terms are usually weighted by TF/IDF. Okapi BM 25 [Walker et al., 1998] and plain TF weightings are also supported. Cosines can be computed either relative to the origin, or relative to the corpus centroid. Terms that appear in a high percentage of documents are stop-listed. The HAIRCUT HMM is a simple two-state model capturing both document and collection statistics [Miller et al., 1999]. HAIRCUT also supports breaking documents into passages, although to date we have received no significant boost in average precision from doing so. HAIRCUT performs rudimentary preprocessing on queries to remove stop structure [Allan et al., 1998], e.g., affixes such as ""... would be relevant"" or ""relevant documents should..."". Other than this preprocessing, queries are parsed in the same fashion as are documents in the collection.  After the query is parsed and appropriately weighted (TF/IDF for the vector model, TF for the HMM; query section term-weighting was not used), an initial retrieval is performed with a single round of blind relevance feedback. We found a 27.6% relative increase in average precision on the TREC-7 ad hoc task when using relevance feedback. To perform relevance feedback, HAIRCUT first retrieves the top 1000 documents. The top 20 documents are then used for positive feedback, and the bottom 75 documents for negative feedback. Query terms are reweighted using the Rocchio score (=3, =2, =2) and an affinity score, which is a function of the term's frequency in the retrieved documents and its frequency in the collection as a whole. The topscoring terms, ignoring very high and very low frequency terms, are then used as the revised query. After retrieval using this expanded and reweighted query, we have found a slight improvement by penalizing document scores for documents missing many query terms. We multiply document scores by a penalty factor: 1.25  # of missing terms  PF = 1.0 -    number of terms in query  We use only about one-fifth of the terms of the expanded query for this penalty function: # Top Terms # Penalty Terms words 60 12 6-grams 400 75 We conducted our work on a shared 4-node Sun Microsystems Ultra Enterprise 450 server. The workstation had 2 GB of physical memory and access to 50 GB of hard disk space. The HAIRCUT system comprises approximately 25,000 lines of Java code. For TREC-8 we tested three types of terms: stemmed words, 6-grams and phrases. After eliminating   Figure 1. JHU/APL TREC-8 Ad Hoc Results 100%  90%  80%  70%  60%  apl8c221 apl8c621 apl8p apl8n apl8ctd  Precision  50%  40%  30%  20%  10%  0% 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%  Recall  punctuation, downcasing letters, and mapping numbers to a single digit, a word was any remaining blank-delimited sequence of characters. For n-grams we used 6-grams formed from the same character stream used for selecting words. In TREC-7 we used  5-grams [Mayfield & McNamee 1999], but we have found 6-grams to be preferable for English. Our use of 6-grams for other languages is based on convenience, not proven superiority.  Figure 2. APL TREC-8 Ad Hoc Results Three Baseline Runs and One Merged Run 100% 90% 80%  (31.5%) Combo: 2:2:1 70%  (29.1%) stems, HMM (28.9%) 6-grams, HMM (23.4%) 6-grams, cosine  Precision  60% 50% 40% 30% 20% 10% 0% 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%  Recall   Figure 3. JHU/APL TREC-8 Ad Hoc Base Runs by Topic 100% 90% 80% Average Precision 70% 60% 50% 40% 30% 20% 10% 0% Topic TREC-8 best automatic TREC-8 median automatic base run 1: stem HMM base run 2: 6-gram HMM base run 3: 6-gram cosine base run 4: phrases  Our focus this year was on combining evidence from multiple runs. We varied three system features to obtain runs that were then merged:  use of a vector model versus use of a hidden Markov model;  use of n-grams as terms versus use of words or stemmed words as terms; and  use of phrases. We used two different methods for merging these runs. In most cases we used linear combination of normalized scores. Scores were normalized simply by scaling the range of scores exhibited by the top 1000 documents to the range 0..1. In one case, we selected the retrieval technique on a per-query basis. Ad hoc Results The JHU/APL submissions were based on four underlying retrieval runs:  stemhmm: an HMM run using stemmed words, with =0.3.  sixhmm: an HMM run using 6-grams, using =0.15.  sixcos: a vector-based run using 6-grams as terms and TF/IDF term weighting.  phrase: an HMM run using common stem bigrams, in addition to individual stems, as terms. Our phrase list comprised one million stem pairs. JHU/APL submitted five ad hoc runs. All underlying runs were first normalized as described above. Four runs were based on topic/description/narrative (TDN); one run, as required by the TREC-8 rules, was based on topic and description (TD) only:  apl8c221: A linear combination of stemhmm, sixhmm, and sixcos, with scores from both stemhmm and sixhmm receiving twice the weight of sixcos.  apl8c621: A linear combination comprising six parts stemhmm, two parts sixhmm, and one part sixcos.    Figure 4. JHU/APL TREC-8 Official Ad Hoc Runs by Topic 100% 90%  Average Precision  80% 70% 60% 50% 40% 30% 20% 10% 0%  Topic TREC-8 median automatic TREC-8 best automatic apl8c221 apl8c621 apl8p   Figure 5. JHU/APL TREC-8 CLIR Performance 100% 90% 80% 70% Precision 60% 50% 40% 30% 20% 10% 0% aplxl1 aplxl2 aplxl3 aplxl4  0%  10%  20%  30%  40%  50% Recall  60%  70%  80%  90%  100%  apl8p: A query-by-query combination of apl8c221 and phrase, in which queries that the system judged likely to benefit from phrases were handled exclusively by the phrase run, while the remaining queries were handled exactly as in apl8c221.  apl8n: sixhmm unmodified, submitted as a test of the efficacy of raw n-grams.  apl8ctd: A TD run combining stemhmm, sixhmm, and sixcos in a 2:2:1 ratio. Our official results for these five runs are shown in Figure 1. Aggregate numbers for the base and submitted runs are as follows: Average precision 0.2914 0.2885 0.2340 0.2850 0.3150 0.3126 0.3154 0.2885 0.2860 Relevant retrieved 3156 3061 2919 3153 3332 3335 3295 3061 3117 Precision @100 0.2378 0.2436 0.2106 0.2410 0.2558 0.2558 0.2568 0.2436 0.2324    Figure 2 shows the aggregate improvement obtained by combining three base runs to form apl8c221. Figure 3 shows the average precision for each of the fifty TREC-8 ad hoc topics produced by our four base runs. The chart shows wide variability in the responsiveness of queries to the four techniques. As shown in Figure 4, our linear combination method manages to outperform each of the base methods in aggregate by performing in the upper half of the range of base scores for most queries. Our phrase combination method, also shown in Figure 4, is a first attempt to select a retrieval method on a query-byquery basis. Cross Language Track JHU/APL was a first-time entrant in the CLIR track at TREC-8. We used SYSTRAN to translate English queries into German, French and Italian, HAIRCUT to perform both word-based and n-grambased retrieval on the four collections, and linear combination of normalized scores to combine the eight runs. We found that different languages responded differently to words and n-grams; thus (except for run aplxl2) within each language we used the following weights to combine the two types of runs (which weights were derived from training on the TREC-7 CLIR task): English French German Italian 6-grams 1.0 3.3 3.5 1.0 Words 3.0 1.0 1.0 1.2  stemhmm sixhmm sixcos phrase apl8c221 apl8c621 apl8p apl8n apl8ctd  Our submitted TDN runs exhibited eight of the top scores over the fifty queries; our single TD run exhibited four bests: Task pool Best At or above median apl8c221 automatic TDN 0 40 apl8c621 automatic TDN 4 39 apl8p automatic TDN 1 39 apl8n automatic TDN 3 30 apl8ctd automatic TD 4 37   F i gure 6. Words and n-gr am bas e runs for the four CL IR l anguages . Englis h 100 % 10 0%  Fr ench  90 %  90 %  80 %  80 %  70 %  70 %  P r ecis ion  50 %  P r ecis ion 0% 10% 20% 30 % 40% 50 % 6 0% 70 % 8 0% 90 % 100 %  60 %  60 %  50 %  40 %  40 %  30 %  30 %  20 %  20 %  10 %  10 %  0%  0% 0% 10 % 20% 30 % 40 % 50 % 6 0% 7 0% 8 0% 9 0% 10 0%  Recall (25.38% ) 6- gr am s (24.81% ) Wor ds  Recall (33.55% ) 6- gr am s (35.74% ) Wor ds  Ger man 100 % 10 0%  It alian  90 %  90 %  80 %  80 %  70 %  70 %  P r ecis ion  50 %  P r ecis ion 0% 10% 20% 30 % 40% 50 % 6 0% 70 % 8 0% 90 % 100 %  60 %  60 %  50 %  40 %  40 %  30 %  30 %  20 %  20 %  10 %  10 %  0%  0% 0% 10 % 20% 30 % 40 % 50 % 6 0% 7 0% 8 0% 9 0% 10 0%  Recall (28.29% ) 6- gr am s (16.14% ) Wor ds  Recall (23.91% ) 6- gr am s (24.09% ) Wor ds  We submitted four CLIR runs: 1. aplxl1: A combination that weighted the languages as follows: English French German Italian 2.3 2.0 2.0 1.8 These weights were also derived from training on the TREC-7 CLIR task. It is unclear whether these weights optimize average precision on the TREC-7 task because of differing HAIRCUT performance on the various languages, because of the number of relevant documents in the various languages, or because of other factors. 2. aplxl2: A two-phase combination, in which the languages were first individually combined using the following weights:  English French German Italian 6-grams 1.0 2.5 8.5 1.0 Words 6.0 1.0 1.0 1.5 The resulting combined runs were then merged using these weights: English French German Italian 2.0 1.1 1.1 0.6 As with aplxl1, these weights were trained from the TREC-7 CLIR task. 3. aplxl3: A combination that weighted the four languages evenly: English French German Italian 1.0 1.0 1.0 1.0 4. aplxl4: A combination that weighted English as 1.5, and the other languages as 1.0:   English French German Italian 1.5 1.0 1.0 1.0 Results from these four runs are shown in Figure 5. The eight base runs are shown in Figure 6. Aggregate numbers for our submitted CLIR runs are as follows: Average Relevant Precision precision retrieved @100 aplxl1 0.2571 1911 0.2714 aplxl2 0.2471 1944 0.2782 aplxl3 0.2542 1890 0.2711 aplxl4 0.2389 1902 0.2575 The similarity of these runs lead us to believe that tuning weights under this approach to merging is not a cost-effective use of one's time. Our monolingual results for the four languages, using the human-translated queries provided by NIST, were significantly below those seen on the TREC-7 CLIR task: English French German Italian T8 Words 0.2481 0.3780 0.2525 0.3152 T8 6-grams 0.2538 0.3342 0.3933 0.2778 T7 Words 0.4533 0.3715 0.3671 0.3936 T7 6-grams 0.4363 0.3767 0.4143 0.3281 The reasons for this drop in performance are unclear. Given HAIRCUT's average precision of 31.5% on the TREC-8 ad hoc task, it seems unlikely that the drop in English performance is due to some sort of overtraining on the TREC-7 data. We note a significant drop in the number of relevant documents for the TREC-8 CLIR task, which may play a role: English French German Italian TREC-7 1689 991 917 501 TREC-8 956 578 717 170 Query Track JHU/APL also participated in the query track. We generated four query sets, although space aliens in black helicopters managed to prevent two of them from appearing in the official query track collection. These latter two were generated by hand, by reading the narrative version of each source query and generating a title query and a description query for each. Our first official query set (APL5a) was created using a variant of the mutual information statistic [Church & Hanks 1990] to extract important terms from the top 75 documents retrieved for the source query. Our second set (APL5b) used the same statistic to extract important terms from the query track training set. All terms in these query sets were unstemmed words; we did not anticipate that other systems could make use of n-grams.  We used a single each of the 23 configuration used hidden Markov mo  system configuration to process query track query sets. This unstemmed words as terms, and a del to gauge document similarity.  Our results showed tremendous variability in result quality across the 23 query sets. The following table shows HAIRCUT's performance on each query set, the average performance over all eight runs submitted by five different groups to the query track, and HAIRCUT's percentage above or below the all systems average. Our best results were obtained from APL5b, which was developed using training data. For further details on the query track, see the Query Track Overview paper in these proceedings. HAIRCUT Average precision 0.2521 0.2471 0.2912 0.1697 0.2089 0.2261 0.2061 0.2300 0.1622 0.1990 0.2658 0.2208 0.2533 0.1486 0.1292 0.1293 0.1601 0.1758 0.2603 0.2550 0.2791 0.2405 0.2627 Rel. ret. 5553 5648 6242 4261 4902 5195 4901 4480 4201 4673 5427 5367 5440 3725 3766 3430 4220 4470 5999 5610 5946 5555 5816 Prec. @100 0.3316 0.3300 0.4192 0.2242 0.2642 0.2934 0.2788 0.2796 0.2180 0.2586 0.3386 0.2862 0.3222 0.2050 0.1980 0.1716 0.2078 0.2382 0.3590 0.3312 0.3636 0.3040 0.3558 All systs. average prec. 0.2449 N/A N/A 0.1771 0.2124 0.2259 0.1919 0.2269 0.1612 0.1869 0.2407 0.2022 0.2388 0.1320 0.1182 0.1299 0.1578 0.1754 0.2464 0.2384 0.2504 0.2533 0.2364 Diff. in avg. 2.9% N/A N/A -4.2% -1.6% 0.1% 7.4% 1.4% 0.6% 6.5% 10.4% 9.2% 6.1% 12.6% 9.3% -0.5% 1.5% 0.2% 5.6% 7.0% 11.5% -5.1% 11.1%  acs1a APL5a APL5b INQ1a INQ1b INQ1c INQ1d INQ1e INQ2a INQ2b INQ2c INQ2d INQ2e INQ3a INQ3b INQ3c INQ3d INQ3e pir1a Sab1a Sab1b Sab1c Sab3a  Conclusions We had good results using a simple linear combination of scores across several HAIRCUT runs. In general, HMMs outperformed the vector model, while n-grams and words were roughly comparable on average. Using run combination, HAIRCUT sees an 8% relative gain on the ad hoc task over the best base run. Such combination is low risk; we have never found a drop in average precision over fifty or more queries. Furthermore, effective combination does not require disparate systems. A single system can produce the required variability simply by using different term types or similarity metrics. Availability of both words and n-grams also helped us significantly in the cross-language task, for which   HAIRCUT was a first-time participant. HAIRCUT exhibited 79% recall at 1000 on the CLIR task, and a high average precision relative to retrieval using human-translated queries. References [Allan et al., 1998] James Allan, Jamie Callan, W. Bruce Croft, Lisa Ballesteros, Don Byrd, Russell Swan, and Jinxi Xu, `INQUERY does battle with TREC-6.' In E. M. Voorhees and D. K. Harman, eds., The Sixth Text REtrieval Conference (TREC-6). NIST Special Publication 500-240, pp. 169-206, 1998. [Church & Hanks 1990] Kenneth Ward Church and Patrick Hanks, `Word association norms, mutual information, and lexicography.' Computational Linguistics 16(1):22-29, 1990. [Mayfield & McNamee 1999] James Mayfield and Paul McNamee, `Indexing using both n-grams and words.' In E. M. Voorhees and D. K. Harman, eds., The Seventh Text REtrieval Conference (TREC-7). NIST Special Publication 500-242, pp. 419-423, 1999. [Miller et al., 1999] David R. H. Miller, Tim Leek and Richard M. Schwartz, `BBN at TREC7: Using Hidden Markov Models for Information Retrieval.' In E. M. Voorhees and D. K. Harman, eds., The Seventh Text REtrieval Conference (TREC-7). NIST Special Publication 500-242, pp. 133-142, 1999. [Walker et al., 1998] S. Walker, S. E. Robertson, M. Boughanem, G. J. F. Jones and Karen Sparck Jones, `Okapi at TREC-6, Automatic ad hoc, VLC, routing, filtering and QSDR.' In E. M. Voorhees and D. K. Harman, eds., The Sixth Text REtrieval Conference (TREC-6). NIST Special Publication 500-240, pp. 125-136, 1998."
GX050-24-2301068	"HMMERBUILD     [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]      Table of Contents      FUNCTION   DESCRIPTION   EXAMPLE   OUTPUT   INPUT FILES   RELATED PROGRAMS   RESTRICTIONS   SPECIFYING SEQUENCES FOR HMMERBUILD   ALGORITHM   CONSIDERATIONS   COMMAND-LINE SUMMARY   ACKNOWLEDGEMENT   PARAMETER REFERENCE                       FUNCTION    [   Top  |  Next  ]          HmmerBuild creates a position-specific scoring  table, called a profile hidden  Markov model (HMM),  that is a statistical model  of the consensus of a  multiple sequence alignment.  The  profile HMM can be  used for database searching (HmmerSearch),  sequence alignment (HmmerAlign) or generating  random  sequences that match the model  (HmmerEmit).        DESCRIPTION    [  Previous  |  Top  |  Next  ]          HmmerBuild provides a Wisconsin Package  interface to the hmmbuild program  of Dr. Sean Eddy's  HMMER package.  It allows  you to access most of  hmmbuild's parameters from the Wisconsin  Package  command line.    HmmerBuild creates a profile hidden  Markov model from a group  of aligned sequences.  A  profile HMM  is a mathematical model that  represents the primary structure consensus  of a sequence family.   The  output from HmmerBuild is a  file that contains an ASCII  text representation of the profile  HMM.    This profile HMM file can  be used as input to  several other programs in the  HMMER package.  HmmerSearch uses the profile HMM  as a query to find  sequences in a database that  are similar to the  aligned sequences from which the  model was built.  HmmerAlign  uses a profile HMM as  a seed to  optimally align a group of  sequences related to the model.   HmmerEmit generates random sequences  that match the profile HMM.    Instead of creating a single  profile HMM as ouput, you  also can add the resulting  profile HMM directly  to an existing HMM database  by using parameter  -APP end .    The aligned sequences may be  specified to HmmerBuild with an  ambiguous file expression or in  a list  file similar to the input  for  Pretty  or  LineUp .   (See Chapter 2, Using Sequence  Files and Databases in  the User's Guide for more  information.)        EXAMPLE    [  Previous  |  Top  |  Next  ]          Here is a session using  HmmerBuild to make a profile  HMM from aligned 75 kd  heat shock and heat  shock cognate peptide sequences (these  sequences were aligned in the  example session for  PileUp ):          %  hmmerbuild    HMMERBUILD of what aligned sequences ?   hsp70.msf{*}    Type of alignments/searches model should lead to:     G Global    L Local    B Single global    C Single local   Choose a model (* G *) :   Setting model type to global.   What should the output file be called (* hsp70.hmm_g *)?   Creating temporary file for input to hmmbuild.   Calling hmmbuild to perform analysis ...  hmmbuild - build a hidden Markov model from an alignment HMMER 2.1.1 (Dec 1998) Copyright (C) 1992-1998 Washington University School of Medicine HMMER is freely distributed under the GNU General Public License (GPL). - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Training alignment:                hsp70.msf{*} Number of sequences:               25 Search algorithm configuration:    Multiple domain (hmmls) Model construction strategy:       MAP (gapmax hint: 0.50) Null model used:                   (default) Prior used:                        (default) Prior strategy:                    Dirichlet Sequence weighting method:         G/S/C tree weights - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Determining effective sequence number    ... done. [3] Weighting sequences heuristically        ... done. Constructing model architecture          ... done. Converting counts to probabilities       ... done. Setting model name, etc.                 ... done. [hsp70]  Constructed a profile HMM (length 677) Average score:     1633.25 bits Minimum score:     1328.99 bits Maximum score:     1777.86 bits Std. deviation:     131.34 bits  Finalizing model configuration           ... done. Saving model to file                     ... done.  [/usr/users/share/smith/hsp70.hmm_g]  %              OUTPUT    [  Previous  |  Top  |  Next  ]          Here is some of the  output file:        HMMER2.0 NAME  hsp70 LENG  677 ALPH  Amino RF    no CS    no MAP   yes COM   gcg_hmmbuild /usr/users/share/smith//hsp70.hmm__g hsp70.msf NSEQ  25 DATE  Fri Jul  9 14:09:29 1999 CKSUM 3252 XT      -8455     -4  -1000  -1000  -8455     -4  -8455     -4 NULT      -4  -8455 NULE     595  -1558     85    338   -294    453  -1158  ...  -1998   -644 HMM        A      C      D      E      F      G      H  ...      W      Y          m->m   m->i   m->d   i->m   i->i   d->m   d->d    b->m   m->e          -368      *  -2150      1    482  -1538   -242    709  -1777   -345     14 ...  -1783  -1160    27      -   -149   -500    233     43   -381    399    106 ...   -294   -249      -    -18  -6880  -7922   -894  -1115   -701  -1378   -386      *      2    209  -1369   -338    519  -1590   -486    -48 ...  -1681  -1096    28      -   -149   -500    233     43   -381    399    106 ...   -294   -249      -    -18  -6880  -7922   -894  -1115   -701  -1378      *      *  ////////////////////////////////////////////////////////////////////////////////     675   -664  -1701     33   2728  -1813  -1361   -295 ...  -1992  -1378   717      -   -149   -500    233     43   -381    399    106 ...   -294   -249      -    -24  -6511  -7553   -894  -1115   -701  -1378      *      *    676   -576   -717  -2213  -1989  -1191  -1755  -1601 ...  -1918  -1514   718      -   -149   -500    233     43   -381    399    106 ...   -294   -249      -    -24  -6511  -7553   -894  -1115   -701  -1378      *      *    677  -1248  -2485   3484    210  -3124   -286   -821 ...  -3039  -2364   719      -      *      *      *      *      *      *      * ...      *      *      -      *      *      *      *      *      *      *      *      0 //              INPUT FILES    [  Previous  |  Top  |  Next  ]          HmmerBuild accepts multiple sequences (one  or more) all of the  same type.  You can  specify multiple  sequences in a number of  ways:  by using a list file,  for example  @project.list ;  by using an  MSF or  RSF file, for example  project.msf{*} ;  or  by using a sequence specification  with an asterisk ( * )  wildcard, for example  GenEMBL:* .    The function of HmmerBuild depends  on whether your input sequence(s)  are protein or nucleotide.  Programs determine the type of  a sequence by the presence  of either  Type: N  or   Type: P  on the last  line of the text heading  just above the sequence.   If your sequence(s) are not  the correct type, turn to  Appendix VI for information on how  to change or set the  type of a sequence.        RELATED PROGRAMS    [  Previous  |  Top  |  Next  ]           PileUp  creates a multiple sequence  alignment from a group of  related sequences.   LineUp  is  a multiple  sequence editor used to create  multiple sequence alignments.   Pretty   displays multiple sequence  alignments.     ProfileMake  makes a profile from  a multiple sequence alignment.    ProfileSearch  uses the profile to  search a database for sequences  with similarity to the group  of aligned sequences.   ProfileSegments   displays optimal alignments between each  sequence in the  ProfileSearch  output  list and the group of  aligned sequences (represented by the  profile consensus).   ProfileGap  makes  optimal alignments  between one or more sequences  and a group of aligned  sequences represented as a profile.    ProfileScan   finds structural and sequence motifs  in protein sequences, using predetermined  parameters to  determine significance.    HmmerBuild makes a profile hidden  Markov model from a multiple  sequence alignment.  HmmerAlign  aligns one or more sequences  to a profile HMM.   HmmerPfam searches a database of  profile HMMs  with a sequence query in  order to identify known domains  within the sequence.  HmmerSearch  uses a  profile HMM as a query  to search a sequence database  for sequences similar to the  original aligned  sequences.  HmmerCalibrate calibrates a  hidden Markov model so that  database searches using it as  a  query will be more sensitive.   HmmerIndex creates a binary  GSI (""generic sequence index"") for  a  database of profile HMMs.   HmmerFetch retrieves a profile hidden  Markov model by name from  an  indexed database of profile HMMs.   HmmerEmit randomly generates sequences  that match a profile  HMM.  HmmerConvert converts between  different profile HMM file formats  and from profile HMM to  GCG profile file format.     MEME  finds conserved motifs in  a group of unaligned sequences  and saves these motifs as  a set of  profiles.  You can search  a database of sequences with  these profiles using the  MotifSearch   program.        RESTRICTIONS    [  Previous  |  Top  |  Next  ]          Hmmerbuild does not perform alignments.   It is your responsibility  to ensure that the sequences  input  to HmmerBuild are in alignment.    HmmerBuild  will  append the ASCII  text format HMM output to  a binary format file, when  using  parameter  -APP end , but the resulting  file will be unusable by  other programs in the HMMER  package.  It also lets  you create mixed nucleic and  protein profile HMM databases, which  will be  unusable by other programs in  the HMMER package as well.        SPECIFYING SEQUENCES FOR HMMERBUILD    [  Previous  |  Top  |  Next  ]          The sequences used to make  the profile HMM can be  specified in two ways.   (See Chapter 2, Using  Sequence Files and Databases in  the User's Guide for more  information.) A group of sequences  may be  named with an ambiguous expression  like  kf*.pep  or  pileup.msf{*} .   The sequences may also be  specified in a list file,  and a beginning and ending  position can be assigned to  each sequence in the list  with the  begin:  and  end:   sequence attributes, respectively.  (See   ""Using List Files""  in Chapter  2,  Using Sequence Files and Databases  in the User's Guide).   Make sure that the sequence  ranges you  specify will result in the  sequences being in alignment.   If you do not specify  beginning and ending  positions, the entire sequence is  used.    HmmerBuild has several built-in ways  of weighting the input sequences  (see the ALGORITHM topic  for more details).  If  you want to use your  own sequence weighting scheme, add  the appropriate  parameters to the list file,  MSF file, or RSF file  that is used as the  input file.  You must  also use the   -WEI ghting =N  parameter when invoking HmmerBuild  to turn off HmmerBuild's built-in  weighting  schemes so that yours will  take precedence.    If you are using a  list file to input your  files, you can add a  weight attribute to any line  in the list with a  text editor in order to  specify a weight for that  sequence (if no weight attribute  is present, the weight  defaults to 1.0).  For  example:               fa12.ugly    begin: 201       end: 250       weight: 0.5      fo1k.ugly    begin: 201       end: 250       weight: 1.0          You can assign weights to  sequences in an MSF file  by editing the MSF file  and modifying the weight  on the name line for  each sequence.  (See ""Using  Multiple Sequence (MSF) Files"" in  Chapter 2, Using  Sequence Files and Databases in  the User's Guide for a  complete description of MSF files.)                Name: Hs70Plafa       Len:   720  Check:  297  Weight:  0.50       Name: Hs70Thean       Len:   720  Check: 1483  Weight:  1.00          You can also edit RSF  files to add a weight  attibute to each sequence.   (See ""Using Rich Sequence  Format (RSF) Files"" in Chapter  2, Using Sequence Files and  Databases in the User's Guide  for a  complete description of RSF files.)               {      name  hs70plafa      descrip    PileUp of: @Hsp70.List      type    PROTEIN      longname  hsp70.msf{Hs70Plafa}      checksum    297      weight 0.5      creation-date 08/08/2000 15:40:21      strand  1      sequence        [...]      }      {      name  hs70thean      descrip    PileUp of: @Hsp70.List      type    PROTEIN      longname  hsp70.msf{Hs70Thean}      checksum    1483      weight 1.0      creation-date 08/08/2000 15:40:21      strand  1      sequence        [...]      }          You can use the  SeqLab   editor to assign weights to  sequences in MSF and RSF  files.  (See ""Viewing and  Editing Sequence Attribute and Reference  Information"" in Chapter 2, Editing  Sequences and  Alignments in the  SeqLab  Guide  for more information about modifying  the sequence weight attributes.)    Weights assigned in a list  file take precedence over weights  assigned within MSF or RSF  files that are  components of the list.        ALGORITHM    [  Previous  |  Top  |  Next  ]             See the Profile HMM Analysis  Essay for an introduction to  profile hidden Markov models and  the  terminology associated with them.             State Assignments          In constructing an HMM, HmmerBuild  must first determine which columns  in the alignment  should be assigned to a  match state and which to  an insert state.  The  profile HMM is then built  from this ""marked"" alignment.   By default, HmmerBuild uses maximum   a posteriori  (MAP)  construction:  a dynamic programming algorithm is  used to determine the maximum   a posteriori   choice of state for each  column in the alignment.   This algorithm can be tuned  to favor longer or  shorter models by means of  the  -ARCH prior  parameter, which can  be set to values between  0.0  and 1.0.  By default  this is set to 0.85.   To favor longer models,  set it higher;  to favor shorter  models, set it lower.    Like most dynamic programming algorithms,  MAP construction is fairly slow.   You can use a  faster heuristic method to ""mark""  the columns by specifying the   -FAS t  parameter.  The  heuristic method assigns a column  in the alignment to the  insert state if the column  contains  more than a certain fraction  of gap characters.  By  default, this fraction is 0.5.   You can change it  using the  -GAPS  parameter.    For more detailed information on  how MAP construction works, see  section 5.7, ""Optimal Model  Construction,"" in Chapter 5 of   Biological Sequence Analysis  by Richard  Durbin, et al. (Cambridge  University Press, 1998).        Probability Parameters and Pseudocounts          After determining the state assignments,  HmmerBuild must next assign the  probability  parameters for the model:  the transition  probabilities and emission probabilities.   If there are a  large number of sequences in  the alignment, this can be  done simply by counting up  the number  of times each transition or  emission is used and doing  a trivial calculation to get  the probability.  For example, if column 57  in an alignment of 100  protein sequences contains 60 L's,  10 I's, 9 V's,  two each of M, A,  T and S, and one  each of the remaining amino  acids, the emission probabilities  would be 0.6 for L,  0.1 for I, 0.09 for  V, 0.02 for M, A,  T, and S, and 0.01  for each of the remaining  13 amino acids.    Unfortunately, for alignments containing a  small number of sequences the  observed counts may  not be representative of the  family as a whole.   For example, an alignment containing  only 20 of  the sequences from the example  above may contain all L's  in column 57, resulting in  an  emissions probability of 1.0 for  L and 0.0 for all  other amino acids.  So  there must be a way  of  adjusting the probabilities to account  for unobserved data.    One approach is to add  pseudocounts to the observed counts  so that no zero probabilities  can  occur.  A simple way  is to just add one  to all counts.  More  accurate adjustments can be obtained  by using prior knowledge about  the behavior of sequence families  to adjust the counts.   Two ways  of applying prior knowledge are  substitition matrices and Dirichlet distributions.    The more intuitive method for  most biologists is the use  of substitution matrices.  With  this  heuristic method, entries in a  substitution matrix are converted into  conditional probabilities  that are used to derive  the pseudocounts.  However, the  default method used by HmmerBuild  is  to use a mixture of  Dirichlet distributions as the prior,  because this has a well-founded  theoretical basis.  This method  has been shown to create  good profile HMMs from alignments  containing as few as 10  or 20 sequences.  (Use  the  -MATR ix  parameter if you  want to override  the default and have HmmerBuild  use the substitution matrix method  rather than Dirichlet  priors.)    You can override the default  Dirichlet priors used by HmmerBuild  by providing your own prior  information in a file.   Use the  -DIRI chlet  parameter to  specify this file.  Files  containing the  default prior information are available  to use as models.   These are GenMoreData:amino.pri and  GenMoreData:nucleic.pri.  For a more  detailed description of the file  format, go to   http://hmmer.wustl.edu/hmmer-html/node34.html .    For more information on how  priors work, see section 5.6,  ""More on estimation of probabilities,""  in Chapter 5 of  Biological  Sequence Analysis  by Richard Durbin,  et al. (Cambridge University  Press, 1998).        Null model for profile HMMs          Alignments between profile HMMs and  sequences are scored by computing  a log-odds score  relative to a  null model   of random sequence composition.   The default null model contains  the  expected background occurrence frequencies of  each residue type plus a  parameter called  p1   that controls the expected length  of the randomly generated sequences.   When a profile HMM  is  built, HmmerBuild stores information about  the null model that was  used to create it along  with  the HMM itself.    For proteins, the frequencies for  each of the 20 amino  acids are set to their  observed frequencies  in release 34 of the  SWISS-PROT database and  p1  is  set to 350/351, which implies  that the  expected mean length of a  protein is about 350 residues.   For nucleic acid sequences,  each of the  four nucleotides is assigned a  frequency of 0.25, and  p1   is set to 1000/1001.    You can override this default  null model by providing your  own null model information in  a file.  Use the  -NUL lmodel  parameter to  inform HmmerBuild of the name  of the file.  Files  containing  the default null model information  are available to use as  models.  These are  GenMoreData:amino.null and GenMoreData:nucleic.null.  For  a more detailed description go  to   http://hmmer.wustl.edu/hmmer-html/node33.html .        Weighting the Sequences in the  Alignment          Usually one's sequence alignments do  not contain a good random  sample of all possible  sequences belonging to the family,  but instead may contain a  group of very closely related  sequences plus a number of  more distantly related sequences.   To account for this distorted  representation of a sequence family,  closely related sequences in the  alignment should have less  individual effect on the final  probability distribution than sequences highly  diverged from all  other sequences in the alignment.   For example, if the  same sequence occurs twice in  your  alignment, each instance of this  sequence should get only half  the weight of a single  sequence.  HmmerBuild provides several built-in weighting  schemes.    By default an algorithm proposed  by Gerstein, Sonnhammer, and Clothia  is used.  An  evolutionary tree of the sequences  in the alignment serves as  a guide to weight each  sequence.  Starting at the leaves of  the tree (level N), the  GSC algorithm assigns each sequence  a weight  equal to its distance to  its parent node at the  next higher level (level N-1)  in the tree.  At  level  N-1, the distance to the  parent node at level N-2  is shared among all sequences  in the subtree  below.  A fraction of  that distance, proportional to their  current weight, is added to  the weights  for each sequence.    Another available weighting scheme is  the BLOSUM filtering algorithm ( -WEI ghting =B ).   This  is based on the same  concept that was used to  create the BLOSUM substitution matrices.   The  sequences are clustered depending on  their percent identity; by default  using 62 percent identity  ( -CLUSTERL evel =0.62 ) as the cutoff for  each cluster (as for the  BLOSUM62 matrix).  Each  cluster is assigned a weight  of 1.0, which in turn  is distributed evenly among all  sequences in the  cluster.    The third algorithm is Krogh-Mitchison  maximum entropy weighting ( -WEI ghting =W ), which  is  a more robust version of  the older Eddy-Mitchison-Durbin algorithm.   The original algorithm  determines a weight at each  position of a sequence by  weighting the least common residue  at  that position in the alignment  most heavily, and the most  common residue least heavily.   These  positional weights are then averaged  to give an overall weight  for the sequence.  The  Krogh-Mitchison version doesn't compute a  simple average over the positional  weights, but  instead uses an entropy maximization  method.  It gives a  slight increase in sensitivity over  the  default GSC weighting method, at  the expense of increased computing  time.    A fourth weighting scheme uses  the Sibbald-Argos Voronoi weighting algorithm  ( -WEI ghting =V ).  The idea is  to picture how all sequences  from a family lie in  ""sequence space.""  Some sequences will lie close  together (be clustered) while other  ones will lie far apart  from any  other sequence.  Weights are  assigned proportional to the empty  space around each sequence.    Lastly you can choose to  disable all built-in weighting schemes  ( -WEI ghting =N ).  Normally you  would do this only if  you are providing your own  weights for the sequences.    For more information on the  built-in weighting schemes, see Section  5.8, ""Weighting training  sequences,"" in Chapter 5 of   Biological Sequence Analysis  by Richard  Durbin, et al. (Cambridge  University Press, 1998).        Alignment type incorporated in HMM          The HMMER programs differ from  commonly used sequence comparison and  alignment  programs in that the type  of alignment you want to  eventually perform with the profile  HMM  (global or local) must be  specified at the time the  model is built, rather than  at the time it is  used.  (Note that this  is with respect to the  model only; if the test  sequence is longer than the  model, the entire model may  align within the sequence and  thus be local with respect  to the  sequence and global with respect  to the model.)    For a global alignment to  a model, the entire profile  HMM is aligned with the  test sequence.  This is equivalent to aligning  the entire original sequence alignment  from which the model is  built to a segment within  the test sequence.  For  a local alignment, only part  of the profile HMM  need be aligned with the  sequence.  This is equivalent  to finding the best section  of the original  alignment that matches the test  sequence.    Another alignment characteristic that is  built into the model is  whether to find single or  multiple  domains in the test sequence.   If the profile HMM  is created for single hits,  only one domain per  sequence will be reported, even  if others are present.   Creating a model for multiple  hits means  that all matching domains in  a sequence will be sought  for and reported.    By default, HmmerBuild creates a  model which will allow multiple  global alignments of the  profile HMM and a sequence  ( -MEN u =g ).  You can build  a single global HMM by  specifying the   -MEN u =b  parameter.  Global models  provide maximum sensitivity at the  expense of only locating  complete domains in the test  sequence.    If you are looking for  domain fragments (only part of  the model might be found  in the test  sequence), build a model that  allows local alignments with respect  to the HMM.  Here  again you  can choose to find only  a single match with each  test sequence ( -MEN u =c ) or to  find multiple  matches ( -MEN u =l ).  There is  a slight loss of sensitivity  with the local models.    For creating local models you  can use the  -SWEN try  and   -SWEX it  parameters to favor which  end of the model should  match the test sequence.   By default these are both  set to 0.5 to indicate  no preference.  Setting  -SWEN try   to zero constrains the alignment  to start at the beginning  of  the model while setting it  to 1.0 prevents it from  starting at the beginning of  the model.  Similarly, setting  -SWEX it  to zero  means that the end of  the alignment must coincide with  the  end of the model, while  a value of 1.0 forces  it not to continue to  the end of the model.   So setting  both of these parameters to  zero is equivalent to changing  the model to a global  profile HMM.            For more information, see Eddy,  et al. (Curr. Opin. Struct. Biol., 6; 361-365 (1996)) and  the Eddy lab  website at  http://hmmer.wustl.edu/ .           CONSIDERATIONS    [  Previous  |  Top  |  Next  ]          If you use the default  Dirichlet mixture priors, you can  obtain a good profile HMM  with as few as ten  or  twenty aligned sequences.    You should calibrate a profile  HMM with HmmerCalibrate before using  it with HmmerSearch or  HmmerPfam.  This will ensure  a more sensitive search, with  better chances of finding distantly  related  homologs to your original sequences.    HmmerBuild, unlike the original hmmbuild  program, will overwrite existing profile  HMMs without  asking your permission.    When you specify option  -MATR ix   to use a heuristic substitution  matrix-based prior, the default  Dirichlet prior is unaffected.   Therefore in principle you could  use options  -DIRI chlet  and  -MATR ix   together, but this is not  recommended, since it has not  been tested.  (Option  -MATR ix   itself has not  been tested extensively.)        COMMAND-LINE SUMMARY    [  Previous  |  Top  |  Next  ]          All parameters for this program  may be added to the  command line.  Use  -CHE ck   to view the summary  below and to specify parameters  before the program executes.   In the summary below, the  capitalized  letters in the parameter names  are the letters that you   must  type in order to  use the parameter.  Square brackets ([ and ])  enclose parameter values that are  optional.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.        Minimal Syntax: % hmmerbuild [-INfile1=]hsp70.msf{*} -Default    Prompted Parameters:    [-OUTfile=]hsp70.hmm_g  names the output file    -MENu=g                 sets model type to multiple global       l                 sets model type to multiple local       b                 sets model type to single global       c                 sets model type to single local    Local Data Files:  None Optional Parameters:    -BEGin1=1 -END1=100     sets the range of interest for each sequence    -SWENtry=0.5            assigns the probability that a local alignment will                           begin at the leftmost end of the model (applies only                           if the model type is l or c) -SWEXit=0.5             assigns the probability that a local alignment will                           end at the rightmost end of the model (applies only                           if the model type is l or c) -PROtein                insists that the sequence alignment is amino acid -DNA                    insists that the sequence alignment is nucleic acid -ARCHprior=0.85         sets the architecture prior used by MAP construction                           algorithm -FASt                   determines model architecture quickly and heuristically                           by assigning columns with more than a certain                           fraction of gap characters to insert states   -GAPS=0.5             sets the minimum fraction of gaps for the -FASt option -NULlmodel=amino.null   uses the null model given in amino.null instead of the                           default null model -DIRIchlet=amino.pri    uses Dirichlet prior information from amino.pri in                           place of the default Dirichlet priors -MATRix=PAM30           uses a heuristic prior based on the PAM30 substitution                             matrix instead of the default Dirichlet priors   -MATWeight=20.0         sets the number of pseudocounts contributed by the                             substitution matrix-based prior -NOEffseqnum            uses the true number of sequences instead of the                           effective sequence number -WEIghting=B            uses the BLOSUM filtering algorithm to weight the                           sequences            M            uses the Krogh/Mitchison maximum entropy algorithm to                           weight the sequences            V            uses the Sibbald/Argos Voronoi sequence weighting                           algorithm to weight the sequences            N            turns off built-in sequence weighting -CLUSTERLevel=0.62      controls determination of effective sequence number and                            sets the clustering threshold when using the                            -WEIghting=B option -NAME=myhmm             sets the internal (not file) name of the profile HMM -APPend                 appends this profile HMM to an existing hmm file -BINary                 writes the profile HMM to hmm file in HMMER binary                           format instead of readable ASCII text -VERbose                prints extra information, such as the individual scores                           for each sequence in the alignment -NOMONitor              doesn't display information about analysis parameters                           used               ACKNOWLEDGEMENT    [  Previous  |  Top  |  Next  ]          The programs comprising the HMMER  package are designed and implemented  by Dr. Sean Eddy of the  Washington University School of Medicine,  St. Louis, Missouri.  The Wisconsin  Package front-end  programs were written by Christiane  van Schlun in collaboration with  Dr. Eddy.    Pfam - A database of  protein domain family alignments and  HMMs Copyright (C) 1996-2000 The  Pfam  Consortium.        PARAMETER REFERENCE    [  Previous  |  Top  |  Next  ]          You can set the parameters  listed below from the command  line.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.              Following some of the parameters  described below is a short  expression in parentheses.  These  are the  names of the corresponding parameters  used in the native HMMER  package.  Some of the  GCG  parameters are identical to the  original HMMER parameters, others have  been changed to fit GCG's  conventions.             -BEG in =1          sets the beginning position for  all sequences in the alignment.   When beginning positions are  specified for individual sequences in  a list file, HmmerBuild ignores  the beginning position set on  the command line.        -END=100          sets the ending position for  all sequences in the alignment.   When ending positions are  specified  for individual sequences in a  list file, HmmerBuild ignores the  ending position set on the  command line.        -MEN u =G      ( -g, -f, -s )         sets the model to be  configured to a specific type  of alignment to a target  sequence: multiple  global alignments (G), single global  alignment (B =  -g ), multiple  local alignments (matching  partial domains) (L =  -f ),  single local alignments (C =   -s ).             -SWEN try =0.5      ( --swentry 0.5 )         When  -MEN u =L  or  -MEN u =C , this  parameter gives you control over  the local  vs  global  alignment behavior at the left  (N- or 5'-terminal) side of  the model.  The default  value is  0.5 and the value may  range from 0.0 to 1.0,  inclusive.    Values greater than 0.5 increase  the penalty for matches that  start at the very beginning  of the model and thus  favor local matches on that  side of the model.   Values less than 0.5,  on the other hand, favor  global matches (those that start  at the very beginning of  the  model) on that side.   Thus setting  -SWEN try  to 0.0  constrains the alignment to start  at  the beginning of the model  and setting it to 1.0  constrains it not to start  at the beginning  of the model.        -SWEX it =0.5      ( --swexit 0.5 )         When  -MEN u =L  or  -MEN u =C , this  parameter gives you control over  the local  vs  global  alignment behavior at the right  (C- or 3'-terminal) side of  the model.  The default  value is  0.5 and the value may  range from 0.0 to 1.0,  inclusive.    Values greater than 0.5 increase  the penalty for matches continuing  to the very end of  the  model and thus favor local  matches on that side of  the model.  Values less  than 0.5, on the  other hand, favor global matches  (those that continue to the  very end of the model)  on that  side.  Thus setting  -SWEX it   to 0.0 means that the  end of the alignment must  coincide  with the end of the  model and setting it to  1.0 constrains it not to  end at the end of  the  model.             -PRO tein      ( --amino )         insists that the sequence alignment  is amino acid.  Normally  HmmerBuild autodetects whether  the sequences are protein or  DNA, but if the sequences  are too short, the autodetect  algorithm  may fail.        -DNA      ( --nucleic )         insists that the sequence alignment  is nucleic acid.  Normally  HmmerBuild autodetects whether  the sequences are protein or  DNA, but if the sequences  are too short, the autodetect  algorithm  may fail.        -ARCH prior =0.85      ( --archpri 0.85 )         sets the  architecture prior  used  by MAP architecture construction.   The default is 0.85 and  the  value may range from 0.0  to 1.0, inclusive.  This  parameter governs a geometric prior  distribution over model lengths.   Higher values mean longer models  are favored  a priori .   Lower  values require greater conservation in  a column before it is  regarded as a ""consensus"" match  column in the model architecture.        -FAS t      ( --fast )         determines the architecture of the  model heuristically by assigning all  columns with more than a  certain fraction of gap characters  to insert states.  This  is faster than using the  default MAP  algorithm.             -GAPS=0.5      ( --gapmax 0.5 )         sets the fraction of gap  characters in a column that  will cause that column to  be assigned  to the insert state when  the  -FAS t  parameter is used.   If a column contains  a higher  fraction of gap symbols than  this, it gets assigned to  an insert column.  The  value can lie  between 0.0 and 1.0, inclusive,  and is set to 0.5  by default.  Higher values  mean more  columns get assigned to the  match state, resulting in a  longer model;  with smaller values,  fewer columns are assigned to  the match state, and the  length of the model is  shorter.             -NUL lmodel =amino.null      ( --null amino.null )         reads null model data from  the file amino.null instead of  using the default null model.   By  default, protein sequences use the  amino acid frequencies from release  34 of the SWISS-PROT  database and  p1  = 350/351;  for nucleic acids each base  is assigned the frequency 0.25  and  p1  =  1000/1001.        -DIRI chlet =amino.pri      ( --prior amino.pri )         reads Dirichlet prior data from  a file named amino.pri, instead  of using the default Dirichlet  priors mixture.        -MATR ix =PAM30      ( --pam PAM30 )         specifies a substitution matrix to  use for a heuristic substitution  matrix-based prior in place of  the default Dirichlet priors mixture.   The matrix must be  in  BLAST  matrix format.   If  HmmerBuild can't find the matrix  you specified in your working  directory, it automatically looks  in the directory associated with  the logical name BLASTMAT.             -MATW eight =20.0      ( --pamwgt 20.0 )         the number of pseudocounts contributed  by the heuristic prior when  a substitution  matrix-based prior is specified with  the  -MATR ix  parameter.  Any  positive real number  may be used; the default  value is 20.0.  Very  high values can force the  scoring system to be  entirely driven by the substitution  matrix, making a profile HMM  behave similarly to a  Gribskov profile.             -NOE ffseqnum      ( --noeff )         turns off the effective sequence  number calculation, and uses the  true number of sequences  instead.  This will usually  reduce the sensitivity of the  final model.        -WEI ghting =B      ( --wblosum )         uses the BLOSUM filtering algorithm  to weight the sequences.   Sequences at a given percent  identity are clustered, and each  cluster is assigned a total  weight of 1.0, distributed equally  among the members of that  cluster.        -WEI ghting =M      ( --wme )         uses the Krogh-Mitchison maximum entropy  algorithm to weight the sequences.   This  supercedes the Eddy-Mitchison-Durbin maximum discrimination  algorithm, which gives almost  identical weights but is less  robust.  Maximum entropy weighting  seems to give a marginal  increase in sensitivity over the  default GSC weights, but takes  a fair amount of time.        -WEI ghting =V      ( --wvoronoi )         uses the Sibbald-Argos Voronoi sequence  weighting algorithm in place of  the default GSC  weighting.        -WEI ghting =N      ( --wnone )         turns off all sequence weighting.        -CLUSTERL evel =0.62      ( --idlevel 0.62 )         controls the determination of effective  sequence number and the behavior  of the  -WEI ghting =B   option.  The sequence alignment  is clustered by percent identity,  and the number of clusters  at  the set cutoff threshold is  used to determine the effective  sequence number.  Higher values  give  more clusters and higher effective  sequence numbers; lower values give  fewer clusters and lower  effective sequence numbers.  The  default is 0.62, corresponding to  the clustering level used in  constructing the BLOSUM62 substitution matrix,  and the value needs to  be between 0.0 and 1.0,  inclusive.        -NAME=myhmm      ( -n myhmm )         sets the internal name (not  file name) of the profile  HMM.        -APP end      ( -A )         appends this model to an  existing HMM file, specified by   -OUT file , rather than overwriting it.  Useful for building profile HMM  libraries (like Pfam).        -BIN ary      ( --binary )         writes the profile HMM to  an HMM file in HMMER  binary format instead of readable  ASCII  text.        -VER bose      ( --verbose )         prints additional information to the  screen, such as the individual  scores for each sequence in  the  alignment.        -NOMON itor          suppresses the display of the  program's progress on the screen.                 Printed: January 9, 2002  13:45 (1162)           [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]       Technical Support:  support-us@accelrys.com  or  support-eu@accelrys.com      Copyright (c) 1982-2002 Accelrys Inc.  A subsidiary of Pharmacopeia, Inc.  All rights reserved.    Licenses and Trademarks Wisconsin Package is a trademark and GCG and the GCG logo are registered trademarks of Accelrys Inc.    All other product names mentioned in this documentation may be trademarks, and if so, are trademarks or registered trademarks of their respective holders and are used in this documentation for identification purposes only.       www.accelrys.com/bio"
GX251-20-8800014	"10.1 Golden Section Search in One Dimension  397  one-dimensional sub-minimization. Turn to 10.6 for detailed discussion and implementation.  The second family goes under the names quasi-Newton or variable metric methods, as typified by the Davidon-Fletcher-Powell (DFP) algorithm (sometimes referred to just as Fletcher-Powell) or the closely related Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm. These methods require of order N 2 storage, require derivative calculations and onedimensional sub-minimization. Details are in 10.7. You are now ready to proceed with scaling the peaks (and/or plumbing the depths) of practical optimization. CITED REFERENCES AND FURTHER READING: Dennis, J.E., and Schnabel, R.B. 1983, Numerical Methods for Unconstrained Optimization and Nonlinear Equations (Englewood Cliffs, NJ: Prentice-Hall). Polak, E. 1971, Computational Methods in Optimization (New York: Academic Press). Gill, P.E., Murray, W., and Wright, M.H. 1981, Practical Optimization (New York: Academic Press). Acton, F.S. 1970, Numerical Methods That Work; 1990, corrected edition (Washington: Mathematical Association of America), Chapter 17. Jacobs, D.A.H. (ed.) 1977, The State of the Ar t in Numerical Analysis (London: Academic Press), Chapter III.1. Brent, R.P. 1973, Algorithms for Minimization without Derivatives (Englewood Cliffs, NJ: PrenticeHall). Dahlquist, G., and Bjorck, A. 1974, Numerical Methods (Englewood Cliffs, NJ: Prentice-Hall), Chapter 10.  Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  10.1 Golden Section Search in One Dimension Recall how the bisection method finds roots of functions in one dimension (9.1): The root is supposed to have been bracketed in an interval (a, b). One then evaluates the function at an intermediate point x and obtains a new, smaller bracketing interval, either (a, x) or (x, b). The process continues until the bracketing interval is acceptably small. It is optimal to choose x to be the midpoint of (a, b) so that the decrease in the interval length is maximized when the function is as uncooperative as it can be, i.e., when the luck of the draw forces you to take the bigger bisected segment. There is a precise, though slightly subtle, translation of these considerations to the minimization problem: What does it mean to bracket a minimum? A root of a function is known to be bracketed by a pair of points, a and b, when the function has opposite sign at those two points. A minimum, by contrast, is known to be bracketed only when there is a triplet of points, a < b < c (or c < b < a), such that f (b) is less than both f (a) and f (c). In this case we know that the function (if it is nonsingular) has a minimum in the interval (a, c). The analog of bisection is to choose a new point x, either between a and b or between b and c. Suppose, to be specific, that we make the latter choice. Then we evaluate f (x). If f (b) < f (x), then the new bracketing triplet of points is (a, b, x);   398  Chapter 10.  Minimization or Maximization of Functions  2 4 1 5 4 6 Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  5  6  3  Figure 10.1.1. Successive bracketing of a minimum. The minimum is originally bracketed by points 1,3,2. The function is evaluated at 4, which replaces 2; then at 5, which replaces 1; then at 6, which replaces 4. The rule at each stage is to keep a center point that is lower than the two outside points. After the steps shown, the minimum is bracketed by points 5,3,6.  contrariwise, if f (b) > f (x), then the new bracketing triplet is (b, x, c). In all cases the middle point of the new triplet is the abscissa whose ordinate is the best minimum achieved so far; see Figure 10.1.1. We continue the process of bracketing until the distance between the two outer points of the triplet is tolerably small. How small is ""tolerably"" small? For a minimum located at a value b, you might naively think that you will be able to bracket it in as small a range as (1 - )b < b < (1 + )b, where is your computer's floating-point precision, a number like 3  10 -8 (for float) or 10 -15 (for double). Not so! In general, the shape of your function f (x) near b will be given by Taylor's theorem 1 f (x)  f (b)+ f (b)(x - b)2 2 (10.1.1)  The second term will be negligible compared to the first (that is, will be a factor smaller and will act just like zero when added to it) whenever |x - b| <  |b| 2 |f (b)| b2 f (b) (10.1.2)  The reason for writing the right-hand side in this way is that, for most functions, the final square root is a number of order unity. Therefore, as rule of thumb, it a times its central is hopeless to ask for a bracketing interval of width less than value, a fractional width of only about 10 -4 (single precision) or 3  10 -8 (double precision). Knowing this inescapable fact will save you a lot of useless bisections! The minimum-finding routines of this chapter will often call for a user-supplied argument tol, and return with an abscissa whose fractional precision is about tol (bracketing interval of fractional size about 2tol). Unless you have a better   10.1 Golden Section Search in One Dimension  399  estimate for the right-hand side of equation (10.1.2), you should set tol equal to (not much less than) the square root of your machine's floating-point precision, since smaller values will gain you nothing. It remains to decide on a strategy for choosing the new point x, given (a, b, c). Suppose that b is a fraction w of the way between a and c, i.e. b-a =w c-a c-b =1-w c-a Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  (10.1.3)  Also suppose that our next trial point x is an additional fraction z beyond b, x-b =z c-a (10.1.4)  Then the next bracketing segment will either be of length w + z relative to the current one, or else of length 1 - w. If we want to minimize the worst case possibility, then we will choose z to make these equal, namely z = 1 - 2w (10.1.5)  We see at once that the new point is the symmetric point to b in the original interval, namely with |b - a| equal to |x - c|. This implies that the point x lies in the larger of the two segments (z is positive only if w < 1/2). But where in the larger segment? Where did the value of w itself come from? Presumably from the previous stage of applying our same strategy. Therefore, if z is chosen to be optimal, then so was w before it. This scale similarity implies that x should be the same fraction of the way from b to c (if that is the bigger segment) as was b from a to c, in other words, z =w 1-w Equations (10.1.5) and (10.1.6) give the quadratic equation  3- 5 2  0.38197 w - 3w +1 = 0 yielding w= 2 (10.1.6)  (10.1.7)  In other words, the optimal bracketing interval (a, b, c) has its middle point b a fractional distance 0.38197 from one end (say, a), and 0.61803 from the other end (say, b). These fractions are those of the so-called golden mean or golden section, whose supposedly aesthetic properties hark back to the ancient Pythagoreans. This optimal method of function minimization, the analog of the bisection method for finding zeros, is thus called the golden section search, summarized as follows: Given, at each stage, a bracketing triplet of points, the next point to be tried is that which is a fraction 0.38197 into the larger of the two intervals (measuring from the central point of the triplet). If you start out with a bracketing triplet whose segments are not in the golden ratios, the procedure of choosing successive points at the golden mean point of the larger segment will quickly converge you to the proper, self-replicating ratios. The golden section search guarantees that each new function evaluation will (after self-replicating ratios have been achieved) bracket the minimum to an interval   400  Chapter 10.  Minimization or Maximization of Functions  just 0.61803 times the size of the preceding interval. This is comparable to, but not quite as good as, the 0.50000 that holds when finding roots by bisection. Note that the convergence is linear (in the language of Chapter 9), meaning that successive significant figures are won linearly with additional function evaluations. In the next section we will give a superlinear method, where the rate at which successive significant figures are liberated increases with each successive function evaluation.  Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  Routine for Initially Bracketing a Minimum The preceding discussion has assumed that you are able to bracket the minimum in the first place. We consider this initial bracketing to be an essential part of any one-dimensional minimization. There are some one-dimensional algorithms that do not require a rigorous initial bracketing. However, we would never trade the secure feeling of knowing that a minimum is ""in there somewhere"" for the dubious reduction of function evaluations that these nonbracketing routines may promise. Please bracket your minima (or, for that matter, your zeros) before isolating them! There is not much theory as to how to do this bracketing. Obviously you want to step downhill. But how far? We like to take larger and larger steps, starting with some (wild?) initial guess and then increasing the stepsize at each step either by a constant factor, or else by the result of a parabolic extrapolation of the preceding points that is designed to take us to the extrapolated turning point. It doesn't much matter if the steps get big. After all, we are stepping downhill, so we already have the left and middle points of the bracketing triplet. We just need to take a big enough step to stop the downhill trend and get a high third point. Our standard routine is this: #include   #include ""nrutil.h"" #define GOLD 1.618034 #define GLIMIT 100.0 #define TINY 1.0e-20 #define SHFT(a,b,c,d) (a)=(b);(b)=(c);(c)=(d); Here GOLD is the default ratio by which successive intervals are magnified; GLIMIT is the maximum magnification allowed for a parabolic-fit step. void mnbrak(float *ax, float *bx, float *cx, float *fa, float *fb, float *fc, float (*func)(float)) Given a function func, and given distinct initial points ax and bx, this routine searches in the downhill direction (defined by the function as evaluated at the initial points) and returns new points ax, bx, cx that bracket a minimum of the function. Also returned are the function values at the three points, fa, fb, and fc. { float ulim,u,r,q,fu,dum; *fa=(*func)(*ax); *fb=(*func)(*bx); if (*fb > *fa) { SHFT(dum,*ax,*bx,dum) SHFT(dum,*fb,*fa,dum) } *cx=(*bx)+GOLD*(*bx-*ax); *fc=(*func)(*cx); while (*fb > *fc) { r=(*bx-*ax)*(*fb-*fc); q=(*bx-*cx)*(*fb-*fa); u=(*bx)-((*bx-*cx)*q-(*bx-*ax)*r)/  Switch roles of a and b so that we can go downhill in the direction from a to b. First guess for c. Keep returning here until we bracket. Compute u by parabolic extrapolation from a, b, c. TINY is used to prevent any possible division by zero.   10.1 Golden Section Search in One Dimension  401  (2.0*SIGN(FMAX(fabs(q-r),TINY),q-r)); ulim=(*bx)+GLIMIT*(*cx-*bx); We won't go farther than this. Test various possibilities: if ((*bx-u)*(u-*cx) > 0.0) { Parabolic u is between b and c: try it. fu=(*func)(u); if (fu < *fc) { Got a minimum between b and c. *ax=(*bx); *bx=u; *fa=(*fb); *fb=fu; return; } else if (fu > *fb) { Got a minimum between between a and u. *cx=u; *fc=fu; return; } u=(*cx)+GOLD*(*cx-*bx); Parabolic fit was no use. Use default magfu=(*func)(u); nification. } else if ((*cx-u)*(u-ulim) > 0.0) { Parabolic fit is between c and its fu=(*func)(u); allowed limit. if (fu < *fc) { SHFT(*bx,*cx,u,*cx+GOLD*(*cx-*bx)) SHFT(*fb,*fc,fu,(*func)(u)) } } else if ((u-ulim)*(ulim-*cx) >= 0.0) { Limit parabolic u to maximum allowed value. u=ulim; fu=(*func)(u); } else { Reject parabolic u, use default magnification. u=(*cx)+GOLD*(*cx-*bx); fu=(*func)(u); } SHFT(*ax,*bx,*cx,u) Eliminate oldest point and continue. SHFT(*fa,*fb,*fc,fu) } }  Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  (Because of the housekeeping involved in moving around three or four points and their function values, the above program ends up looking deceptively formidable. That is true of several other programs in this chapter as well. The underlying ideas, however, are quite simple.)  Routine for Golden Section Search #include #define #define #define #define   R 0.61803399 The golden ratios. C (1.0-R) SHFT2(a,b,c) (a)=(b);(b)=(c); SHFT3(a,b,c,d) (a)=(b);(b)=(c);(c)=(d);  float golden(float ax, float bx, float cx, float (*f)(float), float tol, float *xmin) Given a function f, and given a bracketing triplet of abscissas ax, bx, cx (such that bx is between ax and cx, and f(bx) is less than both f(ax) and f(cx)), this routine performs a golden section search for the minimum, isolating it to a fractional precision of about tol. The abscissa of the minimum is returned as xmin, and the minimum function value is returned as golden, the returned function value. { float f1,f2,x0,x1,x2,x3;   402  Chapter 10.  Minimization or Maximization of Functions  x0=ax; At any given time we will keep track of four x3=cx; points, x0,x1,x2,x3 . if (fabs(cx-bx) > fabs(bx-ax)) { Make x0 to x1 the smaller segment, x1=bx; x2=bx+C*(cx-bx); and fill in the new point to be tried. } else { x2=bx; x1=bx-C*(bx-ax); } f1=(*f)(x1); The initial function evaluations. Note that f2=(*f)(x2); we never need to evaluate the function while (fabs(x3-x0) > tol*(fabs(x1)+fabs(x2))) { at the original endpoints. if (f2 < f1) { One possible outcome, SHFT3(x0,x1,x2,R*x1+C*x3) its housekeeping, SHFT2(f1,f2,(*f)(x2)) and a new function evaluation. } else { The other outcome, SHFT3(x3,x2,x1,R*x2+C*x0) SHFT2(f2,f1,(*f)(x1)) and its new function evaluation. } } Back to see if we are done. if (f1 < f2) { We are done. Output the best of the two *xmin=x1; current values. return f1; } else { *xmin=x2; return f2; } }  Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  10.2 Parabolic Interpolation and Brent's Method in One Dimension We already tipped our hand about the desirability of parabolic interpolation in the previous section's mnbrak routine, but it is now time to be more explicit. A golden section search is designed to handle, in effect, the worst possible case of function minimization, with the uncooperative minimum hunted down and cornered like a scared rabbit. But why assume the worst? If the function is nicely parabolic near to the minimum -- surely the generic case for sufficiently smooth functions -- then the parabola fitted through any three points ought to take us in a single leap to the minimum, or at least very near to it (see Figure 10.2.1). Since we want to find an abscissa rather than an ordinate, the procedure is technically called inverse parabolic interpolation. The formula for the abscissa x that is the minimum of a parabola through three points f (a), f (b), and f (c) is x=b- 1 (b - a)2 [f (b) - f (c)] - (b - c)2 [f (b) - f (a)] 2 (b - a)[f (b) - f (c)] - (b - c)[f (b) - f (a)] (10.2.1)  as you can easily derive. This formula fails only if the three points are collinear, in which case the denominator is zero (minimum of the parabola is infinitely far"
GX034-25-12140964	"[  Index |  A   B   C   D   E   F   G   H   I   J   K   L   M   N   O   P   Q   R   S   T   U   V  W  X  Y Z ]       RADREC: Range, ra and dec to rectangular coordinates         Abstract      Convert from range, right ascension, and declination to     rectangular coordinates.       Copyright      Copyright (1995), California Institute of Technology.     U.S. Government sponsorship acknowledged.       Required Reading      None.       Brief I/O      VARIABLE  I/O  DESCRIPTION     --------  ---  ---------------------------------------------------     range      I   Distance of a point from the origin.     ra         I   Right ascension, angular distance of the point from                    the XZ plane radians.     dec        I   Declination, angular distance of the point from the                    XY plane in radians.     rectan     O   Rectangular coordinates of the point, in input                    units.       Detailed Input      range      is the distance of the point from the origin. Input                should be in terms of the same units in which the                output is desired.      ra         is the right ascension, the angular distance measured                toward the east from the XZ plane to the point. ra                normally ranges from 0 to ( 2 *  pi  ) radians; however,                this routine accepts angles not in this range.      dec        is the declination, the angular distance from the XY                plane to the point.  dec normally ranges from                -(  pi /2 ) to (  pi /2 ) radians; however this routine                accepts angles not in this range. Occasionally the                declination is an angle greater than  pi /2.       Detailed Output      rectan     is the array containing the rectangular coordinates of                the point.  The output unit of the rectangular                coordinates is the same as the input unit of the range.        Parameters      None.       Particulars      This routine converts the right ascension, declination, and range     describing a point into the associated rectangular coordinates by     calling the CSPICE routine  latrec .      The input is defined by a distance from a central reference point,     an angle from a reference meridian, and an angle above the equator     of a sphere centered at the central reference point.      This is a companion routine to  recrad . These routines exist as a     convenience, and merely call other routines.       Examples      The following code fragment converts right ascension and     declination from  B1950  to  J2000 .            SpiceDouble      ra;          SpiceDouble      dec;           SpiceDouble      r;          SpiceInt         oldref;          SpiceInt         newref;          SpiceDouble      rotab  [ 3 ][ 3 ];           SpiceDouble      oldvec [ 3 ];          SpiceDouble      newvec [ 3 ];             radrec  ( 1.0, ra, dec, oldvec );           irfnum ( ' B1950 ', oldref );          irfnum ( ' J2000 ', newref );          irfrot ( oldref,  newref, rotab  );            mxv     ( rotab,   oldvec, newvec );           recrad  ( newvec,  R,      ra,     dec );        Restrictions      None.       Exceptions      Error free.       Files      None.       Author and Institution      H.A. Neilan     (JPL)       Literature References      ""Celestial Mechanics, A Computational Guide for the Practitioner""     by Laurence G. Taff       Version      -CSPICE Version 1.0.0, 08-FEB-1998 (EDW)      Index Entries      range ra and dec to rectangular coordinates     right_ascension and declination to rectangular             RAV2XF: Rotation and angular velocity to transform         Abstract      This routine determines from a state transformation matrix     the associated rotation matrix and angular velocity of the     rotation.       Copyright      Copyright (1995), California Institute of Technology.     U.S. Government sponsorship acknowledged.       Required Reading      None.       Brief I/O      VARIABLE  I/O  DESCRIPTION     --------  ---  --------------------------------------------------     rot        I   Rotation matrix.    av         I   Angular velocity vector.     xform      O   State transformation associated with rot and av.      Detailed Input      rot         is a rotation that gives the transformation from                 some  frame  frame1 to another  frame  frame2.      av          is the angular velocity of the transformation.                 In other words, if p is the position of a fixed                 point in frame2, then from the point of view of                 frame1,  p rotates (in a right handed sense) about                 an axis parallel to av.  Moreover the rate of rotation                 in radians per unit time is given by the length of                 av.                  More formally, the velocity v of p in frame1 is                 given by                                    t                     v  = av x ( rot * p )       Detailed Output      xform       is a state transformation matrix associated                 with rot and av.  If s1 is the state of an object                 with respect to frame1, then the state s2 of the                 object with respect to frame2 is given by                      s2  =  xform * s1                  where ""*"" denotes matrix-vector multiplication.        Parameters      None.       Particulars      This routine is essentially a macro routine for converting     a rotation and angular velocity of the rotation to the     equivalent state transformation matrix.      This routine is an inverse of  xf2rav .      Examples      Suppose that you wanted to determine state transformation     matrix from a platform  frame  to the  J2000   frame .         /.       The following call obtains the  J2000 -to-platform transformation       matrix and platform angular velocity at the time of interest.       The time value is expressed as encoded SCLK.       ./         ckgpav  ( ckid, time, tol, "" J2000 "", rot, av, &clkout, &fnd );        /.       Recall that rot and av are the rotation and angular velocity        of the transformation from  J2000  to the platform  frame .        ./        if ( fnd )       {           /.          First get the state transformation from  J2000  to the platform            frame .           ./            rav2xf  ( rot, av, j2plt );           /.            Invert  the state transformation matrix (using invstm) to            the desired state transformation matrix.           ./           invstm ( j2plt, xform );       }       Restrictions      None.       Exceptions      Error free.      1) No checks are performed on ROT to ensure that it is indeed        a rotation matrix.       Files      None.       Author and Institution      N.J. Bachman    (JPL)    W.L. Taber      (JPL)       Literature References      None.       Version      -CSPICE Version 1.0.0, 18-JUN-1999 (WLT) (NJB)       Index Entries     State transformation to rotation and angular velocity             RAXISA: Rotation axis of a matrix         Abstract      Compute the axis of the rotation given by an input matrix     and the angle of the rotation about that axis.       Copyright      Copyright (1995), California Institute of Technology.     U.S. Government sponsorship acknowledged.       Required Reading       ROTATION        Brief I/O       VARIABLE  I/O  DESCRIPTION      --------  ---  --------------------------------------------------      matrix     I   3x3 rotation matrix in double precision.      axis       O   Axis of the rotation.      angle      O   Angle through which the rotation is performed.       Detailed Input       matrix     is a 3x3 rotation matrix in double precision.       Detailed Output       axis       is a unit vector pointing along the axis of the                 rotation.  In other words, axis is a unit eigen vector                 of the input matrix.       angle      is the angle between v and matrix*v for any non-zero                 vector v orthogonal to axis.  Angle is given in                 radians.       Parameters       None.       Particulars       Using the formulas developed in the reference this routine      computes the axis and angle of the rotation matrix.       The pertinent formulas are:       Let r be the rotation matrix            r11  r12  r13           r21  r22  r23           r31  r32  r33       cosine(angle) = 0.5* trace (r) - 0.5        w1  =  2*sine(angle)*axis[0]  =  r32 - r23      w2  =  2*sine(angle)*axis[1]  =  r13 - r31      w3  =  2*sine(angle)*axis[2]  =  r21 - r12       If the angle is a multiple of  pi , then r is given by           2*w1**2 - 1   2*w1*w2         2*w1*w3          2*w1*w2       2*w2**2 - 1     2*w2*w3          2*w1*w3       2*w2*w3         2*w3**2 - 1       These equations are those used to compute the axis and angle of      the rotation.       Examples       This routine can be used to numerically approximate the      instantaneous angular velocity vector of a rotating object.       Suppose that r(t) is the rotation matrix whose columns      represent the inertial pointing vectors of the bodyfixed      axes of an object at time t.       Then the angular velocity vector points along the vector      given by:                             T         limit  axis( r(t+h)r )         h-->0       And the magnitude of the angular velocity at time t is given by:                              T         d angle ( r(t+h)r(t) )         ----------------------   at   h = 0         dh       Thus to approximate the angular velocity vector the following      code fragment will do          [ Load t      into the double precision variable t           Load h      into the double precision variable h           Load r(t+h) into the 3 by 3 double precision array rth           Load r(t)   into the 3 by 3 double precision array rt            .            .            .         ]         /.                                                     T        Compute the infinitesimal rotation r(t+h)r(t)          ./         mxmt  ( rth, rt, infrot );         /.        Compute the axis and angle of the infinitesimal rotation.        /.         raxisa  ( infrot, axis, &angle );         /.        Scale axis to get the angular velocity vector.        ./         vscl  ( angle/h, axis, angvel );        Restrictions       It's the user's responsibility to make sure the input matrix      is indeed a rotation matrix.       The user should be aware that the input matrix is taken to be an      object that acts on (rotates) vectors---it is not regarded as      a coordinate transformation.  If the user needs to find the axis      and angle of a coordinate transformation he/she should input      the transpose of that matrix to this routine.       Exceptions      Error free       Files       None.       Author and Institution       W.L. Taber      (JPL)      N.J. Bachman    (JPL)      Literature References       JPL IOM 314.8-568, 14 October 1985. ""Rotations and Their Habits"",      by W. L. Taber       Version      -CSPICE Version 1.0.0, 31-MAY-1999 (WLT) (NJB)      Index Entries      rotation axis of a matrix             RDTEXT: Read a line from a text file         Abstract      Read the next line of text from a text file.      Copyright      Copyright (1999), California Institute of Technology.    U.S. Government sponsorship acknowledged.      Required Reading      None.      Brief I/O      VARIABLE  I/O  DESCRIPTION    --------  ---  ---------------------------------------------------    file       I   Name of text file.    lenout     I   Available room in output line.    line       O   Next line from the text file.    eof        O   End-of-file indicator.      Detailed Input      file        is the name of the text file from which the next                line is to be read. If the file is not currently                open, it is opened with a logical unit determined                at run time, and the first line of the file is                returned. Otherwise, the next line not yet read                from the file is read and returned.     lenout      is the available room in the output line, including                the terminating null.  If the maximum expected length                of an output line is N, lenout should be at least N+1.      Detailed Output      line        is next line of text in the specified file.                If the end of the file is reached, LINE is blank.     eof         is true when the end of the file is reached, and is                otherwise false.      Parameters      None.      Particulars       rdtext  reads the next line from a text file. If the file is    not currently open, it is opened with a logical unit determined    at run time, and the first line of the file is returned.    Otherwise, the next line not yet read from the file is returned.     If the end of the file is reached, an empty line is returned,    the end-of-file indicator is true, and the file is closed.     Several files may be opened and read simultaneously. Thus,    you may begin reading from one file before the end of another    file has been reached.  rdtext  maintains a separate file pointer    for each file.      Examples      Let FILE.1 contain the following lines.        Mary had a little lamb       Everywhere that Mary went     Let FILE.2 contain the following lines.        Its fleece was white as snow.       The lamb was sure to go.        Note:  You do not what and end-of-file on the same line as       text.  That text will be ignored.      Then the code fragment     #include ""SpiceUsr.h""    #define LENOUT 32     main(void)       {        SpiceBoolean eof;       SpiceChar    line[LENOUT];        eof = SPICEFALSE;        do {           rdtext  ( ""file.1"", LENOUT, line, &eof );          printf ( ""%s \n"", line );            rdtext  ( ""file.2"", LENOUT, line, &eof );          printf ( ""%s \n"", line );          }       while ( !eof );        }     produces the following output        Mary had a little lamb       Its fleece was white as snow.       Everywhere that Mary went       The lamb was sure to go.      Restrictions      None.      Exceptions      1) If too many files are open already, the error       SPICE(TOOMANYFILESOPEN) is signaled.     2) If the attempt to open the file fails, the error       SPICE(FILEOPENFAILED) is signaled.     3) If the attempt to read from the file fails, the error       SPICE(FILEREADFAILED) is signaled.     4) If the attempt to ""inquire"" the status of the file fails,       the error SPICE(INQUIREFAILED) is signaled.      Files      See input FILE.      Author and Institution      N.J. Bachman    (JPL)    H.A. Neilan     (JPL)    M.J. Spencer    (JPL)    I.M. Underwood  (JPL)      Literature References      None.      Version      -CSPICE Version 2.0.0, 07-OCT-1999   (NJB)        Changed argument list to conform to SPICE convention:  LENOUT       now precedes the output string.        Added description of lenout to the header.        Added local logical variable for EOF flag.     -CSPICE Version 1.0.0, 25-MAY-1999   (EDW)      Index Entries      read a line from a text file            RECCYL: Rectangular to cylindrical coordinates         Abstract      Convert from rectangular to cylindrical coordinates.        Copyright      Copyright (1995), California Institute of Technology.     U.S. Government sponsorship acknowledged.       Required Reading      None.       Brief I/O      VARIABLE  I/O  DESCRIPTION     --------  ---  -------------------------------------------------     rectan     I   Rectangular coordinates of a point.     r          O   Distance of the point from z axis.     lon        O   Angle (radians) of the point from xZ plane     z          O   Height of the point above xY plane.       Detailed Input      rectan     Rectangular coordinates of the point of interest.       Detailed Output      r          Distance of the point of interest from z axis.      lon        Cylindrical angle (in radians) of the point of                interest from xZ plane.      z          Height of the point above xY plane.       Parameters      None.       Particulars      This routine transforms the coordinates of a point from     rectangular to cylindrical coordinates.       Examples      Below are two tables.      Listed in the first table (under x(1), x(2) and x(3) ) are a     number of points whose rectangular coordinates coorindates are     taken from the set {-1, 0, 1}.      The result of the code fragment            reccyl  ( x, r,  lon, z );          Use the CSPICE routine  convrt  to convert the angular          quantities to degrees            convrt  (  lon, ""RADIANS"", ""DEGREES"", lon  );     are listed to 4 decimal places in the second parallel table under     r (radius), lon  (longitude), and  z (same as rectangular z     coordinate).         x(1)       x(2)     x(3)        r         lon      z       --------------------------      -------------------------       0.0000     0.0000   0.0000      0.0000    0.0000   0.0000       1.0000     0.0000   0.0000      1.0000    0.0000   0.0000       0.0000     1.0000   0.0000      1.0000   90.0000   0.0000       0.0000     0.0000   1.0000      0.0000    0.0000   1.0000      -1.0000     0.0000   0.0000      1.0000  180.0000   0.0000       0.0000    -1.0000   0.0000      1.0000  270.0000   0.0000       0.0000     0.0000  -1.0000      0.0000    0.0000  -1.0000       1.0000     1.0000   0.0000      1.4142   45.0000   0.0000       1.0000     0.0000   1.0000      1.0000    0.0000   1.0000       0.0000     1.0000   1.0000      1.0000   90.0000   1.0000       1.0000     1.0000   1.0000      1.4142   45.0000   1.0000       Restrictions      None.       Exceptions      Error free.       Files      None.       Author and Institution      W.L. Taber      (JPL)       Literature References      None.       Version      -CSPICE Version 1.1.0, 21-OCT-1998 (NJB)        Made input vector const.     -CSPICE Version 1.0.0, 08-FEB-1998   (EDW)      Index Entries      rectangular to cylindrical coordinates             RECGEO: Rectangular to geodetic         Abstract      Convert from rectangular coordinates to geodetic coordinates.       Copyright      Copyright (1995), California Institute of Technology.     U.S. Government sponsorship acknowledged.       Required Reading      None.       Brief I/O      VARIABLE  I/O  DESCRIPTION     --------  ---  --------------------------------------------------     rectan     I   Rectangular coordinates of a point.     re         I   Equatorial radius of the reference ellipsoid.     f          I   Flattening coefficient.     lon        O   Geodetic longitude of the point (radians).     lat        O   Geodetic latitude  of the point (radians).     alt        O   Altitude of the point above reference ellipsoid.       Detailed Input       rectan    Rectangular coordinates of the input point.  Note that               the X, Y and Z axes point in the directions of               (0 lat, 0 lon), (0 lat, 90 lon) and (90 lat, 0 lon)               respectively. (The units used in this description are               in degrees.  The input units for latitude and               longitude should be radians.)      re        Equatorial radius of the reference spheroid.      f         Flattening coefficient = (re-rp) / re, where rp is               the polar radius of the spheroid.       Detailed Output      lon       Geodetic longitude of point (radians).      lat       Geodetic latitude  of point (radians).      alt       Altitude of point above the reference spheroid.       Parameters       None.       Particulars      Given the bodyfixed rectangular coordinates of a point, and the     constants describing the reference spheroid,  this routine     returns the geodetic coordinates of the point.  The bodyfixed     rectangular  frame  is that having the x-axis pass through the     0 degree latitude 0 degree longitude point.  The y-axis passes     through the 0 degree latitude 90 degree longitude.  The z-axis     passes through the 90 degree latitude point.  For some bodies     this coordinate system may not be a right-handed coordinate     system.       Examples      This routine can be used to convert body fixed rectangular     coordinates (such as the Satellite Tracking and Data Network     of 1973) to geodetic coordinates such as those used by the     United States Geological Survey topographic maps.      The code would look something like this             /.            Shift the STDN-73 coordinates to line up with the center            of the Clark66 reference system.            ./                vsub  ( STDNX, OFFSET, X );            /.           Using the equatorial radius of the Clark66 spheroid            (CLARKR = 6378.2064 km) and the Clark 66 flattening            factor (CLARKF = 1.0 / 294.9787 ) convert to            geodetic coordinates of the North American Datum of 1927.            ./             recgeo  ( X, CLARKR, CLARKF, lon, lat, alt )        Below are two tables.      Listed in the first table (under X[0], X[1] and X(3) ) are a     number of points whose rectangular coordinates are     taken from the set {-1, 0, 1}.        The result of the code fragment            recgeo  ( X, CLARKR, CLARKF, lon, lat, alt );          Use the CSPICE routine  convrt  to convert the angular          quantities to degrees            convrt  ( lat, ""RADIANS"", ""DEGREES"", lat  );          convrt  ( lon, ""RADIANS"", ""DEGREES"", lon );     are listed to 4 decimal places in the second parallel table under     r (radius), colat (co-latitude), and  lon (longitude).          X[0]       X[1]     X(3)         lon      colat        alt       --------------------------       ----------------------------       0.0000     0.0000   0.0000       0.0000    90.0000   -6356.5838       1.0000     0.0000   0.0000       0.0000     0.0000   -6377.2063       0.0000     1.0000   0.0000      90.0000     0.0000   -6377.2063       0.0000     0.0000   1.0000       0.0000    90.0000   -6355.5838      -1.0000     0.0000   0.0000     180.0000     0.0000   -6377.2063       0.0000    -1.0000   0.0000     -90.0000     0.0000   -6377.2063       0.0000     0.0000  -1.0000       0.0000   -90.0000   -6355.5838       1.0000     1.0000   0.0000      45.0000     0.0000   -6376.7921       1.0000     0.0000   1.0000       0.0000    88.7070   -6355.5725       0.0000     1.0000   1.0000      90.0000    88.7070   -6355.5725       1.0000     1.0000   1.0000      45.0000    88.1713   -6355.5612       Restrictions       The bodyfixed rectangular  frame  is that having the x-axis pass      through the 0 degree latitude 0 degree longitude point.  The      y-axis passes through the 0 degree latitude 90 degree longitude.      The z-axis passes through the 90 degree latitude point.  For some      bodies this coordinate system may not be a right-handed      coordinate system.       Exceptions       1) If the equatorial radius is non-positive, the error         SPICE(VALUEOUTOFRANGE) is signalled.       2) If the flattening coefficient is greater than or equal to         one, the error SPICE(VALUEOUTOFRANGE) is signalled.       Files       None.       Author and Institution       H.A. Neilan     (JPL)      W.L. Taber      (JPL)       Literature References       See FUNDAMENTALS OF ASTRODYNAMICS, Bate, Mueller, White      published by Dover for a description of geodetic coordinates.       Version      -CSPICE Version 1.1.0, 21-OCT-1998 (NJB)        Made input vector const.     -CSPICE Version 1.0.0, 08-FEB-1998   (EDW)      Index Entries      rectangular to geodetic             RECLAT: Rectangular to latitudinal coordinates         Abstract      Convert from rectangular coordinates to latitudinal coordinates.      Copyright      Copyright (1997), California Institute of Technology.    U.S. Government sponsorship acknowledged.      Required Reading      None.      Brief I/O      VARIABLE  I/O  DESCRIPTION    --------  ---  --------------------------------------------------    rectan     I   Rectangular coordinates of the point.    radius     O   Distance of a point from the origin.    longitude  O   Angle of the point from the XZ plane in radians.    latitude   O   Angle of the point from the XY plane in radians.      Detailed Input      rectan     The rectangular coordinates of the input point, a 3               vector.      Detailed Output      radius     Distance of a point from the origin.     longitude  Angle of the point from the XZ plane in radians.     latitude   Angle of the point from the XY plane in radians.      Parameters      None.       Particulars      This routine returns the latitudinal coordinates of a point    whose position is input in rectangular coordinates.     Latitudinal coordinates are defined by a distance from a central    reference point, an angle from a reference meridian, and an angle    above the equator of a sphere centered at the central reference    point.      Examples      Below are two tables.     Listed in the first table (under rectan[0], rectan[1], and rectan[2])     are a number of points whose rectangular coordinates coorindates are    taken from the set {-1, 0, 1}.     The result of the code fragment         reclat  ( rectan, &r, &longitude, &latitude );        latitude  = latitude  *  dpr ();       longitude = longitude *  dpr ();     are listed to 4 decimal places in the second parallel table under    r (radius), longitude, and latitude.     rectan[0]  rectan[1] rectan[2]    r       longitude  latitude    -------------------------------   ----------------------------      0.0000     0.0000   0.0000      0.0000    0.0000    0.0000      1.0000     0.0000   0.0000      1.0000    0.0000    0.0000      0.0000     1.0000   0.0000      1.0000   90.0000    0.0000      0.0000     0.0000   1.0000      1.0000    0.0000   90.0000     -1.0000     0.0000   0.0000      1.0000  180.0000    0.0000      0.0000    -1.0000   0.0000      1.0000  -90.0000    0.0000      0.0000     0.0000  -1.0000      1.0000    0.0000  -90.0000      1.0000     1.0000   0.0000      1.4142   45.0000    0.0000      1.0000     0.0000   1.0000      1.4142    0.0000   45.0000      0.0000     1.0000   1.0000      1.4142   90.0000   45.0000      1.0000     1.0000   1.0000      1.7320   45.0000   35.2643      Restrictions      None.      Exceptions      Error free.       Files      None.       Author and Institution      W.L. Taber      (JPL)     E.D. Wright     (JPL)      Literature References      None.      Version      -CSPICE Version 1.1.0, 21-OCT-1998 (NJB)        Made input vector const.     -CSPICE Version 1.0.0, 08-FEB-1998 (EDW)      Index Entries      rectangular to latitudinal coordinates            RECRAD: Rectangular coordinates to ra and dec         Abstract       Accepts as input rectangular coordinates and returns the range,      right ascension, and declination.       Copyright      Copyright (1995), California Institute of Technology.     U.S. Government sponsorship acknowledged.       Required Reading      None.       Brief I/O      VARIABLE  I/O  DESCRIPTION     --------  ---  --------------------------------------------------     rectan     I   Rectangular coordinates of a point.     range      O   Distance of the point from the origin.     ra         O   Right ascension in radians.     dec        O   Declination in radians.       Detailed Input      rectan     contains the rectangular coordinates of a point.       Detailed Output      range      is the distance of the point from the origin.      ra         is the right ascension, the angular distance                measured toward the east from the XZ plane to the                point.  ra ranges from 0 to ( 2 *  pi  ) radians.      dec        is the angle from the XY plane to the point.                dec ranges from - (  pi /2 ) to (  pi /2 ) radians.       Parameters      None.       Particulars      This routine returns the range, right ascension, and declination     of a point whose position is input in rectangular coordinates.      The output is defined by a distance from a central reference     point, an angle from a reference meridian, and an angle above     the equator of a sphere centered at the central reference     point.      This subroutine calls  reclat  which returns range, latitude, and     longitude. The longitude ranges from -  pi  to  pi  radians.  The     right ascension however, ranges from zero to two  pi  radians.     If the longitude returned by  reclat  is negative, this subroutine     adds two  pi  to it so that it then falls within the range of the     right ascension.       Examples      The following code fragment demonstrates the use of  recrad .       Determine the intersection of a line-of-sight vector with the     surface of an ellipsoid.        surfpt  ( positn, u, a, b, c, point, &found );      Convert to range, right ascension, and declination.        recrad  ( point, &range, &ra, &dec );       Restrictions      None.       Exceptions      Error free.       Files      None.       Author and Institution      H.A. Neilan     (JPL)       Literature References      None.       Version      -CSPICE Version 1.1.0, 22-OCT-1998 (NJB)        Made input vector const.     -CSPICE Version 1.0.0, 08-FEB-1998 (EDW)      Index Entries      rectangular coordinates to ra and dec     rectangular to right_ascension and declination             RECSPH: Rectangular to spherical coordinates         Abstract      Convert from rectangular coordinates to spherical coordinates.       Copyright      Copyright (1995), California Institute of Technology.     U.S. Government sponsorship acknowledged.       Required Reading      None.       Brief I/O      VARIABLE  I/O  DESCRIPTION     --------  ---  --------------------------------------------------     rectan     I   Rectangular coordinates of a point.     r          O   Distance of the point from the origin.     colat      O   Angle of the point from the positive Z-axis.     lon        O   Angle of the point from the XY plane in radians.       Detailed Input      rectan     The rectangular coordinates of a point.       Detailed Output      r          Distance of the point from the origin.      colat      Angle between the point and the positive z-axis.      lon        Angle of the point from the XY plane in radians.       Parameters      None.       Particulars      This routine returns the spherical coordinates of a point     whose position is input in rectangular coordinates.      spherical coordinates are defined by a distance from a central     reference point, an angle from a reference meridian, and an angle     from the z-axis.       Examples      Below are two tables.      Listed in the first table (under X(1), X(2) and X(3) ) are a     number of points whose rectangular coordinates are     taken from the set {-1, 0, 1}.      The result of the code fragment            recsph  ( X, r, colat, lon  )           Use the CSPICE routine  convrt  to convert the angular          quantities to degrees            convrt  ( colat, ""RADIANS"", ""DEGREES"", colat )           convrt  (  lon,  ""RADIANS"", ""DEGREES"", lon   )      are listed to 4 decimal places in the second parallel table under     r (radius), colat (co-latitude), and  lon  (longitude).        X(1)       X(2)     X(3)        r         colat       lon        --------------------------      ----------------------------       0.0000     0.0000   0.0000      0.0000     0.0000     0.0000       1.0000     0.0000   0.0000      1.0000    90.0000     0.0000       0.0000     1.0000   0.0000      1.0000    90.0000    90.0000       0.0000     0.0000   1.0000      1.0000     0.0000     0.0000      -1.0000     0.0000   0.0000      1.0000    90.0000   180.0000       0.0000    -1.0000   0.0000      1.0000    90.0000   -90.0000       0.0000     0.0000  -1.0000      1.0000   180.0000     0.0000       1.0000     1.0000   0.0000      1.4142    90.0000    45.0000       1.0000     0.0000   1.0000      1.4142    45.0000     0.0000       0.0000     1.0000   1.0000      1.4142    45.0000    90.0000       1.0000     1.0000   1.0000      1.7320    54.7356    45.0000       Restrictions      None.       Exceptions      Error free.       Files      None.       Author and Institution      W.L. Taber      (JPL)     E.D. Wright     (JPL)      Literature References      None.       Version      -CSPICE Version 1.1.0, 22-OCT-1998 (NJB)        Made input coordinate array const.     -CSPICE Version 1.0.0, 08-FEB-1998 (EDW)      Index Entries      rectangular to spherical coordinates             RESET: Reset Error Status         Abstract       Reset  the CSPICE error status to a value of ""no error.""    As a result, the status routine,  failed , will return a value    of SPICEFALSE      Copyright      Copyright (1998), California Institute of Technology.    U.S. Government sponsorship acknowledged.      Required Reading       ERROR       Brief I/O      VARIABLE  I/O  DESCRIPTION    --------  ---  --------------------------------------------------    None.      Detailed Input      None.      Detailed Output      None.      Parameters      None.      Particulars      Please read the ""required reading"" first!     The effects of this routine are:     1. The CSPICE status is set to a value of ""no error.""     2. The long and short error messages are set to blank.     3. Setting of the long error message is re-enabled.      Subsequent to a call to  reset , references to the status    indicator function,  failed , will return a value of SPICEFALSE,    until an error is detected.     This routine should be called in cases where one wishes    to attempt to continue processing after detection of an    error, and the ""RETURN"" error action is being used.  When    the error response action is set to ""RETURN"", routines    that have external references, or that can    detect errors, return immediately upon entry when an    error condition  exists .  This prevents a program from    crashing, but does not allow for a recovery attempt.     If one does wish to attempt to recover,    in general the procedure is to test for an error    condition, and if one  exists , respond to the error    (by outputting diagnostic messages, for example).  Next,    a call to  reset  can be made.  After resetting the    error status, the normal execution thread can be resumed.     It is also appropriate to call this routine when the error    response action is ""REPORT"", if one wishes to recover    from errors.      Examples      1.  In this example, we try to read a line from the file,        SPUD.DAT, using the toolkit routine,  rdtext .        When  failed  indicates an error, we grab the short        error message and its explanation, using  getmsg  (see),        log the messages using our user-defined routine,        USER_LOG (NOT a CSPICE routine),  reset  the        status, and keep going.            /.           We read a line from SPUD.DAT:           ./             rdtext  ( ""SPUD.DAT"", line, LENOUT, &eof );            if (  failed () )              {               /.              Oops! an error occurred during the read.              Recover the short error message and its              explanation,  reset  the error status,              log the messages, and continue...              ./                getmsg    ( ""SHORT""  , LENOUT, short_mess );               getmsg    ( ""EXPLAIN"", LENOUT, explain_mess );               USER_LOG (  SMSG );              USER_LOG (  EXPL );                reset ();              }      Restrictions      It can be dangerous to call this routine without    RESPONDING to the error condition first; by calling     reset , you are wiping out the CSPICE's knowledge of    the error.      Exceptions      This routine does not detect any errors.     However, this routine is part of the CSPICE error    handling mechanism.      Files      None.      Author and Institution      N.J. Bachman    (JPL)    K.R. Gehringer  (JPL)      Literature References      None.      Version      -CSPICE Version 1.0.1, 25-MAR-1998 (EDW)        Minor corrections to header.     -CSPICE Version 1.0.0, 08-FEB-1998 (EDW)      Index Entries       reset  error status            RETURN: Immediate Return Indicator         Abstract      True if CSPICE routines should return immediately upon entry.       Copyright      Copyright (1995), California Institute of Technology.     U.S. Government sponsorship acknowledged.       Required Reading        ERROR        Brief I/O       VARIABLE  I/O  DESCRIPTION      --------  ---  --------------------------------------------------       The function returns the value, SPICETRUE, if and only if CSPICE      routines should return immediately upon entry.       Detailed Input       None.       Detailed Output       The function returns the value, SPICETRUE, if and only if CSPICE      routines should return immediately upon entry.  The criterion      for this is that the error response action is set to      ""RETURN"", and an error condition  exists .       Parameters      None.       Particulars       Please read the ""required reading"" first!       This routine can be referenced in non-toolkit code; in      fact, its use is encouraged.  Its purpose is to signal      to the routine calling it that the caller should      return immediately.  The reference to return should      be the first executable line of the calling program.       In ""RETURN"" mode, CSPICE routines      that have external references, or that can      detect errors, return immediately upon entry when an      error condition  exists .  They use return to determine      when these conditions are met.  Non--toolkit routines      can do the same.       Additionally, when an error is signalled in ""RETURN"" mode,      no further errors can be signalled until the error condition      is  reset  by a call to  reset .  Calls to  SIGERR  simply have      no effect.  Therefore, the error messages set in response      to the FIRST error that was detected will be saved until       reset  is called.  These messages can be retrieved by      calls to  getmsg .       There are a number of advantages to using this mechanism.      First, the likelihood of an error resulting in crash      in a different routine is greatly reduced.  Second,      a program does not have to test the error status      (using a reference to  failed ) after each call to a toolkit      routine, but rather can make one test of status at the end      of a series of calls.  See ""Examples"" below.       See the subroutine  erract  for definitions of the error action       codes.       Examples       1.  In this example, we show how to place a reference          to return in your code:          /.                No executable lines precede this one.                 Test whether to return before doing                anything else.         ./                 if ( return() )                  {                  return;                         }                 [ rest of code goes here]                           .                          .                          .        2.  Here's how one might code a sequence of calls          to routines with code that follows the pattern          given in example #1 above:                          .                         .                         .                 [ code may go here ]          /.                We call routines A, B, and C;  then we                test for errors, using the CSPICE error                status indicator,  failed :         ./                 A();                B();               C();                if (  failed () )                  {         /.                   If we're here, an error occurred.  The                   error might have been detected by A, B, C,                   or by a routine called by one of them.                   Get the explanation of the short error message                   and output it using the routine, user_out                   [user_out is a fictitious routine]:         ./                     getmsg  ( ""EXPLAIN"", MSG );                   user_out ( MSG );                   }                 [ rest of code goes here ]                            .                           .                           .       Restrictions       This routine has no effect unless the error action is ""RETURN""!       Exceptions       This routine does not detect any errors.       However, this routine is part of the CSPICE error      handling mechanism.       Files       None.       Author and Institution       N.J. Bachman    (JPL)      K.R. Gehringer  (JPL)       Literature References       None.       Version      -CSPICE Version 1.0.0, 08-FEB-1998   (EDW)      Index Entries      immediate return indicator             ROTATE: Generate a rotation matrix         Abstract      Calculate the 3x3 rotation matrix generated by a rotation     of a specified angle about a specified axis. This rotation     is thought of as rotating the coordinate system.       Copyright      Copyright (1995), California Institute of Technology.     U.S. Government sponsorship acknowledged.       Required Reading      None.       Brief I/O      VARIABLE  I/O  DESCRIPTION     --------  ---  --------------------------------------------------     angle      I   Angle of rotation (radians).     iaxis      I   Axis of rotation (X=1, Y=2, Z=3).     mout       O   Resulting rotation matrix [angle]                                                     iaxis       Detailed Input      angle   The angle given in radians, through which the rotation             is performed.      iaxis   The index of the axis of rotation.  The X, Y, and Z             axes have indices 1, 2 and 3 respectively.       Detailed Output      mout    Rotation matrix which describes the rotation of the             COORDINATE system through angle radians about the             axis whose index is iaxis.       Parameters      None.       Particulars      A rotation about the first, i.e. x-axis, is described by         |  1        0          0      |        |  0   cos(theta) sin(theta)  |        |  0  -sin(theta) cos(theta)  |      A rotation about the second, i.e. y-axis, is described by         |  cos(theta)  0  -sin(theta)  |        |      0       1        0      |        |  sin(theta)  0   cos(theta)  |      A rotation about the third, i.e. z-axis, is described by         |  cos(theta) sin(theta)   0   |        | -sin(theta) cos(theta)   0   |        |       0          0       1   |       rotate  decides which form is appropriate according to the value     of IAXIS.       Examples      If  rotate  is called from a C program as follows:             rotate  (  pi ()/4, 3, mout );      then mout will be given by                   | sqrt(2)/2   sqrt(2)/2   0  |           mout = |-sqrt(2)/2   sqrt(2)/2   0  |                  |     0           0       1  |       Restrictions      None.       Exceptions      Error free.      1) If the axis index is not in the range 1 to 3 it will be        treated the same as that integer 1, 2, or 3 that is congruent        to it mod 3.       Files      None.       Author and Institution      N.J. Bachman    (JPL)    W.M. Owen       (JPL)     W.L. Taber      (JPL)       Literature References      None.       Version      -CSPICE Version 1.0.0 08-FEB-1998 (NJB)        Based on SPICELIB Version 1.0.1, 10-MAR-1992 (WLT)      Index Entries      generate a rotation matrix             ROTMAT: Rotate a matrix         Abstract       rotmat  applies a rotation of angle radians about axis iaxis to a     matrix.  This rotation is thought of as rotating the coordinate     system.       Copyright      Copyright (1995), California Institute of Technology.     U.S. Government sponsorship acknowledged.       Required Reading      None.       Brief I/O      VARIABLE  I/O  DESCRIPTION     --------  ---  --------------------------------------------------     m1        I     Matrix to be rotated.     angle     I     Angle of rotation (radians).     iaxis     I     Axis of rotation (X=1, Y=2, Z=3).     mout      O     Resulting rotated matrix.      Detailed Input      m1      This is a matrix to which a rotation is to be applied.             In matrix algebra, the components of the matrix are             relative to one particular coordinate system. Applying              rotmat  changes the components of m1 so that they are             relative to a rotated coordinate system.      angle   The angle in radians through which the original             coordinate system is to be rotated.      iaxis   An index for the axis of the original coordinate system             about which the rotation by angle is to be performed.             iaxis = 1,2 or 3 designates the x-, y- or z-axis,             respectively.       Detailed Output      mout    The matrix resulting from the application of the             specified rotation to the input matrix m1.  If                 [angle]                              iaxis              denotes the rotation matrix by angle radians about iaxis,            (see the Rotations Required Reading document) then mout is             given by the following matrix equation:                 mout = [angle]      * m1                              iaxis              mout can overwrite m1.       Parameters      None.       Particulars      None.       Examples      Suppose that to  rotate  the a set of inertial axes to body fixed     axes, one must first roll the coordinate axes about the x-axis by     angle r to get x', y', z'.  From this one must pitch about the     y' axis by angle o to get x'', y'', z''.  And finally yaw the     x'', y'', z'' about the z'' axis by angle y to obtain the     transformation to bodyfixed coordinates.  If id is the identity     matrix, then the following code fragment generates the     transformation from interitial to body fixed.          rotmat  ( id, r, 1, m1   );         rotmat  ( m1, p, 2, m2   );         rotmat  ( m2, y, 3, tibf );       Restrictions      None.       Exceptions      Error free.      1) If the axis index is not in the range 1 to 3 it will be        treated the same as that integer 1, 2, or 3 that is congruent        to it mod 3.       Files      None.       Author and Institution      N.J. Bachman    (JPL)    W.M. Owen       (JPL)     W.L. Taber      (JPL)       Literature References      None.       Version      -CSPICE Version 1.1.0, 22-OCT-1998 (NJB)        Made input matrix const.     -CSPICE Version 1.0.0, 08-FEB-1998 (NJB)        Based on SPICELIB Version 1.0.1, 10-MAR-1992 (WLT)      Index Entries       rotate  a matrix             ROTVEC: Transform a vector via a rotation         Abstract      Transform a vector to a new coordinate system rotated by angle     radians about axis iaxis.  This transformation rotates v1 by     -angle radians about the specified axis.      Copyright      Copyright (1995), California Institute of Technology.     U.S. Government sponsorship acknowledged.       Required Reading      None.      Brief I/O      VARIABLE  I/O  DESCRIPTION     --------  ---  --------------------------------------------------     v1        I    Vector whose coordinate system is to be rotated.     angle     I    Angle of rotation in radians.     iaxis     I    Axis of rotation (X=1, Y=2, Z=3).     vout      O    Resulting vector [angle]      * v1 expressed in                                            iaxis                    the new coordinate system. vout can overwrite v1.       Detailed Input      v1      This is a vector (typically representing a vector fixed             in inertial space) which is to be expressed in another             coordinate system.  The vector remains fixed but the             coordinate system changes.      angle   The angle given in radians, through which the rotation             is performed.      iaxis   The index of the axis of rotation.  The X, Y, and Z             axes have indices 1, 2 and 3 respectively.       Detailed Output      vout    This is the vector expressed in the new coordinate system             specified by the angle of rotation and axis. If             [angle]       represents the rotation matrix described by                    iaxis             the angle and axis, (refer to the routine  ROTATE )             then vout = [angle]      * v1                                iaxis       Parameters      None.       Particulars      A rotation about the first, i.e. x-axis, is described by      |  1        0          0      |     |  0   cos(theta) sin(theta)  |     |  0  -sin(theta) cos(theta)  |      A rotation about the second, i.e. y-axis, is described by      |  cos(theta)  0  -sin(theta)  |     |      0       1        0      |     |  sin(theta)  1   cos(theta)  |      A rotation about the third, i.e. z-axis, is described by      |  cos(theta) sin(theta)   0   |     | -sin(theta) cos(theta)   0   |     |       0          0       1   |       rotvec  decides which form is appropriate according to the value     of iaxis and applies the rotation to the input vector.       Examples      Suppose that     v1 = (1.414, 0, 0), angle =  PI /4, iaxis = 3     then after calling  rotvec  according to              rotvec  (v1, angle, iaxis, vout)      vout will be equal to (1, -1, 0).       Restrictions      None       Exceptions      1) If the axis index is not in the range 1 to 3 it will be treated        the same as that integer 1, 2, or 3 that is congruent to it mod        3.       Files      None       Author and Institution      W.M. Owen       (JPL)     W.L. Taber      (JPL)       Literature References      None       Version      -CSPICE Version 1.1.1, 04-OCT-1999 (NJB)        Procedure line and abstract and were changed to dispel the       impression that the input vector is rotated by +angle       radians about the specified axis.     -CSPICE Version 1.1.0, 22-OCT-1998 (NJB)        Made input vector const.     -CSPICE Version 1.0.0, 08-FEB-1998   (EDW)      Index Entries       rotate  a vector             RPD: Radians per degree         Abstract      Return the number of radians per degree.      Copyright      Copyright (1997), California Institute of Technology.    U.S. Government sponsorship acknowledged.      Required Reading      None.      Brief I/O      The function returns the number of radians per degree.       Detailed Input      None.       Detailed Output      The function returns the number of radians per degree:  pi /180.    The value of  pi  is determined by the ACOS function. That is,         rpd  = acos ( -1. ) / 180.      Parameters      None.       Particulars      When the function is referenced, the value computed as shown     above is returned.      Examples      The code fragment below illustrates the use of  rpd .        /. Convert all angles to radians for output  ./           clock *=  rpd ()           cone  *=  rpd ()           twist *=  rpd ()        Restrictions      None.      Exceptions      Error free.       Files      None.       Author and Institution      W.L. Taber      (JPL)     I.M. Underwood  (JPL)     E.D. Wright     (JPL)      Literature References      None.      Version      -CSPICE Version 1.0.0, 08-FEB-1998 (EDW)      Index Entries      radians per degree            RQUAD: Roots of a quadratic equation         Abstract      Find the roots of a quadratic equation.       Copyright      Copyright (1995), California Institute of Technology.     U.S. Government sponsorship acknowledged.       Required Reading      None.       Brief I/O      Variable  I/O  Description     --------  ---  --------------------------------------------------      a          I   Coefficient of quadratic term.     b          I   Coefficient of linear term.     c          I   Constant.     root1      O   Root built from positive discriminant term.     root2      O   Root built from negative discriminant term.       Detailed Input      a,     b,     c              are the coefficients of a quadratic polynomial                          2                       ax   +   bx   +   c.       Detailed Output      root1,     root2         are the roots of the equation,                          2                       ax   +   bx   +   c   =  0.                     root1 and root2 are both arrays of length 2.  The                   first element of each array is the real part of a                   root; the second element contains the complex part                   of the same root.                    When a is non-zero, root1 represents the root                                     ____________                                   /  2                      - b   +    \/  b    -   4ac                      ---------------------------                                    2a                     and root2 represents the root                                     ____________                                   /  2                      - b   -    \/  b    -   4ac                      --------------------------- .                                    2a                     When a is zero and b is non-zero, root1 and root2                   both represent the root                       - c / b.       Parameters      None.       Particulars      None.       Examples      1)   Humor us and suppose we want to compute the ""golden ratio.""           The quantity r is defined by the equation              1/r = r/(1-r),           which is equivalent to               2             r   +  r  -  1  =  0.           The following code fragment does the job.               /.            Compute ""golden ratio.""  The root we want,                        __                      /               -1 + \/  5               -----------,                    2              is contained in root1.            ./               rquad  ( 1., 1., -1., root1, root2 );              printf ( ""The \""golden ratio\"" is %f\n"", root1[0] );       2)   The equation,               2             x   +  1  =  0           can be solved by the code fragment               /.            Let's do one with imaginary roots just for fun.             ./              rquad  ( 1.,  0.,  1.,  root1,  root2 );              printf ( ""root1 is %f   %f\n"", root1[0], root1[1] );             printf ( ""root2 is %f   %f\n"", root2[0], root2[1] );            The printed results will be something like:              root1 is 0.000000000000000   1.000000000000000             root2 is 0.000000000000000   -1.000000000000000       Restrictions      No checks for overflow of the roots are performed.       Exceptions      1)   If the input coefficients a and b are both zero, the error          SPICE(DEGENERATECASE) is signalled.  The output arguments          are not modified.       Files      None.       Author and Institution      N.J. Bachman   (JPL)       Literature References      None.       Version      -CSPICE Version 1.0.0, 13-JUN-1999 (NJB)      Index Entries      roots of a quadratic equation            [  Index |  A   B   C   D   E   F   G   H   I   J   K   L   M   N   O   P   Q   R   S   T   U   V  W  X  Y Z ]     $Id: Created Tue Nov 21 11:00:51 2000 by gen_spice_html.pl v1.6 $     Ed Santiago  /  esm@lanl.gov"
GX194-07-0618135	1                                   c     2                                   c     cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc     3                                         subroutine  green_function ( mtasa , n_spin_pola , n_spin_cant ,     4                                        >                           lmax , lmaxp , kkrsz , wx , wy , wz ,     5                                        >                           rins , r_zpl1 , r_zpl2 , r_mesh , jmt , jws ,     6                                        >                           pnrel , tau00_l , matom , zlr , jlr ,     7                                        >                           wfreg , wfirr , wf_ldim , kmax_phi , kmax_kkr ,     8                                        >                           ngaussr ,     9                                        >                           cgnt , lmax_gnt ,     10                                        >                           dos , dosck , green , dipole ,     11                                        >                           dele1 , lofk , mofk , lmax_rho ,     12                                        >                           irfit , irstart , irpts , irjpts , ie , nume ,     13                                        >                           iprint , istop , itscf )     14                                   c     ================================================================     15                                   c     16                                   c     17                                   c     ****************************************************************     18                                   c     input:     19                                   c                tau00_l     20                                   c                kkrsz   (size of KKR-matrix)     21                                   c                istop   (index of subroutine prog. stops in)     22                                   c     output:     23                                   c                dos     (wigner-seitz cell density of states)     24                                   c                dosck   (muffin-tin density of states)     25                                   c                green   (Green's function)     26                                   c     ****************************************************************     27                                   c     28                                         implicit   none     29                                   c     30                                   c     ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++     31                                         include    ' atom_param.h '     32                                   c     ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++     33                                   c     34                                         character   istop *20     35                                         character   sname *20     36                                   c     37                                         integer     mtasa , wf_ldim , kmax_phi , kmax_kkr , itscf     38                                         integer     irpts     39                                         integer     irjpts     40                                         integer     n_spin_pola     41                                         integer     n_spin_cant     42                                         integer     lmax , lmaxp     43                                         integer     lmax_rho , lmax_gnt     44                                         integer     kkrsz     45                                         integer     jmt     46                                         integer     jws     47                                         integer     m     48                                         integer     ie     49                                         integer     nume     50                                         integer     ir , l , l1     51                                         integer     ngaussr     52                                         integer     iprint     53                                         integer     zsl     54                                         integer     zsr     55                                         integer     zj_flag     56                                         integer     isp     57                                         integer     irfit (( lmax_rho + 1 ) * ( lmax_rho + 2 ) / 2 )     58                                         integer     irstart (( lmax_rho + 1 ) * ( lmax_rho + 2 ) / 2 )     59                                         integer     lofk ( kmax_phi )     60                                         integer     mofk ( kmax_phi )     61                                   c     62                                         real* 8       rins , r_zpl1 , r_zpl2 , r_mesh ( iprpts )     63                                         real* 8       cgnt ( lmax_gnt + 1 ,( lmax_gnt + 1 ) ** 2 ,( lmax_gnt + 1 ) ** 2 )     64                                         real* 8       fnpi     65                                         real* 8       pi     66                                         real* 8       two     67                                         parameter ( two = 2.0d0 )     68                                   c     69                                         complex* 16   wx ( 4 )     70                                         complex* 16   wy ( 4 )     71                                         complex* 16   wz ( 4 )     72                                         complex* 16   pnrel     73                                         complex* 16   matom ( lmax + 1 , n_spin_cant )     74                                         complex* 16   tau00_l ( kkrsz * kkrsz * n_spin_cant * n_spin_cant )     75                                         complex* 16   zlr ( iprpts * ( iplmax + 1 ), n_spin_cant )     76                                         complex* 16   jlr ( iprpts * ( iplmax + 1 ), n_spin_cant )     77                                         complex* 16   dos ( n_spin_cant * n_spin_cant )     78                                         complex* 16   dosck ( n_spin_cant * n_spin_cant )     79                                         complex* 16   green ( iprjpts , n_spin_cant * n_spin_cant )     80                                         complex* 16   dipole ( 6 , n_spin_cant * n_spin_cant )     81                                         complex* 16   t1     82                                         complex* 16   t2     83                                         complex* 16   t3     84                                         complex* 16   t4     85                                         complex* 16   dele1     86                                         complex* 16   wfreg ( wf_ldim , kmax_phi , kmax_kkr , n_spin_cant )     87                                         complex* 16   wfirr ( wf_ldim , kmax_phi , kmax_kkr , n_spin_cant )     88                                   c     89                                         parameter ( sname =' green_function ')     90                                   c     91                                   c     write(6,'(''green_f::r_zpl1,r_zpl2'',2f12.5)')r_zpl1,r_zpl2     92                                          pi = fnpi ()     93                                         call  zeroout ( green , 2 * iprjpts * n_spin_cant * n_spin_cant )     94                                   c     95                                         do  isp = 1 , n_spin_cant * n_spin_cant     96                                            if( isp .eq. 1 ) then     97                                                zsl = 1     98                                                zsr = 1     99                                                zj_flag = 1     100                                            else if( isp .eq. 2 ) then     101                                                zsl = 2     102                                                zsr = 1     103                                                zj_flag = 0     104                                            else if( isp .eq. 3 ) then     105                                                zsl = 1     106                                                zsr = 2     107                                                zj_flag = 0     108                                            else if( isp .eq. 4 ) then     109                                                zsl = 2     110                                                zsr = 2     111                                                zj_flag = 1     112                                            endif     113                                   c        --------------------------------------------------------------     114                                   c        write(6,'(''green::wf_ldim,lmax'',2i5)')wf_ldim,lmax     115                                   c        do ir=1,wf_ldim,50     116                                   c         do l1=0,lmax     117                                   c            write(6,'(''green::l,r,z,wf'',2i5,9d12.5)')     118                                   c    >       l1,(l1+1)**2,     119                                   c    >       r_mesh(ir),zlr(ir+iprpts*(l1),zsl),     120                                   c    >       wfreg(ir,(l1+1)**2,(l1+1)**2,zsl)     121                                   c        enddo     122                                   c        enddo     123                                            call  gf_local ( mtasa , zj_flag , lmax , lmaxp , kkrsz , rins ,     124                                        >                  r_zpl1 , r_zpl2 , r_mesh , jmt , jws , isp ,     125                                        >                  wx , wy , wz , n_spin_cant ,     126                                        >                  pnrel , tau00_l ( kkrsz * kkrsz * ( isp - 1 ) + 1 ),     127                                        >                  matom ( 1 , zsl ), matom ( 1 , zsr ),     128                                        >                  zlr ( 1 , zsl ), zlr ( 1 , zsr ), jlr ( 1 , zsr ),     129                                        >                  wfreg ( 1 , 1 , 1 , zsl ), wfreg ( 1 , 1 , 1 , zsr ),     130                                        >                  wfirr ( 1 , 1 , 1 , zsr ), wf_ldim , kmax_phi , kmax_kkr ,     131                                        >                  ngaussr , cgnt , lmax_gnt ,     132                                        >                  dos ( isp ), dosck ( isp ), green , dipole ( 1 , isp ),     133                                        >                  dele1 , lofk , mofk , lmax_rho ,     134                                        >                  irfit , irstart , irpts , irjpts , ie , nume ,     135                                        >                  pi , iprint , istop , itscf )     136                                   c        --------------------------------------------------------------     137                                         enddo     138                                   c     139                                   c     ================================================================     140                                   c     re-calculate dos and green so that:     141                                   c     142                                   c     dos(1) = Tr[dos],           green(r,1) = Tr[green(r)]     143                                   c                 ---                             -----     144                                   c     145                                   c     dos(2) = Tr[dos*wx],        green(r,2) = Tr[green(r)*wx]     146                                   c                 --- --                          -----    --     147                                   c     148                                   c     dos(3) = Tr[dos*wy],        green(r,3) = Tr[green(r)*wy]     149                                   c                 --- --                          -----    --     150                                   c     151                                   c     dos(4) = Tr[dos*wz],        green(r,4) = Tr[green(r)*wz]     152                                   c                 --- --                          -----    --     153                                   c     154                                   c     ================================================================     155                                         if( n_spin_cant .eq. 2 ) then         ! spin canting case     156                                             t1 = dos ( 1 ) + dos ( 4 )     157                                             t2 = dos ( 1 ) * wx ( 1 ) + dos ( 2 ) * wx ( 3 ) + dos ( 3 ) * wx ( 2 ) + dos ( 4 ) * wx ( 4 )     158                                             t3 = dos ( 1 ) * wy ( 1 ) + dos ( 2 ) * wy ( 3 ) + dos ( 3 ) * wy ( 2 ) + dos ( 4 ) * wy ( 4 )     159                                             t4 = dos ( 1 ) * wz ( 1 ) + dos ( 2 ) * wz ( 3 ) + dos ( 3 ) * wz ( 2 ) + dos ( 4 ) * wz ( 4 )     160                                             dos ( 1 )= t1     161                                             dos ( 2 )= t2     162                                             dos ( 3 )= t3     163                                             dos ( 4 )= t4     164                                             t1 = dosck ( 1 ) + dosck ( 4 )     165                                             t2 = dosck ( 1 ) * wx ( 1 ) + dosck ( 2 ) * wx ( 3 ) + dosck ( 3 ) * wx ( 2 ) + dosck ( 4 ) * wx ( 4 )     166                                             t3 = dosck ( 1 ) * wy ( 1 ) + dosck ( 2 ) * wy ( 3 ) + dosck ( 3 ) * wy ( 2 ) + dosck ( 4 ) * wy ( 4 )     167                                             t4 = dosck ( 1 ) * wz ( 1 ) + dosck ( 2 ) * wz ( 3 ) + dosck ( 3 ) * wz ( 2 ) + dosck ( 4 ) * wz ( 4 )     168                                             dosck ( 1 )= t1     169                                             dosck ( 2 )= t2     170                                             dosck ( 3 )= t3     171                                             dosck ( 4 )= t4     172                                   c        do ir=1,irjpts     173                                   c           t1=green(ir,1)+green(ir,4)     174                                   c           t2=green(ir,1)*wx(1)+green(ir,2)*wx(3)+     175                                   c    >         green(ir,3)*wx(2)+green(ir,4)*wx(4)     176                                   c           t3=green(ir,1)*wy(1)+green(ir,2)*wy(3)+     177                                   c    >         green(ir,3)*wy(2)+green(ir,4)*wy(4)     178                                   c           t4=green(ir,1)*wz(1)+green(ir,2)*wz(3)+     179                                   c    >         green(ir,3)*wz(2)+green(ir,4)*wz(4)     180                                   c           green(ir,1)=t1     181                                   c           green(ir,2)=t2     182                                   c           green(ir,3)=t3     183                                   c           green(ir,4)=t4     184                                   c        enddo     185                                     do  m = 1 , 6     186                                             t1 = dipole ( m , 1 ) + dipole ( m , 4 )     187                                             t2 = dipole ( m , 1 ) * wx ( 1 ) + dipole ( m , 2 ) * wx ( 3 ) + dipole ( m , 3 ) * wx ( 2 ) +     188                                        &       dipole ( m , 4 ) * wx ( 4 )
GX260-54-16323461	"Multiprecision Translation and Execution of Fortran Programs David H. Bailey February 3, 1993 Ref: ACM Trans. on Mathematical Software, vol. 19, no. 3 (Sept. 1993), pg. 288319 Abstract This paper describes two Fortran utilities for multiprecision computation. The first is a package of Fortran subroutines that perform a variety of arithmetic operations and transcendental functions on floating point numbers of arbitrarily high precision. This package is in some cases over 200 times faster than that of certain other packages that have been developed for this purpose. The second utility is a translator program, which facilitates the conversion of ordinary Fortran programs to use this package. By means of source directives (special comments) in the original Fortran program, the user declares the precision level and specifies which variables in each subprogram are to be treated as multiprecision. The translator program reads this source program and outputs a program with the appropriate multiprecision subroutine calls. This translator supports multiprecision integer, real and complex datatypes. The required array space for multiprecision data types is automatically allocated. In the evaluation of computational expressions, all of the usual conventions for operator precedence and mixed mode operations are upheld. Furthermore, most of the Fortran-77 intrinsics, such as ABS, MOD, NINT, COS, EXP are supported and produce true multiprecision values.  The author is with the NAS Applied Research Branch, NASA Ames Research Center, Moffett Field, CA 94035. E-mail: dbailey@nas.nasa.gov. 1   Intro duction Section 1 of this paper gives an introduction to the problem of multiprecision computation, including a number of specific applications. Section 2 describes in moderate detail the multiprecision function package (MPFUN), emphasizing the algorithms and computational techniques used. For full details, including a listing of the subroutines and argument definitions, see [4]. Section 3 describes the multiprecision translator program (TRANSMP), including instructions for usage. It is not necessary to understand details of the MPFUN package in order to effectively use it via the translator program. Readers mainly interested in the translator may skip directly to section 3. Full documentation and the actual source code for both of these programs may be obtained either from the ACM TOMS database or directly from the author by sending e-mail to dbailey@nas.nasa.gov. 1.0 Applications of Multiprecision Computation Multiprecision computation (i.e. computation using numeric precision beyond the single or double precision ordinarily provided in hardware) has been performed on electronic computers since the earliest models were introduced over forty years ago. One question that is frequently raised in this context is what applications justify a multiprecision facility. Actually, there are quite a number of applications, ranging from the highly theoretical to the completely practical. One important area of applications is in pure mathematics. While some still dispute whether a computer calculation can be the basis of a formal mathematical proof, certainly computations can be used to explore conjectures and reject those that are not sound. Some particularly nice applications of high precision computation to pure mathematics include the disproof of the Mertens conjecture by A. M. Odlyzko and H. J. J. te Riele [26], the disproof of the Bernstein conjecture in approximation theory by Varga and Carpenter and the resolution of the ""one-ninth"" conjecture [31]. A number of other examples of multiprecision applications in analysis, approximation theory and numerical analysis are also described in [31]. One area in which multiprecision computations are especially useful is the study of mathematical constants. For example, although Euler's constant  is believed to be transcendental, it has not been proven that  is even irrational. There is similar ignorance regarding other classical constants, such as log  and e +  , and also regarding some constants that have arisen in twentieth century mathematics, such as the Feigenbaum  constant (4.669201609 ) [13, 19] and the Bernstein  constant (0.2801694990 ) [31]. However, in most of these cases algorithms are known that permit these numbers to be computed to high precision. When this is done, the hypothesis of whether a constant  satisfies some reasonably simple, low-degree polynomial can be tested by computing the vector (1,,2 ,  ,n-1 ) and then applying one of the recently discovered integer relation finding algorithms [5, 20, 21]. Such algorithms, when applied to an n-long vector x, determine whether there exist integers ai such that ai xi = 0. Thus if a computation 2   finds such a set of integers ai , these integers are the coefficients of a polynomial satisfied by . Even if no such relation is found, these algorithms also produce bounds within which no relation can exist, which results are of interest by themselves. The author has performed some computations of this type [3, 5], and others are in progress. Some recent results include the following: if  satisfies an integer polynomial of degree 50 or less, then the Euclidean norm of the coefficients must exceed 7  1017 ; if Feigenbaum's  constant satisfies an integer polynomial of degree 20 or less, then the Euclidean norm of the coefficients must exceed 2  1015 . This last result is based on joint work with K. Briggs of the University of Melbourne in Australia. Computations of this sort have also been applied to study a certain conjecture regarding the  function. It is well known [8] that    (2) = 3 k=1  1 k 2 2k k -1 3 2k k  5  (3) = 2  (4) =   k=1   (-1)k k 1 k  36 17  k=1  4 2k k  These results have led some to suggest that   Z5 =  (5)/ k=1  (-1)k k  -1  5 2k k  might also be a simple rational or algebraic number. Unfortunately, the author and K. Briggs have established that if Z5 satisfies a polynomial of degree 25 or less, then the Euclidean norm of the coefficients must exceed 2  1037 . In one case the author, working in conjunction with H. R. P. Ferguson, obtained the following positive result: the third bifurcation point of the chaotic iteration xk+1 = rxk (1 - xk ), namely the constant 3.54409035955 , satisfies the polynomial 4913 + 2108t2 - 604t3 - 977t4 +8t5 +44t6 + 392t7 - 193t8 - 40t9 +48t10 - 12t11 + t12 (verified to a precision level of over 1000 digits). In this case, it can be proven fairly easily that this constant must be algebraic. The fact that it satisfies a polynomial of only degree 12 is something of a surprise. One of the oldest applications of multiprecision computation is to explore the perplexing question of whether the decimal expansions (or the expansions in any other radix) of  classical constants such as , e, 2, etc. are random in some sense. Almost any reasonable notion of randomness could be used here, including the property that every digit occurs with limiting frequency 1/10, or the stronger property that every n-long string of digits occurs with limiting frequency 10-n . This conjecture is believed to hold for a very wide range of mathematical constants, including all irrational algebraic numbers and the transcendentals  and e, among others. Its verification for a certain class of constants would 3   potentially have the practical application of providing researchers with provably reliable pseudorandom number generators. Unfortunately, however, this conjecture has not been proven in even a single instance among the classical constants of mathematics. Thus there is continuing interest in computations of certain constants to very high precision, in order to see if there are any statistical anomalies in the results. The computation of  has been of particular interest in this regard, and recently the one billion digit mark was passed by both Kanada [22] and the Chudnovskys [15], and the Chudnovskys have more recently extended their calculation to beyond two billion digits [16]. Statistical analyses of these results have so far not yielded any statistical anomalies (see for example [1]). An eminently practical application of multiprecision computation is the emerging field of public-key cryptography, in particular research on the Rivest-Shamir-Adleman (RSA) cryptosystem [27, 17]. This cryptosystem relies on the exponentiation of a large integer to a large integer power modulo a third large integer. The RSA cryptosystem has also spawned a great deal of research into advanced algorithms for factoring large integers, since the RSA system can be ""broken"" if one can factor the modulus. The most impressive result in this area so far is the recent factorization of the ninth Fermat number 2512 +1, an integer with 155 digits, which was accomplished by means of numerous computer systems communicating by electronic mail. This computation employed a new factoring algorithm, known as the ""number field sieve"" [25]. An indirect application of multiprecision computation is the integrity testing of computer systems. A unique feature of multiprecision computations is that they are exceedingly unforgiving of hardware or compiler error. This is because if even a single computational error occurs, the result will almost certainly be completely incorrect after a possibly correct initial section. In many other scientific computations, a hardware error in particular might simply retard the convergence to the correct solution. 2.0 Overview of the MPFUN Package The MPFUN package consists of approximately 10,000 lines of Fortran code organized into 87 subprograms. These routines operate on three custom data types: multiprecision (MP) numbers, multiprecision complex (MPC) numbers and double precision plus exponent (DPE) numbers. A MP number is represented by a single precision floating point array. The sign of the first word is the sign of the MP number. The magnitude of the first word is the number of mantissa words. The second word of the MP array contains the exponent, which represents the power of the radix, which is either 222 = 4194304 for Cray systems or 224 = 16777216 for most other systems, including systems based on the IEEE 754 standard. Words beginning with the third word in the array contain the mantissa. Mantissa words are floating point whole numbers between 0 and one less than the radix. For MP numbers with zero exponent, the ""decimal"" point is assumed after the first mantissa word. For example, the MP number 3 is represented by the three-long array (1., 0., 3.). A MP zero is represented by the two-long array (0., 0.). If sufficient memory is available, the maximum precision level for MP numbers is ap4   proximately 50 million digits. The limiting factor for this precision level is the accuracy of calculations in the FFT-based multiplication routine. Beyond a certain level, rounding the double precision results of the final FFT to nearest integer is no longer reliable (see section 2.1 below). The maximum dynamic range of MP numbers is about 1014,000,000 . A MPC number is represented as two consecutive MP numbers, which are the real and imaginary parts of the complex number. A DPE number is a pair (A, N), where A is a double precision scalar and N is an integer. It represents A * 2**N. These DPE numbers are useful in multiple precision applications to represent numbers that do not require high precision but may have large exponent ranges. One distinguishing feature of the MPFUN package is its portability. The standard version of MPFUN should run correctly, without alteration, on any computer with a Fortran77 compiler that satisfies some minimal accuracy requirements. Any system based on the IEEE 754 floating point standard, with a 24 bit mantissa in single precision and a 52 bit mantissa in double precision (24 and 53 bits, including the hidden bit), easily meets these requirements. All DEC VAX systems meet these requirements. All IBM mainframes and workstations meet these requirements. Cray systems meet these requirements with double precision disabled (i.e. by using only single precision). To insure that these routines are working correctly, a test suite is available. It exercises virtually all of the routines in the package and checks the results. This test program is useful in its own right as a computer system integrity test. Versions of this program have on numerous occasions disclosed hardware and software bugs in scientific computer systems. 2.1 The Four Basic Arithmetic Op erations Multiprecision addition and subtraction are not computationally expensive compared to multiplication, division, and square root extraction. Thus simple algorithms suffice to perform addition and subtraction. The only part of these operations that is not immediately conducive to vector processing is releasing the carries for the final result. A key component of a high-performance multiprecision arithmetic system is the multiply operation, since in real applications typically a significant fraction of the total time is spent here. The author's basic multiply routine, which is used for modest levels of precision, employs a conventional ""schoolboy"" scheme, although care has been taken to insure that the operations are vectorizable. A significant saving is achieved by not releasing the carries after each vector multiply operation, but instead waiting until 32 such vector multiply operations have been completed (16 on Crays). An additional saving is achieved by computing only the first half of the multiplication ""pyramid"". The schoolboy scheme for multiprecision multiplication has computational complexity proportional to n2 , where n is the number of words or digits. For higher precision levels, other more sophisticated techniques have a significant advantage, with complexity as low as n log n log log n. The history of the development of advanced multiprecision multiplication algorithms will not be reviewed here. The interested reader is referred to Knuth [23]. Because of the difficulty of implementing these advanced schemes and the widespread misconception that these algorithms are not suitable for ""practical"" application, they are 5   rarely employed. For example, none of the widely used multiprecision packages employs an ""advanced"" multiplication algorithm, to the author's knowledge. One instance where an advanced multiplication technique was employed is [17]. Another is Slowinski's searches for large Mersenne prime numbers [29]. The author has implemented a number of these schemes, including variations of the Karatsuba-Winograd algorithm and schemes based on the discrete Fourier transform (DFT) in various number fields [23]. Based on performance studies of these implementations, the author has found that a scheme based on complex DFTs appears to be the most effective and efficient for modern scientific computer systems. The complex DFT and the inverse complex DFT of the sequence x = (x0 ,x1 ,x2 ,  ,xN -1 ) are given by N -1  Fk (x) = - Fk 1 (x) =  j =0  xj e-  2ij k/N  1 N  N -1 j =0  xj e2ij  k/N  Let C (x, y ) denote the circular convolution of the sequences x and y : N -1  Ck (x, y ) =  j =0  xj y  k -j  where the subscript k - j is to be interpreted as k - j + N if k - j is negative. Then the convolution theorem for discrete sequences states that F [C (x, y )] = F (x)F (y ) or expressed another way C (x, y ) = F -1  [F (x)F (y )]  This result is applicable to multiprecision multiplication in the following way. Let x and y be n-long representations of two multiprecision numbers (without the sign or exponent words). Extend x and y to length 2n by appending n zeroes at the end of each. Then the multiprecision product z of x and y , except for releasing the carries, can be written as follows: z0 = x0 y0 z1 = x0 y1 + x1 y0 z2 = x0 y2 + x1 y1 + x2 y0   zn-1 = x0 yn-1 + x1 yn-2 +  + x   n-1 y0  6   z2n- z2n- z2n-  3 2 1   =x =x =0  n-1 yn-2 n-1 yn-1  +x  n-2 yn-1  It can now be seen that this multiplication pyramid is precisely the convolution of the two sequences x and y , where N = 2n. In other words, the multiplication pyramid can be obtained by performing two forward DFTs, one vector complex multiplication, and one inverse DFT, each of length N = 2n. Once the inverse DFT results have been adjusted to the nearest integer to compensate for any numerical error, the final multiprecision product may be obtained by merely releasing the carries as described above. The computational savings arises from the fact that complex DFTs may of course be economically computed using some variation of the fast Fourier transform (FFT) algorithm. The particular FFT algorithm utilized for the MPFUN advanced multiplication routine is described in [2]. Since in this application the two inputs and the final output of the convolution are purely real, an algorithm is employed that converts the problem of computing the FFT on real data to that of computing the FFT on complex data of half the size. This results in a computational savings of approximately 50 percent. One important detail has been omitted from the above discussion. Since the radix of MP numbers is either 222 or 224 , the products xj yk-j may be as large as 248 - 1, and the sum of a large number of these products cannot be represented exactly as a 64 bit floating point value, no matter how it is computed. In particular, the nearest integer operation at the completion of the final inverse FFT cannot reliably recover the exact multiplication pyramid result. For this reason, each input data word is split into two words upon entry to the FFT-based multiply routine. This permits computations of up to approximately 50 million digits to be performed correctly. The division of two MP numbers of modest precision is performed using a fairly straightforward scheme. Trial quotients are computed in double precision. This guarantees that the trial quotient is virtually always correct. In those rare cases where one or more words of the quotient are incorrect, the result is automatically fixed in a cleanup routine at no extra computational cost. In the advanced division routine, the quotient of a and b is computed as follows. First the following Newton-Raphson iteration is employed, which converges to 1/b: x k+1  = xk + xk (1 - bxk )  Multiplying the final approximation to 1/b by a gives the quotient. Note that this algorithm involves only an addition and a subtraction, plus two multiplications, which can be performed using the FFT-based technique mentioned above. Also note that the term in parentheses is small. In fact, the product of xk with this term can be performed with half the normal level of precision. Algorithms based on Newton iterations have the desirable property that they are inherently self-correcting. Thus these Newton iterations can be performed with a precision 7   level that doubles with each iteration. One difficulty with this procedure is that errors can accumulate in the trailing mantissa words. This error can be economically controlled by repeating the next-to-last iteration. This increases the run time by only about 25 percent, and yet the result is accurate to all except possibly the last two words. It can easily be seen that the total cost of computing a reciprocal by this means is about 2.5 times the cost of the final iteration. The total cost of a multiprecision division is only about five times the cost of a multiprecision multiplication operation of equivalent size. 2.2 Other Algebraic Op erations Complex multiprecision multiplication is performed using the identity (a1 + a2 i)(b1 + b2 i) = [a1 b1 - a2 b2 ]+[(a1 + a2 )(b1 + b2 ) - a1 b1 - a2 b2 ]i Note that this formula can be implemented using only three multiprecision multiplications, whereas the straightforward formula requires four. Complex division is performed using the identity (a1 + a2 i)(b1 - b2 i) a1 + a 2 i = b1 + b2 i b2 + b2 1 2 where the complex product in the numerator is evaluated as above. Since division is significantly more expensive than multiplication, the two real divisions ordinarily required in this formula are replaced with a reciprocal computation of b2 + b2 followed by two 1 2 multiplications. The advanced routines for complex multiplication and division utilize these same formulas, but they call the advanced routines for real multiplication and division. The general scheme described in the previous section to perform division by Newton iterations is also employed to evaluate a number of other algebraic operations. For example, square roots are computed by employing the following Newton iteration, which converges  to 1/ a: x k+1  = xk +   Multiplying the final approximation to 1/ a by a gives the square root. As with division, these iterations are performed with a precision level that approximately doubles with each iteration. The basic square root routine computes each iteration to one word more than a power of two. As a result, errors do not accumulate very much, and it suffices to repeat the third-from-the-last iteration to insure full accuracy in the final result. The added cost of repeating this iteration is negligible. The advanced square root routine cannot compute each iteration to one greater than a power of two words, since the levels of precision are restricted to exact powers of two by the FFT-based multiply procedure. Thus the advanced routine repeats the next-tolast iteration. As in the advanced divide routine, repeating the next-to-last iteration adds about 25 percent to the run time. 8  xk (1 - ax2 ) k 2   The complex square root of z = x + iy can be computed by applying the formulas  |x| + x2 + y 2 s= 2  y z = s+i if x  0 2s |y |  is if x < 0 = 2s where the  sign is taken to be the same as the sign of y . Cube roots are computed by the following Newton iteration, which converges to a- xk xk+1 = xk + (1 - a2 x3 ) k 3  2/3  :  Multiplying the final approximation to a-2/3 by a gives the cube root. Included in the MPFUN package are basic and advanced routines to compute the n-th power of multiprecision real and complex numbers. These operations are performed using the binary rule for exponentiation [23]. When n is negative, the reciprocal is taken of the final result. Along with the n-th power routines are two n-th root routines. When the argument a is very close to one and n is large, the n-th root is computed using a binomial expansion. Otherwise, it is computed using the following Newton iteration, which converges to a-1/n : xk xk+1 = xk + (1 - axn ) k n The reciprocal of the final approximation to a-1/n is the n-th root. These iterations are performed with a dynamic precision level as before. The MPFUN package includes four routines for computing roots of polynomials. There is a basic and an advanced routine for computing real roots of real polynomials and complex roots of complex polynomials. Let P (x) be a polynomial and let P (x) be the derivative of P (x). Let x0 be a starting value that is close to the desired root. These routines then employ the following Newton iteration, which converges directly to the root: x k+1  = xk - P (xk )/P (xk )  These iterations are computed with a dynamic precision level scheme similar to the routines described above. One requirement for this method to work is that the desired root is not a repeated root. If one wishes to apply these routines to find a repeated root, it is first necessary to reduce the polynomial to one that has only simple roots. This can be done by performing the Euclidean algorithm in the ring of polynomials to determine the greatest common divisor Q(x) of P (x) and P (x). Then R(x) = P (x)/Q(x) is a polynomial that has only simple roots. In section 1.0, the usage of integer relation finding algorithms was mentioned in exploring the transcendence of certain mathematical constants. The author has tested two 9   recently discovered algorithms for this purpose, the ""small integer relation algorithm"" in [21], which will be termed the HJLS routine from the initials of the authors, and the ""partial sum of squares"" (PSOS) algorithm of H. R. P. Ferguson [5]. While each has its merits, the author has found that the HJLS routine is generally faster. Thus it has been implemented in MPFUN. Neither algorithm will be presented here. Interested readers are referred to the respective papers. 2.3 Computing  The computation of  to high precision has a long and colorful history. Interested readers are referred to [6] for discussion of the classical history of computing  . Recently a number of advanced algorithms have been discovered for the computation of  that feature very high rates of convergence [8, 9]. The first of these was discovered independently by Salamin [28] and Brent [10] and is referred to as either the Salamin-Brent algorithm or the Gauss-Legendre algorithm, since the mathematical basis of this algorithm has its roots in the nineteenth century. This algorithm exhibits quadratic convergence, i.e. each iteration approximately doubles the number of correct digits. Subsequently the Borweins have discovered a class of algorithms that exhibit m-th order convergence for any m [8, 9]. The author has tested a number of these algorithms. Surprisingly, although the Borwein algorithms exhibit higher rates of convergence, the overall run time is generally comparable to that of the Salamin-Brent algorithm. Since the Salamin-Brent algorithm is simpler, it wa chosen for implementation in MPFUN. It may be stated as follows. Set a0 = 1, b0 = s  1/ 2, and d0 = 2 - 1/2. Then iterate the following operations beginning with k = 1: a b k  = (a =  k -1  +b  k -1  )/2  k  a  k -1 bk -1  dk = dk  -1  - 2k (ak - bk )2  Then pk = (ak + bk )2 /dk converges quadratically to  . Unfortunately this algorithm is not self-correcting like algorithms based on Newton iterations. Thus all iterations must be done with at least the precision level desired for the final result. 2.4 Transcendental Functions The basic routine for exp employs a modification of the Taylor's series for et : r2 r3 r4 et = (1 + r + + + )256 2n 2! 3! 4! where r = t /256, t = t - n log 2 and where n is chosen to minimize the absolute value of t . The exponentiation in this formula is performed by repeated squaring. Reducing t modulo log 2 and dividing by 256 insures that -0.001 < r  0.001, which significantly accelerates convergence in the above series. The basic routine for log employs the following Newton iteration, which converges to log t: t - exp xk xk+1 = xk + exp xk 10   The run time of the basic log routine is only about 2.5 times that of the exp routine. The advanced routine for log employs a quadratically convergent algorithm due to Salamin, as described in [12]. Inputs t that are extremely close to 1 are handled using a Taylor series. Otherwise let n be the number of bits of precision required in the result. If t is exactly two, select m > n/2. Then the following formula gives log 2 to the required precision:  log 2 = 2mA(1, 4/2m ) Here A(a, b) is the limit of the arithmetic-geometric mean: let a0 = a and b0 = b. Then iterate ak b +1  k+1  ak + b 2 = ak b k =  k  For other t select m such that s = t2m > 2n/2 . Then the following formula gives log t to the required precision:  - m log 2 log t = 2A(1, 4/s) The advanced routine for exp employs the following Newton iteration, which converges to et : x k+1  = xk (t +1 - log xk )  It might be mentioned that quadratically convergent algorithms for exp and log were first presented by Brent in [10], and others were presented by the Borweins in [7, 8]. Based on the author's comparisons, however, the Salamin algorithm is significantly faster than either the Brent or the Borwein algorithm. For this reason the Salamin algorithm was selected for inclusion in this package. The basic routine for sin and cos utilizes the Taylor's series for sin s: sin s = s - s3 s5 s7 + -  3! 5! 7!  where s = t - a /2 - b /16 and the integers a and b are chosen to minimize the absolute value of s. We can then compute sin t = sin(s + a /2+ b /16) cos t = cos(s + a /2+ b /16) by applying elementary trigonometric identities for sums. The sin and cos of b /16 are of  the form 0.5 2  2  2. Reducing t in this manner insures that -/32 < s  /32, which significantly accelerates convergence in the above series. 11   The advanced routines for cos and sin, and for inverse cos and inverse sin, employ complex arithmetic versions of the advanced algorithms described above for exp and log (recall that eix = cos x + i sin x). 2.5 Accuracy of Results Most of the basic routines, and the advanced multiplication routine, are designed to produce results correct to the last word of working precision. In the case of the transcendental functions, the last word should be accurate provided the input values  and log 2 have been computed to at least one word of precision greater than the working precision. Even so, an entire word can easily be lost in many calculations due to normalization, such as when the reciprocal of a number slightly less than one is computed. Thus computations should always be performed with at least one extra word of precision than required for the final results. For the advanced routines other than multiplication, the last two to four words are not reliable, as explained in the previous sections. For example, the ratio of two integers computed using the advanced division routine, the first of which is an exact multiple of the second, may not give the correct integer result. This situation should be familiar to users of Cray computers, which also uses Newton iterations to calculate reciprocals. Most anomalies of this sort can be remedied by adding a ""fuzz"" to results. The accuracy of results from the MPFUN routines can also be controlled by setting a rounding mode parameter. Depending on the value of this parameter, results are either truncated at the last mantissa word of working precision, or else the last word is rounded up depending on contents of the first omitted word. Whichever routines and rounding mode are used, it is not easy to determine ahead of time what level of precision is necessary to produce results accurate to a desired tolerance. Also, despite safeguards and testing, a package of this sort cannot be warranted to be free from bugs. Additionally, compiler and hardware errors do occur, and it is not certain that they will be detected by the package. Thus the following procedure is recommended to increase one's confidence in computed results: 1. Start with a working double precision program, and then check that the ported multiprecision code duplicates intermediate and final results to a reasonable accuracy. 2. Where possible, use the ported multiprecision code to compute special values that can be compared with other published high precision values. 3. Repeat the calculation with the rounding mode parameter changed, in order to test the sensitivity of the calculation to numerical error. Alternatively, repeat the calculation with the precision level set to a higher level. 4. Repeat the calculation on another computer system, in order to certify that no hardware or compiler error has occurred.  12   2.6 MPFUN Performance One application of a package such as MPFUN is to remedy difficult numerical problems that sometimes arise in conventional scientific programs. In these cases, a precision level perhaps double or triple that of ordinary machine precision is all that is required. One might wonder how much longer such a program is likely to run using calls to MPFUN. Using the translator program described below, the author has converted to multiprecision a program that, among other things, computes fast Fourier transforms (FFTs). The precision level was 40 digits. On a Silicon Graphics RISC workstation, the multiprecision code ran 135 times slower than the same program with ordinary double precision (64-bit) arithmetic. Thus while such runs are indeed possible, they are not to be considered lightly. Another application of a package such as MPFUN is for problems where the precision level required is much higher than that which can be obtained through ordinary machine arithmetic, perhaps hundreds or even thousands of digits. Such applications arise most often in numerical studies of mathematical questions. In such cases the dominant computational cost is not merely subroutine calling overhead, and algorithmic factors become more significant. One way to compare the performance of the author's package with other multiprecision packages is to compare timings for the computation of a mathematical constant such as  to high precision, since this is easily programmed and yet exercises all of the basic arithmetic routines. Tables 1 and 2 give some performance results on this problem for the MPFUN package, the Mathematica package and Brent's package. The algorithm used by Mathematica is not mentioned in the Mathematica reference book [32], but it is probably either the Salamin-Brent algorithm or one of the Borwein algorithms. The algorithm used by Brent's package for computing  is the Salamin-Brent algorithm, basically the same as described in section 2.3. The timings in Table 1 are for a Silicon Graphics model 4D-380 RISC workstation (one processor), which has a theoretical peak performance of 16 MFLOPS and a Linpack performance of 4.9 MFLOPS (double precision figures). The timings in Table 2 are for a Cray Y-MP supercomputer (one processor), which has a theoretical peak performance of 330 MFLOPS and a Linpack performance of 90 MFLOPS. When these runs were made, the SGI system was running IRIX 3.3 system software, and the Cray was running UNICOS 6.0. A blank in the table indicates that the run would have taken an unreasonable amount of time and was not performed. The numbers of digits in the second column of the two tables correspond to 7.225  2m and 6.623  2m , respectively, which are the sizes convenient for the FFT-based multiplication scheme described above. It can be seen from these results that the MPFUN package is the fastest of the three at all precision levels on both systems. On the SGI system, MPFUN is nearly twice as fast as Mathematica and three times as fast as Brent's package for the lowest precision levels. Once the level of precision rises above 1000 digits, MPFUN has a considerable advantage, due mainly to its FFT-based multiply routine. At 29,590 digit precision, the highest level at which all three could be compared, the MPFUN package is seven times faster than Mathematica and 18 times faster than Brent's package. 13   m Digits MPFUN Mathematica Brent 3 60 0.011 0.020 0.033 4 115 0.024 0.040 0.062 5 230 0.053 0.100 0.174 6 460 0.139 0.340 0.543 7 925 0.444 1.190 2.150 8 1,850 1.420 4.570 8.610 9 3,700 4.880 17.410 34.550 10 7,400 14.150 68.240 145.330 11 14,795 41.800 270.600 619.160 12 29,590 146.890 1080.000 2661.640 13 59,185 504.090 14 118,370 1361.190 Table 1: SGI Workstation Performance Results (seconds)  m Digits MPFUN Brent 4 105 0.006 0.019 5 210 0.010 0.037 6 425 0.018 0.088 7 845 0.037 0.229 8 1,695 0.088 0.815 9 3,390 0.177 3.176 10 6,780 0.386 13.040 11 13,565 0.772 54.620 12 27,125 1.598 230.800 13 54,250 3.450 975.600 14 108,505 7.503 15 217,010 16.710 16 434,020 36.490 17 868,045 81.690 18 1,736,090 173.300 Table 2: Cray Y-MP Performance Results (seconds)  14   On the Cray Y-MP, the MPFUN package is three times faster than Brent's package at the lowest precision level and 280 times faster at 54,250 digits precision, the highest level at which both could be compared. Two reasons this ratio is so high on the Cray Y-MP are (1) the MPFUN routines employ floating point arithmetic, whereas Brent's package uses integer operations, and (2) a high percentage of operations in the MPFUN routines are performed in vector mode, whereas much of the computation in Brent's package is done in scalar mode. At the highest precision level listed, the Y-MP is running the author's code at 195 MFLOPS, or 59% of the one processor peak rate. Since Brent's package and Mathematica are perhaps the most widely used packages of this sort, other authors typically compare their performance figures with one of these. For example, Smith [30] compares his package with Brent's. Since Smith's timings for fundamental add and multiply operations are roughly comparable to Brent's, it would be expected that MPFUN would exhibit similar performance ratios with Smith's package. 3.0 Overview of the Multiprecision Translator Conversion of a conventional scientific application program to use the MPFUN routines is generally straightforward, but it is often tedious and error prone. For example, if the slightest error is made in any of the arguments to the many subroutine calls, not only will the results be in error, but the program may abort with little information to guide the programmer. As a result of these difficulties, few serious scientific programs have been manually converted to use the MPFUN routines. Similar difficulties have plagued programmers who have attempted to use other multiprecision systems, such as Brent's package [11]. To facilitate such conversions, the author has developed a translator program that accepts as input a conventional Fortran-77 program to which has been added certain special comments that declare the desired level of precision and specify which variables in each subprogram are to be treated as multiprecision. This translator then parses the input code and generates an output program that has all of the calls to the appropriate MPFUN routines. This output program may then be compiled and linked with the MPFUN package for execution. This translation program allows one to extend the Fortran-77 language with the datatypes MULTIP INTEGER, MULTIP REAL and MULTIP COMPLEX. These datatypes can be used for integer, floating point or complex numbers of an arbitrarily high, pre-specified level of precision. Variables in the input program may be declared to have one of these multiprecision types in the output program by placing directives (special comments) in the input file. In this way, the input file remains an ANSI Fortran-77 compatible program and can be run at any time using ordinary arithmetic on any Fortran system for comparison with the multiprecision equivalent. This translator supports a large number of Fortran-77 constructs involving multiprecision variables, including all the standard arithmetic operators, mixed mode expressions, automatic type conversions, comparisons, logical IF constructs, function calls, READ and WRITE statements and most of the Fortran intrinsics (i.e. ABS, MOD, COS, EXP, etc.). 15   Storage is automatically allocated for multiprecision variables, including temporaries, and the required initialization for the MPFUN package is automatically performed. This processor translates programs to use the standard MP routines from the author's MPFUN package. If one wishes to utilize this translator in connection with the extra-high precision routines of this package, which are designed for precision levels greater than about 1,000 digits, contact the author for instructions. 3.1 Op eration of the Translator Program This translator program should run on any Fortran-77 system that supports recursive subroutine references. On some systems, including Sun and IBM workstations, a minor source modification and/or a special compiler option must be enabled to permit the program to run correctly. Detailed instructions for compiling and testing the translator on various systems are given in a ""read-me"" file that accompanies the program code. The translator has been successfully implemented on Cray supercomputers, Sun workstations, SGI workstations, IBM workstations and mainframes (AIX operating system), DEC workstations, HP workstations and Intel parallel computers. The translator is in effect a compiler in the sense that it identifies and analyzes every input statement. It develops a symbol table that contains type and dimension information for all variables used in a subprogram. A number of Fortran statements, such as DO, CONTINUE and OPEN statements, are not modified by the translator. Most other statements are analyzed in detail, including type declarations, IMPLICIT, COMMON, DIMENSION, PARAMETER, READ, WRITE and CALL statements, as well as all assignment statements. If any input statement is modified or translated, the original statement is included in the output file as a comment, starting with the string CMP>. The comment CMP< is placed after the translated lines. Warnings and error messages are also written in the output file. Warnings are issued as comments starting with CMP*. Fatal error messages start with ***. When a fatal error is detected, the message is output on the output file, and processing is terminated. Thus to make sure that the translation of an input program was successful, check the end of the output file to make sure there is no fatal error message. It is also strongly recommended that the output program be scanned for CMP* warning messages before it is compiled and executed. 3.2 Precision Level and Explicit Typ e Directives In the following, an MP statement will be defined as a statement that has at least one MP variable. An MP subprogram will be defined as a subprogram with at least one MP variable. Table 3 gives several datatype abbreviations that will be used hereafter in this paper. At the beginning of a file containing a conventional Fortran-77 code to be translated, before any program or subroutine statement, a directive (i.e. special comment) of the following form must be inserted: CMP+ PRECISION LEVEL 120  16   IN SP DP CO DC MPI MPR MPC MP  Integer Single precision real Double precision real Single precision complex Double precision complex (non-ANSI extension of Fortran-77) Multiprecision integer Multiprecision real Multiprecision complex Denotes the three multiprecision types collectively Table 3: Datatype Abbreviations  This denotes that the maximum precision level to be employed in this program is 120 digits. Only one such declaration is allowed in a single file, and Fortran-77 files whose translated routines later will be linked together must have equivalent precision level declarations. This directive must precede any of the other CMP+ directives to be described below. This and all other MP directives described in this paper may alternately be written with lower case alphabetics. Variables in a subprogram of the input Fortran-77 program file that are to be treated as MP by the translator program may be declared by explicit MP type directives, such as the following: CMP+ MULTIP INTEGER IA, IPR, KMAX3 CMP+ MULTIP REAL SUM, TOL34, X, Y CMP+ MULTIP COMPLEX W, ZAB  An MP variable must be declared prior to any appearance of that variable in the subprogram, including any appearance in a type declaration, DIMENSION or COMMON statement. An exception to this rule is that MP variable names appearing in the argument list of a FUNCTION or SUBROUTINE statement may be afterwards declared. However, if the function name of a function subprogram is to have an MP type, this name must be declared with an MP type directive immediately preceding the FUNCTION statement. The dimensions for MP variables are not included in MP type directives. These dimensions will be taken from the standard type declaration, DIMENSION or COMMON statement where these dimensions are defined in the original program. 3.3 Implicit Typ e Directives Many Fortran-77 codes utilize implicit typing of variables, either with the default convention or with IMPLICIT statements. For example, many programmers use an IMPLICIT statement to automatically declare all variables whose first letters are in the ranges A-H and O-Z to be DP. To simplify the translation of such code, implicit MP type directives may be used, as in these examples: 17   CMP+ IMPLICIT MULTIP REAL (A-H, O-Z) CMP+ IMPLICIT MULTIP INTEGER (M) CMP+ IMPLICIT MULTIP COMPLEX (C, Z)  Implicit MP type directives should appear at the beginning of a subprogram, just like standard IMPLICIT statements. An implicit MP type directive overrides any standard IMPLICIT statement, but it does not override either an explicit MP type directive or a standard type statement. In function subprograms, an implicit MP type directive may not be used to declare the type of the function name. Use an explicit MP type directive for this purpose, placed immediately before the FUNCTION statement. 3.4 The SAFE and FAST Options Expressions involving MP variables and constants are evaluated using precedence conventions of Fortran-77, and using predictable extensions of 77 mixed mode conventions. There are two options for the evaluation of operations: FAST and SAFE. The difference between these conventions may the following example, where A and B are MPR and N is an ordinary integer B = A + 1.D0 / N  the operator the Fortranmixed mode be seen with variable:  With the FAST option, the subexpression 1.D0 / N is evaluated using DP arithmetic, and the result temporary has type DP. With the SAFE option, which is the default, 1.D0 / N is performed using MP arithmetic, and the result temporary has type MPR. As the name signifies, the FAST option produces somewhat more efficient translated code, but it may also give unexpectedly inaccurate answers, for instance if N in the above example has the value 7. An exception to the SAFE option is in the argument lists of subroutine calls or nonintrinsic function references. Expressions appearing in these lists are always evaluated using the FAST option, since this corresponds more closely to the Fortran convention that most users expect. Thus in the statement B = 3 * FUN (N - 1, A)  the subexpression N - 1 is always evaluated using ordinary integer arithmetic, and the result temporary, which is passed to FUN, has type IN. The user may switch between these options by inserting one of the following directives in the declaration section of any subprogram: CMP+ MIXED MODE FAST CMP+ MIXED MODE SAFE  For the operators + - * /, Tables 4 and 5 give the types of results with these two options. Table 6 lists the argument types and results defined for the ** operator. In Table 6, if a particular combination is not listed, or if its position in the table is blank, then it is not 18   defined. Comparison operations (i.e. .EQ., .LT., etc.), where one or both of the operands are MP, are permitted both in logical IF statements and in logical assignment statements. If one of the operands has type CO, DC or MPC, only .EQ. and .NE. comparisons are permitted. 3.5 Multiprecision Constants With the SAFE option, all IN constants appearing in MP statements are considered MPI constants and are converted to full precision, and all SP or DP constants in MP statements are considered MPR constants and are converted to full precision. With the FAST option, IN, SP and DP constants are recognized and treated as such by the translator. They are merely passed unchanged to the output program and are converted to binary by the underlying Fortran system. For modest sized whole numbers and exact binary fractions, these constants are converted exactly and produce accurate results when they appear in expressions with MP variables. However, SP or DP constants that cannot be precisely converted (i.e. 1.01D0), or IN, SP or DP constants that have more significant digits than can be exactly accommodated in these datatypes, may result in inaccurate MP calculations. To avoid such difficulties with the FAST option, the user may explicitly specify that a constant in the input program will be treated as an MP constant for the output program. This is done by appending +0 to the constant, as in the following examples: 3+0 -12345678901234567890+0 3.141592653589793+0 1.2345678901234567890D-13+0  The first two constants have type MPI, and the last two have type MPR. Embedded blanks are allowed anywhere in these constants. MP constants must appear in a context where the plus operation would actually be performed between the two components of the MP constant if interpreted according to the standard Fortran rules for evaluating expressions. For example, the expression N*12345+0 is not treated as containing an MP constant. Write this as N*(12345+0) if so intended. MP constants are recognized as such only in MP statements. There is no definition of this sort for MPC constants, but MPC constants may be defined by using the special conversion function DPCMPL (see section 3.6), where the two arguments are MPR constants. MP constants may be defined symbolically using PARAMETER statements. The parameter assignment expression for an MP variable may reference previously defined MP and nonMP parameters, and it may also include intrinsic function references. All such assignments are performed upon entry to the subprogram the first time it is called. 3.6 Intrinsic Functions Table 7 lists Fortran intrinsic functions that are supported by this translator with MP arguments. References to these functions will be automatically translated to call 19   Arg. 1 / Arg. 2 IN IN IN SP SP DP DP CO CO DC DC MPI MPI MPR MPR MPC MPC  SP SP SP DP CO DC MPR MPR MPC  DP DP DP DP CO DC MPR MPR MPC  CO CO CO DC CO DC MPC MPC MPC  DC MPI MPR DC MPI MPR DC MPR MPR DC MPR MPR DC MPC MPC DC MPC MPC MPC MPI MPR MPC MPR MPR MPC MPC MPC  MPC MPC MPC MPC MPC MPC MPC MPC MPC  Table 4: Results of Mixed Mode Arithmetic Operations with the FAST option  Arg. 1 / Arg. 2 IN IN MPI SP MPR DP MPR CO MPC DC MPC MPI MPI MPR MPR MPC MPC  SP MPR MPR MPR MPC MPC MPR MPR MPC  DP MPR MPR MPR MPC MPC MPR MPR MPC  CO MPC MPC MPC MPC MPC MPC MPC MPC  DC MPC MPC MPC MPC MPC MPC MPC MPC  MPI MPI MPR MPR MPC MPC MPI MPR MPC  MPR MPR MPR MPR MPC MPC MPR MPR MPC  MPC MPC MPC MPC MPC MPC MPC MPC MPC  Table 5: Results of Mixed Mode Arithmetic Operations with the SAFE option (default)  20   Arg. 1 IN IN or SP IN, SP or DP IN, SP or CO IN, SP, DP, CO or DC IN IN, SP or DP CO CO CO DC DC MPI MPI MPR MPC  Arg. 2 IN SP DP CO DC MPI MPR IN SP DP or DC IN SP, DP, CO or DP IN or MPI SP, DP or MPR IN, SP, DP, MPI or MPR IN  Result FAST SAFE IN MPI SP MPR DP MPR CO DC MPI MPI MPR MPR CO MPC CO DC DC MPC DC MPI MPI MPR MPR MPR MPR MPC MPC  Table 6: Defined Combinations for the ** Operator  21   the appropriate routines from the MPFUN package, provided the arguments are of the appropriate MP type. If the SAFE option is in effect, non-MP arguments are first converted to MP, so that true MP results are always returned. If the user requires either a function not listed here or a function with an argument type not listed here, contact the author. Note that Table 7 does not include any of the (obsolescent) type-specific Fortran-77 functions (i.e. AMOD, DABS, MIN0, etc.). This is in keeping with the Fortran-77 convention that these are defined only for specific IN, SP and DP argument types. References to these functions are not permitted in MP statements. Use the equivalent generic Fortran-77 functions (i.e. MOD, ABS, MIN, etc.) instead. Also note in Table 7 that the conversion intrinsics of Fortran-77, namely INT, CMPLX, DBLE, DCMPLX and REAL, return results of types IN, CO, DP, DC and SP, respectively, even though the arguments have MP types. This is in keeping with the conventions of Fortran-77. If one wishes to truncate an MPR number to MPI, form an MPC number from two MPR numbers, or extract the MPR real and imaginary components of an MPC number, the special functions MPINT, DPCMPL, DPREAL, DPIMAG (see Table 8) should be used instead. These special functions are not defined for ordinary SP, DP, CO or DC arguments in the translated program (although they may be in the input program). Thus, for example, DPREAL cannot be used to convert a DP number to MPR. Type conversions such as this can be performed either by simple assignment statements, or else by defining an external MP function. To preserve comparable functionality between an input Fortran-77 program that uses one of these four special conversion functions and the output MP program, equivalent SP or DP function subprograms should be included in the input file. Table 9 has some examples of equivalent definitions for these functions that use DP and DC datatypes. If your program uses ordinary SP and CO datatypes instead, these sample subprograms need to be changed accordingly. Do not place any MP directives in these function subprograms. If another subprogram references one of these functions, it should declare the argument and function names to be of the appropriate types (i.e. IN, DP or DC). However, the names MPINT, DPCMPL, DPREAL and DPIMAG do not need to be declared with MP type directives in the subprograms where they are referenced. In the output program, MP results will be automatically be returned with types according to Table 8, and these sample subprograms will be ignored. With the FAST option, non-MP arguments to intrinsic functions appearing in MP statements are passed without change to the non-MP intrinsic functions. For non-MP arguments the translator recognizes the following ""generic"" intrinsic function names and assigns result types according to argument types, in accordance with the standard Fortran conventions: ABS, ACOS, AINT, AIMAG, ANINT, ASIN, ATAN, ATAN2, CHAR, CMPLX, CONJG, COS, COSH, DBLE, DCMPLX, DIM, DIMAG, DREAL, EXP, ICHAR, INDEX, INT, LEN, LOG, LOG10, MAX, MIN, MOD, NINT, REAL, SIGN, SIN, SINH, SQRT, TAN, TANH.  Note that this list, like Table 7, does not include any of the type-specific Fortran-77 intrinsic functions (i.e. AMOD, DABS, MIN0, etc.). References to these functions are not permitted 22   Function ABS  ACOS AINT ANINT ASIN ATAN ATAN2 CMPLX CONJG COS COSH DBLE  DCMPLX EXP INT  LOG LOG10 MAX MIN MOD NINT REAL  SIGN SIN SINH SQRT TAN TANH  Arg. 1 MPI MPR MPC MPR MPR MPR MPR MPR MPR MPC MPC MPR MPR MPI MPR MPC MPC MPR MPI MPR MPC MPR MPR MPI MPR MPI MPR MPI MPR MPI MPR MPI MPR MPC MPI MPR MPR MPR MPR MPC MPR MPR  Arg. 2  MPR  MPI MPR MPI MPR MPI MPR  MPI MPR  Result MPI MPR MPR MPR MPR MPR MPR MPR MPR CO MPC MPR MPR DP DP DP DC MPR IN IN IN MPR MPR MPI MPR MPI MPR MPI MPR MPI MPR SP SP SP MPI MPR MPR MPR MPR MPC MPR MPR  Table 7: Fortran Intrinsics Supported with MP Arguments 23   Function MPINT DPCMPL DPREAL DPIMAG  Arg. 1 Arg. 2 Result MPR MPI MPR MPR MPC MPC MPR MPC MPR  Table 8: Special MP Conversion Functions  FUNCTION MPINT (X) DOUBLE PRECISION X MPINT = INT (X) RETURN END FUNCTION DPCMPL (A, B) DOUBLE COMPLEX DPCMPL DOUBLE PRECISION A, B DPCMPL = DCMPLX (A, B) RETURN END FUNCTION DPREAL (C) DOUBLE PRECISION DPREAL DOUBLE COMPLEX C DPREAL = DBLE (C) RETURN END FUNCTION DPIMAG (C) DOUBLE PRECISION DPIMAG DOUBLE COMPLEX C DPIMAG = DIMAG (C) RETURN END  Table 9: DP Equivalents of the Special Conversion Functions  24   in MP statements. Use the equivalent generic Fortran-77 functions (i.e. MOD, ABS, MIN, etc.) instead. 3.7 Other Sp ecial Functions and Constants Whenever the translator encounters a reference to COS or SIN in the source program, it inserts a call to the MPFUN routine MPCSSN. However, in many instances the user's code requires both function values for a single argument, often computed in adjacent lines of code. Since MPCSSN actually returns both the cosine and sine of the input argument at no extra cost, the two calls to MPCSSN are redundant and may represent a significant waste of computing time. If run-time performance is an issue in such programs, the user may optionally replace the separate references to COS and SIN with a single call to the special MP subroutine DPCSSN, which has three arguments: the first is the input value, and the second and third are the output cosine and sine values. The translator recognizes this subroutine name and will substitute a call to MPCSSN to produce MP results. For compatibility purposes, a functional equivalent of DPCSSN should be included in the program file. A DP example is shown in Table 10. The analogous subroutine name recognized for the hyperbolic functions COSH and SINH is DPCSSH (see Table 10). Another operation of this nature is root extraction, i.e. B = A ** (1.D0 / N), for which the efficient routine MPNRT exists in the MPFUN package. Thus it is recommended (for improved run-time performance) that any code in the input program that performs root extraction using the ** operator be changed to reference the function DPNRT instead, i.e. B = DPNRT (A, N). A DP equivalent of DPNRT is shown in Table 10. One additional special function that many users may find useful produces pseudorandom MPR numbers. The routine MPRAND in the MPFUN package generates pseudorandom numbers uniformly in the range (0, 1). To access this routine by means of the translator, one references the special function DPRAND. This function has no arguments. One references it by means of statements such as A = 3 * DPRAND (). It is not possible to write a completely equivalent DP version of this routine. However, the basic pseudorandom number functionality can be reproduced by means of a simple routine such as the one shown in Table 10. The sample program definitions for DPCSSN, DPCSSH, DPNRT and DPRAND in Table 10, like the definitions of the special conversion functions in Table 9, are only for the purpose of providing comparable functionality when the input program is run with ordinary SP or DP arithmetic, and are ignored in the translated program. Do not place any MP directives in any of these sample subprograms. If another subprogram references either DPNRT or DPRAND, it should declare the function name to be of the appropriate type (DP in the examples above). However, the names DPNRT and DPRAND do not need to be declared with an MP type directive in subprograms that reference them. The constants log 2 = 0.69314  , log 10 = 2.30258  and  = 3.14159  are computed in the program initialization and are available in any subprogram that contains MP variables. These values may be referenced by the user by means of the special variable 25   SUBROUTINE DPCSSN (A, X, Y) DOUBLE PRECISION A, X, Y X = COS (A) Y = SIN (A) RETURN END SUBROUTINE DPCSSH (A, X, Y) DOUBLE PRECISION A, X, Y X = COSH (A) Y = SINH (A) RETURN END FUNCTION DPNRT (A, N) DOUBLE PRECISION A, DPNRT DPNRT = A ** (1.D0 / N) RETURN END FUNCTION DPRAND () C C C C C This routine returns a pseudorandom DP floating number nearly uniformly distributed between 0 and 1 by means of a linear congruential scheme. 2^28 pseudorandom numbers with 30 bits each are returned before repeating. IMPLICIT DOUBLE PRECISION (A-H, O-Z) PARAMETER (F7 = 78125.D0, R30 = 0.5D0 ** 30, T30 = 2.D0 ** 30) SAVE SD DATA SD/314159265.D0/ C T1 = F7 * SD T2 = AINT (R30 * T1) SD = T1 - T30 * T2 DPRAND = R30 * SD C RETURN END  Table 10: Suggested DP Equivalents of DPCSSN, DPCSSH, DPNRT and DPRAND  26   names DPL02, DPL10 and DPPIC. Whenever any of these names appears in a statement, the translator substitutes the MP value. For compatibility purposes, any subprogram that references one of these constants should declare it to be SP or DP and set its approximate decimal value in a parameter statement. Example: DOUBLE PRECISION DPPIC PARAMETER (DPPIC = 3.141592653589793D0)  This parameter statement will be ignored in the output program, and the MP value will be used instead. The names DPL02, DPL10 and DPPIC do not need to be declared with an MP type directive. Do not attempt to define any of these values by means of assignments or function calls. 3.8 Input and Output of MP Numb ers MP variables may appear in READ or WRITE statements only with the following two special forms: WRITE (6, *) VAR1, VAR2(I), VAR3(I,J) READ (11) VAR1, VAR2, VAR3  Either form may be a READ or WRITE, but neither may employ implied DO loops. Convert implied DO loops to explicit DO loops instead. The unit numbers may be integer variables instead of integer constants. Non-MP variables and constants may be included in the list, in which case they are handled using ordinary Fortran I/O. The first form is used for input and output of individual MP numbers (not entire unsubscripted arrays) in ordinary decimal form. The digits of the number may span more than one line. A comma at the end of the last line denotes the end of an MP number. Input lines may not exceed 120 characters in length, but embedded blanks are allowed anywhere. The exponent is optional in an input number, but if present it must appear first, as in the following example: 10 ^ -4 x 3.14159 26535 89793 23846 26433 83279 50288 41971 69399 37510,  MPC numbers are input or output as two consecutive MPR numbers. The output of an MP write operation is in the correct form for a subsequent MP read operation. By default, all digits of an MP number are output. The user can control the number of mantissa digits output by including a directive such as CMP+ OUTPUT PRECISION 200  in the declaration section of any subprogram. It remains in effect until the end of file or until another such directive is encountered. The second form of READ/WRITE statement above is used to perform binary I/O of entire MP arrays. Subscripted variables are not allowed in the second form. 27   3.9 Controlling the Multiprecision ""Epsilon"" and Precision Level Many programs need to control the MP ""epsilon"" for performing comparisons. To this end, the user can reference the special MP constant DPEPS. For compatibility purposes, any subprogram that uses DPEPS should declare it to be SP or DP and set it to some nominal small value in a parameter statement. Example: DOUBLE PRECISION DPEPS PARAMETER (DPEPS = 1D-16)  Whenever this name appears in a subprogram that contains MP variables, the translator substitutes the MP ""epsilon"" value, which by default is 107-D , where D is the number of digits of precision specified in the precision level directive. DPEPS does not need to be declared with an MP type directive. The MP epsilon value may be modified (independent of the precision level directive) by inserting a directive such as CMP+ EPSILON 1E-200  in the declaration section of any subprogram (for instance, adjacent to the parameter statement in which DPEPS is defined). It remains in effect until the end of file or until another such directive is encountered. The number of mantissa words allocated by the translator for MP numbers is approximately one seventh the number of digits specified in the precision level directive. The first dimension of MP arrays is this number plus 4. The user may access the number of mantissa words in the special constant MPNWP. For compatibility purposes, any subprogram that uses MPNWP should be declare it to be of type IN and set it to some nominal integer value in a parameter statement. Example: INTEGER MPNWP PARAMETER (MPNWP = 1)  MPNWP, like MPL02 and MPPIC, is considered a constant and may not be changed. If one wishes to dynamically change the working precision level within a program (which is not recommended for novice users), this may be done by calling the MPFUN routines MPSETP and MPINQP, as follows: CALL MPSETP ('NW', 35) CALL MPINQP ('NW', NX)  The first line sets the working precision level to 35 words. This value must not be greater than the value of MPNWP. The second line sets NX to be the value of the current working precision. If the user is not concerned about possible name conflicts, the same functions can be accomplished by simply including the MPFUN common block COMMON /MPCOM1/ NW, IDB, LDB, IER, MCR, IRD, ICS, IHS, IMS  28   in the subprogram and directly modifying the variable NW. 3.10 Single Precision Scratch Space for the MPFUN Package The maximum amount of SP scratch space in common block MPCOM3 (see the documentation for the MPFUN package [4]), cannot be determined in advance by the translator program. The MPFUN package allocates 1024 SP cells in this block, which for most programs is sufficient. If the ""insufficient single precision scratch space"" error is encountered during execution of the resulting MP program, place a directive of the form CMP+ SCRATCH SPACE 2000  at the beginning of the input file, before the PROGRAM statement but after the precision level directive. The number placed on this line should be at least the size mentioned in the error message. 3.11 Other Restrictions and Limitations It should be emphasized again that the Fortran-77 language is not perfectly or completely supported by the translator. In addition to the restrictions already mentioned, a number of other limitations apply. A complete list is included below. However, note that in almost every case there is a simple change that can be made to the input program to make it acceptable to this translation program, while retaining both its functionality and Fortran-77 compliance. The ma jority of these restrictions are merely good programming practice. 1. A number of identifiers beginning with DP and MP are reserved for use by the translator, and the translator will flag an error if any of these appears in the user's input program. To be safe, do not use such names in your program, other than as instructed in this paper. 2. ENTRY,typed FUNCTION (i.e. INTEGER FUNCTION), assigned GOTO, arithmetic IF, READ or WRITE without parentheses, and PRINT statements are not allowed. Please replace these constructs, which in most cases are obsolescent, with more conventional alternatives: FUNCTION statements followed by type statements, normal subroutine calls, computed or ordinary GOTO statements, logical IF statements and normal READ or WRITE statements, respectively. 3. References to the (obsolescent) type-specific Fortran-77 intrinsic functions (i.e. AMOD, DABS, MIN0, etc.) are not allowed in MP statements. Use the equivalent generic Fortran-77 functions (i.e. MOD, ABS, MIN, etc.) instead. 4. Statement functions may not be used to define MP functions. Convert these into MP function subprograms or subroutines. 5. MP variables may not appear in DATA statements. Convert these into parameter or assignment statements. 29   6. MP variables or constants may not appear in DO statements, array dimensions or array subscripts. 7. An MP statement may not be the terminal line of a DO loop. Place the line number on a CONTINUE line immediately following the statement. If the line number is also the target of a GOTO, the DO loop must be changed to use a separate terminal line number. 8. MP variables or constants may not appear in formatted READ or WRITE statements, and other restrictions apply to the I/O of MP data. See section 3.8 for details. 9. The logical operators .NOT., .EQV. and .NEQV. may not appear in MP statements. Rewrite such statements using .AND. and .OR. operators, or move such subexpressions to a separate statement. 10. Complex constants [i.e. (3., 2.)] may not appear in MP statements. Either use the intrinsic functions CMPLX or DCMPLX, or else assign such constants to CO or DC variables in separate statements. 11. Except for variables in the argument list, variables that appear in a type statement or an MP type directive may not have previously appeared in the subprogram. 12. A single IMPLICIT statement may be used to declare the initial letter(s) for only one datatype. A single COMMON statement may be used to declare only one common block. 13. DATA statements and FORMAT statements may appear only after the end of the specification section of the program, i.e. only after type declaration, DIMENSION statements, COMMON statements, etc. 14. Fortran keywords (i.e. CALL, DO, IF, READ, RETURN, etc.) may not be used as identifiers. 15. Embedded blanks may not appear in Fortran keywords, line numbers, variable names, comparison operators and logical operators. Exceptions: DOUBLE PRECISION, DOUBLE COMPLEX, ELSE IF, END DO, END IF, GO TO are permitted. 16. Fortran keywords must be followed by a blank or an operator. Also, a blank must follow the line number in a DO statement. 17. If an integer constant is followed by a comparison or logical operator, the constant and the operator must be separated by a blank (i.e. 12340 .LE. X). 18. Input code must be in the standard 72 column format. Comments up to 80 characters long are correctly copied to the output file. 19. Tab characters are not allowed. Convert these to blanks with a text editor. 30   On the other hand, this program will correctly process code with the following features, which do not comply with the Fortran-77 standard, provided the user's Fortran compiler also supports such constructs: 1. Both upper and lower case alphabetics may be used in identifiers and Fortran keywords. 2. Long variable names (up to 16 characters long) are permitted. 3. Character strings may be delimited with pairs of quotation marks [""] instead of apostrophes [']. 4. The double complex (DC) datatype is supported, including DC intrinsics. 5. The IMPLICIT NONE statement is supported. Untyped variables found in executable MP statements will be flagged as errors. 6. The datatypes INTEGER*4, REAL*8, etc. are supported. REAL*8 is interpreted as DP; COMPLEX*16 is interpreted as DC. 7. .T. and .F. may be used in place of the logical constants .TRUE. and .FALSE.. 8. DO-ENDDO constructs are permitted. 9. Recursive subroutine calls are permitted. 3.12 Error Checking More than 100 error conditions are checked by the translator program, and if any of these is encountered, an error message is output, together with the line number of the statement in the input file where the error was detected. An attempt has been made to cover all of the prohibited situations mentioned in this paper, as well as many violations of the standard rules of Fortran. In some cases, certain possible Fortran errors are not checked by the translator, because if they do occur, they will certainly be trapped when an attempt is made to compile the output program. One example of an error condition that is checked by the translator is any type mismatch between the argument list of a reference to a subroutine or function and its definition (provided both are in the same file). Such errors can easily occur when, for example, a DP constant is used as an argument, but the defining subprogram expects a MPR value. These errors can also occur if the name of an MPR function is not declared to be of type MPR in the subprograms where it is referenced. Although this is certainly not a recommended programming practice, type mismatches between argument lists do exist in some working Fortran programs. For example, some codes pass a scratch array of type real to a subroutine when a complex scratch array is expected. Because in some cases it may be difficult to remove type mismatches from an 31   existing code, and since the resulting code may work correctly anyway, a provision has been made for the translator to toggle type error trapping on and off. This is done by inserting one of the following directives in the declaration section of any subprogram: CMP+ TYPE ERROR ON CMP+ TYPE ERROR OFF  It remains in effect until the end of file or until another such directive is encountered. When type error trapping is disabled with the OFF option, a non-fatal warning message is included in the output file for the programmer's information. 3.13 Performance of Translated Co de A number of fairly large programs have been successfully translated with this program. These include the Linpack benchmark [18], both a real and a complex FFT benchmark [2], a vortex analysis code [24], a Feigenbaum number calculation [13], implementations of Ferguson's PSOS and PSLQ integer relation algorithms [5, 20], and an implementation of the RSA public-key cryptosystem [27]. All appear to work correctly. In most cases where the author had previously coded the application by hand using the MPFUN routines, the performance of the translated code (using the FAST option) is not significantly different. Thus it appears that in most cases there will not be a performance penalty for using the translator. Partly this is due to the fact that in translating arithmetic expressions, the translator program separately handles each of the many mixed mode cases, as opposed to merely handling all cases in a stock fashion. However, users should be prepared for a substantial slowdown, compared with conventional IN, SP or DP code. See the performance results in section 2.6 for details. Acknowledgments The author wishes to acknowledge helpful comments and suggestions by W. Kahan of the University of California, Berkeley, by K. Briggs of the University of Melbourne, Australia, and by R. Brent of the Australian National University.  32   References [1] D. H. Bailey, ""The Computation of  to 29,360,000 Decimal Digits Using Borweins' Quartically Convergent Algorithm"", Mathematics of Computation, vol. 50 (Jan. 1988), p. 283  296. [2] D. H. Bailey, ""A High Performance FFT Algorithm for Vector Supercomputers"", International Journal of Supercomputer Applications, vol. 2 (Spring 1988), p. 82 87. [3] D. H. Bailey, ""Numerical Results on the Transcendence of Constants Involving  , e, and Euler's Constant"", Mathematics of Computation, vol. 50 (Jan. 1988), p. 275  281. [4] D. H. Bailey, ""A Portable High Performance Multiprecision Package"", Technical Report RNR-90-022, NASA Ames Research Center, 1990. [5] D. H. Bailey and H. R. P. Ferguson, ""Numerical Results on Relations Between Numerical Constants Using a New Algorithm"", Mathematics of Computation, vol. 53 (October 1989), p. 649 - 656. [6] P. Beckmann, A History of Pi, Golem Press, Boulder CO, 1977. [7] J. M. Borwein and P. B. Borwein, ""The Arithmetic-Geometric Mean and Fast Computation of Elementary Functions"", SIAM Review vol. 26 (1984), p. 351  365. [8] J. M. Borwein and P. B. Borwein, Pi and the AGM, John Wiley, New York, 1987. [9] J. M. Borwein, P. B. Borwein and D. H. Bailey, ""Ramanujan, Modular Equations, and Approximations to Pi"", The American Mathematical Monthly, vol. 96 (1989), p. 201  219. [10] R. P. Brent, ""Fast Multiple-Precision Evaluation of Elementary Functions"", Journal of the ACM, vol. 23 (1976), p. 242  251. [11] R. P. Brent, ""A Fortran Multiple Precision Arithmetic Package"", ACM Transactions on Mathematical Software, vol. 4 (1978), p. 57  70. [12] R. P. Brent, ""Multiple-Precision Zero-Finding Methods and the Complexity of Elementary Function Evaluation"", Analytic Computational Complexity, Academic Press, New York, 1976, p. 151  176. [13] K. Briggs, ""A Precise Calculation of the Feigenbaum Constants"", Mathematics of Computation, vol. 57 (1991), p. 435 - 439. [14] D. Buell, and R. Ward, ""A Multiprecise Integer Arithmetic Package"", Journal of Supercomputing, vol. 3 (1989), p. 89  107. 33   [15] D. V. Chudnovsky and G. V. Chudnovsky, ""Computation and Arithmetic Nature of Classical Constants"", IBM Research Report, IBM T. J. Watson Research Center, RC14950 (#66818), 1989. [16] D. V. Chudnovsky and G. V. Chudnovsky, personal communication, 1991. [17] P. G. Comba, ""Exponentiation Cryptosystems on the IBM PC"", IBM Systems Journal, vol. 29 (1990), p. 526  538. [18] J. J. Dongarra, ""The Linpack Benchmark: An Explanation"", SuperComputing (Spring 1988), p. 10 - 14. [19] M. J. Feigenbaum, ""Quantitative Universality for a Class of Nonlinear Transformations"", Journal of Statistical Physics, vol. 19 (1978), p. 25  52. [20] H. R. P. Ferguson and D. H. Bailey, ""A Polynomial Time, Numerically Stable Integer Relation Algorithm"", Technical Report RNR-91-032, NAS Applied Research Branch, NASA Ames Research Center, Moffett Field, CA 94035, March 1992. [21] J. Hastad, B. Just, J. C. Lagarias, and C. Schnorr, ""Polynomial Time Algorithms for Finding Integer Relations Among Real Numbers"", SIAM Journal on Computing, vol. 18 (1988), p. 859  881. [22] Y. Kanada, personal communication, 1989. [23] D. E. Knuth, The Art of Computer Programming, Addison Wesley, Menlo Park, 1981. [24] R. Krasny, ""Desingularization of Periodic Vortex Sheet Roll-Up"", Journal of Computational Physics, vol. 65, no. 2 (August 1986), p. 292 - 313. [25] A. K. Lenstra, H. W. Lenstra, M. S. Manasse and J. M. Pollard, ""The Number Field Sieve"", 1990 ACM Symposium on the Theory of Computing, p. 564  572. [26] A. M. Odlyzko and H. J. J. te Riele, ""Disproof of the Mertens Conjecture"", J. Reine Angew. Mathematik, vol. 357 (1985), p. 138  160. [27] R. L. Rivest, A. Shamir, and L. Adleman, ""A Method for Obtaining Digital Signatures and Public-Key Cryptosystems"", Communications of the ACM, vol. 21 (1978), p. 120 - 126. [28] E. Salamin, ""Computation of  Using Arithmetic-Geometric Mean"", Mathematics of Computation, vol. 30 (1976), p. 565  570. [29] D. Slowinski, personal communication, 1991. [30] D. M. Smith, ""A FORTRAN Package for Floating-Point Multiple-Precision Arithmetic"", ACM Transactions on Mathematical Software, vol. 17, no. 2 (June 1991), p. 273  283. 34   [31] R. S. Varga, Scientific Computation on Mathematical Problems and Conjectures, SIAM, Philadelphia, 1990. [32] S. Wolfram, Mathematica: A System for Doing Mathematics by Computer, AddisonWesley, New York, 1988.  35"
GX241-48-1482350	"A Compendium of BBP-Type Formulas for Mathematical Constants David H. Bailey1 28 November 2000  Abstract A 1996 paper by the author, Peter Borwein and Simon Plouffe showed that any mathematical constant given by an infinite series of a certain type has the property that its n-th digit in a particular number base could be calculated directly, without needing to compute any of the first n - 1 digits, by means of a simple algorithm that does not require multiple-precision arithmetic. Several such formulas were presented in that paper, including formulas for the constants  and log 2. Since then, numerous other formulas of this type have been found. This paper presents a compendium of currently known results of this sort, both formal and experimental. Many of these results were found in the process of compiling this collection and have not previously appeared in the literature. Several conjectures suggested by these results are mentioned.  Lawrence Berkeley National Laboratory, Berkeley, CA 94720, USA, dhbailey@lbl.gov. Bailey's work is supported by the Director, Office of Computational and Technology Research, Division of Mathematical, Information, and Computational Sciences of the U.S. Department of Energy, under contract number DE-AC03-76SF00098.  1  1   1. Intro duction This is a collection of formulas for various mathematical constants that are of the form similar to that first noted in the ""BBP"" paper [3]. That article presented the following formula for  (which was discovered using Ferguson's PSLQ integer relation finding algorithm [10, 4]): =  k=0  1 16k  4 2 1 1 - - - 8k +1 8k +4 8k +5 8k +6  (1)  It was shown in [3] that this formula permits one to calculate the n-th hexadecimal or binary digit of  , without computing any of the first n - 1 digits, by means of a simple algorithm that does not require multiple-precision arithmetic. Further, as shown in [3], several other well-known constants also have this individual digit-computation property. One of these is log 2, based on the following centuries-old formula:   log 2 = k=1  1 k 2k  (2)  In general, any constant C that can be written in the form C=  k=0  p(k ) , q (k )bk  where p and q are integer polynomials, deg(p) < deg(q ), and p(k )/q (k ) is nonsingular for nonnegative k , possesses this individual digit-computation property. Note that formula 1 can be written in this form, since the four fractions can be combined into one, yielding =  k=0  1 47 + 151k + 120k 2 16k 15 + 194k + 712k 2 + 1024k 3 + 512k  4  Since the publication of [3], other papers have presented formulas of this type for various constants, including several constants that arise in quantum field theory [7, 8, 5]. More recently, interest in BBP-type formulas has been heightened by the observation that the question of the statistical randomness of the digit expansions of these constants can be reduced to the following hypothesis regarding the behavior of a particular class of chaotic iterations [5]: Hyp othesis A (from the paper [5]). Denote by rn = p(n)/q (n) a rational-polynomial function, i.e. p, q  Z [X ]. Assume further that 0  deg p < deg q , with rn nonsingular for positive integers n. Choose an integer b  2 and initialize x0 = 0. Then the sequence x = (x0 ,x1 ,x2 ,...) determined by the iteration: x n  = (bx  n-1  + rn ) mod 1.  either has a finite attractor or is equidistributed in [0, 1). Assuming this hypothesis, it is shown in [5] that any BBP-type constant is either normal to base b (i.e., any n-long string digits appears in the base b expansion with 2   limiting frequency b-n ), or else it is rational. No proof of Hypothesis A was presented in [5], and indeed it is likely that Hypothesis A is rather difficult to prove. However, it should be emphasized that even particular instances of Hypothesis A, if established, would have interesting consequences. For example, if it could be established that the specific iteration given by x0 = 0, and x n  = (2x  n-1  +  1 ) mo d 1 n  is equidistributed in [0, 1), then it would follow that log 2 is normal to base 2. In a similar vein, if it could be established that the iteration given by x0 = 0 and x n  =  16x  n-1  +  120n2 - 89n +16 512n4 - 1024n3 + 712n2 - 206n +21  mod 1  is equidistributed in [0, 1), then it would follow that  is normal to base 16 (and thus to base 2 also). One additional impetus for the study of BPP-type constants comes from a recent paper by Lagarias [13], who demonstrates a connection to G-functions and to a conjecture of Furstenberg from ergodic theory. Lagarias' analysis suggests that there may be a special signficance to constants that have BBP-type formulas in two or more bases -- say both a base 2 and a base 3 formula. This paper is a compendium of the growing set of BBP-type formulas that have been found by various researchers. Part of these formulas are collected here from previously published sources. In other cases, formulas whose existence has been demonstrated in the literature are presented here explicitly for the first time. Still others are new, having been found using the author's PSLQ program [4] in the course of this research. The PSLQ integer relation algorithm [10] or one of its variants [4] can be used to find formulas such as those listed in this paper as follows. Suppose, for example, that it is conjectured that a given constant  satisfies a BBP-type formula of the form 1 = r  k=0  1 bk  a2 an a1 + +  + , s s (kn +1) (kn +2) (kn + n)s  where r and ak are unknown integers, for a specified selection of the parameters b, s and n. Then one calculates the vector ( k0 1/(bk (kn + j )s ), 1  j  n), as well as  itself, to very high precision and then gives this (n + 1)-long vector (including  at the end) to an integer relation finding program. If a solution vector (aj ) is found with sufficiently high numerical fidelity, then = -1 an+1  k=0  1 bk  a1 a2 an + +  + s s (kn +1) (kn +2) (kn + n)s  (at least to the level of numeric precision used). This compendium is not intended to be a comprehensive listing of all such formulas -- ordinarily a formula is not listed here if 3   1. it is a telescoping sum. 2. it is a formal rewriting of another formula on the list. 3. it can be derived by a straightforward formal manipulation starting with another formula in the list. 4. it is a linear combination of two or more formulas already in the list. Item 1 refers to a summation such as S=  k=1  1 bk  1 b2 , - k k +2  which, if split into two summations, has the property that the terms of the first series cancel with offset terms of the second series, so that S reduces to a rational number (in this example, S = b + 1/2). Item 2 refers to the fact that a formula with base b and length n can be rewritten as a formula with base br and length rn. Item 4 refers to the fact that the rational linear sum of two BBP series can, in many cases, be written as a single BBP series. This is clear if the two individual series have the same base b. If one has base br and the other has base bs , their sum can be written as a single BBP series with base blcm(r,s) [5]. Along this line, many of the formulas listed below possess variants that can be obtained by adding to the listed formula a rational multiple of one of the zero relations listed in Section 11. The formulas are listed below using a notation introduced in [5]: P (s, b, n, A) =  k=0  1 bk  n j =1  aj (kn + j )s  (3)  where s, b and n are integers, and A = (a1 , a2 ,  , an ) is a vector of integers. For instance, using this notation we can write formulas 1 and 2 more compactly as follows:  = P (1, 16, 8, (4, 0, 0, -2, -1, -1, 0, 0)) 1 P (1, 2, 1, (1)) log 2 = 2 (4) (5)  In most cases below, the representation shown using this notation is a translation from the original source. Also, in some cases the formula listed here is not precisely the one mentioned in the cited reference -- an equivalent one is listed here instead -- but the original discoverer is given due credit. In cases where the formula has been found experimentally (i.e., by using the PSLQ integer relation finding algorithm), and no formal proof . is available, the relation is listed here with the = notation instead of an equal sign. The P notation formulas listed below have been checked using a computer program A that parses the L TEXsource of this document, then computes the left-hand and right-hand sides of these formulas to 2000 decimal digit accuracy. Additional contributions to this compendium are welcome -- please send a note to the author at dhbailey@lbl.gov. 4   2. Logarithm Formulas Clearly log n can be written with a binary BBP formula (i.e. a formula with b for some integer m) provided n factors completely using primes whose logarithms binary BBP formulas -- one merely combines the individual series for the different p into a single binary BBP formula. We have seen above that log 2 possesses a binary formula, and so does the log 3, by the following reasoning: log 3 = 2 log 2 + log 1 - = = k=0  = 2m have rimes BBP  1 4    =2 k=1  1 - k 2k  k=0   k=1  1 k 4k 2 2k +2 (6)  1 2    k=0   1 4k  1 1 2 - + 2k +1 2k +2 4 1 2k +1  1 4k  1 4k  = P (1, 4, 2, (1, 0))  In a similar manner, one can show, by examining the factorization of 2n +1 and 2n - 1, where n is an integer, that numerous other primes have this property. Harley [11] further extended this list of primes by writing Re log 1  1+ i 2n = 1 1 - n log 2 + log(22n-1  2n +1), 2 2  where Re denotes the real part. He noted that the Taylor series of the left-hand side can be written as a binary BBP-type formula and then applied Aurefeuille's factorization formula 24n-2 +1 = (22n-1 +2n + 1)(22n-1 - 2n +1) to the right-hand side. More recently, Jonathan Borwein has observed that both of these sets of results can be derived by working with the single expression Re log 1  (1 + i)k 2n .  A preliminary list of primes p such that log p has a binary BBP formula was given in [3]. This list has now been augmented by the author to the following: 2, 3, 5, 7, 11, 13, 17, 19, 29, 31, 37, 41, 43, 61, 73, 109, 113, 127, 151, 241, 257, 337, 397, 683, 1321, 1613, 2113, 2731, 5419, 8191, 43691, 61681, 87211, 131071, 174763, 262657, 524287, 2796203, 15790321, 18837001, 22366891, 4278255361, 4562284561, 2932031007403, 4363953127297, 4432676798593 (7) This list is certainly not complete, and it is unknown whether or not all primes have this property, or even whether the list of such primes is finite or infinite. The actual  5   formulas for log p for the primes above are generally straightforward to derive and are not shown here. One can also obtain BBP formulas in non-binary bases for the logarithms of certain integers and rational numbers. One example is given by the base ten formula 46 below, which was used in [3] to compute the ten billionth decimal digit of log(9/10). 3. Arctangent Formulas Shortly after the original BBP paper appeared in 1996, Adamchik and Wagon observed that [1] tan-1 2 = 1 P (1, 16, 8, (8, 0, 4, 0, -2, 0, -1, 0)) 8 (8)  More recently, binary BBP formulas have been found for tan-1 q for a large set of rational numbers q . These experimental results, which were obtained by the author using the PSLQ program, coincide exactly in the cases studied so far with the set of rationals given by q = |Im(T )/Re(T )| or |Re(T )/Im(T )|, where T= m k=1  1  (1 + i)u 2vk  k  w  k  .  (9)  The arctangents of these q clearly possess binary BBP formulas, because Im(log T ) decomposes into a linear sum of terms, the Taylor series of which are binary BBP formulas. The author is indebited to Jonathan Borwein for this observation. See also [6, pg. 344]. Alternatively, one can write 9 as T= m k=1  i 1 t 2k  u  k  1+ i 1 v 2k  w  k  (10)  for various m-long nonnegative integer vectors t, u, v , w and choices of signs as shown. For example, setting t = (1, 1), u = (1, 1), v = (1, 3), w = (1, 1), with signs (1, -1, -1, 1), gives the result T = 25/32 - 5i/8, which yields q = 4/5. Indeed one can obtain the formula tan- 1  4 5  =  1 P (1, 220 , 40, (0, 219 , 0, -3  217 , -15  215 , 0, 0, 5  215 , 0, 215 , 0, 217 -3  213 , 0, 0, 5  210 , 5  211 , 0, 211 , 0, 210 , 0, 0, 0, 5  27 , 15  25 , 128, 0, -96, 0, 0, 0, 40, 0, 8, -5, -6, 0, 0, 0, 0)) (11)  In this manner, it can be seen that binary BBP formulas exist for the arctangents of the following rational numbers. Only those rationals with numerators < denominators  50 are listed here. 1/2, 1/3, 2/3, 1/4, 3/4, 1/5, 2/5, 3/5, 4/5, 1/7, 3/7, 4/7, 6/7, 1/8, 7/8, 1/9, 2/9, 7/9, 8/9, 3/10, 2/11, 3/11, 7/11, 8/11, 10/11, 1/12, 5/12, 1/13, 6/13, 7/13, 9/13, 11/13, 3/14, 5/14, 1/15, 4/15, 8/15, 1/16, 11/16, 13/16, 15/16, 1/17, 6/17, 7/17, 11/17, 15/17, 6   16/17, 1/18, 13/18, 4/19, 6/19, 7/19, 8/19, 9/19, 11/19, 17/19, 1/21, 16/21, 3/22, 7/22, 9/22, 19/22, 2/23, 4/23, 6/23, 7/23, 11/23, 14/23, 15/23, 7/24, 11/24, 23/24, 13/25, 19/25, 21/25, 7/26, 23/26, 5/27, 11/27, 2/29, 3/29, 15/29, 17/29, 24/29, 28/29, 17/30, 1/31, 5/31, 8/31, 12/31, 13/31, 17/31, 18/31, 22/31, 27/31, 1/32, 9/32, 31/32, 1/33, 4/33, 10/33, 14/33, 19/33, 31/33, 32/33, 7/34, 27/34, 13/35, 25/36, 5/37, 9/37, 10/37, 16/37, 29/37, 36/37, 1/38, 5/38, 13/38, 21/38, 20/39, 23/39, 37/39, 9/40, 3/41, 23/41, 27/41, 28/41, 38/41, 11/42, 19/42, 37/42, 6/43, 19/43, 23/43, 32/43, 33/43, 7/44, 23/44, 27/44, 3/46, 9/46, 17/46, 35/46, 37/46, 1/47, 13/47, 14/47, 16/47, 19/47, 27/47, 19/48, 3/49, 8/49, 13/49, 18/49, 31/49, 37/49, 43/49, 29/50, 49/50  (12)  Note that not all ""small"" rationals appear in this list. For instance, it is not known whether tan-1 (1/6) possesses a binary BBP formula. For that matter, it has not been proven that formulas 9 and 10 above generate all such rational numbers, although this is a reasonable conjecture. One can obtain BBP formulas in non-binary bases for the arctangents of certain rational numbers by employing appropriate variants of formulas 9 and 10. 4. Other Degree 1 Binary Formulas We present here some additional degree 1 binary BBP-type formulas (in other words, in the P notation defined in equation 3 above, s = 1, and b = 2m for some integer m > 0). =   2  3   2ln(1 + 2)  2tan- 1  = = = = =  1  2  1 P (1, 16, 8, (8, 8, 4, 0, -2, -2, -1, 0)) 4 P (1, -4, 4, (2, 2, 1, 0)) 1 P (1, 64, 12, (32, 0, 8, 0, 8, 0, -4, 0, -1, 0, -1, 0)) 8 9 P (1, 64, 6, (16, 8, 0, -2, -1, 0)) 32 1 P (1, 16, 8, (8, 0, 4, 0, 2, 0, 1, 0)) 8 1 P (1, 16, 8, (8, 0, -4, 0, 2, 0, -1, 0)) 8  (13) (14) (15) (16) (17) (18)  Formula 13 was first found by Ferguson [10], while 14, which is the alternating sign equivalent of 13, was found independently by Hales and by Adamchik and Wagon [1]. Technically speaking, these formulas can be obtained from the original BBP formula for  (formula 1) by adding 1/4 times relation 52 of Section 11, but they are included here for historical interest, since their discovery predated the discovery of relation 52. Formula 15 appeared in [3]. Formulas 16, 17 and 18 are due to Knuth [12, pg. 628]. 7   5. Degree 2 Binary Formulas Here are some degree 2 binary formulas (i.e., s = 2, and b = 2m for some integer m > 0). The constant G here is Catalan's constant, namely G = 1 - 1/32 +1/52 - 1/72 +  = 0.9159655941 ....   2 2  log2 2 log2 2 1 G -  log 2 8  log 2    3log 2  G  = P (2, 16, 8, (16, -16, -8, -16, -4, -4, 2, 0)) 9 = P (2, 64, 6, (16, -24, -8, -6, 1, 0)) 8 .1 = P (2, 16, 8, (16, -40, -8, -28, -4, -10, 2, -3)) 6 1 = P (2, 64, 6, (64, -160, -56, -40, 4, -1)) 32 1 = P (2, 16, 8, (8, 8, 4, 0, -2, -2, -1, 0)) 16 1 . P (2, 212 , 24, (212 , -213 , -51  29 , 15  210 , -210 , 39  28 , 0, = 256 45  28 , 37  26 , -29 , 0, 3  28 , -64, 0, 51  23 , 45  24 , 16, 196, 0, 60, -37, 0, 0, 0)) 1 P (2, 212 , 24, (9  29 , -27  29 , -9  211 , 27  29 , 0, 81  27 , = 128 9  26 , 45  28 , 9  28 , 0, 0, 9  26 , -72, -216, 9  25 , 9  26 , 0, 162, -9, 72, -36, 0, 0, 0, )) 1 . = 10 P (2, 212 , 24, (210 , 210 , -29 , -3  210 , -256, -211 , -256, 2 -9  27 , -5  26 , 64, 64, 0, -16, 64, 8, -72, 4, -8, 4, -12, 5, 4, -1, 0))  (19) (20) (21) (22) (23)  (24)  (25)  (26)  Formulas 19, 20, 22 and 23 were presented in [3] (although 23 appeared in a 1909 book by Nielsen [14, pg. 105]). Formulas 21 and 25 were found by the author, using the PSLQ program. Formulas for  log 2 and G were first derived by Broadhurst, although the specific explicit formulas given here (24 and 26) were found by the author in the course of this research. 6. Degree 3 Binary Formulas 1 P (3, 212 , 24, (3  211 , -21  211 , 3  213 , 15  211 , -3  29 , 3  210 , 7  28 3  28 , 0, -3  210 , -21  27 , -192, -3  29 , -96, -21  25 , -3  27 , 0, 24, 48, -12, 120, 48, -42, 3, 0)) (27) 1 . P (3, 212 , 24, (0, 3  213 , -27  212 , 3  214 , 0, 93  29 , 0, 3  214 , 27  29 , log3 2 = 256 3  29 , 0, 75  26 , 0, 3  27 , 27  26 , 3  210 , 0, 93  23 , 0, 192, -216, 24, 0, 3)) (28)  (3) = 8   1 P (3, 212 , 24, (0, 9  211 , -135  29 , 9  211 , 0, 99  28 , 0, 27  210 , 135  26 , 32 9  27 , 0, 45  26 , 0, 9  25 , 135  23 , 27  26 , 0, 396, 0, 72, -135, 18, 0, 0)) (29) 1 .  log2 2 = 56 P (3, 260 , 120, (7  259 , -37  260 , -63  258 , 85  259 , 3861  256 , 2 -3357  255 , 0, -655  258 , 347  254 , 79  253 , 0, 4703  252 , -7  253 , 0, -1687  252 , -655  254 , 7  251 , -4067  249 , 0, -6695  248 , -347  248 , 0, 0, -7375  246 , -3861  246 , -37  248 , -63  246 , 85  247 , -7  245 , -933  245 , 0, -655  246 , 347  242 , -37  244 , 875  243 , 4703  240 , -7  241 , 0, 63  240 , -3105  238 , 7  239 , -4067  237 , 0, 85  239 , 441  239 , 0, 0, -7375  234 , 7  235 , 79  233 , -63  234 , 85  235 , -7  233 , -3357  231 , -875  233 , -655  234 , 347  230 , -37  232 , 0, -167  232 , -7  229 , 0, 63  228 , -655  230 , -3861  226 , -4067  225 , 0, 85  227 , -347  224 , -375  223 , 0, -7375  222 , 7  223 , -37  224 , 1687  222 , 85  223 , -7  221 , -3357  219 , 0, -3105  218 , 347  218 , -37  220 , 0, 4703  216 , 3861  216 , 0, 63  216 , -655  218 , 7  215 , -923  215 , 0, 85  215 , -347  212 , 0, -875  213 , -7375  210 , 7  211 , -37  212 , -63  210 , -6695  28 , -7  29 , -3357  27 , 0, -655  210 , -441  29 , -37  28 , 0, 4703  24 , -224, -375  23 , 63  24 , -655  26 , 56, -8134, 875  23 , 85  23 , -347, 0, 0, 0)) (30) 1 .  3 = 54 P (3, 260 , 120, (5  259 , -15  260 , -225  258 , 95  259 , 4115  256 , 2 -3735  255 , 0, -685  258 , 505  254 , 5  253 , 0, 5485  252 , -5  253 , 0, -1775  252 , -685  254 , 5  251 , -3945  249 , 0, -7365  248 , -505  248 , 0, 0, -8125  246 , -4115  246 , -15  248 , -225  246 , 95  247 , -5  245 , -965  245 , 0, -685  246 , 505  242 , -15  244 , 125  246 , 5485  240 , -5  241 , 0, 225  240 , -2835  238 , 5  239 , -3945  237 , 0, 95  239 , 905  238 , 0, 0, -8125  234 , 5  235 , 5  233 , -225  234 , 95  235 , -5  233 , -3735  231 , -125  236 , -685  234 , 505  230 , -15  232 , 0, -165  232 , -5  229 , 0, 225  228 , -685  230 , -4115  226 , -3945  225 , 0, 95  227 , -505  224 , -125  223 , 0, -8125  222 , 5  223 , -15  224 , 1775  222 , 95  223 , -5  221 , -3735  219 , 0, -2835  218 , 505  218 , -15  220 , 0, 5485  216 , 4115  216 , 0, 225  216 , -685  218 , 5  215 , -955  215 , 0, 95  215 , -505  212 , 0, -125  216 , -8125  210 , 5  211 , -15  212 , -225  210 , -7365  28 , -5  29 , -3735  27 , 0, -685  210 , -905  28 , -15  28 , 0, 5485  24 , -160, -125  23 , 225  24 , -685  26 , 40, -7890, 125  26 , 95  23 , -505, 0, 0, 0)) (31) 9  .  2 log 2 =   The existence of BBP formulas for these constants was originally established by Broadhurst [8]. However, except for 27, which appeared in [5], the specific explicit formulas listed here were produced by the author's PSLQ program. The results for  log2 and  3 were produced by a special parallel version of this program, running on the IBM SP parallel computer system in the NERSC supercomputer facility at the Lawrence Berkeley National Laboratory. 7. Degree 4 Binary Formulas 1 P (4, 212 , 24, (27  211 , -513  211 , 135  214 , -27  211 , -27  29 , 164 -621  210 , 27  28 , -729  210 , -135  211 , -513  27 , -27  26 , -189  29 , -27  25 , -513  25 , -135  28 , -729  26 , 216, -621  24 , -108, -216, 135  25 , -1026, 27, 0)) (32) 1 . log4 2 = P (4, 212 , 24, (73  212 , -2617  212 , 8455  212 , -2533  212 , 5 205  2 -73  210 , -25781  29 , 73  29 , -6891  211 , -8455  29 , -2617  28 , -73  27 , -23551  26 , -73  26 , -2617  26 , -8455  26 , -6891  27 , 73  24 , -25781  23 , -73  23 , -2533  24 , 8455  23 , -10468, 146, -615)) (33) 1 . P (4, 212 , 24, (121  211 , -3775  211 , 10375  211 , -1597  211 ,  2 log2 2 = 41  25 -121  29 , -3421  211 , 121  28 , -7695  210 , -10375  28 , -3775  27 , -121  26 , -3539  28 , -121  25 , -3775  25 , -10375  25 , -7695  26 , (34) 121  23 , -3421  25 , -484, -1597  23 , 41500, -7550, 121, 0))  4  . =  The existence of BBP-type formulas for these constants was originally established by Broadhurst [8], although the explicit formulas given here were found by the author's PSLQ program. 8. Degree 5 Binary Formulas .  (5) = 1 P (5, 260 , 120, (279  259 , -7263  260 , 293715  257 , 62651  249 -13977  260 , -1153683  256 , 28377  260 , 279  256 , 83871  259 , -293715  254 , -7263  256 , -279  254 , -889173  253 , -279  253 , -7263  254 , 429705  252 , 83871  255 , 279  251 , 28377  254 , -279  250 , 1041309  249 , 293715  248 , -7263  250 , 279  248 , 1153125  247 , 1153683  246 , -7263  248 , 293715  245 , -13977  248 , -279  245 , 28377  248 , 279  244 , 83871  247 , -293715  242 , -7263  244 , -1153683  241 , -889173  241 , -279  241 , -7263  242 , -293715  239 , 188811  239 , 279  239 , 28377  242 , -279  238 , 10   -13977  240 , -429705  237 , -7263  238 , 279  236 , 1153125  235 , 279  235 , -7263  236 , 293715  233 , -13977  236 , -279  233 , 28377  236 , 1153683  231 , 83871  235 , -293715  230 , -7263  232 , -279  230 , 16497  233 , -279  229 , -7263  230 , -293715  227 , 83871  231 , 1153683  226 , 28377  230 , -279  226 , -13977  228 , 293715  224 , -7263  226 , 279  224 , 1153125  223 , 279  223 , -7263  224 , -429705  222 , -13977  224 , -279  221 , 28377  224 , 279  220 , 188811  219 , -293715  218 , -7263  220 , -279  218 , -889173  217 , -1153683  216 , -7263  218 , -293715  215 , 83871  219 , 279  215 , 28377  218 , -279  214 , -13977  216 , 293715  212 , -7263  214 , 1153683  211 , 1153125  211 , 279  211 , -7263  212 , 293715  29 , 1041309  29 , -279  29 , 28377  212 , 279  28 , 83871  211 , 429705  27 , -7263  28 , -279  26 , -889173  25 , -279  25 , -7263  26 , -293715  23 , 83871  27 , 279  23 , (35) 28377  26 , -2307366, -13977  24 , 293715, -29052, 279, 0)) 1 . P (5, 260 , 120, (2783  259 , -32699  262 , 7171925  257 , log5 2 = 2021  252 -187547  261 , -41252441  256 , 9391097  257 , 2783  256 , 52183  265 , -7171925  254 , -32699  258 , -2783  254 , -29483621  253 , -2783  253 , -32699  256 , 17037475  252 , 52183  261 , 2783  251 , 9391097  251 , -2783  250 , 38246123  249 , 7171925  248 , -32699  252 , 2783  248 , 41307505  247 , 41252441  246 , -32699  250 , 7171925  245 , -187547  249 , -2783  245 , 9391097  245 , 2783  244 , 52183  253 , -7171925  242 , -32699  246 , -41252441  241 , -29483621  241 , -2783  241 , -32699  244 , -7171925  239 , 12188517  239 , 2783  239 , 9391097  239 , -2783  238 , -187547  241 , -17037475  237 , -32699  240 , 2783  236 , 41307505  235 , 2783  235 , -32699  238 , 7171925  233 , -187547  237 , -2783  233 , 9391097  233 , 41252441  231 , 52183  241 , -7171925  230 , -32699  234 , -2783  230 , 5881627  230 , -2783  229 , -32699  232 , -7171925  227 , 52183  237 , 41252441  226 , 9391097  227 , -2783  226 , -187547  229 , 7171925  224 , -32699  228 , 2783  224 , 41307505  223 , 2783  223 , -32699  226 , -17037475  222 , -187547  225 , -2783  221 , 9391097  221 , 2783  220 , 11   12188517  219 , -7171925  218 , -32699  222 , -2783  218 , -29483621  217 , -41252441  216 , -32699  220 , -7171925  215 , 52183  225 , 2783  215 , 9391097  215 , -2783  214 , -187547  217 , 7171925  212 , -32699  216 , 41252441  211 , 41307505  211 , 2783  211 , -32699  214 , 7171925  29 , 38246123  29 , -2783  29 , 9391097  29 , 2783  28 , 52183  217 , 17037475  27 , -32699  210 , -2783  26 , -29483621  25 , -2783  25 , -32699  28 , -7171925  23 , 52183  213 , 2783  23 , 9391097  23 , -82504882, -187547  25 , 7171925, (36) -32699  24 , 2783, 30315)) 1 . P (5, 260 , 120, (21345  259 , -464511  261 , 47870835  257 ,  2 log3 2 = 2021  253 -1312971  261 , -236170815  256 , 1579179  262 , 21345  256 , 286131  265 , -47870835  254 , -464511  257 , -21345  254 , -173704605  253 , -21345  253 , -464511  255 , 94128645  252 , 286131  261 , 21345  251 , 1579179  256 , -21345  250 , 215120589  249 , 47870835  248 , -464511  251 , 21345  248 , 236128125  247 , 236170815  246 , -464511  249 , 47870835  245 , -1312971  249 , -21345  245 , 1579179  250 , 21345  244 , 286131  253 , -47870835  242 , -464511  245 , -236170815  241 , -173704605  241 , -21345  241 , -464511  243 , -47870835  239 , 56870019  239 , 21345  239 , 1579179  244 , -21345  238 , -1312971  241 , -94128645  237 , -464511  239 , 21345  236 , 236128125  235 , 21345  235 , -464511  237 , 47870835  233 , -1312971  237 , -21345  233 , 1579179  238 , 236170815  231 , 286131  241 , -47870835  230 , -464511  233 , -21345  230 , 1950735  234 , -21345  229 , -464511  231 , -47870835  227 , 286131  237 , 236170815  226 , 1579179  232 , -21345  226 , -1312971  229 , 47870835  224 , -464511  227 , 21345  224 , 236128125  223 , 21345  223 , -464511  225 , -94128645  222 , -1312971  225 , -21345  221 , 1579179  226 , 21345  220 , 56870019  219 , -47870835  218 , -464511  221 , -21345  218 , -173704605  217 , -236170815  216 , -464511  219 , -47870835  215 , 286131  225 , 21345  215 , 1579179  220 , -21345  214 , -1312971  217 , 47870835  212 , -464511  215 , 236170815  211 , 236128125  211 , 21345  211 , -464511  213 , 47870835  29 , 215120589  29 , -21345  29 , 1579179  214 , 21345  28 , 286131  217 , 94128645  27 , -464511  29 , 12   -21345  26 , -173704605  25 , -21345  25 , -464511  27 , -47870835  23 , 286131  213 , 21345  23 , 1579179  28 , -472341630, -1312971  25 , 47870835, -464511  23 , 21345, 0)) (37) 1 .  4 log 2 = P (5, 260 , 120, (5157  259 , -89127  261 , 7805295  257 , 50 2021  2 -195183  261 , -32325939  256 , 1621107  259 , 5157  256 , 37287  265 , -7805295  254 , -89127  257 , -5157  254 , -24620409  253 , -5157  253 , -89127  255 , 12255165  252 , 37287  261 , 5157  251 , 1621107  253 , -5157  250 , 29192697  249 , 7805295  248 , -89127  251 , 5157  248 , 32315625  247 , 32325939  246 , -89127  249 , 7805295  245 , -195183  249 , -5157  245 , 1621107  247 , 5157  244 , 37287  253 , -7805295  242 , -89127  245 , -32325939  241 , -24620409  241 , -5157  241 , -89127  243 , -7805295  239 , 5866263  239 , 5157  239 , 1621107  241 , -5157  238 , -195183  241 , -12255165  237 , -89127  239 , 5157  236 , 32315625  235 , 5157  235 , -89127  237 , 7805295  233 , -195183  237 , -5157  233 , 1621107  235 , 32325939  231 , 37287  241 , -7805295  230 , -89127  233 , -5157  230 , 480951  233 , -5157  229 , -89127  231 , -7805295  227 , 37287  237 , 32325939  226 , 1621107  229 , -5157  226 , -195183  229 , 7805295  224 , -89127  227 , 5157  224 , 32315625  223 , 5157  223 , -89127  225 , -12255165  222 , -195183  225 , -5157  221 , 1621107  223 , 5157  220 , 5866263  219 , -7805295  218 , -89127  221 , -5157  218 , -24620409  217 , -32325939  216 , -89127  219 , -7805295  215 , 37287  225 , 5157  215 , 1621107  217 , -5157  214 , -195183  217 , 7805295  212 , -89127  215 , 32325939  211 , 32315625  211 , 5157  211 , -89127  213 , 7805295  29 , 29192697  29 , -5157  29 , 1621107  211 , 5157  28 , 37287  217 , 12255165  27 , -89127  29 , -5157  26 , -24620409  25 , -5157  25 , -89127  27 , -7805295  23 , 37287  213 , 5157  23 , 1621107  25 , -64651878, -195183  25 , 7805295, -89127  23 , 5157, 0)) (38) As before, the existence of BBP-type formulas for these constants was originally established by Broadhurst [8], although the explicit formulas given here were found by the author's PSLQ program. 13   9. Ternary Formulas No ternary BBP formulas (i.e. formulas with b = 3m for some integer m > 0) were presented in [3], but several have subsequently been discovered. Here are some that are now known: 2 P (1, 9, 2, (1, 0)) (39) log 2 = 3   3 1 P (1, 9, 3, (3, -1, 0)) (40) 3tan-1 = 7 6  1 3= P (1, 36 , 12, (81, -54, 0, -9, 0, -12, -3, -2, 0, -1, 0, 0)) (41) 9 1 log 3 = (42) P (1, 36 , 6, (729, 81, 81, 9, 9, 1)) 729 2 2 = P (2, 36 , 12, (243, -405, 0, -81, -27, -72, -9, -9, 0, 27 -5, 1, 0)) (43) 1 P (2, 36 , 12, (4374, -13122, 0, -2106, -486, -243  23 , log2 3 = 729 -162, -234, 0, -162, 18, -8)) (44)  2 P (2, 36 , 12, (243, -405, -486, -135, 27, 0, -9, 15, 18,  3log 3 = 27 5, -1, 0)) (45) Formulas 39 and 40 appeared in [5]. Formulas 41 through 45 are due to Broadhurst [7]. 10. Other BBP-Typ e Formulas Here are several interesting results in other bases, together with two formulas for an  arbitrary base b. Here  = (1 + 5)/2 is the golden mean. log   25 781 log   2 256 1  tan-  1   51/4 233 - 329 5   5938   57 - 5 5  57 + 5 5    9 -1 P (1, 10, 1, (1)) = 10 10 5  (46) (47)     = P (1, 55 , 5, (0, 5, 1, 0, 0)) + =   tan- 1   51/4 939 + 281 5   5938  log  1111111111 387420489 b2 + b +1 b2 - 2b +1  1 P (1, 55 , 5, (125, -25, 5, -1, 0)) (48) 13/4 25 1 = P (1, 1010 , 10, (108 , 107 , 106 , 105 , 104 , 103 , 8 10 (49) 102 , 101 , 1, 0)) = 3P (1,b3 , 3, (b, 1, 0)) 14 (50)  b2 log   b  b-2  log  bb - 1 (b - 1)b  = P (1,bb ,b, (b  b- 2  ,b  b- 3  ,  ,b2 ,b, 1))  (51)  Formula 46 appeared in [3] (although it is an elementary observation). Formulas 47 through 51 appeared in [5]. 11. Zero Relations Below are some of the known BBP zero relations, or in other words BBP-type formulas that evaluate to zero. These have been discovered using the author's PSLQ program, and most are new with this compilation. For brevity, not all of the zero relations that have been found are listed here -- some of the larger ones are omitted -- although the author has a complete set. Further, zero relations that are merely a rewriting of another on the list, such as by expanding a relation with base b and length n to one with base br and length rn, are not included in these listings. For convenience, however, the total number of linearly independent zero relations for various choices of s, b and n, including rewritings and unlisted relations, are tabulated in Table 1. Knowledge of these zero relations is essential for finding formulas such as those above using integer relation programs (such as PSLQ). This is because unless these zero relations are excluded from the search for a conjectured BBP-type formula, the search may only recover a zero relation. A zero relation may be excluded from a integer relation search by setting the input vector element whose position corresponds to the zero relation's smallest nonzero element to some value that is not linearly related to the other entries of the input vector. For example, note in Table 1 below that there are five zero relations with s = 1, b = 212 and n = 24. These relations are given below as formulas 54 through 58. If one is searching for a conjectured formula with these parameters using PSLQ, then these five zero relations must be excluded. This can be done by setting entries 19 through 23 of the PSLQ input vector to e, e2 , e3 , e4 and e5 , respectively, where e is the base of natural logarithms. Positions 19 through 23 are specified here because in relations 54 through 58 below, the smallest nonzero entries appear in positions 23, 22, 21, 20 and 19, respectively. Powers of e are specified here because, as far as anyone can tell (although this has not been rigorously proven), e is not a polylogarithmic constant in the sense of this paper, and thus it and its powers are not expected to satisfy BBP-type linear relations (this assumption is confirmed by extensive experience using the author's PSLQ programs). In any event, it is clear that many other sets of transcendental constants could be used here. Note that by simply adding a rational multiple of one of these zero relations to one the formulas above (with matching arguments s, b and n), one can produce a valid variant of that formula. Clearly infinitely many variants can be produced in this manner. Aside from the discussion in [9], these zero relations are somewhat mysterious -- it is not understood why zero relations occur for certain s, b and n, but not others. It should also be noted that in most but not all cases where a zero relation has been found, nontrivial BBP-type formulas have been found with the same parameters. This suggests that significant BBP-type results may remain to be discovered. In any event, it is hoped that this compilation will spur some additional insight into these questions. 15   s 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  b 16 64 28 212 212 216 218 220 224 224 228 230 230 232 236 236 240 242 242 244 36  n 8 6 16 12 24 32 18 40 24 48 56 30 60 64 36 72 80 42 84 88 12  No. zero relations 1 1 1 1 5 1 1 3 1 5 1 1 1 1 1 5 3 1 1 1 2  s 1 1 1 1 1 1 1 2 2 2 2 2 2 2 3 3 3 3 3 4  248 248 252 254 256 260 260 212 220 224 236 240 248 260 212 224 236 248 260 260  b  n 48 96 104 54 112 60 120 24 40 48 72 80 96 120 24 48 72 96 120 120  No. zero relations 1 5 1 1 1 1 7 2 1 2 2 1 2 4 1 1 1 1 2 1  Table 1: Zero relation counts for various parameters  Note that all of these formulas except for the last two are binary formulas (i.e. b = 2m for some integer m > 0). 0 = P (1, 16, 8, (-8, 8, 4, 8, 2, 2, -1, 0)) (52) 0 = P (1, 64, 6, (16, -24, -8, -6, 1, 0)) (53) . 12 11 11 9 8 0 = P (1, 2 , 24, (0, 0, 2 , -2 , 0, -2 , 256, -3  2 , 0, 0, -64, -128, 0, -32, -32, -48, 0, -24, -4, -8, 0, -2, 1, 0)) (54) . 12 9 10 10 8 8 7 0 = P (1, 2 , 24, (-2 , -2 , 2 , 7  2 , 256, 3  2 , 64, 3  2 , 0, 0, 0, 0, 8, -32, -16, 12, -4, 4, -1, 8, 0, -1, 0, 0)) (55) . 12 9 10 9 7 0 = P (1, 2 , 24, (2 , -2 , -2 , 256, 0, 256, 64, 3  2 , 64, 0, 0, 0, -8, -16, 8, 12, 0, 4, -1, 2, -1, 0, 0, 0)) (56) . 12 9 10 7 0 = P (1, 2 , 24, (3  2 , -3  2 , 0, -256, 0, 0, 192, 3  2 , 0, 0, 0, -64, -24, -48, 0, -12, 0, 0, -3, 2, 0, 0, 0, 0)) (57) . 12 10 99 0 = P (1, 2 , 24, (-2 , 3  2 , 2 , 256, 128, 128, -64, -192, 0, 32, 0, 32, 16, 16, 16   -8, 0, -2, -2, 1, 0, 0, 0, 0, 0)) (58) . 20 18 18 17 16 16 15 16 14 13 0 = P (1, 2 , 40, (0, 2 , -2 , 2 , 0, -5  2 , 2 , -5  2 , 0, -2 , -2 , 2 , 0, -5  212 , -214 , -5  211 , 0, 210 , -210 , -211 , 0, -5  28 , 256, -5  27 , 0, 64, -64, 32, 0, 0, 16, -40, 0, 4, 16, 2, 0, -5, 1, 0)) (59) . 20 18 19 17 15 16 14 13 13 12 12 0 = P (1, 2 , 40, (2 , -2 , 0, -2 , 3  2 , 2 , 0, 0, 2 , 2 , 0, -2 , -2 , 2 , 5  210 , 0, 210 , -211 , 0, -29 , -256, 256, 0, 0, -96, -128, 0, -32, -16, -24, 0, 0, 4, -8, -5, -2, -1, 1, 0, 0)) (60) . 0 = P (1, 220 , 40, (-218 , 3  218 , 0, -218 , -13  215 , 0, 0, 5  215 , -214 , 213 , 0, -214 , 212 , 0, 5  210 , 5  211 , -210 , 3  210 , 0, 3  29 , 256, 0, 0, 5  27 , 13  25 , 192, 0, -64, 16, 40, 0, 40, -4, 12, -5, -4, 1, 0, 0, 0)) (61) . 0 = P (2, 212 , 24, (0, 210 , -3  210 , 29 , 0, 210 , 0, 9  27 , 3  27 , 64, 0, 128, 0, 16, 48, 72, 0, 16, 0, 2, -6, 1, 0, 0)) (62) . 12 11 11 10 9 10 8 0 = P (2, 2 , 24, (-2 , 0, 17  2 , -17  2 , 2 , -15  2 , -256, -63  2 , -17  28 , 0, 64, -5  28 , 32, 0, -17  25 , -63  24 , -8, -240, 4, -68, 68, 0, -1, 0)) (63) . 20 19 20 18 18 20 18 16 0 = P (2, 2 , 40, (2 , -3  2 , -2 , 13  2 , 3  2 , -3  2 , 2 , -25  216 , 215 , -3  216 , -214 , 13  214 , -213 , -3  214 , -3  215 , -25  212 , 211 , -3  212 , -210 , -3  212 , -29 , -3  210 , 256, -25  28 , -3  210 , -3  28 , -64, 13  26 , -32, -192, 16, -25  24 , 8, -48, 96, 52, -2, -12, 1, 0)) (64) . 0 = P (3, 212 , 24, (211 , -19  211 , 5  214 , -211 , -29 , -23  210 , 256, -27  210 , -5  211 , -19  27 , -64, -7  29 , -32, -19  25 , -5  28 , -27  26 , 8, -23  24 , -4, -8, 160, -38, 1, 0)) (65) . 0 = P (1, 729, 12, (0, 81, -162, 0, 27, 36, 0, 9, 6, 4, -1, 0)) (66) . 0 = P (1, 729, 12, (243, -324, -162, -81, 0, -36, -9, 0, 6, -1, 0, 0)) (67) Relation 52 appeared in [3]. Relation 53 and 54 were given in [5]. Relations 55 through 67 were found by the author using his PSLQ program, and are new with this compilation. 12. Curiosities There are two other formulas worth mentioning, although neither, technically speaking, is a BBP-type formula. The first formula employs the irrational base b = 2/ = 2 -2, where  is the golden mean (see Section 9):  1 3  = 9 P (1, 2/ , 10, (256, 128 3 , 64 4 , 32 4 , 0, -8 6 , -4 8 , -2 9 , 0)) (68) 5/4 5 2 The second example of this class is the formula 1  cos 19 -1  k=0  9 10  =  1 10  Dk 10k  1 k +1 17  (69)   where the D coefficients satisfy the recurrence D k  2. It is possible that a variant of the original case, on the idea that the Dk comprise a Lucas of sequence elements mod n can be effected via formulas appeared in [5].  0  = D1 = 1, and Dk+1 = Dk - 5Dk-1 for BBP algorithm can be fashioned for this sequence, and as is known, evaluations exponential-ladder methods. These two  13. Acknowledgements The author wishes to acknowledge some very helpful comments and suggestions from J. Borwein, P. Borwein, R. Crandall and S. Wagon.  18   References [1] Victor Adamchik and Stan Wagon, ""A Simple Formula for Pi,"" American Mathematical Monthly, Nov. 1997, pg. 852-855. [2] Victor Adamchik and Stan Wagon, ""Pi: A 2000-Year-Old Search Changes Direction,"" Mathematica in Science and Education, vol. 5 (1996), no. 1, pg. 11-19. [3] David H. Bailey, Peter B. Borwein and Simon Plouffe, ""On The Rapid Computation of Various Polylogarithmic Constants,"" Mathematics of Computation, vol. 66, no. 218, 1997, pp. 903913. [4] David H. Bailey and David J. Broadhurst, ""Parallel Integer Relation Detection: Techniques and Applications,"" Mathematics of Computation, to appear, 2000. [5] David H. Bailey and Richard E. Crandall, ""On the Random Character of Fundamental Constant Expansions,"" manuscript, Oct. 2000, available from http://www.nersc.gov/~dhbailey. [6] Jonathan M. Borwein and Peter B. Borwein, Pi and the AGM, John Wiley and Sons, New York, 1987. [7] David J. Broadhurst, ""Massive 3-loop Feynman Diagrams Reducible to SC Primitives of Algebras of the Sixth Root of Unity,"" preprint, Mar. 1998, available from http://xxx.lanl.gov/format/hep-ph/9803091. [8] David J. Broadhurst, ""Polylogarithmic Ladders, Hypergeometric Series and the Ten Millionth Digits of  (3) and  (5),"" preprint, March 1998, available from http://xxx.lanl.gov/format/math/9803067. [9] David J. Broadhurst, ""Vanishing Polylogarithmic Ladders,"" manuscript, March 2000, available from author. [10] Helaman R. P. Ferguson, David H. Bailey and Stephen Arno, ""Analysis of PSLQ, An Integer Relation Finding Algorithm,"" Mathematics of Computation, vol. 68, no. 225 (Jan. 1999), pg. 351-369. [11] Robert Harley, personal communication to Peter Borwein, 1995. [12] Donald E. Knuth, The Art of Computer Programming, vol. 2, third edition, AddisonWesley, 1998. [13] Jeffrey C. Lagarias, ""On the Normality of Arithmetical Constants,"" manuscript, Sept. 2000. [14] N. Nielsen, Der Eulersche Dilogarithmus, Halle, Leipzig, 1909.  19"
GX241-51-11186167	D01  Quadrature  D01GDF  NAG Fortran Library Routine Document Note. Before using this routine, please read the Users' Note for your implementation to check the interpretation of bold italicised terms and other implementation-dependent details.  1  Purp ose  D01GDF calculates an approximation to a definite integral in up to 20 dimensions, using the Korobov Conroy number theoretic metho d. This routine is designed to be particularly efficient on vector pro cessors.  2  Sp ecification SUBROUTINE D01GDF(NDIM, VECFUN, VECREG, NPTS, VK, NRAND, ITRANS, 1 RES, ERR, IFAIL) INTEGER NDIM, NPTS, NRAND, ITRANS, IFAIL real VK(NDIM), RES, ERR EXTERNAL VECFUN, VECREG  3  Description d 1  This routine calculates an approximation to the integral, d n  I= c 1  ... c n  f (x1 ,... ,xn )dxn ... dx1  (1)  using the KorobovConroy number theoretic metho d ([1], [2], [3]). The region of integration defined in (1) is such that generally ci and di may be functions of x1 ,x2 ,...,xi-1 , for i = 2, 3,... ,n, with c1 and d1 constants. The integral is first of all transformed to an integral over the n-cube [0, 1]n by the change of variables i = 1, 2,... ,n. xi = ci +(di - ci )yi , The metho d then uses as its basis the number theoretic formula for the n-cube, [0, 1]n : 1 1 p  ... 0 0  g (x1 ,...,xn )dxn ...dx1 =  1 p  g k=1  k  a1 p  ,..., k  an p  -E  (2)  where {x} denotes the fractional part of x, a1 ,... ,an are the so-called optimal co efficients, E is the error and p is a prime integer. (It is strictly only necessary that p be relatively prime to all a1 ,...,an and is in fact chosen to be even for some cases in Conroy, [3].) The metho d makes use of properties of the Fourier expansion of g (x1 ,...,xn ) which is assumed to have some degree of perio dicity. Depending on the choice of a1 ,... ,an the contributions from certain groups of Fourier co efficients are eliminated from the error, E . Korobov shows that a1 ,... ,an can be chosen so that the error satisfies E  CK p -  ln p  (3)  where  and C are real numbers depending on the convergence rate of the Fourier series,  is a constant depending on n and K is a constant depending on  and n. There are a number of pro cedures for calculating these optimal co efficients. Korobov imposes the constraint that a1 = 1 ai = a i-1  (mo d p)  and gives a pro cedure for calculating the parameter, a, to satisfy the optimal conditions. In this routine the periodisation is achieved by the simple transformation 2 xi = yi (3 - 2yi ),  i = 1, 2,... ,n.  More sophisticated periodisation procedures are available but in practice the degree of perio disation does not appear to be a critical requirement of the metho d. [NP3390/19/pdf ] D01GDF.1   D01GDF  D01  Quadrature  An easily calculable error estimate is not available apart from repetition with an increasing sequence of values of p which can yield erratic results. The difficulties have been studied by Cranley and Patterson [4] who have proposed a Monte Carlo error estimate arising from converting (2) into a sto chastic integration rule by the inclusion of a random origin shift which leaves the form of the error (3) unchanged; i.e., in the formula (2), k ai is replaced by i + k ai , for i = 1, 2,... ,n, where each i , is uniformly distributed p p over [0, 1]. Computing the integral for each of a sequence of random vectors  allows a `standard error' to be estimated. This routine provides built-in sets of optimal co efficients, corresponding to six different values of p. Alternatively, the optimal coefficients may be supplied by the user. D01GYF and D01GZF compute the optimal coefficients for the cases where p is a prime number or p is a pro duct of two primes, respectively. This routine is designed to be particularly efficient on vector pro cessors, although it is very important that the user also co des the subroutines VECFUN and VECREG efficiently.  4  References  [1] Korobov N M (1957) The approximate calculation of multiple integrals using number theoretic methods Dokl. Acad. Nauk SSSR 115 10621065 [2] Korobov N M (1963) Number Theoretic Methods in Approximate Analysis Fizmatgiz, Moscow [3] Conroy H (1967) Molecular Shro edinger equation VIII. A new metho d for evaluting multidimensional integrals J. Chem. Phys. 47 53075318 [4] Cranley R and Patterson T N L (1976) Randomisation of number theoretic metho ds for mulitple integration SIAM J. Numer. Anal. 13 904914  5 1:  Parameters NDIM -- INTEGER On entry: the number of dimensions of the integral, n. Constraint: 1  NDIM  20. Input  2:  VECFUN -- SUBROUTINE, supplied by the user. VECFUN must evaluate the integrand at a specified set of points. Its specification is: SUBROUTINE VECFUN(NDIM, X, FV, M) INTEGER NDIM, M real X(M,NDIM), FV(M) 1:  External Procedure  NDIM -- INTEGER On entry: the number of dimensions of the integral, n.  Input  2:  X(M,NDIM) -- real array Input On entry: the co-ordinates of the m points at which the integrand must be evaluated. X(i, j ) contains the j th co-ordinate of the ith point. FV(M) -- real array Output On exit: FV(i) must contain the value of the integrand of the ith point. i.e., FV(i) = f (X(i, 1), X(i, 2),... , X(i, NDIM)), for i = 1, 2,...,M. M -- INTEGER On entry: the number of points m at which the integrand is to be evaluated. Input  3:  4:  VECFUN must be declared as EXTERNAL in the (sub)program from which D01GDF is called. Parameters denoted as Input must not be changed by this pro cedure. D01GDF.2 [NP3390/19/pdf ]   D01  Quadrature  D01GDF  3:  VECREG -- SUBROUTINE, supplied by the user. Its specification is: SUBROUTINE VECREG(NDIM, X, J, C, D, M) INTEGER NDIM, J, M real X(M,NDIM), C(M), D(M) 1:  External Procedure  VECREG must evaluate the limits of integration in any dimension for a set of points.  NDIM -- INTEGER On entry: the number of dimensions of the integral, n.  Input  2:  X(M,NDIM) -- real array Input On entry: for i = 1, 2,... ,m, X(i,1), X(i,2),...,X(i, j - 1) contain the current values of the first j - 1 co-ordinates of the ith point, which may be used if necessary in calculating the m values of cj and dj . J -- INTEGER Input On entry: the index, j , of the dimension for which the limits of the range of integration are required. C(M) -- real array Output On exit: C(i) must be set to the lower limit of the range for X(i, j ), for i = 1, 2,... ,m. D(M) -- real array Output On exit: D(i) must be set to the upper limit of the range for X(i, j ), for i = 1, 2,... ,m. M -- INTEGER Input On entry: the number of points m at which the limits of integration must be specified.  3:  4:  5:  6:  VECREG must be declared as EXTERNAL in the (sub)program from which D01GDF is called. Parameters denoted as Input must not be changed by this pro cedure. 4:  NPTS -- INTEGER (a) 1  NPTS  6.  Input  On entry: the Korobov rule to be used. There are two alternatives depending on the value of NPTS.  In this case one of six preset rules is chosen using 2129, 5003, 10007, 20011, 40009 or 80021 points depending on the respective value of NPTS being 1, 2, 3, 4, 5 or 6. (b) NPTS > 6. NPTS is the number of actual points to be used with corresponding optimal co efficients supplied in the array VK. Constraint: NPTS  1 5:  VK(NDIM) -- real array  Input/Output  On entry: If NPTS > 6, VK must contain the n optimal co efficients (which may be calculated using D01GYF or D01GZF); if NPTS  6, VK need not be set. On exit: if NPTS > 6, VK is unchanged; if NPTS  6, VK contains the n optimal co efficients used by the preset rule. 6:  NRAND -- INTEGER  Input  On entry: the number of random samples to be generated (generally a small value, say 3 to 5, is sufficient). The estimate, RES, of the value of the integral returned by the routine is then the average of NRAND calculations with different random origin shifts. If NPTS > 6, the total number of integrand evaluations will be NRAND  NPTS. If 1  NPTS  6, then the number of integrand [NP3390/19/pdf ] D01GDF.3   D01GDF  D01  Quadrature  evaluations will be NRAND  p, where p is the number of points corresponding to the six preset rules. For reasons of efficiency, these values are calculated a number at a time in VECFUN. Constraint: NRAND  1 7:  ITRANS -- INTEGER On entry: indicates whether the perio dising transformation is to be used:  Input  if ITRANS = 0, the transformation is to be used. if ITRANS = 0, the transformation is to be suppressed (to cover cases where the integrand may already be periodic or where the user desires to specify a particular transformation in the definition of VECFUN). Suggested value: ITRANS = 0. 8:  RES -- real On exit: an estimate of the value of the integral.  Output  9:  ERR -- real  Output  On exit: the standard error as computed from NRAND sample values. If NRAND = 1, then ERR contains zero. 10:  IFAIL -- INTEGER  Input/Output  On entry: IFAIL must be set to 0, -1 or 1. For users not familiar with this parameter (described in Chapter P01) the recommended value is 0. On exit: IFAIL = 0 unless the routine detects an error (see Section 6).  6  Error Indicators and Warnings  If on entry IFAIL = 0 or -1, explanatory error messages are output on the current error message unit (as defined by X04AAF). Errors detected by the routine: IFAIL = 1 On entry, NDIM < 1, or NDIM > 20. IFAIL = 2 On entry, NPTS < 1. IFAIL = 3 On entry, NRAND < 1.  7  Accuracy  If NRAND > 1, an estimate of the absolute standard error is given by the value, on exit, of ERR.  D01GDF.4  [NP3390/19/pdf ]   D01  Quadrature  D01GDF  8  Further Comments  This routine performs the same computation as the D01GCF. However, the interface has been mo dified so that it can perform more efficiently on machines with vector pro cessing capabilities. In particular, the routines VECFUN and VECREG must calculate the integrand and limits of integration at a set of points. For some problems the amount of time spent in these two subroutines, which must be supplied by the user, may account for a significant part of the total computation time. For this reason it is vital that the user considers the possibilities for vectorization in the co de supplied for these two subroutines. The time taken will be approximately proportional to NRAND  p, where p is the number of points used, but may depend significantly on the efficiency of the co de provided by the user in subroutines VECFUN and VECREG. The exact values of RES and ERR returned by D01GDF will depend (within statistical limits) on the sequence of random numbers generated within the routine by calls to G05CAF. To ensure that the results returned by D01GDF in separate runs are identical, users should call G05CBF immediately before calling D01GDF; to ensure that they are different, call G05CCF.  9  Example 1 0 0 1 0 1 0 1  This example calculates the integral cos(0.5+2(x1 + x2 + x3 + x4 ) - 4) dx1 dx2 dx3 dx4 .  9.1  Program Text  Note. The listing of the example program presented below uses bold italicised terms to denote precision-dependent details. Please read the Users' Note for your implementation to check the interpretation of these terms. As explained in the Essential Introduction to this manual, the results produced may not be identical for all implementations.  * * *  *  * * *  D01GDF Example Program Text Mark 14 Release. NAG Copyright 1989. .. Parameters .. INTEGER NOUT PARAMETER (NOUT=6) INTEGER NDIM PARAMETER (NDIM=4) .. Local Scalars .. real ERR, RES INTEGER IFAIL, ITRANS, NPTS, NRAND .. Local Arrays .. real VK(NDIM) .. External Subroutines .. EXTERNAL D01GDF, VECFUN, VECREG .. Executable Statements .. WRITE (NOUT,*) 'D01GDF Example Program Results' WRITE (NOUT,*) NPTS = 2 ITRANS = 0 NRAND = 4 IFAIL = 0 CALL D01GDF(NDIM,VECFUN,VECREG,NPTS,VK,NRAND,ITRANS,RES,ERR,IFAIL)  * * WRITE (NOUT,99999) 'Result = ', RES, ', standard error = ', ERR STOP * 99999 FORMAT (1X,A,F13.5,A,e10.2) END [NP3390/19/pdf ] D01GDF.5   D01GDF  D01  Quadrature  * * * * * * SUBROUTINE VECFUN(NDIM,X,FV,M) .. Scalar Arguments .. INTEGER M, NDIM .. Array Arguments .. real FV(M), X(M,NDIM) .. Local Scalars .. INTEGER I, J .. Intrinsic Functions .. INTRINSIC COS, real .. Executable Statements .. DO 20 I = 1, M FV(I) = 0.0e0 CONTINUE DO 60 J = 1, NDIM DO 40 I = 1, M FV(I) = FV(I) + X(I,J) CONTINUE CONTINUE DO 80 I = 1, M FV(I) = COS(0.5e0+2.0e0*FV(I)-real(NDIM)) CONTINUE RETURN END  20  40 60  80  * * * * * SUBROUTINE VECREG(NDIM,X,J,C,D,M) .. Scalar Arguments .. INTEGER J, M, NDIM .. Array Arguments .. real C(M), D(M), X(M,NDIM) .. Local Scalars .. INTEGER I .. Executable Statements .. DO 20 I = 1, M C(I) = 0.0e0 D(I) = 1.0e0 20 CONTINUE RETURN END  9.2 None.  Program Data  9.3  Program Results D01GDF Example Program Results Result = 0.43999, standard error = 0.18E-05  D01GDF.6 (last)  [NP3390/19/pdf ]
GX252-17-13624814	"7.1 Uniform Deviates  267  As for references on this subject, the one to turn to first is Knuth [1 ]. Then try [2 ]. Only a few of the standard books on numerical methods [3-4 ] treat topics relating to random numbers.  CITED REFERENCES AND FURTHER READING: Sample page from NUMERICAL RECIPES IN FORTRAN 77: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43064-X) Copyright (C) 1986-1992 by Cambridge University Press. Programs Copyright (C) 1986-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  Knuth, D.E. 1981, Seminumerical Algorithms, 2nd ed., vol. 2 of The Ar t of Computer Programming (Reading, MA: Addison-Wesley), Chapter 3, especially 3.5. [1] Bratley, P., Fox, B.L., and Schrage, E.L. 1983, A Guide to Simulation (New York: SpringerVerlag). [2] Dahlquist, G., and Bjorck, A. 1974, Numerical Methods (Englewood Cliffs, NJ: Prentice-Hall), Chapter 11. [3] Forsythe, G.E., Malcolm, M.A., and Moler, C.B. 1977, Computer Methods for Mathematical Computations (Englewood Cliffs, NJ: Prentice-Hall), Chapter 10. [4]  7.1 Uniform Deviates Uniform deviates are just random numbers that lie within a specified range (typically 0 to 1), with any one number in the range just as likely as any other. They are, in other words, what you probably think ""random numbers"" are. However, we want to distinguish uniform deviates from other sorts of random numbers, for example numbers drawn from a normal (Gaussian) distribution of specified mean and standard deviation. These other sorts of deviates are almost always generated by performing appropriate operations on one or more uniform deviates, as we will see in subsequent sections. So, a reliable source of random uniform deviates, the subject of this section, is an essential building block for any sort of stochastic modeling or Monte Carlo computer work.  System-Supplied Random Number Generators Your computer very likely has lurking within it a library routine which is called a ""random number generator."" That routine typically has an unforgettable name like ""ran,"" and a calling sequence like x=ran(iseed) sets x to the next random number and updates iseed  You initialize iseed to a (usually) arbitrary value before the first call to ran. Each initializing value will typically return a different subsequent random sequence, or at least a different subsequence of some one enormously long sequence. The same initializing value of iseed will always return the same random sequence, however. Now our first, and perhaps most important, lesson in this chapter is: Be very, very suspicious of a system-supplied ran that resembles the one just described. If all scientific papers whose results are in doubt because of bad rans were to disappear from library shelves, there would be a gap on each shelf about as big as your fist. System-supplied rans are almost always linear congruential generators, which   268  Chapter 7.  Random Numbers  generate a sequence of integers I 1 ,I2 ,I3 ,... , each between 0 and m - 1 (a large number) by the recurrence relation Ij +1  = aIj + c  (mod m)  (7.1.1) Sample page from NUMERICAL RECIPES IN FORTRAN 77: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43064-X) Copyright (C) 1986-1992 by Cambridge University Press. Programs Copyright (C) 1986-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  Here m is called the modulus, and a and c are positive integers called the multiplier and the increment, respectively. The recurrence (7.1.1) will eventually repeat itself, with a period that is obviously no greater than m. If m, a, and c are properly chosen, then the period will be of maximal length, i.e., of length m. In that case, all possible integers between 0 and m - 1 occur at some point, so any initial ""seed"" choice of I 0 is as good as any other: The sequence just takes off from that point. The real number between 0 and 1 which is returned is generally I j +1 /m, so that it is strictly less than 1, but occasionally (once in m calls) exactly equal to zero. iseed is set to I j +1 (or some encoding of it), so that it can be used on the next call to generate I j +2 , and so on. The linear congruential method has the advantage of being very fast, requiring only a few operations per call, hence its almost universal use. It has the disadvantage that it is not free of sequential correlation on successive calls. If k random numbers at a time are used to plot points in k dimensional space (with each coordinate between 0 and 1), then the points will not tend to ""fill up"" the k -dimensional space, but rather will lie on (k - 1)-dimensional ""planes."" There will be at most about m 1/k such planes. If the constants m, a, and c are not very carefully chosen, there will be many fewer than that. The number m is usually close to the machine's largest representable integer, e.g.,  2 32 . So, for example, the number of planes on which triples of points lie in three-dimensional space is usually no greater than about the cube root of 2 32 , about 1600. You might well be focusing attention on a physical process that occurs in a small fraction of the total volume, so that the discreteness of the planes can be very pronounced. Even worse, you might be using a ran whose choices of m, a, and c have been botched. One infamous such routine, RANDU, with a = 65539 and m = 2 31 , was widespread on IBM mainframe computers for many years, and widely copied onto other systems [1 ]. One of us recalls producing a ""random"" plot with only 11 planes, and being told by his computer center's programming consultant that he had misused the random number generator: ""We guarantee that each number is random individually, but we don't guarantee that more than one of them is random."" Figure that out. Correlation in k -space is not the only weakness of linear congruential generators. Such generators often have their low-order (least significant) bits much less random than their high-order bits. If you want to generate a random integer between 1 and 10, you should always do it using high-order bits, as in j=1+int(10.*ran(iseed))  and never by anything resembling j=1+mod(int(1000000.*ran(iseed)),10)   7.1 Uniform Deviates  269  (which uses lower-order bits). Similarly you should never try to take apart a ""ran"" number into several supposedly random pieces. Instead use separate calls for every piece.  Portable Random Number Generators Sample page from NUMERICAL RECIPES IN FORTRAN 77: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43064-X) Copyright (C) 1986-1992 by Cambridge University Press. Programs Copyright (C) 1986-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  Park and Miller [1 ] have surveyed a large number of random number generators that have been used over the last 30 years or more. Along with a good theoretical review, they present an anecdotal sampling of a number of inadequate generators that have come into widespread use. The historical record is nothing if not appalling. There is good evidence, both theoretical and empirical, that the simple multiplicative congruential algorithm Ij +1  = aIj  (mod m)  (7.1.2)  can be as good as any of the more general linear congruential generators that have c = 0 (equation 7.1.1) -- if the multiplier a and modulus m are chosen exquisitely carefully. Park and Miller propose a ""Minimal Standard"" generator based on the choices a = 75 = 16807 m=2 31  - 1 = 2147483647  (7.1.3)  First proposed by Lewis, Goodman, and Miller in 1969, this generator has in subsequent years passed all new theoretical tests, and (perhaps more importantly) has accumulated a large amount of successful use. Park and Miller do not claim that the generator is ""perfect"" (we will see below that it is not), but only that it is a good minimal standard against which other generators should be judged. It is not possible to implement equations (7.1.2) and (7.1.3) directly in a high-level language, since the product of a and m - 1 exceeds the maximum value for a 32-bit integer. Assembly language implementation using a 64-bit product register is straightforward, but not portable from machine to machine. A trick due to Schrage [2,3 ] for multiplying two 32-bit integers modulo a 32-bit constant, without using any intermediates larger than 32 bits (including a sign bit) is therefore extremely interesting: It allows the Minimal Standard generator to be implemented in essentially any programming language on essentially any machine. Schrage's algorithm is based on an approximate factorization of m, m = aq + r, i.e., q = [m/a], r = m mod a (7.1.4)  with square brackets denoting integer part. If r is small, specifically r < q , and 0 < z < m - 1, it can be shown that both a(z mod q ) and r[z/q ] lie in the range 0,... ,m - 1, and that az mod m = a(z mod q ) - r[z/q ] a(z mod q ) - r[z/q ]+ m if it is  0, otherwise (7.1.5)  The application of Schrage's algorithm to the constants (7.1.3) uses the values q = 127773 and r = 2836. Here is an implementation of the Minimal Standard generator:   270  Chapter 7.  Random Numbers  *  FUNCTION ran0(idum) INTEGER idum,IA,IM,IQ,IR,MASK REAL ran0,AM PARAMETER (IA=16807,IM=2147483647,AM=1./IM, IQ=127773,IR=2836,MASK=123459876) ""Minimal"" random number generator of Park and Miller. Returns a uniform random deviate between 0.0 and 1.0. Set or reset idum to any integer value (except the unlikely value MASK) to initialize the sequence; idum must not be altered between calls for successive deviates in a sequence. INTEGER k idum=ieor(idum,MASK) XORing with MASK allows use of zero and other simple k=idum/IQ bit patterns for idum. idum=IA*(idum-k*IQ)-IR*k Compute idum=mod(IA*idum,IM) without overflows by if (idum.lt.0) idum=idum+IM Schrage's method. ran0=AM*idum Convert idum to a floating result. idum=ieor(idum,MASK) Unmask before return. return END  Sample page from NUMERICAL RECIPES IN FORTRAN 77: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43064-X) Copyright (C) 1986-1992 by Cambridge University Press. Programs Copyright (C) 1986-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  The period of ran0 is 2 31 - 2  2.1  109 . A peculiarity of generators of the form (7.1.2) is that the value 0 must never be allowed as the initial seed -- it perpetuates itself -- and it never occurs for any nonzero initial seed. Experience has shown that users always manage to call random number generators with the seed idum=0. That is why ran0 performs its exclusive-or with an arbitrary constant both on entry and exit. If you are the first user in history to be proof against human error, you can remove the two lines with the ieor function. Park and Miller discuss two other multipliers a that can be used with the same m = 231 - 1. These are a = 48271 (with q = 44488 and r = 3399) and a = 69621 (with q = 30845 and r = 23902). These can be substituted in the routine ran0 if desired; they may be slightly superior to Lewis et al.'s longer-tested values. No values other than these should be used. The routine ran0 is a Minimal Standard, satisfactory for the majority of applications, but we do not recommend it as the final word on random number generators. Our reason is precisely the simplicity of the Minimal Standard. It is not hard to think of situations where successive random numbers might be used in a way that accidentally conflicts with the generation algorithm. For example, since successive numbers differ by a multiple of only 1.6  10 4 out of a modulus of more than 2  10 9 , very small random numbers will tend to be followed by smaller than average values. One time in 106 , for example, there will be a value < 10 -6 returned (as there should be), but this will always be followed by a value less than about 0.0168. One can easily think of applications involving rare events where this property would lead to wrong results. There are other, more subtle, serial correlations present in ran0. For example, if successive points (Ii ,Ii+1 ) are binned into a two-dimensional plane for i = 1, 2,... ,N , then the resulting distribution fails the  2 test when N is greater than a few 107 , much less than the period m - 2. Since low-order serial correlations have historically been such a bugaboo, and since there is a very simple way to remove them, we think that it is prudent to do so. The following routine, ran1, uses the Minimal Standard for its random value, but it shuffles the output to remove low-order serial correlations. A random deviate derived from the j th value in the sequence, I j , is output not on the j th call, but rather on a randomized later call, j +32 on average. The shuffling algorithm is due to Bays and Durham as described in Knuth [4 ], and is illustrated in Figure 7.1.1.   7.1 Uniform Deviates  271  *  FUNCTION ran1(idum) INTEGER idum,IA,IM,IQ,IR,NTAB,NDIV REAL ran1,AM,EPS,RNMX PARAMETER (IA=16807,IM=2147483647,AM=1./IM,IQ=127773,IR=2836, NTAB=32,NDIV=1+(IM-1)/NTAB,EPS=1.2e-7,RNMX=1.-EPS) ""Minimal"" random number generator of Park and Miller with Bays-Durham shuffle and added safeguards. Returns a uniform random deviate between 0.0 and 1.0 (exclusive of the endpoint values). Call with idum a negative integer to initialize; thereafter, do not alter idum between successive deviates in a sequence. RNMX should approximate the largest floating value that is less than 1. INTEGER j,k,iv(NTAB),iy SAVE iv,iy DATA iv /NTAB*0/, iy /0/ if (idum.le.0.or.iy.eq.0) then Initialize. idum=max(-idum,1) Be sure to prevent idum = 0. do 11 j=NTAB+8,1,-1 Load the shuffle table (after 8 warm-ups). k=idum/IQ idum=IA*(idum-k*IQ)-IR*k if (idum.lt.0) idum=idum+IM if (j.le.NTAB) iv(j)=idum enddo 11 iy=iv(1) endif k=idum/IQ Start here when not initializing. idum=IA*(idum-k*IQ)-IR*k Compute idum=mod(IA*idum,IM) without overflows by if (idum.lt.0) idum=idum+IM Schrage's method. j=1+iy/NDIV Will be in the range 1:NTAB. iy=iv(j) Output previously stored value and refill the shuffle taiv(j)=idum ble. ran1=min(AM*iy,RNMX) Because users don't expect endpoint values. return END  Sample page from NUMERICAL RECIPES IN FORTRAN 77: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43064-X) Copyright (C) 1986-1992 by Cambridge University Press. Programs Copyright (C) 1986-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  The routine ran1 passes those statistical tests that ran0 is known to fail. In fact, we do not know of any statistical test that ran1 fails to pass, except when the number of calls starts to become on the order of the period m, say > 10 8  m/20. For situations when even longer random sequences are needed, L'Ecuyer [6 ] has given a good way of combining two different sequences with different periods so as to obtain a new sequence whose period is the least common multiple of the two periods. The basic idea is simply to add the two sequences, modulo the modulus of either of them (call it m). A trick to avoid an intermediate value that overflows the integer wordsize is to subtract rather than add, and then add back the constant m - 1 if the result is  0, so as to wrap around into the desired interval 0,... ,m - 1. Notice that it is not necessary that this wrapped subtraction be able to reach all values 0,... ,m - 1 from every value of the first sequence. Consider the absurd extreme case where the value subtracted was only between 1 and 10: The resulting sequence would still be no less random than the first sequence by itself. As a practical matter it is only necessary that the second sequence have a range covering substantially all of the range of the first. L'Ecuyer recommends the use of the two generators m1 = 2147483563 (with a1 = 40014, q1 = 53668, r1 = 12211) and m2 = 2147483399 (with a2 = 40692, q2 = 52774, r2 = 3791). Both moduli are slightly less than 231 . The periods m 1 - 1 = 2  3  7  631  81031 and m2 - 1 = 2  19  31  1019  1789 share only the factor 2, so the period of the combined generator is  2.3  10 18 . For present computers, period exhaustion is a practical impossibility.   272  Chapter 7.  Random Numbers  iy  1 Sample page from NUMERICAL RECIPES IN FORTRAN 77: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43064-X) Copyright (C) 1986-1992 by Cambridge University Press. Programs Copyright (C) 1986-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  iv  1  OUTPUT  RAN  3  2  iv  32  Figure 7.1.1. Shuffling procedure used in ran1 to break up sequential correlations in the Minimal Standard generator. Circled numbers indicate the sequence of events: On each call, the random number in iy is used to choose a random element in the array iv. That element becomes the output random number, and also is the next iy. Its spot in iv is refilled from the Minimal Standard routine.  Combining the two generators breaks up serial correlations to a considerable extent. We nevertheless recommend the additional shuffle that is implemented in the following routine, ran2. We think that, within the limits of its floating-point precision, ran2 provides perfect random numbers; a practical definition of ""perfect"" is that we will pay $1000 to the first reader who convinces us otherwise (by finding a statistical test that ran2 fails in a nontrivial way, excluding the ordinary limitations of a machine's floating-point representation). FUNCTION ran2(idum) INTEGER idum,IM1,IM2,IMM1,IA1,IA2,IQ1,IQ2,IR1,IR2,NTAB,NDIV REAL ran2,AM,EPS,RNMX PARAMETER (IM1=2147483563,IM2=2147483399,AM=1./IM1,IMM1=IM1-1, IA1=40014,IA2=40692,IQ1=53668,IQ2=52774,IR1=12211, IR2=3791,NTAB=32,NDIV=1+IMM1/NTAB,EPS=1.2e-7,RNMX=1.-EPS) Long period (> 2  1018 ) random number generator of L'Ecuyer with Bays-Durham shuffle and added safeguards. Returns a uniform random deviate between 0.0 and 1.0 (exclusive of the endpoint values). Call with idum a negative integer to initialize; thereafter, do not alter idum between successive deviates in a sequence. RNMX should approximate the largest floating value that is less than 1. INTEGER idum2,j,k,iv(NTAB),iy SAVE iv,iy,idum2 DATA idum2/123456789/, iv/NTAB*0/, iy/0/ if (idum.le.0) then Initialize. idum=max(-idum,1) Be sure to prevent idum = 0. idum2=idum do 11 j=NTAB+8,1,-1 Load the shuffle table (after 8 warm-ups). k=idum/IQ1  * *   7.1 Uniform Deviates  273  idum=IA1*(idum-k*IQ1)-k*IR1 if (idum.lt.0) idum=idum+IM1 if (j.le.NTAB) iv(j)=idum enddo 11 iy=iv(1) endif k=idum/IQ1 idum=IA1*(idum-k*IQ1)-k*IR1 if (idum.lt.0) idum=idum+IM1 k=idum2/IQ2 idum2=IA2*(idum2-k*IQ2)-k*IR2 if (idum2.lt.0) idum2=idum2+IM2 j=1+iy/NDIV iy=iv(j)-idum2 iv(j)=idum if(iy.lt.1)iy=iy+IMM1 ran2=min(AM*iy,RNMX) return END  Start here when not initializing. Compute idum=mod(IA1*idum,IM1) without overflows by Schrage's method. Compute idum2=mod(IA2*idum2,IM2) likewise. Will be in the range 1:NTAB. Here idum is shuffled, idum and idum2 are combined to generate output. Because users don't expect endpoint values.  Sample page from NUMERICAL RECIPES IN FORTRAN 77: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43064-X) Copyright (C) 1986-1992 by Cambridge University Press. Programs Copyright (C) 1986-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  L'Ecuyer [6 ] lists additional short generators that can be combined into longer ones, including generators that can be implemented in 16-bit integer arithmetic. Finally, we give you Knuth's suggestion [4 ] for a portable routine, which we have translated to the present conventions as ran3. This is not based on the linear congruential method at all, but rather on a subtractive method (see also [5 ]). One might hope that its weaknesses, if any, are therefore of a highly different character from the weaknesses, if any, of ran1 above. If you ever suspect trouble with one routine, it is a good idea to try the other in the same application. ran3 has one nice feature: if your machine is poor on integer arithmetic (i.e., is limited to 16-bit integers), substitution of the three ""commented"" lines for the ones directly preceding them will render the routine entirely floating-point. FUNCTION ran3(idum) Returns a uniform random deviate between 0.0 and 1.0. Set idum to any negative value to initialize or reinitialize the sequence. INTEGER idum INTEGER MBIG,MSEED,MZ REAL MBIG,MSEED,MZ REAL ran3,FAC PARAMETER (MBIG=1000000000,MSEED=161803398,MZ=0,FAC=1./MBIG) PARAMETER (MBIG=4000000.,MSEED=1618033.,MZ=0.,FAC=1./MBIG) According to Knuth, any large mbig, and any smaller (but still large) mseed can be substituted for the above values. INTEGER i,iff,ii,inext,inextp,k INTEGER mj,mk,ma(55) The value 55 is special and should not be modified; see REAL mj,mk,ma(55) Knuth. SAVE iff,inext,inextp,ma DATA iff /0/ if(idum.lt.0.or.iff.eq.0)then Initialization. iff=1 mj=abs(MSEED-abs(idum)) Initialize ma(55) using the seed idum and the large nummj=mod(mj,MBIG) ber mseed. ma(55)=mj mk=1 do 11 i=1,54 Now initialize the rest of the table, ii=mod(21*i,55) in a slightly random order, ma(ii)=mk with numbers that are not especially random. mk=mj-mk if(mk.lt.MZ)mk=mk+MBIG  C C  C   274  Chapter 7.  Random Numbers  mj=ma(ii) enddo 11 do 13 k=1,4 We randomize them by ""warming up the generator."" do 12 i=1,55 ma(i)=ma(i)-ma(1+mod(i+30,55)) if(ma(i).lt.MZ)ma(i)=ma(i)+MBIG enddo 12 enddo 13 inext=0 Prepare indices for our first generated number. inextp=31 The constant 31 is special; see Knuth. idum=1 endif inext=inext+1 Here is where we start, except on initialization. Increment if(inext.eq.56)inext=1 inext, wrapping around 56 to 1. inextp=inextp+1 Ditto for inextp. if(inextp.eq.56)inextp=1 mj=ma(inext)-ma(inextp) Now generate a new random number subtractively. if(mj.lt.MZ)mj=mj+MBIG Be sure that it is in range. ma(inext)=mj Store it, ran3=mj*FAC and output the derived uniform deviate. return END  Sample page from NUMERICAL RECIPES IN FORTRAN 77: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43064-X) Copyright (C) 1986-1992 by Cambridge University Press. Programs Copyright (C) 1986-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  Quick and Dirty Generators One sometimes would like a ""quick and dirty"" generator to embed in a program, perhaps taking only one or two lines of code, just to somewhat randomize things. One might wish to process data from an experiment not always in exactly the same order, for example, so that the first output is more ""typical"" than might otherwise be the case. For this kind of application, all we really need is a list of ""good"" choices for m, a, and c in equation (7.1.1). If we don't need a period longer than 104 to 106 , say, we can keep the value of (m - 1)a + c small enough to avoid overflows that would otherwise mandate the extra complexity of Schrage's method (above). We can thus easily embed in our programs jran=mod(jran*ia+ic,im) ran=float(jran)/float(im)  whenever we want a quick and dirty uniform deviate, or jran=mod(jran*ia+ic,im) j=jlo+((jhi-jlo+1)*jran)/im  whenever we want an integer between jlo and jhi, inclusive. (In both cases jran was once initialized to any seed value between 0 and im-1.) Be sure to remember, however, that when im is small, the kth root of it, which is the number of planes in k-space, is even smaller! So a quick and dirty generator should never be used to select points in k-space with k > 1. With these caveats, some ""good"" choices for the constants are given in the accompanying table. These constants (i) give a period of maximal length im, and, more important, (ii) pass Knuth's ""spectral "" for dimensions 2, 3, 4, 5, and 6. The increment ic is a prime, close to test the value ( 1 - 1 3)im; actually almost any value of ic that is relatively prime to im will do 2 6 just as well, but there is some ""lore"" favoring this choice (see [4 ], p. 84).   7.1 Uniform Deviates  275  Constants for Quick and Dirty Random Number Generators overflow at 220 221 222 im 6075 7875 7875 ia 106 211 421 ic 1283 1663 1663 1283 1399 2531 228 227 overflow at im ia ic 18257 25673 54773 24749 25673 66037 30809 36979 49297 51749  86436 1093 121500 1021 259200 421 117128 1277 121500 2041 312500 741 145800 175000 233280 244944 3661 2661 1861 1597  Sample page from NUMERICAL RECIPES IN FORTRAN 77: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43064-X) Copyright (C) 1986-1992 by Cambridge University Press. Programs Copyright (C) 1986-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  223  6075 1366 6655 936 11979 430 14406 29282 53125  2  24  967 3041 419 6173 171 11213  229  225  12960 1741 2731 14000 1541 2957 21870 1291 4621 31104 625 6571 139968 205 29573 29282 1255 6173 81000 421 17117 134456 281 28411  230 231 232  139968 3877 29573 214326 3613 45289 714025 1366 150889 134456 8121 259200 7141 28411 54773  233280 9301 49297 714025 4096 150889  2  26  An Even Quicker and Dirtier Generator Many FORTRAN compilers can be abused in such a way that they will multiply two 32-bit integers ignoring any resulting overflow. In such cases, on many machines, the value returned is predictably the low-order 32 bits of the true 64-bit product. (C compilers, incidentally, can do this without the requirement of abuse -- it is guaranteed behavior for so-called unsigned long int integers. On VMS VAXes, the necessary FORTRAN command is FORTRAN/CHECK=NOOVERFLOW .) If we now choose m = 232 , the ""mod"" in equation (7.1.1) is free, and we have simply I j +1  = aIj + c  (7.1.6)  Knuth suggests a = 1664525 as a suitable multiplier for this value of m. H.W. Lewis has  conducted extensive tests of this value of a with c = 1013904223, which is a prime close to ( 5 - 2)m. The resulting in-line generator (we will call it ranqd1) is simply idum=1664525*idum+1013904223  This is about as good as any 32-bit linear congruential generator, entirely adequate for many uses. And, with only a single multiply and add, it is very fast. To check whether your compiler and machine have the desired overflow properties, see if you can generate the following sequence of 32-bit values (given here in hex): 00000000, 3C6EF35F, 47502932, D1CCF6E9, AAF95334, 6252E503, 9F2EC686, 57FE6C2D, A3D95FA8, 81FDBEE7, 94F0AF1A, CBF633B1. If you need floating-point values instead of 32-bit integers, and want to avoid a divide by floating-point 232 , a dirty trick is to mask in an exponent that makes the value lie between 1 and 2, then subtract 1.0. The resulting in-line generator (call it ranqd2) will look something like   276  Chapter 7.  Random Numbers  INTEGER idum,itemp,jflone,jflmsk REAL ftemp EQUIVALENCE (itemp,ftemp) DATA jflone /Z'3F800000'/, jflmsk /Z'007FFFFF'/ ... idum=1664525*idum+1013904223 itemp=ior(jflone,iand(jflmsk,idum)) ran=ftemp-1.0  Sample page from NUMERICAL RECIPES IN FORTRAN 77: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43064-X) Copyright (C) 1986-1992 by Cambridge University Press. Programs Copyright (C) 1986-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  The hex constants 3F800000 and 007FFFFF are the appropriate ones for computers using the IEEE representation for 32-bit floating-point numbers (e.g., IBM PCs and most UNIX workstations). For DEC VAXes, the correct hex constants are, respectively, 00004080 and FFFF007F. Notice that the IEEE mask results in the floating-point number being constructed out of the 23 low-order bits of the integer, which is not ideal. Also notice that your compiler may require a different notation for hex constants, e.g., x'3f800000', '3F800000'X,or even 16#3F800000 . (Your authors have tried very hard to make almost all of the material in this book machine and compiler independent -- indeed, even programming language independent. This subsection is a rare aberration. Forgive us. Once in a great while the temptation to be really dirty is just irresistible.)  Relative Timings and Recommendations Timings are inevitably machine dependent. Nevertheless the following table is indicative of the relative timings, for typical machines, of the various uniform generators discussed in this section, plus ran4 from 7.5. Smaller values in the table indicate faster generators. The generators ranqd1 and ranqd2 refer to the ""quick and dirty"" generators immediately above.  Generator ran0 ran1 ran2 ran3 ranqd1 ranqd2 ran4  Relative Execution Time  1.0  1.3  2.0  0.6  0.10  0.25  4.0  On balance, we recommend ran1 for general use. It is portable, based on Park and Miller's Minimal Standard generator with an additional shuffle, and has no known (to us) flaws other than period exhaustion. If you are generating more than 100,000,000 random numbers in a single calculation (that is, more than about 5% of ran1's period), we recommend the use of ran2, with its much longer period. Knuth's subtractive routine ran3 seems to be the timing winner among portable routines. Unfortunately the subtractive method is not so well studied, and not a standard. We like to keep ran3 in reserve for a ""second opinion,"" substituting it when we suspect another generator of introducing unwanted correlations into a calculation. The routine ran4 generates extremely good random deviates, and has some other nice properties, but it is slow. See 7.5 for discussion.   7.2 Transformation Method: Exponential and Normal Deviates  277  Finally, the quick and dirty in-line generators ranqd1 and ranqd2 are very fast, but they are machine dependent, nonportable, and at best only as good as a 32-bit linear congruential generator ever is -- in our view not good enough in many situations. We would use these only in very special cases, where speed is critical. CITED REFERENCES AND FURTHER READING: Park, S.K., and Miller, K.W. 1988, Communications of the ACM, vol. 31, pp. 11921201. [1] Schrage, L. 1979, ACM Transactions on Mathematical Software, vol. 5, pp. 132138. [2] Bratley, P., Fox, B.L., and Schrage, E.L. 1983, A Guide to Simulation (New York: SpringerVerlag). [3] Knuth, D.E. 1981, Seminumerical Algorithms, 2nd ed., vol. 2 of The Ar t of Computer Programming (Reading, MA: Addison-Wesley), 3.23.3. [4] Kahaner, D., Moler, C., and Nash, S. 1989, Numerical Methods and Software (Englewood Cliffs, NJ: Prentice Hall), Chapter 10. [5] L'Ecuyer, P. 1988, Communications of the ACM, vol. 31, pp. 742774. [6] Forsythe, G.E., Malcolm, M.A., and Moler, C.B. 1977, Computer Methods for Mathematical Computations (Englewood Cliffs, NJ: Prentice-Hall), Chapter 10. Sample page from NUMERICAL RECIPES IN FORTRAN 77: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43064-X) Copyright (C) 1986-1992 by Cambridge University Press. Programs Copyright (C) 1986-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  7.2 Transformation Method: Exponential and Normal Deviates In the previous section, we learned how to generate random deviates with a uniform probability distribution, so that the probability of generating a number between x and x + dx, denoted p(x)dx, is given by p(x)dx = dx 0 0"
GX253-57-9085816	"7.1 Uniform Deviates  275  As for references on this subject, the one to turn to first is Knuth [1 ]. Then try [2 ]. Only a few of the standard books on numerical methods [3-4 ] treat topics relating to random numbers. CITED REFERENCES AND FURTHER READING: Knuth, D.E. 1981, Seminumerical Algorithms, 2nd ed., vol. 2 of The Ar t of Computer Programming (Reading, MA: Addison-Wesley), Chapter 3, especially 3.5. [1] Bratley, P., Fox, B.L., and Schrage, E.L. 1983, A Guide to Simulation (New York: SpringerVerlag). [2] Dahlquist, G., and Bjorck, A. 1974, Numerical Methods (Englewood Cliffs, NJ: Prentice-Hall), Chapter 11. [3] Forsythe, G.E., Malcolm, M.A., and Moler, C.B. 1977, Computer Methods for Mathematical Computations (Englewood Cliffs, NJ: Prentice-Hall), Chapter 10. [4] Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  7.1 Uniform Deviates Uniform deviates are just random numbers that lie within a specified range (typically 0 to 1), with any one number in the range just as likely as any other. They are, in other words, what you probably think ""random numbers"" are. However, we want to distinguish uniform deviates from other sorts of random numbers, for example numbers drawn from a normal (Gaussian) distribution of specified mean and standard deviation. These other sorts of deviates are almost always generated by performing appropriate operations on one or more uniform deviates, as we will see in subsequent sections. So, a reliable source of random uniform deviates, the subject of this section, is an essential building block for any sort of stochastic modeling or Monte Carlo computer work.  System-Supplied Random Number Generators Most C implementations have, lurking within, a pair of library routines for initializing, and then generating, ""random numbers."" In ANSI C, the synopsis is: #include   #define RAND_MAX ... void srand(unsigned seed); int rand(void);  You initialize the random number generator by invoking srand(seed) with some arbitrary seed. Each initializing value will typically result in a different random sequence, or a least a different starting point in some one enormously long sequence. The same initializing value of seed will always return the same random sequence, however. You obtain successive random numbers in the sequence by successive calls to rand(). That function returns an integer that is typically in the range 0 to the largest representable positive value of type int (inclusive). Usually, as in ANSI C, this largest value is available as RAND_MAX, but sometimes you have to figure it out for yourself. If you want a random float value between 0.0 (inclusive) and 1.0 (exclusive), you get it by an expression like   276  Chapter 7.  Random Numbers  x = rand()/(RAND_MAX+1.0);  Now our first, and perhaps most important, lesson in this chapter is: be very, very suspicious of a system-supplied rand() that resembles the one just described. If all scientific papers whose results are in doubt because of bad rand()s were to disappear from library shelves, there would be a gap on each shelf about as big as your fist. System-supplied rand()s are almost always linear congruential generators, which generate a sequence of integers I 1 ,I2 ,I3 ,..., each between 0 and m - 1 (e.g., RAND_MAX) by the recurrence relation Ij +1  Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  = aIj + c  (mod m)  (7.1.1)  Here m is called the modulus, and a and c are positive integers called the multiplier and the increment respectively. The recurrence (7.1.1) will eventually repeat itself, with a period that is obviously no greater than m. If m, a, and c are properly chosen, then the period will be of maximal length, i.e., of length m. In that case, all possible integers between 0 and m - 1 occur at some point, so any initial ""seed"" choice of I 0 is as good as any other: the sequence just takes off from that point. Although this general framework is powerful enough to provide quite decent random numbers, its implementation in many, if not most, ANSI C libraries is quite flawed; quite a number of implementations are in the category ""totally botched."" Blame should be apportioned about equally between the ANSI C committee and the implementors. The typical problems are these: First, since the ANSI standard specifies that rand() return a value of type int -- which is only a two-byte quantity on many machines -- RAND_MAX is often not very large. The ANSI C standard requires only that it be at least 32767. This can be disastrous in many circumstances: for a Monte Carlo integration (7.6 and 7.8), you might well want to evaluate 10 6 different points, but actually be evaluating the same 32767 points 30 times each, not at all the same thing! You should categorically reject any library random number routine with a two-byte returned value. Second, the ANSI committee's published rationale includes the following mischievous passage: ""The committee decided that an implementation should be allowed to provide a rand function which generates the best random sequence possible in that implementation, and therefore mandated no standard algorithm. It recognized the value, however, of being able to generate the same pseudo-random sequence in different implementations, and so it has published an example... . [emphasis added]"" The ""example"" is unsigned long next=1; int rand(void) /* NOT RECOMMENDED (see text) */ { next = next*1103515245 + 12345; return (unsigned int)(next/65536) % 32768; } void srand(unsigned int seed) { next=seed; }   7.1 Uniform Deviates  277  This corresponds to equation (7.1.1) with a = 1103515245, c = 12345, and m = 232 (since arithmetic done on unsigned long quantities is guaranteed to return the correct low-order bits). These are not particularly good choices for a and c (the period is only 2 30 ), though they are not gross embarrassments by themselves. The real botches occur when implementors, taking the committee's statement above as license, try to ""improve"" on the published example. For example, one popular 32-bit PC-compatible compiler provides a long generator that uses the above congruence, but swaps the high-order and low-order 16 bits of the returned value. Somebody probably thought that this extra flourish added randomness; in fact it ruins the generator. While these kinds of blunders can, of course, be fixed, there remains a fundamental flaw in simple linear congruential generators, which we now discuss. The linear congruential method has the advantage of being very fast, requiring only a few operations per call, hence its almost universal use. It has the disadvantage that it is not free of sequential correlation on successive calls. If k random numbers at a time are used to plot points in k dimensional space (with each coordinate between 0 and 1), then the points will not tend to ""fill up"" the k -dimensional space, but rather will lie on (k - 1)-dimensional ""planes."" There will be at most about m 1/k such planes. If the constants m, a, and c are not very carefully chosen, there will be many fewer than that. If m is as bad as 32768, then the number of planes on which triples of points lie in three-dimensional space will be no greater than about the cube root of 32768, or 32. Even if m is close to the machine's largest representable integer, e.g.,  232 , the number of planes on which triples of points lie in three-dimensional space is usually no greater than about the cube root of 2 32 , about 1600. You might well be focusing attention on a physical process that occurs in a small fraction of the total volume, so that the discreteness of the planes can be very pronounced. Even worse, you might be using a generator whose choices of m, a, and c have been botched. One infamous such routine, RANDU, with a = 65539 and m = 2 31 , was widespread on IBM mainframe computers for many years, and widely copied onto other systems [1 ]. One of us recalls producing a ""random"" plot with only 11 planes, and being told by his computer center's programming consultant that he had misused the random number generator: ""We guarantee that each number is random individually, but we don't guarantee that more than one of them is random."" Figure that out. Correlation in k -space is not the only weakness of linear congruential generators. Such generators often have their low-order (least significant) bits much less random than their high-order bits. If you want to generate a random integer between 1 and 10, you should always do it using high-order bits, as in j=1+(int) (10.0*rand()/(RAND_MAX+1.0));  Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  and never by anything resembling j=1+(rand() % 10);  (which uses lower-order bits). Similarly you should never try to take apart a ""rand()"" number into several supposedly random pieces. Instead use separate calls for every piece.   278  Chapter 7.  Random Numbers  Portable Random Number Generators Park and Miller [1 ] have surveyed a large number of random number generators that have been used over the last 30 years or more. Along with a good theoretical review, they present an anecdotal sampling of a number of inadequate generators that have come into widespread use. The historical record is nothing if not appalling. There is good evidence, both theoretical and empirical, that the simple multiplicative congruential algorithm Ij +1  Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  = aIj  (mod m)  (7.1.2)  can be as good as any of the more general linear congruential generators that have c = 0 (equation 7.1.1) -- if the multiplier a and modulus m are chosen exquisitely carefully. Park and Miller propose a ""Minimal Standard"" generator based on the choices a = 75 = 16807 m=2 31  - 1 = 2147483647  (7.1.3)  First proposed by Lewis, Goodman, and Miller in 1969, this generator has in subsequent years passed all new theoretical tests, and (perhaps more importantly) has accumulated a large amount of successful use. Park and Miller do not claim that the generator is ""perfect"" (we will see below that it is not), but only that it is a good minimal standard against which other generators should be judged. It is not possible to implement equations (7.1.2) and (7.1.3) directly in a high-level language, since the product of a and m - 1 exceeds the maximum value for a 32-bit integer. Assembly language implementation using a 64-bit product register is straightforward, but not portable from machine to machine. A trick due to Schrage [2,3 ] for multiplying two 32-bit integers modulo a 32-bit constant, without using any intermediates larger than 32 bits (including a sign bit) is therefore extremely interesting: It allows the Minimal Standard generator to be implemented in essentially any programming language on essentially any machine. Schrage's algorithm is based on an approximate factorization of m, m = aq + r, i.e., q = [m/a], r = m mod a (7.1.4)  with square brackets denoting integer part. If r is small, specifically r < q , and 0 < z < m - 1, it can be shown that both a(z mod q ) and r[z/q ] lie in the range 0,... ,m - 1, and that az mod m = a(z mod q ) - r[z/q ] a(z mod q ) - r[z/q ]+ m if it is  0, otherwise (7.1.5)  The application of Schrage's algorithm to the constants (7.1.3) uses the values q = 127773 and r = 2836. Here is an implementation of the Minimal Standard generator:   7.1 Uniform Deviates  279  #define #define #define #define #define #define  IA 16807 IM 2147483647 AM (1.0/IM) IQ 127773 IR 2836 MASK 123459876 Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  float ran0(long *idum) ""Minimal"" random number generator of Park and Miller. Returns a uniform random deviate between 0.0 and 1.0. Set or reset idum to any integer value (except the unlikely value MASK) to initialize the sequence; idum must not be altered between calls for successive deviates in a sequence. { long k; float ans; *idum ^= MASK; k=(*idum)/IQ; *idum=IA*(*idum-k*IQ)-IR*k; if (*idum < 0) *idum += IM; ans=AM*(*idum); *idum ^= MASK; return ans; } XORing with MASK allows use of zero and other simple bit patterns for idum. Compute idum=(IA*idum) % IM without overflows by Schrage's method. Convert idum to a floating result. Unmask before return.  The period of ran0 is 2 31 - 2  2.1  109 . A peculiarity of generators of the form (7.1.2) is that the value 0 must never be allowed as the initial seed -- it perpetuates itself -- and it never occurs for any nonzero initial seed. Experience has shown that users always manage to call random number generators with the seed idum=0. That is why ran0 performs its exclusive-or with an arbitrary constant both on entry and exit. If you are the first user in history to be proof against human error, you can remove the two lines with the  operation. Park and Miller discuss two other multipliers a that can be used with the same m = 231 - 1. These are a = 48271 (with q = 44488 and r = 3399) and a = 69621 (with q = 30845 and r = 23902). These can be substituted in the routine ran0 if desired; they may be slightly superior to Lewis et al.'s longer-tested values. No values other than these should be used. The routine ran0 is a Minimal Standard, satisfactory for the majority of applications, but we do not recommend it as the final word on random number generators. Our reason is precisely the simplicity of the Minimal Standard. It is not hard to think of situations where successive random numbers might be used in a way that accidentally conflicts with the generation algorithm. For example, since successive numbers differ by a multiple of only 1.6  10 4 out of a modulus of more than 2  10 9 , very small random numbers will tend to be followed by smaller than average values. One time in 10 6 , for example, there will be a value < 10 -6 returned (as there should be), but this will always be followed by a value less than about 0.0168. One can easily think of applications involving rare events where this property would lead to wrong results. There are other, more subtle, serial correlations present in ran0. For example, if successive points (Ii ,Ii+1 ) are binned into a two-dimensional plane for i = 1, 2,... ,N , then the resulting distribution fails the  2 test when N is greater than a few 107 , much less than the period m - 2. Since low-order serial correlations have historically been such a bugaboo, and since there is a very simple way to remove   280  Chapter 7.  Random Numbers  them, we think that it is prudent to do so. The following routine, ran1, uses the Minimal Standard for its random value, but it shuffles the output to remove low-order serial correlations. A random deviate derived from the j th value in the sequence, I j , is output not on the j th call, but rather on a randomized later call, j +32 on average. The shuffling algorithm is due to Bays and Durham as described in Knuth [4 ], and is illustrated in Figure 7.1.1. #define #define #define #define #define #define #define #define #define IA 16807 IM 2147483647 AM (1.0/IM) IQ 127773 IR 2836 NTAB 32 NDIV (1+(IM-1)/NTAB) EPS 1.2e-7 RNMX (1.0-EPS)  Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  float ran1(long *idum) ""Minimal"" random number generator of Park and Miller with Bays-Durham shuffle and added safeguards. Returns a uniform random deviate between 0.0 and 1.0 (exclusive of the endpoint values). Call with idum a negative integer to initialize; thereafter, do not alter idum between successive deviates in a sequence. RNMX should approximate the largest floating value that is less than 1. { int j; long k; static long iy=0; static long iv[NTAB]; float temp; if (*idum <= 0 || !iy) { if (-(*idum) < 1) *idum=1; else *idum = -(*idum); for (j=NTAB+7;j>=0;j--) { k=(*idum)/IQ; *idum=IA*(*idum-k*IQ)-IR*k; if (*idum < 0) *idum += IM; if (j < NTAB) iv[j] = *idum; } iy=iv[0]; } k=(*idum)/IQ; *idum=IA*(*idum-k*IQ)-IR*k; if (*idum < 0) *idum += IM; j=iy/NDIV; iy=iv[j]; iv[j] = *idum; if ((temp=AM*iy) > RNMX) return RNMX; else return temp; } Initialize. Be sure to prevent idum = 0. Load the shuffle table (after 8 warm-ups).  Start here when not initializing. Compute idum=(IA*idum) % IM without overflows by Schrage's method. Will be in the range 0..NTAB-1 . Output previously stored value and refill the shuffle table. Because users don't expect endpoint values.  The routine ran1 passes those statistical tests that ran0 is known to fail. In fact, we do not know of any statistical test that ran1 fails to pass, except when the number of calls starts to become on the order of the period m, say > 10 8  m/20. For situations when even longer random sequences are needed, L'Ecuyer [6 ] has given a good way of combining two different sequences with different periods so as to obtain a new sequence whose period is the least common multiple of the two periods. The basic idea is simply to add the two sequences, modulo the modulus of   7.1 Uniform Deviates  281  iy  1 Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  iv  0  OUTPUT  RAN  3  2  iv  31  Figure 7.1.1. Shuffling procedure used in ran1 to break up sequential correlations in the Minimal Standard generator. Circled numbers indicate the sequence of events: On each call, the random number in iy is used to choose a random element in the array iv. That element becomes the output random number, and also is the next iy. Its spot in iv is refilled from the Minimal Standard routine.  either of them (call it m). A trick to avoid an intermediate value that overflows the integer wordsize is to subtract rather than add, and then add back the constant m - 1 if the result is  0, so as to wrap around into the desired interval 0,... ,m - 1. Notice that it is not necessary that this wrapped subtraction be able to reach all values 0,... ,m - 1 from every value of the first sequence. Consider the absurd extreme case where the value subtracted was only between 1 and 10: The resulting sequence would still be no less random than the first sequence by itself. As a practical matter it is only necessary that the second sequence have a range covering substantially all of the range of the first. L'Ecuyer recommends the use of the two generators m1 = 2147483563 (with a1 = 40014, q1 = 53668, r1 = 12211) and m2 = 2147483399 (with a2 = 40692, q2 = 52774, r2 = 3791). Both moduli are slightly less than 231 . The periods m 1 - 1 = 2  3  7  631  81031 and m2 - 1 = 2  19  31  1019  1789 share only the factor 2, so the period of the combined generator is  2.3  10 18 . For present computers, period exhaustion is a practical impossibility. Combining the two generators breaks up serial correlations to a considerable extent. We nevertheless recommend the additional shuffle that is implemented in the following routine, ran2. We think that, within the limits of its floating-point precision, ran2 provides perfect random numbers; a practical definition of ""perfect"" is that we will pay $1000 to the first reader who convinces us otherwise (by finding a statistical test that ran2 fails in a nontrivial way, excluding the ordinary limitations of a machine's floating-point representation).   282 #define #define #define #define #define #define #define #define #define #define #define #define #define #define IM1 2147483563 IM2 2147483399 AM (1.0/IM1) IMM1 (IM1-1) IA1 40014 IA2 40692 IQ1 53668 IQ2 52774 IR1 12211 IR2 3791 NTAB 32 NDIV (1+IMM1/NTAB) EPS 1.2e-7 RNMX (1.0-EPS)  Chapter 7.  Random Numbers  Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  float ran2(long *idum) Long period (> 2  1018 ) random number generator of L'Ecuyer with Bays-Durham shuffle and added safeguards. Returns a uniform random deviate between 0.0 and 1.0 (exclusive of the endpoint values). Call with idum a negative integer to initialize; thereafter, do not alter idum between successive deviates in a sequence. RNMX should approximate the largest floating value that is less than 1. { int j; long k; static long idum2=123456789; static long iy=0; static long iv[NTAB]; float temp; if (*idum <= 0) { if (-(*idum) < 1) *idum=1; else *idum = -(*idum); idum2=(*idum); for (j=NTAB+7;j>=0;j--) { k=(*idum)/IQ1; *idum=IA1*(*idum-k*IQ1)-k*IR1; if (*idum < 0) *idum += IM1; if (j < NTAB) iv[j] = *idum; } iy=iv[0]; } k=(*idum)/IQ1; *idum=IA1*(*idum-k*IQ1)-k*IR1; if (*idum < 0) *idum += IM1; k=idum2/IQ2; idum2=IA2*(idum2-k*IQ2)-k*IR2; if (idum2 < 0) idum2 += IM2; j=iy/NDIV; iy=iv[j]-idum2; iv[j] = *idum; if (iy < 1) iy += IMM1; if ((temp=AM*iy) > RNMX) return RNMX; else return temp; } Initialize. Be sure to prevent idum = 0. Load the shuffle table (after 8 warm-ups).  Start here when not initializing. Compute idum=(IA1*idum) % IM1 without overflows by Schrage's method. Compute idum2=(IA2*idum) % IM2 likewise. Will be in the range 0..NTAB-1 . Here idum is shuffled, idum and idum2 are combined to generate output. Because users don't expect endpoint values.  L'Ecuyer [6 ] lists additional short generators that can be combined into longer ones, including generators that can be implemented in 16-bit integer arithmetic. Finally, we give you Knuth's suggestion [4 ] for a portable routine, which we have translated to the present conventions as ran3. This is not based on the linear congruential method at all, but rather on a subtractive method (see also [5 ]). One might hope that its weaknesses, if any, are therefore of a highly different character   7.1 Uniform Deviates  283  from the weaknesses, if any, of ran1 above. If you ever suspect trouble with one routine, it is a good idea to try the other in the same application. ran3 has one nice feature: if your machine is poor on integer arithmetic (i.e., is limited to 16-bit integers), you can declare mj, mk, and ma[] as float, define mbig and mseed as 4000000 and 1618033, respectively, and the routine will be rendered entirely floating-point. #include   Change to math.h in K&R C. #define MBIG 1000000000 #define MSEED 161803398 #define MZ 0 #define FAC (1.0/MBIG) According to Knuth, any large MBIG, and any smaller (but still large) MSEED can be substituted for the above values. float ran3(long *idum) Returns a uniform random deviate between 0.0 and 1.0. Set idum to any negative value to initialize or reinitialize the sequence. { static int inext,inextp; static long ma[56]; The value 56 (range ma[1..55] ) is special and should not be modified; see Knuth. static int iff=0; long mj,mk; int i,ii,k; if (*idum < 0 || iff == 0) { Initialization. iff=1; mj=labs(MSEED-labs(*idum)); Initialize ma[55] using the seed idum and the mj %= MBIG; large number MSEED. ma[55]=mj; mk=1; for (i=1;i<=54;i++) { Now initialize the rest of the table, ii=(21*i) % 55; in a slightly random order, ma[ii]=mk; with numbers that are not especially random. mk=mj-mk; if (mk < MZ) mk += MBIG; mj=ma[ii]; } for (k=1;k<=4;k++) We randomize them by ""warming up the generfor (i=1;i<=55;i++) { ator."" ma[i] -= ma[1+(i+30) % 55]; if (ma[i] < MZ) ma[i] += MBIG; } inext=0; Prepare indices for our first generated number. inextp=31; The constant 31 is special; see Knuth. *idum=1; } Here is where we start, except on initialization. if (++inext == 56) inext=1; Increment inext and inextp, wrapping around if (++inextp == 56) inextp=1; 56 to 1. mj=ma[inext]-ma[inextp]; Generate a new random number subtractively. if (mj < MZ) mj += MBIG; Be sure that it is in range. Store it, ma[inext]=mj; and output the derived uniform deviate. return mj*FAC; }  Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  Quick and Dirty Generators One sometimes would like a ""quick and dirty"" generator to embed in a program, perhaps taking only one or two lines of code, just to somewhat randomize things. One might wish to   284  Chapter 7.  Random Numbers  process data from an experiment not always in exactly the same order, for example, so that the first output is more ""typical"" than might otherwise be the case. For this kind of application, all we really need is a list of ""good"" choices for m, a, and c in equation (7.1.1). If we don't need a period longer than 104 to 106 , say, we can keep the value of (m - 1)a + c small enough to avoid overflows that would otherwise mandate the extra complexity of Schrage's method (above). We can thus easily embed in our programs Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  unsigned long jran,ia,ic,im; float ran; ... jran=(jran*ia+ic) % im; ran=(float) jran / (float) im;  whenever we want a quick and dirty uniform deviate, or jran=(jran*ia+ic) % im; j=jlo+((jhi-jlo+1)*jran)/im;  whenever we want an integer between jlo and jhi, inclusive. (In both cases jran was once initialized to any seed value between 0 and im-1.) Be sure to remember, however, that when im is small, the kth root of it, which is the number of planes in k-space, is even smaller! So a quick and dirty generator should never be used to select points in k-space with k > 1. With these caveats, some ""good"" choices for the constants are given in the accompanying table. These constants (i) give a period of maximal length im, and, more important, (ii) pass Knuth's ""spectral "" for dimensions 2, 3, 4, 5, and 6. The increment ic is a prime, close to test the value ( 1 - 1 3)im; actually almost any value of ic that is relatively prime to im will do 2 6 just as well, but there is some ""lore"" favoring this choice (see [4 ], p. 84).  An Even Quicker Generator In C, if you multiply two unsigned long int integers on a machine with a 32-bit long integer representation, the value returned is the low-order 32 bits of the true 64-bit product. If we now choose m = 232 , the ""mod"" in equation (7.1.1) is free, and we have simply I j +1  = aIj + c  (7.1.6)  Knuth suggests a = 1664525 as a suitable multiplier for this value of m. H.W. Lewis has  conducted extensive tests of this value of a with c = 1013904223, which is a prime close to ( 5 - 2)m. The resulting in-line generator (we will call it ranqd1) is simply unsigned long idum; ... idum = 1664525L*idum + 1013904223L;  This is about as good as any 32-bit linear congruential generator, entirely adequate for many uses. And, with only a single multiply and add, it is very fast. To check whether your machine has the desired integer properties, see if you can generate the following sequence of 32-bit values (given here in hex): 00000000, 3C6EF35F, 47502932, D1CCF6E9, AAF95334, 6252E503, 9F2EC686, 57FE6C2D, A3D95FA8, 81FDBEE7, 94F0AF1A, CBF633B1. If you need floating-point values instead of 32-bit integers, and want to avoid a divide by floating-point 232 , a dirty trick is to mask in an exponent that makes the value lie between 1 and 2, then subtract 1.0. The resulting in-line generator (call it ranqd2) will look something like   7.1 Uniform Deviates  285  Constants for Quick and Dirty Random Number Generators overflow at 220 221 222 im 6075 7875 7875 ia 106 211 421 ic 1283 1663 1663 1283 1399 2531 228 227 overflow at im ia ic 18257 25673 54773 24749 25673 66037 30809 36979 49297 51749  86436 1093 121500 1021 259200 421 117128 1277 121500 2041 312500 741 145800 175000 233280 244944 3661 2661 1861 1597  Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  223  6075 1366 6655 936 11979 430 14406 29282 53125  2  24  967 3041 419 6173 171 11213  229  225  12960 1741 2731 14000 1541 2957 21870 1291 4621 31104 625 6571 139968 205 29573 29282 1255 6173 81000 421 17117 134456 281 28411  230 231 232  139968 3877 29573 214326 3613 45289 714025 1366 150889 134456 8121 259200 7141 28411 54773  233280 9301 49297 714025 4096 150889  2  26  unsigned long idum,itemp; float rand; #ifdef vax static unsigned long jflone = 0x00004080; static unsigned long jflmsk = 0xffff007f; #else static unsigned long jflone = 0x3f800000; static unsigned long jflmsk = 0x007fffff; #endif ... idum = 1664525L*idum + 1013904223L; itemp = jflone | (jflmsk & idum); rand = (*(float *)&itemp)-1.0;  The hex constants 3F800000 and 007FFFFF are the appropriate ones for computers using the IEEE representation for 32-bit floating-point numbers (e.g., IBM PCs and most UNIX workstations). For DEC VAXes, the correct hex constants are, respectively, 00004080 and FFFF007F. Notice that the IEEE mask results in the floating-point number being constructed out of the 23 low-order bits of the integer, which is not ideal. (Your authors have tried very hard to make almost all of the material in this book machine and compiler independent -- indeed, even programming language independent. This subsection is a rare aberration. Forgive us. Once in a great while the temptation to be really dirty is just irresistible.)  Relative Timings and Recommendations Timings are inevitably machine dependent. Nevertheless the following table   286  Chapter 7.  Random Numbers  is indicative of the relative timings, for typical machines, of the various uniform generators discussed in this section, plus ran4 from 7.5. Smaller values in the table indicate faster generators. The generators ranqd1 and ranqd2 refer to the ""quick and dirty"" generators immediately above. Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  Generator ran0 ran1 ran2 ran3 ranqd1 ranqd2 ran4  Relative Execution Time  1.0  1.3  2.0  0.6  0.10  0.25  4.0  On balance, we recommend ran1 for general use. It is portable, based on Park and Miller's Minimal Standard generator with an additional shuffle, and has no known (to us) flaws other than period exhaustion. If you are generating more than 100,000,000 random numbers in a single calculation (that is, more than about 5% of ran1's period), we recommend the use of ran2, with its much longer period. Knuth's subtractive routine ran3 seems to be the timing winner among portable routines. Unfortunately the subtractive method is not so well studied, and not a standard. We like to keep ran3 in reserve for a ""second opinion,"" substituting it when we suspect another generator of introducing unwanted correlations into a calculation. The routine ran4 generates extremely good random deviates, and has some other nice properties, but it is slow. See 7.5 for discussion. Finally, the quick and dirty in-line generators ranqd1 and ranqd2 are very fast, but they are somewhat machine dependent, and at best only as good as a 32-bit linear congruential generator ever is -- in our view not good enough in many situations. We would use these only in very special cases, where speed is critical.  CITED REFERENCES AND FURTHER READING: Park, S.K., and Miller, K.W. 1988, Communications of the ACM, vol. 31, pp. 11921201. [1] Schrage, L. 1979, ACM Transactions on Mathematical Software, vol. 5, pp. 132138. [2] Bratley, P., Fox, B.L., and Schrage, E.L. 1983, A Guide to Simulation (New York: SpringerVerlag). [3] Knuth, D.E. 1981, Seminumerical Algorithms, 2nd ed., vol. 2 of The Ar t of Computer Programming (Reading, MA: Addison-Wesley), 3.23.3. [4] Kahaner, D., Moler, C., and Nash, S. 1989, Numerical Methods and Software (Englewood Cliffs, NJ: Prentice Hall), Chapter 10. [5] L'Ecuyer, P. 1988, Communications of the ACM, vol. 31, pp. 742774. [6] Forsythe, G.E., Malcolm, M.A., and Moler, C.B. 1977, Computer Methods for Mathematical Computations (Englewood Cliffs, NJ: Prentice-Hall), Chapter 10.   7.2 Transformation Method: Exponential and Normal Deviates  287  7.2 Transformation Method: Exponential and Normal Deviates In the previous section, we learned how to generate random deviates with a uniform probability distribution, so that the probability of generating a number between x and x + dx, denoted p(x)dx, is given by p(x)dx = dx 0 0  float expdev(long *idum) Returns an exponentially distributed, positive, ran1(idum) as the source of uniform deviates. { float ran1(long *idum); float dum; do dum=ran1(idum); while (dum == 0.0); return -log(dum); } random deviate of unit mean, using"
GX257-49-9254980	"DOE-HDBK-1014/1-92 JUNE 1992  DOE FUNDAMENTALS HANDBOOK MATHEMATICS Volume 1 of 2  U.S. Department of Energy Washington, D.C. 20585  FSC-6910  Distribution Statement A. Approved for public release; distribution is unlimited.   This document has been reproduced directly from the best available copy. Availab le to DOE and DOE contractors from the Office of Scientific and Technical Information. P. O. Box 62, Oak Ridge, TN 37831; (615) 576-8401. Available to the public from the National Technical Information Service, U.S. Department of Commerce, 5285 Port Royal Rd., Springfield, VA 22161. Order No. DE92019794   MATHEMATICS  ABSTRACT  The Mathematics Fundamentals Handbook was developed to assist nuclear facility operating contractors provide operators, maintenance personnel, and the technical staff with the necessary fundamentals training to ensure a basic understanding of mathematics and its application to facility operation. The handbook includes a review of introductory mathematics and t he co ncepts and functional use of algebra, geometry, trigonometry, and calculus. Word problems, equations, calculations, and practical exercises that require the use of each of the mat hematical concepts are also presented. This information will provide personnel with a foundation for understanding and performing basic mathematical calculations that are associated with various DOE nuclear facility operations.  Key Words: Training Material, Mathematics, Algebra, Geometry, Trigonometry, Calculus  Rev. 0  MA   blank   MATHEMATICS  FOREWORD  The Department of Energy (DOE) Fundamentals Handbooks consist of ten academic subjects, which include Mathematics; Classical Physics; Thermodynamics, Heat Transfer, and Fluid Flow; Instrumentation and Control; Electrical Science; Material Science; Mechanical Science; Chemist ry; Engineering Symbology, Prints, and Drawings; and Nuclear Physics and Reactor Theory. The handbooks are provided as an aid to DOE nuclear facility contractors. These handbooks were first published as Reactor Operator Fundamentals Manuals in 1985 for use by DOE category A reactors. The subject areas, subject matter content, and level of detail o f the Reactor Operator Fundamentals Manuals were determined from several sources. DOE Category A reactor training managers determined which materials should be included, and served as a primary reference in the initial development phase. Training guidelines from the commercial nuclear power industry, results of job and task analyses, and independent input from contractors and operations-oriented personnel were all considered and included to some degree in developing the text material and learning objectives. The DOE Fundamentals Handbooks represent the needs of various DOE nuclear facilities' fundamental training requirements. To increase their applicability to nonreactor nuclear facilities, the Reactor Operator Fundamentals Manual learning objectives were distributed to the Nuclear Facility Training Coordination Program Steering Committee for review and comment. To update t heir reactor-specific content, DOE Category A reactor training managers also reviewed and commented on the content. On the basis of feedback from these sources, information that applied to two or more DOE nuclear facilities was considered generic and was included. The final draft of each of the handbooks was then reviewed by these two groups. This approach has resulted in revised modular handbooks that contain sufficient detail such that each facility may adjust the content to fit their specific needs. Each handbook contains an abstract, a foreword, an overview, learning objectives, and text material, and is divided into modules so that content and order may be modified by individual DOE co ntractors to suit their specific training needs. Each subject area is supported by a separate examination bank with an answer key. The DOE Fundamentals Handbooks have been prepared for the Assistant Secretary for Nuclear Energy, Office of Nuclear Safety Policy and Standards, by the DOE Training Coordination Program. This program is managed by EG&G Idaho, Inc.  Rev. 0  MA   blank   MATHEMATICS  OVERVIEW  The Department of Energy Fundamentals Handbook entitled Mathematics was prepared as an information resource for personnel who are responsible for the operation of the Depart ment's nuclear facilities. A basic understanding of mathematics is necessary for DOE nuclear facility operators, maintenance personnel, and the technical staff to safely operate and maintain the facility and facility support systems. The information in the handbook is presented to provide a foundation for applying engineering concepts to the job. This knowledge will help personnel more fully understand the impact that their actions may have on the safe and reliable operation of facility components and systems. The Mathematics handbook consists of five modules that are contained in two volumes. The fo llo wing is a brief description of the information presented in each module of the handbook. Volume 1 of 2 Module 1 - Review of Introductory Mathematics This module describes the concepts of addition, subtraction, multiplication, and division involving whole numbers, decimals, fractions, exponents, and radicals. A review of basic calculator operation is included. Module 2 - Algebra This module describes the concepts of algebra including quadratic equations and word problems. Volume 2 of 2 Module 3 - Geometry This module describes the basic geometric figures of triangles, quadrilaterals, and circles; and the calculation of area and volume. Module 4 - Trigonometry This module describes the trigonometric functions of sine, cosine, tangent, cotangent, secant, and cosecant. The use of the pythagorean theorem is also discussed.  Rev. 0  MA   blank   MATHEMATICS  Module 5 - Higher Concepts of Mathematics This module describes logarithmic functions, statistics, complex numbers, imaginary numbers, matrices, and integral and derivative calculus. The information contained in this handbook is by no means all encompassing. An attempt t o present the entire subject of mathematics would be impractical. However, the Mathematics handbook does present enough information to provide the reader with a fundamental knowledge level sufficient to understand the advanced theoretical concepts presented in other subject areas, and to better understand basic system and equipment operations.  Rev. 0  MA   blank   Department of Energy Fundamentals Handbook  MATHEMATICS Module 1 Review of Introductory Mathematics    Review of Introductory Mathematics  TABLE OF CONTENTS  TABLE OF CONTENTS LIST OF FIGURES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iv LIST OF TABLES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . v REFERENCES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vi OBJECTIVES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vii TERMINOLOGY . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 CALCULATOR OPERATIONS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 FOUR BASIC ARITHMETIC OPERATIONS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 Calculator Usage, Special Keys . . . . . The Decimal Numbering System . . . . Adding Whole Numbers . . . . . . . . . . Subtracting Whole Numbers . . . . . . . Multiplying Whole Numbers . . . . . . Dividing Whole Numbers . . . . . . . . . Hierarchy of Mathematical Operations Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6 6 7 9 11 13 16 19  AVERAGES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 Average Value . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 FRACTIONS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 Proper and Improper Fractions . . . . . . . . Equivalent Fractions . . . . . . . . . . . . . . . Addition and Subtraction of Fractions . . . Least Common Denominator Using Primes Addition and Subtraction . . . . . . . . . . . . Multiplication . . . . . . . . . . . . . . . . . . . . Division . . . . . . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 25 26 31 33 34 34 37  Rev. 0  Page i  MA-01   TABLE OF CONTENTS  Review of Introductory Mathematics  TABLE OF CONTENTS (Cont.) DECIMALS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 Fraction to Decimal Conversion . . . Decimal to Fraction Conversion . . . Addition and Subtraction of Decimals Multiplying Decimals . . . . . . . . . . . Dividing Decimals . . . . . . . . . . . . . Rounding Off . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . ... ... .. ... ... ... ... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 40 42 42 43 44 47  SIGNED NUMBERS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 Calculator Usage, Addition . . . . . . Subtraction . . . . Multiplication . . Division . . . . . . Summary . . . . . Special ...... ...... ...... ...... ...... Keys .... .... .... .... .... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48 48 50 51 51 52  SIGNIFICANT DIGITS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 Calculator Usage, Special Keys . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 Significant Digits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 PERCENTAGES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56 Calculator Usage, Special Keys . Changing Decimals to Percent . . Changing Common Fractions and Changing a Percent to a Decimal Percent Differential . . . . . . . . . Ratio . . . . . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . ..... ..... Whole ..... ..... ..... ..... ....... ....... Numbers ....... ....... ....... ....... .. .. to .. .. .. .. ...... ...... Percent ...... ...... ...... ...... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56 56 57 57 58 59 60  MA-01  Page ii  Rev. 0   Review of Introductory Mathematics  TABLE OF CONTENTS  TABLE OF CONTENTS (Cont.) EXPONENTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61 Calculator Usage, Special Keys Exponents . . . . . . . . . . . . . . . Basic Rules for Exponents . . . Zero Exponents . . . . . . . . . . . Negative Exponents . . . . . . . . Fractional Exponents . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61 61 62 64 64 65 66  SCIENTIFIC NOTATION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 Calculator Usage . . . . . . . . . Writing Numbers in Scientific Converting Scientific Notation Addition . . . . . . . . . . . . . . . Subtraction . . . . . . . . . . . . . Multiplication . . . . . . . . . . . Division . . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . ........ Notation . to Integers ........ ........ ........ ........ ........ ... ... .. ... ... ... ... ... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 67 69 70 71 71 72 73  RADICALS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 Calculator Usage, Special Keys The Radical . . . . . . . . . . . . . Simplifying Radicals . . . . . . . Addition and Subtraction . . . . Multiplication . . . . . . . . . . . . Division . . . . . . . . . . . . . . . . Dissimilar Radicals . . . . . . . . Changing Radicals to Exponents Changing Exponents to Radicals Summary . . . . . . . . . . . . . . . Appendix A TI-30 Calculator Keypad Layout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A-1 . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 74 75 76 76 76 77 77 78 79  Rev. 0  Page iii  MA-01   LIST OF FIGURES  Review of Introductory Mathematics  LIST OF FIGURES Figure 1 TI-30 Keyboard Layout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . A-1  MA-01  Page iv  Rev. 0   Review of Introductory Mathematics  LIST OF TABLES  LIST OF TABLES NONE  Rev. 0  Page v  MA-01   REFERENCES  Review of Introductory Mathematics  REFERENCES Dolciani, Mary P., et al., Algebra Structure and Method Book 1, Atlanta: HoughtonMifflin, 1979. Naval Education and Training Command, Mathematics, Vol:1, NAVEDTRA 10069-D1, Washington, D.C.: Naval Education and Training Program Development Center, 1985. Olivio, C. Thomas and Olivio, Thomas P., Basic Mathematics Simplified, Albany, NY: Delmar, 1977. Science and Fundamental Engineering, Windsor, CT: Combustion Engineering, Inc., 1985. Academic Program For Nuclear Power Plant Personnel, Volume 1, Columbia, MD: General Physics Corporation, Library of Congress Card #A 326517, 1982.  MA-01  Page vi  Rev. 0   Review of Introductory Mathematics  OBJECTIVES  TERMINAL OBJECTIVE 1.0 Given a basic mathematical problem, SOLVE for the answer with or without the aid of a calculator.  ENABLING OBJECTIVES 1.1 IDENTIFY the following basic mathematical symbols and definitions. a. = equals b.  is not equal to c.  is defined as d. + plus or minus e. f. g. h. i. j. k. l. m. n. o. p. q. r. s. 1.2 n  a a N x i  nth root of a absolute value of a sum of N values angle percent multiplied by divided by greater than or equal to less than or equal to is not equal to (computer) infinity is proportional to approximately equal to perpendicular to parallel to  i1  % x, , * , / > < ><, <>      APPLY one of the arithmetic operations of addition, subtraction, multiplication, and division using whole numbers. Given a set of numbers, CALCULATE the average value. APPLY one of the arithmetic operations of addition, subtraction, multiplication, and division using fractions. APPLY one of the arithmetic operations of addition, subtraction, multiplication, and division of fractions by conversion to decimal form using a calculator.  1.3 1.4  1.5  Rev. 0  Page vii  MA-01   OBJECTIVES  Review of Introductory Mathematics  ENABLING OBJECTIVES (Cont.) 1.6 APPLY one of the arithmetic operations of addition, subtraction, multiplication, and division using decimals. APPLY one of the arithmetic operations of addition, subtraction, multiplication, and division using signed numbers. DETERMINE the number of significant digits in a given number. Given a formula, CALCULATE the answer with the appropriate number of significant digits. CONVERT between percents, decimals, and fractions. CALCULATE the percent differential. APPLY one of the arithmetic operations of addition, subtraction, multiplication, and division using exponential numbers. Given the data, CONVERT integers into scientific notation and scientific notation into integers. APPLY one of the arithmetic operations of addition, subtraction, multiplication, and division to numbers using scientific notation. CALCULATE the numerical value of numbers in radical form.  1.7  1.8 1.9  1.10 1.11 1.12  1.13  1.14  1.15  MA-01  Page viii  Rev. 0   Review of Introductory Mathematics  TERMINOLOGY  TERMINOLOGY This chapter reviews the terminology and associated symbols used in mathematics. EO 1.1 a. b. c. d. e. f. g. h. i. j.  % x, , * IDENTIFY the following symbols and definitions. = equals  is not equal to  is defined as  plus or minus n  basic mathematical k. l. m. n. , / > < ><, <>     divided by greater than or equal to less than or equal to is not equal to (computer) infinity is proportional to approximately equal to perpendicular to parallel to  a a  nth root of a absolute value of a o. sum of N values angle percent multiplied by p. q. r. s.  In order to understand and communicate in mathematical terms and to lay the foundation for the concepts and principles presented in this material, certain terms and expressions must be defined. This section covers basic definitions used in mathematics. Once understood, such knowledge should provide the foundation from which the principles of mathematics can be presented. By no means are the terms here all inclusive; they are representative of those found within the nuclear field. Equals An expression indicating values which are identical in mathematical value or logical denotation. It is given the symbol =. Is Not Equal to An expression indicating values which are not identical in mathematical value or logical denotation. It is given the symbol  or ><, >< (computer).  Rev. 0  Page 1  MA-01   TERMINOLOGY  Review of Introductory Mathematics  Is defined as A mathematical expression for defining a symbol or variable in mathematics. It is usually given the symbol  . Plus or Minus While plus (+) and minus (-) are used individually to indicate addition and subtraction, this form is used to denote a control band, or tolerance band, or error band, such as 100 + 5 psig. It is given the symbol +. nth root For any integer (n greater than one), the nth root ( a ) of a is defined as follows: = b if, root of of b is equals n n n  a  and only if, bn = a. The number n, in a , is called the index of the root. The nth a number (a) is a number (b) which has the property that the product of n values a. For example, the third (or cube) root of 8 is 2, because 2x2x2 8.  Absolute Value of a This expression represents the signifies the distance from zero because -6 is 6 units from zero. is 6 units from zero. It is given Sum of N values  magnitude of a variable without regard to its sign. It on a number line. That is, the absolute value of -6 is 6 Likewise, the absolute value of +6 is 6 because it, too, the symbol A where A is any number or variable.  xi indicates the sum of numbered (indexed) values. For example, if the xi are grades for the individual students in a class, the sum of the xi (grades) for the students in the class of N students, divided by N, gives the average grade. Angle An angle is a set of points consisting of two rays with a common midpoint. It is given the symbol  . Percent An expression used to indicate a fraction of the whole, such as 50% of 90 is 45. It is given the symbol %. Multiplied by A mathematical operation that, at its simplest, is an abbreviated process of adding an integer to itself a specified number of times. It is given the symbols x, , or * (computer).  MA-01  Page 2  Rev. 0   Review of Introductory Mathematics  TERMINOLOGY  Divided by A mathematical process that subjects a number to the operation of finding out how many times it contains another number. It is given the symbol  or /. Greater than or equal to It is given the symbol >, and denotes one quantity is equal to or larger than another. Less than or equal to It is given the symbol <, and denotes one quantity is equal to or smaller than another. Infinity A mathematical expression meaning very large in magnitude or distance. It is so large that it cannot be measured. It is given the symbol  . Is Proportional to The statement that a is proportionl to b (a  b) means that a = (some constant) x b. For example, the dollars you earn in a week (straight rate) are proportional to the hours you work, with the constant being the dollars per hour you earn. Approximately Equal to An expression indicating a value which is not exact, but rather close to the value. It is given the symbol . Perpendicular to This expression means that two objects are at right angles (form a 90-degree angle) to each other. It is given the symbol  . Parallel to Two lines extending in the same direction which are everywhere equidistant and not meeting. It is given the symbol .  Summary The important information from this chapter is summarized below.  Terminology Summary This chapter reviewed the terminology needed in the application and study of mathematics.  Rev. 0  Page 3  MA-01   CALCULATOR OPERATIONS  Review of Introductory Mathematics  CALCULATOR OPERATIONS This chapter gives the student a chance to reacquaint himself with basic calculator operations.  The teaching of the ""mechanics of mathematics"" (division, multiplication, logarithms, etc.) in recent years has focused more on the skills of using a calculator than on the pure principles of the basic subject material. With the decreased cost of hand calculators, virtually every person owns, or has access to, a calculator. A nuclear plant operator would be wise to learn how to use most of the calculators available today. Such knowledge will help the operator make quick decisions when circumstances arise for the need of a ""quick calculation"" of flow rate or some other parameter. Many calculators are available on the market today, and each one is a little different. For the purpose of this module, a scientific calculator will be needed. The Texas Instruments scientific calculator TI-30 will be used for the examples in this module. Most calculators work on the same principles, but some do not. Some calculators operate on a programming principle like Hewlett-Packard (HP). An HP calculator does not use an equal key. To perform a mathematical operation, the first number is inserted, the ENTER key is pressed, the second number is inserted, and then the mathematical function key is pressed. The result will be displayed. If a different calculator is used, the student will need to refer to the reference manual for his or her calculator. The following section will review the general use function keys on a TI-30 calculator. In each following chapter of this module, the applicable calculator operations will be addressed. Appendix A of this module gives a representation of a TI-30 keyboard to assist the student. Keys Clear entry/Clear key Pressing this key once will clear the last operation and the display. Pressing this key twice will clear all operations except the memory. Note: To clear the memory, press clear then STO. Note: Many brands break this function into two separate keys, usually labeled ""clear"" and ""all clear,"" where the ""clear"" key clears the last entry and the ""all clear"" key clears the display and all pending operations.  MA-01  Page 4  Rev. 0   Review of Introductory Mathematics  CALCULATOR OPERATIONS  Memory Key The TI-30 has only one memory. Pressing the STO key enters the displayed number into memory. Any number already in memory will be overwritten. Note: Calculators with more than one memory will require a number to be entered with the STO key. For example, STO 01 means store the displayed number in memory 01; STO 20 means store the number in memory 20. Memory Recall Key Pressing the RCL key will retrieve the number in memory and display it. Note that the number is also still in memory. This allows the number to be used again. Pressing the RCL will also overwrite any number previously displayed. Note: Calculators with more than one memory will require a number to be entered with the RCL key. RCL 01 means recall the number stored in the 01 memory. RCL 20 means recall the number stored in memory 20. Constant Key Certain calculations often contain repetitive operations and numbers. The K, constant, is a time-saving function that allows a single key stroke to perform a single operation and number on the displayed number. For example, if 20 numbers are to be multiplied by -17.35, the K key can be used. Enter -17.35, then press the times key, then the K key; this ""teaches"" the calculator the required operation. From this point on when entering a number and pressing the K key, the calculator will automatically multiply the displayed number by -17.35, saving you six key strokes. Summation Key If a long list of numbers is to be added, the summation key will save time if used. Pressing the summation key adds the displayed number to the number in memory. The final sum is then retrieved from memory. Memory Exchange Key The EXC, memory exchange key, swaps the displayed number with the number in memory.  Reciprocal Key When pressed, it divides the displayed number into one.  Rev. 0  Page 5  MA-01   FOUR BASIC ARITHMETIC OPERATIONS  Review of Introductory Mathematics  FOUR BASIC ARITHMETIC OPERATIONS This chapter reviews the basic mathematical operations of addition, subtraction, multiplication, and division of whole numbers. EO 1.2 APPLY one of the arithmetic operations of addition, subtraction, multiplication, and division using whole numbers.  Calculator Usage, Special Keys This chapter requires the use of the +, -, x,  , and = keys. When using a TI-30 calculator, the number and operation keys are entered as they are written. For example, the addition of 3 plus 4 is entered as follows: 3 key, + key, 4 key, = key, the answer, 7, is displayed Parentheses The parentheses keys allow a complicated equation to be entered as written. This saves the time and effort of rewriting the equation so that multiplication/division is performed first and addition/subtraction is performed second, allowing the problem to be worked from left to right in one pass.  The Decimal Numbering System The decimal numbering system uses ten symbols called digits, each digit representing a number. These symbols are 0, 1, 2, 3, 4, 5, 6, 7, 8 and 9. The symbols are known as the numbers zero, one, two, three, etc. By using combinations of 10 symbols, an infinite amount of numbers can be created. For example, we can group 5 and 7 together for the number 57 or 2 and 3 together for the number 23. The place values of the digits are multiples of ten and given place titles as follows:  MA-01  Page 6  Rev. 0   Review of Introductory Mathematics  FOUR BASIC ARITHMETIC OPERATIONS  Numbers in the decimal system may be classified as integers or fractions. An integer is a whole number such as 1, 2, 3, . . . 10, 11, . . . A fraction is a part of a whole number, and it is expressed as a ratio of integers, such as 1/2, 1/4, or 2/3. An even integer is an integer which can be exactly divided by 2, such as 4, 16, and 30. All other integers are called odd, such as 3, 7, and 15. A number can be determined to be either odd or even by noting the digit in the units place position. If this digit is even, then the number is even; if it is odd, then the number is odd. Numbers which end in 0, 2, 4, 6, 8 are even, and numbers ending in 1, 3, 5, 7, 9 are odd. Zero (0) is even. Examples: Determine whether the following numbers are odd or even: 364, 1068, and 257. Solution: 1. 2. 3. 364 is even because the right-most digit, 4, is an even number. 1068 is even because the right-most digit, 8, is an even number. 257 is odd because the right-most digit, 7, is an odd number.  Adding Whole Numbers When numbers are added, the result is called the sum. The numbers added are called addends. Addition is indicated by the plus sign (+). To further explain the concept of addition, we will use a number line to graphically represent the addition of two numbers. Example: Solution: Add the whole numbers 2 and 3. Using a line divided into equal segments we can graphically show this addition.  Rev. 0  Page 7  MA-01   FOUR BASIC ARITHMETIC OPERATIONS  Review of Introductory Mathematics  Starting at zero, we first move two places to the right on the number line to represent the number 2. We then move an additional 3 places to the right to represent the addition of the number 3. The result corresponds to the position 5 on the number line. Using this very basic approach we can see that 2 + 3 = 5. Two rules govern the addition of whole numbers. The commutative law for addition states that two numbers may be added in either order and the result is the same sum. In equation form we have: a+b=b+a (1-1)  For example, 5 + 3 = 8 OR 3 + 5 = 8. Numbers can be added in any order and achieve the same sum. The associative law for addition states that addends may be associated or combined in any order and will result in the same sum. In equation form we have: (a + b) + c = a + (b + c) (1-2)  For example, the numbers 3, 5, and 7 can be grouped in any order and added to achieve the same sum: (3 + 5) + 7 = 15 OR 3 + (5 + 7) = 15 The sum of both operations is 15, but it is not reached the same way. The first equation, (3 + 5) + 7 = 15, is actually done in the order (3 + 5) = 8. The 8 is replaced in the formula, which is now 8 + 7 = 15. The second equation is done in the order (5 + 7) = 12, then 3 + 12 = 15. Addition can be done in any order, and the sum will be the same.  MA-01  Page 8  Rev. 0   Review of Introductory Mathematics  FOUR BASIC ARITHMETIC OPERATIONS  When several numbers are added together, it is easier to arrange the numbers in columns with the place positions lined up above each other. First, the units column is added. After the units column is added, the number of tens is carried over and added to the numbers in the tens column. Any hundreds number is then added to the hundreds column and so on. Example: Add 345, 25, 1458, and 6. Solution: 345 25 1458 +6 1834 When adding the units column, 5 + 5 + 8 + 6 = 24. A 4 is placed under the units column, and a 2 is added to the tens column. Then, 2 + 4 + 2 + 5 = 13. A 3 is placed under the tens column and a 1 is carried over to the hundreds column. The hundreds column is added as follows: 1 + 3 + 4 = 8. An 8 is placed under the hundreds column with nothing to carry over to the thousands column, so the thousands column is 1. The 1 is placed under the thousands column, and the sum is 1834. To verify the sum, the numbers should be added in reverse order. In the above example, the numbers should be added from the bottom to the top.  Subtracting Whole Numbers When numbers are subtracted, the result is called the remainder or difference. The number subtracted is called the subtrahend; the number from which the subtrahend is subtracted is called the minuend. Subtraction is indicated by the minus sign (-). 86 -34 52 Minuend -Subtrahend Remainder or Difference  Unlike addition, the subtraction process is neither associative nor commutative. The commutative law for addition permitted reversing the order of the addends without changing the sum. In subtraction, the subtrahend and minuend cannot be reversed. a-b=b-a / (1-3)  Rev. 0  Page 9  MA-01   FOUR BASIC ARITHMETIC OPERATIONS  Review of Introductory Mathematics  Thus, the difference of 5 - 3 is not the same as 3 - 5. The associative law for addition permitted combining addends in any order. In subtraction, this is not allowed. (a-b)-c  a-(b-c) Example: (10-5)-1  10-(5-1) 46  When subtracting two numbers, the subtrahend is placed under the minuend with the digits arranged in columns placing the units place under the units place, the tens column next, and so on. Example: Subtract 32 from 54. Solution: 54 -32 22 Whenever the digit in the subtrahend is larger than the digit in the minuend in the same column, one place value is borrowed from the next digit to the left in the minuend. Refer to the following example. Example: Subtract 78 from 136. Solution: 2  13 /6 - 78 58 When subtracting the units column, 6 - 8, a 10 is borrowed from the tens column. This now makes subtracting the units column 16 - 8. An 8 is placed under the units column. Next the tens column is subtracted. A 10 was borrowed from the tens column and now 7 is subtracted from 12, not 13. This yields: 12 - 7 = 5. The 5 is placed under the tens column and the difference is 58. This can be done for any subtraction formula. When the digit in the subtrahend column is larger than the digit in the minuend in the same column, a number from the next higher place position column is ""borrowed."" This reduces the higher position column by one.  MA-01  Page 10  Rev. 0   Review of Introductory Mathematics  FOUR BASIC ARITHMETIC OPERATIONS  Subtraction can be verified by adding the difference to the subtrahend, which should result in the minuend.  Multiplying Whole Numbers Multiplication is the process of counting a number two or more times. It can be considered a shortened form of addition. Thus, to add the number 4 three times, 4 + 4 + 4, we can use multiplication terms, that is, 4 multiplied by 3. When numbers are multiplied, the result is called the product. The numbers multiplied are called factors. One factor is called the multiplicand; the other is called the multiplier. Multiplication is indicated by the times or multiplication sign (x), by a raised dot ( ), or by an asterick (*). 9 x4 36 Multiplicand x Multiplier Product  In multiplying several numbers, the same product is obtained even if the numbers are multiplied in a different order or even if some of the numbers are multiplied together before the final multiplication is made. These properties are called the commutative and associative laws for multiplication. The commutative law for multiplication states that numbers can be multiplied in any order, and the result is the same product. In equation form: axb=bxa Thus, the product of 8 x 3 is the same as 3 x 8. The associative law for multiplication states that factors can be associated in any order, and the result is the same product. In equation form: a x (b x c) = (a x b) x c (1-5) (1-4)  Thus, the numbers 2, 3, and 5 can be multiplied by first multiplying 2 x 3 to equal 6 and then multiplying 6 x 5 to equal 30. The equation may also be solved by first multiplying 3 x 5 to equal 15, and then multiplying 15 x 2 to equal 30. In either case, the product is 30. In multiplying two numbers, one number is columns placing units under the units place, larger number is considered the multiplicand The digit in the units place of the multiplier multiplier next, and so on. placed under the other with the digits arranged in tens under the tens place, and so on. Usually, the and the smaller number is considered the multiplier. is multiplied first, the digit in the tens place of the  Rev. 0  Page 11  MA-01   FOUR BASIC ARITHMETIC OPERATIONS  Review of Introductory Mathematics  Example 1: Multiply 432 by 8. Solution: 432 8 3,456 In multiplying the multiplier in the units column to the multiplicand, 8 x 2 = 16. A 6 is placed under the units column, and 1 ten is carried. Then, 8 x 3 = 24, plus the 1 carried over equals 25. A 5 is placed under the tens column, and 2 hundreds are carried over. Next, 8 x 4 = 32, plus 2 carried over, equals 34. A 4 is placed under the hundreds column and a 3 under the thousands column. Example 2: What is the product of 176 x 59? Solution: 176 x 59 1584 Multiplication by 9 880 Multiplication by 50 10384 Start by multiplying the digit in the units place of the multiplier, 9 x 6 = 54. A 4 is placed under the units column, and 5 tens are carried over. Next, 9 x 7 = 63, plus the 5 carried over, equals 68. An 8 is placed under the tens column, and 6 hundreds are carried over. Then, 9 x 1 = 9, plus 6 carried over, equals 15. A 5 is placed under the hundreds column and a 1 under the thousands column. The digit in the tens place of the multiplier is multiplied now: 5 x 6 = 30. Since the 5 in 59 is in the tens column, the zero is placed under the tens column, and 3 tens are carried over. Next, 5 x 7 = 35, plus the 3 carried over, equals 38. An 8 is placed under the hundreds column, and 3 hundreds are carried over. Then, 5 x 1 = 5, plus 3 carried over, equals 8. An 8 is placed under the thousands column. The results of 176 multiplied by 9 and 50 are then added to give the final product.  MA-01  Page 12  Rev. 0   Review of Introductory Mathematics  FOUR BASIC ARITHMETIC OPERATIONS  Dividing Whole Numbers Division is the process of determining how many times one number is contained in another number. When numbers are divided, the result is the quotient and a remainder. The remainder is what remains after division. The number divided by another number is called the dividend; the number divided into the dividend is called the divisor. Division is indicated by any of the following: a division sign () a division sign ( )    #  #  a horizontal line with the dividend above the line and the divisor below the line  a slanting line a/b meaning  a divided by b  Thus, the relationship between the dividend, divisor, and quotient is as shown below:  37 Dividend 4 Divisor 9 Quotient 1 Remainder  Unlike multiplication, the division process is neither associative nor commutative. The commutative law for multiplication permitted reversing the order of the factors without changing the product. In division the dividend and divisor cannot be reversed. Using the equation form: ab=ba / (1-6)  For example, the quotient of 18  6 is not the same as the quotient of 6  18. 18 divided by 6 equals 3; 6 divided by 18 equals 0.33.  Rev. 0  Page 13  MA-01   FOUR BASIC ARITHMETIC OPERATIONS  Review of Introductory Mathematics  The associative law for multiplication permitted multiplication of factors in any order. In division, this is not allowed. (ab)  c  a  (bc) Example: (84)  2  8  (42) 14 When dividing two numbers, the divisor and dividend are lined up horizontally with the divisor to the left of the dividend. Division starts from the left of the dividend and the quotient is written on a line above the dividend. Example 1: Divide 347 by 5. Solution:  Starting from the left of the dividend, the divisor is divided into the first digit or set of digits it divides into. In this case, 5 is divided into 34; the result is 6, which is placed above the 4. This result (6) is then multiplied by the divisor, and the product is subtracted from the set of digits in the dividend first selected. 6 x 5 equals 30; 30 subtracted from 34 equals 4. The next digit to the right in the dividend is then brought down, and the divisor is divided into this number. In this case, the 7 is brought down, and 5 is divided into 47; the result is 9, which is placed above the 7. Again, this result is multiplied by the divisor, and the product is subtracted from the last number used for division. 9 x 5 equals 45; 45 subtracted from 47 equals 2. This process is repeated until all of the digits in the dividend have been brought down. In this case, there are no more digits in the dividend. The result of the last subtraction is the remainder. The number placed above the dividend is the quotient. In this case, 347  5 yields a quotient of 69 with a remainder of 2.  MA-01  Page 14  Rev. 0   Review of Introductory Mathematics  FOUR BASIC ARITHMETIC OPERATIONS  Example 2: Divide 738 by 83. Solution:  Example 3: Divide 6409 by 28. Solution:  Division can be verified by multiplying the quotient by the divisor and adding the remainder. The result should be the dividend. Using Example 3, multiply 228 by 28 to check the quotient. 228 x 28 1824 456 6384  Product + 25  Remainder of 25 6409  Rev. 0  Page 15  MA-01   FOUR BASIC ARITHMETIC OPERATIONS  Review of Introductory Mathematics  Hierarchy of Mathematical Operations Mathematical operations such as addition, subtraction, multiplication, and division are usually performed in a certain order or sequence. Typically, multiplication and division operations are done prior to addition and subtraction operations. In addition, mathematical operations are also generally performed from left to right using this heirarchy. The use of parentheses is also common to set apart operations that should be performed in a particular sequence. Example: Perform the following mathematical operations to solve for the correct answer: (2 + 3) + (2 x 4) + ( 6 2 ) = __________ 2  Solution: a. b. Mathematical operations are typically performed going from left to right within an equation and within sets of parentheses. Perform all math operations within the sets of parentheses first. 2+3=5 2x4=8 62 2 8 2 4 Note that the addition of 6 and 2 was performed prior to dividing  by 2. c. Perform all math operations outside of the parentheses. In this case, add from left to right. 5 + 8 + 4 = 17 Example: Solve the following equation: (4 - 2) + (3 x 4) - (10  5) - 6 = ______ Solution: a. Perform math operations inside each set of parentheses. 4-2=2 3 x 4 = 12  MA-01  Page 16  Rev. 0   Review of Introductory Mathematics  FOUR BASIC ARITHMETIC OPERATIONS  10  5 = 2 b. c. Perform addition and subtraction operations from left to right. The final answer is 2 + 12 - 2 - 6 = 6  There may be cases where several operations will be performed within multiple sets of parentheses. In these cases you must perform all operations within the innermost set of parentheses and work outward. You must continue to observe the hierarchical rules through out the problem. Additional sets of parentheses may be indicated by brackets, [ ]. Example: Solve the following equation: [2 ( 3 + 5) - 5 + 2] x 3 = ______ Solution: a. Perform operations in the innermost set of parentheses. 3+5=8 b. Rewriting the equation: [2 8 - 5 + 2] x 3 = c. Perform multiplication prior to addition and subtraction within the brackets. [16 - 5 + 2] x 3 = [11 + 2] x 3 = [13] x 3 = d. Perform multiplication outside the brackets. 13 x 3 = 39  Rev. 0  Page 17  MA-01   FOUR BASIC ARITHMETIC OPERATIONS  Review of Introductory Mathematics  Example: Solve the following equation: 5 + [2 (3 + 1) - 1] x 2 = _____ Solution: 5 5 5 5 Example: Solve the following equation: [(10 - 4)  3] + [4 x (5 - 3)] = _____ Solution: [(6)  3] + [4 x (2)] = [2] + [8] = 2 + 8 = 10 + + + + [2 [8 [7] 14 (4) - 1] x 2 = - 1] x 2 = x2= = 19  MA-01  Page 18  Rev. 0   Review of Introductory Mathematics  FOUR BASIC ARITHMETIC OPERATIONS  Summary The important information from this chapter is summarized below.  Four Basic Arithmetic Operations Summary This chapter reviewed using whole numbers to perform the operations of: Addition Subtraction Multiplication Division While this chapter discussed the commutative and associative laws for whole numbers, it should be noted that these laws will also apply to the other types of numbers discussed in later chapters and modules of this course.  Rev. 0  Page 19  MA-01   AVERAGES  Review of Introductory Mathematics  AVERAGES This chapter covers the concept of averages and how to calculate the average of a given set of data. EO 1.3 Given a set of numbers, CALCULATE the average value.  An average is the sum of a group of numbers or quantities divided by or quantities. Averages are helpful when summarizing or generalizing a different conditions. For example, when analyzing reactor power level, the average power for a day, a week, or a month. The average can be of the reactor power for the day, week, or month. Average calculations involve the following steps: Step 1: Add the individual numbers or quantities. Step 2: Count the number of numbers or quantities. Step 3: Divide the sum in Step 1 by the number in Step 2. Example 1:  the number of numbers condition resulting from it may be helpful to use used as a generalization  Find the average cost of a car, given the following list of prices. $10,200; $11,300; $9,900; $12,000; $18,000; $7,600 Solution: Step 1: 10200 + 11300 + 9900 + 12000 + 18000 + 7600 = 69000 Step 2: Total number of prices is 6 Step 3: Divide 69000 by 6. The result is 11500 Thus, the average price of the six cars is $11,500. Example 2: Find the average temperature if the following values were recorded: 600F, 596F, 597F, 603F Solution: Step 1: 600 + 596 + 597 + 603 = 2396 Step 2: The number of items is 4. Step 3: 2396/4 = 599F  MA-01  Page 20  Rev. 0   Review of Introductory Mathematics  AVERAGES  Average Value The summation symbol, , introduced in the first chapter, is often used when dealing with the average value, x . Using the first example in this chapter, the average value could have been expressed in the following manner: N x x  1 N    car  where: x = = = the average value (cost) of a car each of the individual car prices total number of cars  car  x  i  N  The right side of the above equation can then be rewritten. x1 x2 x3 x4 x5 x car  x  6  6  substituting 10,200 for x1, 11300 for x2, 9,900 for x3, etc. 10,200 11,300 9,900 12,000 18,000 7600 6  x  car  x  car  = 11,500  Rev. 0  Page 21  MA-01   AVERAGES  Review of Introductory Mathematics  Example: If we were to apply the average value equation from above to the second example concerning temperature, how would it be written, and what would be the values for N1, xi? Solution: 4 x x  1 4  temp  x1 x2 x3 x4  = = = =  600 596 597 603 x1 x2 x3 x  x  4  temp  4  600 596 597 603 4 = 599  MA-01  Page 22  Rev. 0   Review of Introductory Mathematics  AVERAGES  Summary The important information from this chapter is summarized below.  Averages Summary Calculating the average of a set of numbers requires three steps: 1. 2. Add the individual numbers or quantities. Count the number of numbers or quantities added in previous step. Divide the sum calculated in step 1 by the number in step 2.  3.  Rev. 0  Page 23  MA-01   FRACTIONS  Review of Introductory Mathematics  FRACTIONS This chapter covers the basic operations of addition, subtraction, multiplication, and division using fractions. EO 1.4 APPLY one of the arithmetic operations of addition, subtraction, multiplication, and division using fractions.  1 , consists of the numerator 1 and the denominator 3. It is 3 referred to as a rational number describing the division of 1 by 3 (division of the numerator by the denominator). A common fraction, such as  Proper and Improper Fractions There are two types of fractions: proper fractions and improper fractions. The value of the numerator and the denominator determines the type of fraction. If the numerator is less than the denominator, the fraction is less than one; this fraction is called a proper fraction. If the numerator is equal to or greater than the denominator, the fraction is called an improper fraction. Example: 3 8 proper fraction 8 3 improper fraction 3 3 improper fraction  An improper fraction expressed as the sum of an integer and a proper fraction is called a mixed number. To write an improper fraction as a mixed number, divide the numerator by the denominator, obtaining an integer part (quotient) plus a fractional part whose numerator is the remainder of the division.  MA-01  Page 24  Rev. 0   Review of Introductory Mathematics  FRACTIONS  Example: 22 4 4 =2+ =2 9 9 9 Here, 9 can be divided into 22 two times, with 4 left over or remaining. 9  Thus, the improper fraction  22 4 is equivalent to the mixed number 2 . 9 9  Every number may be expressed as a fraction or sum of fractions. A whole number is a fraction whose denominator is 1. Any fraction with the same numerator and denominator is equal to one. Examples: 5= 5 10 , 11 10, 1 16 , 16 5 =1 5  Equivalent Fractions An equivalent fraction is a fraction that is equal to another fraction. Example: 2 3 4 6 6 9  A fraction can be changed into an equivalent fraction by multiplying or dividing the numerator and denominator by the same number. Example: 2 3 2 2 4 2 because = 1, and 1 x any number = that number 6 2  A fraction may be reduced by dividing both the numerator and the denominator of a fraction by the same number.  Rev. 0  Page 25  MA-01   FRACTIONS  Review of Introductory Mathematics  Example: 6 2 8 2  6 8  3 4  Addition and Subtraction of Fractions When two or more fractions have the same denominator, they are said to have a common denominator. The rules for adding fractions with a common denominator will first be explored. Consider the example. 3 8 1 8 3 1 3 1 means three segments, i.e. = 3 x . Looking at this as the 8 8 8 8  First of all, the fraction addition of pie segments:  1  1  It is obvious that three of these segments  ths plus one of these segments  ths equal four 8  8  1  of these segments  ths . 8   MA-01  Page 26  Rev. 0   Review of Introductory Mathematics  FRACTIONS  This graphic illustration can be done for any addition of fractions with common denominators. The sum of the fractions is obtained by adding the numerators and dividing this sum by the common denominator. 2 6 3 6 1 6  2   1 1 1  3   1   6 6 6 6 1 6 1  Also, this general method applies to subtraction, for example,  The general method of subtraction of fractions with common denominators is to subtract the numerators and place this difference over the common denominator. 5 8 2 8  5   1  8  2   1  8  (5 2)    1  8  3   1  8 3 8  Rev. 0  Page 27  MA-01   FRACTIONS  Review of Introductory Mathematics  When fractions do not have a common denominator, this method must be modified. For example, consider the problem: 1 2 1 3 ?  This presents a problem, the same problem one would have if he were asked to add 6 feet to 3 yards. In this case the entities (units) aren't equal, so the 6 feet are first converted to 2 yards and then they are added to 3 yards to give a total of 5 yards. 6 feet + 3 yards = 2 yards + 3 yards = 5 yards 1 1 and must both 2 3 1 segments to be added. Without developing the general method, is 2 1 2 or (one) to give the equivalent fraction. Similarly, equals . 3 6 Going back to the fraction addition example, then be expressed in the same 3 1 3 ths . Multiply by 6 2 3  MA-01  Page 28  Rev. 0   Review of Introductory Mathematics  FRACTIONS  Then,  The general method of adding or subtracting fractions which do not have a common denominator is to convert the individual fractions to equivalent fractions with a common denominator. These equally sized segments can then be added or subtracted. The simplest method to calculate a common denominator is to multiply the denominators. This is obtained if each fraction is multiplied top and bottom by the denominator of the other fraction (and thus by one, giving an equivalent fraction). 1 3 1 3 6 18 8 6 6 6 24 18 8 6 30 18 3 3  For more than two fractions, each fraction is multiplied top and bottom by each of the other denominators. This method works for simple or small fractions. If the denominators are large or many fractions are to be added, this method is cumbersome.  Rev. 0  Page 29  MA-01   FRACTIONS  Review of Introductory Mathematics  Example: 105 64 15 32 1 6  would require the denominator to be equal to 64 x 32 x 6 = 12,288. This kind of number is very hard to use. In the earlier example 1 3 6 18 8 6 24 18 was shown to equal 30 . 18  You notice that both 30 and 18 can be divided by 6; if this is done: 30  6 18  6 5 3 5 30 takes the place of . 3 18  By doing this we arrive at a smaller and more useful number:  The sum of two or more fractions reduced to its simplest form contains the smallest possible denominator common to both fractions. This denominator is called the least common denominator (LCD). Example: 1 3 1 6 1 8  Using trial and error we can find that 24 is the LCD or smallest number that 3, 6, and 8 will all divide into evenly. Therefore, if each fraction is converted into 24ths, the fractions can be added. 1 3 8 24    8  8 4 24 1 6 3 24    4  4 15 24 1 8    3  3  MA-01  Page 30  Rev. 0   Review of Introductory Mathematics  FRACTIONS  This is the simplest form the fraction can have. To eliminate the lengthy process of trial and error used in finding the LCD, you can reduce the denominators to their prime numbers.  Least Common Denominator Using Primes A prime number is a whole number (integer) whose only factors are itself and one. The first prime numbers are: 1, 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, . . . . By dividing by primes, you can find that the primes of 105 are: 105 3 35 35 5 7 7 = a prime number, therefore, stop dividing.  The primes of 105 are: 3, 5, 7 A systematic way of finding the prime factors of larger positive integers is illustrated below. The primes are tried in order, as factors, using each as many times as possible before going on to the next. The result in this case is: 504 =(2)(252) =(2)(2)(126) =(2)(2)(2)(63) =(2)(2)(2)(3)(21) =(2)(2)(2)(3)(3)(7)  To add several fractions with different denominators, follow these steps: Step 1: Step 2: Express denominators in prime factors. Determine the least common denominator by using all of the prime numbers from the largest denominator, and then include each prime number from the other denominators so that each denominator can be calculated from the list of primes contained in the LCD. Rewrite using the least common denominator. Add the fractions.  Step 3: Step 4:  Rev. 0  Page 31  MA-01   FRACTIONS  Review of Introductory Mathematics  Example 1: Add Solution: Step 1: Find primes of each denominator. 15 = 5 x 3 10 = 5 x 2 Step 2: In the example, 15 is the largest denominator, so use the 5 and the 3; now look at the second denominator's primes--the five already appears in the list, but the 2 does not, so use the 2. 5 x 3 x 2 = 30 Step 3: Rewrite with least common denominators. 1 2 15 30 7 21 10 30 Add the new fractions. 2 30 Example 2: Add Solution: Step 1: Find primes of each denominator. 7 3 12 6 Step 2: = = = = 7 3 2 2 (already is a prime number) (already is a prime number) x6=2x2x3 x3 1 7 2 3 11 12 4 6 21 30 23 30 1 7 and 15 10  Step 4:  12 is the largest, so start with 2x2x3  MA-01  Page 32  Rev. 0   Review of Introductory Mathematics  FRACTIONS  Comparing this list to the others, the denominators of 3, 12, and 6 can all be calculated from the list, but 7 cannot be, so a 7 must be included in the list. 2 x 2 x 3 x 7 = 84 Step 3: Rewrite the equation 1 7 Step 4: Add 12 84 56 84 77 84 56 84 201 84 12 12 2 3 28 28 11 12 7 7 4 6 14 14  Addition and Subtraction Denominators of fractions being added or subtracted must be the same. The resulting sum or difference is then the sum or difference of the numerators of the fractions being added or subtracted. Examples: 2 3 4 7 4 9 8 11 2 11 5 = 11 1 21 = =1 3 3 1 41 5 = = 7 7 7 2 42 2 = = 9 9 9 8 2 11 5 = 1 11  Rev. 0  Page 33  MA-01   FRACTIONS  Review of Introductory Mathematics  Multiplication The methods of multiplication of fractions differ from addition and subtraction. The operation of multiplication is performed on both the numerator and the denominator. Step 1: Multiply the numerators. Step 2: Multiply the denominators. Step 3: Reduce fraction to lowest terms. Example: 2 3 1 4 2 12 1 6  Multiplication of mixed numbers may be accomplished by changing the mixed number to an improper fraction and then multiplying the numerators and denominators. Example: 1 1 2 3 5 3 2 3 5 9 10  Division The division of fractions can be performed by two methods. The first method employs the basic concept of multiplying by 1. Example:       4 5 2 9    = _____     MA-01  Page 34  Rev. 0   Review of Introductory Mathematics  FRACTIONS  Solution:   Multiply by           Step 2: 4 5 2 9             9 2 9 2 9 2 9 2    , which is the same as multiplying by 1.     Step 1:     = _____    2 9 9 2 1 . This leaves  Looking at the two division fractions we see that us with the following. 4 5 1 9 2  4 5  9 2  Step 3:  Multiply numerators and denominators. 4 5 9 2 36 10  Example:       Solution: Step 1: 7 6 Multiply by . 7 6 3 8 6 7 Rev. 0  3 8 6 7     = _____     7 6 = 7 6 Page 35 MA-01   FRACTIONS  Review of Introductory Mathematics  Step 2:  Multiplication of division fractions equals 1. 3 8 1 7 6  =  Step 3:  Multiplication of numerators and denominators yields: 3 8 7 6 21 48  The second method for dividing fractions is really a short cut to the first method. When dividing one fraction by another, first invert the divisor fraction and then multiply. Example:       Solution: Step 1: 2 9 Invert the divisor fraction   to  9 2  Multiply the dividend fraction,      Step 3:       36 2 10 2       4  5    9  2 36 10  .  4 5 2 9        Step 2:  4 9  , by the inverted fraction   . 5 2  Reduce fraction to lowest terms.  18 5  3  3 5  Division of mixed numbers may be accomplished by changing the mixed number into an improper fraction (a/b), inverting the divisor, and proceeding as in multiplication.  MA-01  Page 36  Rev. 0   Review of Introductory Mathematics  FRACTIONS  Invert the divisor fraction and then follow the rule for multiplication. Example: 1 2 3 3 7  5 3  7 3  35 9  3  8 9  Summary The important information from this chapter is summarized below.  Fractions Summary Denominator - bottom number in a fraction Numerator - top number in a fraction Proper fraction - numerator is less than denominator Improper fraction - numerator is greater than or equal to denominator Mixed number - sum of an integer and a proper fraction Fractions, like whole numbers can be: a. Added b. Subtracted c. Multiplied d. Divided  Rev. 0  Page 37  MA-01   DECIMALS  Review of Introductory Mathematics  DECIMALS This chapter covers the processes of addition, subtraction, multiplication, and division of numbers in decimal form. EO 1.5 APPLY one of the arithmetic operations of addition, subtraction, multiplication, and division of fractions by conversion to decimal form using a calculator. APPLY one of the arithmetic operations of addition, subtraction, multiplication, and division using decimals.  EO 1.6  When using numbers, the operator will use whole numbers at times and decimal numbers at other times. A decimal number is a number that is given in decimal form, such as 15.25. The decimal portion is equivalent to a certain ""fraction-of-one,"" thus allowing values between integer numbers to be expressed. A decimal is a linear array of integers that represents a fraction. Every decimal place indicates a multiple of a power of 10. Example:  Fraction to Decimal Conversion In the process of converting a fraction to a decimal, we must perform the operation of division that the fraction represents.  MA-01  Page 38  Rev. 0   Review of Introductory Mathematics  DECIMALS  Example: Convert Solution: The fraction 3 represents 3 divided by 4. To put this into decimal form, we first divide 4 3 by 4. Add a decimal point and zeros to carry out this division. 3 to a decimal. 4  Example: Convert Solution: 1 to a decimal. 3  In the above example we see that no matter how many zeros we add, there will always remainder of 1. This is called a repeating decimal. A repeating decimal is indicated by a 1 over the last number to the right of the decimal point. So, 0.333 . The bar is placed 3 the repeating portion. For a repeating single digit, the bar is placed over only a single digit. a repeating sequence of digits, the bar is placed over the whole sequence of digits.  be a dash over For  Rev. 0  Page 39  MA-01   DECIMALS  Review of Introductory Mathematics  Decimal to Fraction Conversion The process of decimal to fraction conversion involves the use of the fundamental rule of fractions; the fraction should be written in its lowest terms. The following examples demonstrate how to convert decimals to fractions. Example 1: Convert 0.65 to a fraction. Solution: Step 1: Note the number of place positions to the right of the decimal point. In this example, 0.65 is 65 hundredths, which is two places to the right of the decimal point. 65 100 Step 2: Although we have now converted the decimal into a fraction, the fraction is not in its lowest terms. To reduce the new fraction into its lowest or simplest terms, both the numerator and the denominator must be broken down into primes. 65 100 5 5 13 20 5 5 4 13 5 5 13 5225  Note that we can cancel one set of 5s, because This gives 65 100 13 20  5 = 1. 5  and this is the simplest form of this fraction. Example 2: Convert 18.82 to a mixed number.  MA-01  Page 40  Rev. 0   Review of Introductory Mathematics  DECIMALS  Solution: Step 1: 18.82 is 18 and 82 hundredths. 82 18.82 18 100 82 Reduce to its simplest form 100 82 100 2 41 2 50 2 41 2 2 25 41 . 50 2 41 2255  Step 2:  41 50 41 255 41 50  The answer is 18 Example 3: Convert 1.73 to a fraction. Solution: Step 1: Step 2: 1.73 = 1 73 100  73 = 73 x 1 100 = 2 x 2 x 5 x 5 There are no common factors between 73 and 100, so it cannot be reduced. 1 73 100  Example 4: Convert 0.333 to a fraction. Solution: Step 1: Step 2: 0.333 333 1000  There are no common factors between 333 and 1000, so it is already in its simplest form.  Rev. 0  Page 41  MA-01   DECIMALS  Review of Introductory Mathematics  Addition and Subtraction of Decimals When adding or subtracting decimals, each number must be placed to align the decimal points. When necessary, zeros are used as place holders to make this possible. Then the operation of addition or subtraction is performed. Example: 0.423 + 1.562 + 0.0736 + 0.2 = Solution: Align decimal points 0.4230 1.5620 0.0736 0.2000 2.2586 Example: 0.832 - 0.0357 = Solution: 0.8320 0.0357 0.7963  Multiplying Decimals When multiplying decimals, the decimal points do not have to be aligned. Rather, it is important to accurately position the decimal point in the product. To position the decimal in the product, the total number of digits to the right of the decimals in the numbers being multiplied must be equal to the number of digits to the right of the decimal in the product. This is best illustrated in the following examples: Step 1: Step 2: Step 3: Multiply numbers without inserting decimal in the products. Sum the number of digits to the right of the decimal in all of the numbers being multiplied. Position the decimal in the product so the number of digits to the right of the decimal equals the total number of digits to the right of the decimal in the numbers multiplied (from Step 2).  MA-01  Page 42  Rev. 0   Review of Introductory Mathematics  DECIMALS  Example: 0.056 x 0.032 = Solution: 0.056 0.032 112 168 0.001792 NOTE: Since 0.056 has three digits to the right of the decimal point, and 0.032 has three digits to the right of the decimal point, six digits must be to the right of the decimal point in the product. To have six digits in the product, zeros are inserted to the left of the computed digits.  To multiply a decimal by 10, move the decimal point one position to the right. Example: 0.45 x 10 = 4.5. Similarly, when multiplying a decimal by 100, 1000, and 10,000, move the decimal point to the right the same number of zeros that are in the multiplier.  Example: 0.45 x 100 = 45 0.45 x 1000 = 450 0.45 x 10,000 = 4500 The reverse is true when multiplying by fractions of 10. 0.45 0.45 0.45 0.45 x x x x 0.1 = 0.045 0.01 = 0.0045 0.001 = 0.00045 0.0001 = 0.000045  Dividing Decimals When solving problems involving division of decimals, the following procedure should be applied. Step 1: Step 2: Write out the division problem. Move the decimal in the divisor to the right.  Rev. 0  Page 43  MA-01   DECIMALS  Review of Introductory Mathematics  Step 3:  Move the decimal in the dividend the same number of places to the right. Add zeros after the decimal in the dividend if necessary. Place the decimal point in the quotient directly above the decimal in the dividend. Divide the numbers.  Step 4:  Step 5: Example:  3.00  0.06 Solution:  Rounding Off When there is a remainder in division, the remainder may be written as a fraction or rounded off. When rounding off, the following rules should be applied: Step 1: Step 2: Observe the digit to the right of the digit being rounded off. If it is less than 5, drop the digit. If the digit is 5 or higher, add 1 to the digit being rounded off. Write the new rounded number.  Step 3:  MA-01  Page 44  Rev. 0   Review of Introductory Mathematics  DECIMALS  Example: Round off the following number to two decimal places. 3.473 Solution: Step 1: Step 2: Step 3: Example: Round off the following number to two decimal places. 6.238 Solution: Step 1: Step 2: 8 is the number to the right of the 2nd decimal place. 8 is greater than 5, so drop the 8 and add one to the number in the second decimal place (3 + 1 = 4). 6.24 is the number rounded to two decimal places. 3 is the number to the right of the 2nd decimal place. 3 is less than 5, so drop the digit. 3.47 is the number rounded to two decimal places.  Step 3: Example:  Round off the following number to two decimal places. 6.2385 Solution: Step 1: Step 2: 8 is the number to the right of the 2nd decimal place. 8 is greater than 5, so drop the 8 and add one to number in the second decimal place (3 + 1 = 4). 6.24 is the number rounded to two decimal places.  Step 3:  Rev. 0  Page 45  MA-01   DECIMALS  Review of Introductory Mathematics  Example: Round off the following number to three decimal places. 6.2385 Solution: Step 1: Step 2: 5 is the number to the right of the 3rd decimal place. 5 is equal to 5, so drop the 5 and add one to the number in the third decimal place (8 + 1 = 9). 6.239 is the number rounded to three decimal places.  Step 3: Example:  Divide 2.25 by 6 and round off the answer to 1 decimal place. 2.25 = 0.375 6 Solution: Step 1: 7 is the number to the right of the 1 decimal place. st  Step 2:  7 is greater than 5, so drop the 7 and add one to the number in the first decimal place (3 + 1 = 4). 0.4 is .375 rounded to 1 decimal place.  Step 3:  MA-01  Page 46  Rev. 0   Review of Introductory Mathematics  DECIMALS  Summary The important information from this chapter is summarized below.  Decimals Summary When using the decimal process: Convert fractions to decimals by dividing the numerator by the denominator. Convert decimals to fractions by writing the decimal in fraction format and reducing. Align decimal points when adding or subtracting decimals. Before dividing decimals, move the decimal in the divisor and dividend to the right by the same number of places. When rounding, numbers less than 5 are dropped, and numbers 5 or greater increase the number immediately to the left by one.  Rev. 0  Page 47  MA-01   SIGNED NUMBERS  Review of Introductory Mathematics  SIGNED NUMBERS This chapter covers the processes of addition, subtraction, division, and multiplication of signed numbers. EO 1.7 APPLY one of the arithmetic operations of addition, subtraction, multiplication, and division using signed numbers.  Calculator Usage, Special Keys Change Sign key Pressing this key changes the sign of the number in the display. To enter a negative number, the number is entered as a positive number and then the change sign key is pressed to convert it to a negative. The display will show a ""-"" in front of the number.  Addition Addition of signed numbers may be performed in any order. Begin with one number and count to the right if the other number is positive or count to the left if the other number is negative. Example: 2 + 3 = 0 - 2 + 3 Solution: Begin with 2 and count 3 whole numbers to the right.  Therefore: -2 + 3 = 1  MA-01  Page 48  Rev. 0   Review of Introductory Mathematics  SIGNED NUMBERS  Example: (-2) + 3 + 4 = 0 - 2 + 3 + 4 Solution:  Therefore: (-2) + 3 + 4 = 5 Example: (2) + (4) = Solution: Begin with 2 and count 4 whole numbers to the left.  Therefore: (2) + (4) = 2  Rev. 0  Page 49  MA-01   SIGNED NUMBERS  Review of Introductory Mathematics  Adding numbers with unlike signs may be accomplished by combining all positive numbers, then all negative numbers, and then subtracting. Example: 10 + (5) + 8 + (7) + 5 + (18) = Solution: +10  5 + 8  7 + 5  18 = +10 + 8 + 5  18  7  5 = +23  30 = 7  Subtraction Subtraction of signed numbers may be regarded as the addition of numbers of the opposite signs. To subtract signed numbers, reverse the sign of the subtrahend (the second number) and add. For example, one could treat his incomes for a given month as positive numbers and his bills as negative numbers. The difference of the two is his increase in cash balance. Suppose he buys a window for $40. This gives a bill of $40 and adds as negative $40 to his cash balance. Now suppose he returns this window to the store and the manager tears up his bill, subtracting the $40. This is equivalent of adding +$40 to his cash balance. Example: ab = Solution: (+3)  (+5) (4)  (1) (5)  (+8) (+7)  (2) = = = = (+3) + (5) (4) + (+1) (5) + (8) (+7) + (+2) = 2 = 3 = 13 = +9 a + (b)  MA-01  Page 50  Rev. 0   Review of Introductory Mathematics  SIGNED NUMBERS  Multiplication Multiplication of signed numbers may be performed by using the following rules: The product of any two numbers with like signs is positive: (+)(+) = (+) or ()() = (+). The product of any two numbers with unlike signs is negative: (+)() = () or ()(+) = (). The product is negative if there is an odd number of negatives. The product is positive if there is an even number of negatives. Example: (+3)(+3) (2) (+4) (1) (2) (2) (+2) = +9 = 8 (+1) (2) = 4 (+2) (2) = +16  Zero times any number equals zero. Multiplying by 1 is the equivalent of changing the sign.  Division Division of signed numbers may be performed using the following rules: Rule 1: The quotient of any two numbers with like signs is positive: (+)/(+) = (+) or ()/() = (+) The quotient of any two numbers with unlike signs is negative: (+)/() = () or ()/(+) = () Zero divided by any number not equal to zero is zero.  Rule 2:  Rule 3:  Rev. 0  Page 51  MA-01   SIGNED NUMBERS  Review of Introductory Mathematics  Examples: 0 5  a)  0  Apply rule 3.  b)  3 1  3  Apply rule 1.  c)  4 2  2  Apply rule 2.  Summary The important information from this chapter is summarized below.  Signed Numbers Summary When using signed numbers: Adding a negative number is the same as subtracting a positive number. Subtracting a negative number is the same as adding a positive number. A product is negative if there is an odd number of negatives. A product is positive if there is an even number of negatives. Division of two numbers with like signs results in a positive answer. Division of two numbers with unlike signs results in a negative answer.  MA-01  Page 52  Rev. 0   Review of Introductory Mathematics  SIGNIFICANT DIGITS  SIGNIFICANT DIGITS This chapter presents the concept of significant digits and the application of significant digits in a calculation. EO 1.8 DETERMINE the number of significant digits in a given number. Given a formula, CALCULATE the answer with the appropriate number of significant digits.  EO 1.9  Calculator Usage, Special Keys Most calculators can be set up to display a fixed number of decimal places. In doing so, the calculator continues to perform all of its internal calculations using its maximum number of places, but rounds the displayed number to the specified number of places. INV key To fix the decimal place press the INV key and the number of the decimal places desired. For example, to display 2 decimal places, enter INV 2.  Significant Digits When numbers are used to represent a measured physical quantity, there is uncertainty associated with them. In performing arithmetic operations with these numbers, this uncertainty must be taken into account. For example, an automobile odometer measures distance to the nearest 1/10 of a mile. How can a distance measured on an odometer be added to a distance measured by a survey which is known to be exact to the nearest 1/1000 of a mile? In order to take this uncertainty into account, we have to realize that we can be only as precise as the least precise number. Therefore, the number of significant digits must be determined. Suppose the example above is used, and one adds 3.872 miles determined by survey to 2.2 miles obtained from an automobile odometer. This would sum to 3.872 + 2.2 = 6.072 miles, but the last two digits are not reliable. Thus the answer is rounded to 6.1 miles. Since all we know about the 2.2 miles is that it is more than 2.1 and less than 2.3, we certainly don't know the sum to any better accuracy. A single digit to the right is written to denote this accuracy.  Rev. 0  Page 53  MA-01   SIGNIFICANT DIGITS  Review of Introductory Mathematics  Both the precision of numbers and the number of significant digits they contain must be considered in performing arithmetic operations using numbers which represent measurement. To determine the number of significant digits, the following rules must be applied: Rule 1: Rule 2: The left-most non-zero digit is called the most significant digit. The right-most non-zero digit is called the least significant digit except when there is a decimal point in the number, in which case the right-most digit, even if it is zero, is called the least significant digit. The number of significant digits is then determined by counting the digits from the least significant to the most significant.  Rule 3:  Example: In the number 3270, 3 is the most significant digit, and 7 is the least significant digit. Example: In the number 27.620, 2 is the most significant digit, and 0 is the least significant digit. When adding or subtracting numbers which represent measurements, the right-most significant digit in the sum is in the same position as the left-most least significant digit in the numbers added or subtracted. Example: 15.62 psig + 12.3 psig = 27.9 psig Example: 401.1 + 50 = 450 Example: 401.1 + 50.0 = 451.1  MA-01  Page 54  Rev. 0   Review of Introductory Mathematics  SIGNIFICANT DIGITS  When multiplying or dividing numbers that represent measurements, the product or quotient has the same number of significant digits as the multiplied or divided number with the least number of significant digits. Example: 3.25 inches x 2.5 inches = 8.1 inches squared  Summary The important information from this chapter is summarized below.  Significant Digits Summary Significant digits are determined by counting the number of digits from the most significant digit to the least significant digit. When adding or subtracting numbers which represent measurements, the rightmost significant digit in the sum is in the same position as the left-most significant digit in the numbers added or subtracted. When multiplying or dividing numbers that represent measurements, the product or quotient has the same number of significant digits as the multiplied or divided number with the least number of significant digits.  Rev. 0  Page 55  MA-01   PERCENTAGES  Review of Introductory Mathematics  PERCENTAGES This chapter covers the conversion between percents, decimals, and fractions. EO 1.10 EO 1.11 CONVERT between percents, decimals, and fractions. CALCULATE the percent differential.  A special application of proper fractions is the use of percentage. When speaking of a 30% raise in pay, one is actually indicating a fractional part of a whole, 30/100. The word percent means ""hundredth;"" thus, 30% is based on the whole value being 100%. However, to perform arithmetic operations, the 30% expression is represented as a decimal equivalent (0.30) rather than using the % form.  Calculator Usage, Special Keys Percent Key When pressed, the percent key divides the displayed number by 100.  Changing Decimals to Percent Any number written as a decimal may be written as a percent. To write a decimal as a percent, multiply the decimal by 100, and add the percent symbol. Example: Change 0.35 to percent. 0.35 x 100 = 35% Example: Change 0.0125 to percent. 0.0125 x 100 = 1.25%  MA-01  Page 56  Rev. 0   Review of Introductory Mathematics  PERCENTAGES  Example: Change 2.7 to percent. 2.7 x 100 = 270%  Changing Common Fractions and Whole Numbers to Percent When changing common fractions to percent, convert the fraction to a decimal, then multiply by 100 and add the percent symbol. Example: 3 to a percent 5 0.6 x 100 = 60% Change When changing a whole number to a percent, multiply by 100 and add the percent symbol. Example: Change 10 to percent 10 x 100 = 1000% Percents are usually 100% or less. Percents are most often used to describe a fraction, but can be used to show values greater than 1(100%). Examples are 110%, 200%, etc.  Changing a Percent to a Decimal Any number written as a percent may be written as a decimal. To change a percent to a decimal, drop the percent symbol and divide by 100. Example: Express 33.5% in decimal form. 33.5 = 0.335 100 Express 3.35% in decimal form. 3.35 = 0.0335 100  Rev. 0  Page 57  MA-01   PERCENTAGES  Review of Introductory Mathematics  Express 1200% in decimal form. 1200 12 100  Percent Differential Percent differentials are used to provide a means of comparing changes in quantities or amounts. Percent differentials express the relationship between some initial condition and another specified condition. The method of calculating percent differential involves the following: Step 1: Step 2: Step 3: Step 4: Subtract the original value from the present value. Divide by the original value. Multiply by 100. Add the percent symbol (%).  Example: A tank initially contains 50 gallons of water. Five gallons are drained out. By what percent is the amount of water in the tank reduced? Solution: Step 1: Step 2: Step 3: The difference between initial and final is given in the problem: 5 gallons. 5 = 0.1 50 0.1 x 100 = 10% Five gallons represents 10% of the original 50 gals that were in the tank.  MA-01  Page 58  Rev. 0   Review of Introductory Mathematics  PERCENTAGES  Ratio Two numbers may be compared by expressing the relative size as the quotient of one number divided by the other and is called a ratio. Ratios are simplified fractions written with a colon (:) instead of a division bar or slash. Example: One day Eric paid $700 for a stereo and Scott paid $600 for the same stereo. Compare the amount that Eric paid to the amount that Scott paid, using ratios. Solution: Step 1: Divide the numbers to be compared. In this example the amount paid by Scott is being compared to the amount paid by Eric. The amount paid by 700 Eric is divided by the amount paid by Scott = . 600 Simplifying this expression, both 700 and 600 can be divided by 100. Expressing this fraction as a ratio: Eric s price 7 or Eric's price : Scott's price = 7:6 6 Scott s price  Step 2: Step 3:  Example: If one yard equals three feet, what is the ratio of yards to feet? Solution: Step 1: Step 2: 1 yd./ 3 ft. 1 is already in simplest terms 3 yards feet 1 or yards : feet = 1:3 3  Step 3:  Rev. 0  Page 59  MA-01   PERCENTAGES  Review of Introductory Mathematics  Summary Pertinent information concerning percentages and ratios is summarized below.  Percentages and Ratios Summary Change decimals to percents by multiplying by 100 and adding the percent symbol. Change fractions to percents by first changing the fraction into a decimal. Then change the decimal to a percent. Compute percent differential by dividing the difference by the original value, multiplying by 100, and adding the percent symbol. Ratios are fractions written with a colon instead of a division bar or slash.  MA-01  Page 60  Rev. 0   Review of Introductory Mathematics  EXPONENTS  EXPONENTS This chapter covers the addition, subtraction, multiplication, and division of numbers with exponents. EO 1.12 APPLY one of the arithmetic operations of addition, subtraction, multiplication, and division using exponential numbers.  Calculator Usage, Special Keys Exponent key Raising a number to an exponent requires the yx key the base number is entered and the yx key is pressed; (y). Next, the exponent number is pressed and the y the exponent and tells the calculator to complete the will display the value. x squared key Pressing this key squares the displayed number. This key will save time over using the yx key. to be pressed twice. First, this enters the base number x key is pressed; this enters calculation. The calculator  Exponents The product a x a x a x a can be written as a4, where 4 is called the exponent of a or power to which a is raised. In this notation, a is often called the base. Examples: a4 a a a a 53 5 5 5 (a b) (a b) (a b)  (a  b)  5  (a b)  (a b)  When an exponent is not written, it is assumed to be 1. For example, a1 = a. An exponent applies only to the quantity immediately to the left and below it. For example, in 3 + (-2)3 the base is -2, but in 3 - 23 the base is 2.  Rev. 0  Page 61  MA-01   EXPONENTS  Review of Introductory Mathematics  Basic Rules for Exponents The following rules are applied to exponents. Rule 1: To multiply numbers with the same base, add the exponents and keep the base the same. aman = a Example: 22 x 23 = (2 x 2) x (2 x 2 x 2) = 2 x 2 x 2 x 2 x 2 = 2 Rule 2: 5 m+n  When raising a power of a number to a power, multiply the exponents and keep the base the same. (am)n = amn  Example: (a2)3 = (a x a) x (a x a) x (a x a) = a6 that is, you multiply (a x a) three times. Similarly, for (am)n, one multiplies (am) n times. There are m values of a in each parenthesis multiplied by n parenthesis or m x n values of a to multiply. Thus, (am)n = amn  Rule 3:  When dividing two exponential numbers, subtract the powers. a a m n  a  mn  Example: a a 5 2  aaaaa aa  aa  aaa aa  a  3  MA-01  Page 62  Rev. 0   Review of Introductory Mathematics  EXPONENTS  Rule 4:  Any exponential number divided by itself is equal to one. a a n n  1  Rule 5:  To raise a product to a power, raise each factor to that power. (ab)n = anb n  This arises from the associative law for multiplication, that is, order of multiplication does not alter the product. Example: (ab)2 = (a x b) x (a x b) = (a x a) (b x b) = a2 x b 2  If doubt exists in the student's mind, try multiplying (2 x 3)2 out in different orders. All orders will yield 36. Rule 6: To raise a quotient to a power, raise both the numerator and denominator to that power.    Example: To demonstrate this, consider 3 2 2 2  a  b  n  a b  n n   3 2  2  1.5  2  2.25  2  1 4  9 4  But  9 , the same value. 4  Rev. 0  Page 63  MA-01   EXPONENTS  Review of Introductory Mathematics  Zero Exponents Using the rule for exponents (Rule 4) to evaluate an/an, then a a n n  1 n-n  This interpretation is consistent with the rule an/an = a equal to 0. Any number to the zero power equals one. Example: 30 = 1 (b2+2)0 = 1  = a0. Therefore, a0 = 1 when a is not  Negative Exponents The rules for positive exponents apply to negative exponents. a-n is defined as follows: a-n = a a n n  1 an n  1 a  1 is written as a-2, and the rules for 2 a 1 multiplication are applied to this, a5 x a-2 = a5-2 = a3. Thus, writing as a-n and applying the n a 1 rules for multiplication yields the same results as and applying the rules of division. an For example, a5/a2 = a 5-2  as shown earlier.  If  Examples: c x 2  1 c2 1 x 3  3  MA-01  Page 64  Rev. 0   Review of Introductory Mathematics  EXPONENTS  Fractional Exponents 1  Fractional exponents are defined as follows, a m  a . This permits manipulations with numbers with fractional exponents to be treated using the laws expressed earlier for integers. For example, 1 3  n  8    3  8  2 1 3  since 2  2  2  8 13 3  Taking the statement 8 8 13 3  2 and cubing both sides, 8  23 .  But (am)n = a  mxn  so  8  1  8 which agrees with 23 = 8 for the right-hand side of the equality. 2 3 12 3 1 23 1 3  A number such as 8 can be written 8 2 4 x 4 x 4 = 64; that is, 4 is the cube root of 64. Examples: 1 3 2 3 1 3 2 3  2  4 or alternately as 8  64  4 since  a b b  a  a 1 2  a  1  a  1 4 1 2  b  1 4  b  1 2  1 b2  d  19 3  d  1 9 3  d  3  Rev. 0  Page 65  MA-01   EXPONENTS  Review of Introductory Mathematics  Summary Pertinent information concerning exponents is summarized below.  Exponents Summary Base Exponent  = Product To multiply numbers with the same base, add the exponents and keep the base the same. aman = am+n When raising a power of a number to a power, multiply the exponents and keep the base the same. (am)n = amn When dividing two exponential numbers, subtract the powers. am/an = am-n Any exponential number divided by itself is equal to one. an/an = 1 To raise a product to a power, raise each factor to that power. (ab)n = anbn To raise a quotient to a power, raise both the numerator and denominator to that power. (a/b)n = an/bn  Rule 1:  Rule 2:  Rule 3:  Rule 4:  Rule 5:  Rule 6:  Any number to the zero power equals one. The rules for positive exponents apply to negative exponents. The rules for integer exponents apply to fractional exponents.  MA-01  Page 66  Rev. 0   Review of Introductory Mathematics  SCIENTIFIC NOTATION  SCIENTIFIC NOTATION This chapter covers the addition, subtraction, multiplication, and division of numbers in scientific notation. EO 1.13 Given the data, CONVERT integers into scientific notation and scientific notation into integers. APPLY one of the arithmetic operations of addition, subtraction, multiplication, and division to numbers using scientific notation.  EO 1.14  Calculator Usage Scientific Notation key If pressed after a number is entered on the display, the EE key will convert the number into scientific notation. If a number is to be entered in scientific notation into the calculator, pressing the EE key tells the calculator the next entered numbers are the exponential values. Scientists, engineers, operators, and technicians use large and very small numbers. The speed of light is mass of an electron is 0.000549 atomic mass units. shorter way called scientific notation, thus avoiding errors. 29,900,000,000 = 2.99 x 1010 0.000549 = 5.49 x 10-4 scientific notation when working with very 29,900,000,000 centimeters per second; the It is easier to express these numbers in a the writing of many zeros and transposition  Writing Numbers in Scientific Notation To transform numbers from decimal form to scientific notation, it must be remembered that the laws of exponents form the basis for calculations using powers.  Rev. 0  Page 67  MA-01   SCIENTIFIC NOTATION  Review of Introductory Mathematics  Using the results of the previous chapter, the following whole numbers and decimals can be expressed as powers of 10: 1 =100 10 =101 100 =102 1000 =103 10,000 =10 0.1 = 1/10 = 10-1 0.01 = 1/100 = 10-2 0.001 = 1/1000 = 10-3 4  A number N is in scientific notation when it is expressed as the product of a decimal number between 1 and 10 and some integer power of 10. N = a x 10n where 1 < a < 10 and n is an integer. The steps for converting to scientific notation are as follows: Step 1: Step 2: Step 3: Place the decimal immediately to the right of the left-most non-zero number. Count the number of digits between the old and new decimal point. If the decimal is shifted to the left, the exponent is positive. If the decimal is shifted to the right, the exponent is negative.  Let us examine the logic of this. Consider as an example the number 3750. The number will not be changed if it is multiplied by 1000 and divided by 1000 (the net effect is to multiply it by one). Then, 3750  1000 1000 3.750  1000 3.750  10 3  There is a division by 10 for each space the decimal point is moved to the left, which is compensated for by multiplying by 10. Similarly, for a number such as .0037, we multiply the number by 10 for each space the decimal point is moved to the right. Thus, the number must be divided by 10 for each space.  MA-01  Page 68  Rev. 0   Review of Introductory Mathematics  SCIENTIFIC NOTATION  Example 1: Circulating water flows at 440,000 gallons per minute. Express this number in scientific notation. Solution: 440,000 becomes 4.4 x 10 n  n = +5 because the decimal is shifted five places to the left. 440,000 = 4.4 x 10 Example 2: Express 0.0000247 in scientific notation. Solution: n= -5 because the decimal is shifted five places to the right. 0.0000247 = 2.47 x 10 Example 3: Express 34.2 in scientific notation. Solution: n= 1 because the decimal is shifted one place to the left. 34.2 = 3.42 x 10 1 -5 5  Converting Scientific Notation to Integers Often, numbers in scientific notation need to be put in integer form. To convert scientific notation to integers: Step 1: Step 2: Write decimal number. Move the decimal the number of places specified by the power of ten: to the right if positive, to the left if negative. Add zeros if necessary.  Rev. 0  Page 69  MA-01   SCIENTIFIC NOTATION  Review of Introductory Mathematics  Step 3: Example:  Rewrite the number in integer form.  Convert 4.4 x 103 to integer form. Solution:  Addition In order to add two or more numbers using scientific notation, the following three steps must be used. Step 1: Step 2: Step 3: Change all addends to have the same power of ten by moving the decimal point (that is, change all lower powers of ten to the highest power). Add the decimal numbers of the addends and keep the common power of ten. If necessary, rewrite the decimal with a single number to the left of the decimal point.  For example, for 3.5 x 103 + 5 x 102 you are asked to add 3.5 thousands to 5 hundreds. Converting 3.5 thousands to 35 hundreds ( 3.5 x 103 = 35 x 102) we obtain 35 hundreds + 5 hundreds = 40 hundreds or 3.5 x 103 = 35 x 102 + 5 x 102 = 4 x 103. The student should do the same problem by converting the 5 x 102 to thousands and then adding. Example: Add (9.24 x 104) + (8.3 x 103) Solution: Step 1: 9.24 x 104 = 9.24 x 10 8.3 x 103= 0.83 x 104 4  MA-01  Page 70  Rev. 0   Review of Introductory Mathematics  SCIENTIFIC NOTATION  Step 2: Step 3:  9.24 x 104 +0.83 x 104 10.07 x 104 = 1.007 x 10 5  Subtraction In order to subtract two numbers in scientific notation, the steps listed below must be followed. Step 1: Step 2: Step 3: Example: Subtract (3.27 x 104) - (2 x 103) Solution: Step 1: Step 2: Step 3: 3.27 x 104 = 3.27 x 10 2.00 x 103 = 0.20 x 10 3.27 x 104 -0.20 x 104 3.07 x 104 4 4  As in addition, change all addends to have the same power of ten. Subtract one digit from the other and keep the power of ten. If necessary, rewrite the decimal with a single number to the left of the decimal point.  Multiplication When multiplying two or more numbers in scientific notation, the following steps must be used. Step 1: Step 2: Step 3: Step 4: Multiply the decimal numbers and obtain the product. Multiply the powers of ten together by adding the exponents. Put the product in single-digit scientific notation. If necessary, rewrite decimal with a single number to the left of the decimal point.  Rev. 0  Page 71  MA-01   SCIENTIFIC NOTATION  Review of Introductory Mathematics  Example: Multiply (3 x 103)(5 x 10-2) Solution: Step 1: 3 x 5 = 15 Step 2: 103 x 10-2 = 10 3 + -2  =101  Step 3: The product is: 15 x 101 Step 4: = 1.5 x 10 2  Division Follow the steps listed below when dividing numbers in scientific notation. Step 1: Step 2: Step 3: Step 4: Example: (1 x 106)  5 x 104 = Solution: Step 1: 1 5 0.2 Divide one decimal into the other. Divide one power of ten into the other by subtracting the exponents. Put product in single-digit scientific notation. If necessary, rewrite decimal with a single number to the left of the decimal point.  Step 2:  106 = 10 104  (6-4)  = 10  2  Step 3: 0.2 x 102 Step 4: 2.0 x 101  MA-01  Page 72  Rev. 0   Review of Introductory Mathematics  SCIENTIFIC NOTATION  Summary Pertinent information concerning scientific notation is summarized below.  Scientific Notation Summary When changing from integer form to scientific notation: If the decimal is shifted left, the exponent is positive. If the decimal is shifted right, the exponent is negative. When adding or subtracting numbers in scientific notation, change both numbers to the same power of ten by moving the decimal point. Add or subtract the decimal numbers, and keep the power of ten. Rewrite if necessary. To multiply two numbers in scientific notation, multiply decimal numbers and add exponents. Rewrite if necessary. To divide two numbers in scientific notation, divide decimal numbers and subtract exponents. Rewrite if necessary.  Rev. 0  Page 73  MA-01   RADICALS  Review of Introductory Mathematics  RADICALS This chapter covers the addition, subtraction, multiplication, and division of radicals. EO 1.15 CALCULATE the numerical value of numbers in radical form.  Calculator Usage, Special Keys The exponent key can be used for radicals if the exponent is entered in decimal form. Exponent key Raising a number to an exponent requires the yx key to be pressed twice. First, the base number is entered and the yx key is pressed. This enters the base number (y). Next, the exponent number is entered and the yx key is pressed. This enters the exponent and tells the calculator to complete the calculation. The calculator will display the value. Square-root key Pressing this key takes the square root of the displayed number.  The Radical A previous chapter explained how to raise a number to a power. The inverse of this operation is called extracting a root. For any positive integer n, a number x is the nth root of the number a if it satisfies xn = a. For example, since 25 = 32, 2 is the fifth root of 32. To indicate the nth root of a, the expression a 1/n  is often used. The symbol n  is called the  radical sign, and the nth root of a can also be shown as a . The letter a is the radicand, and n is the index. The index 2 is generally omitted for square roots. Example: 4 3  2 3  27  MA-01  Page 74  Rev. 0   Review of Introductory Mathematics  RADICALS  Simplifying Radicals An expression having radicals is in simplest form when: The index cannot be reduced. The radicand is simplified. No radicals are in the denominator. There are four rules of radicals that will be useful in simplifying them. Rule 1: n n n  a  a  n  a  Rule 2:  n  ab  n  a  n  b  Rule 3:  Rule 4: Examples: 3  n  a 10  n  a , when n is odd.  10  2  3  26 27  26 93 3  9  3 3  33 27 3  3  54  ( 27)(2)  2  3  3  2  When a radical sign exists in the denominator, it is desirable to remove the radical. This is done by multiplying both the numerator and denominator by the radical and simplifying. 3 5 3 5 5 5 35 5  Example:  Rev. 0  Page 75  MA-01   RADICALS  Review of Introductory Mathematics  Addition and Subtraction Addition and subtraction of radicals may be accomplished with radicals showing the same radicand and the same index. Add or subtract similar radicals using the distributive law. Examples: 3 ab 75 2 ab 35 (7 (3 2) ab 3) 5 5 ab 45  Multiplication Multiplication of radicals having the same index may be accomplished by applying the rule used in simplification: 3 n n n  ab 3  a  b 27 x 6  3  Examples:  3x xy  4  9x 3x  2  3x  2  3x 2y  x 3y  Division Division of radicals having the same index, but not necessarily the same radicand, may be performed by using the following rule and simplifying.  Examples:  MA-01  Page 76  Rev. 0   Review of Introductory Mathematics  RADICALS  Dissimilar Radicals Often, dissimilar radicals may be combined after they are simplified. 4 6  Example:  81x  2  x x  64x 2x  3  3x  (3 1 2) x  2x  Changing Radicals to Exponents This chapter has covered solving radicals and then converting them into exponential form. It is much easier to convert radicals to exponential form and then perform the indicated operation. The expression 13 3 3  4 can be written with a fractional exponent as 41/3. Note that this meets the  condition 4 4 , that is, the cube root of 4 cubed equals 4. This can be expressed in the following algebraic form: a 1/n n  a  The above definition is expressed in more general terms as follows: a m/n n m n  a  a  m  Example 1: Express the following in exponential form. 3  27 2 Example 2:  2  27 2 1/2  2/3  Solve the following by first converting to exponential form. 27 3  27  27  1/2  271/3  27  5/6  but 27 = 33 substituting: 275/6 = (33) 5/6  =3  5/2  Rev. 0  Page 77  MA-01   RADICALS  Review of Introductory Mathematics  Changing Exponents to Radicals How to convert radicals into exponential form has been explained. Sometimes however, it is necessary or convenient to convert exponents to radicals. Recognizing that an exponent is the equivalent of the nth root is useful to help comprehend an expression. The expression 5 1 m m 1/3  can be written as  3  5 . It is algebraically expressed as:  a  a  The above definition can be more generally described as: n m 1 mn m n  a  (a )  a  and n m 1m n m n  b  b 15 16  b 3  Examples:  2/3  15 2  2  1/2  16  4  MA-01  Page 78  Rev. 0   Review of Introductory Mathematics  RADICALS  Summary Pertinent information concerning radicals is summarized below.  Radicals Summary n n n  a ab n  a a  n  a b  Used in simplification Used in simplification and multiplication  n  n  Used in simplification and division  n  a  a  1/n  Used to change radicals to exponents and exponents to radicals  Rev. 0  Page 79  MA-01   RADICALS  Review of Introductory Mathematics  Intentionally Left Blank  MA-01  Page 80  Rev. 0   Appendix A TI-30 Keyboard  Review of Introductory Mathematics   blank   Review of Introductory Mathematics  APPENDIX A  Figure A-1 TI-30 Keyboard Layout  Rev. 0  Page A-1  MA-01   Review of Introductory Mathematics  APPENDIX A  Intentionally Left Blank  Rev. 0  Page A-2  MA-01   Department of Energy Fundamentals Handbook  MATHEMATICS Module 2 Algebra    Algebra  TABLE OF CONTENTS  TABLE OF CONTENTS LIST OF FIGURES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iii LIST OF TABLES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iv REFERENCES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . v OBJECTIVES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vi ALGEBRAIC LAWS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Algebraic Laws . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3 LINEAR EQUATIONS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 Solutions to Algebraic Equations Algebraic Equations . . . . . . . . . Types of Algebraic Equations . . Linear Equations . . . . . . . . . . . Solving Fractional Equations . . . Ratio and Proportion . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 4 5 6 10 13 16  QUADRATIC EQUATIONS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 Types of Quadratic Equations Solving Quadratic Equations . Taking Square Root . . . . . . . Factoring Quadratic Equations The Quadratic Formula . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 17 18 21 25 30  SIMULTANEOUS EQUATIONS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 Solving Simultaneous Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41  Rev. 0  Page i  MA-02   TABLE OF CONTENTS  Algebra  TABLE OF CONTENTS (Cont) WORD PROBLEMS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 Basic Approach to Solving Algebraic Word Problems Steps for Solving Algebraic Word Problems . . . . . . . Word Problems Involving Money . . . . . . . . . . . . . . Problems Involving Motion . . . . . . . . . . . . . . . . . . . Solving Word Problems Involving Quadratic Equations Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42 43 50 54 60 62  LOGARITHMS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63 Calculator Usage, Special Keys . . . . Introduction . . . . . . . . . . . . . . . . . Definition . . . . . . . . . . . . . . . . . . . Log Rules . . . . . . . . . . . . . . . . . . . Common and Natural Logarithms . . Anti-Logarithms . . . . . . . . . . . . . . Natural and Common Log Operations Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63 63 64 65 68 69 69 71  GRAPHING . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72 The Cartesian Coordinate System Cartesian Coordinate Graphs . . . Logarithmic Graphs . . . . . . . . . Graphing Equations . . . . . . . . . Nomographs . . . . . . . . . . . . . . Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 74 77 81 82 84  . . . . .  SLOPES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 Slope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89 INTERPOLATION AND EXTRAPOLATION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90 Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90 Interpolation and Extrapolation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92  MA-02  Page ii  Rev. 0   Algebra  LIST OF FIGURES  LIST OF FIGURES Figure 1 Figure 2 Figure 3 The Cartesian Coordinate System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 Cartesian Coordinate Graph of Temperature vs. Time . . . . . . . . . . . . . . . 75 Cartesian Coordinate Graph of Density of Water vs. Temperature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 Cartesian Coordinate Plot of Radioactive Decay of Strontium 90 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78 Semi-log Plot of Radioactive Decay of Strontium 90 . . . . . . . . . . . . . . . . 79 Log-Log Plot of Frequency vs. Wavelength of Electromagnetic Radiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 Plot of x + y = 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81 Cartesian Coordinate Graph of Quadratic Equation or Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 Cartesian Coordinate Graph of Exponential Equation or Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 Typical Nomograph . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 Slope . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86  Figure 4  Figure 5 Figure 6  Figure 7 Figure 8  Figure 9  Figure 10 Figure 11  Rev. 0  Page iii  MA-02   LIST OF TABLES  Algebra  LIST OF TABLES Table 1 Table 2 Data on the Radioactive Decay of Strontium 90 . . . . . . . . . . . . . . . . . . . 77 Data on Frequency vs. Wavelength of Electromagnetic Radiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79  MA-02  Page iv  Rev. 0   Algebra  REFRENCES  REFERENCES Dolciani, Mary P., et al., Algebra Structure and Method Book 1, Atlanta: HoughtonMifflin, 1979. Naval Education and Training Command, Mathematics, Volume 1, NAVEDTRA 10069D1, Washington, D.C.: Naval Education and Training Program Development Center, 1985. Science and Fundamental Engineering, Windsor, CT: Combustion Engineering, Inc., 1985. Academic Program For Nuclear Power Plant Personnel, Volume 1, Columbia, MD: General Physics Corporation, Library of Congress Card #A 326517, 1982.  Rev. 0  Page v  MA-02   OBJECTIVES  Algebra  TERMINAL OBJECTIVE 1.0 Given a calculator and a list of formulas, APPLY the laws of algebra to solve for unknown values.  ENABLING OBJECTIVES 1.1 Given an equation, DETERMINE the governing algebraic law from the following: a. Commutative law b. Associative law c. Distributive law SOLVE for the unknown given a linear equation. APPLY the quadratic formula to solve for an unknown. Given simultaneous equations, SOLVE for the unknowns. Given a word problem, WRITE equations and SOLVE for the unknown. STATE the definition of a logarithm. CALCULATE the logarithm of a number. STATE the definition of the following terms: a. Ordinate b. Abscissa Given a table of data, PLOT the data points on a cartesian coordinate graph. Given a table of data, PLOT the data points on a logarithmic coordinate graph. Given a table of data, PLOT the data points on the appropriate graphing system to obtain the specified curve.  1.2 1.3 1.4 1.5 1.6 1.7 1.8  1.9 1.10 1.11  MA-02  Page vi  Rev. 0   Algebra  OBJECTIVES  ENABLING OBJECTIVES (Cont) 1.12 1.13 1.14 OBTAIN data from a given graph. Given the data, SOLVE for the unknown using a nomograph. STATE the definition of the following terms: a. Slope b. Intercept Given the equation, CALCULATE the slope of a line. Given the graph, DETERMINE the slope of a line. Given a graph, SOLVE for the unknown using extrapolation. Given a graph, SOLVE for the unknown using interpolation.  1.15 1.16 1.17 1.18  Rev. 0  Page vii  MA-02   Algebra  Intentionally Left Blank  MA-02  Page viii  Rev. 0   Algebra  ALGEBRAIC LAWS  ALGEBRAIC LAWS This chapter covers the laws used for solving algebraic equations. EO 1.1 Given an equation, DETERMINE the governing algebraic law from the following: a. b. c. Commutative law Associative law Distributive law  Most of the work in basic mathematics completed by DOE facility personnel involves real numbers, as mentioned in the last section. As a result, one should be very familiar with the basic laws that govern the use of real numbers. Most of these laws are covered under the general area called Algebra.  Algebraic Laws Many operations on real numbers are based on the commutative, associative, and distributive laws. The effective use of these laws is important. These laws will be stated in written form as well as algebraic form, where letters or symbols are used to represent an unknown number. The commutative laws indicate that numbers can be added or multiplied in any order. Commutative Law of Addition: a + b = b + a Commutative Law of Multiplication: a(b) = b(a) The associative laws state that in addition or multiplication, numbers can be grouped in any order. Associative Law of Addition: a+(b+c) = (a+b)+c Associative Law of Multiplication: a(bc) = (ab)c  The distributive laws involve both addition and multiplication and state the following. Distributive law: a(b + c) = ab + ac Distributive law: (a + b)c = ac + bc  Rev. 0  Page 1  MA-02   ALGEBRAIC LAWS  Algebra  The following list of axioms pertains to the real number system where a, b, and c represent any real numbers. These properties must be true for the algebraic laws to apply. Closure Properties 1. 2. 3. 4. 5. a + b is a real number ab is a real number a+0=a a(l) = a For every real number, a, there exists a real number, -a, such that a + (-a) = 0 For every real number, a  0, there exists a real number, l/a, such that a (1/a) = 1  Identity Properties  Inverse Properties  6.  An equation is a statement of equality. For example, 4 + 3 = 7. An equation can also be written with one or more unknowns (or variables). The equation x + 7 = 9 is an equality only when the unknown x = 2. The number 2 is called the root or solution of this equation. The end product of algebra is solving a mathematical equation(s). The operator normally will be involved in the solution of equations that are either linear, quadratic, or simultaneous in nature.  MA-02  Page 2  Rev. 0   Algebra  ALGEBRAIC LAWS  Summary The important information in this chapter is summarized below.  Algebraic Laws Summary Commutative Law of Addition Commutative Law of Multiplication Associative Law of Addition Associative Law of Multiplication Distributive Law a+b=b+a a(b) = b(a) a+(b+c) = (a+b)+c a(bc) = (ab)c a(b + c) = ab + ac  Rev. 0  Page 3  MA-02   LINEAR EQUATIONS  Algebra  LINEAR EQUATIONS This chapter covers solving for unknowns using linear equations. EO 1.2 SOLVE for the unknown given a linear equation.  The rules for addition, subtraction, multiplication, and division described in previous lessons will apply when solving linear equations. Before continuing this course it may be worthwhile to review the basic math laws in Module 1 and the first chapter of this module.  Solutions to Algebraic Equations The equation is the most important concept in mathematics. Alone, algebraic operations are of little practical value. Only when these operations are coupled with algebraic equations can algebra be applied to solve practical problems. An equation is a statement of equality between two equal quantities. Most people are familiar with the concept of equality. The idea of equal physical quantities is encountered routinely. An equation is merely the statement of this equality. There are three key ideas in an equation: an equation must involve two expressions, the expressions must be equal, and the equation must indicate that the expressions are equal. Thus, the statement that the sum of three and one equals four is an equation. It involves two expressions, (four and the sum of three and one), the expressions are equal, and the equation states that they are equal. The equal sign (=) is used to indicate equality in an equation. In its most general form, an algebraic equation consists of two algebraic expressions separated by an equal sign. The equal sign is the key sign in algebra. It is the sign that defines one expression in terms of another. In solving practical problems, it is the sign that defines the unknown quantity in terms of known quantities.  Algebraic Equations There are two kinds of equations: identities and conditional equations. An identity is an equation that is true for all values of the unknown involved. The identity sign () is used in place of the equal sign to indicate an identity. Thus, x2  (x)(x), 3y + 5y  8y, and yx + yz  y(x + z) are all identities because they are true for all values of x, y, or z. A conditional equation is one that is true only for some particular value(s) of the literal number(s) involved. A conditional equation is 3x + 5 = 8, because only the value x = 1 satisfies the equation. When the word equation is used by itself, it usually means a conditional equation.  MA-02  Page 4  Rev. 0   Algebra  LINEAR EQUATIONS  The root(s) of an equation (conditional equation) is any value(s) of the literal number(s) in the equation that makes the equation true. Thus, 1 is the root of the equation 3x + 5 = 8 because x = 1 makes the equation true. To solve an algebraic equation means to find the root(s) of the equation. The application of algebra is practical because many physical problems can be solved using algebraic equations. For example, pressure is defined as the force that is applied divided by the area over which it is applied. Using the literal numbers P (to represent the pressure), F (to represent the force), and A (to represent the area over which the force is applied), this physical F relationship can be written as the algebraic equation P . When the numerical values of the A force, F, and the area, A, are known at a particular time, the pressure, P, can be computed by solving this algebraic equation. Although this is a straightforward application of an algebraic equation to the solution of a physical problem, it illustrates the general approach that is used. Almost all physical problems are solved using this approach.  Types of Algebraic Equations The letters in algebraic equations are referred to as unknowns. Thus, x is the unknown in the equation 3x + 5 = 8. Algebraic equations can have any number of unknowns. The name unknown arises because letters are substituted for the numerical values that are not known in a problem. The number of unknowns in a problem determines the number of equations needed to solve for the numerical values of the unknowns. Problems involving one unknown can be solved with one equation, problems involving two unknowns require two independent equations, and so on. The degree of an equation depends on the power of the unknowns. The degree of an algebraic term is equivalent to the exponent of the unknown. Thus, the term 3x is a first degree term; 3x2 is a second degree term, and 3x3 is a third degree term. The degree of an equation is the same as the highest degree term. Linear or first degree equations contain no terms higher than first degree. Thus, 2x + 3 = 9 is a linear equation. Quadratic or second degree equations contain up to second degree terms, but no higher. Thus, x2 + 3x = 6, is a quadratic equation. Cubic or third degree equations contain up to third degree terms, but no higher. Thus, 4x3 + 3x = 12 is a cubic equation. The degree of an equation determines the number of roots of the equation. Linear equations have one root, quadratic equations have two roots, and so on. In general, the number of roots of any equation is the same as the degree of the equation.  Rev. 0  Page 5  MA-02   LINEAR EQUATIONS  Algebra  Exponential equations are those in which the unknown appears in the exponent. For example, e-2.7x = 290 is an exponential equation. Exponential equations can be of any degree. The basic principle used in solving any algebraic equation is: any operation performed on one side of an equation must also be performed on the other side for the equation to remain true. This one principle is used to solve all types of equations. There are four axioms used in solving equations: Axiom 1. If the same quantity is added to both sides of an equation, the resulting equation is still true. If the same quantity is subtracted from both sides of an equation, the resulting equation is still true. If both sides of an equation are multiplied by the same quantity, the resulting equation is still true. If both sides of an equation are divided by the same quantity, except 0, the resulting equation is still true.  Axiom 2.  Axiom 3.  Axiom 4.  Axiom 1 is called the addition axiom; Axiom 2, the subtraction axiom; Axiom 3, the multiplication axiom; and Axiom 4, the division axiom. These four axioms can be visualized by the balancing of a scale. If the scale is initially balanced, it will remain balanced if the same weight is added to both sides, if the same weight is removed from both sides, if the weights on both sides are increased by the same factor, or if the weights on both sides are decreased by the same factor.  Linear Equations These four axioms are used to solve linear equations with three steps: Step 1. Using the addition and subtraction axioms, Axioms 1 and 2, eliminate all terms with no unknowns from the left-hand side of the equation and eliminate all terms with the unknowns from the right-hand side of the equation. Using the multiplication and division axioms, Axioms 3 and 4, eliminate the coefficient from the unknowns on the left-hand side of the equation.  Step 2.  MA-02  Page 6  Rev. 0   Algebra  LINEAR EQUATIONS  Step 3. Example 1:  Check the root by substituting it for the unknowns in the original equation.  Solve the equation 3x + 7 = 13. Solution: Step 1. Using Axiom 2, subtract 7 from both sides of the equation. 3x + 7 - 7 = 13 - 7 3x = 6 Step 2. Using Axiom 4, divide both sides of the equation by 3. 3x 6 3 3 x=2 Step 3. Check the root. 3(2) + 7 = 6 + 7 = 13 The root checks. Example 2: Solve the equation 2x + 9 = 3(x + 4). Solution: Step 1. Using Axiom 2, subtract 3x and 9 from both sides of the equation. 2x + 9 = 3(x + 4) 2x + 9 - 3x - 9 = 3x + 12 - 3x - 9 -x = 3 Step 2. Using Axiom 4, divide both -1. x 1 x=sides of the equation by 3 1 3  Rev. 0  Page 7  MA-02   LINEAR EQUATIONS  Algebra  Step 3.  Check the root. 2(-3) + 9 = -6 + 9 = 3 3[(-3) + 4] = 3(1) = 3 The root checks.  These same steps can be used to solve equations that include several unknowns. The result is an expression for one of the unknowns in terms of the other unknowns. This is particularly important in solving practical problems. Often the known relationship among several physical quantities must be rearranged in order to solve for the unknown quantity. The steps are performed so that the unknown quantity is isolated on the left-hand side of the equation. Example 1: Solve the equation ax - b = c for x in terms of a, b, and c. Solution: Step 1. Using Axiom 1, add b to both sides of the equation. ax - b + b ax Step 2. = c+b = c+b  Using Axiom 4, divide both sides of the equation by a. ax a x c a c a b b  Step 3.  Check the root. a c a b b c b b c  The root checks.  MA-02  Page 8  Rev. 0   Algebra  LINEAR EQUATIONS  Example 2: The equation relating the pressure, P, to the force, F, and the area, A, over which F the force is applied is P . Solve this equation for F, in terms of P and A. A Solution: Step 1. Axioms 1 and 2 do not help solve the problem, so go to Step 2. Using Axiom 3, multiply both sides of the equation by A. P (A) F (A) A  Step 2.  F = PA Step 3. Check the root. PA A The root checks. The addition or subtraction of the same quantity from both sides of an equation may be accomplished by transposing a quantity from one side of the equation to the other. Transposing is a shortened way of applying the addition or subtraction axioms. Any term may be transposed or transferred from one side of an equation to the other if its sign is changed. Thus, in the equation 5x + 4 = 7, the 4 can be transposed to the other side of the equation by changing its sign. The result is 5x = 7 - 4 or 5x = 3. This corresponds to applying the subtraction axiom, Axiom 2, subtracting 4 from both sides of the equation. P  Rev. 0  Page 9  MA-02   LINEAR EQUATIONS  Algebra  Example: Solve the equation 4x + 3 = 19 by transposing. Solution: Step 1. Transpose the 3 from the left-hand to the right-hand side of the equation by changing its sign. 4x 4x Step 2. = 19 - 3 = 16  Using Axiom 4, divide both sides of the equation by 4. 4x 4 16 4  x=4 Step 3. Check the root. 4(4) + 3 = 16 + 3 = 19 The root checks.  Solving Fractional Equations A fractional equation is an equation containing fraction or a decimal fraction. The unknowns may or may not be part of the fraction. If they numerator or the denominator. The following 5x 1 2 8 2x 3x 6 a fraction. The fraction can be either a common can occupy any position in the equation. They are part of the fraction, they can be either in the are three examples of fractional equations: 9 y 0.67x 1.25y 9  Fractional equations are solved using the same axioms and approach used for other algebraic equations. However, the initial step is to remove the equation from fractional form. This is done by determining the lowest common denominator (LCD) for all of the fractions in the equation and then multiplying both sides of the equation by this common denominator. This will clear the equation of fractions.  MA-02  Page 10  Rev. 0   Algebra  LINEAR EQUATIONS  Example 1: Solve the fractional equation Solution: Multiply both sides of the equation by the LCD (x).  3x 8 ( x)  x  5  (0)(x) 3x x 8 5 0.  3x + 8 + 5x = 0 8x + 8 =0  Now solve the equation like an ordinary linear equation. Step 1. Transpose the +8 from the left-hand to the righthand side of the equation by changing its sign. 8x = 0 - 8 8x = -8 Step 2. Using Axiom 4, divide both sides of the equation by 8. 8x 8 8 8  x = -1 Step 3. Check the root. 3( 1) 1 8 5 3 1 8 5 5 5 0  The root checks.  Rev. 0  Page 11  MA-02   LINEAR EQUATIONS  Algebra  Example 2: Solve the fractional equation Solution: The LCD is (x - 2)(x + 3); therefore, multiply both sides of the equation by 2)(x + 3). (x 2) (x 1 3)  x 2 2) (x 3) (x 2) 1 x   3 (0) (x 2) (x 3) (x 1 x 2 x 1 3 0  (x  (x  2) (x 3) (x 3)  0  (x + 3) + (x - 2) = 0 2x + 1 = 0 Now solve the equation like an ordinary linear equation. Step 1. Transpose the +1 from the left-hand to the right-hand side of the equation by changing its sign. 2x = 0 - 1 2x = - 1 Step 2. Using Axiom 4, divide both sides of the equation by 2. 2x 2 x 1 2 1 2  MA-02  Page 12  Rev. 0   Algebra  LINEAR EQUATIONS  Step 3. 1 1 2  Check the root. 1 1 2 1 3 1 2 2 1 1 2 2 2 5 2 5 0  2  The root checks.  Ratio and Proportion One of the most important applications of fractional equations is ratio and proportion. A ratio is a comparison of two like quantities by division. It is written by separating the quantities by a colon or by writing them as a fraction. To write a ratio, the two quantities compared must be $8 of the same kind. For example, the ratio of $8 to $12 is written as $8:$12 or . Two unlike $12 quantities cannot be compared by a ratio. For example, 1 inch and 30 minutes cannot form a ratio. However, two different units can be compared by a ratio if they measure the same kind of quantity. For example, 1 minute and 30 seconds can form a ratio, but they must first be converted to the same units. Since 1 minute equals 60 seconds, the ratio of 1 minute to 30 60 seconds seconds is written 60 seconds:30 seconds, or , which equals 2:1 or 2. 30 seconds A proportion is a statement of equality between two ratios. For example, if a car travels 40 miles in 1 hour and 80 miles in 2 hours, the ratio of the distance traveled is 40 miles:80 miles, or 40 miles 1 hour , and the ratio of time is 1 hour:2 hours, or . The proportion relating these 80 miles 2 hours two ratios is: 40 miles:80 miles = 1 hour:2 hours 40 miles 80 miles 1 hour 2 hours  A proportion consists of four terms. The first and fourth terms are called the extremes of the proportion; the second and third terms are called the means. If the letters a, b, c and d are used to represent the terms in a proportion, it can be written in general form. a b c d  Rev. 0  Page 13  MA-02   LINEAR EQUATIONS  Algebra  Multiplication of both sides of this equation by bd results in the following. (bd) a b c (bd) d  ad = cb Thus, the product of the extremes of a proportion (ad) equals the product of the means (bc). For example, in the proportion 40 miles:80 miles = 1 hour:2 hours, the product of the extremes is (40 miles)(2 hours) which equals 80 miles-hours, and the product of the means is (80 miles)(1 hour), which also equals 80 miles-hours. Ratio and proportion are familiar ideas. Many people use them without realizing it. When a recipe calls for 1 cups of flour to make a serving for 6 people, and the cook wants to determine how many cups of flour to use to make a serving for 8 people, she uses the concepts of ratios and proportions. When the price of onions is 2 pounds for 49 cents and the cost of 3 pounds is computed, ratio and proportion are used. Most people know how to solve ratio and proportion problems such as these without knowing the specific steps used. Ratio and proportion problems are solved by using an unknown such as x for the missing term. The resulting proportion is solved for the value of x by setting the product of the extremes equal to the product of the means. Example 1: Solve the following proportion for x. Solution: 5:x = 4:15 The product of the extremes is (5)(15) = 75. The product of the means is (x)(4) = 4x. Equate these two products and solve the resulting equation. 4x = 75 4x 4 x 75 4 18 3 4  MA-02  Page 14  Rev. 0   Algebra  LINEAR EQUATIONS  Example 2: If 5 pounds of apples cost 80 cents, how much will 7 pounds cost? Solution: Using x for the cost of 7 pounds of apples, the following proportion can be written. 5 pounds 7 pounds 80 cents x  The product of the extremes is (5)(x) = 5x. The product of the means is (7)(80) = 560. Equate these two products and solve the resulting equation. 5x = 560 5x 5 560 5  x = 112 The unit of x is cents. Thus, 7 pounds of apples cost 112 cents or $1.12. Example 3: 1 cups of flour to make servings for 6 people. How much 2 flour should be used to make servings for 4 people? A recipe calls for 1 Solution: Using x for the flour required for 4 people, the following proportion can be written. 1 1 cups 2 x  6 people 4 people  The product of the extremes is (6)(x) = 6x. 1 The product of the means is (4) 1 6. 2 Rev. 0 Page 15 MA-02   LINEAR EQUATIONS  Algebra  Equate these two products and solve the resulting equation. 6x = 6 6x 6 6 6  x =1 The unit of x is cups. Thus, servings for 4 people require 1 cup of flour.  Summary The important information in this chapter is summarized below.  Linear Equations Summary There are four axioms used in solving linear equations. Axiom 1. If the same quantity is added to both sides of an equation, the resulting equation is still true. If the same quantity is subtracted from both sides of an equation, the resulting equation is still true. If both sides of an equation are multiplied by the same quantity, the resulting equation is still true. If both sides of an equation are divided by the same quantity, except 0, the resulting equation is still true.  Axiom 2.  Axiom 3.  Axiom 4.  Axiom 1 is called the addition axiom; Axiom 2, the subtraction axiom; Axiom 3, the multiplication axiom; and Axiom 4, the division axiom.  MA-02  Page 16  Rev. 0   Algebra  QUADRATIC EQUATIONS  QUADRATIC EQUATIONS This chapter covers solving for unknowns using quadratic equations. EO 1.3 APPLY the quadratic formula to solve for an unknown.  Types of Quadratic Equations A quadratic equation is an equation containing the second power of an unknown but no higher power. The equation x2 - 5x + 6 = 0 is a quadratic equation. A quadratic equation has two roots, both of which satisfy the equation. The two roots of the quadratic equation x2 - 5x + 6 = 0 are x = 2 and x = 3. Substituting either of these values for x in the equation makes it true. The general form of a quadratic equation is the following: ax2 - bx + c = 0 (2-1)  The a represents the numerical coefficient of x2 , b represents the numerical coefficient of x, and c represents the constant numerical term. One or both of the last two numerical coefficients may be zero. The numerical coefficient a cannot be zero. If b=0, then the quadratic equation is termed a ""pure"" quadratic equation. If the equation contains both an x and x2 term, then it is a ""complete"" quadratic equation. The numerical coefficient c may or may not be zero in a complete quadratic equation. Thus, x2 + 5x + 6 = 0 and 2x2 - 5x = 0 are complete quadratic equations.  Solving Quadratic Equations The four axioms used in solving linear equations are also used in solving quadratic equations. However, there are certain additional rules used when solving quadratic equations. There are three different techniques used for solving quadratic equations: taking the square root, factoring, and the Quadratic Formula. Of these three techniques, only the Quadratic Formula will solve all quadratic equations. The other two techniques can be used only in certain cases. To determine which technique can be used, the equation must be written in general form: ax2 + bx + c = 0 (2-1)  If the equation is a pure quadratic equation, it can be solved by taking the square root. If the numerical constant c is zero, equation 2-1 can be solved by factoring. Certain other equations can also be solved by factoring.  Rev. 0  Page 17  MA-02   QUADRATIC EQUATIONS  Algebra  Taking Square Root A pure quadratic equation can be Before taking the square root, the hand side of the equation and its quadratic equations by taking the Step 1. solved by taking the square root of both sides of the equation. equation must be arranged with the x2 term isolated on the leftcoefficient reduced to 1. There are four steps in solving pure square root.  Using the addition and subtraction axioms, isolate the x2 term on the left-hand side of the equation. Using the multiplication and division axioms, eliminate the coefficient from the x2 term. Take the square root of both sides of the equation. Check the roots.  Step 2.  Step 3. Step 4.  In taking the square root of both sides of the equation, there are two values that satisfy the equation. For example, the square roots of x2 are +x and -x since (+x)(+x) = x2 and (-x)(-x) = x2. The square roots of 25 are +5 and -5 since (+5)(+5) = 25 and (-5)(-5) = 25. The two square roots are sometimes indicated by the symbol . Thus, 25 5 . Because of this property of square roots, the two roots of a pure quadratic equation are the same except for their sign. At this point, it should be mentioned that in some cases the result of solving pure quadratic equations is the square root of a negative number. Square roots of negative numbers are called imaginary numbers and will be discussed later in this section. Example: Solve the following quadratic equation by taking the square roots of both sides. 3x2 = 100 - x Solution: Step 1. Using the addition axiom, add x2 to both sides of the equation. 3x2 + x2 4x 2 2  = 100 - x2 + x = 100  2  MA-02  Page 18  Rev. 0   Algebra  QUADRATIC EQUATIONS  Step 2.  Using the division axiom, divide both sides of the equation by 4. 4x 4 2  100 4  x2 = 25 Step 3. Take the square root of both sides of the equation. x 2  = 25  x =+ _5 Thus, the roots are x = +5 and x = -5. Step 4. Check the roots. 3x 2  = 100 - x2  3(5)2 = 100 - (5)2 3(25) = 100 - 25 75 = 75  If a pure quadratic equation is written in general form, a general expression can be written for its roots. The general form of a pure quadratic is the following. ax2 + c = 0 Using the subtraction axiom, subtract c from both sides of the equation. ax2 = -c Using the division axiom, divide both sides of the equation by a. x2 = c a (2-2)  Rev. 0  Page 19  MA-02   QUADRATIC EQUATIONS  Algebra  Now take the square roots of both sides of the equation.  x= Thus, the roots of a pure quadratic equation written in general form ax2 + c = 0 are x=+ Example: Find the roots of the following pure quadratic equation. 4x2 - 100 = 0 Solution: Using Equation 2-3, substitute the values of c and a and solve for x. and x = .  (2-3)  x=  x=  x =  25 x = 5 Thus, the roots are x = 5 and x = -5.  MA-02  Page 20  Rev. 0   Algebra  QUADRATIC EQUATIONS  Factoring Quadratic Equations Certain complete quadratic equations can be solved by factoring. If the left-hand side of the general form of a quadratic equation can be factored, the only way for the factored equation to be true is for one or both of the factors to be zero. For example, the left-hand side of the quadratic equation x2 + x - 6 = 0 can be factored into (x + 3)(x - 2). The only way for the equation (x + 3) (x - 2) = 0 to be true is for either (x + 3) or (x - 2) to be zero. Thus, the roots of quadratic equations which can be factored can be found by setting each of the factors equal to zero and solving the resulting linear equations. Thus, the roots of (x + 3)(x - 2) = 0 are found by setting x + 3 and x - 2 equal to zero. The roots are x = -3 and x = 2. Factoring estimates can be made on the basis that it is the reverse of multiplication. For example, if we have two expressions (dx + c) and (cx + g) and multiply them, we obtain (using the distribution laws) (dx + c) (fx + g) = (dx) (fx) + (dx) (g) + (c) (fx) + cg = = dfx2 + (dg + cf)x + cg. Thus, a statement (dx + c) (fx + g) = 0 can be written df x2 + (dg + cf)x + cg = 0. Now, if one is given an equation ax2 + bx + c = 0, he knows that the symbol a is the product of two numbers (df) and c is also the product of two numbers. For the example 3x2 - 4x - 4 = 0, it is a reasonable guess that the numbers multiplying x2 in the two factors are 3 and 1, although they might be 1.5 and 2. The last -4 (c in the general equation) is the product of two numbers (eg), perhaps -2 and 2 or -1 and 4. These combinations are tried to see which gives the proper value of b (dg + ef), from above. There are four steps used in solving quadratic equations by factoring. Step 1. Using the addition and subtraction axioms, arrange the equation in the general quadratic form ax2 + bx + c = 0. Factor the left-hand side of the equation. Set each factor equal to zero and solve the resulting linear equations. Check the roots.  Step 2. Step 3. Step 4.  Rev. 0  Page 21  MA-02   QUADRATIC EQUATIONS  Algebra  Example: Solve the following quadratic equation by factoring. 2x2 - 3 = 4x - x2 + 1 Solution: Step 1. Using the subtraction axiom, subtract (4x - x2 + 1) from both sides of the equation. 2x2 - 3 - (4x - x2 + 1) = 4x - x2 + 1 - (4x - x2 + 1)  3x2 - 4x - 4 = 0 Step 2. Factor the resulting equation. 3x2 - 4x - 4 = 0 (3x + 2)(x - 2) Step 3. =0  Set each factor equal to zero and solve the resulting equations. 3x + 2 = 0 3x 3x 3 x x-2 x = =0 =2 2 and x = 2. 3 = -2 2 3 2 3  Thus, the roots are x =  MA-02  Page 22  Rev. 0   Algebra  QUADRATIC EQUATIONS  Step 4.  Check the roots. 2x 2  3 3  4x  x  2  1  2 2   3 1   2 2 2   3  2  4  9   2 4   3 8 3 24 9 19 9 4x 4(2) 8 5 5 4 x 2  3 27 9 19 9  4 9 4 9  1 9 9  8 9  2x 2(2)  2  3 3 3 3 5  1 2  2  (2)  1  2(4) 8  1  Thus, the roots check. Quadratic equations in which the numerical constant c is zero can always be solved by factoring. One of the two roots is zero. For example, the quadratic equation 2x2 + 3x = 0 can be solved 3 by factoring. The factors are (x) and (2x + 3). Thus, the roots are x = 0 and x = - . If a 2 quadratic equation in which the numerical constant c is zero is written in general form, a general expression can be written for its roots. The general form of a quadratic equation in which the numerical constant c is zero is the following: ax2 + bx = 0 The left-hand side of this equation can be factored by removing an x from each term. x(ax + b) = 0 (2-5) (2-4)  Rev. 0  Page 23  MA-02   QUADRATIC EQUATIONS  Algebra  The roots of this quadratic equation are found by setting the two factors equal to zero and solving the resulting equations. x=0 x=b a (2-6) (2-7)  Thus, the roots of a quadratic equation in which the numerical constant c is zero are x = 0 and b x=- . a Example: Find the roots of the following quadratic equation. 3x2 + 7x = 0 Solution: Using Equation 2-6, one root is determined. x=0 Using Equation 2-7, substitute the values of a and b and solve for x. x=b a 7 3  x=7 . 3  Thus, the roots are x = 0 and x = -  MA-02  Page 24  Rev. 0   Algebra  QUADRATIC EQUATIONS  The Quadratic Formula Many quadratic equations cannot readily be solved by either of the two techniques already described (taking the square roots or factoring). For example, the quadratic equation x2 - 6x + 4 = 0 is not a pure quadratic and, therefore, cannot be solved by taking the square roots. In addition, the left-hand side of the equation cannot readily be factored. The Quadratic Formula is a third technique for solving quadratic equations. It can be used to find the roots of any quadratic equation. b  b 2 4ac 2a  x  (2-8)  Equation 2-8 is the Quadratic Formula. It states that the two roots of a quadratic equation written in general form, ax2 + bx + c = 0, are equal to x = x= b b b 2 4ac and 2a  b 2 4ac . The Quadratic Formula should be committed to memory because it is 2a such a useful tool for solving quadratic equations. There are three steps in solving a quadratic equation using the Quadratic Formula. Step 1. Step 2. Write the equation in general form. Substitute the values for a, b, and c into the Quadratic Formula and solve for x. Check the roots in the original equation.  Step 3.  Rev. 0  Page 25  MA-02   QUADRATIC EQUATIONS  Algebra  Example 1: Solve the following quadratic equation using the Quadratic Formula. 4x2 + 2 = x2 - 7x: Solution: Step 1. Write the equation in general form. 4x 3x 2 2  2 2  x 0  2  7x  7x  a  3, b  7, c  2 4ac  x  b  b2 2a  x  7  (7)2 4(3)(2) 2(3) 7  49 24 6 7  25 6 75 6 7 6 2 , 6 5 , 7 6 5  x  Step 2.  x  x  x  x  12 6  x  1 ,2 3 1 and x = -2. 3  Thus, the roots are x = -  MA-02  Page 26  Rev. 0   Algebra  QUADRATIC EQUATIONS  Step 3.  Check the roots. 4x 2  2 2  x  2  7x  1 7   3   1 2 4   3  4  1  9   1 2   3 1 9 1 9 22 9 and,  2 18 9 22 9   7   3 21 9  4 9  4x2 + 2  = x2 - 7x  4(-2)2 + 2 = (-2)2 - 7(-2) 4(4) + 2 = 4 -(-14) 16 + 2 = 4 + 14 18 = 18 Thus, the roots check.  Rev. 0  Page 27  MA-02   QUADRATIC EQUATIONS  Algebra  Example 2: Solve the following quadratic equation using the Quadratic Formula. 2x2 + 4 = 6x + x Solution: Step 1. Write the equation in general form. 2x x a 1, b 2 2 2  4 4 4  6x 0  x  2  6x 6, c  x  b  b2 2a  4ac  x  ( 6)  ( 6)2 2(1) 6  36 2 6  20 2 3 1 20 2 1 (4)(5) 2 16  4(1)(4)  x  x Step 2. x  x x x x x  3  3 5 3 3 5, 3 2.236, 3 5 2.236  5.236, 0.746  MA-02  Page 28  Rev. 0   Algebra  QUADRATIC EQUATIONS  Step 3.  Check the roots. 2x 2(3 2(9 65 12 5 32 and, 2x 2(3 2(9 65 12 5 32 5) 2 2  4 4 4 4  6x 6(3 18 18 32  x  2  5)  2  5) 65 12 5 12 5  (3 9 9  5) 65 5  2  5) 10  5  18  12 5  4 4 4 4  6x 6(3 18 18 32  x  2  2  5) 65 12 5 12 5  (3 9 9  5) 65 5  2  5) 10  5  18  12 5  Thus, the roots check. The Quadratic Formula can be used to find the roots of any quadratic equation. For a pure quadratic equation in which the numerical coefficient b equals zero, the Quadratic Formula (2-8) reduces to the formula given as Equation 2-9. b  b2 2a 4ac  x  (2-8)  Rev. 0  Page 29  MA-02   QUADRATIC EQUATIONS  Algebra  For b = 0, this reduces to the following.  (2-9)  Summary The important information in this chapter is summarized below.  Quadratic Equations Summary There are three methods used when solving quadratic equations: Taking the square root Factoring the equation Using the quadratic formula b b 2 4ac 2a  x  MA-02  Page 30  Rev. 0   Algebra  SIMULTANEOUS EQUATIONS  SIMULTANEOUS EQUATIONS This chapter covers solving for two unknowns using simultaneous equations. EO 1.4 Given simultaneous unknowns. equations, SOLVE for the  Many practical problems that can be solved using algebraic equations involve more than one unknown quantity. These problems require writing and solving several equations, each of which contains one or more of the unknown quantities. The equations that result in such problems are called simultaneous equations because all the equations must be solved simultaneously in order to determine the value of any of the unknowns. The group of equations used to solve such problems is called a system of equations. The number of equations required to solve any problem usually equals the number of unknown quantities. Thus, if a problem involves only one unknown, it can be solved with a single equation. If a problem involves two unknowns, two equations are required. The equation x + 3 = 8 is an equation containing one unknown. It is true for only one value of x: x = 5. The equation x + y = 8 is an equation containing two unknowns. It is true for an infinite set of xs and ys. For example: x = 1, y = 7; x = 2, y = 6; x = 3, y = 5; and x = 4, y = 4 are just a few of the possible solutions. For a system of two linear equations each containing the same two unknowns, there is a single pair of numbers, called the solution to the system of equations, that satisfies both equations. The following is a system of two linear equations: 2x + y = 9 x-y=3 The solution to this system of equations is x = 4, y = 1 because these values of x and y satisfy both equations. Other combinations may satisfy one or the other, but only x = 4, y = 1 satisfies both. Systems of equations are solved using the same four axioms used to solve a single algebraic equation. However, there are several important extensions of these axioms that apply to systems of equations. These four axioms deal with adding, subtracting, multiplying, and dividing both sides of an equation by the same quantity. The left-hand side and the right-hand side of any equation are equal. They constitute the same quantity, but are expressed differently. Thus, the left-hand and right-hand sides of one equation can be added to, subtracted from, or used to multiply or divide the left-hand and right-hand sides of another equation, and the resulting equation will still be true. For example, two equations can be added.  Rev. 0  Page 31  MA-02   SIMULTANEOUS EQUATIONS  Algebra  3x (x 4x  4y 5y 9y  7 12) 19  Adding the second equation to the first the first equation. Thus, the resulting subtracted. 4x (2x 2x  corresponds to adding the same quantity to both sides of equation is still true. Similarly, two equations can be 3y 5y 8y 8 11) 3  Subtracting the second equation from the first corresponds to subtracting the same quantity from both sides of the first equation. Thus, the resulting equation is still true. The basic approach used to solve a system of equations is to reduce the system by eliminating the unknowns one at a time until one equation with one unknown results. This equation is solved and its value used to determine the values of the other unknowns, again one at a time. There are three different techniques used to eliminate unknowns in systems of equations: addition or subtraction, substitution, and comparison.  Solving Simultaneous Equations The simplest system of equations is one involving two linear equations with two unknowns. 5x + 6y = 12 3x + 5y = 3 The approach used to solve systems of two linear equations involving two unknowns is to combine the two equations in such a way that one of the unknowns is eliminated. The resulting equation can be solved for one unknown, and either of the original equations can then be used to solve for the other unknown. Systems of two equations involving two unknowns can be solved by addition or subtraction using five steps. Step 1. Multiply or divide one or both equations by some factor or factors that will make the coefficients of one unknown numerically equal in both equations. Eliminate the unknown having equal coefficients by addition or subtraction. Solve the resulting equation for the value of the one remaining unknown.  Step 2.  Step 3.  MA-02  Page 32  Rev. 0   Algebra  SIMULTANEOUS EQUATIONS  Step 4.  Find the value of the other unknown by substituting the value of the first unknown into one of the original equations. Check the solution by substituting the values of the two unknowns into the other original equation.  Step 5.  Example: Solve the following system of equations using addition or subtraction. 5x + 6y = 12 3x + 5y = 3 Solution: Step 1. Make the coefficients of y equal in both equations by multiplying the first equation by 5 and the second equation by 6. 5(5x + 6y = 12) yields 25x + 30y = 60 6(3x + 5y = 3) yields 18x + 30y = 18 Step 2. Subtract the second equation from the first. 25x 30y (18x 30y 7x 0 Step 3. 60 18) 42  Solve the resulting equation. 7x 7x 7 x = 42 = 42 7 =6  Rev. 0  Page 33  MA-02   SIMULTANEOUS EQUATIONS  Algebra  Step 4.  Substitute x = 6 into one of the original equations and solve for y. 5x 5(6) 30 6y 6y 6y 6y 6y 6y 6 y 12 12 12 12 18 18 6 3 30  Step 5.  Check the solution by substituting x = 6 and y = -3 into the other original equation. 3x 3(6) 18 5y 5( 3) 15 3 Thus, the solution checks. 3 3 3 3  Systems of two equations involving two unknowns can also be solved by substitution. Step 1. Step 2. Step 3. Step 4. Solve one equation for one unknown in terms of the other. Substitute this value into the other equation. Solve the resulting equation for the value of the one remaining unknown. Find the value of the other unknown by substituting the value of the first unknown into one of the original equations. Check the solution by substituting the values of the two unknowns into the other original equation.  Step 5.  MA-02  Page 34  Rev. 0   Algebra  SIMULTANEOUS EQUATIONS  Example: Solve the following system of equations using substitution. 5x + 6y = 12 3x + 5y = 3 Solution: Step 1. Solve the first equation for x. 5x 6y 5x 5x 5 x Step 2. 12 12 12 5 12 5 6y 5 6y 6y  Substitute this value of x into the second equation. 3x  12 3 5 6y   5 5y 5y 3 3  Rev. 0  Page 35  MA-02   SIMULTANEOUS EQUATIONS  Algebra  Step 3.  Solve the resulting equation. 6y   12 3  5y 5 5  36 5  36 (5)  5 36 18y 5 18 y 5 18y 5y  5y  25y 7y 7y 7y 7 y  3  3  3(5) 15 15 21 21 7 3 36  Step 4.  Substitute y = -3 into one of the original equations and solve for x. 5x 5x 5x 6y 6( 3) 18 5x 5x 5x 5 x 12 12 12 12 30 30 5 6 18  Step 5.  Check the solution by substituting x = 6 and y = -3 into the other original equation. 3x + 5y = 3(6) + 5(-3) = 18 - 15 = 3= Thus, the solution checks. 3 3 3 3  MA-02  Page 36  Rev. 0   Algebra  SIMULTANEOUS EQUATIONS  Systems of two equations involving two unknowns can also be solved by comparison. Step 1. Step 2. Step 3. Step 4. Solve each equation for the same unknown in terms of the other unknown. Set the two expressions obtained equal to each other. Solve the resulting equation for the one remaining unknown. Find the value of the other unknown by substituting the value of the first unknown into one of the original equations. Check the solution by substituting the values of the two unknowns into the other original equation.  Step 5.  Example: Solve the following system of equations by comparison. 5x + 6y = 12 3x + 5y = 3 Solution: Step 1. Solve both equations for x. 5x 6y 5x 5x 5 x 3x 5y 3x 3x 3 x 12 12 12 5 12 5 3 3 3 3 3 3 5y 5y 5y 6y 6y 6y  Rev. 0  Page 37  MA-02   SIMULTANEOUS EQUATIONS  Algebra  Step 2.  Set the two values for x equal to each other. 12 5 6y 3 3 5y  Step 3.  Solve the resulting equation for y. 12 5 (3) (5) 12 5 6y) 18y 18y 7y 7y 7 y 5(3 15 15 21 21 7 3 6y 3 3 6y 3 3 5y (3) (5) 5y  3(12 36 25y  5y) 25y 36  Step 4.  Substitute y = -3 into one of the original equations and solve for x. 5x 5x 5x 6y 6( 3) 18 5x 5x 5x 5 x 12 12 12 12 30 30 5 6 18  MA-02  Page 38  Rev. 0   Algebra  SIMULTANEOUS EQUATIONS  Step 5.  Check the solution by substituting x = 6 and y = -3 into the other original equation. 3x 3(6) 18 5y 5( 3) 15 3 Thus, the solution checks. 3 3 3 3  Quite often, when more than one unknown exists in a problem, the end result of the equations expressing the problem is a set of simultaneous equations showing the relationship of one of the unknowns to the other unknowns. Example: Solve the following simultaneous equations by substitution. 3x + 4y = 6 Solution: Solve for x: 3x = 6 - 4y x = 2 - 4y 3 5x + 3y = -1  Rev. 0  Page 39  MA-02   SIMULTANEOUS EQUATIONS  Algebra  Substitute the value for x into the other equation: 5 (2 - 4y) + 3y = -1 3 10 - 20y + 3y = -1 3 10 - 20y + 9y = -1 3 3 10 - 11y = -1 3 -11y = -11 3 y=3 Substitute y = 3 into the first equation: 3x + 4(3) = 6 3x = -6 x = -2 Check the solution by substituting x = -2 and y = 3 into the original equations. 3x + 4y = 6 3(-2) + 4(3) = 6 -6 + 12 = 6 6 =6 Thus, the solution checks. 5x + 3y = -1 5(-2) + 3(3) = -1  -10 + 9 = -1 -1 = -1  MA-02  Page 40  Rev. 0   Algebra  SIMULTANEOUS EQUATIONS  Summary The important information in this chapter is summarized below.  Simultaneous Equations Summary There are three methods used when solving simultaneous equations: Addition or subtraction Substitution Comparison  Rev. 0  Page 41  MA-02   WORD PROBLEMS  Algebra  WORD PROBLEMS This chapter covers ways of setting up word problems and solving for the unknowns. EO 1.5 Given a word problem, write equations and SOLVE for the unknown.  Basic Approach to Solving Algebraic Word Problems Algebra is used to solve problems in science, industry, business, and the home. Algebraic equations can be used to describe laws of motion, pressures of gases, electric circuits, and nuclear facility operations. They can be applied to problems about the ages of people, the cost of articles, football scores, and other everyday matters. The basic approach to solving problems in these apparently dissimilar fields is the same. First, condense the available information into algebraic equations, and, second, solve the equations. Of these two basic steps, the first is frequently the most difficult to master because there are no clearly defined rules such as those that exist for solving equations. Algebraic word problems should not be read with the objective of immediately determining the answer because only in the simpler problems is this possible. Word problems should be initially read to identify what answer is asked for and to determine which quantity or quantities, if known, will give this answer. All of these quantities are called the unknowns in the problem. Recognizing all of the unknowns and writing algebraic expressions to describe them is often the most difficult part of solving word problems. Quite often, it is possible to identify and express the unknowns in several different ways and still solve the problem. Just as often, it is possible to identify and express the unknowns in several ways that appear different but are actually the same relationship. In writing algebraic expressions for the various quantities given in word problems, it is helpful to look for certain words that indicate mathematical operations. The words ""sum"" and ""total"" signify addition; the word ""difference"" signifies subtraction; the words ""product,"" ""times,"" and ""multiples of"" signify multiplication; the words ""quotient,"" ""divided by,"" ""per,"" and ""ratio"" signify division; and the words ""same as"" and ""equal to"" signify equality. When quantities are connected by these words and others like them, these quantities can be written as algebraic expressions. Sometimes you may want to write equations initially using words. For example, Bob is 30 years older than Joe. Express Bob's age in terms of Joe's. Bob's age = Joe's age plus 30 years  MA-02  Page 42  Rev. 0   Algebra  WORD PROBLEMS  If we let Bob's age be represented by the symbol B and Joe's age by the symbol J, this becomes B = J + 30 years Examples: Equations: 1. The total electrical output of one nuclear facility is 200 megawatts more than that of another nuclear facility. Let L be the output of the larger facility and S the capacity of the smaller facility. The statement above written in equation form becomes L = 200MW+ S. 2. The flow in one branch of a piping system is one-third that in the other branch. If B is the flow in the branch with more flow, and b is the flow in the smaller branch, this statement becomes the equation b 1 B. 3  3.  A man is three times as old as his son was four years ago. Let M = man's age and S = son's age. Then M = 3 (S-4).  4.  A car travels in one hour 40 miles less than twice as far as it travels in the next hour. Let x1 be the distance it travels the first hour and x2 the distance it travels the second then, x1 = (2) (x2) -40.  Steps for Solving Algebraic Word Problems Algebraic word problems can involve any number of unknowns, and they can require any number of equations to solve. However, regardless of the number of unknowns or equations involved, the basic approach to solving these problems is the same. First, condense the available information into algebraic equations, and, second, solve the equations. The most straightforward type of algebraic word problems are those that require only one equation to solve. These problems are solved using five basic steps. Step 1. Let some letter, such as x, represent one of the unknowns.  Rev. 0  Page 43  MA-02   WORD PROBLEMS  Algebra  Step 2.  Express the other unknowns in terms of x using the information given in the problem. Write an equation that says in symbols exactly what the problem says in words. Solve the equation. Check the answer to see that it satisfies the conditions stated in the problem.  Step 3.  Step 4. Step 5.  Example 1: What are the capacities of two water storage tanks in a nuclear facility if one holds 9 gallons less than three times the other, and their total capacity is 63 gallons? Solution: Step 1. Step 2. Step 3. Let x = Capacity of the Smaller Tank Then, 3x - 9 = Capacity of the Larger Tank Total Capacity = Capacity of the Smaller Tank + Capacity of the Larger Tank 63 = x + (3x - 9) Step 4. Solving for x: x + (3x - 9) = 63 4x - 9 = 63 4x = 63 + 9 4x = 72 x = 18  MA-02  Page 44  Rev. 0   Algebra  WORD PROBLEMS  Solving for the other unknown: 3x - 9 = 3(18) - 9 3x - 9 = 54 - 9 3x - 9 = 45 Answer: Capacity of the Smaller Tank = 18 gallons Capacity of the Larger Tank = 45 gallons The larger tank holds 9 gallons less than three times the smaller tank. 3(18) - 9 = 54 - 9 = 45 The total capacity of the two tanks is 63 gallons. 18 + 45 = 63 Thus, the answers check. Example 2: A utility has three nuclear facilities that supply a total of 600 megawatts (Mw) of electricity to a particular area. The largest facility has a total electrical output three times that of the smallest facility. The third facility has an output that is 50 Mw more than half that of the largest facility. What is the electrical output of each of the three facilities? Solution: Step 1. Step 2. Let x = Electrical Output of the Smallest Facility. Then, 3x = Electrical Output of the Largest Facility, and, 3x + 50 = Electrical Output of the Third Facility. 2  Step 5.  Rev. 0  Page 45  MA-02   WORD PROBLEMS  Algebra  Step 3.  Total Electrical Output = Sum of the Electrical Outputs of the Three Facilities. 3x 2  600  x  3x  50  Step 4.  Solving for x: x 3x 3x 2 50 600  2x 2  6x 2  3x 2  600  50  11x 2  550  11x = 1100 x = 100 Solving for the other unknowns: 3x = 3(100) 3x = 300 1 (3x) 2 1 (3x) 2 1 (3x) 2 Answers: 50 1 (300) 2 50  50  150  50  50  200  Electrical Output of the Smallest Facility = 100 Mw Electrical Output of the Largest Facility = 300 Mw Electrical Output of the Third Facility = 200 Mw  MA-02  Page 46  Rev. 0   Algebra  WORD PROBLEMS  Step 5.  The largest facility has a total electrical output three times that of the smallest facility. 3(100) = 300 The other facility has an output which is 50 Mw more than half that of the largest facility. 1 (300) 2 50 150 50 200  The total output of the three facilities is 600 Mw. 100 + 200 + 300 = 600 Thus, the answers check. Example 3: The winning team in a football game scored 7 points less than twice the score of the losing team. If the total score of both teams was 35 points, what was the final score? Solution: Step 1. Let x = Winning Team's Score 1 (x 2  Step 2.  Then,  7) = Losing Team's Score  Step 3.  Total Score = Winning Team's Score + Losing Team's Score 1 (x 2  35  x  7)  Rev. 0  Page 47  MA-02   WORD PROBLEMS  Algebra  Step 4.  Solving for x: 1 (x 2  x  7)  35  2x  x  7  70  3x  70  7  3x = 63 x = 21 points Solving for the other unknowns: 1 (x 2 1 (21 2  7)  7)  1 (x 2  7)  1 (28) 2  1 (x 2 Answers:  7)  14 points  Winning Team's Score = 21 points Losing Team's Score = 14 points The winning team's score is 7 points less than twice the score of the losing team. 2(14) - 7 = 28 - 7 = 21 points The total score of both teams is 35 points. 21 + 14 = 35 points Thus, the answers check.  Step 5.  MA-02  Page 48  Rev. 0   Algebra  WORD PROBLEMS  Example 4: A man is 21 years older than his son. Five years ago he was four times as old as his son. How old is each now? Solution: Step 1. Step 2. Let x = Son's Age Now Then, x + 21 = Father's Age Now x - 5 = Son's Age Five Years Ago (x + 21) - 5 = Father's Age Five Years Ago Step 3. Five years ago the father was four times as old as his son. (x + 21) - 5 = 4(x - 5) Step 4. (x + 21) - 5 x + 16 x - 4x -3x x = = = = = 4(x - 5) 4x - 20 -20 - 16 -36 12 years  Solving for the other unknowns: x + 21 = 12 + 21 x + 21 = 33 years Answers: Son's Age Now = 12 years Father's Age Now = 33 years The man is 21 years older than his son. 12 + 21 = 33 years Five years ago he was four times as old as his son. 33 - 5 = 28 = 4(12 - 5) = 4 x 7 Thus, the answers check.  Step 5.  Rev. 0  Page 49  MA-02   WORD PROBLEMS  Algebra  Word Problems Involving Money The five basic steps for solving algebraic word problems can be used for solving word problems involving money. Writing algebraic expressions for these problems depends on the general relationship between the total value and the unit value of money. The total value of a collection of money or a collection of items with a certain monetary value equals the sum of the numbers of items each multiplied by their unit values. Thus, the total value of five pennies, three nickels, four dimes, and two quarters is found by solving the following equation: x = 5($0.01) + 3($0.05) + 4($.10) + 2($0.25) x = $0.05 + $0.15 + $0.40 + $0.50 x = $1.10 The total value of 25 tickets worth $1.50 each and 30 tickets worth $0.75 each is 25($1.50) + 30($0.75) which equals $37.50 + $22.50 or $60.00. Algebraic word problems involving money are solved using this general relationship following the same five basic steps for solving any algebraic word problems. Example 1: The promoter of a track meet engages a 6,000 seat armory. He wants to gross $15,000. The price of children's tickets is to be one-half the price of adults' tickets. If one-third of the crowd is children, what should be the price of tickets, assuming capacity attendance? Solution: Step 1. Step 2. Let x = Price of an Adult Ticket (in dollars) Then, x 2  = Price of a Child's Ticket (in  dollars) 1 (6,000) 3 2,000 = Number of Children's Tickets  6,000 - 2,000 = 4,000 = Number of Adults' Tickets  MA-02  Page 50  Rev. 0   Algebra  WORD PROBLEMS  Step 3.  Gross Income = (Number of Children's Tickets times their Unit Price) + (Number of Adults' Tickets times their Unit Price)  2,000   x  2  $15,000  4,000 (x)  Step 4.  Solving for x:  2,000   x  2  15,000  4,000 (x)  15,000  1,000x  4,000x  15,000  5,000x  x  $3.00  solving for the other unknown: x 2  = Price of a Child's Ticket (in dollars)  x 2  $3.00 2  x 2 Answers:  $1.50  Price of Adults' Tickets = $3.00 Price of Children's Tickets = $1.50  Rev. 0  Page 51  MA-02   WORD PROBLEMS  Algebra  Step 5.  The price of children's tickets is one-half the price of adults' tickets. 1 ($3.00) 2 The gross is $15,000. 4,000($3.00) + 2,000($1.50) = $12,000 + $3,000 = $15,000 Thus, the answers check.  $1.50  Example 2: A collection of coins consists of nickels, dimes, and quarters. The number of quarters is twice the number of nickels, and the number of dimes is five more than the number of nickels. If the total amount of money is $5.05, how many of each type of coin are in the collection? Solution: Step 1. Step 2. Let x = Number of Nickels Then, 2x = Number of Quarters x + 5 = Number of Dimes Step 3. Total Value = (Number of Nickels)(Value of a Nickel) + (Number of Dimes)(Value of a Dime) + (Number of Quarters)(Value of a Quarter) $5.05 = (x)($0.05) + (x + 5)($0.10) + (2x)($0.25) Step 4. Solving for x: $5.05 = (x)($0.05) + (x + 5)($0.10) + (2x)($0.25) $5.05 = $0.05x + $0.10x + $0.50 + $0.50x $5.05 = $0.65x + $0.50 $0.65x = $5.05 - $0.50 $0.65x = $4.55  MA-02  Page 52  Rev. 0   Algebra  WORD PROBLEMS  x=  $4.55 $0.65  x =7 Solving for the other unknowns: 2x = 2(7) 2x = 14 x+5=7+5 x + 5 = 12 Answers: Number of Nickels Number of Dimes =7 = 12  Number of Quarters = 14  Step 5.  The number of quarters is twice the number of nickels. 2(7) = 14 The number of dimes is five more than the number of nickels. 7 + 5 = 12 The total value is $5.05. 7($0.05) + 12($0.10) + 14($0.25) = $0.35 + $1.20 + $3.50 = $5.05 Thus, the answers check.  Rev. 0  Page 53  MA-02   WORD PROBLEMS  Algebra  Problems Involving Motion Many algebraic word problems involve fundamental physical relationships. Among the most common are problems involving motion. For example, the definition of speed is distance traveled divided by the time it takes. Vave distance time d t or multiplying both sides by t, d  = Vave x t. For example, if a car travels at 50 miles per hour for 2 hours, the distance traveled equals (50 mi/hr)(2 hr) or 100 miles. This relationship applies for constant velocity motion only. In practice, it is applied more generally by using an average speed or average rate of travel for the time involved. The distance traveled is often represented by s; the average speed or average rate of travel, also called the average velocity, by vav; and the time of travel by t. s = vavt (2-13)  This same basic physical relationship can be written in two other forms, obtained by dividing both sides of the equation by vav or by t. s vav  t  (2-14)  v  av  s t  (2-15)  Example 1: How far can a car traveling at a rate of 52 miles per hour travel in 2 hours? Solution: Using Equation 2-13: s = vavt s = (52 miles/hour)(2 hours) s = 130 miles  MA-02  Page 54  Rev. 0   Algebra  WORD PROBLEMS  Example 2: How long does it take a plane traveling at 650 miles per hour to go 1430 miles? Solution: Using Equation 2-14: t s vav  t  1430 miles miles 650 hour t = 2.2 hours  Example 3: What is the average speed of a train that completes a 450-mile trip in 5 hours? Solution: Using Equation 2-15: v av  s t  v  av  450 miles 5 hours 90 miles/hour  v  av  Algebraic word problems involving motion are solved using the general relationship among distance, time, and average velocity following the same five basic steps for solving any algebraic word problem. Example 1: A plane flying at 525 miles per hour completes a trip in 2 hours less than another plane flying at 350 miles per hour. What is the distance traveled?  Rev. 0  Page 55  MA-02   WORD PROBLEMS  Algebra  Solution: Step 1. Step 2. Let x = Distance Traveled (in miles) Then, using Equation 2-14, x 525 x 350 Step 3. = Time Taken by Faster Plane (in hours)  = Time Taken by Slower Plane (in hours)  Time Taken by Faster Plane = Time Taken by Slower Plane - 2 hours x hours 525 x 525 x 525 x (350) (525)   525  x hours 350 x 350 x 700 350 700 350   (350) (525)  2 hours   x 700   350  350x = 525 (x - 700) 350x = 525x - 367,500 350x - 525x = -367,500 -175x = -367,5000 175x 175 367,500 175  x = 2100 miles  MA-02  Page 56  Rev. 0   Algebra  WORD PROBLEMS  Solving for the other unknowns: x 525 = Time Taken by Faster Plane (in hours)  x 525 x 525 x 350  2100 525  = 4 hours  = Time Taken by Slower Plane (in hours)  x 350 x 350 Answers:  2100 350  = 6 hours  Distance Traveled = 2100 miles Time Taken by Faster Plane = 4 hours Time Taken by Slower Plane = 6 hours The faster plane takes 2 hours less to complete the trip than the slower plane. 6 hours - 2 hours = 4 hours Thus, the answer checks.  Step 5.  Example 2: It takes a man 4 hours to reach a destination 1325 miles from his home. He drives to the airport at an average speed of 50 miles per hour, and the average speed of his plane trip is 500 miles per hour. How far does he travel by each mode of transportation? Solution: Step 1. Step 2. Let x = Distance Traveled by Car (in miles) Then,  Rev. 0  Page 57  MA-02   WORD PROBLEMS  Algebra  1325 - x = Distance Traveled by Plane (in miles) and, using Equation 2-14, x 50  = Time Traveled by Car (in hours)  1325 x 500 Step 3.  = Time Traveled by Plane (in hours)  Total Time = (Time Traveled by Car) + (Time Traveled by Plane) x hours 50 1325 x hours 500  4 hours  Step 4.  Solving for x: 4 x 50 1325 x 500  4  10x  1325 500  x  (500) 4  9x  1325 (500) 500  2000 = 9x + 1325 2000 - 1325 = 9x 685 = 9x 9x 9 675 9  x = 75 miles Solving for the other unknowns:  MA-02  Page 58  Rev. 0   Algebra  WORD PROBLEMS  x 50  = Time Traveled by Car (in hours)  x 50  75 50  x 50  1  1 hours 2  1325 x 500  = Time Traveled by Plane (in hours)  1325 x 500  1324 75 500  1325 x 500  1250 500  2  1 hours 2  1325 - x = Distance Traveled by Plane (in miles) 1325 - x = 1325 - 75 1325 - x = 1250 miles Answers: Distance Traveled by Car = 75 miles Distance Traveled by Plane = 1250 miles The total distance traveled is 1325 miles. 75 miles + 1250 miles = 1325 miles The average speed by car is 50 miles per hour.  Step 5.  Rev. 0  Page 59  MA-02   WORD PROBLEMS  Algebra  75 miles 1 1 hours 2  = 50 miles per hour  The average speed by plane is 500 miles per hour. 1250 miles 1 2 hours 2  = 500 miles per hour  The total time traveling is 4 hours. 1 hours + 2 hours = 4 hours Thus, the answers check.  Solving Word Problems Involving Quadratic Equations Many algebraic word problems involve quadratic equations. Any time the algebraic expressions describing the relationships in the problem involve a quantity multiplied by itself, a quadratic equation must be used to solve the problem. The steps for solving word problems involving quadratic equations are the same as for solving word problems involving linear equations. Example: A radiation control point is set up near a solid waste disposal facility. The pad on which the facility is set up measures 20 feet by 30 feet. If the health physicist sets up a controlled walkway around the pad that reduces the area by 264 square feet, how wide is the walkway? Solution: Step 1. Step 2. Let x = Width of the Walkway Then, 30 - 2x = Length of Reduced Pad 20 - 2x = Width of Reduced Pad  MA-02  Page 60  Rev. 0   Algebra  WORD PROBLEMS  Step 3.  Area of Reduced Pad =  (Length of Reduced Pad)(Width of Reduced Pad) 2x)(20 100x 2x) 4x 2  600  264 336  (30 600  Step 4.  Solve this quadratic equation. 4x2 - 100x + 264 = 0 Using the Quadratic Formula, substitute the coefficients for a, b, and c and solve for x.  x  b  b2 2a  4ac  x  ( 100)  ( 100) 2(4) 100  10,000 8 100  5,776 8 100  76 8 100 8 176 24 , 8 8 22, 3 76 , 100 8  2  4(4)(264)  x  4,224  x  x  x  76  x x  The two roots are x = 22 feet and x = 3 feet. Since x = 22 feet is not physically meaningful, the answer is x = 3 feet.  Rev. 0  Page 61  MA-02   WORD PROBLEMS  Algebra  Step 5.  Check the answer. The area of the reduced area pad is 264 square feet less than the area of the original pad. 600 264 336 336 336 336 (20 [20 (20 2x)(30 2(3)][30 6)(30 6) 2x) 2(3)]  (14)(24) 336  Thus, the answer checks.  Summary The important information from this chapter is summarized below.  Algebraic Word Problems Summary Algebraic word problems can easily be solved by following these five basic steps: Step 1. Let some letter, such as x, represent one of the unknowns. Express the other unknowns in terms of x using the information given in the problem. Write an equation that represents in symbols exactly what the problem states in words. Solve the equation. Check the answer to see that it satisfies the conditions stated in the problem.  Step 2.  Step 3.  Step 4. Step 5.  MA-02  Page 62  Rev. 0   Algebra  LOGARITHMS  LOGARITHMS This chapter covers changing the base of a logarithm and solving problems with logarithms. EO 1.6 EO 1.7 STATE the definition of a logarithm. CALCULATE the logarithm of a number.  Calculator Usage, Special Keys This chapter will require the use of certain keys on a calculator to perform the necessary calculations. An understanding of the functions of each key will make logarithms (logs) an easy task. Common Logarithm key This key when pressed will compute the common log (base 10) of the number x in the display, where x is greater than zero. Natural Logarithm key This key when pressed will compute the natural logarithm (base e) of the number x in the display, where x is greater than zero. This key when pressed before the log and ln keys will compute the antilog of the number x in the display. When used with the log key it will raise 10 to the displayed power (107.12) and when used with the ln key will raise (e) to the displayed power (e-381).  Introduction Logarithms are exponents, as will be explained in the following sections. Before the advent of calculators, logarithms had great use in multiplying and dividing numbers with many digits since adding exponents was less work than multiplying numbers. Now they are important in nuclear work because many laws governing physical behavior are in exponential form. Examples are radioactive decay, gamma absorption, and reactor power changes on a stable period.  Rev. 0  Page 63  MA-02   LOGARITHMS  Algebra  Definition Any number (X) can be expressed by any other number b (except zero) raised to a power x; that is, there is always a value of x such that X = bx. For example, if X = 8 and b = 2, x = 3. For X = 8 and b = 4, 8 = 4x is satisfied if x = 3/2. 3 2 1 32 1 2  4 or  (4 )  (64)  8  4  3 2  (4 )  1 23  2  3  8  In the equation X = bx, the exponent x is the logarithm of X to the base b. Stated in equation form, x = logb X, which reads x is the logarithm to the base b of X. In general terms, the logarithm of a number to a base b is the power to which base b must be raised to yield the number. The rules for logs are a direct consequence of the rules for exponents, since that is what logs are. In multiplication, for example, consider the product of two numbers X and Y. Expressing each as b raised to a power and using the rules for exponents: XY = (bx) (by) = bx+y Now, equating the logb of the first and last terms, logb XY = logb bx+y. Since the exponent of the base b (x+y) is the logarithm to the base b, Logb b logb XY = x+y Similarily, since X = bx and Y = by, logb X = x and logb Y = y. Substituting these into the previous equation, logb XY = logb X + logb Y Before the advent of hand-held calculators it was common to use logs for multiplication (and division) of numbers having many significant figures. First, logs for the numbers to be multiplied were obtained from tables. Then, the numbers were added, and this sum (logarithm of the product) was used to locate in the tables the number which had this log. This is the product of the two numbers. A slide rule is designed to add logarithms as numbers are multiplied. Logarithms can easily be computed with the calculator using the keys identified earlier. x+y  = x+y.  MA-02  Page 64  Rev. 0   Algebra  LOGARITHMS  Examples: log2 8 = 3 log10 0.01 = -2 log5 5 = 1 logb 1 = 0 since since since since 8=2 3  0.01 = 10 5=5 1=b 1  -2  From the above illustration, it is evident that a logarithm is an exponent. 34 is called the exponential form of the number 81. In logarithmic form, 34 would be expressed as log3 81 = 4, or the logarithm of 81 to the base 3 is 4. Note the symbol for taking the logarithm of the number 81 to a particular base 3, is log3 81, where the base is indicated by a small number written to the right and slightly below the symbol log.  Log Rules Since logs are exponents, the rules governing logs are very similar to the laws of exponents. The most common log rules are the following: 1. 2. 3. 4. 5. 6. 7. logb (ABC) = logb A + logb B + logb C logb (A/B) = logb A - logb B logb (An) = nlogb A logb b = 1 log n b  A = logb A1/n = (1/n)logb A  logb 1 = 0 logb (1/A) = logb 1 - logb A = -logb A  Rev. 0  Page 65  MA-02   LOGARITHMS  Algebra  Example 1: Solution:  y=  12 gt where g = 32 2  y = 16 t2 Find y for t = 10 using logs. log10y = log10 (16 t2) log10y = log10 16 + log10 t 2  log10y = log10 16 + (2 log10 t) log10y = 1.204 + 2 log10 10 log10y = 1.204 + 2 x 1 log10y = 3.204 but this means 10 y = 1600 3.204  =y  Example 2: Solution: Rule 2.  Calculate log10 2 - log10 3.  log10 (A/B): log10 A - log10 B log10 2 - log10 3 = log10 (2/3) = log10 (.667) = -0.176  MA-02  Page 66  Rev. 0   Algebra  LOGARITHMS  Example 3: Solution: Rule 3.  Calculate 3log10 2.  logb (An) = nlogb A 3log10 2 = log10 (23) = log10 8 = 0.903  Example 4: Solution: Rule 4.  Calculate 4log10 10.  logb b = 1 4log10 10 = 4(1) =4  Example 5: Solution: Rule 5.  Calculate (1/3)log10 2.  log  n b  A = logb A1/n = (1/n)logb A  (1/3)log10 2 = log10 3  2  = log10 1.259 = 0.1003  Rev. 0  Page 67  MA-02   LOGARITHMS  Algebra  Example 6: Solution: Rule 6.  Calculate log10 1.  logb 1 = 0 log10 1 = 0  Example 7: Solution:  Calculate -log10 2.  Rule 7:  logb (1/A) = -logbA -log10 2 = log10 (1/2) = -log10 0.5 = -0.3010  Common and Natural Logarithms In scientific and engineering practice, the natural system of logarithms uses the number 2.718281828459042. Since this number is frequently encountered, the letter e is used. Many natural occurrences can be expressed by exponential equations with e as the base. For example, the decay of radioactive isotopes can be expressed as a natural logarithm equation. These logarithmic expressions are called natural logs because e is the basis for many laws of nature. The expression ln is used to represent a logarithm when e is the base. Therefore, the exponential equation is written as ex = N. and the logarithm expression is written as loge N = x or lnN = x.  As with base 10 logs (common logs), natural logs can be determined easily with the aid of a calculator.  MA-02  Page 68  Rev. 0   Algebra  LOGARITHMS  Base 10 logs are often referred to as common logs. Since base 10 is the most widely used number base, the ""10"" from the designation log10 is often dropped. Therefore, any time ""log"" is used without a base specified, one should assume that base 10 is being used.  Anti-Logarithms An anti-logarithm is the opposite of a logarithm. Thus, finding the anti-logarithm of a number is the same as finding the value for which the given number is the logarithm. If log10 X = 2, then 2.0 is the power (exponent) to which one must raise the base 10 to obtain X, that is, X = 102.0 = 100. The determination of an anti-log is the reverse process of finding a logarithm.  Example: Multiply 38.79 and 6896 using logarithms. Log 38.79 = 1.58872 Add the logarithms to get 5.42732 Find the anti-log. Anti-log 5.42732 = 2.675 x 105 = 267,500 Thus, 38.79 x 6896 = 2.675 x 105 = 267,500 Log 6896 = 3.83860  Natural and Common Log Operations The utilization of the log/ln can be seen by trying to solve the following equation algebraically. This equation cannot be solved by algebraic methods. The mechanism for solving this equation is as follows: Using Common Logs 2 log 2 log 7 log 2 X X  Using Natural Logs 2 ln 2 ln 7 ln 2 X X  7 log 7 log 7 0.8451 0.3010 2.808 X  7 ln 7 ln 7 1.946 0.693 2.808  X log 2 X  X ln 2  Rev. 0  Page 69  MA-02   LOGARITHMS  Algebra  How would you calculate x in the following equation? log x = 5  The easy way to solve this equation is to take the anti-log. As division is the reverse of multiplication, so anti-log is the reverse of log. To take the anti-log log10 x = 5: anti-log (log X) = anti-log 5 x = anti-log 5 x = 100,000 This is accomplished on a calculator by pressing the 5, INV, then the LOG key. This causes the inverse of the log process.  MA-02  Page 70  Rev. 0   Algebra  LOGARITHMS  Summary The important information in this chapter is summarized below.  Logarithms Summary A number L is said to be the logarithm of a positive real number N to the base b (where b is real, positive, and not equal to 1), if L is the exponent to which b must be raised to obtain N, or the function can be expressed as L = Logb N for which the inverse is N = bL Simply stated, the logarithm is the inverse of the exponential function. Product = baseexponent Logbaseproduct = exponent Logb (ABC) = logb A + logb B + logb C Logb (A/B) = logb A - logb B Logb (An) = nlogb A Logb n  A = logb A1/n = (1/n)logb A  Logb 1 = 0 Logb (1/A) = logb 1 - logb A = -logbA    Common logs are base 10 Natural logs are base e Anti-log is the opposite of a log  Rev. 0  Page 71  MA-02   GRAPHING  Algebra  GRAPHING This chapter covers graphing functions and linear equations using various types of graphing systems. EO 1.8 STATE the definition of the following terms: a. Ordinate b. Abscissa Given a table of data, PLOT the data points on a cartesian coordinate graph. Given a table of data, PLOT the data points on a logarithmic coordinate graph. Given a table of data, PLOT the data points on the appropriate graphing system to obtain the specified curve. Obtain data from a given graph. Given the data, SOLVE for the unknown using a nomograph.  EO 1.9  EO 1.10  EO 1.11  EO 1.12 EO 1.13  In work with physical systems, the relationship of one physical quantity to another is often of interest. For example, the power level of a nuclear reactor can be measured at any given time. However, this power level changes with time and is often monitored. One method of relating one physical quantity to another is to tabulate measurements. Thus, the power level of a nuclear reactor at specific times can be recorded in a log book. Although this method does provide information on the relationship between power level and time, it is a difficult method to use effectively. In particular, trends or changes are hard to visualize. Graphs often overcome these disadvantages. For this reason, graphs are widely used. A graph is a pictorial representation of the relationship between two or more physical quantities. Graphs are used frequently both to present fundamental data on the behavior of physical systems and to monitor the operation of such systems. The basic principle of any graph is that distances are used to represent the magnitudes of numbers. The number line is the simplest type of graph. All numbers are represented as distances along the line. Positive numbers are located to the right of zero, and negative numbers are located to the left of zero.  MA-02  Page 72  Rev. 0   Algebra  GRAPHING  The coordinate system of a graph is the framework upon which the graph is drawn. A coordinate system consists of numbered scales that give the base and the direction for measuring points on the graph. Any point on a graph can be specified by giving its coordinates. Coordinates describe the location of the point with respect to the scales of the coordinate system. There are several different coordinate systems commonly encountered.  The Cartesian Coordinate System The Cartesian Coordinate System, also known as the rectangular coordinate system, consists of two number scales, called the x-axis (at y = 0) and the y-axis (at x = 0), that are perpendicular to each other. Each scale is a number line drawn to intersect the other at zero. The zero point is called the origin. The divisions along the scales may be any size, but each division must be equal. Figure 1 shows a rectangular coordinate system. The axes divide the coordinate system into four regions called quadrants. Quadrant I is the region above the x-axis and to the right of the y-axis. Quadrant II is the region above the x-axis and to the left of the y-axis. Quadrant III is the region below the x-axis and to the left of the y-axis. Quadrant IV is the region below the x-axis and to the right of the y-axis.  Figure 1  The Cartesian System  Rev. 0  Page 73  MA-02   GRAPHING  Algebra  The use of a graph starts with the plotting of data points using the coordinate system. These data points are known as the abscissa and the ordinate. The abscissa, also known as the y-coordinate, is the distance along the y-axis. The ordinate, also known as the x-coordinate, is the distance along the x-axis. A point on a Cartesian coordinate graph is specified by giving its x-coordinate and its y-coordinate. Positive values of the x-coordinate are measured to the right, negative values to the left. Positive values of the y-coordinate are measured up, negative values down. For example, the x- and y-coordinates are both zero at the origin. The origin is denoted as (0,0), where the first zero refers to the value of the x-coordinate. Point A in Figure 1 is denoted as (0,4), since the value of the x-coordinate is zero, and the value of the y-coordinate is 4. In Quadrant I, every point has a positive x-coordinate and a positive y-coordinate. Point B in Figure 1 is located in Quadrant I and is denoted by (4,2). Fractional values of coordinates can also be shown. Point C in Figure 1 is denoted by (1,1.5). In Quadrant II, every point has a negative x-coordinate and a positive y-coordinate. Point D is denoted by (-2,2). In Quadrant III, every point has a negative x-coordinate and a negative y-coordinate. Point E is located in Quadrant III and is denoted by (-2,-4). In Quadrant IV, every point has a positive x-coordinate, but a negative y-coordinate. Point F is located in Quadrant IV and is denoted by (5,-4).  Cartesian Coordinate Graphs The most common type of graph using the Cartesian Coordinate System is one in which all values of both the x-coordinate and the y-coordinate are positive. This corresponds to Quadrant I of a Cartesian coordinate graph. The relationship between two physical quantities is often shown on this type of rectangular plot. The x-axis and the y-axis must first be labeled to correspond to one of the physical quantities. The units of measurement along each axis must also be established. For example, to show the relationship between reactor power level and time, the x-axis can be used for time in minutes and the y-axis for the reactor power level as a percentage of full power level. Data points are plotted using the associated values of the two physical quantities. Example: The temperature of water flowing in a high pressure line was measured at regular intervals. Plot the following recorded data on a Cartesian coordinate graph. Time (min) 0 15 30 45 60 75 90 105 120 Temperature (F) 400 420 440 460 480 497 497 497 497  MA-02  Page 74  Rev. 0   Algebra  GRAPHING  The first step is to label the x-axis and the y-axis. Let the x-axis be time in minutes and the y-axis be temperature in F. The next step is to establish the units of measurement along each axis. The x-axis must range from 0 to 120, the y-axis from 400 to 500. The points are then plotted one by one. Figure 2 shows the resulting Cartesian coordinate graph.  Figure 2  Cartesian Coordinate Graph of Temperature vs. Time  Example:  The density of water was measured over a range of temperatures. following recorded data on a Cartesian coordinate graph. Temperature (C) 40 50 60 70 80 90 100 Density (g/ml) 0.992 0.988 0.983 0.978 0.972 0.965 0.958  Plot the  Rev. 0  Page 75  MA-02   GRAPHING  Algebra  The first step is to label the x-axis and the y-axis. Let the x-axis be temperature in C and the y-axis be density in g/ml. The next step is to establish the units of measurement along each axis. The x-axis must range from approximately 40 to 100, the y-axis from 0.95 to 1.00. The points are then plotted one by one. Figure 3 shows the resulting Cartesian coordinate graph.  Figure 3  Cartesian Coordinate Graph of Density of Water vs. Temperature  Graphs are convenient because, at a single glance, the major features of the relationship between the two physical quantities plotted can be seen. In addition, if some previous knowledge of the physical system under consideration is available, the numerical value pairs of points can be connected by a straight line or a smooth curve. From these plots, the values at points not specifically measured or calculated can be obtained. In Figures 2 and 3, the data points have been connected by a straight line and a smooth curve, respectively. From these plots, the values at points not specifically plotted can be determined. For example, using Figure 3, the density of water at 65C can be determined to be 0.98 g/ml. Because 65C is within the scope of the available data, it is called an interpolated value. Also using Figure 3, the density of water at 101C can be estimated to be 0.956 g/ml. Because 101C is outside the scope of the available  MA-02  Page 76  Rev. 0   Algebra  GRAPHING  data, it is called an extrapolated value. Although the value of 0.956 g/ml appears reasonable, an important physical fact is absent and not predictable from the data given. Water boils at 100C at atmospheric pressure. At temperatures above 100C it is not a liquid, but a gas. Therefore, the value of 0.956 g/ml is of no significance except when the pressure is above atmospheric. This illustrates the relative ease of interpolating and extrapolating using graphs. It also points out the precautions that must be taken, namely, interpolation and extrapolation should be done only if there is some prior knowledge of the system. This is particularly true for extrapolation where the available data is being extended into a region where unknown physical changes may take place.  Logarithmic Graphs Frequently, the function to be plotted on a graph makes it convenient to use scales different from those used for the Cartesian coordinate graphs. Logarithmic graphs in which one or both of the scales are divided logarithmically are common. A semi-log plot is used when the function is an exponential, such as radioactive decay. A semi-log plot is obtained by using an ordinary linear scale for one axis and a logarithmic scale for the other axis. A log-log plot is used when the function is a power. A log-log plot is obtained by using logarithmic scales for both axes. Table 1 gives data on the amount of radioactive strontium 90 present as a function of time in years. Every twenty-five years one-half of the material decays. Figure 4 is a Cartesian coordinate graph of the data given in Table 1. It can be seen from Figure 4 that it is difficult to determine from this plot the amount of strontium 90 present after long periods of time such as 125 years, 150 years, or 175 years.  TABLE 1 Data on the Radioactive Decay of Strontium 90 Time (years) 0 25 50 75 100 125 150 175 Amount of Strontium 90 (grams) 100 50 25 12.5 6.25 3.125 1.5625 0.78125  Rev. 0  Page 77  MA-02   GRAPHING  Algebra  Figure 4  Cartesian Coordinate Plot of Radioactive Decay of Strontium 90  If the same data, the decay of strontium 90, is plotted on semi-log, the resulting plot (Figure 5) will be a straight line. This is because the decay of radioactive material is an exponential function. The resulting straight line of the semi-log plot allows a more accurate extrapolation or interpolation of the data than the curve obtained from the cartesian plot. For graphs in which both of the quantities (x,y) vary as a power function, a log-log plot is convenient. A log-log plot is obtained by using logarithmic scales for both axes. Table 2 gives data on the frequency of electromagnetic radiation as a function of the wavelength of the radiation. Figure 6 is a log-log plot of the data given in Table 2.  MA-02  Page 78  Rev. 0   Algebra  GRAPHING  Figure 5  Semi-log Plot of Radioactive Decay of Strontium 90  TABLE 2 Data on Frequency vs. Wavelength of Electromagnetic Radiation Wavelength (cm) 1 0 1 0 1 . . . . . 0 5 0 5 0 x x x x x 1 1 1 1 1 0 0 0 0 0 -8 -7 -7 -6 -6  Frequency (s-1) 3 6 3 6 3 x x x x x 1 1 1 1 1 0 0 0 0 0 18 17 17 16 16  Rev. 0  Page 79  MA-02   GRAPHING  Algebra  Figure 6  Log-Log Plot of Frequency vs. Wavelength of Electromagnetic Radiation  In summary, the type of coordinate system used to plot data, cartesian, semi-log, or log-log, should be based on the type of function to be graphed and the desired shape (curve or line) of the curve wanted. Cartesian system Linear (y = mx + b) type functions when plotted will provide straight lines; exponential functions (y = ex) will plot as curves. Should not plot linear type functions on semi-log. Exponential functions, such as radioactive decay and reactor power equations when plotted will graph as straight lines. Rarely used; used to plot power equations.  Semi-log system -  Log-log -  MA-02  Page 80  Rev. 0   Algebra  GRAPHING  Graphing Equations Algebraic equations involving two unknowns can readily be shown on a graph. Figure 7 shows a plot of the equation x + y = 5. The equation is solved for corresponding sets of values of x and y that satisfy the equation. Each of these points is plotted and the points connected. The graph of x + y = 5 is a straight line.  Figure 7  Plot of x + y = 5  The x-intercept of a line on a graph is defined as the value of the x-coordinate when the y-coordinate is zero. It is the value of x where the graph intercepts the x-axis. The y-intercept of a graph is defined as the value of the y-coordinate when the x-coordinate is zero. It is the value of y where the graph intercepts the y-axis. Thus, the x-intercept of the graph of x + y = 5 is +5. For a linear equation in the general form ax + by = c, the x-intercept and y-intercept can also be given in general form. Any algebraic equation involving two unknowns of any function relating two physical quantities can be plotted on a Cartesian coordinate graph. Linear equations or linear functions plot as straight lines on Cartesian coordinate graphs. For example, x + y = 5 and f(x) = 3x + 9 plot as straight lines. Higher order equations or functions, such as quadratic equations or functions and exponential equations, can be plotted on Cartesian coordinate graphs. Figure 8 shows the shape of the graph of a typical quadratic equation or function. This shape is called a parabola. Figure 9 shows the shape of the graph of a typical exponential equation or function.  Rev. 0  Page 81  MA-02   GRAPHING  Algebra  Figure 8 Cartesian Coordinate Graph of Quadratic Equation or Function  Figure 9 Cartesian Coordinate Graph of Exponential Equation or Function  Nomographs A nomograph is a device used to relate the physical quantities in such a way that the value of an unknown quantity can be determined given the values of the other related quantities. Nomographs normally involve the relationship among three physical quantities. The scales are located in such a way that, when a straight line is drawn between the values of the known quantities on their respective scales, the line crosses the value of the unknown quantity on its scale. Figure 10 is a typical nomograph that relates the distance traveled, the average speed, and the time traveled. It should be noted that, as with any graphical representation, the values determined are only approximations.  Figure 10  Typical Nomograph  MA-02  Page 82  Rev. 0   Algebra  GRAPHING  Example: Using Figure 10, find the distance traveled if the average speed is 20 mph and the time traveled is 40 minutes. The line labeled A in Figure 10 connects 20 mph and 40 minutes. It passes through 14.5 miles. Thus, the distance traveled is 14.5 miles. Example: Using Figure 10, find the time required to travel 31 miles at an average speed of 25 mph. The line labeled B in Figure 10 connects 31 miles and 25 mph. It passes through 70 minutes. Thus, the time required is 70 minutes.  Rev. 0  Page 83  MA-02   GRAPHING  Algebra  Summary The important information in this chapter is summarized below.  Graphing Summary Ordinate Abscissa x-coordinate y-coordinate  Cartesian Coordinate System Rectangular Coordinate System Divided into four quadrants by x- and y-axis  Logarithmic Coordinate System One or both of the scales are divided logarithmically Semi-log graphs contain linear x-axis and logarithmic y-axis Log-log graphs contain logarithmic x- and y-axis  Linear functions are usually plotted on Cartesian coordinate graph. Exponential functions (y = ex) are usually plotted on semi-log graphs to provide a straight line instead of the resulting curve placed on a Cartesian coordinate graph. Power functions (Y = ax2, y = ax3, etc.) are usually plotted on log-log graphs.  MA-02  Page 84  Rev. 0   Algebra  SLOPES  SLOPES This chapter covers determining and calculating the slope of a line. EO 1.14 STATE the definition of the following terms: a. Slope b. Intercept Given the equation, CALCULATE the slope of a line. Given the graph, DETERMINE the slope of a line.  EO 1.15 EO 1.16  Many physical relationships in science and engineering may be expressed by plotting a straight line. The slope(m), or steepness, of a straight line tells us the amount one parameter changes for a certain amount of change in another parameter.  Slope For a straight line, slope is equal to rise over run, or slope rise run change in y change in x y x y x 2 2  y x  1 1  Consider the curve shown in Figure 11. Points P1 and P2 are any two different points on the line, and a right triangle is drawn whose legs are parallel to the coordinate axes. The length of the leg parallel to the x-axis is the difference between the x-coordinates of the two points and is called ""x,"" read ""delta x,"" or ""the change in x."" The leg parallel to the y-axis has length y, which is the difference between the y-coordinates. For example, consider the line containing points (1,3) and (3,7) in the second part of the figure. The difference between the x-coordinates is x = 3-1 = 2. The difference between the y-coordinates is y = 7-3 = 4. The ratio of the differences, y/x, is the slope, which in the preceding example is 4/2 or 2. It is important to notice that if other points had been chosen on the same line, the ratio y/x would be the same, since the triangles are clearly similar. If the points (2,5) and (4,9) had been chosen, then y/x = (9-5)/(4-2) = 2, which is the same number as before. Therefore, the ratio y/x depends on the inclination of the line, m = rise [vertical (y-axis) change]  run [horizontal (x-axis) change].  Rev. 0  Page 85  MA-02   SLOPES  Algebra  Figure 11 Slope  MA-02  Page 86  Rev. 0   Algebra  SLOPES  Since slope m is a measure of the steepness of a line, a slope has the following characteristics: 1. 2. 3. 4. A horizontal line has zero slope. A line that rises to the right has positive slope. A line rising to the left has negative slope. A vertical line has undefined slope because the calculation of the slope would involve division by zero. ( y/x approaches infinity as the slope approaches vertical.)  Example: Solution:  What is the slope of the line passing through the points (20, 85) and (30, 125)? m 125 30 85 20 40 10 4  Given the coordinates of the y-intercept where the line crosses the y-axis [written (0, y)] and the equation of the line, determine the slope of the line. The standard linear equation form is y = mx + b. If an equation is given in this standard form, m is the slope and b is the y coordinate for the y-intercept.  Example:  Determine the slope of the line whose equation is y = 2x + 3 and whose y-intercept is (0,3). y = mx + b y = 2x + 3 m=2  Solution:  Rev. 0  Page 87  MA-02   SLOPES  Algebra  Example:  Determine the slope of the line whose equation is 2x + 3y = 6 and whose y-intercept is (0,2). y = mx + b 2x + 3y = 6 3y = 6 - 2x 3y = -2x + 6 y = -2x + 6 3 y = -2/3x + 2 m = -2/3 Write in standard form.  Solution:  Example: Plot the graph of the following linear function. Determine the x-intercept, the y-intercept, and the slope. 7x + 3y = 21 Solution: y = mx + b y = (-7/3)x + 7 x-intercept = 3 y-intercept = 7 Slope = -2.333  MA-02  Page 88  Rev. 0   Algebra  SLOPES  Summary The important information in this chapter is summarized below.  Slopes Summary For a straight line, slope is equal to rise over run, or Slope Rise Run Change in y Change in x y x  Since slope m is a measure of the steepness of a line, a slope has the following characteristics: 1. 2. 3. 4. A horizontal line has zero slope. A line that rises to the right of vertical has positive slope. A line rising to the left of vertical has negative slope. A vertical line has undefined slope because the calculation of the slope would involve division by zero (y/x approaches infinity as the slope approaches vertical).  Rev. 0  Page 89  MA-02   INTERPOLATION AND EXTRAPOLATION  Algebra  INTERPOLATION AND EXTRAPOLATION This chapter covers the use of interpolation and extrapolation to solve for unknowns on various types of graphs. EO 1.17 Given a graph, SOLVE for the unknown using extrapolation. Given a graph, SOLVE for the unknown using interpolation.  EO 1.18  Definitions Interpolation Interpolation is the process of obtaining a value from a graph or table that is located between major points given, or between data points plotted. A ratio process is usually used to obtain the value. Extrapolation Extrapolation is the process of obtaining a value from a chart or graph that extends beyond the given data. The ""trend"" of the data is extended past the last point given and an estimate made of the value.  Interpolation and Extrapolation Developing a curve from a set of data provides the student with the opportunity to interpolate between given data points. Using the curve in the following example, the value of the dependent variable at 4.5 can be estimated by interpolating on the curve between the two data points given, resulting in the value of 32. Note that the interpolation is the process of obtaining a value on the plotted graph that lies between two given data points. Extrapolation is the process in which information is gained from plotted data by extending the data curve beyond the points of given data (using the basic shape of the curve as a guide), and then estimating the value of a given point by using the extended (extrapolated) curve as the source. The above principles are illustrated in the example that follows.  MA-02  Page 90  Rev. 0   Algebra  INTERPOLATION AND EXTRAPOLATION  Example: Given equation y = x2 + 2x + 3: Plot the curve for x from 0 to 5. Extrapolate the curve and give the value of y at x = 6. Put 6 into the equation evaluating y, then compare the values. Interpolate the curve at x = 4.5. Put 4.5 into the equation evaluating y, then compare the values.  Extrapolating x = 6 gives a value of y = 48. Using the equation, the actual value of y is 51. Interpolating x = 4.5 gives a value of y = 32. Using the equation, the actual value of y is 32.25.  Rev. 0  Page 91  MA-02   INTERPOLATION AND EXTRAPOLATION  Algebra  Summary The important information in this chapter is summarized below.  Interpolation and Extrapolation Summary Interpolation Interpolation is the process of obtaining a value from a graph or table that is located between major points given, or between data points plotted. A ratio process is usually used to obtain the value. Extrapolation Extrapolation is the process of obtaining a value from a chart or graph that extends beyond the given data. The ""trend"" of the data is extended past the last point given and an estimate made of the value.  MA-02  Page 92  Rev. 0"
GX039-02-15844827	MED: Cultivation Medium      the name of a standard medium or composition of the medium
GX055-38-10059168	NMRPipe Processing Functions    REV Reverse Data              Command-Line Argument List     REV: reverse spectrum.  -sw            Adjust Sweep Width                 and ppm calibration.
GX003-44-2179192	"Short Descriptions     [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]     This appendix lists and briefly describes programs in the Wisconsin Package. Programs are grouped by function and may appear under multiple functional headings.  For more information on using these programs, see the  Program Manual .    + - Denotes a program that generates graphics which require a graphics output device.                 Comparison       Pairwise Comparison     Gap   Uses the algorithm of Needleman and Wunsch to find the alignment of two complete sequences that maximizes the number of matches and minimizes the number of gaps.     BestFit   Makes an optimal alignment of the best segment of similarity between two sequences. Optimal alignments are found by inserting gaps to maximize the number of matches using the local homology algorithm of Smith and Waterman.     FrameAlign   Creates an optimal alignment of the best segment of similarity (local alignment) between a protein sequence and the codons in all possible reading frames on a single strand of a nucleotide sequence.  Optimal alignments may include reading frame shifts.     Compare   Compares two protein or nucleic acid sequences and creates a file of the points of similarity between them for plotting with  DotPlot . Compare finds the points using either a window/stringency or a word match criterion. The word comparison is 1,000 times faster than the window/stringency comparison, but somewhat less sensitive.     DotPlot+   Makes a dot-plot with the output file from  Compare  or  StemLoop .     GapShow+   Displays an alignment by making a graph that shows the distribution of similarities and gaps.  The two input sequences should be aligned with either  Gap  or  BestFit  before they are given to GapShow for display.     ProfileGap   Makes an optimal alignment between a profile and one or more sequences.     Multiple Comparison     PileUp+   Creates a multiple sequence alignment from a group of related sequences using progressive, pairwise alignments.  It can also plot a tree showing the clustering relationships used to create the alignment.     HmmerAlign*   Uses a profile hidden Markov model (HMM) as a template to create an optimal multiple alignment of a group of sequences.     SeqLab   Is the graphical user interface for the Wisconsin Package. For additional information, refer to the SeqLab Guide.     PlotSimilarity+   Plots the running average of the similarity among the sequences in a multiple sequence alignment.     Pretty   Displays multiple sequence alignments and calculates a consensus sequence.  It does not create the alignment; it simply displays it.     PrettyBox+   Displays multiple sequence alignments as shaded boxes in Postscript format for printing or displaying with a Postscript-compatible device.  PrettyBox  optionally calculates a consensus sequence.  The program does not  create the alignment; it simply displays it.     MEME   (Multiple EM for Motif Elicitation) Finds conserved motifs in a group unaligned sequences. MEME saves these motifs as a set of profiles. You can search a database of sequences with these profiles using the  MotifSearch  program.     HmmerBuild*   Creates a position-specific scoring table, called a profile hidden Markov  model (HMM), that is a statistical model of the consensus of a multiple sequence alignment. The profile HMM can be used for database searching (HmmerSearch), sequence alignment (HmmerAlign) or generating random sequences that match the model (HmmerEmit).     HmmerCalibrate*   ""Calibrates"" a profile hidden Markov model in order to increase the sensitivity of database searches performed using that profile HMM as a query. The program compares the original profile HMM with a large number of randomly generated sequences and computes the extreme value distribution (EVD) parameters for this simulated search. The original profile HMM is replaced with a new one that contains these EVD parameters.     ProfileMake   Creates a position-specific scoring table, called a profile, that quantitatively represents the information from a group of aligned sequences.  The profile can then be used for database searching (ProfileSearch) or sequence alignment (ProfileGap).     ProfileGap   Makes an optimal alignment between a profile and one or more sequences.     Overlap   Compares two sets of DNA sequences to each other in both orientations using a  WordSearch  style comparison.     NoOverlap   Identifies the places where a group of nucleotide sequences do not share any common subsequences.     OldDistances   Makes a table of the pairwise similarities within a group of aligned sequences.       Database Searching       Reference Searching         LookUp   Identifies sequence database entries by name, accession number, author, organism, keyword, title, reference, feature, definition, length, or date. The output is a list of sequences.     StringSearch   Identifies sequences by searching for character patterns such as ""globin"" or ""human"" in the sequence documentation.     Names   Identifies GCG data files and sequence entries by name. It can show you what set of sequences is implied by any sequence specification.     Sequence Searching         BLAST   Searches for sequences similar to a query sequence. The query and the database searched can be either peptide or nucleic acid in any combination.  BLAST can search databases on your own computer or databases maintained at the National Center for Biotechnology Information (NCBI) in Bethesda, Maryland, USA.     NetBLAST   Searches for sequences similar to a query sequence. The query and the database searched can be either peptide or nucleic acid in any combination. NetBLAST can search only databases maintained at the National Center for Biotechnology Information (NCBI) in Bethesda, Maryland, USA.     FastA   Does a Pearson and Lipman search for similarity between a query sequence and a group of sequences of the same type (nucleic acid or protein). For nucleotide searches, FastA may be more sensitive than  BLAST .     SSearch   Does a rigorous Smith-Waterman search for similarity between a query sequence and a group of sequences of the same type (nucleic acid or protein). This may be the most sensitive method available for similarity searches. Compared to  BLAST  and  FastA , it is very slow.     TFastA   Does a Pearson and Lipman search for similarity between a protein query sequence and any group of nucleotide sequences. TFastA translates the nucleotide sequences in all six reading frames before performing the comparison.  It is designed to answer the question, ""What implied protein sequences in a nucleotide sequence database are similar to my protein sequence?""     TFastX   Does a Pearson and Lipman search for similarity between a protein query sequence and any group of nucleotide sequences, taking frameshifts into account. It is designed to be a replacement for  TFastA , and like TFastA, it is designed to answer the question, ""What implied protein sequences in a nucleotide sequence database are similar to my protein sequence?"" TFastA treats each of the six reading frames of a nucleotide sequence as a separate sequence, resulting in three separate alignments for each strand. TFastX, on the other hand, compares the protein query sequence to only one translated protein per strand of the nucleotide sequence, resulting in one alignment per strand. It calculates a similarity score for alignments that takes frameshifts into account, allowing it to ""join"" short regions separated by frameshifts into a single long alignment. TFastX may alert you to more meaningful hits than TFastA does when the nucleotide sequences contain frameshift errors.     FastX   Does a Pearson and Lipman search for similarity between a nucleotide query sequence and a group of protein sequences, taking frameshifts into account. FastX translates both strands of the nucleic sequence before performing the comparison. It is designed to answer the question, ""What implied protein sequences in my nucleic acid sequence are similar sequences in a protein database?""     FrameSearch+   Searches a group of protein sequences for similarity to one or more nucleotide query sequences, or searches a group of nucleotide sequences for similarity to one or more protein query sequences.  For each sequence comparison, the program finds an optimal alignment between the protein sequence and all possible codons on each strand of the nucleotide sequence.  Optimal alignments may include reading frame shifts.     MotifSearch   Uses a set of profiles (representing similarities  within a family of sequences) as a query to either a) search a database for new sequences similar to the original family, or b) annotate the members of the the original family with details of the  matches between the profiles and each of the members. Normally, the profiles are created with the program  MEME .     HmmerSearch*   Uses a profile hidden Markov model as a query to search a sequence database to find sequences similar to the family from which the profile HMM was built. Profile HMMs can be created using HmmerBuild.     ProfileSearch   Uses a profile (representing a group of aligned sequences) as a query to search the database for new sequences with similarity to the group.  The profile is created with the program  ProfileMake .     ProfileSegments   Makes optimal alignments showing the segments of  similarity found by  ProfileSearch .     FindPatterns   Identifies sequences that contain short patterns like GAATTC or YRYRYRYR.  You can define the patterns ambiguously and allow mismatches. You can provide the patterns in a file or simply type them in from the terminal.     Motifs   Looks for sequence motifs by searching through proteins for the patterns defined in the  PROSITE Dictionary of Protein Sites and Patterns .  Motifs can display an abstract of the current literature on each of the motifs it finds.     HmmerPfam*   Compares one or more sequences to a database of profile hidden Markov models, such as the Pfam library, in order to identify known domains within the sequences.     HmmerBuild*   Creates a position-specific scoring table, called a profile hidden  Markov  model (HMM), that is a statistical model of the consensus of a multiple sequence alignment. The profile HMM can be used for database searching (HmmerSearch), sequence alignment (HmmerAlign) or generating random sequences that match the model (HmmerEmit).     HmmerCalibrate*   ""Calibrates"" a profile hidden Markov model in order to increase the sensitivity of database searches performed using that profile HMM as a query. The program compares the original profile HMM with a large number of randomly generated sequences and computes the extreme value distribution (EVD) parameters for this simulated search. The original profile HMM is replaced with a new one that contains these EVD parameters.     WordSearch+   Identifies sequences in the database that share large  numbers of common words in the same register of comparison with your query sequence.  The output of  WordSearch can be displayed with  Segments .     Segments   Aligns and displays the segments of similarity found by  WordSearch .     Sequence Retrieval         Fetch   Copies GCG sequences or data files from the GCG database  into your directory or displays them on your terminal screen.     NetFetch   Retrieves entries from NCBI listed in a  NetBLAST  output file. It can also be used to retrieve entries individually by entry name or accession number.  The output of NetFetch is an RSF file.       Editing and Publication       SeqEd   Is an interactive editor for entering and modifying sequences and for assembling parts of existing sequences into new genetic constructs.  You can enter sequences from the keyboard or from a digitizer.     SeqLab   Is the graphical user interface for the Wisconsin Package. For additional information, refer to the SeqLab Guide.     Assemble   Constructs new sequences from pieces of existing sequences.  It concatenates the fragments you specify and writes them out as a new sequence file.   SeqEd  is a better tool for assembling sequences interactively, but Assemble is best for assembling sequences from fragments defined in a list file.     Pretty   Displays multiple sequence alignments and calculates a consensus sequence.  It does not create the alignment; it simply displays it.     PrettyBox+   Displays multiple sequence alignments as shaded boxes in Postscript format for printing or displaying with a Postscript-compatible device. PrettyBox optionally calculates a consensus sequence.  The program does not  create the alignment; it simply displays it.     Publish   Arranges sequences for publication.  It creates a text file that you can modify to your own needs with a text editor.     PlasmidMap+   Draws a circular plot of a plasmid construct.  It can display restriction patterns, inserts, and known genetic elements. The plot is suitable for publication, record keeping, or analysis.  It is drawn from one or more labeling files such as those written by  MapSort .     LineUp   Is a screen editor for editing multiple sequence alignments. You can edit up to 30 sequences simultaneously.  New sequences can be typed in by hand or added from existing sequence files.  A consensus sequence identifies places where the sequences are in conflict.     Figure+   Makes figures and posters by drawing graphics and text together. You can include output from other Wisconsin Package graphics programs as part of a figure.     Red   Is a text formatter that creates publication-quality documents on a PostScript printer such as the Apple LaserWriter. You can use 13 different fonts, scaling each font to any size. You can also include figures and graphics from any Wisconsin Package graphics program within the text of the document.       Evolution       PAUPSearch   Provides a GCG interface to the tree-searching options in PAUP (Phylogenetic Analysis Using Parsimony). Starting with a set of aligned sequences, you can search for phylogenetic trees that are optimal according to parsimony, distance, or maximum likelihood criteria; reconstruct a neighbor-joining tree; or perform a bootstrap analysis. The program  PAUPDisplay  can produce a graphical version of a PAUPSearch trees file. PAUP is the copyrighted property of the Smithsonian Institution. Use the program  Fetch  to obtain a copy of paup-license.txt to read about rights and limitations for using PAUP.     PAUPDisplay+   Provides a GCG interface to tree manipulation, diagnosis, and display options in PAUP (Phylogenetic Analysis Using Parsimony). Starting with a trees file that contains a sequence alignment and one or more trees reconstructed from this alignment (such as the output from  PAUPSearch ), you can plot the tree(s); compute the score of the tree(s) according to the criteria of parsimony, distance, or maximum likelihood; or calculate a consensus tree (two or more input trees). PAUPDisplay can also plot the trees from a  GrowTree  trees file. PAUP is the copyrighted property of the Smithsonian Institution. Use the program  Fetch  to obtain a copy of paup-license.txt to read about rights and limitations for using PAUP.     Distances   Creates a table of the pairwise distances within a group of aligned sequences.     GrowTree+   Creates a phylogenetic tree from a distance matrix created by  Distances  using either the UPGMA or neighbor-joining method. You can create a text or graphics output file.     Diverge   Estimates the pairwise number of synonymous and nonsynonymous substitutions per site between two or more aligned nucleic acid sequences that code for proteins. It uses a variant of the method published by Li et al.       Fragment Assembly       GelStart   Begins a fragment assembly session by creating a new fragment assembly project or by identifying an existing project.     GelEnter   Adds fragment sequences to a fragment assembly project. It accepts sequence data from your terminal keyboard, a digitizer, or existing sequence files.     GelMerge   Aligns the sequences in a fragment assembly project into assemblies called contigs.  You can view and edit these assemblies in  GelAssemble .     GelAssemble   Is a multiple sequence editor for viewing and editing contigs assembled by  GelMerge .     GelView   Displays the structure of the contigs in a fragment assembly project.     GelDisassemble   Breaks up the contigs in a fragment assembly project into single fragments.       Gene Finding and Pattern Recognition       TestCode+   Helps you identify protein coding sequences by plotting a measure of the non-randomness of the composition at every third base. The statistic does not require a codon frequency table.     CodonPreference+   Is a frame-specific gene finder that tries to recognize protein coding sequences by virtue of the similarity of their codon usage to a codon frequency table or by the bias of their composition (usually GC) in the third position of each codon.     Frames+   Shows open reading frames for the six translation frames of a DNA sequence. Frames can superimpose the pattern of rare codon choices if you provide it with a codon frequency table.     Terminator   Searches for prokaryotic factor-independent RNA polymerase terminators according to the method of Brendel and Trifonov.     Motifs   Looks for sequence motifs by searching through proteins for the patterns defined in the  PROSITE Dictionary of Protein Sites and Patterns .  Motifs can display an abstract of the current literature on each of the motifs it finds.     MEME   (Multiple EM for Motif Elicitation) Finds conserved motifs in a group unaligned sequences. MEME saves these motifs as a set of profiles. You can search a database of sequences with these profiles using the  MotifSearch  program.     Repeat   Finds direct repeats in sequences. You must set the size, stringency, and range within which the repeat must occur; all the repeats of that size or greater are displayed as short alignments.     FindPatterns   Identifies sequences that contain short patterns like GAATTC or YRYRYRYR.  You can define the patterns ambiguously and allow mismatches. You can provide the patterns in a file or simply type them in from the terminal.     Composition   Determines the composition of sequence(s).  For nucleotide sequence(s), Composition also determines dinucleotide and trinucleotide content.     CodonFrequency   Tabulates codon usage from sequences and/or existing codon usage tables. The output file is correctly formatted for input to the  CodonPreference ,  Correspond , and  Frames  programs.     Correspond   Looks for similar patterns of codon usage by comparing codon frequency tables.     Window   Makes a table of the frequencies of different sequence patterns within a window as it is moved along a sequence.  A pattern is any short sequence like GC or R or ATG.  You can plot the output with the program  StatPlot .     StatPlot+   Plots a set of parallel curves from a table of numbers like the table written by the  Window  program. The statistics in each column of the table are associated with a position in the analyzed sequence.     FitConsensus   Uses a consensus table written by  Consensus  as a probe to find the best examples of the consensus in a DNA sequence. You can specify the number of fits you want to see, and FitConsensus tabulates them with their position, frame, and a statistical measure of their quality.     Consensus   Calculates a consensus sequence for a set of pre-aligned short nucleic acid sequences by tabulating the percent of G, A, T, and C for each position in the set.  FitConsensus  uses the Consensus output table as a probe to search for the best examples of the derived consensus in other nucleotide sequences.     Xnu   Replaces statistically significant tandem repeats in protein sequences with X characters.  If a resulting protein sequence is used as a query for a  BLAST  search, the regions with X characters are ignored.     Seg   Replaces low complexity regions in protein sequences with X characters. If a resulting protein sequence is used as a query for a  BLAST  search, the regions with X characters are ignored.       Importing / Exporting       Reformat   Rewrites sequence file(s), scoring matrix file(s), or enzyme  data file(s) so that they can be read by GCG programs.     BreakUp   Reads a GCG-format sequence file containing more than 350,000 sequence characters and writes it as a set of separate, shorter, overlapping sequence files that can be analyzed by Wisconsin Package programs.     ChopUp   Converts a non-GCG sequence file containing lines as long as 32,000 characters into a new file containing lines no longer than 50 characters.  The new file can be read by  Reformat  to create a GCG-format sequence file.     FromStaden   Changes a sequence from Staden format into GCG format.  If the file contains a nucleotide sequence, the ambiguity codes are converted as shown in  Appendix III  of the Program Manual.     FromEMBL   Reformats sequences from the distribution (flat file) format  of the EMBL database into individual sequence files in GCG format.     FromGenBank   Reformats one or more sequences in the flat file format of the GenBank database into individual sequence files in GCG format.     FromPIR   Reformats sequences from the protein database of the Protein Identification Resource (PIR) into individual files in GCG format.     FromIG   Reformats one or more sequences from IntelliGenetics format into individual files in GCG format.     FromTrace   Converts one or more ABI or SCF files into individual sequence files in GCG format.     FromFasta   Reformats one or more sequences from  FastA  format into individual files in GCG format.     ToStaden   Writes a GCG sequence into a file in Staden format. If the file contains a nucleotide sequence, the ambiguity codes are converted as shown in  Appendix III  of the Program Manual.     ToPIR   Writes GCG sequence(s) into a single file in PIR format.     ToIG   Converts GCG sequence file(s) into a single file in IntelliGenetics format.     ToFastA   Converts GCG sequence(s) into  FastA  format.     HmmerConvert*   Converts profile hidden Markov model files into different profile formats.     GetSeq   Reads a sequence from a computer that is acting as a terminal  and writes it into a new sequence file in GCG format on the computer running the Wisconsin Package.     Spew   Sends a GCG sequence from the computer that runs the Wisconsin Package to a personal computer acting as a terminal.       Mapping       Map   Maps a DNA sequence and displays both strands of the mapped sequence with restriction enzyme cut points above the sequence and protein translations below.   Map can also create a peptide map of an amino acid sequence.     MapPlot+   Displays restriction sites graphically.  If you don't have a plotter,  MapPlot  can write a text file that approximates the graph.     MapSort   Finds the coordinates of the restriction enzyme cuts in a DNA sequence and sorts the fragments of the resulting digest by size. MapSort can sort the fragments from single or multiple enzyme digests.     FingerPrint   Identifies the products of T1 ribonuclease digestion.     PeptideMap   Creates a peptide map of an amino acid sequence.     PlasmidMap+   Draws a circular plot of a plasmid construct.  It can display restriction patterns, inserts, and known genetic elements. The plot is suitable for publication, record keeping, or analysis.  It is drawn from one or more labeling files such as those written by  MapSort .     PeptideSort   Shows the peptide fragments from a digest of an amino acid sequence.  It sorts the peptides by weight, position, and HPLC retention at pH 2.1, and shows the composition of each peptide.  It also prints a summary of the composition of the whole protein.       Primer Selection       Prime+   Selects oligonucleotide primers for a template DNA sequence.  The primers may be useful for the polymerase chain reaction (PCR) or for DNA sequencing.  You can allow Prime to choose primers from the whole template or limit the choices to a particular set of primers listed in a file.     PrimePair*   Evaluates individual primers to determine their compatibility for use as PCR primer pairs. You can provide the primers in files (one for forward, one for reverse primers) or on the command line, or you can enter them interactively from the keyboard.     MeltTemp*   Computes the melting temperature of oligonucleotides.  You can provide the oligonucleotide sequences in a file or simply type them in at the keyboard.       Protein Analysis       Motifs   Looks for sequence motifs by searching through proteins for the patterns defined in the  PROSITE Dictionary of Protein Sites and Patterns .  Motifs can display an abstract of the current literature on each of the motifs it finds.     HmmerPfam*   Compares one or more sequences to a database of profile hidden Markov models, such as the Pfam library, in order to identify known domains within the sequences.     ProfileScan   Uses a database of profiles to find structural and sequence motifs in protein sequences.     CoilScan   Locates coiled-coil segments in protein sequences.     HTHScan   Scans protein sequences for the presence of helix-turn-helix motifs, indicative of sequence-specific DNA-binding structures often associated with gene regulation.     SPScan   Scans protein sequences for the presence of secretory signal peptides (SPs).     PeptideSort   Shows the peptide fragments from a digest of an amino acid sequence.  It sorts the peptides by weight, position, and HPLC retention at pH 2.1, and shows the composition of each peptide.  It also prints a summary of the composition of the whole protein.     Isoelectric+   Plots the charge as a function of pH for any peptide sequence.     PeptideMap   Creates a peptide map of an amino acid sequence.     PepPlot+   Plots measures of protein secondary structure and hydrophobicity in parallel panels of the same plot.     PeptideStructure   Makes secondary structure predictions for a peptide sequence. The predictions include (in addition to alpha, beta, coil, and turn) measures for antigenicity, flexibility, hydrophobicity, and surface probability.   PlotStructure  displays the predictions graphically.     PlotStructure+   Plots the measures of protein secondary structure in the output file from  PeptideStructure .  The measures can be shown on parallel panels of a graph or with a two-dimensional ""squiggly"" representation.     Moment+   Makes a contour plot of the helical hydrophobic moment of a peptide sequence.     HelicalWheel+   Plots a peptide sequence as a helical wheel to help you  recognize amphiphilic regions.     Xnu   Replaces statistically significant tandem repeats in protein sequences with X characters.  If a resulting protein sequence is used as a query for a  BLAST  search, the regions with X characters are ignored.     Seg   Replaces low complexity regions in protein sequences with X characters. If a resulting protein sequence is used as a query for a  BLAST  search, the regions with X characters are ignored.       DNA/ RNA Secondary Structure       MFold   Predicts optimal and suboptimal secondary structures for an RNA or DNA molecule using the most recent energy minimization method of Zuker.     PlotFold+   Displays the optimal and suboptimal secondary structures for an RNA or DNA molecule predicted by  MFold .     StemLoop   Finds stems (inverted repeats) within a sequence. You specify the minimum stem length, minimum and maximum loop sizes, and the minimum number of bonds per stem.  All loops or only the best loops can be displayed on your screen or written into a file.     DotPlot+   Makes a dot-plot with the output file from  Compare  or  StemLoop .       Translation       Translate   Translates nucleotide sequences into peptide sequences.     BackTranslate   Backtranslates an amino acid sequence into a nucleotide sequence. The output helps you recognize minimally ambiguous regions that might be good for constructing synthetic probes.     Map   Maps a DNA sequence and displays both strands of the mapped sequence with restriction enzyme cut points above the sequence and protein translations below.   Map can also create a peptide map of an amino acid sequence.     ExtractPeptide   Writes a peptide sequence from one or more of the translation frames displayed in the output from  Map .  Translate  supercedes ExtractPeptide for most applications.     Pepdata   Translates DNA sequence(s) in all six frames.     Reverse   Reverses and/or complements a sequence.     Dataset   Creates a GCG data library from any set of sequences in GCG format.  To translate nucleotide sequences into peptide sequences, include the ToProt parameter.       Utilities       Sequence Utilities     Reverse   Reverses and/or complements a sequence.     Shuffle   Randomizes the order of the symbols in a sequence without changing  the composition.     Simplify   Lets you reduce the number of symbols in a sequence.  Such a  simplification would allow you, for instance, to treat all hydrophobic amino acids as equivalent.     Comptable   Creates a scoring matrix using equivalences defined in a simplification scheme such as the one used for  Simplify .     HmmerEmit*   Generates sequences that match a profile hidden Markov model.     Corrupt   Randomly introduces small numbers of substitutions, insertions, and deletions into nucleotide sequence(s).     Xnu   Replaces statistically significant tandem repeats in protein sequences with X characters.  If a resulting protein sequence is used as a query for a  BLAST  search, the regions with X characters are ignored.     Seg   Replaces low complexity regions in protein sequences with X characters. If a resulting protein sequence is used as a query for a  BLAST  search, the regions with X characters are ignored.     Sample   Extracts sequence fragments randomly from sequence(s). You can set a sampling rate to determine how many fragments Sample extracts.     Database Utilities     DataSet   Creates a GCG data library from any set of sequences in GCG format.     GCGtoBLAST   Combines any set of GCG sequences into a database that you can search with  BLAST .     Sample   Extracts sequence fragments randomly from sequence(s). You can set a sampling rate to determine how many fragments Sample extracts.     Printing / Plotting Utilities     LPrint   Prints text file(s) on a PostScript printer connected to LPrintPort.     ListFile   Prints a file on a printer attached to your terminal's pass-through printer port.     SetPlot   Allows you to choose a plotting configuration from a menu of available graphics devices at your site.     Figure+   Makes figures and posters by drawing graphics and text together. You can include output from other Wisconsin Package graphics programs as part of a figure.     PlotTest+   Plots a test pattern to test of your graphics configuration. The pattern created by PlotTest uses every Wisconsin Package graphics feature.   It should resemble the example test pattern in the documentation for  PlotTest  in the Program Manual.     File Utilities     Chopup   Converts a non-GCG sequence file containing lines as long as 32,000 characters into a new file containing lines no longer than 50 characters.  The new file can be read by  Reformat  to create a GCG-format sequence file.     Replace   Makes character string replacements in text file(s).  You provide a table of replacements in a file showing each existing string and its replacement.     CompressText   Removes any or all of the following from files: A) trailing space; B) blank lines; C) extra space between words;  D) all space; or E) leading space.     OneCase   Puts all of the alphabetic characters in a file into lower or UPPER case.  It can also capitalize every word.     ShiftOver   Moves a file to the right or to the left as many columns as you specify.     Detab   Replaces the tab characters in one or more files with spaces. The files can be written out in card-image format with records of fixed length.     Miscellaneous Utilities     SetKeys   Writes a file in your current directory that redefines your keyboard's keys for easier sequence entry with the  SeqEd ,  LineUp ,  GelEnter  and  GelAssemble  programs and the  SeqLab  sequence editor.  The output file, called set.keys, can be edited if you want to redefine keys that were not considered by the SetKeys program.     Reformat   Rewrites sequence file(s), scoring matrix file(s), or enzyme data file(s) so that they can be read by GCG programs.     HmmerBuild*   Creates a position-specific scoring table, called a profile hidden Markov  model (HMM), that is a statistical model of the consensus of a multiple sequence alignment. The profile HMM can be used for database searching (HmmerSearch), sequence alignment (HmmerAlign) or generating random sequences that match the model (HmmerEmit).     HmmerCalibrate*   ""Calibrates"" a profile hidden Markov model in order to increase the sensitivity of database searches performed using that profile HMM as a query. The program compares the original profile HMM with a large number of randomly generated sequences and computes the extreme value distribution (EVD) parameters for this simulated search. The original profile HMM is replaced with a new one that contains these EVD parameters.     HmmerConvert*   Converts profile hidden Markov model files into different profile formats.     HmmerIndex*   Creates an index for a profile hidden Markov model database so that profile HMMs can be retrieved from the database with HmmerFetch.     HmmerFetch*   Retrieves a profile hidden Markov model (HMM) from a database of profile HMMs that has been indexed by HmmerIndex.     Red   Is a text formatter that creates publication-quality documents on a PostScript printer such as the Apple LaserWriter. You can use 13 different fonts, scaling each font to any size. You can also include figures and graphics from any Wisconsin Package graphics program within the text of the document.     Name   Creates, changes, deletes, or displays GCG logical name(s) from the GCG logical names table.     Symbol   Creates, changes, deletes, or displays GCG symbol(s) from the GCG symbol table.             [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]       Documentation Comments:  doc-comments@gcg.com  Technical Support:  help@gcg.com      Copyright (c) 1982-2000  Genetics Computer Group  Inc., a wholly A subsidiary of Pharmacopeia, Inc.  All rights reserved.    Licenses and Trademarks Wisconsin Package is a trademark of Genetics Computer Group, Inc.  GCG and the GCG logo are registered trademarks of Genetics Computer Group, Inc.    All other product names mentioned in this documentation may be trademarks, and if so, are trademarks or registered trademarks of their respective holders and are used in this documentation for identification purposes only.       www.gcg.com"
GX236-36-16495007	D01  Quadrature  D01GZF  NAG Fortran Library Routine Document Note. Before using this routine, please read the Users' Note for your implementation to check the interpretation of bold italicised terms and other implementation-dependent details.  1  Purp ose  D01GZF calculates the optimal co efficients, for use by D01GCF and D01GDF, when the number of points is the product of two primes.  2  Sp ecification SUBROUTINE D01GZF(NDIM, NP1, NP2, VK, IFAIL) INTEGER NDIM, NP1, NP2, IFAIL real VK(NDIM)  3  Description  Korobov [1] gives a procedure for calculating optimal co efficients for p -point integration over the n-cube [0, 1]n , when the number of points is p = p1 p2 (1) where p1 and p2 are distinct prime numbers. The advantage of this pro cedure is that if p1 is chosen to be the nearest prime integer to p2 , then the 2 number of elementary operations required to compute the rule is of the order of p4/3 which grows less rapidly than the number of operations required by D01GYF. The asso ciated error is likely to be larger although it may be the only practical alternative for high values of p.  4  References  [1] Korobov N M (1963) Number Theoretic Methods in Approximate Analysis Fizmatgiz, Moscow  5 1:  Parameters NDIM -- INTEGER On entry: the number of dimensions of the integral, n. Constraint: NDIM  1. Input  2:  NP1 -- INTEGER On entry: the larger prime factor p1 of the number of points in the integration rule. Constraint: NP1 must be a prime number  5.  Input  3:  NP2 -- INTEGER  Input  On entry: the smaller prime factor p2 of the number of points in the integration rule. For maximum efficiency, p2 should be close to p1 . 2 Constraint: NP2 must be a prime number such that NP1 > NP2  2. 4:  VK(NDIM) -- real array On exit: fl17d01paf.sgml the n optimal co efficients.  Output  5:  IFAIL -- INTEGER  Input/Output  On entry: IFAIL must be set to 0, -1 or 1. For users not familiar with this parameter (described in Chapter P01) the recommended value is 0. On exit: IFAIL = 0 unless the routine detects an error (see Section 6).  [NP3390/19/pdf ]  D01GZF.1   D01GZF  D01  Quadrature  6  Error Indicators and Warnings  Errors detected by the routine: IFAIL = 1 On entry, NDIM < 1. IFAIL = 2 On entry, NP1 < 5, or NP2 < 2, or NP1  NP2. IFAIL = 3 The value NP1  NP2 exceeds the largest integer representable on the machine, and hence the optimal coefficients could not be used in a valid call of D01GCF. IFAIL = 4 On entry, NP1 is not a prime number. IFAIL = 5 On entry, NP2 is not a prime number. IFAIL = 6 The precision of the machine is insufficient to perform the computation exactly. Try smaller values of NP1 or NP2, or use an implementation with higher precision.  7  Accuracy  The optimal co efficients are returned as exact integers (though stored in a real array).  8  Further Comments  The time taken by the routine grows at least as fast as (p1 p2 )4/3 . (See Section 3.)  9  Example  This example program calculates the Korobov optimal co efficients where the number of dimensons is 4 and the number of points is the pro duct of the two prime numbers, 89 and 11.  9.1  Program Text  Note. The listing of the example program presented below uses bold italicised terms to denote precision-dependent details. Please read the Users' Note for your implementation to check the interpretation of these terms. As explained in the Essential Introduction to this manual, the results produced may not be identical for all implementations.  * * *  * *  D01GZF Example Program Text Mark 14 Revised. NAG Copyright 1989. .. Parameters .. INTEGER NDIM PARAMETER (NDIM=4) INTEGER NOUT PARAMETER (NOUT=6) .. Local Scalars .. INTEGER I, IFAIL, NP1, NP2 .. Local Arrays .. real VK(NDIM) [NP3390/19/pdf ]  D01GZF.2   D01  Quadrature  D01GZF  * *  .. External Subroutines .. EXTERNAL D01GZF .. Executable Statements .. WRITE (NOUT,*) 'D01GZF Example Program Results' NP1 = 89 NP2 = 11 WRITE (NOUT,*) WRITE (NOUT,99999) 'NDIM =', NDIM, ' NP1 =', NP1, ' NP2 =', NP2 IFAIL = 0 CALL D01GZF(NDIM,NP1,NP2,VK,IFAIL)  * * WRITE (NOUT,*) WRITE (NOUT,99998) 'Coefficients =', (VK(I),I=1,NDIM) STOP * 99999 FORMAT (1X,A,I3,A,I6,A,I6) 99998 FORMAT (1X,A,4F6.0) END  9.2 None.  Program Data  9.3  Program Results D01GZF Example Program Results NDIM = 4 NP1 = 89 NP2 = 1. 102. 11 614. 951.  Coefficients =  [NP3390/19/pdf ]  D01GZF.3 (last)
GX234-64-13859220	"A STATISTICAL TEST SUITE FOR RANDOM AND PSEUDORANDOM NUMBER GENERATORS FOR CRYPTOGRAPHIC APPLICATIONS NIST Special Publication 800-22 (with revisions dated May 15, 2001)  Andrew Rukhin, Juan Soto, James Nechvatal, Miles Smid, Elaine Barker, Stefan Leigh, Mark Levenson, Mark Vangel, David Banks, Alan Heckert, James Dray, San Vo   ABSTRACT This paper discusses some aspects of selecting and testing random and pseudorandom number generators. The outputs of such generators may be used in many cryptographic applications, such as the generation of key material. Generators suitable for use in cryptographic applications may need to meet stronger requirements than for other applications. In particular, their outputs must be unpredictable in the absence of knowledge of the inputs. Some criteria for characterizing and selecting appropriate generators are discussed in this document. The subject of statistical testing and its relation to cryptanalysis is also discussed, and some recommended statistical tests are provided. These tests may be useful as a first step in determining whether or not a generator is suitable for a particular cryptographic application. However, no set of statistical tests can absolutely certify a generator as appropriate for usage in a particular application, i.e., statistical testing cannot serve as a substitute for cryptanalysis. The design and cryptanalysis of generators is outside the scope of this paper. Key words: random number generator, hypothesis test, P-value  Certain commercial equipment and materials were used in the development of this test suite. Such identification does not imply recommendation or endorsement by the National Institute of Standards and Technology, nor does it imply that the materials or equipment identified are necessarily the best available for the purpose.  iv   TABLE OF CONTENTS 1 1.1  INTRODUCTION TO RANDOM NUMBER TESTING ............................... 1 General Discussion ......................................................................................................................... 1.1.1 Randomness ............................................................................................................................ 1.1.2 Unpredictability ...................................................................................................................... 1.1.3 Random Number Generators (RNGs) ..................................................................................... 1.1.4 Pseudorandom Number Generators (PRNGs) ........................................................................ 1.1.5 Testing .................................................................................................................................... 1.1.6 Considerations for Randomness, Unpredictability and Testing .............................................. 1 1 2 2 3 3 6  1.2 1.3  Definitions and Abbreviations ....................................................................................................... 6 Mathematical Symbols ................................................................................................................. 11  2 2.1  RANDOM NUMBER GENERATION TESTS .......................................... 13 Frequency (Monobit) Test ........................................................................................................... 2.1.1 Test Purpose.......................................................................................................................... 2.1.2 Function Call ........................................................................................................................ 2.1.3 Test Statistic and Reference Distribution.............................................................................. 2.1.4 Test Description .................................................................................................................... 2.1.5 Decision Rule (at the 1 % Level) .......................................................................................... 2.1.6 Conclusion and Interpretation of Test Results ...................................................................... 2.1.7 Input Size Recommendations ............................................................................................... 2.1.8 Example ................................................................................................................................ Frequency Test within a Block ................................................................................................... 2.2.1 Test Purpose.......................................................................................................................... 2.2.2 Function Call ........................................................................................................................ 2.2.3 Test Statistic.......................................................................................................................... 2.2.4 Test Description .................................................................................................................... 2.2.5 Decision Rule (at the 1 % Level) .......................................................................................... 2.2.6 Conclusion and Interpretation of Test Results ...................................................................... 2.2.7 Input Size Recommendations ............................................................................................... 2.2.8 Example ................................................................................................................................ Runs 2.3.1 2.3.2 2.3.3 2.3.4 2.3.5 2.3.6 2.3.7 2.3.8 Test 2.4.1 2.4.2 2.4.3 Test....................................................................................................................................... Test Purpose.......................................................................................................................... Function Call ........................................................................................................................ Test Statistic and Reference Distribution.............................................................................. Test Description .................................................................................................................... Decision Rule (at the 1 % Level) .......................................................................................... Conclusion and Interpretation of Test Results ...................................................................... Input Size Recommendations ............................................................................................... Example ................................................................................................................................ 14 14 14 15 15 15 15 16 16 16 16 16 17 17 18 18 18 18 18 18 19 19 19 20 20 20 21 21 21 21 22  2.2  2.3  2.4  for the Longest Run of Ones in a Block.............................................................................. Test Purpose.......................................................................................................................... Function Call ........................................................................................................................ Test Statistic and Reference Distribution..............................................................................  v   2.4.4 2.4.5 2.4.6 2.4.7 2.4.8 2.5  Test Description .................................................................................................................... Decision Rule (at the 1 % Level) .......................................................................................... Conclusion and Interpretation of Test Results ...................................................................... Input Size Recommendations ............................................................................................... Example ................................................................................................................................  22 23 23 23 23 24 24 24 25 25 26 26 26 26 27 27 27 27 27 28 28 29 29 29 29 29 30 30 31 31 32 32 32 32 33 33 33 35 35 35 36 36 36 36 36 37 39 40 40 40  Binary Matrix Rank Test............................................................................................................. 2.5.1 Test Purpose.......................................................................................................................... 2.5.2 Function Call ........................................................................................................................ 2.5.3 Test Statistic and Reference Distribution.............................................................................. 2.5.4 Test Description .................................................................................................................... 2.5.5 Decision Rule (at the 1 % Level) .......................................................................................... 2.5.6 Conclusion and Interpretation of Test Results ...................................................................... 2.5.7 Input Size Recommendations ............................................................................................... 2.5.8 Example ................................................................................................................................ Discrete Fourier Transform (Spectral) Test .............................................................................. 2.6.1 Test Purpose.......................................................................................................................... 2.6.2 Function Call ........................................................................................................................ 2.6.3 Test Statistic and Reference Distribution.............................................................................. 2.6.4 Test Description .................................................................................................................... 2.6.5 Decision Rule (at the 1 % Level) .......................................................................................... 2.6.6 Conclusion and Interpretation of Test Results ...................................................................... 2.6.7 Input Size Recommendations ............................................................................................... 2.6.8 Example ................................................................................................................................ Non-overlapping Template Matching Test ................................................................................ 2.7.1 Test Purpose.......................................................................................................................... 2.7.2 Function Call ........................................................................................................................ 2.7.3 Test Statistic and Reference Distribution.............................................................................. 2.7.4 Test Description .................................................................................................................... 2.7.5 Decision Rule (at the 1 % Level) .......................................................................................... 2.7.6 Conclusion and Interpretation of Test Results ...................................................................... 2.7.7 Input Size Recommendations ............................................................................................... 2.7.8 Example ................................................................................................................................ Overlapping Template Matching Test........................................................................................ 2.8.1 Test Purpose.......................................................................................................................... 2.8.2 Function Call ........................................................................................................................ 2.8.3 Test Statistic and Reference Distribution.............................................................................. 2.8.4 Test Description .................................................................................................................... 2.8.5 Decision Rule (at the 1 % Level) .......................................................................................... 2.8.6 Conclusion and Interpretation of Test Results ...................................................................... 2.8.7 Input Size Recommendations ............................................................................................... 2.8.8 Example ................................................................................................................................ Maurer's ""Universal Statistical"" Test ........................................................................................ 2.9.1 Test Purpose.......................................................................................................................... 2.9.2 Function Call ........................................................................................................................ 2.9.3 Test Statistic and Reference Distribution.............................................................................. 2.9.4 Test Description .................................................................................................................... 2.9.5 Decision Rule (at the 1 % Level) .......................................................................................... 2.9.6 Conclusion and Interpretation of Test Results ...................................................................... 2.9.7 Input Size Recommendations ............................................................................................... 2.9.8 Example ................................................................................................................................  2.6  2.7  2.8  2.9  vi   2.10  Lempel-Ziv Compression Test .................................................................................................... 2.10.1 Test Purpose ..................................................................................................................... 2.10.2 Function Call .................................................................................................................... 2.10.3 Test Statistic and Reference Distribution ......................................................................... 2.10.4 Test Description ............................................................................................................... 2.10.5 Decision Rule (at the 1 % Level) ..................................................................................... 2.10.6 Conclusion and Interpretation of Test Results ................................................................. 2.10.7 Input Size Recommendations ........................................................................................... 2.10.8 Example ........................................................................................................................... Linear 2.11.1 2.11.2 2.11.3 2.11.4 2.11.5 2.11.6 2.11.7 2.11.8 Complexity Test ............................................................................................................... Test Purpose ..................................................................................................................... Function Call .................................................................................................................... Test Statistic and Reference Distribution ......................................................................... Test Description ............................................................................................................... Decision Rule (at the 1 % Level) ..................................................................................... Conclusion and Interpretation of Test Results ................................................................. Input Size recommendations ............................................................................................ Example ...........................................................................................................................  41 41 41 41 41 42 42 43 43 43 43 43 44 44 45 45 46 46 46 46 46 47 47 48 48 48 48 49 49 49 49 50 51 51 51 51 52 52 52 52 52 54 54 54 54 54 54 55 55 55 58  2.11  2.12  Serial Test...................................................................................................................................... 2.12.1 Test Purpose ..................................................................................................................... 2.12.2 Function Call .................................................................................................................... 2.12.3 Test Statistics and Reference Distribution ....................................................................... 2.12.4 Test Description ............................................................................................................... 2.12.5 Decision Rule (at the 1 % Level) ..................................................................................... 2.12.6 Conclusion and Interpretation of Test Results ................................................................. 2.12.7 Input Size Recommendations ........................................................................................... 2.12.8 Example ........................................................................................................................... Approximate Entropy Test .......................................................................................................... 2.13.1 Test Purpose ..................................................................................................................... 2.13.2 Function Call .................................................................................................................... 2.13.3 Test Statistic and Reference Distribution ......................................................................... 2.13.4 Test Description ............................................................................................................... 2.13.5 Decision Rule (at the 1 % Level) ..................................................................................... 2.13.6 Conclusion and Interpretation of Test Results ................................................................. 2.13.7 Input Size Recommendations ........................................................................................... 2.13.8 Example ........................................................................................................................... Cumulative Sums (Cusum) Test.................................................................................................. 2.14.1 Test Purpose ..................................................................................................................... 2.14.2 Function Call .................................................................................................................... 2.14.3 Test Statistic and Reference Distribution ......................................................................... 2.14.4 Test Description ............................................................................................................... 2.14.5 Decision Rule (at the 1 % Level) ..................................................................................... 2.14.6 Conclusion and Interpretation of Test Results ................................................................. 2.14.7 Input Size Recommendations ........................................................................................... 2.14.8 Example ........................................................................................................................... Random Excursions Test ............................................................................................................. 2.15.1 Test Purpose ..................................................................................................................... 2.15.2 Function Call .................................................................................................................... 2.15.3 Test Statistic and Reference Distribution ......................................................................... 2.15.4 Test Description ............................................................................................................... 2.15.5 Decision Rule (at the 1 % Level) .....................................................................................  2.13  2.14  2.15  vii   2.15.6 2.15.7 2.15.8 2.16  Conclusion and Interpretation of Test Results ................................................................. 59 Input Size Recommendations ........................................................................................... 59 Example ........................................................................................................................... 59 59 59 60 60 60 62 62 62 62  Random Excursions Variant Test ............................................................................................... 2.16.1 Test Purpose ..................................................................................................................... 2.16.2 Function Call .................................................................................................................... 2.16.3 Test Statistic and Reference Distribution ......................................................................... 2.16.4 Test Description ............................................................................................................... 2.16.5 Decision Rule (at the 1 % Level) ..................................................................................... 2.16.6 Conclusion and Interpretation of Test Results ................................................................. 2.16.7 Input Size Recommendations ........................................................................................... 2.16.8 Example ...........................................................................................................................  3 3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9 3.10 3.11 3.12 3.13 3.14 3.15 3.16  TECHNICAL DESCRIPTION OF TESTS ................................................ 64 Frequency (Monobit) Test.................................................................................64 Frequency Test within a Block............................................................................65 Runs Test......................................................................................................66 Test for the Longest Run of Ones in a Block ............................................................67 Binary Matrix Rank Test...................................................................................69 Discrete Fourier Transform (Spectral) Test............................................................71 Non-overlapping Template Matching Test..............................................................74 Overlapping Template Matching Test...................................................................77 Maurer's ""Universal Statistical"" Test....................................................................78 Lempel-Ziv Compression Test.............................................................................81 Linear Complexity Test.....................................................................................84 Serial Test.......................................................................................................87 Approximate Entropy Test..................................................................................89 Cumulative Sums (Cusum) Test...........................................................................91 Random Excursions Test....................................................................................93 Random Excursions Variant Test.........................................................................96  4. 4.1 4.2  TESTING STRATEGY AND RESULT INTERPRETATION .................... 98 Strategies for the Statistical Analysis of an RNG ...................................................................... 98 The Interpretation of Empirical Results .................................................................................. 100  viii   4.2.1 Proportion of Sequences Passing a Test ............................................................................. 100 4.2.2 Uniform Distribution of P-values ....................................................................................... 101 4.3 4.4 General Recommendations and Guidelines ............................................................................. 101 Application of Multiple Tests .................................................................................................... 104  5. 5.1 5.2 5.3 5.4  USER'S GUIDE ..................................................................................... 106 About the Package ...................................................................................................................... 106 System Requirements ................................................................................................................. 107 How to Get Started ..................................................................................................................... 107 Data 5.4.1 5.4.2 5.4.3 Input and Output of Empirical Results ........................................................................... Data Input ........................................................................................................................... Output of Empirical Results................................................................................................ Test Data Files .................................................................................................................... 109 109 109 109 109 110 110 111  5.5  Program Layout ......................................................................................................................... 5.5.1 General Program ................................................................................................................. 5.5.2 Implementation Details ....................................................................................................... 5.5.3 Description of the Test Code ..............................................................................................  5.6 5.7  Running the Test Code............................................................................................................... 113 Interpretation of Results ............................................................................................................ 115  APPENDIX A: RANK COMPUTATION FOR BINARY MATRICES ................ 117 APPENDIX B: SOURCE CODE ...................................................................... 121 APPENDIX C: EMPIRICAL RESULTS FOR SAMPLE DATA......................... 124 APPENDIX D: CONSTRUCTION OF APERIODIC TEMPLATES .................. 127 APPENDIX E: GENERATION OF THE BINARY EXPANSION OF IRRATIONAL NUMBERS ............................................................................................ 129 APPENDIX F: NUMERIC ALGORITHM ISSUES ........................................... 130 APPENDIX G: HIERARCHICAL DIRECTORY STRUCTURE ........................ 132 APPENDIX H: VISUALIZATION APPROACHES........................................... 136  ix   APPENDIX I: INSTRUCTIONS FOR INCORPORATING ADDITIONAL STATISTICAL TESTS ........................................................................... 139 APPENDIX J: INSTRUCTIONS FOR INCORPORATING ADDITIONAL PRNGS .............................................................................................................. 141 APPENDIX K: GRAPHICAL USER INTERFACE (GUI) ................................. 143 APPENDIX L: DESCRIPTION OF THE REFERENCE PSEUDO RANDOM NUMBER GENERATORS..................................................................... 146 APPENDIX M: REFERENCES ....................................................................... 151  x   xi   1  INTRODUCTION TO RANDOM NUMBER TESTING  The need for random and pseudorandom numbers arises in many cryptographic applications. For example, common cryptosystems employ keys that must be generated in a random fashion. Many cryptographic protocols also require random or pseudorandom inputs at various points, e.g., for auxiliary quantities used in generating digital signatures, or for generating challenges in authentication protocols. This document discusses the randomness testing of random number and pseudorandom number generators that may be used for many purposes including cryptographic, modeling and simulation applications. The focus of this document is on those applications where randomness is required for cryptographic purposes. A set of statistical tests for randomness is described in this document. The National Institute of Standards and Technology (NIST) believes that these procedures are useful in detecting deviations of a binary sequence from randomness. However, a tester should note that apparent deviations from randomness may be due to either a poorly designed generator or to anomalies that appear in the binary sequence that is tested (i.e., a certain number of failures is expected in random sequences produced by a particular generator). It is up to the tester to determine the correct interpretation of the test results. Refer to Section 4 for a discussion of testing strategy and the interpretation of test results.  1.1  General Discussion  There are two basic types of generators used to produce random sequences: random number generators (RNGs - see Section 1.1.3) and pseudorandom number generators (PRNGs - see Section 1.1.4). For cryptographic applications, both of these generator types produce a stream of zeros and ones that may be divided into substreams or blocks of random numbers.  1.1.1  Randomness  A random bit sequence could be interpreted as the result of the flips of an unbiased ""fair"" coin with sides that are labeled ""0"" and ""1,"" with each flip having a probability of exactly  of producing a ""0"" or ""1."" Furthermore, the flips are independent of each other: the result of any previous coin flip does not affect future coin flips. The unbiased ""fair"" coin is thus the perfect random bit stream generator, since the ""0"" and ""1"" values will be randomly distributed (and [0,1] uniformly distributed). All elements of the sequence are generated independently of each other, and the value of the next element in the sequence cannot be predicted, regardless of how many elements have already been produced. Obviously, the use of unbiased coins for cryptographic purposes is impractical. Nonetheless, the hypothetical output of such an idealized generator of a true random sequence serves as a benchmark for the evaluation of random and pseudorandom number generators.  1   1.1.2  Unpredictability  Random and pseudorandom numbers generated for cryptographic applications should be unpredictable. In the case of PRNGs, if the seed is unknown, the next output number in the sequence should be unpredictable in spite of any knowledge of previous random numbers in the sequence. This property is known as forward unpredictability. It should also not be feasible to determine the seed from knowledge of any generated values (i.e., backward unpredictability is also required). No correlation between a seed and any value generated from that seed should be evident; each element of the sequence should appear to be the outcome of an independent random event whose probability is 1/2. To ensure forward unpredictability, care must be exercised in obtaining seeds. The values produced by a PRNG are completely predictable if the seed and generation algorithm are known. Since in many cases the generation algorithm is publicly available, the seed must be kept secret and should not be derivable from the pseudorandom sequence that it produces. In addition, the seed itself must be unpredictable.  1.1.3  Random Number Generators (RNGs)  The first type of sequence generator is a random number generator (RNG). An RNG uses a nondeterministic source (i.e., the entropy source), along with some processing function (i.e., the entropy distillation process) to produce randomness. The use of a distillation process is needed to overcome any weakness in the entropy source that results in the production of non-random numbers (e.g., the occurrence of long strings of zeros or ones). The entropy source typically consists of some physical quantity, such as the noise in an electrical circuit, the timing of user processes (e.g., key strokes or mouse movements), or the quantum effects in a semiconductor. Various combinations of these inputs may be used. The outputs of an RNG may be used directly as a random number or may be fed into a pseudorandom number generator (PRNG). To be used directly (i.e., without further processing), the output of any RNG needs to satisfy strict randomness criteria as measured by statistical tests in order to determine that the physical sources of the RNG inputs appear random. For example, a physical source such as electronic noise may contain a superposition of regular structures, such as waves or other periodic phenomena, which may appear to be random, yet are determined to be non-random using statistical tests. For cryptographic purposes, the output of RNGs needs to be unpredictable. However, some physical sources (e.g., date/time vectors) are quite predictable. These problems may be mitigated by combining outputs from different types of sources to use as the inputs for an RNG. However, the resulting outputs from the RNG may still be deficient when evaluated by statistical tests. In addition, the production of high-quality random numbers may be too time consuming, making such production undesirable when a large quantity of random numbers is needed. To produce large quantities of random numbers, pseudorandom number generators may be preferable.  2   1.1.4  Pseudorandom Number Generators (PRNGs)  The second generator type is a pseudorandom number generator (PRNG). A PRNG uses one or more inputs and generates multiple ""pseudorandom"" numbers. Inputs to PRNGs are called seeds. In contexts in which unpredictability is needed, the seed itself must be random and unpredictable. Hence, by default, a PRNG should obtain its seeds from the outputs of an RNG; i.e., a PRNG requires a RNG as a companion. The outputs of a PRNG are typically deterministic functions of the seed; i.e., all true randomness is confined to seed generation. The deterministic nature of the process leads to the term ""pseudorandom."" Since each element of a pseudorandom sequence is reproducible from its seed, only the seed needs to be saved if reproduction or validation of the pseudorandom sequence is required. Ironically, pseudorandom numbers often appear to be more random than random numbers obtained from physical sources. If a pseudorandom sequence is properly constructed, each value in the sequence is produced from the previous value via transformations which appear to introduce additional randomness. A series of such transformations can eliminate statistical autocorrelations between input and output. Thus, the outputs of a PRNG may have better statistical properties and be produced faster than an RNG.  1.1.5  Testing  Various statistical tests can be applied to a sequence to attempt to compare and evaluate the sequence to a truly random sequence. Randomness is a probabilistic property; that is, the properties of a random sequence can be characterized and described in terms of probability. The likely outcome of statistical tests, when applied to a truly random sequence, is known a priori and can be described in probabilistic terms. There are an infinite number of possible statistical tests, each assessing the presence or absence of a ""pattern"" which, if detected, would indicate that the sequence is nonrandom. Because there are so many tests for judging whether a sequence is random or not, no specific finite set of tests is deemed ""complete."" In addition, the results of statistical testing must be interpreted with some care and caution to avoid incorrect conclusions about a specific generator (see Section 4). A statistical test is formulated to test a specific null hypothesis (H0). For the purpose of this document, the null hypothesis under test is that the sequence being tested is random. Associated with this null hypothesis is the alternative hypothesis (Ha) which, for this document, is that the sequence is not random. For each applied test, a decision or conclusion is derived that accepts or rejects the null hypothesis, i.e., whether the generator is (or is not) producing random values, based on the sequence that was produced. For each test, a relevant randomness statistic must be chosen and used to determine the acceptance or rejection of the null hypothesis. Under an assumption of randomness, such a statistic has a distribution of possible values. A theoretical reference distribution of this statistic  3   under the null hypothesis is determined by mathematical methods. From this reference distribution, a critical value is determined (typically, this value is ""far out"" in the tails of the distribution, say out at the 99 % point). During a test, a test statistic value is computed on the data (the sequence being tested). This test statistic value is compared to the critical value. If the test statistic value exceeds the critical value, the null hypothesis for randomness is rejected. Otherwise, the null hypothesis (the randomness hypothesis) is not rejected (i.e., the hypothesis is accepted). In practice, the reason that statistical hypothesis testing works is that the reference distribution and the critical value are dependent on and generated under a tentative assumption of randomness. If the randomness assumption is, in fact, true for the data at hand, then the resulting calculated test statistic value on the data will have a very low probability (e.g., 0.01 %) of exceeding the critical value. On the other hand, if the calculated test statistic value does exceed the critical value (i.e., if the low probability event does in fact occur), then from a statistical hypothesis testing point of view, the low probability event should not occur naturally. Therefore, when the calculated test statistic value exceeds the critical value, the conclusion is made that the original assumption of randomness is suspect or faulty. In this case, statistical hypothesis testing yields the following conclusions: reject H0 (randomness) and accept Ha (non-randomness). Statistical hypothesis testing is a conclusion-generation procedure that has two possible outcomes, either accept H0 (the data is random) or accept Ha (the data is non-random). The following 2 by 2 table relates the true (unknown) status of the data at hand to the conclusion arrived at using the testing procedure. CONCLUSION Accept H0 Accept Ha (reject H0) No error Type I error Type II error No error  TRUE SITUATION Data is random (H0 is true) Data is not random (Ha is true)  If the data is, in truth, random, then a conclusion to reject the null hypothesis (i.e., conclude that the data is non-random) will occur a small percentage of the time. This conclusion is called a Type I error. If the data is, in truth, non-random, then a conclusion to accept the null hypothesis (i.e., conclude that the data is actually random) is called a Type II error. The conclusions to accept H0 when the data is really random, and to reject H0 when the data is non-random, are correct. The probability of a Type I error is often called the level of significance of the test. This probability can be set prior to a test and is denoted as . For the test,  is the probability that the test will indicate that the sequence is not random when it really is random. That is, a sequence appears to have non-random properties even when a ""good"" generator produced the sequence. Common values of  in cryptography are about 0.01. The probability of a Type II error is denoted as . For the test,  is the probability that the test will indicate that the sequence is random when it is not; that is, a ""bad"" generator produced a  4   sequence that appears many different values non-random, and each more difficult than the  to have random properties. Unlike ,  is not a fixed value.  can take on because there are an infinite number of ways that a data stream can be different way yields a different . The calculation of the Type II error  is calculation of  because of the many possible types of non-randomness.  One of the primary goals of the following tests is to minimize the probability of a Type II error, i.e., to minimize the probability of accepting a sequence being produced by a good generator when the generator was actually bad. The probabilities  and  are related to each other and to the size n of the tested sequence in such a way that if two of them are specified, the third value is automatically determined. Practitioners usually select a sample size n and a value for  (the probability of a Type I error  the level of significance). Then a critical point for a given statistic is selected that will produce the smallest  (the probability of a Type II error). That is, a suitable sample size is selected along with an acceptable probability of deciding that a bad generator has produced the sequence when it really is random. Then the cutoff point for acceptability is chosen such that the probability of falsely accepting a sequence as random has the smallest possible value. Each test is based on a calculated test statistic value, which is a function of the data. If the test statistic value is S and the critical value is t, then the Type I error probability is P(S > t || Ho is true) = P(reject Ho | H0 is true), and the Type II error probability is P(S  t || H0 is false) = P(accept H0 | H0 is false). The test statistic is used to calculate a P-value that summarizes the strength of the evidence against the null hypothesis. For these tests, each P-value is the probability that a perfect random number generator would have produced a sequence less random than the sequence that was tested, given the kind of non-randomness assessed by the test. If a P-value for a test is determined to be equal to 1, then the sequence appears to have perfect randomness. A P-value of zero indicates that the sequence appears to be completely nonrandom. A significance level () can be chosen for the tests. If P-value  , then the null hypothesis is accepted; i.e., the sequence appears to be random. If P-value < , then the null hypothesis is rejected; i.e., the sequence appears to be non-random. The parameter  denotes the probability of the Type I error. Typically,  is chosen in the range [0.001, 0.01].  An  of 0.001 indicates that one would expect by the test if the sequence was random. For a considered to be random with a confidence of would be considered to be non-random with a one sequence in 1000 sequences to be rejected P-value  0.001, a sequence would be 99.9 %. For a P-value < 0.001, a sequence confidence of 99.9 %.    An  of 0.01 indicates that one would expect 1 sequence in 100 sequences to be rejected. A P-value  0.01 would mean that the sequence would be considered to be random with a confidence of 99 %. A P-value < 0.01 would mean that the conclusion was that the sequence is non-random with a confidence of 99 %.  For the examples in this document,  has been chosen to be 0.01. Note that, in many cases, the parameters in the examples do not conform to the recommended values; the examples are for illustrative purposes only.  5   1.1.6  Considerations for Randomness, Unpredictability and Testing  The following assumptions are made with respect to random binary sequences to be tested: 1. Uniformity: At any point in the generation of a sequence of random or pseudorandom bits, the occurrence of a zero or one is equally likely, i.e., the probability of each is exactly 1/2. The expected number of zeros (or ones) is n/2, where n = the sequence length. 2. Scalability: Any test applicable to a sequence can also be applied to subsequences extracted at random. If a sequence is random, then any such extracted subsequence should also be random. Hence, any extracted subsequence should pass any test for randomness. 3. Consistency: The behavior of a generator must be consistent across starting values (seeds). It is inadequate to test a PRNG based on the output from a single seed, or an RNG on the basis of an output produced from a single physical output.  1.2  Definitions and Abbreviations Definition A statistical technique that derives limiting approximations for functions of interest. The limiting distribution of a test statistic arising when n approaches infinity. A random variable that takes on the value of one with probability p and the value of zero with probability 1-p. A sequence of zeroes and ones. A random variable is binomially distributed if there is an integer n and a probability p such that the random variable is the number of successes in n Bernoulli experiments, where the probability of success in a single experiment is p. In a Bernoulli experiment, there are only two possible outcomes. A sequence of bits. A subset of a bit string. A block has a predetermined length. For a random sample of size n from a population with mean  and variance 2, the distribution of the sample means is  Term Asymptotic Analysis  Asymptotic Distribution  Bernoulli Random Variable Binary Sequence Binomial Distribution  Bit String Block Central Limit Theorem  6   approximately normal with mean  and variance 2/n as the sample size increases. Complementary Error Function Confluent Hypergeometric Function Critical Value See Erfc.  The confluent hypergeometric function is defined as 1 (b) zt a -1 b - a -1 (a; b; z ) = 0 e t (1 - t ) dt . (a)(b - a ) The value that is exceeded by the test statistic with a small probability (significance level). A ""look-up"" or calculated value of a test statistic (i.e., a test statistic value) that, by construction, has a small probability of occurring (e.g., 5 %) when the null hypothesis of randomness is true. A function giving the probability that the random variable X is less than or equal to x, for every value x. That is, F(x) = P(X  x). A measure of the disorder or randomness in a closed system. The entropy of uncertainty of a random variable X with probabilities pi, ..., pn is defined to be H(X) = -  pi log pi . i =1 n  Cumulative Distribution Function (CDF) F(x)  Entropy  Entropy Source  A physical source of information whose output either appears to be random in itself or by applying some filtering/distillation process. This output is used as input to either a RNG or PRNG. The complementary error function erfc(z) is defined in Section 5.5.3. This function is related to the normal cdf. The incomplete gamma function Q(a,x) is defined in Section 5.5.3. A random variable that takes the value k, a non-negative integer with probability pk(1-p). The random variable x is the number of successes before a failure in an indefinite series of Bernoulli trials. A structure/value that is available by all routines in the test code. Graphical User Interface.  Erfc  igamc  Geometric Random Variable  Global Structure/Global Value GUI  7   Incomplete Gamma Function Hypothesis (Alternative)  See the definition for igamc.  A statement Ha that an analyst will consider as true (e.g., Ha: the sequence is non-random) if and when the null hypothesis is determined to be false. A statement H0 about the assumed default condition/property of the observed sequence. For the purposes of this document, the null hypothesis H0 is that the sequence is random. If H0 is in fact true, then the reference distribution and critical values of the test statistic may be derived. A statistical test that may be used to determine if a set of data comes from a particular probability distribution. The probability of falsely rejecting the null hypothesis, i.e., the probability of concluding that the null hypothesis is false when the hypothesis is, in fact, true. The tester usually chooses this value; typical values are 0.05, 0.01 or 0.001; occasionally, smaller values such as 0.0001 are used. The level of significance is the probability of concluding that a sequence is non-random when it is in fact random. Synonyms: Type I error,  error. In the context of the binary rank matrix test, linear dependence refers to m-bit vectors that may be expressed as a linear combination of the linearly independent m-bit vectors. An interactive computer algebra system that provides a complete mathematical environment for the manipulation and simplification of symbolic algebraic expressions, arbitrary extended precision mathematics, two- and three-dimensional graphics, and programming. An integrated, technical computer environment that combines numeric computation, advanced graphics and visualization, and a high level programming language. MATLAB includes functions for data analysis and visualization; numeric and symbolic computation; engineering and scientific graphics; modeling, simulation and prototyping; and programming, application development and a GUI design. A continuous distribution whose density function is given by  Hypothesis (Null)  Kolmogorov-Smirnov Test Level of Significance ()  Linear Dependence  Maple  MATLAB  Normal (Gaussian) Distribution  8   2 scale parameters. P-value  f ( x;  ;  ) =  1 2  e  1  x-  -  2    2  , where  and  are location and  The probability (under the null hypothesis of randomness) that the chosen test statistic will assume values that are equal to or worse than the observed test statistic value when considering the null hypothesis. The P-value is frequently called the ""tail probability."" Poisson distributions model (some) discrete random variables. Typically, a Poisson random variable is a count of the number of rare events that occur in a certain time interval. A function that provides the ""local"" probability distribution of a test statistic. From a finite sample size n, a probability density function will be approximated by a histogram. The assignment of a probability to the possible outcomes (realizations) of a random variable. A deterministic algorithm which, given a truly random binary sequence of length k, outputs a binary sequence of length l >> k which appears to be random. The input to the generator is called the seed, while the output is called a pseudorandom bit sequence. A mechanism that purports to generate truly random data.  Poisson Distribution 3.8  Probability Density Function (PDF)  Probability Distribution  Pseudorandom Number Generator (PRNG)  Random Number Generator (RNG) Random Binary Sequence  A sequence of bits for which the probability of each bit being a ""0"" or ""1"" is . The value of each bit is independent of any other bit in the sequence, i.e., each bit is unpredictable. Random variables differ from the usual deterministic variables (of science and engineering) in that random variables allow the systematic distributional assignment of probability values to each possible outcome. Refers to the rank of a matrix in linear algebra over GF(2). Having reduced a matrix into row-echelon form via elementary row operations, the number of nonzero rows, if any, are counted in order to determine the number of linearly independent rows or columns in the matrix.  Random Variable  Rank (of a matrix)  9   Run  An uninterrupted sequence of like bits (i.e., either all zeroes or all ones). The input to a pseudorandom number generator. Different seeds generate different pseudorandom sequences. The Secure Hash Algorithm defined in Federal Information Processing Standard 180-1. See the definition in Section 5.5.3. This is the normal function for mean = 0 and variance = 1.  Seed  SHA-1  Standard Normal Cumulative Distribution Function Statistically Independent (Events)  Two events are independent if the occurrence of one event does not affect the chances of the occurrence of the other event. The mathematical formulation of the independence of events A and B is the probability of the occurrence of both A and B being equal to the product of the probabilities of A and B (i.e., P(A and B) = P(A)P(B)). A function of the data (binary stream) which is computed and used to decide whether or not to reject the null hypothesis. A systematic statistical rule whose purpose is to generate a conclusion regarding whether the experimenter should accept or reject the null hypothesis Ho. A predefined substring consisting of a fixed pattern/template (e.g., 010, 0110).  Statistical Test (of a Hypothesis)  Word  Abbreviation ANSI FIPS NIST RNG SHA-1  Definition American National Standards Institute Federal Information Processing Standard National Institute of Standards and Technology Random Number Generator Secure Hash Algorithm  10   1.3  Mathematical Symbols  In general, the following notation is used throughout this document. However, the tests in this document have been designed and described by multiple authors who may have used slightly different notation. The reader is advised to consider the notation used for each test separate from that notation used in other tests. Symbol x  d 2m(obs);  22m(obs) E[ ]   i  Meaning The floor function of x; for a given real positive x, x = x-g, where x is a non-negative integer, and 0  g < 1. The significance level. The normalized difference between the observed and expected number of frequency components. See Sections 2.6 and 3.6. A measure of how well the observed values match the expected value. See Sections 2.12 and 3.12. The expected value of a random variable. The original input string of zero and one bits to be tested. The ith bit in the original sequence . The null hypothesis; i.e., the statement that the sequence is random. The natural logarithm of x: log(x) = loge(x) = ln(x). Defined as ln( x ) , where ln is the natural logarithm. ln( 2 )  H0 log(x) log2(x)  M N n f n  The number of bits in a substring (block) being tested. The number of M-bit blocks to be tested. The number of bits in the stream being tested. The sum of the log2 distances between matching L-bit templates, i.e., the sum of the number of digits in the distance between L-bit templates. See Sections 2.9 and 3.9. 3.14159... unless defined otherwise for a specific test. The average number of ones in a string of n bits.    i  11    2 s obs  The standard deviation of a random variable =  2  (x -  ) f ( x )dx  .  The variance of a random variable = (standard deviation)2. The observed value which is used as a statistic in the Frequency test. The nth partial sum for values Xi = {-1, +1}; i.e., the sum of the first n values of Xi. The summation symbol. Standard Normal Cumulative Distribution Function (see Section 5.5.3). The total number of times that a given state occurs in the identified cycles. See Section 2.16 and 3.16. The elements of the string consisting of 1 that is to be tested for randomness, where Xi = 2i-1. The [theoretical] chi-square distribution; used as a test statistic; also, a test statistic that follows the 2 distribution. The chi-square statistic computed on the observed values. See Sections 2.2, 2.4, 2.5, 2.7, 2.8, 2.11, 2.13, 2.15, and the corresponding sections of Section 3. The expected number of runs that an assumption of randomness See The observed number of runs in a 3.3. The expected number of words in would occur in a sequence of length n under Sections 2.3 and 3.3. sequence of length n. See Sections 2.3 and a bitstring being tested.  S  n    j Xi   2  2(obs)  Vn Vn(obs) W Wobs  The number of disjoint words in a sequence. See Sections 2.10 and 3.10.  12   2  RANDOM NUMBER GENERATION TESTS  The NIST Test Suite is a statistical package consisting of 16 tests that were developed to test the randomness of (arbitrarily long) binary sequences produced by either hardware or software based cryptographic random or pseudorandom number generators. These tests focus on a variety of different types of non-randomness that could exist in a sequence. Some tests are decomposable into a variety of subtests. The 16 tests are: 1. The Frequency (Monobit) Test, 2. Frequency Test within a Block, 3. The Runs Test, 4. Test for the Longest-Run-of-Ones in a Block, 5. The Binary Matrix Rank Test, 6. The Discrete Fourier Transform (Spectral) Test, 7. The Non-overlapping Template Matching Test, 8. The Overlapping Template Matching Test, 9. Maurer's ""Universal Statistical"" Test, 10. The Lempel-Ziv Compression Test, 11. The Linear Complexity Test, 12. The Serial Test, 13. The Approximate Entropy Test, 14.The Cumulative Sums (Cusums) Test, 15. The Random Excursions Test, and 16. The Random Excursions Variant Test. This section (Section 2) consists of 16 subsections, one subsection for each test. Each subsection provides a high level description of the particular test. The corresponding subsections in Section 3 provide the technical details for each test. Section 4 provides a discussion of testing strategy and the interpretation of test results. The order of the application of the tests in the test suite is arbitrary. However, it is recommended that the Frequency test be run first, since this supplies the most basic evidence for the existence of non-randomness in a sequence, specifically, non-uniformity. If this test fails, the likelihood of other tests failing is high. (Note: The most time-consuming statistical test is the Linear Complexity test; see Sections 2.11 and 3.11). Section 5 provides a user's guide for setting up and running the tests, and a discussion on program layout. The statistical package includes source code and sample data sets. The test code was developed in ANSI C. Some inputs are assumed to be global values rather than calling parameters. A number of tests in the test suite have the standard normal and the chi-square (  2 ) as reference distributions. If the sequence under test is in fact non-random, the calculated test statistic will fall in extreme regions of the reference distribution. The standard normal  13   distribution (i.e., the bell-shaped curve) is used to compare the value of the test statistic obtained from the RNG with the expected value of the statistic under the assumption of randomness. The test statistic for the standard normal distribution is of the form z = (x - )/, where x is the sample test statistic value, and  and 2 are the expected value and the variance of the test statistic. The  2 distribution (i.e., a left skewed curve) is used to compare the goodness-of-fit of the observed frequencies of a sample measure to the corresponding expected frequencies of the hypothesized distribution. The test statistic is of the form  2 =   ((  oi - e  i  )  2  ei , where oi and  )  ei are the observed and expected frequencies of occurrence of the measure, respectively. For many of the tests in this test suite, the assumption has been made that the size of the sequence length, n, is large (of the order 103 to 107). For such large sample sizes of n, asymptotic reference distributions have been derived and applied to carry out the tests. Most of the tests are applicable for smaller values of n. However, if used for smaller values of n, the asymptotic reference distributions would be inappropriate and would need to be replaced by exact distributions that would commonly be difficult to compute. Note: For many of the examples throughout Section 2, small sample sizes are used for illustrative purposes only, e.g., n = 10. The normal approximation is not really applicable for these examples.  2.1 2.1.1  Frequency (Monobit) Test Test Purpose  The focus of the test is the proportion of zeroes and ones for the entire sequence. The purpose of this test is to determine whether the number of ones and zeros in a sequence are approximately the same as would be expected for a truly random sequence. The test assesses the closeness of the fraction of ones to , that is, the number of ones and zeroes in a sequence should be about the same. All subsequent tests depend on the passing of this test; there is no evidence to indicate that the tested sequence is non-random.  2.1.2  Function Call  Frequency(n), where: n The length of the bit string.  Additional input used by the function, but supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n.  14   2.1.3 s obs:  Test Statistic and Reference Distribution The absolute value of the sum of the Xi (where, Xi = 2 - 1 = 1) in the sequence divided by the square root of the length of the sequence.  The reference distribution for the test statistic is half normal (for large n). (Note: If z (where z = s obs 2 ; see Section 3.1) is distributed as normal, then |z| is distributed as half normal.) If the sequence is random, then the plus and minus ones will tend to cancel one another out so that the test statistic will be about 0. If there are too many ones or too many zeroes, then the test statistic will tend to be larger than zero.  2.1.4 (1)  Test Description Conversion to 1: The zeros and ones of the input sequence () are converted to values of 1 and +1 and are added together to produce Sn = X1 + X 2 +L+ X n , where Xi = 2i  1. For example, if  = 1011010101, then n=10 and Sn = 1 + (-1) + 1 + 1 + (-1) + 1 + (-1) + 1 + (-1) + 1 = 2.  (2)  Compute the test statistic s  obs  =  Sn n obs  For the example in this section, s (3) s   =  2 10  = .632455532.  Compute P-value = erfc  obs  , where erfc is the complementary error function as    2 defined in Section 5.5.3.3.  .632455532  For the example in this section, P-value = erfc   = 0.527089. 2    2.1.5  Decision Rule (at the 1 % Level)  If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2.1.6  Conclusion and Interpretation of Test Results  Since the P-value obtained in step 3 of Section 2.1.4 is  0.01 (i.e., P-value = 0.527089), the conclusion is that the sequence is random. 15   Note that if the P-value were small (< 0.01), then this would be caused by S n or sobs being large. Large positive values of Sn are indicative of too many ones, and large negative values of Sn are indicative of too many zeros. 2.1.7 Input Size Recommendations  It is recommended that each sequence to be tested consist of a minimum of 100 bits (i.e., n  100).  2.1.8 (input)  Example  = 11001001000011111101101010100010001000010110100011 00001000110100110001001100011001100010100010111000 n = 100 S s 100  (input) (processing) (processing) (output) (conclusion)  = -16 = 1.6  obs  P-value = 0.109599 Since P-value  0.01, accept the sequence as random.  2.2 2.2.1  Frequency Test within a Block Test Purpose  The focus of the test is the proportion of ones within M-bit blocks. The purpose of this test is to determine whether the frequency of ones in an M-bit block is approximately M/2, as would be expected under an assumption of randomness. For block size M=1, this test degenerates to test 1, the Frequency (Monobit) test.  2.2.2  Function Call  BlockFrequency(M,n), where: M n The length of each block. The length of the bit string.  16   Additional input used by the function, but supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n. Test Statistic A measure of how well the observed proportion of ones within a given M-bit block match the expected proportion (1/2).  2.2.3  2 (obs):  The reference distribution for the test statistic is a 2 distribution.  2.2.4 (1)  Test Description n Partition the input sequence into N =   non-overlapping blocks. Discard any unused M   bits.  For example, if n = 10, M = 3 and  = 0110011010, 3 blocks (N = 3) would be created, consisting of 011, 001 and 101. The final 0 would be discarded. (2) Determine the proportion i of ones in each M-bit block using the equation i = j =1    M  ( i -1 ) M + j  M  , for 1  i  N.  For the example in this section, 1 = 2/3, 2 = 1/3, and 3 = 2/3. (3) Compute the  statistic: 2(obs) = 4 M 2   i =1  N  ( i - )2.  2 2 2 For the example in this section, 2(obs) = 4 x 3 x  2 3 - 1 2 + 1 3 - 1 2 + 2 3 - 1 2  = 1 .      (  )(  )(  )  (4)  Compute P-value = igamc (N/2, 2(obs)/2) , where igamc is the incomplete gamma function for Q(a,x) as defined in Section 5.5.3.3. Note: When comparing this section against the technical description in Section 3.2, note that Q(a,x) = 1-P(a,x). 3 1 For the example in this section, P-value = igamc  ,  = 0.801252. 2 2  17   2.2.5  Decision Rule (at the 1 % Level)  If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2.2.6  Conclusion and Interpretation of Test Results  Since the P-value obtained in step 4 of Section 2.2.4 is  0.01 (i.e., P-value = 0.801252), the conclusion is that the sequence is random. Note that small P-values (< 0.01) would have indicated a large deviation from the equal proportion of ones and zeros in at least one of the blocks.  2.2.7  Input Size Recommendations  It is recommended that each sequence to be tested consist of a minimum of 100 bits (i.e., n  100). Note that n  MN. The block size M should be selected such that M  20, M > .01n and N < 100.  2.2.8 (input)  Example  = 11001001000011111101101010100010001000010110100011 00001000110100110001001100011001100010100010111000 n = 100 M = 10 N = 10 2 = 7.2 P-value = 0.706438 Since P-value  0.0, accept the sequence as random.  (input) (input) (processing) (processing) (output) (conclusion)  2.3 2.3.1  Runs Test Test Purpose  18   The focus of this test is the total number of runs in the sequence, where a run is an uninterrupted sequence of identical bits. A run of length k consists of exactly k identical bits and is bounded before and after with a bit of the opposite value. The purpose of the runs test is to determine whether the number of runs of ones and zeros of various lengths is as expected for a random sequence. In particular, this test determines whether the oscillation between such zeros and ones is too fast or too slow.  2.3.2  Function Call  Runs(n), where: n The length of the bit string.  Additional inputs for the function, but supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n. Test Statistic and Reference Distribution The total number of runs (i.e., the total number of zero runs + the total number of one-runs) across all n bits.  2.3.3 Vn(obs):  The reference distribution for the test statistic is a 2 distribution.  2.3.4  Test Description  Note: The Runs test carries out a Frequency test as a prerequisite. (1) Compute the pre-test proportion  of ones in the input sequence:  = For example, if  = 1001101011, then n=10 and  = 6/10 = 3/5. (2) Determine if the prerequisite Frequency test is passed: If it can be shown that -1 2   j n  j  .  ,  then the Runs test need not be performed (i.e., the test should not have been run because of a failure to pass test 1, the Frequency (Monobit) test). If the test is not applicable, then the P-value is set to 0.0000. Note that for this test,  = 2 has been pre-defined in the test n  code.  19   For the example in this section, since < , and the test is not run.  = 2  10   0.63246  , then | - 1/2| = | 3/5  1/2 | = 0.1  Since the observed value  is within the selected bounds, the runs test is applicable. (3) Compute the test statistic Vn ( obs ) =  r( k ) + 1 k =1 n -1  , where r(k)=0 if k=  k+1  , and r(k)=1 otherwise.  Since  = 1 00 11 0 1 0 11, then V10(obs)=(1+0+1+0+1+1+1+1+0)+1=7. (4) Compute P-value = erfc    |V n (obs) - 2n (1 -  ) |  .  2 2n (1 -  )     3  7 -  2  10  1 -   5   P-value = erfc   2  2  10  3  1   5   For the example,     3 - 5 3 5                  = 0.147232.  2.3.5  Decision Rule (at the 1 % Level)  If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2.3.6  Conclusion and Interpretation of Test Results  Since the P-value obtained in step 4 of Section 2.3.4 is  0.01 (i.e., P-value = 0.147232), the conclusion is that the sequence is random. Note that a large value for Vn(obs) would have indicated an oscillation in the string which is too fast; a small value would have indicated that the oscillation is too slow. (An oscillation is considered to be a change from a one to a zero or vice versa.) A fast oscillation occurs when there are a lot of changes, e.g., 010101010 oscillates with every bit. A stream with a slow oscillation has fewer runs than would be expected in a random sequence, e.g., a sequence containing 100 ones, followed by 73 zeroes, followed by 127 ones (a total of 300 bits) would have only three runs, whereas 150 runs would be expected.  2.3.7  Input Size Recommendations  It is recommended that each sequence to be tested consist of a minimum of 100 bits (i.e., n  100).  20   2.3.8 (input)  Example  = 11001001000011111101101010100010001000010110100011 00001000110100110001001100011001100010100010111000 n = 100  = 0.02  = 0.42 Vn(obs) = 52 P-value = 0.500798 Since P-value  0.01, accept the sequence as random.  (input) (input) (processing) (processing) (output) (conclusion)  2.4 2.4.1  Test for the Longest Run of Ones in a Block Test Purpose  The focus of the test is the longest run of ones within M-bit blocks. The purpose of this test is to determine whether the length of the longest run of ones within the tested sequence is consistent with the length of the longest run of ones that would be expected in a random sequence. Note that an irregularity in the expected length of the longest run of ones implies that there is also an irregularity in the expected length of the longest run of zeroes. Therefore, only a test for ones is necessary. See Section 4.4.  2.4.2  Function Call  LongestRunOfOnes(n), where: n The length of the bit string.  Additional input for the function supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n. The length of each block. The test code has been pre-set to accommodate three values for M: M = 8, M = 128 and M = 104 in accordance with the following table.  M  21   Minimum n 128 6272 750,000 N  M 8 128 104  The number of blocks; selected in accordance with the value of M.  2.4.3 2(obs):  Test Statistic and Reference Distribution A measure of how well the observed longest run length within M-bit blocks matches the expected longest length within M-bit blocks.  The reference distribution for the test statistic is a 2 distribution.  2.4.4 (1) (2)  Test Description Divide the sequence into M-bit blocks. Tabulate the frequencies i of the longest runs of ones in each block into categories, where each cell contains the number of runs of ones of a given length. For the values of M supported by the test code, the vi cells will hold the following counts: vi v0 v1 v2 v3 v4 v5 v6 M=8 1 2 3 4 M = 128 4 5 6 7 8 9 M = 104  10 11 12 13 14 15  16  For an example, see Section 2.4.8. (3) K ( - N ) 2 i Compute  2 ( obs ) =  vi , where the values for i are provided in Section 3.4. i =0  N i  The values of K and N are determined by the value of M in accordance with the following table: M 8 K 3 N 16  22   128 104  5 6  49 75  For the example of 2.4.8, ( 4 - 16 (.2148 )) 2 ( 9 - 16 (.3672 )) 2 ( 3 - 16 (.2305 )) 2 ( 0 - 16 (.1875 )) 2 2  ( obs ) = + + + = 4.882605 16 (.2148 ) 16 (.3672 ) 16 (.2305 16 (.1875 )  K  2 ( obs Compute P-value = igamc  , 2 2  ) .    (4)   3 4.882605  For the example, P-value = igamc  ,  = 0.180598. 2 2   2.4.5  Decision Rule (at the 1 % Level)  If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2.4.6  Conclusion and Interpretation of Test Results  For the example in Section 2.4.8, since the P-value  0.01 (P-value = 0.180609), the conclusion is that the sequence is random. Note that large values of 2(obs) indicate that the tested sequence has clusters of ones.  2.4.7  Input Size Recommendations  It is recommended that each sequence to be tested consist of a minimum of bits as specified in the table in Section 2.4.2.  2.4.8  Example  For the case where K = 3 and M = 8: (input)  = 11001100000101010110110001001100111000000000001001 00110101010001000100111101011010000000110101111100 1100111001101101100010110010 n = 128  (input)  23   (processing)  Subblock Max-Run 11001100 (2) 01101100 (2) 11100000 (3) 01001101 (2) 00010011 (2) 10000000 (1) 11001100 (2) 11011000 (2)  Subblock Max-Run 00010101 (1) 01001100 (2) 00000010 (1) 01010001 (1) 11010110 (2) 11010111 (3) 11100110 (3) 10110010 (2)  (processing) (output) (conclusion)  0 = 4; 1 = 9; 2 = 3; 4 = 0; 2 = 4.882457 P-value = 0.180609 Since the P-value is  0.01, accept the sequence as random.  2.5 2.5.1  Binary Matrix Rank Test Test Purpose  The focus of the test is the rank of disjoint sub-matrices of the entire sequence. The purpose of this test is to check for linear dependence among fixed length substrings of the original sequence. Note that this test also appears in the DIEHARD battery of tests [7].  2.5.2  Function Call  Rank(n), where: n The length of the bit string.  Additional input used by the function supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n. The number of rows in each matrix. For the test suite, M has been set to 32. If other values of M are used, new approximations need to be computed. The number of columns in each matrix. For the test suite, Q has been set to 32. If other values of Q are used, new approximations need to be computed.  M  Q  24   2.5.3 2(obs):  Test Statistic and Reference Distribution A measure of how well the observed number of ranks of various orders match the expected number of ranks under an assumption of randomness.  The reference distribution for the test statistic is a 2 distribution.  2.5.4 (1)  Test Description Sequentially divide the sequence into MQ-bit disjoint blocks; there will exist n N =   MQ     such blocks. Discarded bits will be reported as not being used in the  computation within each block. Collect the MQ bit segments into M by Q matrices. Each row of the matrix is filled with successive Q-bit blocks of the original sequence . For example, if n = 20, M = Q = 3, and  = 01011001001010101101, then partition the stream into N = n   3  3   = 2 matrices of cardinality MQ (33 = 9). Note that the last two 010 010 010 011  bits (0 and 1) will be discarded. The two matrices are 1 1 0 and 1 0 1 . Note that the first matrix consists of the first three bits in row 1, the second set of three bits in row 2, and the third set of three bits in row 3. The second matrix is similarly constructed using the next nine bits in the sequence. (2) Determine the binary rank ( Rl ) of each matrix, where l = 1,..., N . The method for determining the rank is described in Appendix A. For the example in this section, the rank of the first matrix is 2 (R1 = 2), and the rank of the second matrix is 3 (R2 = 3). (3) Let FM = the number of matrices with Rl = M (full rank), FM-1 = the number of matrices with Rl = M-1 (full rank - 1), N  FM - FM-1 = the number of matrices remaining. For the example in this section, FM = F3 = 1 (R2 has the full rank of 3), FM-1 = F2 = 1 (R1 has rank 2), and no matrix has any lower rank. (4) Compute ( FM - 0.2888 N ) 2 ( FM -1 - 0.5776 N ) 2 ( N - FM - FM -1 - 0.1336 N ) 2  (obs ) = + + . 0.2888 N 0.5776 N 0.1336 N 2  25   For the example in this section, (1 - 0.2888  2)2 + (1 - 0.5776  2 )2 + (2 - 1 - 1 - 0.1336  2  2 (obs ) = 0.2888  2 0.5776  2 0.1336  2 (5) Compute P - value = e -  2 ( obs ) / 2  )2  = 0.596953.   the example is equal to igamc    . Since there are 3 classes in the example, the P-value for  2 (obs )  . 1,  2  0.596953 2  For the example in this section, P-value = e  = 0.741948.  2.5.5  Decision Rule (at the 1 % Level)  If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2.5.6  Conclusion and Interpretation of Test Results  Since the P-value obtained in step 5 of Section 2.5.4 is  0.01 (P-value = 0.741948), the conclusion is that the sequence is random. Note that large values of  2 ( obs ) (and hence, small P-values) would have indicated a deviation of the rank distribution from that corresponding to a random sequence.  2.5.7  Input Size Recommendations  The probabilities for M = Q = 32 have been calculated and inserted into the test code. Other choices of M and Q may be selected, but the probabilities would need to be calculated. The minimum number of bits to be tested must be such that n  38MQ (i.e., at least 38 matrices are created). For M = Q = 32, each sequence to be tested should consist of a minimum of 38,912 bits.  2.5.8 (input) (input)  Example  = the first 100,000 binary digits in the expansion of e n = 100000, M = Q = 32 N = 97 FM = 23, FM-1 = 60, N  FM  FM-1= 14 (NOTE: 672 BITS WERE DISCARDED.)  (processing) (processing)  26   (processing) (output) (conclusion)  2 = 1.2619656 P-value = 0.532069 Since P-value  0.01, accept the sequence as random.  2.6 2.6.1  Discrete Fourier Transform (Spectral) Test Test Purpose  The focus of this test is the peak heights in the Discrete Fourier Transform of the sequence. The purpose of this test is to detect periodic features (i.e., repetitive patterns that are near each other) in the tested sequence that would indicate a deviation from the assumption of randomness. The intention is to detect whether the number of peaks exceeding the 95 % threshold is significantly different than 5 %.  2.6.2  Function Call  DiscreteFourierTransform(n), where: n The length of the bit string.  Additional input used by the function, but supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n. Test Statistic and Reference Distribution The normalized difference between the observed and the expected number of frequency components that are beyond the 95 % threshold.  2.6.3 d:  The reference distribution for the test statistic is the normal distribution.  2.6.4 (1)  Test Description The zeros and ones of the input sequence () are converted to values of 1 and +1 to create the sequence X = x1, x2, ..., xn, where xi = 2i  1. For example, if n = 10 and  = 1001010011, then X = 1, -1, -1, 1, -1, 1, -1, -1, 1, 1.  27   (2)  Apply a Discrete Fourier transform (DFT) on X to produce: S = DFT(X). A sequence of complex variables is produced which represents periodic components of the sequence of bits at different frequencies (see Section 3.6 for a sample diagram of a DFT result). Calculate M = modulus(S)  |S'|, where S is the substring consisting of the first n/2 elements in S, and the modulus function produces a sequence of peak heights. Compute T = 3n = the 95 % peak height threshold value. Under an assumption of randomness, 95 % of the values obtained from the test should not exceed T. Compute N0 = .95n/2. N0 is the expected theoretical (95 %) number of peaks (under the assumption of randomness) that are less than T. For the example in this section, N0 = 4.75.  (3)  (4)  (5)  (6)  Compute N1 = the actual observed number of peaks in M that are less than T. For the example in this section, N1 = 4.  (7)  Compute d =  ( N1 - N 0 ) n(.95)(.05) / 2  .  For the example in this section, d = d  Compute P-value = erfc  2 .    (4 - 4.75 ) 10(.95 )(.05 )  /2  = -1.538968.  (8)   1.538968  For the example in this section, P-value = erfc  = 0.123812. 2   2.6.5  Decision Rule (at the 1 % Level)  If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2.6.6  Conclusion and Interpretation of Test Results  Since the P-value obtained in step 8 of Section 2.6.4 is  0.01 (P-value = 0.123812), the conclusion is that the sequence is random.  28   A d value that is too low would indicate that there were too few peaks (< 95 %) below T, and too many peaks (more than 5 %) above T.  2.6.7  Input Size Recommendations  It is recommended that each sequence to be tested consist of a minimum of 1000 bits (i.e., n  1000).  2.6.8 (input)  Example  = 11001001000011111101101010100010001000010110100011 00001000110100110001001100011001100010100010111000 n = 100 N1 = 46 N0 = 47.5 d = -0.973329 P-value = 0.330390 Since P-value  0.01, accept the sequence as random.  (input) (processing) (processing) (processing) (output) (conclusion)  2.7 2.7.1  Non-overlapping Template Matching Test Test Purpose  The focus of this test is the number of occurrences of pre-specified target strings. The purpose of this test is to detect generators that produce too many occurrences of a given non-periodic (aperiodic) pattern. For this test and for the Overlapping Template Matching test of Section 2.8, an m-bit window is used to search for a specific m-bit pattern. If the pattern is not found, the window slides one bit position. If the pattern is found, the window is reset to the bit after the found pattern, and the search resumes.  2.7.2  Function Call  NonOverlappingTemplateMatching(m,n) m The length in bits of each template. The template is the target string.  29   n  The length of the entire bit string under test.  Additional input used by the function, but supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n. The m-bit template to be matched; B is a string of ones and zeros (of length m) which is defined in a template library of non-periodic patterns contained within the test code. The length in bits of the substring of  to be tested. M has been set to 131,072 (i.e., 217) in the test code. The number of independent blocks. N has been fixed at 8 in the test code.  B  M  N  2.7.3 2(obs):  Test Statistic and Reference Distribution A measure of how well the observed number of template ""hits"" matches the expected number of template ""hits"" (under an assumption of randomness).  The reference distribution for the test statistic is the 2 distribution.  2.7.4 (1)  Test Description Partition the sequence into N independent blocks of length M. For example, if  = 10100100101110010110, then n = 20. If N = 2 and M = 10, then the two blocks would be 1010010010 and 1110010110.  (2)  Let Wj (j = 1, ..., N) be the number of times that B (the template) occurs within the block j. Note that j = 1,...,N. The search for matches proceeds by creating an m-bit window on the sequence, comparing the bits within that window against the template. If there is no match, the window slides over one bit , e.g., if m = 3 and the current window contains bits 3 to 5, then the next window will contain bits 4 to 6. If there is a match, the window slides over m bits, e.g., if the current (successful) window contains bits 3 to 5, then the next window will contain bits 6 to 8. For the above example, if m = 3 and the template B = 001, then the examination proceeds as follows: Block 1 Bit Positions 1-3 Bits 101 W 0 1  Block 2 Bits 111 W 0 2  30   2-4 3-5 4-6 5-7 6-8 7-9 8-10  010 100 001 (hit) Not examined Not examined 001 010 (hit)  0 0 Increment to 1  Increment to 2 2  110 100 001 (hit) Not examined Not examined 011 110  0 0 Increment to 1  1 1  Thus, W1 = 2, and W2 = 1. (3) Under an assumption of randomness, compute the theoretical mean  and variance 2:  1 2m - 1   = (M-m+1)/2m  2 = M  m - 2m  . 2 2  For the example in this section,  = (10-3+1)/23 = 1, and  1 23-1  2 = 10    3 - 23  = 0.46875  2 2   . j  (4)  Compute  ( obs ) =  2  N  (W  - 2  )  j =1  2  .  For the example in this section,  2 (obs ) =  (2 - 1)2 + (1 - 1)2 0.46875  =  1+ 0 = 2.133333 . 0.46875  (5)   N  2 ( obs )   . Note that multiple P-values will be Compute P-value = igamc  ,   2 2   computed, i.e., one P-value will be computed for each template. For m = 9, up to 148 Pvalues may be computed; for m = 10, up to 284 P-values may be computed.  2 2.133333 For the example in this section, P-value = igamc  , 2 2   = 0.344154.   2.7.5  Decision Rule (at the 1 % Level)  If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2.7.6  Conclusion and Interpretation of Test Results  Since the P-value obtained in step 5 of Section 2.7.4 is  0.01 (P-value = 0.344154), the conclusion is that the sequence is random.  31   If the P-value is very small (< 0.01), then the sequence has irregular occurrences of the possible template patterns.  2.7.7  Input Size Recommendations  The test code has been written to provide templates for m = 2, 3,...,10. It is recommended that m = 9 or m = 10 be specified to obtain meaningful results. Although N = 8 has been specified in the test code, the code may be altered to other sizes. However, N should be chosen such that N  100 to be assured that the P-values are valid. The test code has been written to assume a sequence length of n = 106 (entered via a calling parameter) and M = 131072 (hard coded). If values other than these are desired, be sure that M > 0.01  n and N = n/M..  2.7.8  Example  For a template B = 000000001 whose size is m = 9: (input) (input) (processing) (processing)  = 220 bits produced by the G-SHA-1 generator1 n = 220, B = 000000001  = 255.984375 and 2= 247.499999 W1 = 259; W2 = 229; W3 = 271; W4 = 245; W5 = 272; W6 = 262; W7 = 259; and W8 = 246 2(obs) = 5.999377 P-value = 0.647302 Since the P-value  0.01, accept the sequence as random.  (processing) (output) (conclusion)  2.8 2.8.1  Overlapping Template Matching Test Test Purpose  The focus of the Overlapping Template Matching test is the number of occurrences of prespecified target strings. Both this test and the Non-overlapping Template Matching test of Section 2.7 use an m-bit window to search for a specific m-bit pattern. As with the test in Section 2.7, if the pattern is not found, the window slides one bit position. The difference between this test and the test in Section 2.7 is that when the pattern is found, the window slides only one bit before resuming the search. 1  Defined in Federal Information Processing Standard (FIPS) 186-2.  32   2.8.2  Function Call  OverlappingTemplateMatching(m,n) m n The length in bits of the template  in this case, the length of the run of ones. The length of the bit string.  Additional input used by the function, but supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n. The m-bit template to be matched. The number of degrees of freedom. K has been fixed at 5 in the test code. The length in bits of a substring of  to be tested. M has been set to 1032 in the test code. The number of independent blocks of n. N has been set to 968 in the test code.  B K M  N  2.8.3 2(obs):  Test Statistic and Reference Distribution A measure of how well the observed number of template ""hits"" matches the expected number of template ""hits"" (under an assumption of randomness).  The reference distribution for the test statistic is the 2 distribution.  2.8.4 (1)  Test Description Partition the sequence into N independent blocks of length M. For example, if  = 10111011110010110100011100101110111110000101101001, then n = 50. If K = 2, M = 10 and N = 5, then the five blocks are 1011101111, 0010110100, 0111001011, 1011111000, and 0101101001 .  (2)  Calculate the number of occurrences of B in each of the N blocks. The search for matches proceeds by creating an m-bit window on the sequence, comparing the bits within that window against B and incrementing a counter when there is a match. The window slides over one bit after each examination, e.g., if m = 4 and the first window contains bits 42 to 45, the next window consists of bits 43 to 46. Record the number of  33   occurrences of B in each block by incrementing an array vi (where i = 0,...5), such that v0 is incremented when there are no occurrences of B in a substring, v1 is incremented for one occurrence of B,...and v5 is incremented for 5 or more occurrences of B. For the above example, if m = 2 and B = 11, then the examination of the first block (1011101111) proceeds as follows: Bit Positions 1-2 2-3 3-4 4-5 5-6 6-7 7-8 8-9 9-10 Bits 10 01 11 (hit) 11 (hit) 10 01 11 (hit) 11 (hit) 11 (hit) No. of occurrences of B = 11 0 0 Increment to 1 Increment to 2 2 2 Increment to 3 Increment to 4 Increment to 5  Thus, after block 1, there are five occurrences of 11, v5 is incremented, and v0 = 0, v1 = 0, v2 = 0, v3 = 0, v4 = 0, and v5 = 1. In a like manner, blocks 2-5 are examined. In block 2, there are 2 occurrences of 11; v2 is incremented. In block 3, there are 3 occurrences of 11; v3 is incremented. In block 4, there are 4 occurrences of 11; v4 is incremented. In block 5, there is one occurrence of 11; v1 is incremented. Therefore, v0 = 0, v1 = 1, v2 =1, v3 = 1, v4 = 1, v5 = 1 after all blocks have been examined. (3) Compute values for  and  that will be used to compute the theoretical probabilities  corresponding to the classes of v0:  = (M-m+1)/2m  = /2. For the example in this section,  = (10-2+1)/22 = 2.25, and  = /2=1.125. (4) Compute  ( obs ) =  2 i  , where 0 = 0.367879, 1 = 0.183940, 2 = N i 0.137955, 3 = 0.099634, 4 = 0.069935 and 5 = 0.140657 as computed by the equations specified in Section 3.8. i i i =0  5  (v  - N  )  2  For the example in this section, the values of i were recomputed, since the example doesn't fit the requirements stated in Section 3.8.5. The example is intended only for illustration. The values of i are: 0 = 0.324652, 1 = 0.182617, 2 = 0.142670, 3 = 0.106645, 4 = 0.077147, and 5 = 0.166269. 34    2 ( obs ) =  (1 - 5  0.182617 ) + ( 1 - 5  0.142670 )2 + - 5  0.324652 ) + 5  0.324652 5  0.182617 5  0.142670 2 2 (1 - 5  0.106645 ) + (1 - 5  0.077147 ) + (1 - 5  0.166269 )2 = 3.167729. 5  0.106645 5  0.077147 5  0.166269 2 2  (0  (5)   5  2 ( obs Compute P-value = igamc  , 2 2   ) .     5 3.167729  For the example in this section, P-value = igamc  ,  = 0.274932. 2 2   2.8.5  Decision Rule (at the 1 % Level)  If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2.8.6  Conclusion and Interpretation of Test Results  Since the P-value obtained in step 4 of Section 2.8.4 is  0.01 (P-value = 0.274932), the conclusion is that the sequence is random. Note that for the 2-bit template (B = 11), if the entire sequence had too many 2-bit runs of ones, then: 1) 5 would have been too large, 2) the test statistic would be too large, 3) the P-value would have been small (< 0.01) and 4) a conclusion of non-randomness would have resulted.  2.8.7  Input Size Recommendations  The values of K, M and N have been chosen such that each sequence to be tested consists of a minimum of 106 bits (i.e., n  106). Various values of m may be selected, but for the time being, NIST recommends m = 9 or m = 10. If other values are desired, please choose these values as follows:  n  MN.  N should be chosen so that N  (min i) > 5.   = (M-m+1)/2m  2  m should be chosen so that m  log2 M  Choose K so that K  2. Note that the i values would need to be recalculated for values of K other than 5.  35   2.8.8 (input) (input)  Example  = the binary expansion of e up to 1,000,000 bits n = 1000000, B = 111111111 0 = 329; 1 = 164; 2 = 150; 3 = 111; 4 = 78; and 5 = 136 2(obs) = 8.965859 P-value = 0.110434 Since the P-value  0.01, accept the sequence as random.  (processing) (processing) (output) (conclusion)  2.9 2.9.1  Maurer's ""Universal Statistical"" Test Test Purpose  The focus of this test is the number of bits between matching patterns (a measure that is related to the length of a compressed sequence). The purpose of the test is to detect whether or not the sequence can be significantly compressed without loss of information. A significantly compressible sequence is considered to be non-random.  2.9.2  Function Call  Universal(L, Q, n), where L The length of each block. Note: the use of L as the block size is not consistent with the block size notation (M) used for the other tests. However, the use of L as the block size was specified in the original source of Maurer's test. The number of blocks in the initialization sequence. The length of the bit string.  Q n  Additional input used by the function, but supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n. Test Statistic and Reference Distribution  2.9.3  36   fn :  The sum of the log2 distances between matching L-bit templates, i.e., the sum of the number of digits in the distance between L-bit templates.  The reference distribution for the test statistic is the half-normal distribution (a one-sided variant of the normal distribution) as is also the case for the Frequency test in Section 2.1.  2.9.4 (1)  Test Description The n-bit sequence () is partitioned into two segments: an initialization segment consisting of Q L-bit non-overlapping blocks, and a test segment consisting of K L-bit non-overlapping blocks. Bits remaining at the end of the sequence that do not form a complete L-bit block are discarded.  The first Q blocks are used to initialize the test. The remaining K blocks are the test blocks (K = n/L - Q). For example, if  = 01011010011101010111, then n = 20. If L = 2 and Q = 4, then K = n/L - Q = 20/2 - 4 = 6 . The initialization segment is 01011010; the test segment is 011101010111. The L-bit blocks are shown in the following table: Block Type 1 Initialization 2 Segment 3 4 5 Test Segment 6 7 8 9 10 Contents 01 01 10 10 01 11 01 01 01 11  (2)  Using the initialization segment, a table is created for each possible L-bit value (i.e., the L-bit value is used as an index into the table). The block number of the last occurrence of each L-bit block is noted in the table (i.e., For i from 1 to Q, Tj= i, where j is the decimal representation of the contents of the ith L-bit block).  37   For the example in this section, the following table is created using the 4 initialization blocks.  Initialization  00 (saved in T0) 0  Possible L-bit Value 01 10 (saved in T1) (saved in T2) 2 4  11 (saved in T3) 0  (3)  Examine each of the K blocks in the test segment and determine the number of blocks since the last occurrence of the same L-bit block (i.e., i  Tj). Replace the value in the table with the location of the current block (i.e., Tj= i). Add the calculated distance between re-occurrences of the same L-bit block to an accumulating log2 sum of all the differences detected in the K blocks (i.e., sum = sum + log2(i  Tj)). For the example in this section, the table and the cumulative sum are developed as follows: For block 5 (the 1st test block): 5 is placed in the ""01"" row of the table (i.e., T1), and sum=log2(5-2) = 1.584962501. For block 6: 6 is placed in the ""11"" row of the table (i.e., T3), and sum = 1.584962501 + log2(6-0) = 1.584962501 + 2.584962501 = 4.169925002. For block 7: 7 is placed in the ""01"" row of the table (i.e., T1), and sum = 4.169925002 + log2(7-5) = 4.169925002 + 1 = 5.169925002. For block 8: 8 is placed in the ""01"" row of the table (i.e., T1), and sum = 5.169925002 + log2(8-7) = 5.169925002 + 0 = 5.169925002. For block 9: 9 is placed in the ""01"" row of the table (i.e., T1), and sum = 5.169925002 + log2(9-8) = 5.169925002 + 0 = 5.169925002. For block 10: 10 is placed in the ""11"" row of the table (i.e., T3), and sum = 5.169925002 + log2(10-6) = 5.169925002 + 2 = 7.169925002. The states of the table are: Iteration Block 4 5 6 7 8 9 10 00 0 0 0 0 0 0 0 Possible L-bit Value 01 10 11 2 4 0 5 4 0 5 4 6 7 4 6 8 4 6 9 4 6 9 4 10  38   (4)  Compute the test statistic: f n =  1 Q+ K  log 2 ( i - T j ) K i = Q +1  , where Tj is the table entry  corresponding to the decimal representation of the contents of the ith L-bit block. For the example in this section, f n = Compute P-value = erfc   7.169925002 = 1.1949875. 6 , where erfc is defined in Section  (5)   f n - expectedValue( L )    2    5.5.3.3, and expectedValue(L) and  are taken from a table of precomputed values2 (see the table below). Under an assumption of randomness, the sample mean, expectedValue(L), is the theoretical expected value of the computed statistic for the given L-bit length. The theoretical standard deviation is given by  = c where c = 0.7 - 0 .8  32  K -3 L + 4 +  L L  15 var iance( L ) K  ,  . L 12 13 14 15 16 expectedValue 11.168765 12.168070 13.167693 14.167488 15.167379 variance 3.401 3.410 3.416 3.419 3.421  L expectedValue 5.2177052 6 6.1962507 7 7.1836656 8 8.1764248 9 9.1723243 10 10.170032 11  variance 2.954 3.125 3.238 3.311 3.356 3.384   1.1949875 - 1.5374383   = 0.767189. For the example in this section, P-value = erfc    2 1.338   Note that the expected value and variance for L = 2 are not provided in the above table, since a block of length two is not recommended for testing. However, this value for L is easy to use in an example. The value for the expected value and variance for the case where L = 2, although not shown in the above table, were taken from the indicated reference3.  2.9.5  Decision Rule (at the 1 % Level)  If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2 3  From the ""Handbook of Applied Cryptography."" From the ""Handbook of Applied Cryptography.""  39   2.9.6  Conclusion and Interpretation of Test Results  Since the P-value obtained in step 5 of Section 2.9.4 is  0.01 (P-value = 0.767189), the conclusion is that the sequence is random. Theoretical expected values for  have been computed as shown in the table in step (5) of Section 2.9.4. If fn differs significantly from expectedValue(L), then the sequence is significantly compressible.  2.9.7  Input Size Recommendations which are divided into two segments 16. The first segment consists of Q = 10  2L. The second segment L . The values of L, Q and n should be L  This test requires a long sequence of bits (n  (Q + K)L) of L-bit blocks, where L should be chosen so that 6  L  initialization blocks, where Q should be chosen so that Q consists of K test blocks, where K = n/L - Q  1000  2 chosen as follows: n  387,840  904,960  2,068,480  4,654,080  1,342,400  22,753,280  49,643,520  107,560,960  231,669,760  496,435,200  1,059,061,760 L 6 7 8 9 10 11 12 13 14 15 16  Q = 10  2 640 1280 2560 5120 10240 20480 40960 81920 163840 327680 655360  2.9.8 (input) (input) (note)  Example  = A binary string constructed using G-SHA-14 n = 1048576, L = 7, Q = 1280 Note: 4 bits are discarded. c =0.591311,  = 0.002703, K = 148516, sum = 919924.038020  (processing)  4  Defined in FIPS 186-2.  40   (processing) (output) (conclusion)  fn = 6.194107, expectedValue = 6.196251,  = 3.125 P-value = 0.427733 Since P-value  0.01, accept the sequence as random.  2.10  Lempel-Ziv Compression Test  2.10.1 Test Purpose The focus of this test is the number of cumulatively distinct patterns (words) in the sequence. The purpose of the test is to determine how far the tested sequence can be compressed. The sequence is considered to be non-random if it can be significantly compressed. A random sequence will have a characteristic number of distinct patterns.  2.10.2 Function Call LempelZivCompression(n), where: n The length of the bit string.  Additional input used by the function, but supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n.  2.10.3 Test Statistic and Reference Distribution Wobs: The number of disjoint and cumulatively distinct words in the sequence. The reference distribution for the test statistic is the normal distribution.  2.10.4 Test Description (1) Parse the sequence into consecutive, disjoint and distinct words that will form a ""dictionary"" of words in the sequence. This is accomplished by creating substrings from consecutive bits of the sequence until a substring is created that has not been found previously in the sequence. The resulting substring is a new word in the dictionary. Let Wobs = the number of cumulatively distinct words. For example, if  = 010110010, then the examination proceeds as follows:  41   Bit Position Bit 0 1 1 2 0 3 1 4 1 5 0 6 0 7 1 8 0 9  New Word? Yes Yes No Yes No Yes No No Yes  The Word is: 0 (Bit 1) 1 (Bit 2) 01 (Bits 3-4) 10 (Bits (5-6)  010 (Bits 7-9)  There are five words in the ""dictionary"": 0, 1, 01, 10, 010. Hence, Wobs = 5. (2) Compute P-value =  erfc     -W  obs  2 2     , where  = 69586.25 and  = 70.448718 when  n = 106. For other values of n, the values of  and  would need to be calculated. Note that since no known theory is available to determine the exact values of  and , these values were computed (under an assumption of randomness) using SHA-1. The BlumBlum-Shub generator will give similar results for  and 2. Because the example in this section is much shorter than the recommended length, the values for  and 2 are not valid. Instead, suppose that the test was conducted on a sequence of a million bits, and the value Wobs = 69600 was obtained, then  69586.25 - 69600  P-value =  erfc   = 0.949310.    2  70.448718   2.10.5 Decision Rule (at the 1 % Level) If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2.10.6 Conclusion and Interpretation of Test Results Since the P-value obtained in step 2 of Section 2.10.4 is  0.01 (P-value = 0.949310), the conclusion is that the sequence is random. Note that for n = 106, if Wobs had fallen below 69,561, then the conclusion would have been that the sequence is significantly compressible and, therefore, not random.  42   2.10.7 Input Size Recommendations It is recommended that each sequence to be tested consist of a minimum of 1,000,000 bits (i.e., n  106).  2.10.8 Example (input) (input) (processing) (output) (conclusion)  = the first 1,000,000 digits in the binary expansion of e n = 1,000,000 Wobs = 69559 P-value = 0.000584 Since P-value < 0.01, reject the sequence as being random.  2.11  Linear Complexity Test  2.11.1 Test Purpose The focus of this test is the length of a linear feedback shiftregister (LFSR). The purpose of this test is to determine whether or not the sequence is complex enough to be considered random. Random sequences are characterized by longer LFSRs. An LFSR that is too short implies nonrandomness.  2.11.2 Function Call LinearComplexity(M, n), where: M n The length in bits of a block. The length of the bit string.  Additional input used by the function, but supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n. The number of degrees of freedom; K = 6 has been hard coded into the test.  K  43   2.11.3 Test Statistic and Reference Distribution 2(obs): A measure of how well the observed number of occurrences of fixed length LFSRs matches the expected number of occurrences under an assumption of randomness.  The reference distribution for the test statistic is the 2 distribution.  2.11.4 Test Description (1) (2) Partition the n-bit sequence into N independent blocks of M bits, where n = MN. Using the Berlekamp-Massey algorithm5, determine the linear complexity Li of each of the N blocks (i = 1,...,N). Li is the length of the shortest linear feedback shift register sequence that generates all bits in the block i. Within any Li-bit sequence, some combination of the bits, when added together modulo 2, produces the next bit in the sequence (bit Li + 1). For example, if M = 13 and the block to be tested is 1101011110001, then Li = 4, and the sequence is produced by adding the 1st and 2nd bits within a 4-bit subsequence to produce the next bit (the 5th bit). The examination proceeded as follows: Bit 1 Bit 2 Bit 3 Bit 4 1 1 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 0 Bit 5 0 1 1 1 1 0 0 0 1  The first 4 bits and the resulting 5 bit: Bits 2-5 and the resulting 6th bit: Bits 3-6 and the resulting 7th bit: . . . . . Bits 9-12 and the resulting 13th bit:  th  For this block, the trial feedback algorithm works. If this were not the case, other feedback algorithms would be attempted for the block (e.g., adding bits 1 and 3 to produce bit 5, or adding bits 1, 2 and 3 to produce bit 6, etc.). (3) Under an assumption of randomness, calculate the theoretical mean : = M +2 M 9 + (- 1)M +1 3 9 + - M 2 36 2  (  )(  )  .  5  Defined in The Handbook of Applied Cryptography; A. Menezes, P. Van Oorschot and S. Vanstone; CRC Press, 1997.  44   For the example in this section,  = (4)  For each substring, calculate a value of Ti, where Ti = (- 1)M  (Li -  ) + 2 9 . 13 For the example, Ti = (- 1) (4 - 6.777222 ) + 2 = 2.999444. 9  13 + 2 13 9 + (- 1)13+1 3 9 + - 13 2 36 2  (  )(  )  = 6.777222.  (5)  Record the Ti values in v0,..., v6 as follows: If: Ti  -2.5 -2.5 < Ti  -1.5 -1.5 < Ti  -0.5 -0.5 < Ti  0.5 0.5 < Ti  1.5 1.5 < Ti  2.5 Ti > 2.5 K  Increment Increment Increment Increment Increment Increment Increment  vo v1 v2 v3 v4 v5 v6  by by by by by by by  one one one one one one one  (6)  Compute  2 ( obs ) =   (v  i  i =0  - N  i )2 N i  , where 0 = 0.01047, 1 = 0.03125, 2 = 0.125, 3 =  0.5, 4 = 0.25, 5 = 0.0625, 6 = 0.02078 are the probabilities computed by the equations in Section 3.11. (7) Compute P-value = igamc  , 2   K  2 ( obs 2 )     .  2.11.5 Decision Rule (at the 1 % Level) If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2.11.6 Conclusion and Interpretation of Test Results Since the P-value obtained in step 7 of Section 2.10.4 is  0.01 (P-value = 0.949310), the conclusion is that the sequence is random. Note that if counts of Ti distribution as shown in the P-value were < 0.01, this would have indicated that the observed frequency stored in the I bins varied from the expected values; it is expected that the of the frequency of the Ti (in the I bins) should be proportional to the computed  step (6) of Section 2.11.5.  i  45   2.11.7 Input Size recommendations Choose n  106. The value of M must be in the range 500 M  5000, and N  200 for the  result to be valid (see Section 3.11 for a discussion). 2  2.11.8 Example (input) (input) (processing) (processing) (output) (conclusion)  = ""the first 1,000,000 binary digits in the expansion of e"" n = 1000000 = 106, M = 1000 v0 = 11; v1 = 31; v2 = 116; v3 = 501; v4 = 258; v5 = 57; v6 = 26 2(obs) = 2.700348 P-value = 0.845406 Since the P-value  0.01, accept the sequence as random.  2.12  Serial Test  2.12.1 Test Purpose The focus of this test is the frequency of all possible overlapping m-bit patterns across the entire sequence. The purpose of this test is to determine whether the number of occurrences of the 2m m-bit overlapping patterns is approximately the same as would be expected for a random sequence. Random sequences have uniformity; that is, every m-bit pattern has the same chance of appearing as every other m-bit pattern. Note that for m = 1, the Serial test is equivalent to the Frequency test of Section 2.1.  2.12.2 Function Call Serial(m,n), where: m n The length in bits of each block. The length in bits of the bit string.  Additional input used by the function, but supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n.  46   2.12.3 Test Statistics and Reference Distribution 2m(obs) and 22m(obs): A measure of how well the observed frequencies of m-bit patterns match the expected frequencies of the m-bit patterns. The reference distribution for the test statistic is the 2 distribution.  2.12.4 Test Description (1) Form an augmented sequence : Extend the sequence by appending the first m-1 bits to the end of the sequence for distinct values of n. For example, given n = 10 and  = 0011011101. If m = 3, then  = 001101110100. If m = 2, then  = 00110111010. If m = 1, then  = the original sequence 0011011101. (2) Determine the frequency of all possible overlapping m-bit blocks, all possible overlapping (m-1)-bit blocks and all possible overlapping (m-2)-bit blocks. Let vi1 ...im denote the frequency of the m-bit pattern i1...im; let vi1 ...im -1 denote the frequency of the (m-1)-bit pattern i1...i i1...i m-2. m-1;  and let v  i1 ...im  -2  denote the frequency of the (m-2)-bit pattern  For the example in this section, when m = 3, then (m-1) = 2, and (m-2) = 1. The frequency of all 3-bit blocks is: v000 = 0, v001 = 1, v010 = 1, v011 = 2, v100 = 1, v101 = 2, v110 = 2, v111 = 0. The frequency of all possible (m-1)-bit blocks is: v00 = 1, v01 = 3, v10 = 3, v11 = 3. The frequency of all (m-2)-bit blocks is: v0 = 4, v1 = 6. (3) Compute:  2 = m   2m  n i1 ...im = =  n 2m  v i1 ...im - =  v2 - n   n i1 ...im i1 ...im 2m   m -1  2  2 m -1 2 m-2  2 m -1    vi1 ...i n i1 ...im-1   n - m- 2  2 2 m -1  =  1 n i1 ...im   v -1  2 i1 ...i  m -1  -n -n  2m-2    vi1 ...i n i1 ...im-2   m-2  n - m- 2  2 2m-2  =  2 n i1 ...im   v -2  2 i1 ...i  m-2  For the example in this section, 23 ( 0 + 1 + 1 + 4 + 1 + 4 + 4 + 1 ) - 10 = 12.8 - 10 = 2.8 23 = 10 22 22 = (1 + 9 + 9 + 9) - 10 = 11.2 - 10 = 1.2 10 2 21 = (16 + 36) - 10 = 10.4 - 10 = 0.4 10  47   (4)  Compute:  2 =  2 - m m 2  2 m -1  , and 2 m -1  2 2  m =  m - 2  +    2 m-2  .  For the example in this section,  2 =  2 -  2 -1 = 32 - 22 = 2.8 - 1.2 = 1.6 m m m 2 2  2  m =  m - 2 2 m -1  +  2 m-2  = 32 - 222 + 12 = 2.8 - 2(1.2) + 0.4 = 0.8  (5)  Compute: P-value1 = igamc  2  P-value2 = igamc  2 m-2 , m  and     2 m -3 , 2  2  .   m   For the example in this section,  1.6  P-value1 = igamc  2,  = 0.9057  2  0.8  P-value2 = igamc 1,  = 0.8805.  2 2.12.5 Decision Rule (at the 1 % Level) If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2.12.6 Conclusion and Interpretation of Test Results Since the P-value obtained in step 5 of Section 2.12.4 is  0.01 (P-value1 = 0.808792 and Pvalue2 = 0.670320), the conclusion is that the sequence is random. Note that if 2 2 m  or   2  m  had been large, then non-uniformity of the m-bit blocks is implied.  2.12.7 Input Size Recommendations Choose m and n such that m < log2 n -2. 2.12.8 Example (input) (input) (processing)  = 1,000,000 bits from the binary expansion of e m = 2; n = 1000000 = 106 #0s = 499971; #1s = 500029 48   #00s = 250116; #01s = #10s = 249855; #11s = 250174 (processing) (processing) (output) (conclusion) 22 = 0.343128; 21 = 0.003364; 20 = 0.000000 22 = 0.339764; 222 = 0.336400 P-value1 = 0.843764; P-value2 = 0.561915 Since both P-value1 and P-value2 were  0.01, accept the sequences as random for both tests.  2.13  Approximate Entropy Test  2.13.1 Test Purpose As with the Serial test of Section 2.12, the focus of this test is the frequency of all possible overlapping m-bit patterns across the entire sequence. The purpose of the test is to compare the frequency of overlapping blocks of two consecutive/adjacent lengths (m and m+1) against the expected result for a random sequence.  2.13.2 Function Call ApproximateEntropy(m,n), where: m The length of each block  in this case, the first block length used in the test. m+1 is the second block length used. The length of the entire bit sequence.  n  Additional input used by the function, but supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n.  2.13.3 Test Statistic and Reference Distribution 2(obs): A measure of how well the observed value of ApEn(m) (see step 6 in Section 2.13.4) matches the expected value.  The reference distribution for the test statistic is the 2 distribution.  49   2.13.4 Test Description (1) Augment the n-bit sequence to create n overlapping m-bit sequences by appending m-1 bits from the beginning of the sequence to the end of the sequence. For example, if  = 0100110101 and m = 3, then n = 10. Append the 0 and 1 at the beginning of the sequence to the end of the sequence. The sequence to be tested becomes 010011010101. (Note: This is done for each value of m.) (2) A frequency count is made of the n overlapping blocks (e.g., if a block containing j to j+m-1 is examined at time j, then the block containing j+1 to j +m is examined at time j+1). Let the count of the possible m-bit ((m+1)-bit) values be represented as C im , where i is the m-bit value. For the example in this section, the overlapping m-bit blocks (where m = 3) become 010, 100, 001, 011, 110, 101, 010, 101, 010, and 101. The calculated counts for the 2m = 23 = 8 possible m-bit strings are: #000 = 0, #001 = 1, #010 = 3, #011 = 1, #100 = 1, #101 = 3, #110 = 1, #111 = 0 (3) Compute C im = #i n  for each value of i. 3 001  For example in this section, C3000 = 0, C C3101 = 0.3, C3110 = 0.1, C3111 = 0. (4) Compute  (m) 2 m -1 i =0  = 0.1, C3  010  = 0.3, C3  011  =0.1, C3  100  = 0.1,  =   i log  i , where i = C3j , and j=log2 i.  For the example in this section, (3) = 0(log 0) + 0.1(log 0.1) + 0.3(log 0.3) + 0.1(log 0.1) + 0.1(log 0.1) + 0.3(log 0.3) + 0.1(log 0.1) + 0(log 0) = -1.64341772. (5) Repeat steps 1-4, replacing m by m+1. Step 1: For the example in this section, m is now 4, the sequence to be tested becomes 0100110101010. Step 2: The overlapping blocks become 0100, 1001, 0011, 0110, 1101, 1010, 0101, 1010, 0101, 1010. The calculated values are: #0011 = 1, #0100 = 1, #0101 = 2, #0110 = 1, #1001 = 1, #1010 = 3, #1101 = 1, and all other patterns are zero. Step 3: C40011 = C40100 = C4 other values are zero. 0110  = C4  1001  = C4  1101  = 0.1, C4  0101  = 0.2, C4  1010  = 0.3, and all  Step 4: (4) = 0 + 0 + 0 + 0.1(log 0.01) + 0.1(log 0.01) + 0.2(log 0.02) + 0.1(log 0.01) + 0 + 0 + 0.1(log 0.01) + 0.3(log 0.03) + 0 + 0 + 0.1(log 0.01) + 0 + 0) = -1.83437197.  50   (6)  Compute the test statistic: 2 = 2n[log 2  ApEn(m)] , where ApEn(m) =  For the example in this section, ApEn(3) = -1.643418  (-1.834372) = 0.190954 2 = 210(0.693147-0.190954) = 0.502193  (m)  -  ( m +1)  .  (7)  Compute P-value = igamc(2m-1,  2 2  ).  2   0.502193  For the example in this section, P-value = igamc  2 2 ,   = 0.261961.  2.13.5 Decision Rule (at the 1 % Level) If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2.13.6 Conclusion and Interpretation of Test Results Since the P-value obtained in step 7 of Section 2.13.4 is  0.01 (P-value = 0.261961), the conclusion is that the sequence is random. Note that small values of ApEn(m) would imply strong regularity (see step 6 of Section 2.13.4). Large values would imply substantial fluctuation or irregularity.  2.13.7 Input Size Recommendations Choose m and n such that m < log2 n -2. 2.13.8 Example (input)  = 11001001000011111101101010100010001000010110100011 00001000110100110001001100011001100010100010111000 m = 2; n = 100 ApEn(m) = 0.665393 2(obs) = 5.550792 P-value = 0.235301  (input) (processing) (processing) (output)  51   (conclusion)  Since P-value  0.01, accept the sequence as random.  2.14  Cumulative Sums (Cusum) Test  2.14.1 Test Purpose The focus of this test is the maximal excursion (from zero) of the random walk defined by the cumulative sum of adjusted (-1, +1) digits in the sequence. The purpose of the test is to determine whether the cumulative sum of the partial sequences occurring in the tested sequence is too large or too small relative to the expected behavior of that cumulative sum for random sequences. This cumulative sum may be considered as a random walk. For a random sequence, the excursions of the random walk should be near zero. For certain types of non-random sequences, the excursions of this random walk from zero will be large. 2.14.2 Function Call CumulativeSums(mode,n), where: n The length of the bit string.  Additional input for the function, but supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n.  mode A switch for applying the test either forward through the input sequence (mode = 0) or backward through the sequence (mode = 1). 2.14.3 Test Statistic and Reference Distribution z: The largest excursion from the origin of the cumulative sums in the corresponding (-1, +1) sequence.  The reference distribution for the test statistic is the normal distribution. 2.14.4 Test Description (1) Form a normalized sequence: The zeros and ones of the input sequence () are converted to values Xi of 1 and +1 using Xi = 2i  1. For example, if  = 1011010111, then X = 1, (-1), 1, 1, (-1), 1, (-1), 1, 1, 1. (2) Compute partial sums Si of successively larger subsequences, each starting with X1 (if mode = 0) or Xn (if mode = 1).  52   Mode = 0 (forward) S1 S2 S3 . . Sk . . Sn = X1 = X1 + X2 = X1 + X2 + X3 = X1 + X2 + X3 + ... + Xk = X1 + X2 + X3 + ... + Xk + ...+ Xn S1 S2 S3 . . Sk . . Sn  Mode = 1 (backward) = Xn = Xn + Xn-1 = Xn + Xn-1 + Xn-2 = Xn + Xn-1 + Xn-2 + ... + Xn-k+1 = Xn + Xn-1 + Xn-2 + ... + Xk-1 + ...+ X1  That is, Sk = S  k-1  + Xk for mode 0, and Sk = S  k-1  + Xn-k+1 for mode 1.  For the example in this section, when mode = 0 and X = 1, (-1), 1, 1, (-1), 1, (-1), 1, 1, 1, then: S S S S S S S S S S (3) =1 2 = 1 + (-1) = 0 3 = 1 + (-1) + 1 = 1 4 = 1 + (-1) + 1 + 1 = 2 5 = 1 + (-1) + 1 + 1 + (-1) = 1 6 = 1 + (-1) + 1 + 1 + (-1) + 1 = 2 7 = 1 + (-1) + 1 + 1 + (-1) + 1 + (-1) = 1 8 = 1 + (-1) + 1 + 1 + (-1) + 1 + (-1) + 1 = 2 9 = 1 + (-1) + 1 + 1 + (-1) + 1 + (-1) + 1 + 1 = 3 10 = 1 + (-1) + 1 + 1 + (-1) + 1 + (-1) + 1 + 1 + 1 = 4 1 kn  Compute the test statistic z =max1 values of the partial sums Sk.  |Sk|, where max1  kn  |Sk| is the largest of the absolute  For the example in this section, the largest value of Sk is 4, so z = 4. n   -1  4 z   -n  k = +1  4 z   (4)  Compute P-value = 1 -         (4k + 1)   n    (4k - 1)z z  -    n          +   n   -1  4 z   -n  k = -3  4 z          (4k + 3)   n   z  (4k + 1)z  -    n         where  is the Standard Normal Cumulative Probability Distribution Function as defined in Section 5.5.3.3.  53   For the example in this section, P-value = 0.4116588.  2.14.5 Decision Rule (at the 1 % Level) If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2.14.6 Conclusion and Interpretation of Test Results Since the P-value obtained in step 4 of Section 2.14.4 is  0.01 (P-value = 0.411658), the conclusion is that the sequence is random. Note that when mode = 0, large values of this statistic indicate that there are either ""too many ones"" or ""too many zeros"" at the early stages of the sequence; when mode = 1, large values of this statistic indicate that there are either ""too many ones"" or ""too many zeros"" at the late stages. Small values of the statistic would indicate that ones and zeros are intermixed too evenly.  2.14.7 Input Size Recommendations It is recommended that each sequence to be tested consist of a minimum of 100 bits (i.e., n  100).  2.14.8 Example (input)  = 11001001000011111101101010100010001000010110100011 00001000110100110001001100011001100010100010111000 n = 100 mode = 0 (forward) || mode = 1 (reverse) z = 1.6 (forward) || z = 1.9 (reverse) P-value = 0.219194 (forward) || P-value = 0.114866 (reverse) Since P-value > 0.01, accept the sequence as random.  (input) (input) (processing) (output) (conclusion)  2.15  Random Excursions Test  2.15.1 Test Purpose  54   The focus of this test is the number of cycles having exactly K visits in a cumulative sum random walk. The cumulative sum random walk is derived from partial sums after the (0,1) sequence is transferred to the appropriate (-1, +1) sequence. A cycle of a random walk consists of a sequence of steps of unit length taken at random that begin at and return to the origin. The purpose of this test is to determine if the number of visits to a particular state within a cycle deviates from what one would expect for a random sequence. This test is actually a series of eight tests (and conclusions), one test and conclusion for each of the states: -4, -3, -2, -1 and +1, +2, +3, +4.  2.15.2 Function Call RandomExcursions(n), where: n The length of the bit string.  Additional input used by the function, but supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n.  2.15.3 Test Statistic and Reference Distribution 2(obs): For a given state x, a measure of how well the observed number of state visits within a cycle match the expected number of state visits within a cycle, under an assumption of randomness.  The reference distribution for the test statistic is the 2 distribution.  2.15.4 Test Description (1) Form a normalized (-1, +1) sequence X: The zeros and ones of the input sequence () are changed to values of 1 and +1 via Xi = 2i  1. For example, if  = 0110110101, then n = 10 and X = -1, 1, 1, -1, 1, 1, -1, 1, -1, 1. (2) Compute the partial sums Si of successively larger subsequences, each starting with X1. Form the set S = {Si}. S1 = X1 S2 = X1 + X2 S3 = X1 + X2 + X3 . .  55   Sk = X1 + X2 + X3 + ... + Xk . . Sn = X1 + X2 + X3 + ... + Xk + ...+ Xn For the example in this section, S1 = -1 S6 = 2 S2 = 0 S7 = 1 S3 = 1 S8 = 2 S4 = 0 S9 = 1 S5 = 1 S10 = 2 The set S = {-1, 0, 1, 0, 1, 2, 1, 2, 1, 2}. (3) Form a new sequence S' by attaching zeros before and after the set S. That is, S' = 0, s1, s2, ... , sn, 0. For the example in this section, S' = 0, -1, 0, 1, 0, 1, 2, 1, 2, 1, 2, 0. The resulting random walk is shown below.  Example Random Walk (S') (4) Let J = the total number of zero crossings in S', where a zero crossing is a value of zero in S ' that occurs after the starting zero. J is also the number of cycles in S, where a cycle of S is a subsequence of Sconsisting of an occurrence of zero, followed by nozero values, and ending with another zero. The ending zero in one cycle may be the beginning zero in another cycle. The number of cycles in S ' is the number of zero crossings. If J < 500, discontinue the test6. For the example in this section, if S' = {0, 1, 0 1, 0, 1, 2, 1, 2, 1, 2, 0}, then J = 3 (there are zeros in positions 3, 5 and 12 of S'). The zero crossings are easily observed in the above plot. Since J = 3, there are 3 cycles, consisting of {0, -1, 0}, {0, 1, 0} and {0, 1, 2, 1, 2, 1, 2, 0}.  J times the minimum of the probabilities found in the table in Section 3.15 must be  5 in order to satisfy the empirical rule for Chi-square computations. 6  56   (5)  For each cycle and for each non-zero state value x having values 4  x  -1 and 1  x  4, compute the frequency of each x within each cycle. For the example in this section, in step 3, the first cycle has one occurrence of 1, the second cycle has one occurrence of 1, and the third cycle has three occurrences each of 1 and 2. This can be visualized using the following table. Cycles Cycle 2 (0, 1, 0) 0 0 0 0 1 0 0 0  State x -4 -3 -2 -1 1 2 3 4  Cycle 1 (0, -1, 0) 0 0 0 1 0 0 0 0  Cycle 3 (0,1,2,1,2,1,2,0) 0 0 0 0 3 3 0 0  (6)  For each of the eight states of x, compute k(x) = the total number of cycles in which state x occurs exactly k times among all cycles, for k = 0, 1, ..., 5 (for k = 5, all frequencies  5 are stored in 5(x)). Note that   k ( x ) = J . k =0 5  For the example in this section,  0(-1) = 2 (the 1(-1) = 1 (the 2(-1) = 3(-1) times 0 1 3 2 (1) (1) (1) (1) = = = = 1 state occurs exactly 0 times in two cycles), 1 state occurs only once in 1 cycle), and = 4(-1) = 5(-1) = 0 (the 1 state occurs exactly {2, 3, 4, 5} in 0 cycles). occurs exactly 0 times in 1 cycle), occurs only once in 1 cycle), occurs exactly three times in 1 cycle), and = 0 (the 1 state occurs exactly {2, 4, 5} times in 0    1 (the 1 state 1 (the 1 state 1 (the 1 state 4(1) = 5(1) cycles).    0(2) = 2 (the 2 state occurs exactly 0 times in 2 cycles), 3(2) = 1 (the 2 state occurs exactly three times in 1 cycle), and 1(2) = 2(2) = 4(2) = 5(2) = 0 (the 1 state occurs exactly {1, 2, 4, 5} times in 0 cycles). 0(-4) = 3 (the -4 state occurs exactly 0 times in 3 cycles), and    57   1(-4) = 2(-4) = 3(-4) = 4(-4) = 5(-4) = 0 (the -4 state occurs exactly {1, 2, 3, 4, 5} times in 0 cycles). And so on.... This can be shown using the following table: Number of Cycles 2 3 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0  State x -4 -3 -2 -1 1 2 3 4 (7)  0 3 3 3 2 1 2 3 3  1 0 0 0 1 1 0 0 0  4 0 0 0 0 0 0 0 0  5 0 0 0 0 0 0 0 0  For each of the eight states of x, compute the test statistic 5 (  ( x ) - J ( x )) 2 k k  2 ( obs ) =  J k ( x ) k =0  , where k(x) is the probability that the state x occurs k  times in a random distribution (see Section 3.15 for a table of k values). The values for k(x) and their method of calculation are provided in Section 3.15. Note that eight 2 statistics will be produced (i.e., for x = -4, -3, -2, -1, 1, 2, 3, 4). For example in this section, when x = 1, 2 = (1 - 3(0.5)) 2 (1 - 3(0.25)) 2 (0 - 3(0.125)) 2 (1 - 3(0.0625)) 2 (0 - 3(0.0312)) 2 (0 - 3(0.0312)) + + + + + 3(0.5) 3(0.25) 3(0.125) 3(0.0625) 3(0.0312) 3(0.0312) 2  = 4.333033 (8) For each state of x, compute P-value = igamc(5/2,  2 ( obs ) 2 ) . Eight P-values will be produced.  5 4.333033  For the example when x = 1, P-value = igamc  ,  = 0.502529. 2 2   2.15.5 Decision Rule (at the 1 % Level) If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  58   2.15.6 Conclusion and Interpretation of Test Results Since the P-value obtained in step 8 of Section 2.15.4 is  0.01 (P-value = 0.502529), the conclusion is that the sequence is random. Note that if 2(obs) were too large, then the sequence would have displayed a deviation from the theoretical distribution for a given state across all cycles.  2.15.7 Input Size Recommendations It is recommended that each sequence to be tested consist of a minimum of 1,000,000 bits (i.e., n  106).  2.15.8 Example (input) (input) (processing)  = ""the binary expansion of e up to 1,000,000 bits"" n = 1000000 = 106 J = 1490 State=x -4 -3 -2 -1 +1 +2 +3 +4 (conclusion) 2 3.835698 7.318707 7.861927 15.692617 2.485906 5.429381 2.404171 2.393928 P-value 0.573306 0.197996 0.164011 0.007779 0.778616 0.365752 0.790853 0.792378 Conclusion Random Random Random Non-random Random Random Random Random  For seven of the states of x, the P-value is  0.01, and the conclusion would be that the sequence was random. However, for one state of x (x = -1), the P-value is < 0.01, so the conclusion would be that the sequence is non-random. When contradictions arise, further sequences should be examined to determine whether or not this behavior is typical of the generator.  2.16  Random Excursions Variant Test  2.16.1 Test Purpose  59   The focus of this test is the total number of times that a particular state is visited (i.e., occurs) in a cumulative sum random walk. The purpose of this test is to detect deviations from the expected number of visits to various states in the random walk. This test is actually a series of eighteen tests (and conclusions), one test and conclusion for each of the states: -9, -8, ..., -1 and +1, +2, ..., +9.  2.16.2 Function Call RandomExcursionsVariant(n), where: n The length of the bit string; available as a parameter during the function call.  Additional input used by the function, but supplied by the testing code:  The sequence of bits as generated by the RNG or PRNG being tested; this exists as a global structure at the time of the function call;  = 1, 2, ... , n.  2.16.3 Test Statistic and Reference Distribution : For a given state x, the total number of times that the given state is visited during the entire random walk as determined in step 4 of Section 2.15.4.  The reference distribution for the test statistic is the half normal (for large n). (Note: If  is distributed as normal, then || is distributed as half normal.) If the sequence is random, then the test statistic will be about 0. If there are too many ones or too many zeroes, then the test statistic will be large.  2.16.4 Test Description (1) Form the normalized (-1, +1) sequence X in which the zeros and ones of the input sequence () are converted to values of 1 and +1 via X = X1, X2, ... , Xn, where Xi = 2  1. For example, if  = 0110110101, then n = 10 and X = -1, 1, 1, -1, 1, 1, -1, 1, -1, 1. (2) Compute partial sums Si of successively larger subsequences, each starting with x1. Form the set S = {Si}. S1 = X1 S2 = X1 + X2 S3 = X1 + X2 + X3 .  i  60   . Sk = X1 + X2 + X3 + . . . + Xk . . Sn = X1 + X2 + X3 + . . . + Xk + . . .+ Xn For the example in this section, S1 = -1 S6 = 2 S2 = 0 S7 = 1 S3 = 1 S8 = 2 S4 = 0 S9 = 1 S5 = 1 S10 = 2 The set S = {-1, 0, 1, 0, 1, 2, 1, 2, 1, 2}. (3) Form a new sequence S' by attaching zeros before and after the set S. That is, S' = 0, s1, s2, ... , sn, 0. For the example, S' = 0, -1, 0, 1, 0, 1, 2, 1, 2, 1, 2, 0. The resulting random walk is shown below.  Example Random Walk (S') (4) For each of the eighteen non-zero states of x, compute (x) = the total number of times that state x occurred across all J cycles. For the example in this section, (-1) = 1, (1) = 4, (2) = 3, and all other (x) = 0. (5) For each (x), compute P-value = erfc          2 J (4 x - 2)   ( x) - J  . Eighteen P-values are computed.  See Section 5.5.3.3 for the definition of erfc.   4-3  = 0.683091. For the example in this section, when x = 1, P-value = erfc   2  3(4 1 - 2)     61   2.16.5 Decision Rule (at the 1 % Level) If the computed P-value is < 0.01, then conclude that the sequence is non-random. Otherwise, conclude that the sequence is random.  2.16.6 Conclusion and Interpretation of Test Results Since the P-value obtained in step 7 of Section 2.16.4 is  0.01 for the state x = 1 (P-value = 0.683091), the conclusion is that the sequence is random.  2.16.7 Input Size Recommendations It is recommended that each sequence to be tested consist of a minimum of 1,000,000 bits (i.e., n  106).  2.16.8 Example (input) (input)  = ""the binary expansion of e up to 1,000,000 bits"" n = 1000000 = 106  (processing) J = 1490 State(x) -9 -8 -7 -6 -5 -4 -3 -2 -1 +1 +2 +3 +4 +5 +6 +7 +8 Counts 1450 1435 1380 1366 1412 1475 1480 1468 1502 1409 1369 1396 1479 1599 1628 1619 1620 P-value 0.858946 0.794755 0.576249 0.493417 0.633873 0.917283 0.934708 0.816012 0.826009 0.137861 0.200642 0.441254 0.939291 0.505683 0.445935 0.512207 0.538635 62 Conclusion Random Random Random Random Random Random Random Random Random Random Random Random Random Random Random Random Random   +9 (conclusion)  1610  0.593930  Random  Since the P-value  0.01 for each of the eighteen states of x, accept the sequence as random.  63   3  TECHNICAL DESCRIPTION OF TESTS  This section contains the mathematical backgound for the tests in the NIST test suite. Each subsection corresponds to the appropriate subsection in Section 2. The relevant references for each subsection are provided at the end of that subsection.  3.1  Frequency (Monobit) Test  The most basic test is that of the null hypothesis: in a sequence of independent identically distributed Bernoulli random variables (X's or 's, where X = 2 -1, and so Sn = X1 + ... + Xn = 2( 1 + ... + n ) - n), the probability of ones is 1 . By the classic De Moivre-Laplace theorem, for a sufficiently large 2  number of trials, the distribution of the binomial sum, normalized by n, is closely approximated by a standard normal distribution. This test makes use of that approximation to assess the closeness of the fraction of 1's to 1 . 2 All subsequent tests are conditioned on having passed this first basic test. The test is derived from the well-known limit Central Limit Theorem for the random walk, Sn = X1 +  + Xn . According to the Central Limit Theorem, n  lim P  Sn 1   z =  (z )   n 2  z -  e-  u2 /2  du.  (1)  This classical result serves as the basis of the simplest test for randomness. It implies that, for positive z , P According to the test based served value |s(obs)| = |X1 sponding P - value, which erfc is the (complementary) |Sn |   z = 2(z ) - 1. n   on the statistic s = |Sn |/ n, evaluate the ob + ... + Xn |/ n, and then calculate the corre is 2[1 - (|s(obs)|)] = erfc(|s(obs)|/ 2). Here, error function  z  2 erf c(z ) =    e-  u2  du.  64   References for Test [1] Kai Lai Chung, Elementary Probability Theory with Stochastic Processes. New York: Springer-Verlag, 1979 (especially pp. 210-217). [2] Jim Pitman, Probability. New York: Springer-Verlag, 1993 (especially pp. 93-108).  3.2  Frequency Test within a Blo ck  The test seeks to detect lo calized deviations from the ideal 50 % frequency of 1's by decomposing the test sequence into a number of nonoverlapping subsequences and applying a chi-square test for a homogeneous match of empirical frequencies to the ideal 1 . Small P - values indicate large deviations from 2 the equal proportion of ones and zeros in at least one of the substrings. The string of 0's and 1's (or equivalent -1's and 1's) is partitioned into a number of disjoint substrings. For each substring, the proportion of ones is computed. A chi-square statistic compares these substring proportions to the ideal 1 . 2 The statistic is referred to a chi-squared distribution with the degrees of freedom equal to the number of substrings. The parameters of this test are inal string is partitioned into N these substrings, the probability frequency of 1's, i ,i = 1,... ,N M and N , so that n = MN , i.e., the origsubstrings, each of length M . For each of of ones is estimated by the observed relative . The sum N 1  2 (obs) = 4M  i -  1 2  2  under the randomness hypothesis has the 2 -distribution with N degrees of freedom. The reported P - value is  -u/2 N/2-1 u 2 (obs) e (N/2) 2N/2  du  =   -u N/2-1 u 2 (obs)/2 e  du  (N/2)  = igamc .  N 2 (obs) , , 2 2  65   References for Test [1] Nick Maclaren, ""Cryptographic Pseudo-random Numbers in Simulation,"" Cambridge Security Workshop on Fast Software Encryption. Dec. 1993. Cambridge, U.K.: R. Anderson, pp. 185-190. [2] Donald E. Knuth, The Art of Computer Programming. Vol 2: Seminumerical Algorithms. 3rd ed. Reading, Mass: Addison-Wesley, 1998 (especially pp. 42-47). [3] Milton Abramowitz and Irene Stegun, Handbook of Mathematical Functions: NBS Applied Mathematics Series 55. Washington, D.C.: U.S. Government Printing Office, 1967.  3.3  Runs Test  This variant of a classic nonparametric test looks at ""runs"" defined as substrings of consecutive 1's and consecutive 0's, and considers whether the oscillation among such homogeneous substrings is too fast or too slow. The specific test used here is based on the distribution of the total number of runs, Vn . For the fixed proportion  = j j /n (which by the Frequency test 2 of Section 3.1 must have been established to be close to 0.5: | - 1 |  n ). 2 n  lim P  Vn - 2n (1 -  )   z = (z ). 2 n (1 -  )  (2)  To evaluate Vn , define for k = 1,... ,n - 1, r(k ) = 0 if k = k+1 and r(k ) = 1 n-1 if k = k+1 . Then Vn = k=1 r(k ) + 1. The P - value reported is erf c |Vn (obs) - 2n (1 -  )|  . 2 2n (1 -  )  Large values of Vn (obs) indicate oscillation in the string of 's which is too fast; small values indicate oscillation which is too slow.  66   References for Test [1] Jean D. Gibbons, Nonparametric Statistical Inference, 2nd ed. New York: Marcel Dekker, 1985 (especially pp. 50-58). [2] Anant P. Godbole and Stavros G. Papastavridis, (ed), Runs and patterns in probability: Selected papers. Dordrecht: Kluwer Academic, 1994.  3.4  Test for the Longest Run of Ones in a Block  The length of the longest consecutive subsequence (run) of ones is another characteristic that can be used for testing randomness. A string of length n, such that n = MN , must be partitioned into N substrings, each of length M . For the test based on the length of the longest run of ones j within the j -th substring of size M , K + 1 classes are chosen (depending on M ). For each of these substrings, one evaluates the frequencies 0 ,1 ,... ,K (0 + 1 + ... + K = N , i.e., the computed values of the longest run of ones within each of these substrings belonging to any of the K + 1 chosen classes). If there are r ones and M - r zeroes in the m-bit block, then the conditional probability that the longest string of ones  in this block is less than or equal to m has (see David and Barton the following form with U = min M - r +1, mr +1 (1962)): P (  m|r) = 1 M r U  (-1)  j  j =0  M - r +1 j  M - j (m +1) M -r  ,  so that P (  m) =  M r=0  M r  P (  m|r)  1 . 2M  (3)  The theoretical probabilities 0 ,1 ,... ,K of these classes are determined from (3). The empirical frequencies i ,i = 0,... ,K are conjoined by the 2 -statistic 2 = K 0  (i - Ni )2 . Ni 67   which, under the randomness hypothesis, has an approximate 2 -distribution with K degrees of freedom. The reported P - value is  -u/2 K/2-1 u 2 (obs) e (K/2) 2K/2  du  = igamc  K 2 (obs) , , 2 2  with P (a, x) denoting the incomplete gamma function as expressed in Section 3.2. The following table contains selected values of K and M with the corresponding probabilities obtained from (3). Cases K = 3,M = 8; K = 5,M = 128; and K = 6,M = 10000 are currently embedded in the test suite code. K = 3,M = 8 classes probabilities {  1 } { = 2 } { = 3 } {  4 } 0 = 0.2148 1 = 0.3672 2 = 0.2305 3 = 0.1875 K = 5,M = 128 classes probabilities {  4 } { = 5 } { = 6 } { = 7 } 0 = 0.1174 1 = 0.2430 2 = 0.2493 3 = 0.1752 { = 8 } {  9 } 4 = 0.1027 5 = 0.1124 K = 5,M = 512 classes probabilities {  6 } { = 7 } { = 8 } { = 9 } 0 = 0.1170 1 = 0.2460 2 = 0.2523 3 = 0.1755 { = 1 0} {  11} 4 = 0.1015 5 = 0.1077 K = 5,M = 1000 classes probabilities {  7 } { = 8 } { = 9 } { = 1 0} 0 = 0.1307 1 = 0.2437 2 = 0.2452 3 = 0.1714 68   { = 1 1} {  12} 4 = 0.1002 5 = 0.1088 K = 6,M = 10000 classes {  10} { = 1 1 } { = 1 2 } { = 1 3 } probabilities 0 = 0.0882 1 = 0.2092 2 = 0.2483 3 = 0.1933 { = 1 4} { = 1 5} {  16} 4 = 0.1208 5 = 0.0675 6 = 0.0727 Large values of 2 indicate that the sequence has clusters of ones; the generation of ""random"" sequences by humans tends to lead to small values of n (see Revesz, 1990, p. 55). References for Test [1] F. N. David and D. E. Barton, Combinatorial Chance. New York: Hafner Publishing Co., 1962, p. 230. [2] Anant P. Godbole and Stavros G. Papastavridis (ed), Runs and Patterns in Probability: Selected Papers. Dordrecht: Kluwer Academic, 1994. [3] Pal Revesz, Random Walk in Random and Non-Random Environments. Singapore: World Scientific, 1990.  3.5  Binary Matrix Rank Test  Another approach to testing for randomness is to check for linear dependence among fixed-length substrings of the original sequence: construct matrices of successive zeroes and ones from the sequence, and check for linear dependence among the rows or columns of the constructed matrices. The deviation of the rank - or rank deficiency - of the matrices from a theoretically expected value gives the statistic of interest. This test is a specification of one of the tests coming from the DIEHARD 69   [1] battery of tests. It is based on the result of Kovalenko (1972) and also formulated in Marsaglia and Tsay (1985). The result states that the rank R of the M  Q random binary matrix takes values r = 0, 1, 2,... ,m where m  min(M, Q) with probabilities pr = 2 r(Q+M -r)-MQ r -1 i=0  (1 - 2  i-Q  )(1 - 2 1 - 2 i-r  i-M  )  .  The probability values are fixed in the test suite code for M = Q = 32. The number M is then a parameter of this test, so that ideally n = M 2 N , where N is the new ""sample size."" In practice, values for M and N are chosen so that the discarded part of the string, n - NM 2 , is fairly small. The rationale for this choice is that p M   p   j =1  1-  1 = 0.2888.., 2j   2pM  0.5776.., 4 pM p M -2   0.1284.. 9 and all other probabilities are very small ( 0.005) when M  10. M -1  For the N square matrices obtained, their ranks R , = 1,... ,N are evaluated, and the frequencies FM ,FM -1 and N - FM - FM -1 of the values M , M - 1 and of ranks not exceeding M - 2 are determined: F F M  = # {R = M },  M -1  = # {R = M - 1 }. - 0.5776N ) 0.5776N 2  To apply the 2 -test, use the classical statistic 2 = (F M  - 0.2888N )2 (F + 0.2888N M  M -1  - FM -1 - 0.1336N )2 , 0.13336N which, under the null (randomness) hypothesis, has an approximate 2 distribution with 2 degrees of freedom. The reported P -value is exp{-2 (obs)/2}. + (N - F 70   Interpretation of this test: large values of 2 (obs) indicate that the deviation of the rank distribution from that corresponding to a random sequence is significant. For example, pseudo random matrices produced by a shiftregister generator formed by less than M successive vectors systematically have rank R  M , while for truly random data, the proportion of such occurrences should be only about 0.29. References for Test [1] George Marsaglia, DIEHARD: a battery of tests of randomness. http://stat.fsu.edu/~geo/diehard.html. [2] I. N. Kovalenko (1972), ""Distribution of the linear rank of a random matrix,"" Theory of Probability and its Applications. 17, pp. 342-346. [3] G. Marsaglia and L. H. Tsay (1985), ""Matrices and the structure of random number sequences,"" Linear Algebra and its Applications. Vol. 67, pp. 147-156.  3.6  Discrete Fourier Transform (Sp ectral) Test  The test described here is based on the discrete Fourier transform. It is a member of a class of procedures known as spectral methods. The Fourier test detects periodic features in the bit series that would indicate a deviation from the assumption of randomness. Let xk be the k -1 and +1. Let th  bit, where k = 1,...,n. Assume that the bits are coded n  fj =  k=1  xk exp (2i (k - 1)j/n),  where exp (2ikj /n) = cos (2kj /n)+ i sin (2kj /n), j = 0,... ,n - 1, and  i  -1. Because of the symmetry of the real to complex-value transform, only the values from 0 to (n/2 - 1) are considered. Let modj be the modulus of the complex number fj . Under the assumption of the randomness of the series xi , a confidence interval can be placed on the values of modj . More  specifically, 95 percent of the values of modj should be less than h = 3n. 71   A P - value based on this threshold comes from the binomial distribution. Let N1 be the number of peaks less than h. Only the first n/2 peaks are considered. Let N0 = .95N/2 and d = (N1 - N0 )/ n(.95)(.05)/2. The P - value is |d| 2(1 - (|d|)) = erfc  2 where (x) is the cumulative probability function of the standard normal distribution. Other P - values based on the series fj or modj that are sensitive to departures from randomness are possible. However, the primary value of the transform comes from a plot of the series modj . In the accompanying figure, the top plot shows the series of modj for 4096 bits generated from a satisfactory generator. The line through the plot is the 95 % confidence boundary. The P - value for this series is 0.8077. The bottom plot shows a corresponding plot for a generator that produces bits that are statistically dependent in a periodic pattern. In the bottom plot, significantly greater than 5 % of the magnitudes are beyond the confidence boundary. In addition, there is a clear structure in the magnitudes that is not present in the top plot. The P - value for this series is 0.0001. References for Test [1] R. N. Bracewell, The Fourier Transform and Its Applications. New York: McGraw-Hill, 1986.  72    3.7  Non-overlapping Template Matching Test  This test rejects sequences exhibiting too many or too few occurrences of a given aperiodic pattern. Let B = ( 0 ,  , 0 ) be a given word (template or pattern, 1 m sequence of zeros and ones) of length m. This pattern is to be it were a parameter of the test. We consider a test based on fixed length m. A table of selected aperiodic words out of such m = 2,... , 8 is provided at the end of this section. The set of periods of B B = {j, 1  j  m - 1, 0 j +k  i.e., a fixed chosen as if patterns for patterns for  =  0 k  ,k = 1,... ,m - j },  plays an important role. For example, when B corresponds to a run of m ones, B = {1,... ,m - 1}. For the B above, B = , and B is an aperiodic pattern (i.e., it cannot be written as CC . . . CC for a pattern C shorter than B with C denoting a prefix of C ). In this situation, occurrences of B in the string are non-overlapping. In general, let W = W (m, M ) be the number of occurrences of the given pattern B in the string. Note that the statistic W is defined also for patterns B with B = . The best way to calculate W is as the sum, n-m+1  W= i=1  I(  i+k -1  =  0 k  ,k = 1,  ,m).  The random variables I ( i+k-1 = 0 ,k = 1,  ,m) are m-dependent, so that k the Central Limit Theorem holds for W . The mean and variance of the approximating normal distribution have the following form, = 2 = n n - m +1 , 2m 1 2m - 1 - . m 2 22m  For the test suite code, M and N are chosen so that n = MN and N = 8. 74   Partition the original string into N blocks of length M . Let Wj = Wj (m, M ) be the number of occurrences of the pattern B in the block j ,for j = 1,... ,N . Let  = EWj = (M - m + 1)2-m. Then, for large M , Wj has a normal distribution with mean  and variance  2 , so that the statistic 2 (obs) = N j =1  (Wj - ) 2  2  (4)  has an approximate 2 -distribution with N degrees of freedom. Report the 2 obs P - value as 1 - P N ,  (2 ) . 2 The test can be interpreted as rejecting sequences exhibiting irregular occurrences of a given non-periodic pattern. References for Test [1] A. D. Barbour, L. Holst, and S. Janson, Poisson Approximation (1992). Oxford: Clarendon Press (especially Section 8.4 and Section 10.4). Ap erio dic Templates for small values of 2  m  5 m=2 01 10 m 0 0 1 1 = 0 1 0 1 3 1 1 0 0 m 0 0 1 0 1 1 =4 0 1 1 0 0 1 m 0 0 0 1 0 1 1 1 0 1 0 1 = 0 0 1 0 1 1 1 0 1 0 0 1 5 0 1 0 1 1 1 0 1 0 0 0 1  0 0 0 1 1 1  1 1 1 0 0 0  0 0 0 0 0 0 1 1 1 1 1 1  1 1 1 1 1 1 0 0 0 0 0 0  75   Ap erio dic Templates for small values of 6  m  8 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 m=6 0 0 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 m=7 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 0 0 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 m=8 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  76   3.8  Overlapping Template Matching Test  This test rejects sequences which show too many or too few occurrences of m-runs of ones, but can be easily modified to detect irregular occurrences of any periodic pattern B . To implement this test, parameters M and N are determined so that n = MN , i.e., the original string is partitioned into N blocks, each of length M . ~ ~ Let Wj = Wj (m, n) be the number of (possibly overlapping) runs of ones ~ of length m in the j th block. The asymptotic distribution of Wj is the compound Poisson distribution (the so-called Polya-Aeppli law, see Chrysaphi` nou and Papastavridis, 1988): (et - 1) ~ E exp{tWj }  exp 2 - et when (M - m + 1)2 -m  (5)    > 0 (t is a real variable).  The corresponding probabilities can be expressed in terms of the confluent hypergeometric function  =1 F1 . If U denotes a random variable with the compound Poisson asymptotic distribution, then for u  1 with  = /2 e- P (U = u) = u 2 For example, u =1  u-1 -1    e-2 (u +1, 2, ). = ! 2u  P (U = 0) = e- ,  P (U = 1) = e- , 2 - e P (U = 2) = [ +2] , 8 e-  2 P (U = 3) = +  +1 , 8 6 P (U = 4) = e- 16    3  2 3 + + +1 . 24 2 2  77   The complement to the distribution function of this random variable has the form   L(u) = P (U > u) = e- ( , u) =u+1  with ( , u) =  u k=  1 2k  k-1 -1  .  Choose K + 1 classes or cells for U , i.e., {U = 0}, {U = 1},  , {U = K - 1}, {U  K }. The theoretical probabilities 0 ,1 ,... ,K +1 of these cells are found from the above formulas. A reasonable choice could be K = 5, = 2, = 1. After U1 ,... ,UN are found, evaluate the frequencies 0 ,1 ,... ,K of each cell, 0 + 1 + ... + K = N , and calculate the value of the chi-square statistic 2 = K 0  (i - Ni )2 . Ni  The expression for the P - value is the same as that used in Section 3.7. The interpretation is that for very small P - values, the sequence shows irregular occurrences of m-runs of ones. References for Test [1] O. Chrysaphinou and S. Papastavridis, ""A Limit Theorem on the Number of Overlapping Appearances of a Pattern in a Sequence of Independent Trials."" Probability Theory and Related Fields, Vol. 79 (1988), pp. 129-143. [2] N.J. Johnson, S. Kotz, and A. Kemp, Discrete Distributions. John Wiley, 2nd ed. New York, 1996 (especially pp. 378-379).  3.9  Maurer's ""Universal Statistical"" Test  This test was introduced in 1992 by Ueli Maurer of the Department of Computer Science at Princeton University. Maurer's test statistic relates closely to the per-bit entropy of the stream, which its author asserts is ""the correct quality measure for a secret-key source in a cryptographic application."" As 78   such, the test is claimed to measure the actual cryptographic significance of a defect because it is ""related to the running time of [an] enemy's optimal key-search strategy,"" or the effective key size of a cipher system. The test is not designed to detect a very specific pattern or type of statistical defect. However, the test is designed ""to be able to detect any one of the very general class of statistical defects that can be modeled by an ergodic stationary source with finite memory."" Because of this, Maurer claims that the test subsumes a number of the standard statistical tests. The test is a compression-type test ""based on the idea of Ziv that a universal statistical test can be based on a universal source coding algorithm. A generator should pass the test if and only if its output sequence cannot be compressed significantly."" According to Maurer, the source-coding algorithm due to Lempel-Ziv ""seems to be less suited for application as a statistical test"" because it seems to be difficult to define a test statistic whose distribution can be determined or approximated. The test requires a long (on the order of 10  2L + 1000  2L with 6  L  16) sequence of bits which are divided into two stretches of L-bit blocks (6  L  16), Q ( 10  2L ) initialization blocks and K ( 1000  2L ) test blocks. We take K = ceiling(n/L) - Q to maximize its value. The order of magnitude of Q should be specifically chosen to ensure that all possible L-bit binary patterns do in fact o ccur within the initialization blo cks. The test is not suited for very large values of L because the initialization takes time exponential in L. The test looks backs through the entire sequence while walking through the test segment of L-bit blocks, checking for the nearest previous exact L-bit template match and recording the distance - in number of blocks - to that previous match. The algorithm computes the log2 of all such distances for all the L-bit templates in the test segment (giving, effectively, the number of digits in the binary expansion of each distance). Then it averages over all the expansion lengths by the number of test blocks. f n  =  1 [ K  Q +K  log2 (#indices since previous occurrence of ith template)] i=Q+1  79   The algorithm achieves this efficiently by subscripting a dynamic look-up table making use of the integer representation of the binary bits constituting the template blocks. A standardized version of the statistic - the standardization being prescribed by the test - is compared to an acceptable range based on a standard normal (Gaussian) density, making use of the test statistic's mean which is given by formula (16) in Maurer (1992), Efn = 2 -L  i=1  (1 - 2  -L i-1  )  log2 i.  The expected value of the test statistic fn is that of the random variable log2 G where G = GL is a geometric random variable with the parameter 1 - 2 -L . There are several versions of approximate empirical formulas for the variance of the form Var(fn ) = c(L, K )Var(log2 G)/K. Here, c(L, K ) represents the nature of the o ccurrences of (Coron and Naccache (1998): form c(L, K ) = 0.7 factor that takes into account the dependent templates. The latest of the approximations not embedded in the test suite co de) has the -  0.8 12.8 K -4/L . + 1.6+ L L However, Coron and Naccache (1998) report that ""the inaccuracy due to [this approximation] can make the test 2.67 times more permissive than what is theoretically admitted."" In other words, the ratio of the standard deviation of fn obtained from the approximation above to the true standard deviation deviates considerably from one. In view of this fact and also since all approximations are based on the ""admissible"" assumption that Q  , the randomness hypothesis may be tested by verifying normality of the observed values fn , assuming that the variance is unknown. This can be done using a t-test. The original sequence must be partitioned into r (r  20) substrings, on each of which the value of the universal test statistic is evaluated (for the same value of parameters K, L and Q). The sample variance is evaluated, 80   and the P - value is  fn - E ( L )  erf c  var(fn ) References for Test      [1] Ueli M. Maurer, ""A Universal Statistical Test for Random Bit Generators,"" Journal of Cryptology. Vol. 5, No. 2, 1992, pp. 89-105. [2] J-S Coron and D. Naccache, ""An Accurate Evaluation of Maurer's Universal Test,"" Proceedings of SAC '98 (Lecture Notes in Computer Science). Berlin: Springer-Verlag, 1998. [3] H. Gustafson, E. Dawson, L. Nielsen, W. Caelli, ""A computer package for measuring the strength of encryption algorithms,"" Computers & Security. 13 (1994), pp. 687-697. [4] A. J. Menezes, P. C. van Oorschot, S. A. Vanstone, Handbook of Applied Cryptography. Boca Raton: CRC Press, 1997. [5] J. Ziv, ""Compression, tests for randomness and estimating the statistical model of an individual sequence,"" Sequences (ed. R.M. Capo celli). Berlin: Springer-Verlag, 1990. [6] J. Ziv and A. Lempel, ""A universal algorithm for sequential data compression,"" IEEE Transactions on Information Theory. Vol. 23, pp. 337-343.  3.10  Lempel-Ziv Compression Test  This test compresses the candidate random sequence using the (1977) LempelZiv algorithm. If the reduction is statistically significant when compared to a theoretically expected result, the sequence is declared to be non-random. To test a generator, many sequences are tested in this way. Significance probabilities are calculated for each sequence, and the hypothesis that the significance probabilities are uniformly distributed are tested, for example, by the Kolmogorov-Smirnov test.  81   The Lempel-Ziv test is thought to subsume the frequency, runs, other compression, and possibly spectral tests, but it may intersect the random binary matrix rank test. The test is similar to the entropy test and even more similar to Maurer's Universal Statistical test. However, the Lempel-Ziv test directly incorporates the compression heuristic that defines modern information theory. There are several variations on the Lempel-Ziv algorithm (1977). The test used here assumes that {Xi }n=1 is a binary sequence, and specifically proi ceeds as follows: 1. Parse the sequence into consecutive disjoint strings (words) so that the next word is the shortest string not yet seen. 2. Number the words consecutively in base 2. 3. Assign each word a prefix and a suffix; the prefix is the number of the previous word that matches all but the last digit; the suffix is the last digit. Note that what drives this compression is the number of substrings in the parsing. It is possible that, for small n, the Lempel-Ziv compression is actually longer than the original representation. Following the work of Aldous and Shields (1988), let W (n) represent the number of words in the parsing of a binary random sequence of length n. They show that E [W (n)] lim = 1, n n/ log n 2 so that the expected compression is asymptotically well-approximated by n/ log2 n, and that W (n) - E [W (n)]  N (0, 1),  [W (n)] which implies that a central limit theorem holds for the number of words in the Lempel-Ziv compression. However, Aldous and Shields were unable to determine the value of  [W (n)].  82   That difficulty was nominally overcome by Kirschenhofer, Prodinger, and Szpankowski (1994) who prove that  2 [W (n)]  n[C +  (log2 n)] log3 n 2  where C = 0.26600 (to five significant places) and  () is a slowly varying continuous function with mean zero and | ()| < 10-6 . The given sequence is parsed, and the number of words counted. It is not necessary to go through the complete Lempel-Ziv encoding, since the number of words, W , is sufficient. W is used to calculate z= W- n log2 n .266n log3 n 2  which is then compared with a standard normal distribution. The test is preferably one-sided, since some patterned sequences actually are flagged for being too long after compression. It is unclear whether the asymptotics are usefully accurate for values of n of the magnitude that may occur when testing random number generators. A simulation study performed using the Blum-Blum-Shub generator (1986) indicated that the asymptotics are not usefully accurate for sequences of length less than 10 million. Therefore, practitioners are urged to develop empirical estimates of the average compression length and its standard deviation to use in place of E[W(n)] and  [W(n)], respectively. The accuracy of such empirical estimates depends upon the randomness of the generator used. The Blum-Blum-Shub generator was chosen because its randomness is provably equivalent to the hardness of mathematical factorization. The P - value is computed as 1  - Wobs ) erf c(  2 2 2  For this test, the mean and variance were evaluated using SHA-1 for million bit sequences. The mean and variance were computed to be 69586.25 83   and 70.448718, respectively.  References for Test [1] D. Aldous and P. Shields (1988). ""A Diffusion Limit for a Class of Randomly-Growing Binary Trees,"" Probability Theory and Related Fields. 79, pp. 509-542. [2] L. Blum, M. Blum, and M. Shub (1994), ""A Simple Unpredictable PseudoRandom Number Generator,"" SIAM Journal on Computing. 15, pp. 364-383. [3] P. Kirschenhofer, H. Pro dinger, and W. Szpankowski (1994), ""Digital Search Trees Again Revisited: The Internal Path Length Perspective,"" SIAM Journal on Computing. 23, pp. 598-616. [4] U. M. Maurer (1992), ""A Universal Statistical Test for Random Bit Generators,"" Journal of Cryptology. 5, pp. 89-105. [5] J. Ziv and A. Lempel (1977), ""A Universal Algorithm for Sequential Data Compression,"" IEEE Transactions on Information Theory. 23, pp. 337-343.  3.11  Linear Complexity Test  This test uses linear complexity to test for randomness. The concept of linear complexity is related to a popular part of many keystream generators, namely, Linear Feedback Shift Registers (LFSR). Such a register of length L consists of L delay elements each having one input and one output. If the initial state of LFSR is ( L-1 ,... , 1 , 0 ), then the output sequence, ( L , L+1 ,...), satisfies the following recurrent formula for j  L j  = (c1  j -1  + c2  j -2  +  + cL  j -L  ) m o d 2.  c1 ,... ,cL are coefficients of the connection polynomial corresponding to a given LFSR. An LFSR is said to generate a given binary sequence if this sequence is the output of the LFSR for some initial state.  84   For a given sequence sn = ( 1 ,... , n ), its linear complexity L(sn ) is defined as the length of the shortest LFSR that generates sn as its first n terms. The possibility of using the linear complexity characteristic for testing randomness is based on the Berlekamp-Massey algorithm, which provides an efficient way to evaluate finite strings. When the binary n-sequence sn is truly random, formulas exist [2] for the 2 mean, n = EL(sn ), and the variance, n = Var(L(sn )), of the linear complexity L(sn ) = Ln when the n-sequence sn is truly random. The Crypt-X package [1] suggests that the ratio (Ln - n )/n is close to a standard normal variable, so that the corresponding P - values can be found from the normal error function. Indeed, Gustafson et al. [1] (p. 693) claim that ""for large n, L(sn ) is approximately normally distributed with mean n/2 and a variance 81 86/81 times that of the standard normal statistic z = L(sn ) - n ."" 2 86 This is completely false. Even the mean value n does not behave asymptotically precisely as n/2, and in view of the boundedness of the variance, this difference becomes significant. More importantly, the tail probabilities of the limiting distribution are much larger than those of the standard normal distribution. The asymptotic distribution of (Ln - n )/n along the sequence of even or odd values of n is that of a discrete random variable obtained via a mixture of two geometric random variables (one of them taking only negative values). Strictly speaking, the asymptotic distribution as such do es not exist. The cases n even and n odd must be treated separately with two different limiting distributions arising. Because of this fact the following sequence of statistics is adapted 2 Tn = (-1)n [Ln - n ]+ . (6) 9 Here n 4+ rn n = + . (7) 2 18 These statistics, which take only integer values, converge in distribution to the random variable T . This limiting distribution is skewed to the right. While P (T = 0) = 1 , for k = 1, 2.... 2 P (T = k ) = 85 1 , 22k (8)   for k = -1, -2,... P (T = k ) = It follows from (8) that P (T  k > 0) = for k < 0 (9) shows that P (T  k ) = 2  1 2|k|+1  .  (9)  1 32  2k-2  ;  1 3  22|  k|-1  .  So the P - value corresponding to the observed value Tobs can be evaluated in the following way. Let  = [|Tobs |] + 1. Then the P - value is 1 32 2-1  +  1 32  2-2  =  1 2 2-1  .  In view of the discrete nature of this distribution and the impossibility of attaining the uniform distribution for P - values, the same strategy can be used that was used with other tests in this situation. Namely, partition the string of length n, such that that n = MN , into N substrings each of length M . For the test based on the linear complexity statistic (6), evaluate TM within the j -th substring of size M , and choose K + 1 classes (depending on M .) For each of these substrings, the frequencies, 0 ,1 ,... ,K , of values of TM belonging to any of K + 1 chosen classes, 0 + 1 + ... + K = N , are determined. It is convenient to cho ose the classes with end-points at semi-integers. The theoretical probabilities 0 ,1 ,... ,K of these classes are determined from (8) and (9). For this purpose, M has to be large enough for the limiting distribution given by (8) and (9) to provide a reasonable approximation. M should exceed 500. It is recommended that M be chosen so that 500 M 5000. The frequencies are conjoined by the 2 -statistic 2 = K 0  (i - Ni )2 . Ni  86   which, under the randomness hypothesis, has an approximate 2 -distribution with K degrees of freedom. The reported P - value is  -u/2 K/2-1 u 2 (obs) e (K/2) 2K/2  du  = igamc  K 2 (obs) . , 2 2  As before, a conservative condition for the use of the 2 -approximation is that N min i  5. i  For reasonably large values of M and N , the following classes (K = 6) seem to be adequate: {T  -2.5}, {-2.5 < T  -1.5}, {-1.5 < T  -0.5}, {-0.5 < T  0.5}, {0.5 < T  1.5}, {1.5 < T  2.5}, and {T > 2.5}. The probabilities of these classes are 0 = 0.01047,1 = 0.03125,2 = 0.12500, 3 = 0.50000,4 = 0.25000,5 = 0.06250,6 = 0.020833. These probabilities are substantially different from the ones obtained from the normal approximation for which their numerical values are: 0.0041, 0.0432, 0.1944, 0.3646, 0.2863, 0.0939, 0.0135. References for Test [1] H. Gustafson, E. Dawson, L. Nielsen, and W. Caelli (1994), ""A computer package for measuring the strength of encryption algorithms,"" Computers and Security. 13, pp. 687-697. [2] A. J. Menezes, P. C. van Oorschot, and S. A. Vanstone (1997), Handbook of Applied Cryptography. CRC Press, Boca Raton, FL. [3] R.A. Rueppel, Analysis and Design of Stream Ciphers. New York: Springer, 1986.  3.12  Serial Test  The (generalized) serial test represents a battery of procedures based on testing the uniformity of distributions of patterns of given lengths.  87   Specifically, for i1 ,  ,im running through the set of all 2m possible 0, 1 vectors of length m, let i1 im denote the frequency of the pattern (i1 ,  ,im ) in the ""circularized"" string of bits ( 1 ,... , n , 1 ,... , m-1 ). Set 2 m =  2m n   i1 i m  i1 i  m  -  n 2m  2  =  2m n   i1 i m  2 i1 i  m  - n,  2 Thus, m is a 2 -type statistic, but it is a common mistake to assume that 2 m has the 2 -distribution. Indeed, the frequencies i1 im are not independent.  The corresponding generalized serial statistics for the testing of randomness (Kimberley (1987), Knuth, D. E. (1998), Menezes, van Oorschot and Vanstone, (1997)) are 2 2 2 m = m - m-1 and 2 2 2 2 m = m - 2m -1 2 + m-2 .  2 2 2 (Here 0 = -1 = 0.) Then m has a 2 -distribution with 2m-1 degrees 2 of freedom, and 2 m has a 2 -distribution with 2m-2 degrees of freedom. Thus, for small values of m, m  log2 (n) -2, one can find the corresponding 2m P - values from the standard formulas.  P - value1 = igamc 2 P - value2 = igamc 2  m- 2  ,  2 /2 m 2  m- 3  ,  2 /2 m  2 The result for 2 and the usual counting of frequencies is incorrectly given by Menezes, van Oorschot and Vanstone (1997) on p. 181, formula (5.2): +1 should be replaced by -1.  The convergence of  2 m to the 2 - distribution was proven by Good (1953).  References for Test [1] I. J. Good (1953), ""The serial test for sampling numbers and other tests for randomness,"" Proc. Cambridge Philos. Soc.. 47, pp. 276-284.  88   [2] M. Kimberley (1987), ""Comparison of two statistical tests for keystream sequences,"" Electronics Letters. 23, pp. 365-366. [3] D. E. Knuth (1998), The Art of Computer Programming. Vol. 2, 3rd ed. Reading: Addison-Wesley, Inc., pp. 61-80. [4] A. J. Menezes, P. C. van Oorschot, and S. A. Vanstone (1997), Handbook of Applied Cryptography. Boca Raton, FL: CRC Press, p. 181.  3.13  Approximate Entropy Test  Approximate entropy characteristics (Pincus and Singer, 1996) are based on repeating patterns in the string. If Yi (m) = ( i ,... , i+m-1 ), set C and  m i (m) m i  =  1 # {j : 1  j < n - m, Yj (m) = Yi (m)} =  n +1 - m = 1 n +1 - m n+1-m i=1  log Cim ,  C is the relative frequency of occurrences of the pattern Yi (m) in the string, and -(m) is the entropy of the empirical distribution arising on the set of all 2m possible patterns of length m,  (m) 2m  = =1   log  ,  where  is the relative frequency of pattern = (i1 ,  ,im ) in the string. The approximate entropy ApE n of order m, m  1 is defined as ApE n(m) =  (m)  -  (m+1)  with ApE n(0) = -(1) . ""ApE n(m) measures the logarithmic frequency with which blocks of length m that are close together remain close together for blocks augmented by one position. Thus, small values of ApE n(m) imply strong regularity, or persistence, in a sequence. Alternatively, large values of ApE n(m) imply substantial fluctuation, or irregularity."" (Pincus and Singer, 89   1996, p. 2083). Pincus and Kalman (1997) defined a sequence to be m-irregular (m-random) if its approximate entropy ApE n(m) takes the largest possible value. They evaluated quantities ApE n(m),m = 0, 1, 2 for binary and decimal expansions    of e,  , 2 and 3 with the surprising conclusion that the expansion of 3 demonstrated more irregularity than that of  . For a fixed block length m, one should expect that in long random (irregular) strings, ApE n(m)  log 2. The limiting distribution of n[log 2 - ApE n(m)] coincides with that of a 2 -random variable with 2m degrees of freedom. This fact provides the basis for a statistical test, as was shown by Rukhin (2000). Thus, with 2 (obs) = n[log 2 - ApE n(m)], the reported P - value is igamc 2 m- 1  ,2 (obs)/2 .  Actually, this limiting distribution of approximate entropy is more exact for its mo dified definition as ~  (m)  = i1 i m    i1 i  m  log   i1 i  m  ,  where i1 im denotes the relative frequency of the template (i1 ,  ,im ) in the augmented (or circular) version of the original string, i.e., in the string ( 1 ,... , n , 1 ,... , m-1 ). Let i1 im = ni1 im be the frequency of the pattern i1  im . Under our definition, i1 im = k i1 im k , so that for any m, i1 im = n. Define the modified approximate entropy as ~ ApE n(m) =  (m)  ~ -  (m+1)  .  By Jensen's inequality, log s  ApE n(m) for any m, whereas it is possible that log s < ApE n(m). Therefore, the largest possible value of the modified entropy is merely log s, which is attained when n = sm , and the distribution of all m-patterns is uniform. When calculating the approximate entropy for several values of m, it is very convenient to have the sum of all frequencies of m-templates be equal to n. 90   When n is large, ApE n(m) and its modified version cannot differ much. Indeed, one has with i1 im = (n - m +1)i1im  i1 i m  i1 i  m  = n - m +1,  and   i1 i  m  -  i1 i  m   m - 1. It follows that  i1 i m  -  i1 i  m    m-1 , n - m +1  ~ which suggests that for a fixed m, (m) and (m) must be close for large n. Therefore, Pincus' approximate entropy and its modified version are also close, and their asymptotic distributions must coincide. References for Test [1] S. Pincus and B. H. Singer, ""Randomness and degrees of irregularity,"" Proc. Natl. Acad. Sci. USA. Vol. 93, March 1996, pp. 2083-2088. [2] S. Pincus and R. E. Kalman, ""Not all (possibly) ""random"" sequences are created equal,"" Proc. Natl. Acad. Sci. USA. Vol. 94, April 1997, pp. 35133518. [3] A. Rukhin (2000), ""Approximate entropy for testing randomness,"" Journal of Applied Probability. Vol. 37, 2000.  3.14  Cumulative Sums (Cusum) Test  This test is based on the maximum absolute value of the partial sums of the sequence represented in the 1 fashion. Large values of this statistic indicate that there are either too many ones or too many zeros at the early stages of the sequence. Small values indicate that ones and zeros are intermixed to o evenly. A dual test can be derived from the reversed time random walk with Sk = Xn +  + Xn-k+1 . With this definition, the interpretation of the test results is modified by replacing ""the early stages"" by ""the late stages.""  91   The test is based on the limiting distribution of the maximum of the absolute values of the partial sums, max1kn |Sk |, n  lim P  max1kn |Sk | 1  z =  n 2 = 4   j =0  z    -z k=- 2  (-1)k exp -  (u - 2kz ) 2  2  du (10)  (-1)j (2j +1)2  exp - 2j +1 8z 2  = H (z ), z > 0.   With the test statistic z = max1kn |Sk |(obs)/ n , the randomness hypothesis is rejected for large values of z , and the corresponding P - value is   1 - H (max1kn |Sk |(obs)/ n) = 1 - G (max1kn |Sk |(obs)/ n) where the function G(z ) is defined by the formula (11). The series H (z ) in the last line of (10) converges quickly and should be used for numerical calculation only for small values of z . The function G(z ) (which is equal to H (z ) for all z ) is preferable for the calculation for moderate  and large values of max1kn |Sk |(obs)/ n, 1 G(z ) =  2  z  -z k=-  (-1)k exp{-  (u - 2kz )2 } du 2  = k=-  (-1)k [((2k +1)z ) - ((2k - 1)z )]  k=1  = (z ) - (-z )+ 2 = (z ) - (-z ) - 2  k=1  (-1)k [((2k +1)z ) - ((2k - 1)z )]  [2((4k - 1)z ) - ((4k +1)z ) - ((4k - 3)z )]   (z ) - (-z ) - 2 [2(3z ) - (5z ) - (z )] 4 z2 exp{- }, z  . 2 2z where (x) is the standard normal distribution. 1-  More directly, using Theorem 2.6, p. 17 of Revesz (1990), one obtains P 1kn  (11)  max |Sk |  z 92   =1-    k=-  P ((4k - 1)z < Sn < (4k +1)z ))  + k=-  P ((4k +1)z < Sn < (4k +3)z )) .  This formula is used for the evaluation of the P - values with  z = max |Sk |(obs)/ n. 1kn  The randomness hypothesis is rejected for large values of z . References for Test [1] Frank Spitzer, Principles of Random Walk. Princeton: Van Nostrand, 1964 (especially p. 269). [2] Pal Revesz, Random Walk in Random And Non-Random Environments. Singapore: World Scientific, 1990.  3.15  Random Excursions Test  This test is based on considering successive sums of the binary bits (plus or minus simple ones) as a one-dimensional random walk. The test detects deviations from the distribution of the number of visits of the random walk to a certain ""state,"" i.e., any integer value. Consider the random walk S and from zero (i,... , ) : S k  = X1 + ... Xk as a sequence of excursions to = 0 , Sk = 0 f o r i  k  .  i-1  =S  +1  Let J denote the total number of such excursions in the string. The limiting distribution for this (random) number J (i.e., the number of zeros among the sums Sk ,k = 1, 2,... ,n when S0 = 0) is known to be lim P J    0.  (12)   The test rejects the randomness hypothesis immediately if J is too small, i.e., if the following P - value is small: P (J < J (obs))  2   J (obs)/ n 0  e-  u2 /2  du = P  1 J 2 (obs) . , 2 2n   If J < max(0.005 n, 500), the randomness hypothesis is rejected. Otherwise the number of visits of the random walk S to a certain state is evaluated. Let  (x) be the number of visits to x, x = 0, during one 0-excursion. Its distribution is derived in Revesz (1990) and Baron and Rukhin (1999): P ( (x) = 0) = 1 - and for k = 1, 2,... P ( (x) = k ) = 1 4x 2  1 2|x|  (13)  1-  1 2|x|  k -1  .  (14)  This means that  (x) = 0 with probability 1 - 1/2|x|; otherwise (with probability 1/2|x|),  (x) coincides with a geometric random variable with the parameter 1/2|x|. It is easy to see that E (x) = 1, and Var( (x)) = 4|x|- 2. A useful formula is: 1 1 P ( (x)  a +1) = 2xP ( (x) = a +1) = 1- 2|x| 2|x| a  , a = 0, 1, 2,... . (15)  The above results are used for randomness testing in the following way. For a ""representative"" collection of x-values (say, 1  x  7 or -7  x  -1: -4  x  4 is used in the test suite code), evaluate the observed frequencies 94   k (x) of the number k of visits to the state x during J excursions which occur j j in the string. So k (x) = J=1 k (x) with k (x) = 1 if the number of visits to j j x during the j th excursion (j = 1,... ,J ) is exactly equal to k , and k (x) = 0 otherwise. Pool the values of  (x) into classes, say, k = 0, 1,... , 4 with an additional class k  5. The theoretical probabilities for these classes are: 0 (x) = P ( (x) = 0) = 1 - 1 k (x) = P ( (x) = k ) = 4x 1 1- 2|x| 1 ; 2|x| k -1  2  ,k = 1,... , 4; 4  1 1 5 (x) = P ( (x)  5) = 1- 2|x| 2|x| These probabilities have the form x x x x x x x = = = = = = = 1 2 3 4 5 6 7 0 (x) 0.5000 0.7500 0.8333 0.8750 0.9000 0.9167 0.9286 1 (x) 0.2500 0.0625 0.0278 0.0156 0.0100 0.0069 0.0051 2 (x) 0.1250 0.0469 0.0231 0.0137 0.0090 0.0064 0.0047 3 (x) 0.0625 0.0352 0.0193 0.0120 0.0081 0.0058 0.0044  .  4 (x) 0.0312 0.0264 0.0161 0.0105 0.0073 0.0053 0.0041  5 (x) 0.0312 0.0791 0.0804 0.0733 0.0656 0.0588 0.0531  Compare these frequencies to the theoretical ones using the 2 -test, 2 (x) = 5 k=0  (k (x) - Jk (x))2 , Jk (x)  which, for any x under the randomness hypothesis, must have approximately a 2 -distribution with 5 degrees of freedom. This is a valid test when J min k (x)  5, i.e., if J  500. (The test suite code uses 4 (x = 4) for min k (x).) If this condition does not hold, values of  (x) must be pooled into larger classes.  95   The corresponding battery of P - values is reported. These values are obtained from the formula 1-P 5 2 (obs)(x) . , 2 2  References for Test [1] M. Baron and A. L. Rukhin, ""Distribution of the Number of Visits For a Random Walk,"" Communications in Statistics: Sto chastic Mo dels. Vol. 15, 1999, pp. 593-597. [2] Pal Revesz, Random Walk in Random and Non-random Environments. Singapore: World Scientific, 1990. [3] Frank Spitzer, Principles of Random Walk. Princeton: Van Nostrand, 1964, (especially p. 269).  3.16  Random Excursions Variant Test  An alternative to the random excursions test can be derived as follows. Using the notation of the previous subsection, let J (x) be the total number of visits to x during J excursions. (The test suite code assumes J  500.) Since Sk renews at every zero, J (x) is a sum of independent identically distributed variables with the same distribution as  (x) = 1 (x). Therefore, the limiting distribution of J (x), J (x) - J lim P  < z  =  (z ) , J  J (4|x|- 2) is normal. The randomness hypothesis will be rejected when the P - value |J (x)(obs) - J |  erf c  2J (4|x|- 2) is small.      96   References for Test [1] M. Baron and A. L. Rukhin, ""Distribution of the Number of Visits For a Random Walk,"" Communications in Statistics: Sto chastic Mo dels. Vol. 15, 1999. [2] Pal Revesz, Random Walk in Random and Non-random Environments. Singapore: World Scientific, 1990. [3] Frank Spitzer, Principles of Random Walk. Princeton: Van Nostrand, 1964 (especially p. 269).  97   4.  TESTING STRATEGY AND RESULT INTERPRETATION  Three topic areas will be addressed in this section: (1) strategies for the statistical analysis of a random number generator, (2) the interpretation of empirical results using the NIST Statistical Test Suite, and (3) general recommendations and guidelines.  4.1  Strategies for the Statistical Analysis of an RNG  In practice, there are many distinct strategies employed in the statistical analysis of a random number generator. NIST has adopted the strategy outlined in Figure 1. Figure 1 provides an architectural illustration of the five stages involved in the statistical testing of a random number generator. Stage 1: Selection of a Generator  Select a hardware or software based generator for evaluation. The generator should produce a binary sequence of 0's and 1's of a given length n. Examples of pseudorandom generators (PRNG) that may be selected include a DES-based PRNG from ANSI X9.17 (Appendix C), and two further methods that are specified in FIPS 186 (Appendix 3) and are based on the Secure Hash Algorithm (SHA-1) and the Data Encryption Standard (DES). Stage 2: Binary Sequence Generation  For a fixed sequence of length n and the pre-selected generator, construct a set of m binary sequences and save the sequences to a file7. Stage 3: Execute the Statistical Test Suite  Invoke the NIST Statistical Test Suite using the file produced in Stage 2 and the desired sequence length. Select the statistical tests and relevant input parameters (e.g., block length) to be applied. Stage 4: Examine the P-values  An output file will be generated by the test suite with relevant intermediate values, such as test statistics, and P-values for each statistical test. Based on these P-values, a conclusion regarding the quality of the sequences can be made. Stage 5: Assessment: Pass/Fail Assignment  7  Sample data may also be obtained from George Marsaglia's Random Number CDROM, at http://stat.fsu.edu/pub/diehard/cdrom/.  98   Figure 1: Architecture of the NIST Statistical Test Suite For each statistical test, a set of P-values (corresponding to the set of sequences) is produced. For a fixed significance level, a certain percentage of P-values are expected to indicate failure. For example, if the significance level is chosen to be 0.01 (i.e.,  = 0.01), then about 1 % of the sequences are expected to fail. A sequence passes a statistical test whenever the P-value    99   and fails otherwise. For each statistical test, the proportion of sequences that pass is computed and analyzed accordingly. More in-depth analysis should be performed using additional statistical procedures (see Section 4.2.2).  4.2  The Interpretation of Empirical Results  Three scenarios typify events that may occur due to empirical testing. Case 1: The analysis of the P-values does not indicate a deviation from randomness. Case 2: The analysis clearly indicates a deviation from randomness. Case 3: The analysis is inconclusive. The interpretation of empirical results can be conducted in any number of ways. Two approaches NIST has adopted include (1) the examination of the proportion of sequences that pass a statistical test and (2) the distribution of P-values to check for uniformity. In the event that either of these approaches fails (i.e., the corresponding null hypothesis must be rejected), additional numerical experiments should be conducted on different samples of the generator to determine whether the phenomenon was a statistical anomaly or a clear evidence of non-randomness.  4.2.1  Proportion of Sequences Passing a Test  Given the empirical results for a particular statistical test, compute the proportion of sequences that pass. For example, if 1000 binary sequences were tested (i.e., m = 1000),  = 0.01 (the significance level), and 996 binary sequences had P-values  .01, then the proportion is 996/1000 = 0.9960. The range of acceptable proportions is determined using the confidence interval defined ^ (1- ^ ) p p $ p as, ^  3 , where p = 1-, and m is the m sample size. If the proportion falls outside of this interval, then there is evidence that the data is nonrandom. Note that other standard deviation values could be used. For the example above, the confidence interval is .99  3 .99(.01 ) = .99  0.0094392 1000  (i.e.,  the proportion should lie above 0.9805607. This can be illustrated using a graph as shown in Figure 2. Figure 2: P-value Plot The confidence interval was calculated using a normal distribution as an approximation to the binomial distribution, which is reasonably accurate for large sample sizes (e.g., n  1000).  100   4.2.2  Uniform Distribution of P-values The distribution of P-values is examined to ensure uniformity. This may be visually illustrated using a histogram (see Figure 3), whereby, the interval between 0 and 1 is divided into 10 sub-intervals, and the P-values that lie within each sub-interval are counted and displayed. Uniformity may also be determined via an application of a 2 test and the determination of a P-value corresponding to the Goodness-of-Fit Distributional Test on the P-values obtained for an arbitrary statistical test (i.e., a P-value of the P-values). This is accomplished by computing  2  Figure 3: Histogram of P-values  =  10  i =1    ( Fi - s s  10  )2  , where Fi is the number of P-  10  values in sub-interval i, and s is the sample size. A P-value is calculated such that P-valueT = 2 igamc( 9 2 ,  2 ) . If P-valueT  0.0001, then the sequences can be considered to be uniformly distributed.  4.3  General Recommendations and Guidelines  In practice, many reasons can be given to explain why a data set has failed a statistical test. The following is a list of possible explanations. The list was compiled based upon NIST statistical testing efforts. (a) An incorrectly programmed statistical test. Unless otherwise specified, it should be assumed that a statistical test was tailored to handle a particular problem class. Since the NIST test code has been written to allow the selection of input parameters, the code has been generalized in any number of ways. Unfortunately, this doesn't necessarily translate to coding ease. A few statistical tests have been constrained with artificial upper bounds. For example, the random excursions tests are assumed to be no more than max{1000, n/128} cycles. Similarly, the Lempel-Ziv Compression test assumes that the longest word is in the neighborhood of log2 n, where n is the sequence length. Conceivably, fixed parameters may have to be increased, depending on experimental conditions.  101   (b) An underdeveloped (immature) statistical test. There are occasions when either probability or complexity theory isn't sufficiently developed or understood to facilitate a rigorous analysis of a statistical test. Over time, statistical tests are revamped in light of new results. Since many statistical tests are based upon asymptotic approximations, careful work needs to be done to determine how good an approximation is. (c) An improper implementation of a random number generator. It might be plausible that a hardware RNG or a software RNG has failed due to a flaw in the design or due to a coding implementation error. In each case, careful review must be made to rule out this possibility. (d) Improperly written codes to harness test input data. Another area that needs to be scrutinized is the harnessing of test data. The test data produced by a (P)RNG must be processed before being used by a statistical test. For example, processing might include dividing the output stream from the (P)RNG into appropriate sized blocks, and translating the 0's to negative ones. On occasion, it was determined that the failures from a statistical test were due to errors in the code used to process the data. (e) Poor mathematical routines for computing P-values Quality math software must be used to ensure excellent approximations whenever possible. In particular, the incomplete gamma function is more difficult to approximate for larger values of the constant a. Eventually, P-value formulas will result in bogus values due to difficulties arising from numerical approximations. To reduce the likelihood of this event, NIST has prescribed preferred input parameters. (f) Incorrect choices for input parameters. In practice, a statistical test will not provide reliable results for all seemingly valid input parameters. It is important to recognize that constraints are made upon tests on a test-by-test basis. Take the Approximate Entropy Test, for example. For a sequence length on the order of 106, one would expect that block lengths approaching log2 n would be acceptable. Unfortunately, this is not the case. Empirical evidence suggests that beyond m = 14, the observed test statistic will begin to disagree with the expected value (in particular, for known good generators, such as SHA-1). Hence, certain statistical tests may be sensitive to input parameters. Considerations must often be made regarding the numerical experimentation input parameters, namely: sequence length, sample size, block size and template.  102   Sequence Length The determination as to how long sequences should be taken for the purposes of statistical testing is difficult to address. If one examines the FIPS 140-1 statistical tests, it is evident that sequences should be about 20,000 bits long. However, the difficulty with taking relatively short sequence lengths is problematic in the sense that some statistical tests, such as Maurer's Universal Statistical Test, require extremely long sequence lengths. One of the reasons is the realization that asymptotic approximations are used in determining the limiting distribution. Statements regarding the distribution for certain test statistics are more difficult to address for short length sequences than their longer length counterparts. Sample Size The issue of sample size is tied to the choice of the significance level. NIST recommends that, for these tests, the user should fix the significance level to be at least 0.001, but no larger than 0.018. A sample size that is disproportional to the significance level may not be suitable. For example, if the significance level () is chosen to be 0.001, then it is expected that 1 out of every 1000 sequences will be rejected. If a sample of only 100 sequences is selected, it would be rare to observe a rejection. In this case, the conclusion may be drawn that a generator was producing random sequences, when in all likelihood a sufficiently large enough sample was not used. Thus, the sample should be on the order of the inverse of the significance level (-1). That is, for a level of 0.001, a sample should have at least 1000 sequences. Ideally, many distinct samples should be analyzed. Block Size Block sizes are dependent on the individual statistical test. In the case of Maurer's Universal Statistical test, block sizes range from 1 to 16. However, for each specific block size, a minimum sequence length should be used. If the block size were fixed at 16, a sequence of more than a billion bits would be required. For some users, that may not be feasible. Intuitively, it would seem that the larger the block size, the more information could be gained from the parsing of a sequence, such as in the Approximate Entropy test. However, a block size that is too large should not be selected either, for otherwise the empirical results may be misleading and incorrect because the test statistic is better approximated by a distinct probability distribution. In practice, NIST advises selecting a block size no larger than log 2 n , where n is the sequence length. However, certain exceptions hold, and thus NIST suggests choosing a smaller block size.  8  Note that for FIPS 140-2, the significance level has been set to 0.0001 for the power up tests.  103   Template Certain statistical tests are suited for detecting global non-randomness. However, other statistical tests are more apt at assessing local non-randomness, such as tests developed to detect the presence of too many m-bit patterns in a sequence. Still, it makes sense that templates of a block size greater than log 2 n  should not be chosen, since frequency counts will most probably be in the neighborhood of zero, which does not provide any useful information. Thus, appropriate choices must be made. Other Considerations In principle, there are many commonly occurring questions regarding randomness testing. Perhaps the most frequently asked question is, ""How many tests should one apply?"" In practice, no one can truly answer this question. The belief is that the tests should be independent of each other as much as possible. Another, frequently asked question concerns the need for applying a monobits test (i.e., Frequency test), in lieu of Maurer's Universal Statistical test. The perception is that Maurer's Universal Statistical test supercedes the need to apply a monobits test. This may hold true for infinite length sequences. However, it is important to keep in mind that there will be instances when a finite binary sequence will pass Maurer's Universal Statistical test, yet fail the monobits test. Because of this fact, NIST recommends that the Frequency test be applied first. If the results of this test support the null hypothesis, then the user may proceed to apply other statistical tests.  4.4  Application of Multiple Tests  Given a concern regarding the application of multiple tests, NIST performed a study to determine the dependence between the tests. The performance of the tests was checked by using a Kolmogorov-Smirnov test of uniformity on the P-values obtained from the sequences. However, it required an assumption that the sequences that were generated to test uniformity were sufficiently random. There are many tests in the suite. Some tests should intuitively give independent answers (e.g., the frequency test and a runs test that conditions on frequencies should assess completely different aspects of randomness). Other tests, such as the cusum test and the runs test, result in P-values that are likely to be correlated. To understand the dependencies between the tests in order to eliminate redundant tests, and to ensure that the tests in the suite are able to detect a reasonable range of patterned behaviors, a factor analysis of the resulting P-values was performed. More precisely, in order to assess independence, m sequences of binary pseudorandom digits were generated, each of length n, and all k=161 tests in the suite were applied to those sequences to determine their randomness. Each test produced a significance probability; denote by pij the significance probability of test i on sequence j.  104   Given the uniformly distributed pij , the transformation z ij =  -1 pij leads to normally distributed variables. Let zj be the vector of transformed significance probabilities corresponding to the ith sequence. A principal components analysis was performed on the z1, ... , xm. Usually, a small number of components suffices to explain a great proportion of the variability, and the number of these components can be used to quantify the number of ""dimensions'"" of nonrandomness spanned by the suite tests. The principal component analysis of this data was performed. This analysis extracts 161 factors, equal to the number of tests. The first factor is the one that explains the largest variability. If many tests are correlated, their P-values will greatly depend on this factor, and the fraction of total variability explained by this factor will be large. The second factor explains the second largest proportion of variability, subject to the constraint that the second factor is orthogonal to the first, and so on for subsequent factors. The corresponding fractions corresponding to the first 50 factors were plotted for the tests, based on Blum-Blum-Shub sequences of length 1,000,000. This graph showed that there is no large redundancy among our tests. The correlation matrix formed from the z1, ... , xm was constructed via a statistical software application (SAS). The same conclusion was supported by the structure of these matrices. The degree of duplication among the tests seems to be very small.  ()  105   5.  USER'S GUIDE  This section describes the set-up and proper usage of the statistical tests developed by NIST that are available in the NIST test code. Descriptions of the algorithms and data structures that were utilized are included in this section.  5.1  About the Package  This toolbox was specifically designed for individuals interested in conducting statistical testing of cryptographic (P)RNGs. Several implementations of PRNGs utilized during the development phase of the project have also been included. Caveat: The test code was developed using a SUN workstation under the Solaris operating system. No guarantee is made regarding the compilation and execution of the PRNG implementations on other platforms. For this reason, a switch has been incorporated into the source codes to disable the inclusion of the PRNGs. The flag INCLUDE_GENERATORS can be found in the defs.h header file. This package will address the problem of evaluating (P)RNGs for randomness. It will be useful in:      identifying (P)RNGs which produce weak (or patterned) binary sequences, designing new (P)RNGs, verifying that the implementations of (P)RNGs are correct, studying (P)RNGs described in standards, and investigating the degree of randomness by currently used (P)RNGs.  The objectives during the development of the NIST statistical test suite included:      Platform Independence: The source code was written in ANSI C. However, some modification may have to be made, depending on the target platform and the compiler. Flexibility: The user may freely introduce their own math software routines. Extensibility: New statistical tests can easily be incorporated. Versatility: The test suite is useful in performing tests for PRNGs, RNGs and cipher algorithms. Portability: With minor modifications, source code may be ported to different platforms. The NIST source code was ported onto the SGI Origin, and a 200 MHz PC using the Microsoft Visual C++ 6.0 development environment. Orthogonality: A diverse set of tests is provided. Efficiency: Linear time or space algorithms were utilized whenever possible.     106   5.2  System Requirements  This software package was developed on a SUN workstation under the Solaris operating system. All of the source code was written in ANSI C. Source code porting activities were successful for the SGI Origin (IRIX 6.5 with the SGI C compiler) and a desktop computer (IBM PC under Windows 98 and Microsoft C++ 6.0). In practice, minor modifications will have to be introduced during the porting process in order to ensure the correct interpretation of tests. In the event that a user wishes to compile and execute the code on a different platform, sample data and the corresponding results for each of the statistical tests have been provided. In this manner, the user will be able to gain confidence that the ported statistical test suite is functioning properly. For additional details see Appendix C. For the majority of the statistical tests, memory must be allocated dynamically in order to proceed. In the event that workspace cannot be provided, the statistical test returns a diagnostic message.  5.3  How to Get Started  To setup a copy of the NIST test code on a workstation, follow the instructions below.  Copy the sts.tar file into the root directory. Use the instruction, tar -xvf sts.tar, to unbundle the source code.  Several files and subdirectories should have been created. The eight subdirectories include data/, experiments/, generators/, include/, obj/, src/ and templates/. The four files include assess, grid, makefile, and stats.  The data/ subdirectory is reserved for pre-existing RNG data files that are under investigation. Currently, two formats are supported, i.e., data files consisting of ASCII zeroes and ones, and binary formatted hexadecimal character strings.  The experiments/ subdirectory will be the repository of the empirical results for RNG data. Several subdirectories should be contained in it. These include AlgorithmTesting/, BBS/, CCG/, G-SHA-1/, LCG/, MODEXP/, MS/, QCG1/, QCG2/, and XOR/. All but the first of these subdirectories is meant to store the results for the corresponding PRNG. The AlgorithmTesting/ subdirectory is the default subdirectory for empirical results corresponding to RNG data stored in the data/ subdirectory.  The generators/ subdirectory contains the source codes for nine pseudo-  107   random number generators. These include Blum-Blum-Shub, Cubic Congruential Generator, the FIPS 186 one way function based on SHA-1 (GSHA-1), Linear Congruential Generator, Modular Exponentiation, MicaliSchnorr, Quadratic Congruential Generator I and II, and Exclusive OR. Code for the ANSI X9.17 generator and the FIPS 186 one way function based on DES (G-DES) were removed from the package because of possible export issues. User defined PRNGs should be copied into this subdirectory, with the corresponding modifications to the makefile, utilities1.c, defs.h, and proto.h files.  The include/ subdirectory contains the header files for the statistical tests, pseudo-random number generators, and associated routines.  The obj/ subdirectory contains the object files corresponding to the statistical tests, pseudo random number generators and other associated routines.  The src/ subdirectory contains the source codes for each of the statistical tests.  The templates/ subdirectory contains a series of non-periodic templates for varying block sizes that are utilized by the NonOverlapping Templates statistical test.  User prescribed modifications may be introduced in several files. This will be discussed subsequently in Section 5.5.2 and Appendix B.  Edit the makefile. Modify the following lines: (a) CC (your ANSI C compiler) (b) ROOTDIR (the root directory that was prescribed earlier in the process, e.g., rng/)  Now execute Makefile. An executable file named assess should appear in the project directory.  The data may now be evaluated. Type the following: assess  , e.g., assess 1000000. Follow the menu prompts. The files stats and grid correspond respectively to the logs of the per sequence frequency of zeroes and ones and the 0-1 matrix of fail/pass assignments for each individual sequence and each individual statistical test.  108   5.4 5.4.1  Data Input and Output of Empirical Results Data Input  Data input may be supplied in one of two ways. If the user has a stand-alone program or hardware device which implements a RNG, the user may want to construct as many files of arbitrary length as desired. Files should contain binary sequences stored as either ASCII characters consisting of zeroes and ones, or as hexadecimal characters stored in binary format. These files can then be independently examined by the NIST Statistical Test Suite. In the event that storage space is a problem, the user may want to modify the reference implementation and plug-in their implementation of the PRNG under evaluation. The bit streams will be stored directly in the epsilon data structure, which contains binary sequences.  5.4.2  Output of Empirical Results  The output logs of empirical results will be stored in two files, stats and results, that correspond respectively to the computational information, e.g., test statistics, intermediate parameters, and P-values for each statistical test applied to a data set. If these files are not properly created, then it is most probably due to the inability to open the files for output. See Appendix J for further details.  5.4.3  Test Data Files  Five sample files have been created and are contained in the data/ subdirectory. Four of these files correspond to the Mathematica9 generated binary expansion of several classical numbers for over 1,000,000 bits. These files are data.e, data.pi, data.sqrt2, and data.sqrt3. The Mathematica program used in creating these files can be found in Appendix E. A fifth file, data.sha1, was constructed utilizing the SHA-1 hash function.  5.5  Program Layout  The test suite package has been decomposed into a series of modules which include the: statistical tests, (pseudo)random number generators, empirical results (hierarchical) directories, and data. The three primary components of the NIST test suite are the statistical tests, the underlying mathematical software, and the pseudo random number generators under investigation. Other 9  Mathematica, Stephen Wolfram's Computer Algebra System, http://www.mathematica.com.  109   components include the source code library files, the data directory and the hierarchical directory (experiments/) containing the sample data files and empirical result logs, respectively.  5.5.1  General Program  The NIST test suite contains sixteen tests which will be useful in studying and evaluating the binary sequences produced by random and pseudo random number generators. As in previous work in this field, statistical tests must be devised which, under some hypothesized distribution, employ a particular test statistic, such as the number of runs of ones or the number of times a pattern appears in a bit stream. The majority of the tests in the test suite either (1) examine the distribution of zeroes and ones in some fashion, (2) study the harmonics of the bit stream utilizing spectral methods, or (3) attempt to detect patterns via some generalized pattern matching technique on the basis of probability theory or information theory.  5.5.2  Implementation Details  In practice, any number of problems can arise if the user executes this software in unchartered domains. It is plausible that sequence lengths well beyond the testing procedure (i.e., on the order of 106 ) may be chosen. If memory is available, there should not be any reason why the software should fail. However, in many instances, user defined limits are prescribed for data structures and workspace. Under these conditions, it may be necessary to increase certain parameters, such as the MAXNUMOFTEMPLATES and the MAXNUMBEROFCYCLES. Several parameters that may be modified by a user are listed in Table 3. The parameter ALPHA denotes the significance level that determines the region of acceptance and rejection. NIST recommends that ALPHA be in the range [0.001, 0.01]. The parameter ITMAX is utilized by the special functions; it represents the upper bound on the maximum number of iterations allowed for iterative computations. The parameter KAPPA is utilized by the gcf and gser routines defined in the special-functions.c file. It represents the desired accuracy for the incomplete gamma function computations. The parameter MAXNUMOFTEMPLATES indicates the maximum number of non-periodic templates that may be executed by the Nonoverlapping Template Matchings test. For templates of size m = 9, up to 148 possible non-periodic templates may be applied. The parameters NUMOFTESTS and NUMOFGENERATORS correspond to the maximum number of tests that may be defined in the test suite, and the maximum number of generators specified in the test suite, respectively. Lastly, the MAXNUMBEROFCYCLES represents the maximum number of cycles that NIST anticipates in any particular binary sequence.  110   Table 3. User Prescribed Statistical Test Parameters Source Code Parameter ALPHA ITMAX KAPPA MAXNUMOFTEMPLATES NUMOFTESTS NUMOFGENERATORS MAXNUMBEROFCYCLES Default Parameter 0.01 2000000 3e-15 40 16 12 40000 Description/Definition Significance Level Max number of iterations Desired accuracy for incgam Non-overlapping Templates Test Max number of tests Max number of PRNGs Max number of cycles  5.5.3 5.5.3.1  Description of the Test Code Global Data Structures  Binary sequences are stored in the epsilon data structure. To efficiently store this information, a bit field structure was introduced. This is a C structure defined to strictly utilize a single bit to store a zero or a one. In essence, the bit field structure utilizes the minimum amount of storage necessary to hold the information that will be manipulated by the statistical tests. It is flexible enough to allow easy manipulation by accessing individual bits via an index specification.  5.5.3.2 Special Data Structures For many of the tests, efficiency is desired in both time and space. A binary tree data structure is used for this purpose. In this case, the binary tree is implemented as an array, whose root node serves no particular purpose. The binary tree is used in several different ways. One way is as a Boolean structure where each individual node represents either a zero or a one, but whose content indicates the absence or presence of an individual bit. Parsing this tree indicates the presence or absence of a word of fixed length. In addition, the binary tree structure is used as an efficient means to tabulate the frequency of all 2m words of length m in a finite binary sequence. This data structure is also employed in the construction of the dictionary required in the LempelZiv coding scheme. The restriction in this case, however, is that if the stream isn't equidistributed (i.e., is very patterned), then the Lempel-Ziv test may break down. This is due to the unbalanced binary tree10 which may ensue. In this case, the procedure is halted by the test suite and a warning statement is returned.  10  The binary tree will be unbalanced due to the presence of too many words exceeding log2 n, where n is the sequence length.  111   5.5.3.3  Mathematical Software  Special functions required by the test suite are the incomplete gamma function and the complementary error function. The cumulative distribution function, also known as the standard normal function, is also required, but it can be expressed in terms of the error function. One of the initial concerns regarding the development of the reference implementation was the dependencies that were required in order to gain reliable mathematical software for the special functions required in the statistical tests. To resolve this matter, the test suite makes use of the following libraries: The Fast Fourier Transform routine was obtained at http://www.netlib.org/fftpack/fft.c. The normal function utilized in this code was expressed in terms of the error function. Standard Normal (Cumulative Distribution) Function 1 z -u 2 / 2 ( z ) =  e du 2 - The complementary error function (erfc) utilized in the package is the ANSI C function contained in the math.h header file and its corresponding mathematical library. This library should be included during compilation. Complementary Error Function 2  -u 2 erfc( z ) =  e du z The incomplete gamma function is based on an approximation formula whose origin is described in the Handbook of Applied Mathematical Functions [1] and in the Numerical Recipes in C book [6]. Depending on the values of its parameters a and x, the incomplete gamma function may be approximated using either a continued fraction development or a series development. Gamma Function  ( z ) = 0 t  z -1 - t  e dt  Incomplete Gamma Function P(a , x )   (a , x ) 1 x -t  e t  (a )  (a ) 0 a -1  dt  where P(a,0) = 0 and P(a,) = 1.  112   Incomplete Gamma Function Q( a , x )  1 - P ( a , x )   (a , x ) 1  -t  et  (a )  (a ) x a -1  dt  where Q(a,0) = 1 and Q(a,) = 0. NIST has chosen to use the Cephes C language special functions math library in the test software. Cerphes may be found at http://people.ne.mediaone.net/moshier/index.html#Cephes or on the GAMS server at http://math.nist.gov/cgi-bin/gams-serve/list-module components/ CEPHES/CPROB/13192.html. The specific functions that are utilized are igamc (for the complementary incomplete gamma function) and lgam (for the logarithmic gamma function).  5.6  Running the Test Code  A sample NIST Statistical Test Suite monolog is described below. Note: In this section bold items indicate input. In order to invoke the NIST statistical test suite, type assess, followed by the desired bit stream length, n. For example, assess 100000. A series of menu prompts will be displayed in order to select the data to be analyzed and the statistical tests to be applied. The first screen appears as follows: GENERATOR OPTIONS [00] [02] [04] [06] [08] Input File Linear Congruential Micali-Schnorr Quadratic Congruential I Cubic Congruential [01] [03] [05] [07] [09] G Using SHA-1 Blum-Blum-Shub Modular Exponentiation Quadratic Congruential II Exclusive OR  OPTION ----> 0 User Prescribed Input File: data/data.pi Once the user has prescribed a particular data set or PRNG, the statistical tests to be applied must be selected. The following screen is displayed:  113   [01] [03] [05] [07] [09] [11] [13] [15]  STATISTICAL TESTS Frequency [02] Block Frequency Cumulative Sums [04] Runs Longest Runs of Ones [06] Rank Spectral - Discrete Fourier Transform [08] Nonperiodic Template Matchings Overlapping Template Matchings [10] Universal Statistical Approximate Entropy [12] Random Excursions Random Excursions Variant [14] Serial Lempel-Ziv Complexity [16] Linear Complexity INSTRUCTIONS Enter 0 if you DO NOT want to apply all of the statistical tests to each sequence and 1 if you DO. Enter Choice: 0  In this case, 0 has been selected to indicate interest in applying a subset of the available statistical tests. The following screen is then displayed.  INSTRUCTIONS Enter a 0 or 1 to indicate whether or not the numbered statistical test should be applied to each sequence. For example, 1111111111111111 applies every test to each sequence. 1234567891111111 0123456 0000000010000000  As shown above, the only test applied was number 9, the Nonoverlapping templates test. A query for the desired sample size is then made. How many bit streams should be generated? 10 Ten sequences will be parsed using the data.pi file. Since a file was selected as the data specification mode, a subsequent query is made regarding the data representation. The user must specify whether the file consists of bits stored in ASCII format or hexadecimal strings stored in binary format.  114   [0] BITS IN ASCII FORMAT [1] HEX DIGITS IN BINARY FORMAT Select input mode: 0 Since the data consists of a long sequence of zeroes and ones, 0 was chosen. Given all necessary input parameters the test suite proceeds to analyze the sequences. Statistical Testing In Progress......... During the execution of the statistical tests, two log files located under the rng/ directory are updated. One file is the stats file, the other is the grid file. The former contains the distribution of zeroes and ones for each binary sequence, whereas the latter contains a binary matrix of values corresponding to whether or not sequence i passed statistical test j. Once the testing process is complete, the empirical results can be found in the experiments/ subdirectory. Statistical Testing Complete!!!!!!!!!!!! Upon completion, an in-depth analysis is performed utilizing a MATLAB11 script written to simplify the analysis of empirical results. Two types of analyses are conducted. One type examines the proportion of sequences that pass a statistical test. The other type examines the distribution of the P-values for each statistical test. More details are supplied in the Section 4.2.  5.7  Interpretation of Results  An analytical routine has been included to facilitate interpretation of the results. A file finalAnalysisReport is generated when statistical testing is complete. The report contains a summary of empirical results. The results are represented via a table with p rows and q columns. The number of rows, p, corresponds to the number of statistical tests applied. The number of columns, q = 13, are distributed as follows: columns 1-10 correspond to the frequency of Pvalues12, column 11 is the P-value that arises via the application of a chi-square test13, column 12 is the proportion of binary sequences that passed, and the 13th column is the corresponding statistical test. An example is shown in Figure 6.  11 12 13  See Section 1.2, Definitions and Abbreviations. The unit interval has been divided into ten discrete bins. I n order to assess the uniformity of P-values in the ith statistical test.  115   -----------------------------------------------------------------------------RESULTS FOR THE UNIFORMITY OF P-VALUES AND THE PROPORTION OF PASSING SEQUENCES ----------------------------------------------------------------------------------------------------------------------------------------------------------C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 P-VALUE PROPORTION STATISTICAL TEST -----------------------------------------------------------------------------6 12 9 12 8 7 8 12 15 11 0.616305 0.9900 Frequency 11 11 12 6 10 9 8 9 17 7 0.474986 0.9900 Cusum 6 10 8 14 16 10 10 6 5 15 0.129620 0.9900 Cusum 7 9 9 11 11 11 8 12 12 10 0.978072 0.9900 Serial 13 6 13 15 9 7 3 11 13 10 0.171867 0.9600 Serial - - - - - - - - - - - - - - - - - - - - - - - - - - - -- - - - - - - - - - - The minimum pass rate for each statistical test with the exception of the random excursion (variant) test is approximately = 0.960150 for a sample size = 100 binary sequences. For further guidelines construct a probability table using the MAPLE program provided in the addendum section of the documentation. - - - - - - - - - - - - - - - - - - - - - - - - - - - -- - - - - - - - - - - -  Figure 6: Depiction of the Final Analysis Report  116   APPENDIX A: RANK COMPUTATION FOR BINARY MATRICES  Apply elementary row operations where the addition operator is taken to be the exclusive-OR operation. The matrices are reduced to upper triangular form using forward row operations, and the operation is repeated in reverse in order using backward row operations in order to arrive at a matrix in triangular form. The rank is then taken to be the number of nonzero rows in the resulting Gaussian reduced matrix. Forward Application of Elementary Row Operations: Let each element in the m by m matrix be designated as a 1. 2. Set i = 1 If element ai ,i = 0 (i.e., the element on the diagonal  1), then swap all elements in the ith row with all elements in the next row that contains a one in the ith column (i.e., this row is the kth row, where i < k  m) . If no row contains a ""1"" in this position, go to step 4. If element ai ,i = 1 , then if any subsequent row contains a ""1"" in the ith column, replace each element in that row with the exclusive-OR of that element and the corresponding element in the ith row. a. b. c. d. e. f. g. h. 4. 5. Set row = i + 1 Set col=i. If arow,col = 0, then go to step 3g. a row,col = a row,col  ai ,col If col=m, then go to step 3g. col=col+1; go to step 3d. If row = m, then go to step 4. row=row+1; go to step 3b. i,j  3.  If i 2, then i=i-1 and go to step 2. Backward row operation complete. The rank of the matrix = the number of non-zero rows.  Example of Forward Row Operations: 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1  A  The original matrix.  B  Since a1,1 = 1 and rows 3 and 4 contain a 1 in the first column (see the original matrix), rows 3 and 4 are replaced by the exclusive-OR of that row and row 1.  C  Since a2,2  1 and no other row contains a ""1"" in this column (see B), the matrix is not altered.  118   000010 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 1 0 0 1 0 1 0 1  D  Since a3,3  1, but the 4th row contains a ""1"" in the 3rd column (see B or C), the two rows are switched.  E  Since row 5 contains a ""1"" in the 3rd column (see D), row 5 is replaced by the exclusive-OR of row 1 and row 5.  F  Since a4,4  1 and no other row contains a ""1"" in this column (see E), the matrix is not altered.  G  Since a5,5 1, but row 6 contains a 1 in column 5 (see F), the two rows are switched. Since no row below this contains a ""1"" in the 5th column, the end of the forward process is complete.  The Subsequent Backward Row Operations: 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0  H  Since a6,6 = 1 and rows 2 and 4 contain ones in the 6th column (see G), rows 2 and 4 are replaced by the exclusive-OR of that row and row 6.  I  Since a5,5 = 1and row 3 contains a one in the 5th column (see H), row 3 is replaced by the exclusive-OR or row 3 and row 5.  119   000001 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1  J  Since a altered.  4,4   1 and no other row has a one in column 4, the matrix is not  K  Since a altered.  3,3  = 1, but no other row has a one in column 3, the matrix is not  L  Since a2,2 1 and no other row has a one in column 2, the matrix is not altered, and he process is complete.  Since the final form of the matrix has 4 non-zero rows, the rank of the matrix is 4.  120   APPENDIX B: SOURCE CODE Filename: defs.h Debugging Aides: 1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 11. 12. 13. 14. 15. 16. 17. 18. 19. #define #define #define #define #define #define #define #define #define #define #define #define #define #define #define #define #define #define #define FREQUENCY BLOCK_FREQUENCY CUSUM RUNS LONG_RUNS RANK MATRICES DFT APERIODIC_TEMPLATES PERIODIC_TEMPLATES UNIVERSAL APEN SERIAL RANDOM_EXCURSIONS RANDOM_EXCURSIONS_VARIANT LEMPEL_ZIV LINEAR_COMPLEXITY DISPLAY_OUTPUT_CHANNELS PARTITION 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0  Note: For debugging purposes, switches were introduced to display/not display intermediate computations for each statistical test. A one denotes true, i.e., show intermediate results; a zero denotes false, i.e., do not show intermediate results. Filename: defs.h Statistical Testing Alternatives: 1. 2. 3. 4. 5. 6. 7. 8. #define #define #define #define #define #define #define #define INCLUDE_GENERATORS LONG_RUNS_CASE_8 LONG_RUNS_CASE_128 LONG_RUNS_CASE_10000 SAVE_FFT_PARAMETERS SAVE_APEN_PARAMETERS SAVE_RANDOM_EXCURSION_PARAMETERS SEQ_LENGTH_STEP_INCREMENTS 1 0 0 1 0 0 1 5000  Note: Statistical testing alternatives have been incorporated into the test suite using switches. Line 1 refers to the inclusion (or exclusion) of the pseudo-random number generators contained in the NIST test suite during compilation. The ability to enable or disable this function was 121   introduced under the realization that underlying libraries may not port easily to different platforms. The user can disable the sample generators and should be able to compile the statistical tests. Lines 2-4 refer to different probability values that have been included in the Long Runs of Ones Test. Since the statistical test partitions a sequence into sub-strings of varying length, the user has the freedom to select between several cases. The user should enable only one case and disable the other two cases. Lines 5-7 refer to the ability to store intermediate parameter values to a file for the sake of constructing graphics. Line 5 will enable or disable the storage of the Fourier points and corresponding moduli into the files, fourierPoints and magnitude, respectively. Line 6 will enable or disable the storage of the sequence length and approximate entropy value for varying sequence lengths into the files, abscissaValues and ordinateValues. Line 7 will enable or disable the storage of the number of cycles for each binary sequence into the file, cycleInfo. Line 8 refers to the number of sequence length step increments to be taken during the generation and storage of the approximate entropy values in the file, ordinateValues. Filename: defs.h Global Constants: 1. 2. 3. 4. 5. 6. #define #define #define #define #define #define ALPHA MAXNUMOFTEMPLATES NUMOFTESTS NUMOFGENERATORS MAXNUMBEROFCYCLES MAXFILESPERMITTEDFORPARTITION 0.01 148 16 9 40000 400  Lines 1-6 correspond to test suite parameters that have been preset. Under various conditions, the user may decide to modify them. Line 1 refers to the significance level. It is recommended that the user select the level in the range [0.001,0.01]. Line 2 refers to the maximum number of templates that may be used in the Nonoverlapping Template Matching test. Line 3 refers to the maximum number of tests that is supported in the test suite. If the user adds additional tests, this parameter should be incremented. Line 4 refers to the maximum number of generators that is supported in the package. If the user adds additional generators, this parameter should be incremented.  122   Line 5 refers to the maximum number of expected cycles in the random excursions test. If this number is insufficient, the user may increase the parameter appropriately. Line 6 refers to the maximum number of files which may be decomposed by the partitionResultFile routine. This routine is applied only for specific tests where more than one P-value is produced per sequence. This routine decomposes the corresponding results file into separate files, data001, data002, data003, ...  123   APPENDIX C: EMPIRICAL RESULTS FOR SAMPLE DATA The user is urged to validate that the statistical test suite is operating properly. For this reason, five sample files have been provided. These five files are: (1) data.pi, (2) data.e, (3) data.sha1, (4) data.sqrt2, and (5) data.sqrt3. For each data file, all of the statistical tests were applied, and the results recorded in the following tables. The Block Frequency, Long Runs of Ones, Non-overlapping Template Matching, Overlapping Template Matching, Universal, Approximate Entropy, Linear Complexity and Serial tests require user prescribed input parameters. The exact values used in these examples has been included in parenthesis beside the name of the statistical test. In the case of the random excursions and random excursions variant tests, only one of the possible 8 and 18 P-values, respectively, has been reported. Example #1: The binary expansion of  Statistical Test P-value Frequency 0.578211 Block Frequency (m = 100) 0.014444 Cusum-Forward 0.628308 Cusum-Reverse 0.663369 Runs 0.419268 Long Runs of Ones (M = 10000) 0.024390 Rank 0.083553 Spectral DFT 0.012947 Non-overlapping Templates (m = 9, B = 000000001) 0.165757 Overlapping Templates (m = 9) 0.296897 Universal (L = 7, Q = 1280) 0.669012 Approximate Entropy (m = 5) 0.634457 Random Excursions (x = +1) 0.844143 Random Excursions Variant (x = -1) 0.760966 Lempel Ziv Complexity 0.311714 Linear Complexity (M = 500) 0.255475 2 0.583812 Serial (m = 5, m )  124   Example #2: The binary expansion of e Statistical Test P-value Frequency 0.953749 Block Frequency (m = 100) 0.619340 Cusum-Forward 0.669887 Cusum-Reverse 0.724266 Runs 0.561917 Long Runs of Ones (M = 10000) 0.718945 Rank 0.306156 Spectral DFT 0.443864 NonOverlapping Templates (m = 9, B = 000000001) 0.078790 Overlapping Templates (m = 9) 0.110434 Universal (L = 7, Q = 1280) 0.282568 Approximate Entropy (m = 5) 0.361688 Random Excursions (x = +1) 0.778616 Random Excursions Variant (x = -1) 0.826009 Lempel Ziv Complexity 0.000322 Linear Complexity (M = 500) 0.826335 2 0.225783 Serial (m = 5, m ) Example #3: A G-SHA-1 binary sequence Statistical Test P-value Frequency 0.604458 Block Frequency (m = 100) 0.833026 Cusum-Forward 0.451231 Cusum-Reverse 0.550134 Runs 0.309757 Long Runs of Ones (M = 10000) 0.657812 Rank 0.577829 Spectral DFT 0.086702 NonOverlapping Templates (m = 9, B = 000000001) 0.496601 Overlapping Templates (m = 9) 0.339426 Universal (L = 7, Q = 1280) 0.411079 Approximate Entropy (m = 5) 0.731449 Random Excursions (x = +1) 0.000000 Random Excursions Variant (x = -1) 0.000000 Lempel Ziv Complexity 0.398475 Linear Complexity (M = 500) 0.309412 2 0.742275 Serial (m = 5, m )  125   Example #4: The binary expansion of Statistical Test Frequency Block Frequency (m = 100) Cusum-Forward Cusum-Reverse Runs Long Runs of Ones (M = 10000) Rank Spectral DFT NonOverlapping Templates (m = 9, B = 000000001) Overlapping Templates (m = 9) Universal (L = 7, Q = 1280) Approximate Entropy (m = 5) Random Excursions (x = +1) Random Excursions Variant (x = -1) Lempel Ziv Complexity Linear Complexity (M = 500) 2 Serial (m = 5, m ) Example #5: The binary expansion of Statistical Test Frequency Block Frequency (m = 100) Cusum-Forward Cusum-Reverse Runs Long Runs of Ones (M = 10000) Rank Spectral DFT NonOverlapping Templates (m = 9, B = 000000001) Overlapping Templates (m = 9) Universal (L = 7, Q = 1280) Approximate Entropy (m = 5) Random Excursions (x = +1) Random Excursions Variant (x = -1) Lempel Ziv Complexity Linear Complexity (M = 500) 2 Serial (m = 5, m )  2 P-value 0.811881 0.289410 0.879009 0.957206 0.313427 0.012117 0.823810 0.267174 0.569461 0.791982 0.130805 0.853227 0.216235 0.566118 0.949310 0.317127 0.873914 3 P-value 0.610051 0.573925 0.917121 0.689519 0.261123 0.446726 0.314498 0.463412 0.532235 0.082716 0.165981 0.404616 0.783283 0.155066 0.989651 0.346469 0.100780  126   APPENDIX D: CONSTRUCTION OF APERIODIC TEMPLATES For the purposes of executing the Non-overlapping Template Matching statistical test, all 2m mbit binary sequences which are aperiodic were pre-computed. These templates, or patterns, were stored in a file for m = 2 to m = 21. The ANSI-C program utilized in finding these templates is provided below. By modifying the parameter M, the template library corresponding to the template can be constructed. This parameter value should not exceed B, since the dec2bin conversion routine will not operate correctly. Conceivably, this source code can be easily modified to construct arbitrary 2m m-bit binary sequences for larger m.  #include   #include   #define B 32 #define M 6 int *A; static long nonPeriodic; unsigned displayBits(FILE*, long, long); int main() { FILE *fp1, *fp2; long i, j, count, num; A = (unsigned*) calloc(B,sizeof(unsigned)); fp1 = fopen(""template"", ""w""); fp2 = fopen(""dataInfo"", ""a""); num = pow(2,M); count = log(num)/log(2); nonPeriodic = 0; for(i = 1; i < num; i++) displayBits(fp1, i,count); fprintf(fp2,""M = %d\n"", M); fprintf(fp2,""# of nonperiodic templates = %u\n"", nonPeriodic); fprintf(fp2,""# of all possible templates = %u\n"", num); fprintf(fp2,""{# nonperiodic}/{# templates} = %f\n"", (double)nonPeriodic/num); fprintf(fp2,""==========================================""); fprintf(fp2,""===============\n""); fclose(fp1); fclose(fp2); free(A); return 0; }  127   void displayBits(FILE* fp, long value, long count) { int i, j, match, c, displayMask = 1 << (B-1); for(i = 0; i < B; i++) A[i] = 0; for(c = 1; c <= B; c++) { if (value & displayMask) A[c-1] = 1; else A[c-1] = 0; value <<= 1; } for(i = 1; i < count; i++) { match = 1; if ((A[B-count]!= A[B-1]) && ((A[B-count]!= A[B-2])||(A[B-count+1] != A[B-1]))) { for(c = B-count; c <= (B-1)-i; c++) { if (A[c] != A[c+i]) { match = 0; break; } } } if (match) { /* printf(""\nPERIODIC TEMPLATE: SHIFT = %d\n"",i); */ break; } } if (!match) { for(c = B-count; c < (B-1); c++) fprintf(fp,""%u"",A[c]); fprintf(fp,""%u\n"", A[B-1]); nonPeriodic++; } return; }  128   APPENDIX E: GENERATION OF THE BINARY EXPANSION OF IRRATIONAL NUMBERS  The sample Mathematica program utilized in constructing four sample files is shown below.  Mathematica Program (**********************************************************) (* Purpose: Converts num to its decimal expansion using *) (* its binary representation. *) (* *) (* Caution: The $MaxPrecision variable must be set to *) (* the value of d. By default, Mathematica *) (* sets this to 50000, but this can be increased.*) (**********************************************************) BinExp[num_,d_] := Module If[d > n= L= ]; SE = BinExp[E,302500]; Save[""data.e"",{SE}]; SP = BinExp[Pi,302500]; Save[""data.pi"",{SP}]; S2 = BinExp[Sqrt[2],302500]; Save[""data.sqrt2"",{S2}]; S3 = BinExp[Sqrt[3],302500]; Save[""data.sqrt3"",{S3}]; [{n,L}, $MaxPrecision, $MaxPrecision = d]; N[num,d]; First[RealDigits[n,2]]  129   APPENDIX F: NUMERIC ALGORITHM ISSUES For each binary sequence, an individual statistical test must produce at least one P-value. P-values are based on the evaluation of special functions, which must be as accurate as possible on the target platform. The log files produced by each statistical test, report P-values with six digits of precision, which should be sufficient. However, if greater precision is desired, modify the printf statements in each statistical test accordingly. During the testing phase, NIST commonly evaluated sequences on the order 106; hence, results are based on this assumption. If the user wishes to choose longer sequence lengths, then be aware that numerical computations may be inaccurate14 due to machine or algorithmic limitations. For further information on numerical analysis matters, see [6]15. For the purposes of illustration, sample parameter values and corresponding special function values are shown in Table F.1 and Table F.2. Table F.1 compares the results for the incomplete gamma function for selected parameter values for a and x. The results are shown for Maple16, Matlab10, and the Numerical Recipe17 routines. Recall that the definitions for the gamma function and the incomplete gamma function are defined, respectively, as:  ( z ) = 0 t Q ( a, x ) =  z -1 - t  e dt  ( a, x ) 1 = ( a ) ( a )      x  e -t t  a -1  dt ,  where Q(a,0) = 1 and Q(a,) = 0. Since the algorithm used in the test suite implementation of the incomplete gamma function is based on the numerical recipe codes, it is evident that the function is accurate to at least the seventh decimal place. For large values of a, the precision will degrade, as will confidence in the result (unless a computer algebra system is employed to ensure high precision computations). Table F.2 compares the results for the complementary error function (see Section 5.3.3) for selected parameter values for x. The results are shown for ANSI C, Maple, and Matlab. Recall that the definition for the complementary error function is:  14  15  16 17  According to the contents of the GNU C specifications at ""/usr/local/lib/gcc-lib/sparc-sunsolaris2.5.1/2.7.2.3/specs (gcc version 2.7.2.3),"" the limits.h header file on a SUN Ultra 1 workstation, the maximum number of digits of precision of a double is 15. Visit http://www.ulib.org/webRoot/Books/Numerical_Recipes/ or http://beta.ul.cs.cmu.edu/webRoot/ Books/Numerical_Recipes/, particularly, Section 1.3 (Error, Accuracy, and Stability). See Section 1.2, Definitions and Abbreviations. The parameter values for eps and itmax were fixed at 3x10-15 and 2,000,000 respectively. Special function routines based on Numerical Recipe codes will be replaced by non-proprietary codes in the near future.  130   du z Table F.1: Selected Input Parameters for the Incomplete Gamma Function a = x = 600 Maple Matlab Test Suite a = x = 1000 Maple Matlab Test Suite a = x = 100000 Maple Matlab Test Suite Q(a,x) 0.4945710333 0.4945710331 0.4945710331 Q(a,x) 0.4957947559 0.4957947558 0.4957947558 Q(a,x) 0.4995794779 0.4995794779 0.4995794778 a = x = 800 Maple Matlab Test Suite a = x = 10000 Maple Matlab Test Suite a = x = 1000000 Maple Matlab Test Suite Q(a,x) 0.4952983876 0.4952983876 0.4952983876 Q(a,x) 0.4986701918 0.4986701917 0.4986701917 Q(a,x) 0.4998670192 0.4998670196 0.4998670205  erfc( z ) =  2      e  -u  2  Table F.2: Selected Input Parameters for the Complementary Error Function x 0.00 erfc(x) 1.000000000000000 1.000000000000000 1.000000000000000 0.157299207050285 0.157299207050280 0.157299207050285 0.004677734981047 0.004677734981050 0.004677734981047 0.000022090496999 0.000022090497000 0.000022090496999 x 0.50 erfc(x) 0.479500122186953 0.479500122186950 0.479500122186953 0.033894853524689 0.033894853524690 0.033894853524689 0.000406952017445 0.000406952017440 0.000406952017445 0.000000743098372 0.000000743098370 0.000000743098372  1.00  2.00  3.00  Test Suite Maple Matlab Test Suite Maple Matlab Test Suite Maple Matlab Test Suite Maple Matlab  1.50  2.50  3.50  Test Suite Maple Matlab Test Suite Maple Matlab Test Suite Maple Matlab Test Suite Maple Matlab  Thus, it is evident that the various math routines produce results that are sufficiently close to each other. The differences are negligible. To reduce the likelihood for obtaining an inaccurate P-value result, NIST has prescribed recommended input parameters.  131   APPENDIX G: HIERARCHICAL DIRECTORY STRUCTURE rng/ makefile The NIST Statistical Test Suite makefile. This file is invoked in order to recompile the entire test suite, including PRNGs. The NIST Statistical Test Suite makefile. This file is invoked in order to recompile the NIST test suite without the PRNGs (Note: the PRNGs may not compile on all platforms without user intervention). The NIST Statistical Test Suite executable file is called assess. This subdirectory contains the names of all data files to be analyzed. Sample files include the binary expansions to well known constants such as e, , 2 , and 3 .  makefile2  assess data/  experiments/ This subdirectory contains the empirical result subdirectories for each RNG. AlgorithmTesting/ CCG/ LCG/ MS/ QCG2/ BBS/ G-SHA-1/ MODEXP/ QCG1/ XOR/  For each subdirectory there is a set of nested directories, that is, apen/ cumulative-sums/ frequency/ linear-complexity/ nonperiodic-templates/ random-excursions/ rank/ serial/ block-frequency/ fft/ lempel-ziv / longest-run/ overlapping-templates/ random-excursions-variant/ runs/ universal/  For each nested directory there are two files created upon execution of an individual statistical test. The results file contains a P-value list for each binary sequence, and the stats file contains a list of statistical information for each binary sequence. generators/ This subdirectory contains the source code for each PRNG. In the  132   event that the user is interested in evaluating their PRNG (online), their source code may, for example, be added as generators4.c in this directory, with additional changes made in the utilities2.c file and the defs.h file. generators1.c: generators2.c: generators3.c: sha.c : grid contains contains contains contains BBS, MS, LCG ModExp, QCG1, QCG2, CCG1, XOR G-SHA-1 routines required by the G-SHA-1 PRNG.  This file contains bits which represent the acceptance or rejection of a particular sequence for each individual statistical test that is run. The Pvalue computed for the sequence is compared to the chosen significance level . This subdirectory contains all of the header files that prescribe any global variables, constants, and data structures utilized in the reference implementation. In addition, the subdirectory contains all function declarations and prototypes. cephes-protos.h config2.h f2c.h generators2.h globals.h lippar.h mconfig.h proto.h special-functions.h utilities2.h config.h defs.h generators1.h generators3.h lip.h matrix.h mp.h sha.h utilities1.h  include/  obj/  This subdirectory contains the object files corresponding to the source codes. approximateEntropy.o assess.o cephes.o cusum.o dfft.o discreteFourierTransform.o frequency.o functions.o generators1.o generators2.o generators3.o lempelZivCompression.o linearComplexity.o lip.o matrix.o mp.o nonOverlappingTemplateMatchings.o overlappingTemplateMatchings.o randomExcursions.o randomExcursionsVariant.o rank.o runs.o sha.o special-functions.o  133   universal.o src/  utilities1.o  utilities2.o  This subdirectory contains the source codes for the statistical tests. assess.c dfft.c cephes.c lip.c The driver program for this package The discrete fourier transform routine Defines the incomplete gamma function Long integer precision library utilized by Pate Williams implementation of the Blum-Blum-Shub and Micali-Schnorr source codes matrix.c : Source code for the determination of rank for binary matrices mp.c : Multiprecision integer package special-functions.c : Numerical routines for the handling of special functions frequency.c : Frequency Test blockFrequency.c : Block Frequency Test cusum.c : Cumulative Sums Test runs.c : Runs Test longestRunOfOnes.c : Longest Run Of Ones Test rank.c : Rank Test discreteFourierTransform.c : Spectral Test nonOverlappingTemplateMatchings.c : Nonoverlapping Template Matchings Test OverlappingTemplateMatchings.c : Overlapping Template Matchings Test universal.c : Universal Test approximateEntropy.c: Approximate Entropy Test randomExcursions.c : Random Excursions Test randomExcursionsVariant.c : Random Excursions Variant Test serial.c : Serial Test lempelZivComplexity.c : Lempel-Ziv Complexity Test linearComplexity.c : Linear Complexity Test serial.c : Serial Test utilities1.c : Utility functions... utilities2.c : Utility functions... This file contains the frequency distributions for individual sequences. Non-Periodic Template Library: : : : :  stats  templates/  134   This subdirectory contains the templates (or patterns) which are evaluated in the NonOverlapping Template Matching Test. The corresponding file is opened for the prescribed template block length m. Currently, the only options for which nonperiodic templates have been stored are those which lie in [2,21]. In the event that m > 21, the user must pre-compute the non-periodic templates. template2 template7 template12 template17 template3 template8 template13 template18 template4 template9 template14 template19 template5 template10 template15 template20 template6 template11 template16 template21  135   APPENDIX H: VISUALIZATION APPROACHES There are several visualization approaches that may be used to investigate the randomness of binary sequences. Three techniques involve the Discrete Fourier Transform, approximate entropy and the linear complexity profile. (a) Spectral - Discrete Fourier Transform (DFT) Plot Figure H.1 depicts the spectral components (i.e., the modulus of the DFT) obtained via application of the Fast Fourier Transform on a binary sequence (consisting of 5000 bits) extracted from the Blum-Blum-Shub pseudo-random number generator18. To demonstrate how the spectral test can detect periodic features in the binary sequence, every 10th bit was changed to a single one. To pass this test, no more than 5 % of the peaks should surpass the 95 % cutoff, (determined to be sqrt(3*5000)  122.4744871). Clearly, greater than 5 % of the peaks exceed the cutoff point in the figure. Thus, the binary sequence fails this test.  Figure H.1: Discrete Fourier Transform Plot 18  The Blum-Blum-Shub pseudo random number generator, based on the intractability of the quadratic residuocity problem is described in the Handbook of Applied Cryptography, by Menezes, et. al.  136   (b) Approximate Entropy (ApEn) Graph Figure H.2 depicts the approximate entropy values (for block length = 2) for three binary sequences, the binary expansion of e and , and a binary sequence taken from the SHA-1 pseudo-random number generator. In theory, for an n-bit sequence, the maximum entropy value that can be attained is ln (2)  0.69314718. The x-axis reflects the number of bits considered in the sequence. The y-axis reflects the deficit from maximal irregularity, that is, the difference between the ln (2) and the observed approximate entropy value. Thus, for a fixed sequence length, one can determine which sequence appears to be more random. For a sequence of 1,000,000 bits, e appears more random than both  and the SHA-119 sequence. However, for larger block sizes, this is not the case.  G-SHA-1 e G-SHA-1  e    Figure H.2: Approximate Entropy Graph  It is worth noting that, for larger block sizes and sequence lengths on the O(106), SHA-1 binary sequences yield deficit values on the O(10-9). 137  19   (c) Linear Complexity Profile Figure H.3 depicts the linear complexity profile for a pseudo-random number generator that is strictly based on the XOR (exclusive-or) operator. The generator is defined as follows: given a random binary seed, x1 , x 2 ,L , x127 , subsequent bits in the sequence are generated according to the rule, xi = xi - 1  xi -127 for i  128. The Berlekamp-Massey 20algorithm computes the connection polynomial that, for some seed value, reconstructs the finite sequence. The degree of this polynomial corresponds to the length of the shortest Linear Feedback Shift Register (LFSR) that represents the polynomial. The linear complexity profile depicts the degree, which for a random finite length (n-bit) sequence is about n/2. Thus, the x-axis reflects the number of bits observed in the sequence thus far. The y-axis depicts the degree of the connection polynomial. At n = 254, observe that the degree of the polynomial ceases to increase and remains constant at 127. This value precisely corresponds to the number of bits in the seed used to construct the sequence.  Figure H.3: Linear Complexity Profile  20  For a description of the algorithm see Chapter 6 - Stream Ciphers, which may be accessed at http://www.cacr.math.uwaterloo.ca/hac/.  138   APPENDIX I: INSTRUCTIONS FOR INCORPORATING ADDITIONAL STATISTICAL TESTS  In order to add another statistical test to the test suite, the user should make the following modifications: 1. [In the file include/defs.h] Insert any test input parameters into the testParameters structure. Increment the value of NUMOFTESTS by the number of tests to be added. 2. [In the file include/proto.h] Insert the statistical test function prototype declaration. 3. [In the file src/utilities1.c] Embed the test function call into the nist_test_suite function. For example, if the current number of tests is 16, and one test is to be added, insert the following code: if ((testVector[0] == 1) || (testVector[17] == 1)) myNewTest(tp.myNewTestInputParameters,tp.n); 4. [In the file src/myNewTest.c] Define the statistical test function. Note: The programmer should embed fprintf statements using stats[x], and results[x] as the corresponding output channel for writing intermediate test statistic parameters and P-values, respectively. x is the total number of tests. 5. [In the file src/utilities2.c] (a) In the function, openOutputStreams, insert the string, ""myNewTest"" into the testNames variable. In the function, chooseTests, insert the following lines of code (as modified by the actual number of total tests): printf(""\t\t\t printf(""\t\t\t 12345678911111111\n""); 01234567\n"");  Note: For each PRNG defined in the package, a sub-directory myNewTest must be created. (b) In the function, displayTests, insert a printf statement. For example, if the total number of tests is 17, insert 139   printf(""  [17] My New Test\n"");  (c) If an input test parameter is required, in the function, fixParameters, insert the following lines of code (under the assumption that myNewTestParameter is an integer). For example, if the total number of tests is 17, insert if (testVector[17] == 1) { printf(""\tEnter MyNewTest Parameter Value: scanf(""%d"", &tp.myNewTestParameter); }  "");  140   APPENDIX J: INSTRUCTIONS FOR INCORPORATING ADDITIONAL PRNGs In order to add a PRNG to the test suite, the user should make the following modifications: 1. [In the file include/defs.h] Increment the variable NUMOFGENERATORS by one. 2. [In the file include/generators4.h] Insert the generator function prototype declaration. For example, void myNewPRNG(); 3. [In the file generators/generators4.c] Define the generator function. The general scheme for each PRNG defined in the test suite is as follows: Allocate space for epsilon, the n-bit BitField array. for i = 1 to numOfBitStreams { Construct an n-bit sequence using myNewGenerator and store in epsilon. Invoke the nist_test_suite. } Deallocate the space given to epsilon. Note: A sub-directory called myNewPRNG/ must be created. Under this new directory, a set of sub-directories must be created for each of the test suite statistical tests. The script createScript has been included to facilitate this operation. 4. [In the file src/utilities2.c] (a) In the function, generatorOptions, insert the following lines of code: case 12: *streamFile = ""myNewPRNG""; break;  (b) In the function, invokeTestSuite, insert the following lines of code: case 12: myNewPRNG(); break;  (c) In the function, openOutputStreams, insert the generator string name into the generatorDir variable. For example, 141   char generatorDir[20][20] = {""AlgorithmTesting/"", ...,""XOR/"", ""MYNEWPRNG/""}; Similarly, in the routine, partitionResultFile, in the file, assess.c.  142   APPENDIX K: GRAPHICAL USER INTERFACE (GUI) K.1 Introduction  A simple Tcl/Tk graphical user interface (GUI) was developed as a front-end to the NIST Statistical Test Suite. The source code may be found in the file, rng-gui.tcl. The interface consists of a single window with four regions. The topmost region contains the software product laboratory affiliation. The left half of the window consists of a checklist for the sixteen statistical tests. The user should select or de-select the set of statistical tests to be executed. The right half of the window is sub-divided into an upper and lower portion. The upper portion consists of required parameters that must be provided in order to execute the tests. The lower portion consists of test dependent parameters that must be provided only if the corresponding test has been checked.  Figure K.1: Tcl/Tk GUI for the NIST Statistical Test Suite Once the user has selected the statistical tests, the required input parameters, and the test dependent input parameters, then the user should depress the Execute button to invoke the  143   battery of statistical tests. This will result in the de-iconification of the GUI. Upon completion, the GUI will re-iconify. The user should then proceed to review the file, finalAnalysisReport.txt to assess the results.  K.2  An Example  The following table presents an example of the use of the GUI. The user has checked all sixteen of the statistical tests and entered: data.e as the binary date stream  filename      a sequence length of 1000000 bits  1 as the number of binary  sequences 0 as the stream type  9 as the overlapping template block length  7 as the universal block length 1280 as the universal initialization steps  5 as the approximate entropy block length 5 as the serial block length  100 as the block frequency block  length 9 as the nonoverlapping template block length   500 as the linear complexity substring length  K.3  Guidance in the Selection of Parameters  Section 2 provides the recommended parameter choices for each statistical test.  K.4  Interpretation of Results  Section 4.2 contains information regarding the interpretation of empirical results.  K.5  Tcl/Tk Installation Instructions  Tcl/Tk may be obtained from the Scriptics website at http://www.scriptics.com/. Download Tcl/Tk 8.1 for the target platform from http://dev.scriptics.com/software/tcltk/choose.html.  144   K.6 [1] [2]  References Brent Welch, Practical Programming in Tcl and Tk, 2nd edition. Prentice Hall PTR, 1997. Clif Flyntf, Tcl/Tk for Real Programmers. Academic Press, 1999.  145   APPENDIX L: DESCRIPTION OF THE REFERENCE PSEUDO RANDOM NUMBER GENERATORS  The NIST Statistical Test Suite supplies the user with nine pseudo-random number generators. A brief description of each pseudo-random number generator follows. The user supplied sequence length determines the number of iterations for each generator.  L.1  Linear Congruential Generator (LCG)  The input parameter for the Fishman and Moore21 LCG22 is fixed in code but may be altered by the user. Input Parameter: z0 = 23482349 Description: Given a seed z0, subsequent numbers are computed based on zi+1 = a*zi mod (231-1), where a is a function of the current state. These numbers are then converted to uniform values in [0,1]. At each step, output `0' if the number is  0.5, otherwise output `1'.  L.2  Quadratic Congruential Generator I (QCG-I)  The input parameters to the QCG-I are fixed in code, but may modified by the user. Input Parameters: p = 987b6a6bf2c56a97291c445409920032499f9ee7ad128301b5d0254aa1a9633fdbd378 d40149f1e23a13849f3d45992f5c4c6b7104099bc301f6005f9d8115e1 x0 = 3844506a9456c564b8b8538e0cc15aff46c95e69600f084f0657c2401b3c244734b62e a9bb95be4923b9b7e84eeaf1a224894ef0328d44bc3eb3e983644da3f5  21  Fishman, G. S. and L. R. Moore (1986). An exhaustive analysis of multiplicative congruential random number generators with modulus 2**31-1, SIAM Journal on Scientific and Statistical Computation, 7, 24-45. 22 Additional information may be found in Chapter 16 (Pseudo-Random Sequence Generators & Stream Ciphers), Section 16.1 (Linear Congruential Generators) of Bruce Schneier's book, Applied Cryptography: Protocols, Algorithms and Source Code in C, 2nd edition, John Wiley & Sons, 1996.  146   Description: Using a 512-bit prime p, and a random 512-bit seed x0, construct subsequent elements (each 512bit numbers) in the sequence via the rule: xi+1 = xi2 mod p, for i  0.  L.3  Quadratic Congruential Generator II (QCG-II)  The input parameter to the QCG-II is fixed in code, but may be modified by the user. Input Parameter: x0 = 7844506a9456c564b8b8538e0cc15aff46c95e69600f084f0657c2401b3c244734b62e a9bb95be4923b9b7e84eeaf1a224894ef0328d44bc3eb3e983644da3f5 Description: Using a 512-bit modulus, and a random 512-bit seed x0, construct subsequent elements (each 512-bit numbers) in the sequence via the rule: xi+1 = 2xi2 + 3xi + 1 mod 2512, for i  0.  L.4  Cubic Congruential Generator (CCG)  The input parameter to the CCG is fixed in code, but may be modified by the user. Input Parameter: x0 =7844506a9456c564b8b8538e0cc15aff46c95e69600f084f0657c2401b3c244734b62ea 9bb95be4923b9b7e84eeaf1a224894ef0328d44bc3eb3e983644da3f5 Description: Given a 512 bit seed x0, construct subsequent 512-bit strings via the rule: xi+1 = xi3 mod 2512, for i  0.  L.5  Exclusive OR Generator (XORG)  The input parameter to the XORG is a 127-bit seed that is fixed in code, but may be user modified.  147   Input Parameter: x1 , x2 ,K, x127 = 00010110110110010001011110010010100110111011010001000000101 01111111010100100001010110110000000000100110000101110011111111100111 Description: Choose a bit sequence, x1 , x2 ,K , x127 . Construct subsequent bits via the rule: xi = xi - 1  xi - 127  , for i  128.  L.6  Modular Exponentiation Generator (MODEXPG)  The input parameters to the MODEXPG are fixed in code, but they may be user modified. Input Parameters: seed = 7AB36982CE1ADF832019CDFEB2393CABDF0214EC p = 987b6a6bf2c56a97291c445409920032499f9ee7ad128301b5d0254aa1a9633fdbd378 d40149f1e23a13849f3d45992f5c4c6b7104099bc301f6005f9d8115e1 g = 3844506a9456c564b8b8538e0cc15aff46c95e69600f084f0657c2401b3c244734b62ea 9bb95be4923b9b7e84eeaf1a224894ef0328d44bc3eb3e983644da3f5 Description: A sequence {xi} of 512-bit pseudo-random numbers can be generated as follows: Choose a 512-bit prime p, and a base g, as in the Digital Signature Standard (DSS). Choose an arbitrary 160-bit seed y. Let x1 = gseed mod p and xi+1 = g yi mod p, for i  1 where yi is the lowest-order 160 bits of xi. Splicing together the {xi} will generate an n-bit sequence.  L.7  Secure Hash Algorithm Generator (SHA1G)  The input parameters to the SHA1G are fixed in code, but may be user modified. The length of the key, keylen should be chosen in the interval [160, 512]. Input Parameters: seedlen = 160 Xseed = 237c5f791c2cfe47bfb16d2d54a0d60665b20904 keylen = 160 Xkey = ec822a619d6ed5d9492218a7a4c5b15d57c61601 148   Description: For a detailed description of SHA1G (the FIPS 186 one-way function using SHA-1), visit http://www.cacr.math.waterloo.ca/hac/about/chap5.pdf.zip, especially p. 175. L.8 Blum-Blum-Shub Generator (BBSG)  The input parameters to the BBSG are not fixed in code. They are variable parameters, which are time dependent. The three required parameters are two primes, p and q, and a random integer s. Input Parameters: Two primes p and q such that each is congruent to 3 modulo 4. A random integer s (the seed), selected in the interval [1, pq-1] such that gcd(s,pq) = 1. The parameters p, q and s are not fixed in code; thus, the user will not be able to reconstruct the original sequence because these values will vary (i.e., they are dependent on the system time). To reproduce a sequence the user must modify the code to fix the variable input parameters. Description: For a detailed description of the Blum-Blum-Shub pseudo-random number generator, visit http://www.cacr.math.waterloo.ca/hac/about/chap5.pdf.zip, especially p. 186. Pate Williams' ANSI C reference implementation may be located at ftp://www.mindspring. com/users/pate/crypto/chap05/blumblum.c. L.9 Micali-Schnorr Generator (MSG)  The input parameters to the MSG are not fixed in code. They are variable parameters, which are time dependent. The four required parameters are two primes, p and q, an integer e, and the seed x0. Input Parameters: Two primes p and q. A parameter e, selected such that 1 < e <  = (p-1)(q-1), gcd(e, ) = 1, and 80e < N = floor(lg n + 1). A random sequence x0 (the seed) consisting of r (a function of e and n) bits is chosen. The parameters e, p, q, and x0 are not fixed in code; thus, the user will not be able to reconstruct the original sequence because these values will vary (i.e., they are dependent on the system time). To reproduce a sequence the user must modify the code to fix the variable input parameters. Description: For a detailed description of the Micali-Schnorr pseudo-random number generator, visit http://www.cacr.math.waterloo.ca/hac/about/chap5.pdf.zip, especially p. 186. Pate Williams'  149   ANSI C reference implementation may be located at ftp://www.mindspring. com/users/pate/crypto/chap05/micali.c.  L.10  Test Results  The following table depicts test-by-test failures for the above reference generators. Statistical Test Frequency Excessive Rejections X X X X X X X X X X X X X X X X X X X X X X X X X X X X X X Lacks Uniformity X X X X X X X X X X X X X Generator Modular Exponentiation Cubic Congruential Quadratic Congruential (Type Cubic Congruential XOR Micali-Schnorr Modular Exponentiation Cubic Congruential Quadratic Congruential (Type Modular Exponentiation Cubic Congruential Quadratic Congruential (Type XOR Cubic Congruential Quadratic Congruential (Type ANSI X9.17 Micali-Schnorr Modular Exponentiation Cubic Congruential Quadratic Congruential (Type Quadratic Congruential (Type XOR Modular Exponentiation XOR Modular Exponentiation Cubic Congruential Quadratic Congruential (Type XOR Modular Exponentiation Cubic Congruential Quadratic Congruential (Type XOR  I)  Block Frequency Cusum  I)  Runs  I)  Rank Spectral Aperiodic Templates  II)  X  I) II)  X X X X X X X X X X  Periodic Templates Approximate Entropy  I)  Serial  I)  Table M.1: Illustration of Rejection/Uniformity Failures  150   APPENDIX M: REFERENCES [1] M. Abramowitz and I. Stegun, Handbook of Mathematical Functions, Applied Mathematics Series. Vol. 55, Washington: National Bureau of Standards, 1964; reprinted 1968 by Dover Publications, New York. T. Cormen, C. Leiserson, & R. Rivest, Introduction to Algorithms. Cambridge, MA:The MIT Press, 1990. Gustafson et al., ""A computer package for measuring strength of encryption algorithms,"" Journal of Computers & Security. Vol. 13, No. 8, 1994, pp. 687697. U. Maurer, ""A Universal Statistical Test for Random Bit Generators,"" Journal of Cryptology. Vol. 5, No. 2, 1992, pp. 89-105. A. Menezes, et al., Handbook of Applied Cryptography. CRC Press, Inc., 1997. See http://www.cacr.math.uwaterloo.ca/hac/about/chap5.pdf.zip. W. Press, S. Teukolsky, W. Vetterling, Numerical Recipes in C : The Art of Scientific Computing, 2nd Edition. Cambridge University Press, January 1993. G. Marsaglia, DIEHARD Statistical Tests: http://stat.fsu.edu/~geo/diehard.html. T. Ritter, ""Randomness Tests and Related Topics,"" http://www.io.com/~ritter/ RES/RANDTEST.HTM. American National Standards Institute: Financial Institution Key Management (Wholesale), American Bankers Association, ANSI X9.17 - 1985 (Reaffirmed 1991). FIPS 140-1, Security Requirements for Cryptographic Modules, Federal Information Processing Standards Publication 140-1. U.S. Department of Commerce/NIST, National Technical Information Service, Springfield, VA, 1994. FIPS 180-1, Secure Hash Standard, Federal Information Processing Standards Publication 180-1. U.S. Department of Commerce/NIST, National Technical Information Service, Springfield, VA, April 17, 1995."
GX232-72-8613443	"4.4 Improper Integrals  141  which contain no singularities, and where the endpoints are also nonsingular. qromb, in such circumstances, takes many, many fewer function evaluations than either of the routines in 4.2. For example, the integral 2 0  x4 log(x +  x2 +1)dx Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  converges (with parameters as shown above) on the very first extrapolation, after just 5 calls to trapzd, while qsimp requires 8 calls (8 times as many evaluations of the integrand) and qtrap requires 13 calls (making 256 times as many evaluations of the integrand). CITED REFERENCES AND FURTHER READING: Stoer, J., and Bulirsch, R. 1980, Introduction to Numerical Analysis (New York: Springer-Verlag), 3.43.5. Dahlquist, G., and Bjorck, A. 1974, Numerical Methods (Englewood Cliffs, NJ: Prentice-Hall), 7.4.17.4.2. Ralston, A., and Rabinowitz, P. 1978, A First Course in Numerical Analysis, 2nd ed. (New York: McGraw-Hill), 4.102.  4.4 Improper Integrals For our present purposes, an integral will be ""improper"" if it has any of the following problems:  its integrand goes to a finite limiting value at finite upper and lower limits, but cannot be evaluated right on one of those limits (e.g., sin x/x at x = 0)  its upper limit is  , or its lower limit is -  it has an integrable singularity at either limit (e.g., x -1/2 at x = 0)  it has an integrable singularity at a known place between its upper and lower limits  it has an integrable singularity at an unknown place between its upper and lower limits  If an integral is infinite (e.g., 1 x-1 dx), or does not exist in a limiting sense  (e.g., - cos xdx), we do not call it improper; we call it impossible. No amount of clever algorithmics will return a meaningful answer to an ill-posed problem. In this section we will generalize the techniques of the preceding two sections to cover the first four problems on the above list. A more advanced discussion of quadrature with integrable singularities occurs in Chapter 18, notably 18.3. The fifth problem, singularity at unknown location, can really only be handled by the use of a variable stepsize differential equation integration routine, as will be given in Chapter 16. We need a workhorse like the extended trapezoidal rule (equation 4.1.11), but one which is an open formula in the sense of 4.1, i.e., does not require the integrand to be evaluated at the endpoints. Equation (4.1.19), the extended midpoint rule, is the best choice. The reason is that (4.1.19) shares with (4.1.11) the ""deep"" property of   142  Chapter 4.  Integration of Functions  having an error series that is entirely even in h. Indeed there is a formula, not as well known as it ought to be, called the Second Euler-Maclaurin summation formula, x x 1 N  f (x)dx = h[f +  3/2  +f  5/2  +f  7/2  +  + f  N -3/2  +f  N -1/2  ] (4.4.1) Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  B2 h2 (fN - f1 )+  4 B2k h2k (1 - 2-2k+1 )(f + (2k )!  (2k-1) N  -f  (2k-1) 1  )+   This equation can be derived by writing out (4.2.1) with stepsize h, then writing it out again with stepsize h/2, then subtracting the first from twice the second. It is not possible to double the number of steps in the extended midpoint rule and still have the benefit of previous function evaluations (try it!). However, it is possible to triple the number of steps and do so. Shall we do this, or double and  accept the loss? On the average, tripling does a factor 3 of unnecessary work, since the ""right"" number of steps for a desired accuracy criterion may in fact fall anywhere in the logarithmic interval implied by tripling. For doubling, the factor  is only 2, but we lose an extra factor of 2 in being unable to use all the previous evaluations. Since 1.732 < 2  1.414, it is better to triple. Here is the resulting routine, which is directly comparable to trapzd. #define FUNC(x) ((*func)(x)) float midpnt(float (*func)(float), float a, float b, int n) This routine computes the nth stage of refinement of an extended midpoint rule. func is input as a pointer to the function to be integrated between limits a and b, also input. When called with b n=1, the routine returns the crudest estimate of a f (x)dx. Subsequent calls with n=2,3,... (in that sequential order) will improve the accuracy of s by adding (2/3)  3n-1 additional interior points. s should not be modified between sequential calls. { float x,tnm,sum,del,ddel; static float s; int it,j; if (n == 1) { return (s=(b-a)*FUNC(0.5*(a+b))); } else { for(it=1,j=1;j  EPS 1.0e-6 JMAX 14 JMAXP (JMAX+1) K5  float qromo(float (*func)(float), float a, float b, float (*choose)(float(*)(float), float, float, int)) Romberg integration on an open interval. Returns the integral of the function func from a to b, using any specified integrating function choose and Romberg's method. Normally choose will be an open formula, not evaluating the function at the endpoints. It is assumed that choose triples the number of steps on each call, and that its error series contains only even powers of the number of steps. The routines midpnt, midinf, midsql, midsqu, midexp, are possible choices for choose. The parameters have the same meaning as in qromb. { void polint(float xa[], float ya[], int n, float x, float *y, float *dy); void nrerror(char error_text[]); int j; float ss,dss,h[JMAXP+1],s[JMAXP]; h[1]=1.0; for (j=1;j<=JMAX;j++) { s[j]=(*choose)(func,a,b,j); if (j >= K) { polint(&h[j-K],&s[j-K],K,0.0,&ss,&dss); if (fabs(dss) <= EPS*fabs(ss)) return ss; } h[j+1]=h[j]/9.0; This is where the assumption of step tripling and an even } error series is used. nrerror(""Too many steps in routing qromo""); return 0.0; Never get here. }  Don't be put off by qromo's complicated ANSI declaration. A typical invocation (integrating the Bessel function Y 0 (x) from 0 to 2) is simply #include ""nr.h"" float answer; ... answer=qromo(bessy0,0.0,2.0,midpnt);   144  Chapter 4.  Integration of Functions  The differences between qromo and qromb (4.3) are so slight that it is perhaps gratuitous to list qromo in full. It, however, is an excellent driver routine for solving all the other problems of improper integrals in our first list (except the intractable fifth), as we shall now see. The basic trick for improper integrals is to make a change of variables to eliminate the singularity, or to map an infinite range of integration to a finite one. For example, the identity b a  Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  f (x)dx =  1/a 1/b  1 1 f t2 t  dt  ab > 0  (4.4.2)  can be used with either b   and a positive, or with a  - and b negative, and works for any function which decreases towards infinity faster than 1/x 2 . You can make the change of variable implied by (4.4.2) either analytically and then use (e.g.) qromo and midpnt to do the numerical evaluation, or you can let the numerical algorithm make the change of variable for you. We prefer the latter method as being more transparent to the user. To implement equation (4.4.2) we simply write a modified version of midpnt, called midinf, which allows b to be infinite (or, more precisely, a very large number on your particular machine, such as 1  1030 ), or a to be negative and infinite. #define FUNC(x) ((*funk)(1.0/(x))/((x)*(x))) Effects the change of variable. refinement of evenly spaced nd positive as both. aa and  float midinf(float (*funk)(float), float aa, float bb, int n) This routine is an exact replacement for midpnt, i.e., returns the nth stage of the integral of funk from aa to bb, except that the function is evaluated at points in 1/x rather than in x. This allows the upper limit bb to be as large a the computer allows, or the lower limit aa to be as large and negative, but not bb must have the same sign. { float x,tnm,sum,del,ddel,b,a; static float s; int it,j;  b=1.0/aa; These two statements change the limits of integration. a=1.0/bb; if (n == 1) { From this point on, the routine is identical to midpnt. return (s=(b-a)*FUNC(0.5*(a+b))); } else { for(it=1,j=1;j  a)  (4.4.3)  If the singularity is at the upper limit, use the identity b a  1 f (x)dx = 1-  (b-a) 0  1-  t   1-  f (b - t  1 1-  )dt  (b > a)  (4.4.4)  If there is a singularity at both limits, divide the integral at an interior breakpoint as in the example above. Equations (4.4.3) and (4.4.4) are particularly simple in the case of inverse square-root singularities, a case that occurs frequently in practice: b a  f (x)dx =   b-a 0   2tf (a + t2 )dt  (b > a)  (4.4.5)  for a singularity at a, and b a  f (x)dx =  b-a  0  2tf (b - t2 )dt  (b > a)  (4.4.6)  for a singularity at b. Once again, we can implement these changes of variable transparently to the user by defining substitute routines for midpnt which make the change of variable automatically: #include   #define FUNC(x) (2.0*(x)*(*funk)(aa+(x)*(x))) float midsql(float (*funk)(float), float aa, float bb, int n) This routine is an exact replacement for midpnt, except that it allows for an inverse square-root singularity in the integrand at the lower limit aa. { float x,tnm,sum,del,ddel,a,b; static float s; int it,j; b=sqrt(bb-aa); a=0.0; if (n == 1) { The rest of the routine is exactly like midpnt and is omitted.   146 Similarly, #include    Chapter 4.  Integration of Functions  #define FUNC(x) (2.0*(x)*(*funk)(bb-(x)*(x))) float midsqu(float (*funk)(float), float aa, float bb, int n) This routine is an exact replacement for midpnt, except that it allows for an inverse square-root singularity in the integrand at the upper limit bb. { float x,tnm,sum,del,ddel,a,b; static float s; int it,j; b=sqrt(bb-aa); a=0.0; if (n == 1) { The rest of the routine is exactly like midpnt and is omitted.  Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  One last example should suffice to show how these formulas are derived in general. Suppose the upper limit of integration is infinite, and the integrand falls off exponentially. Then we want a change of variable that maps e -x dx into ()dt (with the sign chosen to keep the upper limit of the new variable larger than the lower limit). Doing the integration gives by inspection t=e so that x = x =a -x  or  x = - log t  (4.4.7)  f (x)dx =  t=e- t=0  a  f (- log t)  dt t  (4.4.8)  The user-transparent implementation would be #include   #define FUNC(x) ((*funk)(-log(x))/(x)) float midexp(float (*funk)(float), float aa, float bb, int n) This routine is an exact replacement for midpnt, except that bb is assumed to be infinite (value passed not actually used). It is assumed that the function funk decreases exponentially rapidly at infinity. { float x,tnm,sum,del,ddel,a,b; static float s; int it,j; b=exp(-aa); a=0.0; if (n == 1) { The rest of the routine is exactly like midpnt and is omitted.  CITED REFERENCES AND FURTHER READING: Acton, F.S. 1970, Numerical Methods That Work; 1990, corrected edition (Washington: Mathematical Association of America), Chapter 4.   4.5 Gaussian Quadratures and Or thogonal Polynomials  147  Dahlquist, G., and Bjorck, A. 1974, Numerical Methods (Englewood Cliffs, NJ: Prentice-Hall), 7.4.3, p. 294. Stoer, J., and Bulirsch, R. 1980, Introduction to Numerical Analysis (New York: Springer-Verlag), 3.7, p. 152.  Sample page from NUMERICAL RECIPES IN C: THE ART OF SCIENTIFIC COMPUTING (ISBN 0-521-43108-5) Copyright (C) 1988-1992 by Cambridge University Press. Programs Copyright (C) 1988-1992 by Numerical Recipes Software. Permission is granted for internet users to make one paper copy for their own personal use. Further reproduction, or any copying of machinereadable files (including this one) to any server computer, is strictly prohibited. To order Numerical Recipes books or CDROMs, visit website http://www.nr.com or call 1-800-872-7423 (North America only), or send email to directcustserv@cambridge.org (outside North America).  4.5 Gaussian Quadratures and Orthogonal Polynomials In the formulas of 4.1, the integral of a function was approximated by the sum of its functional values at a set of equally spaced points, multiplied by certain aptly chosen weighting coefficients. We saw that as we allowed ourselves more freedom in choosing the coefficients, we could achieve integration formulas of higher and higher order. The idea of Gaussian quadratures is to give ourselves the freedom to choose not only the weighting coefficients, but also the location of the abscissas at which the function is to be evaluated: They will no longer be equally spaced. Thus, we will have twice the number of degrees of freedom at our disposal; it will turn out that we can achieve Gaussian quadrature formulas whose order is, essentially, twice that of the Newton-Cotes formula with the same number of function evaluations. Does this sound too good to be true? Well, in a sense it is. The catch is a familiar one, which cannot be overemphasized: High order is not the same as high accuracy. High order translates to high accuracy only when the integrand is very smooth, in the sense of being ""well-approximated by a polynomial."" There is, however, one additional feature of Gaussian quadrature formulas that adds to their usefulness: We can arrange the choice of weights and abscissas to make the integral exact for a class of integrands ""polynomials times some known function W (x)"" rather than for the usual class of integrands ""polynomials."" The function W (x) can then be chosen to remove integrable singularities from the desired integral. Given W (x), in other words, and given an integer N , we can find a set of weights wj and abscissas xj such that the approximation b a N  W (x)f (x)dx  j =1  wj f (xj )  (4.5.1)  is exact if f (x) is a polynomial. For example, to do the integral 1 -1  exp(- cos2 x)  dx 1 - x2  (4.5.2)  (not a very natural looking integral, it must be admitted), we might well be interested in a Gaussian quadrature formula based on the choice 1 W (x) =  1 - x2 (4.5.3)  in the interval (-1, 1). (This particular choice is called Gauss-Chebyshev integration, for reasons that will become clear shortly.)"
GX068-46-5759442	"Home     Manual     Packages     Global Index     Keywords     Quick Reference          /*    GCD.I    GCD, LCM, and prime factorization routines.     $Id$  */ /*    Copyright (c) 1995.  The Regents of the University of California.                     All rights reserved.  */   func  gcd  (a, b) /* DOCUMENT  gcd (a,b)      returns the GCD (greatest common divisor) of A and B, which must      be one of the integer data types.  A and B may be conformable       arrays; the semantics of the  gcd   call  are the same as any other      binary operation.  Uses Euclid's celebrated algorithm.      The absolute values of A and B are taken before the operation      commences; if either A or B is 0, the return value will be 0.     SEE ALSO:  lcm ,  is_prime ,  factorize   */ {   a=  abs (a);   b=  abs (b);   c=  min (a, b);   a=  max (a, b);   b= c;          /* simplifies c=0 case */    if ( dimsof (a)(1)) {     /*  array  case */      for (list= where (c) ;  numberof (list) ; list= where (c)) {       b(list)= bl= c(list);       c(list)= a(list) % bl;       a(list)= bl;     }    } else {      /*  scalar  case can be less baroque */     while (c) {       b= c;       c= a % b;       a= b;     }   }    return b; }   func  lcm  (a, b) /* DOCUMENT  lcm (a,b)      returns the LCM (least common multiple) of A and B, which must      be one of the integer data types.  A and B may be conformable       arrays; the semantics of the  lcm   call  are the same as any other      binary operation.      The absolute values of A and B are taken before the operation      commences; if either A or B is 0, the return value will be 0.     SEE ALSO:  gcd ,  is_prime ,  factorize   */ {   d=  gcd (a, b);   /* two potential problems: zero divide and overflow - handle the      first but not the  second  */   return  abs (a*b)/(d+!d); }    func  is_prime  (x) /* DOCUMENT  is_prime (x)       return non-zero if and only if X (which must be a  scalar  integer)      is prime.  May return a false positive if X is greater than about      3e9, since at most 20000 candidate factors are checked.      The absolute value of X is taken first; zero is not prime, but 1 is.     SEE ALSO:  gcd ,  lcm ,  factorize   */ {   x= long( abs (x));   if (x<2) return x==1;    /*  make  a list of factors which includes 2, 3, and all larger       odd numbers not divisible by 3 less or equal to  sqrt (x) */    top=  min (long(( sqrt (x)+8.)/3.+0.5), 20000);    factors= ((3* indgen (2:top))/2)*2 - 7;   factors(1:2)= [2,3];   return  allof (x%factors); }    func  factorize  (x) /* DOCUMENT  factorize (x)      return list of prime factors of X and their powers as an n-by-2       array.  May  include  a large non-prime factor if X exceeds 3e9.       In any event, product(result(,1)^result(,2)) will equal  abs (X).       X must be a  scalar  integer type.     SEE ALSO:  gcd ,  lcm ,  is_prime   */ {   x= long( abs (x));   if (x<2) return [[x],[1]];    /* first get rid of any prime factors less than 102 */   primes= [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,     71,73,79,83,89,97,101];   primes= primes( where (!(x%primes)));    powers=  _fact_extract (primes, x);   /* returns ""deflated"" x */    if (x>1) {      /* large prime factors  require  a less direct approach */      top=  min (long(( sqrt (x)+2.)/3.+0.5), 20000);     if (top>=35) {       /* trial divisors are all odd numbers 103 or greater which are    not divisible by three and do not exceed  sqrt (x) */        trial= ((3* indgen (35:top))/2)*2 - 1;       /* discard all trial divisors which do not divide x */       trial= trial( where (!(x%trial)));        /* the smallest remaining divisor must be prime -  remove  it and   all its subsequent multiples to find the next prime divisor   and so on until the list contains only primes */       list= trial;        for (n=0 ;  numberof (trial) ; ++n) {  list(n+1)= trial(1);  trial= trial( where (trial%trial(1)));       }       if (n) {  trial= list(1:n);  grow, primes, trial;   grow, powers,  _fact_extract (trial,x);       }     }     if (x>1) {        grow , primes, [x];        grow , powers, [1];     }   }    return [primes, powers]; }    func  _fact_extract  (primes, &x) {   if ( is_void (primes)) return [];   /* first get largest power of each prime less than or equal x */    powers= long( log (x)/ log (primes)+1.e-6);   factors=  gcd (primes^powers, x);    x/= long( exp ( sum ( log (factors)))+0.5);    return long( log (factors)/ log (primes)+0.5); }"
GX044-56-11098914	CHARMM c28b1 ewald.doc     File:  Ewald  -=-    Node:  Top    Up : ( commands.doc ) -=-   Next :  Syntax  -=-   Previous :  Top                         The Ewald Summation method    Invoking the Ewald summation for calculating the electrostatic interactions  can be specified any time the nbond specification parser is invoked.  See   the syntax section for a list of all commands that invoke this parser.    Prerequisite reading:  nbonds.doc   * Menu:  *  Syntax ::          Syntax of the Ewald summation specification *  Defaults ::        Defaults used in the specification *  Function ::        Description of the options *  Discussion ::      More general discussion of the algorithm    File:  Ewald  -=-    Node:  Syntax    Up :  Top  -=-   Next :  Defaults  -=-   Previous :  Top  [SYNTAX EWALD]  {  NBONds          }        {  nonbond-spec                   } {  UPDAte          }        {                                 } {  ENERgy          }        {                                 } {  MINImize        }        {                                 } {  DYNAmics        }        {                                 }   The keywords are:  nonbond-spec::= [ method-spec ]                 { [ NOEWald ]                                          }                {                                                      } method-spec::= {   EWALd [ewald-spec] { [ NOPMewald [std-ew-spec] ] } }                {                      {   PMEWald [pmesh-spec]      } }   ewald-spec::=   KAPPa real  [erfc-spec]  std-ew-spec::= { [ KMAX integer ]                        } KSQMAX integer                { KMXX integer KMXY integer KMXZ integer  }  pmesh-spec::=   FFTX int FFTY int FFTZ int  ORDEr integer [QCOR real (***) ]  erfc-spec::=    { SPLIne      { [EWMIn real] [EWMAx real] [EWNPts int] } }                 { INTErpolate {                                        } }                 {                                                        }                 { ABROmowitz                                             }                 { CHEBychev                                              }                 { EXACt_high_precision                                   }                 { LOWPrecision_exact                                     }                 { ERFMode int                                            }    File:  Ewald  -=-    Node:  Defaults    Up :  Top  -=-   Next :  Function  -=-   Previous :  Syntax  The defaults for the ewald summation are set internally and are currently set to NOEWald, KAPPa=1.0, KMAX=5, KSQMax=27, and NOPMewald, KAPPa=1.0, FFTX=FFTY=FFTZ=32, ORDEr=4, QCOR=1.0  Recommended values for Ewald are:    EWALD PMEWald KAPPa 0.34 ORDEr 6 -     FFTX intboxvx FFTY intboxvy FFTZ intboxvz  -    CTOFNB 12.0 CUTNB 14.0 QCOR 1.0(***)  Where intboxv* is an integer value similar to or larger than the corresponding unit cell dimension that has prime factors of 2,3, and 5 only (2,3 preferred). grid point spacing should be between 0.8 and 1.2 Angstroms.  These recommended values should give relative force errors of roughly 10**-5. To reduce the total PME cost at the expense of accuracy, decrease the cutoff distances while increasing KAPPa (keep the product near 4) reduces the real space cost.  To reduce the K-space cost, either reduce ORDEr from 6 to 4 or increase the grid spacing up to perhaps 1.5 Angstroms.  (***) The QCOR value should be 1.0 for vacuum, solid, or finite systems. For periodic systems in solution, it should be reduced (or set to zero) by an amount that depends on how the net charge is distributed and on the effective dielectric constant.  For a treatise on this correction term, see: S. Bogusz, T. Cheatham, and B. Brooks, JCP (1998) 108, 7070-7084 and references contained therein (esp. Hummer and Levy).    File:  Nbonds  -=-    Node:  Function    Up :  Top  -=-   Previous :  Defaults  -=-   Next :  Discussion   i)   The EWALD keyword invokes the Ewald summation for calculation of  electrostatic interactions in periodic, neutral systems.  The formulation of  the Ewald summation dictates that the primary system must be neutral.  If  otherwise, the summation is not formally correct and some  convergence problems may result.  The NOEWald (default) suppresses the Ewald  method for calculating electrostatic interactions.  Van der waals  options VSHIFT and VSWITCH are supported with ewald.  The algorithm currently supports the atom and group nonbond lists and the CRYSTAL facilty  must be used.  The PMEWald keyword invokes the Particle Mesh Ewald algorithm for the reciprocal space summation.  For details on the PME method, see J. Chem. Phys. 103:8577 (1995).  The EWALd algorithm is limited to CUBIC, TETRAGONAL, and ORTHORHOMBIC unit cells.  The PMEWald algorithm supports all unit cells that are supported by the CRYSTAL facility.   ii)  The KAPPa keyword, followed by a real number governs the width of the  Gaussian distribution central to the Ewald method.  An approximate value of kappa can be chosen by taking KAPPa=5/CTOFNB.  This is fairly conservative. Values of 4/CTOFNB lead to small force errors (roughly 10**-5).  See discussion section for details on choosing an optimum value of KAPPa.  iii) The KMAX key word is the number of kvectors (or images of the  primary unit cell) that will be summed in any direction.  It is the  radius of the Ewald summation.  For orthorombic cells, the value of  kmax may be independently specified in the x, y, and z directions with the keywords KMXX, KMXY, and KMXZ.  In the PME version, the number of  FFT grid points for the charge mesh is specified by FFTX, FFTY, and FFTZ.   iv) The KSQMax key word should be chosen between  KMAX squared and 3 times KMAX squared.   v) An appropriate, although not optimal, set of parameters can be  chosen by taking KAPPA=5/CTOFNB and KMAX=KAPPa*boxlength. The actual  values should then be performanced optimized for your particular system. For the PME method, FFTX should be approximately the box length in Angstroms. (for efficiency, FFTX should be a multiple of powers of 2,3, and 5).     IMPORTANT NOTE::: THE SUGGESTION THAT FFTX, FFTY, AND FFTZ HAVE    NO PRIME FACTORS OTHER THAN 2, 3, AND 5 SEEMS TO BE A REQUIREMENT.    LARGE ERRORS IN THE FORCE ARE OBSERVED WHEN THIS CONDITION IS NOT MET.    FUTURE VERSIONS OF CHARMM WILL FLAG THIS AS AN ERROR CONDITION.  ORDEr specifies the order of the B-spline interpolation, e.g. cubic is order 4 (default), fifth degree is ORDEr 6.  The ORDEr must be an even number and at least 4.   vi) EWALd runs in parallel on both shared (PARVECT) and distributed memory parallel computers.  PME runs in parallel on distributed memory computers.  vii) several algorithms are available for the calculation of the complimentary error function, erfc(x).  EXACt and LOWPrecision use an interative technique described in section 6.2 of Numerical Recipies.  ABRO and CHEB are polynomial approximations.  A lookup table (filled at the beginning of the simulation using the EXACt method) can be used with either a linear (INTE) of cubic  spline (SPLINe) interpolation.  SPLIne is recommended.  viii) Ewald with MMFF  A version of EWALD was developed for MMFF.  The usual MMFF electrostatic term: qq/(r+d)  is split into two terms:  qq/r -  qq*d/(r*(r+d)) The first term is handled by the Ewald method in the usual manner (real-space and k-space parts) and the second term is truncated at the cutoff distance using a switching function (from CTONNB to CTOFNB). Since the second term is quite small at the cutoff distance, the use of a switching function should not introduce significant artificial forces.    File:  Ewald  -=-    Node:  Discussion    Up :  Top  -=-   Previous :  Function  -=-   Next :  Top            The Ewald Summation in Molecular Dynamics Simulation   The electrostatic energy of a periodic system can be expressed by a lattice   sum over all pair interactions and over all lattice vectors excluding the i=j term in the primary box.  Summations carried out in this simple  way have been shown to be conditionally convergent.  The method developed by  Ewald, in essence, mathematically transforms  this fairly straightforward   summation to two more complicated but rapidly convergent sums.  One summation  is carried out in reciporcal space while the other is carried out in real  space.  Based on the formulation by Ewald, the simple lattice sum can be reformulated to give absolutely convergent summations which define the principal value of the electrostatic potential, called the intrinsic potential. Given the periodicity present in both crystal calculations and in dynamics  simulations using periodic boundary conditions,  the Ewald formulation becomes  well suited for the calculation of the electrostatic energy and force. If we  consider a system of point charges in the unit or primary cell, we can specify  its charge density by    ro(r) = sum_i [ q_i * delta(r-r_i)]   In the Ewald method  this distribution is replaced by two other distributions   ro_1(r) = sum_i [ q_i ( delta(r-r_i) - f(r-r_i)]  and  ro_2(r) = sum_i [q_i f(r-r_i)  such that the sum of the two recovers the original.  The distribution, f(r), is a spherical distribution generally taken to be Gaussian, the width of the gaussian dictated by the parameter, KAPPa.  The charge distributions are situated on the ion lattice positions, but integrate to zero.  The potential from the distribution ro_1(r) is a short range potential evaluated in a direct real space summation (truncated at CTOFNB).  The diffuse charge distribution placed on the lattice sites reduces to the potential of the corresponding point charge at large r. ro_2(r), being a continuous distribution of Gaussians situated on the periodic lattice positions, is a smoothly varying function of r and thus is well approximated by a superposition of continuous functions.  This distribution is, therefore, expanded in a Fourier series and the potential is obtained by solving the Poisson equation.  The point of splitting the problem into two parts, is that by a suitable choice of the parameter KAPPa we can get very good convergence of both parts of the summation.  For the real space part of the energy, we choose kappa so that the complementary error function term, erfc(kappa*r) decreases rapidly enough with r to make it a good approximation to take only nearest images in the sum and neglect the value for which r > CTOFNB.  The reciprocal space sums are rapidly convergent and a spherical cutoff in k space is applied so that the sum over k becomes a sum over {l,m,n}, with (l**2+m**2+n**2) < or = to KSQMAX A large value of KAPPa means that the real space sum is more rapidly convergent but the reciprocal space sum is less rapid.  In practice one chooses KAPPa to give good convergence at the cutoff radius, CTOFNB.  KMAX is then chosen to such that the reciprocal space calculation converges.  The equation (KMAX/(box length)=KAPPa may be used as a rough guide.  Optimization with respect to the timing trade offs, ie.  how much time is spent in real space vs k-space should be performed before a lengthy production run.  The CCP5 notes in several articles in 1993 cover some possible optimization strategies and criteria although a simple line search will suffice.  Complete optimiztion of the ewald method for a particular application requires optimizing CTOFNB, KAPPa, and KMAX.  A discussion of optimization and error analysis can be found in Kolfka and Perram, Molecular Simulation, 9, 351 (1992).   For PME, see Feller, Pastor, Rojnuckarin, Bogusz, and Brooks. J. Phys. Chem., 100, 42, 17011 (1996) and some of Tom Darden's published work.              NHLBI/LBC Computational Biophysics         CHARMM Documentation /   Rick_Venable@nih.gov
GX047-41-13597000	Next:   The treatment of endothermic    Up:   endep    Previous:   The endep_diff code to           Discrete two-body reactions       In this section we discuss the calculation of energy depositon to secondary particles for discrete two-body reactions.  Suppose that particles 1 and2 interact to form paricles  x  and y .  Let  m j  denote the mass of particle  j  for  j  = 1, 2,  x , and y , and let  v j  be its velocity in the laboratory frame.  Then the kinetic of particle  j  in the laboratory frame is        E j  =  m j v j 2 ,   We let  W j *  denote the excitation level of the  j -th particle, and  Q 0  the contribution of the mass difference to the energy of the  reaction,             Q 0  = ( m 1  +  m 2  -  m x  -  m y ) c 2 .     (1)      If particle2 is at rest in the laboratory frame, then conservation of energy implies that             E 1  +  Q  =  E x  +  E y ,     (2)      where        Q  =  Q 0  + ( W 1 *  +  W 2 * ) - ( W x *  +  W y * ).      The kinetic energies  E x  and  E y  of the particles  x  and y  depend on the angles at which they are ejected.  The  endep  code calculates the average values of  E x  and  E y  based on the probability-density data for the angles (    = 1 data). Because this data is given in terms of the center-of-mass frame, we have to make a transformation to laboratory coordinates before we compute the average.  The arguments given here are based on Newtonian mechanics, so it is assumed that we are dealing with particles that are not too energetic.  We shall concentrate our attention on  E x  since by a choice of the labels  x  and y , this represents the kinetic energy of either secondary particle.    The following derivation of a formula for  E x  in terms of  E 1  and Q  is based on the reference[ 1 , pp.  91-94].  The plan of attack is to transform to center-of-mass coordinates and work out the kinematics there, and then transform back to the laboratory frame.  We use primes to denote quantities in center-of-mass coordinates.  Thus, if  V 0  denotes the velocity of the center of mass,             V 0  =  ,     (3)      then    v 1 ' =  v 1  -  V 0 , etc.  It follows from conservation of momentum that        m 1 v 1 ' = -  m 2 v 2 ',   and from this we may derive the relations             v 1 ' =  ( v 1 ' -  v 2 ') and  v 2 ' =  ( v 1 ' -  v 2 ').     (4)      These relations are useful because they represent  v 1 ' and v 2 ' in terms of             v 1 ' -  v 2 ' =  v 1  -  v 2  =  v 1 .     (5)      The same momentum conservation argument applied to the secondary particles shows that             v x ' =  ( v x ' -  v y ') and  v y ' =  ( v x ' -  v y ').     (6)         Let us now consider the consequences of energy conservation in the center-of-mass system.  It follows from the definition( 3 ) of  V 0  that        m 1 v 1 2  +  m 2 v 2 2  = ( m 1  +  m 2 ) V 0 2  +  m 1 v 1 ' 2  +  m 2 v 2 ' 2 ,   so that  E 1  in the the energy equation( 2 ) may be replaced by        E 1  =  ( m 1  +  m 2 ) V 0 2  +  E 1 ' +  E 2 '.   Likewise, under the assumption that    m 1  +  m 2     m x  +  m y , we may write the right-hand side of( 2 ) as        E x  +  E y  =  ( m x  +  m y ) V 0 2  +  E x ' +  E y '.   In writing this equation, we have neglected a term equal to       ( m x  +  m y )  -  V 0 V 0 ,   and if this difference is not small relative to  Q , we should not be using Newtonian mechanics.  In this same vein, upon neglecting the difference        ( m x  +  m y  -  m 1  -  m 2 ) V 0 2 ,   the energy equation in center-of-mass coordinates takes the form             E 1 ' +  E 2 ' +  Q  =  E x ' +  E y '.     (7)         We now perform some algebraic manipulations, using ( 4 ) and( 6 ) to derive from( 7 ) an equation for  E x ' in terms of E 1 .  We begin by expressing all of the kinetic energies in terms of squares of velocity differences,                ( v 1 ' -  v 2 ')  +  ( v 1 ' -  v 2 ')  +  Q              =  ( v x ' -  v y ')  +  ( v x ' -  v y ') .           Upon combining terms and using the relation( 5 ), we find that         +  Q  =  ( v x ' -  v y ') 2 .   If we again use the first of equations( 6 ), we obtain an expression for  E x ',             E x ' =  v x ' 2  =   +  Q .     (8)             Figure 1:  The relationship    between velocities.   In order to transform( 8 ) into the laboratory    frame, we need a relation between the velocities  v x  and  v x '    depending on the collision angle  in center-of-mass coordinates. In order to do this, we use the    fact that  v x  is the vector sum of  v x ' and    the velocity  V 0  of the center of mass. See Fig.1. With    the notation that |  V 0 | is the length of V 0 ,    we find that           v x 2  =  v x ' 2  +  V 0 2  +2|  v x '||  V 0 | cos .   In ( 8 ) we make the approximation that    m x  +  m y     m 1  +  m 2 .  Then, with the notation              =  ,  =  ,  =  ,     (9)      it follows from( 3 ) that we have             E x  = (  +  ) E 1  +  Q  + 2 ( E 1  +  Q ) E 1 cos .     (10)         The library data for the angular distribution (    = 1 data) is given as the probability density    p ( E 1 , ) with respect to the center-of-mass collision cosine         = cos .   Consequently, in order to calculate the average secondary energy        E x  =  E x p ( E 1 , )d ,   we multiply( 10 ) by  p  and integrate with respect to ,             E x  = (  +  ) E 1  +  Q  + 2 ( E 1  +  Q ) E 1 p ( E 1 , ) d .     (11)              Subsections      The treatment of endothermic reactions near the threshold                               Next:   The treatment of endothermic    Up:   endep    Previous:   The endep_diff code to
GX047-50-12451246	CHARMM c30a1 ewald.doc     File:  Ewald  -=-    Node:  Top    Up : ( commands.doc ) -=-   Next :  Syntax  -=-   Previous :  Top                         The Ewald Summation method    Invoking the Ewald summation for calculating the electrostatic interactions  can be specified any time the nbond specification parser is invoked.  See   the syntax section for a list of all commands that invoke this parser.    Prerequisite reading:  nbonds.doc   * Menu:  *  Syntax ::          Syntax of the Ewald summation specification *  Defaults ::        Defaults used in the specification *  Function ::        Description of the options *  Discussion ::      More general discussion of the algorithm    File:  Ewald  -=-    Node:  Syntax    Up :  Top  -=-   Next :  Defaults  -=-   Previous :  Top  [SYNTAX EWALD]  {  NBONds          }        {  nonbond-spec                   } {  UPDAte          }        {                                 } {  ENERgy          }        {                                 } {  MINImize        }        {                                 } {  DYNAmics        }        {                                 }   The keywords are:  nonbond-spec::= [ method-spec ]                 { [ NOEWald ]                                          }                {                                                      } method-spec::= {   EWALd [ewald-spec] { [ NOPMewald [std-ew-spec] ] } }                {                      {   PMEWald [pmesh-spec]      } }   ewald-spec::=   KAPPa real  [erfc-spec]  std-ew-spec::= { [ KMAX integer ]                        } KSQMAX integer                { KMXX integer KMXY integer KMXZ integer  }  pmesh-spec::=   FFTX int FFTY int FFTZ int  ORDEr integer [QCOR real (***) ]  erfc-spec::=    { SPLIne      { [EWMIn real] [EWMAx real] [EWNPts int] } }                 { INTErpolate {                                        } }                 {                                                        }                 { ABROmowitz                                             }                 { CHEBychev                                              }                 { EXACt_high_precision                                   }                 { LOWPrecision_exact                                     }                 { ERFMode int                                            }    File:  Ewald  -=-    Node:  Defaults    Up :  Top  -=-   Next :  Function  -=-   Previous :  Syntax  The defaults for the ewald summation are set internally and are currently set to NOEWald, KAPPa=1.0, KMAX=5, KSQMax=27, and NOPMewald, KAPPa=1.0, FFTX=FFTY=FFTZ=32, ORDEr=4, QCOR=1.0  Recommended values for Ewald are:    EWALD PMEWald KAPPa 0.34 ORDEr 6 -     FFTX intboxvx FFTY intboxvy FFTZ intboxvz  -    CTOFNB 12.0 CUTNB 14.0 QCOR 1.0(***)  Where intboxv* is an integer value similar to or larger than the corresponding unit cell dimension that has prime factors of 2,3, and 5 only (2,3 preferred). grid point spacing should be between 0.8 and 1.2 Angstroms.  These recommended values should give relative force errors of roughly 10**-5. To reduce the total PME cost at the expense of accuracy, decrease the cutoff distances while increasing KAPPa (keep the product near 4) reduces the real space cost.  To reduce the K-space cost, either reduce ORDEr from 6 to 4 or increase the grid spacing up to perhaps 1.5 Angstroms.  (***) The QCOR value should be 1.0 for vacuum, solid, or finite systems. For periodic systems in solution, it should be reduced (or set to zero) by an amount that depends on how the net charge is distributed and on the effective dielectric constant.  For a treatise on this correction term, see: S. Bogusz, T. Cheatham, and B. Brooks, JCP (1998) 108, 7070-7084 and references contained therein (esp. Hummer and Levy).    File:  Nbonds  -=-    Node:  Function    Up :  Top  -=-   Previous :  Defaults  -=-   Next :  Discussion   i)   The EWALD keyword invokes the Ewald summation for calculation of  electrostatic interactions in periodic, neutral systems.  The formulation of  the Ewald summation dictates that the primary system must be neutral.  If  otherwise, the summation is not formally correct and some  convergence problems may result.  The NOEWald (default) suppresses the Ewald  method for calculating electrostatic interactions.  Van der waals  options VSHIFT and VSWITCH are supported with ewald.  The algorithm currently supports the atom and group nonbond lists and the CRYSTAL facilty  must be used.  The PMEWald keyword invokes the Particle Mesh Ewald algorithm for the reciprocal space summation.  For details on the PME method, see J. Chem. Phys. 103:8577 (1995).  The EWALd algorithm is limited to CUBIC, TETRAGONAL, and ORTHORHOMBIC unit cells.  The PMEWald algorithm supports all unit cells that are supported by the CRYSTAL facility.   ii)  The KAPPa keyword, followed by a real number governs the width of the  Gaussian distribution central to the Ewald method.  An approximate value of kappa can be chosen by taking KAPPa=5/CTOFNB.  This is fairly conservative. Values of 4/CTOFNB lead to small force errors (roughly 10**-5).  See discussion section for details on choosing an optimum value of KAPPa.  iii) The KMAX key word is the number of kvectors (or images of the  primary unit cell) that will be summed in any direction.  It is the  radius of the Ewald summation.  For orthorombic cells, the value of  kmax may be independently specified in the x, y, and z directions with the keywords KMXX, KMXY, and KMXZ.  In the PME version, the number of  FFT grid points for the charge mesh is specified by FFTX, FFTY, and FFTZ.   iv) The KSQMax key word should be chosen between  KMAX squared and 3 times KMAX squared.   v) An appropriate, although not optimal, set of parameters can be  chosen by taking KAPPA=5/CTOFNB and KMAX=KAPPa*boxlength. The actual  values should then be performanced optimized for your particular system. For the PME method, FFTX should be approximately the box length in Angstroms. (for efficiency, FFTX should be a multiple of powers of 2,3, and 5).     IMPORTANT NOTE::: THE SUGGESTION THAT FFTX, FFTY, AND FFTZ HAVE    NO PRIME FACTORS OTHER THAN 2, 3, AND 5 SEEMS TO BE A REQUIREMENT.    LARGE ERRORS IN THE FORCE ARE OBSERVED WHEN THIS CONDITION IS NOT MET.    FUTURE VERSIONS OF CHARMM WILL FLAG THIS AS AN ERROR CONDITION.  ORDEr specifies the order of the B-spline interpolation, e.g. cubic is order 4 (default), fifth degree is ORDEr 6.  The ORDEr must be an even number and at least 4.   vi) EWALd runs in parallel on both shared (PARVECT) and distributed memory parallel computers.  PME runs in parallel on distributed memory computers.  vii) several algorithms are available for the calculation of the complimentary error function, erfc(x).  EXACt and LOWPrecision use an interative technique described in section 6.2 of Numerical Recipies.  ABRO and CHEB are polynomial approximations.  A lookup table (filled at the beginning of the simulation using the EXACt method) can be used with either a linear (INTE) of cubic  spline (SPLINe) interpolation.  SPLIne is recommended.  viii) Ewald with MMFF  A version of EWALD was developed for MMFF.  The usual MMFF electrostatic term: qq/(r+d)  is split into two terms:  qq/r -  qq*d/(r*(r+d)) The first term is handled by the Ewald method in the usual manner (real-space and k-space parts) and the second term is truncated at the cutoff distance using a switching function (from CTONNB to CTOFNB). Since the second term is quite small at the cutoff distance, the use of a switching function should not introduce significant artificial forces.    File:  Ewald  -=-    Node:  Discussion    Up :  Top  -=-   Previous :  Function  -=-   Next :  Top            The Ewald Summation in Molecular Dynamics Simulation   The electrostatic energy of a periodic system can be expressed by a lattice   sum over all pair interactions and over all lattice vectors excluding the i=j term in the primary box.  Summations carried out in this simple  way have been shown to be conditionally convergent.  The method developed by  Ewald, in essence, mathematically transforms  this fairly straightforward   summation to two more complicated but rapidly convergent sums.  One summation  is carried out in reciporcal space while the other is carried out in real  space.  Based on the formulation by Ewald, the simple lattice sum can be reformulated to give absolutely convergent summations which define the principal value of the electrostatic potential, called the intrinsic potential. Given the periodicity present in both crystal calculations and in dynamics  simulations using periodic boundary conditions,  the Ewald formulation becomes  well suited for the calculation of the electrostatic energy and force. If we  consider a system of point charges in the unit or primary cell, we can specify  its charge density by    ro(r) = sum_i [ q_i * delta(r-r_i)]   In the Ewald method  this distribution is replaced by two other distributions   ro_1(r) = sum_i [ q_i ( delta(r-r_i) - f(r-r_i)]  and  ro_2(r) = sum_i [q_i f(r-r_i)  such that the sum of the two recovers the original.  The distribution, f(r), is a spherical distribution generally taken to be Gaussian, the width of the gaussian dictated by the parameter, KAPPa.  The charge distributions are situated on the ion lattice positions, but integrate to zero.  The potential from the distribution ro_1(r) is a short range potential evaluated in a direct real space summation (truncated at CTOFNB).  The diffuse charge distribution placed on the lattice sites reduces to the potential of the corresponding point charge at large r. ro_2(r), being a continuous distribution of Gaussians situated on the periodic lattice positions, is a smoothly varying function of r and thus is well approximated by a superposition of continuous functions.  This distribution is, therefore, expanded in a Fourier series and the potential is obtained by solving the Poisson equation.  The point of splitting the problem into two parts, is that by a suitable choice of the parameter KAPPa we can get very good convergence of both parts of the summation.  For the real space part of the energy, we choose kappa so that the complementary error function term, erfc(kappa*r) decreases rapidly enough with r to make it a good approximation to take only nearest images in the sum and neglect the value for which r > CTOFNB.  The reciprocal space sums are rapidly convergent and a spherical cutoff in k space is applied so that the sum over k becomes a sum over {l,m,n}, with (l**2+m**2+n**2) < or = to KSQMAX A large value of KAPPa means that the real space sum is more rapidly convergent but the reciprocal space sum is less rapid.  In practice one chooses KAPPa to give good convergence at the cutoff radius, CTOFNB.  KMAX is then chosen to such that the reciprocal space calculation converges.  The equation (KMAX/(box length)=KAPPa may be used as a rough guide.  Optimization with respect to the timing trade offs, ie.  how much time is spent in real space vs k-space should be performed before a lengthy production run.  The CCP5 notes in several articles in 1993 cover some possible optimization strategies and criteria although a simple line search will suffice.  Complete optimiztion of the ewald method for a particular application requires optimizing CTOFNB, KAPPa, and KMAX.  A discussion of optimization and error analysis can be found in Kolfka and Perram, Molecular Simulation, 9, 351 (1992).   For PME, see Feller, Pastor, Rojnuckarin, Bogusz, and Brooks. J. Phys. Chem., 100, 42, 17011 (1996) and some of Tom Darden's published work.              NHLBI/LBC Computational Biophysics         CHARMM Documentation /   Rick_Venable@nih.gov
GX047-72-1885899	CHARMM c27b2 ewald.doc     File:  Ewald  -=-    Node:  Top    Up : ( commands.doc ) -=-   Next :  Syntax  -=-   Previous :  Top                         The Ewald Summation method    Invoking the Ewald summation for calculating the electrostatic interactions  can be specified any time the nbond specification parser is invoked.  See   the syntax section for a list of all commands that invoke this parser.    Prerequisite reading:  nbonds.doc   * Menu:  *  Syntax ::          Syntax of the Ewald summation specification *  Defaults ::        Defaults used in the specification *  Function ::        Description of the options *  Discussion ::      More general discussion of the algorithm    File:  Ewald  -=-    Node:  Syntax    Up :  Top  -=-   Next :  Defaults  -=-   Previous :  Top  [SYNTAX EWALD]  {  NBONds          }        {  nonbond-spec                   } {  UPDAte          }        {                                 } {  ENERgy          }        {                                 } {  MINImize        }        {                                 } {  DYNAmics        }        {                                 }   The keywords are:  nonbond-spec::= [ method-spec ]                 { [ NOEWald ]                                          }                {                                                      } method-spec::= {   EWALd [ewald-spec] { [ NOPMewald [std-ew-spec] ] } }                {                      {   PMEWald [pmesh-spec]      } }   ewald-spec::=   KAPPa real  [erfc-spec]  std-ew-spec::= { [ KMAX integer ]                        } KSQMAX integer                { KMXX integer KMXY integer KMXZ integer  }  pmesh-spec::=   FFTX int FFTY int FFTZ int  ORDEr integer [QCOR real (***) ]  erfc-spec::=    { SPLIne      { [EWMIn real] [EWMAx real] [EWNPts int] } }                 { INTErpolate {                                        } }                 {                                                        }                 { ABROmowitz                                             }                 { CHEBychev                                              }                 { EXACt_high_precision                                   }                 { LOWPrecision_exact                                     }                 { ERFMode int                                            }    File:  Ewald  -=-    Node:  Defaults    Up :  Top  -=-   Next :  Function  -=-   Previous :  Syntax  The defaults for the ewald summation are set internally and are currently set to NOEWald, KAPPa=1.0, KMAX=5, KSQMax=27, and NOPMewald, KAPPa=1.0, FFTX=FFTY=FFTZ=32, ORDEr=4, QCOR=1.0  Recommended values for Ewald are:    EWALD PMEWald KAPPa 0.34 ORDEr 6 -     FFTX intboxvx FFTY intboxvy FFTZ intboxvz  -    CTOFNB 12.0 CUTNB 14.0 QCOR 1.0(***)  Where intboxv* is an integer value similar to or larger than the corresponding unit cell dimension that has prime factors of 2,3, and 5 only (2,3 preferred). grid point spacing should be between 0.8 and 1.2 Angstroms.  These recommended values should give relative force errors of roughly 10**-5. To reduce the total PME cost at the expense of accuracy, decrease the cutoff distances while increasing KAPPa (keep the product near 4) reduces the real space cost.  To reduce the K-space cost, either reduce ORDEr from 6 to 4 or increase the grid spacing up to perhaps 1.5 Angstroms.  (***) The QCOR value should be 1.0 for vacuum, solid, or finite systems. For periodic systems in solution, it should be reduced (or set to zero) by an amount that depends on how the net charge is distributed and on the effective dielectric constant.  For a treatise on this correction term, see: S. Bogusz, T. Cheatham, and B. Brooks, JCP (1998) 108, 7070-7084 and references contained therein (esp. Hummer and Levy).    File:  Nbonds  -=-    Node:  Function    Up :  Top  -=-   Previous :  Defaults  -=-   Next :  Discussion   i)   The EWALD keyword invokes the Ewald summation for calculation of  electrostatic interactions in periodic, neutral systems.  The formulation of  the Ewald summation dictates that the primary system must be neutral.  If  otherwise, the summation is not formally correct and some  convergence problems may result.  The NOEWald (default) suppresses the Ewald  method for calculating electrostatic interactions.  Van der waals  options VSHIFT and VSWITCH are supported with ewald.  The algorithm currently supports the atom and group nonbond lists and the CRYSTAL facilty  must be used.  The PMEWald keyword invokes the Particle Mesh Ewald algorithm for the reciprocal space summation.  For details on the PME method, see J. Chem. Phys. 103:8577 (1995).  The EWALd algorithm is limited to CUBIC, TETRAGONAL, and ORTHORHOMBIC unit cells.  The PMEWald algorithm supports all unit cells that are supported by the CRYSTAL facility.   ii)  The KAPPa keyword, followed by a real number governs the width of the  Gaussian distribution central to the Ewald method.  An approximate value of kappa can be chosen by taking KAPPa=5/CTOFNB.  This is fairly conservative. Values of 4/CTOFNB lead to small force errors (roughly 10**-5).  See discussion section for details on choosing an optimum value of KAPPa.  iii) The KMAX key word is the number of kvectors (or images of the  primary unit cell) that will be summed in any direction.  It is the  radius of the Ewald summation.  For orthorombic cells, the value of  kmax may be independently specified in the x, y, and z directions with the keywords KMXX, KMXY, and KMXZ.  In the PME version, the number of  FFT grid points for the charge mesh is specified by FFTX, FFTY, and FFTZ.   iv) The KSQMax key word should be chosen between  KMAX squared and 3 times KMAX squared.   v) An appropriate, although not optimal, set of parameters can be  chosen by taking KAPPA=5/CTOFNB and KMAX=KAPPa*boxlength. The actual  values should then be performanced optimized for your particular system. For the PME method, FFTX should be approximately the box length in Angstroms. (for efficiency, FFTX should be a multiple of powers of 2,3, and 5).     IMPORTANT NOTE::: THE SUGGESTION THAT FFTX, FFTY, AND FFTZ HAVE    NO PRIME FACTORS OTHER THAN 2, 3, AND 5 SEEMS TO BE A REQUIREMENT.    LARGE ERRORS IN THE FORCE ARE OBSERVED WHEN THIS CONDITION IS NOT MET.    FUTURE VERSIONS OF CHARMM WILL FLAG THIS AS AN ERROR CONDITION.  ORDEr specifies the order of the B-spline interpolation, e.g. cubic is order 4 (default), fifth degree is ORDEr 6.  The ORDEr must be an even number and at least 4.   vi) EWALd runs in parallel on both shared (PARVECT) and distributed memory parallel computers.  PME runs in parallel on distributed memory computers.  vii) several algorithms are available for the calculation of the complimentary error function, erfc(x).  EXACt and LOWPrecision use an interative technique described in section 6.2 of Numerical Recipies.  ABRO and CHEB are polynomial approximations.  A lookup table (filled at the beginning of the simulation using the EXACt method) can be used with either a linear (INTE) of cubic  spline (SPLINe) interpolation.  SPLIne is recommended.  viii) Ewald with MMFF  A version of EWALD was developed for MMFF.  The usual MMFF electrostatic term: qq/(r+d)  is split into two terms:  qq/r -  qq*d/(r*(r+d)) The first term is handled by the Ewald method in the usual manner (real-space and k-space parts) and the second term is truncated at the cutoff distance using a switching function (from CTONNB to CTOFNB). Since the second term is quite small at the cutoff distance, the use of a switching function should not introduce significant artificial forces.    File:  Ewald  -=-    Node:  Discussion    Up :  Top  -=-   Previous :  Function  -=-   Next :  Top            The Ewald Summation in Molecular Dynamics Simulation   The electrostatic energy of a periodic system can be expressed by a lattice   sum over all pair interactions and over all lattice vectors excluding the i=j term in the primary box.  Summations carried out in this simple  way have been shown to be conditionally convergent.  The method developed by  Ewald, in essence, mathematically transforms  this fairly straightforward   summation to two more complicated but rapidly convergent sums.  One summation  is carried out in reciporcal space while the other is carried out in real  space.  Based on the formulation by Ewald, the simple lattice sum can be reformulated to give absolutely convergent summations which define the principal value of the electrostatic potential, called the intrinsic potential. Given the periodicity present in both crystal calculations and in dynamics  simulations using periodic boundary conditions,  the Ewald formulation becomes  well suited for the calculation of the electrostatic energy and force. If we  consider a system of point charges in the unit or primary cell, we can specify  its charge density by    ro(r) = sum_i [ q_i * delta(r-r_i)]   In the Ewald method  this distribution is replaced by two other distributions   ro_1(r) = sum_i [ q_i ( delta(r-r_i) - f(r-r_i)]  and  ro_2(r) = sum_i [q_i f(r-r_i)  such that the sum of the two recovers the original.  The distribution, f(r), is a spherical distribution generally taken to be Gaussian, the width of the gaussian dictated by the parameter, KAPPa.  The charge distributions are situated on the ion lattice positions, but integrate to zero.  The potential from the distribution ro_1(r) is a short range potential evaluated in a direct real space summation (truncated at CTOFNB).  The diffuse charge distribution placed on the lattice sites reduces to the potential of the corresponding point charge at large r. ro_2(r), being a continuous distribution of Gaussians situated on the periodic lattice positions, is a smoothly varying function of r and thus is well approximated by a superposition of continuous functions.  This distribution is, therefore, expanded in a Fourier series and the potential is obtained by solving the Poisson equation.  The point of splitting the problem into two parts, is that by a suitable choice of the parameter KAPPa we can get very good convergence of both parts of the summation.  For the real space part of the energy, we choose kappa so that the complementary error function term, erfc(kappa*r) decreases rapidly enough with r to make it a good approximation to take only nearest images in the sum and neglect the value for which r > CTOFNB.  The reciprocal space sums are rapidly convergent and a spherical cutoff in k space is applied so that the sum over k becomes a sum over {l,m,n}, with (l**2+m**2+n**2) < or = to KSQMAX A large value of KAPPa means that the real space sum is more rapidly convergent but the reciprocal space sum is less rapid.  In practice one chooses KAPPa to give good convergence at the cutoff radius, CTOFNB.  KMAX is then chosen to such that the reciprocal space calculation converges.  The equation (KMAX/(box length)=KAPPa may be used as a rough guide.  Optimization with respect to the timing trade offs, ie.  how much time is spent in real space vs k-space should be performed before a lengthy production run.  The CCP5 notes in several articles in 1993 cover some possible optimization strategies and criteria although a simple line search will suffice.  Complete optimiztion of the ewald method for a particular application requires optimizing CTOFNB, KAPPa, and KMAX.  A discussion of optimization and error analysis can be found in Kolfka and Perram, Molecular Simulation, 9, 351 (1992).   For PME, see Feller, Pastor, Rojnuckarin, Bogusz, and Brooks. J. Phys. Chem., 100, 42, 17011 (1996) and some of Tom Darden's published work.              NHLBI/LBC Computational Biophysics Section         CHARMM Documentation /   Rick_Venable@nih.gov
GX049-17-1858239	CHARMM c29b1 ewald.doc     File:  Ewald  -=-    Node:  Top    Up : ( commands.doc ) -=-   Next :  Syntax  -=-   Previous :  Top                         The Ewald Summation method    Invoking the Ewald summation for calculating the electrostatic interactions  can be specified any time the nbond specification parser is invoked.  See   the syntax section for a list of all commands that invoke this parser.    Prerequisite reading:  nbonds.doc   * Menu:  *  Syntax ::          Syntax of the Ewald summation specification *  Defaults ::        Defaults used in the specification *  Function ::        Description of the options *  Discussion ::      More general discussion of the algorithm    File:  Ewald  -=-    Node:  Syntax    Up :  Top  -=-   Next :  Defaults  -=-   Previous :  Top  [SYNTAX EWALD]  {  NBONds          }        {  nonbond-spec                   } {  UPDAte          }        {                                 } {  ENERgy          }        {                                 } {  MINImize        }        {                                 } {  DYNAmics        }        {                                 }   The keywords are:  nonbond-spec::= [ method-spec ]                 { [ NOEWald ]                                          }                {                                                      } method-spec::= {   EWALd [ewald-spec] { [ NOPMewald [std-ew-spec] ] } }                {                      {   PMEWald [pmesh-spec]      } }   ewald-spec::=   KAPPa real  [erfc-spec]  std-ew-spec::= { [ KMAX integer ]                        } KSQMAX integer                { KMXX integer KMXY integer KMXZ integer  }  pmesh-spec::=   FFTX int FFTY int FFTZ int  ORDEr integer [QCOR real (***) ]  erfc-spec::=    { SPLIne      { [EWMIn real] [EWMAx real] [EWNPts int] } }                 { INTErpolate {                                        } }                 {                                                        }                 { ABROmowitz                                             }                 { CHEBychev                                              }                 { EXACt_high_precision                                   }                 { LOWPrecision_exact                                     }                 { ERFMode int                                            }    File:  Ewald  -=-    Node:  Defaults    Up :  Top  -=-   Next :  Function  -=-   Previous :  Syntax  The defaults for the ewald summation are set internally and are currently set to NOEWald, KAPPa=1.0, KMAX=5, KSQMax=27, and NOPMewald, KAPPa=1.0, FFTX=FFTY=FFTZ=32, ORDEr=4, QCOR=1.0  Recommended values for Ewald are:    EWALD PMEWald KAPPa 0.34 ORDEr 6 -     FFTX intboxvx FFTY intboxvy FFTZ intboxvz  -    CTOFNB 12.0 CUTNB 14.0 QCOR 1.0(***)  Where intboxv* is an integer value similar to or larger than the corresponding unit cell dimension that has prime factors of 2,3, and 5 only (2,3 preferred). grid point spacing should be between 0.8 and 1.2 Angstroms.  These recommended values should give relative force errors of roughly 10**-5. To reduce the total PME cost at the expense of accuracy, decrease the cutoff distances while increasing KAPPa (keep the product near 4) reduces the real space cost.  To reduce the K-space cost, either reduce ORDEr from 6 to 4 or increase the grid spacing up to perhaps 1.5 Angstroms.  (***) The QCOR value should be 1.0 for vacuum, solid, or finite systems. For periodic systems in solution, it should be reduced (or set to zero) by an amount that depends on how the net charge is distributed and on the effective dielectric constant.  For a treatise on this correction term, see: S. Bogusz, T. Cheatham, and B. Brooks, JCP (1998) 108, 7070-7084 and references contained therein (esp. Hummer and Levy).    File:  Nbonds  -=-    Node:  Function    Up :  Top  -=-   Previous :  Defaults  -=-   Next :  Discussion   i)   The EWALD keyword invokes the Ewald summation for calculation of  electrostatic interactions in periodic, neutral systems.  The formulation of  the Ewald summation dictates that the primary system must be neutral.  If  otherwise, the summation is not formally correct and some  convergence problems may result.  The NOEWald (default) suppresses the Ewald  method for calculating electrostatic interactions.  Van der waals  options VSHIFT and VSWITCH are supported with ewald.  The algorithm currently supports the atom and group nonbond lists and the CRYSTAL facilty  must be used.  The PMEWald keyword invokes the Particle Mesh Ewald algorithm for the reciprocal space summation.  For details on the PME method, see J. Chem. Phys. 103:8577 (1995).  The EWALd algorithm is limited to CUBIC, TETRAGONAL, and ORTHORHOMBIC unit cells.  The PMEWald algorithm supports all unit cells that are supported by the CRYSTAL facility.   ii)  The KAPPa keyword, followed by a real number governs the width of the  Gaussian distribution central to the Ewald method.  An approximate value of kappa can be chosen by taking KAPPa=5/CTOFNB.  This is fairly conservative. Values of 4/CTOFNB lead to small force errors (roughly 10**-5).  See discussion section for details on choosing an optimum value of KAPPa.  iii) The KMAX key word is the number of kvectors (or images of the  primary unit cell) that will be summed in any direction.  It is the  radius of the Ewald summation.  For orthorombic cells, the value of  kmax may be independently specified in the x, y, and z directions with the keywords KMXX, KMXY, and KMXZ.  In the PME version, the number of  FFT grid points for the charge mesh is specified by FFTX, FFTY, and FFTZ.   iv) The KSQMax key word should be chosen between  KMAX squared and 3 times KMAX squared.   v) An appropriate, although not optimal, set of parameters can be  chosen by taking KAPPA=5/CTOFNB and KMAX=KAPPa*boxlength. The actual  values should then be performanced optimized for your particular system. For the PME method, FFTX should be approximately the box length in Angstroms. (for efficiency, FFTX should be a multiple of powers of 2,3, and 5).     IMPORTANT NOTE::: THE SUGGESTION THAT FFTX, FFTY, AND FFTZ HAVE    NO PRIME FACTORS OTHER THAN 2, 3, AND 5 SEEMS TO BE A REQUIREMENT.    LARGE ERRORS IN THE FORCE ARE OBSERVED WHEN THIS CONDITION IS NOT MET.    FUTURE VERSIONS OF CHARMM WILL FLAG THIS AS AN ERROR CONDITION.  ORDEr specifies the order of the B-spline interpolation, e.g. cubic is order 4 (default), fifth degree is ORDEr 6.  The ORDEr must be an even number and at least 4.   vi) EWALd runs in parallel on both shared (PARVECT) and distributed memory parallel computers.  PME runs in parallel on distributed memory computers.  vii) several algorithms are available for the calculation of the complimentary error function, erfc(x).  EXACt and LOWPrecision use an interative technique described in section 6.2 of Numerical Recipies.  ABRO and CHEB are polynomial approximations.  A lookup table (filled at the beginning of the simulation using the EXACt method) can be used with either a linear (INTE) of cubic  spline (SPLINe) interpolation.  SPLIne is recommended.  viii) Ewald with MMFF  A version of EWALD was developed for MMFF.  The usual MMFF electrostatic term: qq/(r+d)  is split into two terms:  qq/r -  qq*d/(r*(r+d)) The first term is handled by the Ewald method in the usual manner (real-space and k-space parts) and the second term is truncated at the cutoff distance using a switching function (from CTONNB to CTOFNB). Since the second term is quite small at the cutoff distance, the use of a switching function should not introduce significant artificial forces.    File:  Ewald  -=-    Node:  Discussion    Up :  Top  -=-   Previous :  Function  -=-   Next :  Top            The Ewald Summation in Molecular Dynamics Simulation   The electrostatic energy of a periodic system can be expressed by a lattice   sum over all pair interactions and over all lattice vectors excluding the i=j term in the primary box.  Summations carried out in this simple  way have been shown to be conditionally convergent.  The method developed by  Ewald, in essence, mathematically transforms  this fairly straightforward   summation to two more complicated but rapidly convergent sums.  One summation  is carried out in reciporcal space while the other is carried out in real  space.  Based on the formulation by Ewald, the simple lattice sum can be reformulated to give absolutely convergent summations which define the principal value of the electrostatic potential, called the intrinsic potential. Given the periodicity present in both crystal calculations and in dynamics  simulations using periodic boundary conditions,  the Ewald formulation becomes  well suited for the calculation of the electrostatic energy and force. If we  consider a system of point charges in the unit or primary cell, we can specify  its charge density by    ro(r) = sum_i [ q_i * delta(r-r_i)]   In the Ewald method  this distribution is replaced by two other distributions   ro_1(r) = sum_i [ q_i ( delta(r-r_i) - f(r-r_i)]  and  ro_2(r) = sum_i [q_i f(r-r_i)  such that the sum of the two recovers the original.  The distribution, f(r), is a spherical distribution generally taken to be Gaussian, the width of the gaussian dictated by the parameter, KAPPa.  The charge distributions are situated on the ion lattice positions, but integrate to zero.  The potential from the distribution ro_1(r) is a short range potential evaluated in a direct real space summation (truncated at CTOFNB).  The diffuse charge distribution placed on the lattice sites reduces to the potential of the corresponding point charge at large r. ro_2(r), being a continuous distribution of Gaussians situated on the periodic lattice positions, is a smoothly varying function of r and thus is well approximated by a superposition of continuous functions.  This distribution is, therefore, expanded in a Fourier series and the potential is obtained by solving the Poisson equation.  The point of splitting the problem into two parts, is that by a suitable choice of the parameter KAPPa we can get very good convergence of both parts of the summation.  For the real space part of the energy, we choose kappa so that the complementary error function term, erfc(kappa*r) decreases rapidly enough with r to make it a good approximation to take only nearest images in the sum and neglect the value for which r > CTOFNB.  The reciprocal space sums are rapidly convergent and a spherical cutoff in k space is applied so that the sum over k becomes a sum over {l,m,n}, with (l**2+m**2+n**2) < or = to KSQMAX A large value of KAPPa means that the real space sum is more rapidly convergent but the reciprocal space sum is less rapid.  In practice one chooses KAPPa to give good convergence at the cutoff radius, CTOFNB.  KMAX is then chosen to such that the reciprocal space calculation converges.  The equation (KMAX/(box length)=KAPPa may be used as a rough guide.  Optimization with respect to the timing trade offs, ie.  how much time is spent in real space vs k-space should be performed before a lengthy production run.  The CCP5 notes in several articles in 1993 cover some possible optimization strategies and criteria although a simple line search will suffice.  Complete optimiztion of the ewald method for a particular application requires optimizing CTOFNB, KAPPa, and KMAX.  A discussion of optimization and error analysis can be found in Kolfka and Perram, Molecular Simulation, 9, 351 (1992).   For PME, see Feller, Pastor, Rojnuckarin, Bogusz, and Brooks. J. Phys. Chem., 100, 42, 17011 (1996) and some of Tom Darden's published work.              NHLBI/LBC Computational Biophysics         CHARMM Documentation /   Rick_Venable@nih.gov
GX055-73-15836544	"home                manual                quick ref.                packages                index                keywords                examples                              file: tmp/gcd.i        /*      GCD.I      GCD, LCM, and prime factorization routines.         $Id$    */   /*    Copyright (c) 1995.  The Regents of the University of California.                       All rights reserved.  */       func  gcd( a, b)    /* DOCUMENT  gcd( a,b)        returns the GCD (greatest common divisor) of A and B, which must        be one of the integer data types.  A and B may be conformable        arrays; the semantics of the gcd call are the same as any other        binary operation.  Uses Euclid's celebrated algorithm.        The absolute values of A and B are taken before the operation        commences; if either A or B is 0, the return value will be 0.      SEE ALSO: lcm, is_prime, factorize    */   {     a=  abs( a);     b=  abs( b);     c=  min( a, b);     a=  max( a, b);     b= c;          /* simplifies c=0 case */        if ( dimsof( a)(1)) {       /* array case */       for (list= where( c) ;  numberof( list) ; list= where( c)) {         b(list)= bl= c(list);         c(list)= a(list) % bl;         a(list)= bl;       }        } else {       /* scalar case can be less baroque */       while (c) {         b= c;         c= a % b;         a= b;       }     }        return b;   }       func  lcm( a, b)    /* DOCUMENT  lcm( a,b)        returns the LCM (least common multiple) of A and B, which must        be one of the integer data types.  A and B may be conformable        arrays; the semantics of the lcm call are the same as any other        binary operation.        The absolute values of A and B are taken before the operation        commences; if either A or B is 0, the return value will be 0.      SEE ALSO: gcd, is_prime, factorize    */   {     d=  gcd( a, b);     /* two potential problems: zero divide and overflow - handle the        first but not the second */     return  abs( a*b)/(d+!d);   }       func  is_prime( x)    /* DOCUMENT  is_prime( x)        return non-zero if and only if X (which must be a scalar integer)        is prime.  May return a false positive if X is greater than about        3e9, since at most 20000 candidate factors are checked.        The absolute value of X is taken first; zero is not prime, but 1 is.      SEE ALSO: gcd, lcm, factorize    */   {     x= long( abs( x));     if (x<2) return x==1;     /* make a list of factors which includes 2, 3, and all larger        odd numbers not divisible by 3 less or equal to  sqrt( x) */     top=  min( long(( sqrt( x)+8.)/3.+0.5), 20000);     factors= ((3* indgen( 2:top))/2)*2 - 7;     factors(1:2)= [2,3];     return  allof( x%factors);   }       func  factorize( x)    /* DOCUMENT  factorize( x)        return list of prime factors of X and their powers as an n-by-2        array.  May include a large non-prime factor if X exceeds 3e9.        In any event, product(result(,1)^result(,2)) will equal  abs( X).        X must be a scalar integer type.      SEE ALSO: gcd, lcm, is_prime    */   {     x= long( abs( x));     if (x<2) return [[x],[1]];        /* first get rid of any prime factors less than 102 */     primes= [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,       71,73,79,83,89,97,101];     primes= primes( where( !(x%primes)));     powers=  _fact_extract( primes, x);   /* returns ""deflated"" x */        if (x>1) {       /* large prime factors require a less direct approach */       top=  min( long(( sqrt( x)+2.)/3.+0.5), 20000);       if (top>=35) {         /* trial divisors are all odd numbers 103 or greater which are     not divisible by three and do not exceed  sqrt( x) */         trial= ((3* indgen( 35:top))/2)*2 - 1;         /* discard all trial divisors which do not divide x */         trial= trial( where( !(x%trial)));         /* the smallest remaining divisor must be prime - remove it and     all its subsequent multiples to find the next prime divisor     and so on until the list contains only primes */         list= trial;         for (n=0 ;  numberof( trial) ; ++n) {    list(n+1)= trial(1);    trial= trial( where( trial%trial(1)));         }         if (n) {    trial= list(1:n);    grow, primes, trial;    grow, powers,  _fact_extract( trial,x);         }       }       if (x>1) {         grow, primes, [x];         grow, powers, [1];       }     }        return [primes, powers];   }       func  _fact_extract( primes, &x)    {     if ( is_void( primes)) return [];     /* first get largest power of each prime less than or equal x */     powers= long( log( x)/ log( primes)+1.e-6);     factors=  gcd( primes^powers, x);     x/= long( exp( sum( log( factors)))+0.5);     return long( log( factors)/ log( primes)+0.5);   }                  Back to  Source File Index       C++ to HTML Conversion by  ctoohtml"
GX065-13-8841565	[index]   [keywords]   [category]   [parent]   Category B [Number theory]       PRIME       Decompose an integer into its prime factors.
GX065-16-15302460	[index]   [keywords]   [category]   DFPS2H    SUBROUTINE DFPS2H (PRHS, BRHS, COEFU, NX, NY, AX, BX, AY, BY,                           IBCTY, IORDER, U, LDU)       Purpose      Solve Poisson's or Helmholtz's equation on a                    two-dimensional rectangle using a fast Poisson solver                   based on the HODIE finite-difference scheme on a                uniform mesh.                IMSL Name     FPS2H / DFPS2H  (Single/Double precision version)       GAMS   I2B1A1A   Keyword(s)   partial_differential_equation ;  laplace_equation ;  high_order_differences_by_identity_expansion ;  pde ;  partial_differential_equation   Usage        CALL FPS2H (PRHS, BRHS, COEFU, NX, NY, AX, BX, AY, BY,                              IBCTY, IORDER, U, LDU)                   Argument(s)        PRHS   - User-supplied FUNCTION to evaluate the right side of                    the partial differential equation.  The form is                 PRHS(X, Y), where               X      - X-coordinate value.  (Input)                   Y      - Y-coordinate value.  (Input)                   PRHS   - Value of the right side at (X,Y).  (Output)                    PRHS must be declared EXTERNAL in the calling program.         BRHS   - User-supplied FUNCTION to evaluate the right side of                    the boundary conditions.  The form is                   BRHS(ISIDE, X, Y), where                ISIDE  - Side number.  (Input)                           See IBCTY below for the definition of the                               side numbers.                  X      - X-coordinate value.  (Input)                   Y      - Y-coordinate value.  (Input)                   BRHS   - Value of the right side of the boundary                         condition at (X,Y).  (Output)                  BRHS must be declared EXTERNAL in the calling program.         COEFU  - Value of the coefficient of U in the differential               equation.  (Input)             NX     - Number of grid lines in the X-direction.  (Input)               NX must be at least 4.  See Remark 2 for further                restrictions on NX.            NY     - Number of grid lines in the Y-direction.  (Input)               NY must be at least 4.  See Remark 2 for further                restrictions on NY.            AX     - The value of X along the left side of the domain.               (Input)        BX     - The value of X along the right side of the domain.                      (Input)        AY     - The value of Y along the bottom of the domain.  (Input)        BY     - The value of Y along the top of the domain.  (Input)           IBCTY  - Array of size 4 indicating the type of boundary                 condition on each side of the domain or that the                solution is periodic.  (Input)                  The sides are numbered 1 to 4 as follows:                Side              Location                      1 - Right         (X = BX)                      2 - Bottom        (Y = AY)                      3 - Left          (X = AX)                      4 - Top           (Y = BY)                     There are three boundary condition types.                IBCTY       Boundary Condition                    1          Value of U is given.  (Dirichlet)                    2          Value of dU/dX is given (sides 1 and/or                                 3).  (Neumann) Value of dU/dY is given                                  (sides 2 and/or 4).                  3          Periodic.        IORDER - Order of accuracy of the finite-difference                      approximation.  (Input)                 It can be either 2 or 4.  Usually, IORDER = 4 is used.         U      - Array of size NX by NY containing the solution at the                   grid points.  (Output)         LDU    - Leading dimension of U exactly as specified in the                      dimension statement of the calling program.  (Input)                 Remark(s)     1. Automatic workspace usage is                     FPS2H    (NX+2)(NY+2)+(NX+1)(NY+1)(IORDER-2)/2+ 6(NX+                            NY)+NX/2+16                    DFPS2H   2(NX+2)(NY+2)+(NX+1)(NY+1)(IORDER-2)+ 12(NX+                            NY)+NX+32             Workspace may be explicitly provided, if desired, by use of             F2S2H/DF2S2H.  The reference is                  CALL F2S2H (PRHS, BRHS, COEFU, NX, NY, AX, BX, AY, BY,                              IBCTY, IORDER, U, LDU, UWORK, WORK)        The additional arguments are as follows:        UWORK  - Work array of size NX+2 by NY+2.  If the actual                 dimensions of U are large enough, then U and UWORK can                  be the same array.             WORK   - Work array of length (NX+1)(NY+1)(IORDER-2)/2+                  6(NX+NY)+NX/2+16.           2. The grid spacing is the distance between the (uniformly spaced)         grid lines.  It is given by the formulas HX = (BX-AX)/(NX-1) and        HY = (BY-AY)/(NY-1).  The grid spacings in the X and Y directions       must be the same, i.e., NX and NY must be such that HX equals HY.       Also, as noted above, NX and NY must both be at least 4.  To            increase the speed of the fast Fourier transform, NX-1 should be        the product of small primes.  Good choices are 17, 33, and 65.               3. If -COEFU is nearly equal to an eigenvalue of the Laplacian with        homogeneous boundary conditions, then the computed solution might       have large errors.            Chapter(s)   MATH/LIBRARY Differential Equations          Computer     crympu/DOUBLE        Revised      May 30, 1991         Warranty     IMSL warrants only that IMSL testing has been applied                   to this code.  No other warranty, expressed or implied,                 is applicable.               Copyright    1991 by IMSL, Inc.  All Rights Reserved.
GX069-01-0161112	"Go forward to  Error Forms . Go backward to  Date Forms . Go up to  Data Types .   Modulo Forms ============  A ""modulo form"" is a real number which is taken modulo (i.e., within an integer multiple of) some value `M'.  Arithmetic modulo `M' often arises in number theory.  Modulo forms are written `a mod M', where `a' and `M' are real numbers or HMS forms, and `0 <= a < M'.  In many applications `a' and `M' will be integers but this is not required.  Modulo forms are not to be confused with the modulo operator `%'.  The expression `27 % 10' means to compute 27 modulo 10 to produce the result 7.  Further computations treat this 7 as just a regular integer.  The expression `27 mod 10' produces the result `7 mod 10'; further computations with this value are again reduced modulo 10 so that the result always lies in the desired range.  When two modulo forms with identical `M''s are added or multiplied, the Calculator simply adds or multiplies the values, then reduces modulo `M'.  If one argument is a modulo form and the other a plain number, the plain number is treated like a compatible modulo form.  It is also possible to raise modulo forms to powers; the result is the value raised to the power, then reduced modulo `M'.  (When all values involved are integers, this calculation is done much more efficiently than actually computing the power and then reducing.)  Two modulo forms `a mod M' and `b mod M' can be divided if `a', `b', and `M' are all integers.  The result is the modulo form which, when multiplied by `b mod M', produces `a mod M'.  If there is no solution to this equation (which can happen only when `M' is non-prime), or if any of the arguments are non-integers, the division is left in symbolic form.  Other operations, such as square roots, are not yet supported for modulo forms.  (Note that, although `(a mod M)^.5' will compute a ""modulo square root"" in the sense of reducing `sqrt(a)' modulo `M', this is not a useful definition from the number-theoretical point of view.)  To create a modulo form during numeric entry, press the shift-`M' key to enter the word `mod'.  As a special convenience, pressing shift-`M' a second time automatically enters the value of `M' that was most recently used before.  During algebraic entry, either type `mod' by hand or press `M-m' (that's `META-m').  Once again, pressing this a second time enters the current modulo.  You can also use `v p' and `%' to modify modulo forms. See  Building Vectors .  See  Basic Arithmetic .  It is possible to mix HMS forms and modulo forms.  For example, an HMS form modulo 24 could be used to manipulate clock times; an HMS form modulo 360 would be suitable for angles.  Making the modulo `M' also be an HMS form eliminates troubles that would arise if the angular mode were inadvertently set to Radians, in which case `2@ 0' 0"" mod 24' would be interpreted as two degrees modulo 24 radians!  Modulo forms cannot have variables or formulas for components.  If you enter the formula `(x + 2) mod 5', Calc propagates the modulus to each of the coefficients: `(1 mod 5) x + (2 mod 5)'.  The algebraic function `makemod(a, m)' builds the modulo form `a mod m'."
GX228-29-8882507	CHARMM c30b1 ewald.doc     File:  Ewald  -=-    Node:  Top    Up : ( commands.doc ) -=-   Next :  Syntax  -=-   Previous :  Top                         The Ewald Summation method    Invoking the Ewald summation for calculating the electrostatic interactions  can be specified any time the nbond specification parser is invoked.  See   the syntax section for a list of all commands that invoke this parser.    Prerequisite reading:  nbonds.doc   * Menu:  *  Syntax ::          Syntax of the Ewald summation specification *  Defaults ::        Defaults used in the specification *  Function ::        Description of the options *  Discussion ::      More general discussion of the algorithm    File:  Ewald  -=-    Node:  Syntax    Up :  Top  -=-   Next :  Defaults  -=-   Previous :  Top  [SYNTAX EWALD]  {  NBONds          }        {  nonbond-spec                   } {  UPDAte          }        {                                 } {  ENERgy          }        {                                 } {  MINImize        }        {                                 } {  DYNAmics        }        {                                 }   The keywords are:  nonbond-spec::= [ method-spec ]                 { [ NOEWald ]                                          }                {                                                      } method-spec::= {   EWALd [ewald-spec] { [ NOPMewald [std-ew-spec] ] } }                {                      {   PMEWald [pmesh-spec]      } }   ewald-spec::=   KAPPa real  [erfc-spec]  std-ew-spec::= { [ KMAX integer ]                        } KSQMAX integer                { KMXX integer KMXY integer KMXZ integer  }  pmesh-spec::=   FFTX int FFTY int FFTZ int  ORDEr integer [QCOR real (***) ]  erfc-spec::=    { SPLIne      { [EWMIn real] [EWMAx real] [EWNPts int] } }                 { INTErpolate {                                        } }                 {                                                        }                 { ABROmowitz                                             }                 { CHEBychev                                              }                 { EXACt_high_precision                                   }                 { LOWPrecision_exact                                     }                 { ERFMode int                                            }    File:  Ewald  -=-    Node:  Defaults    Up :  Top  -=-   Next :  Function  -=-   Previous :  Syntax  The defaults for the ewald summation are set internally and are currently set to NOEWald, KAPPa=1.0, KMAX=5, KSQMax=27, and NOPMewald, KAPPa=1.0, FFTX=FFTY=FFTZ=32, ORDEr=4, QCOR=1.0  Recommended values for Ewald are:    EWALD PMEWald KAPPa 0.34 ORDEr 6 -     FFTX intboxvx FFTY intboxvy FFTZ intboxvz  -    CTOFNB 12.0 CUTNB 14.0 QCOR 1.0(***)  Where intboxv* is an integer value similar to or larger than the corresponding unit cell dimension that has prime factors of 2,3, and 5 only (2,3 preferred). grid point spacing should be between 0.8 and 1.2 Angstroms.  These recommended values should give relative force errors of roughly 10**-5. To reduce the total PME cost at the expense of accuracy, decrease the cutoff distances while increasing KAPPa (keep the product near 4) reduces the real space cost.  To reduce the K-space cost, either reduce ORDEr from 6 to 4 or increase the grid spacing up to perhaps 1.5 Angstroms.  (***) The QCOR value should be 1.0 for vacuum, solid, or finite systems. For periodic systems in solution, it should be reduced (or set to zero) by an amount that depends on how the net charge is distributed and on the effective dielectric constant.  For a treatise on this correction term, see: S. Bogusz, T. Cheatham, and B. Brooks, JCP (1998) 108, 7070-7084 and references contained therein (esp. Hummer and Levy).    File:  Nbonds  -=-    Node:  Function    Up :  Top  -=-   Previous :  Defaults  -=-   Next :  Discussion   i)   The EWALD keyword invokes the Ewald summation for calculation of  electrostatic interactions in periodic, neutral systems.  The formulation of  the Ewald summation dictates that the primary system must be neutral.  If  otherwise, the summation is not formally correct and some  convergence problems may result.  The NOEWald (default) suppresses the Ewald  method for calculating electrostatic interactions.  Van der waals  options VSHIFT and VSWITCH are supported with ewald.  The algorithm currently supports the atom and group nonbond lists and the CRYSTAL facilty  must be used.  The PMEWald keyword invokes the Particle Mesh Ewald algorithm for the reciprocal space summation.  For details on the PME method, see J. Chem. Phys. 103:8577 (1995).  The EWALd algorithm is limited to CUBIC, TETRAGONAL, and ORTHORHOMBIC unit cells.  The PMEWald algorithm supports all unit cells that are supported by the CRYSTAL facility.   ii)  The KAPPa keyword, followed by a real number governs the width of the  Gaussian distribution central to the Ewald method.  An approximate value of kappa can be chosen by taking KAPPa=5/CTOFNB.  This is fairly conservative. Values of 4/CTOFNB lead to small force errors (roughly 10**-5).  See discussion section for details on choosing an optimum value of KAPPa.  iii) The KMAX key word is the number of kvectors (or images of the  primary unit cell) that will be summed in any direction.  It is the  radius of the Ewald summation.  For orthorombic cells, the value of  kmax may be independently specified in the x, y, and z directions with the keywords KMXX, KMXY, and KMXZ.  In the PME version, the number of  FFT grid points for the charge mesh is specified by FFTX, FFTY, and FFTZ.   iv) The KSQMax key word should be chosen between  KMAX squared and 3 times KMAX squared.   v) An appropriate, although not optimal, set of parameters can be  chosen by taking KAPPA=5/CTOFNB and KMAX=KAPPa*boxlength. The actual  values should then be performanced optimized for your particular system. For the PME method, FFTX should be approximately the box length in Angstroms. (for efficiency, FFTX should be a multiple of powers of 2,3, and 5).     IMPORTANT NOTE::: THE SUGGESTION THAT FFTX, FFTY, AND FFTZ HAVE    NO PRIME FACTORS OTHER THAN 2, 3, AND 5 SEEMS TO BE A REQUIREMENT.    LARGE ERRORS IN THE FORCE ARE OBSERVED WHEN THIS CONDITION IS NOT MET.    FUTURE VERSIONS OF CHARMM WILL FLAG THIS AS AN ERROR CONDITION.  ORDEr specifies the order of the B-spline interpolation, e.g. cubic is order 4 (default), fifth degree is ORDEr 6.  The ORDEr must be an even number and at least 4.   vi) EWALd runs in parallel on both shared (PARVECT) and distributed memory parallel computers.  PME runs in parallel on distributed memory computers.  vii) several algorithms are available for the calculation of the complimentary error function, erfc(x).  EXACt and LOWPrecision use an interative technique described in section 6.2 of Numerical Recipies.  ABRO and CHEB are polynomial approximations.  A lookup table (filled at the beginning of the simulation using the EXACt method) can be used with either a linear (INTE) of cubic  spline (SPLINe) interpolation.  SPLIne is recommended.  viii) Ewald with MMFF  A version of EWALD was developed for MMFF.  The usual MMFF electrostatic term: qq/(r+d)  is split into two terms:  qq/r -  qq*d/(r*(r+d)) The first term is handled by the Ewald method in the usual manner (real-space and k-space parts) and the second term is truncated at the cutoff distance using a switching function (from CTONNB to CTOFNB). Since the second term is quite small at the cutoff distance, the use of a switching function should not introduce significant artificial forces.    File:  Ewald  -=-    Node:  Discussion    Up :  Top  -=-   Previous :  Function  -=-   Next :  Top            The Ewald Summation in Molecular Dynamics Simulation   The electrostatic energy of a periodic system can be expressed by a lattice   sum over all pair interactions and over all lattice vectors excluding the i=j term in the primary box.  Summations carried out in this simple  way have been shown to be conditionally convergent.  The method developed by  Ewald, in essence, mathematically transforms  this fairly straightforward   summation to two more complicated but rapidly convergent sums.  One summation  is carried out in reciporcal space while the other is carried out in real  space.  Based on the formulation by Ewald, the simple lattice sum can be reformulated to give absolutely convergent summations which define the principal value of the electrostatic potential, called the intrinsic potential. Given the periodicity present in both crystal calculations and in dynamics  simulations using periodic boundary conditions,  the Ewald formulation becomes  well suited for the calculation of the electrostatic energy and force. If we  consider a system of point charges in the unit or primary cell, we can specify  its charge density by    ro(r) = sum_i [ q_i * delta(r-r_i)]   In the Ewald method  this distribution is replaced by two other distributions   ro_1(r) = sum_i [ q_i ( delta(r-r_i) - f(r-r_i)]  and  ro_2(r) = sum_i [q_i f(r-r_i)  such that the sum of the two recovers the original.  The distribution, f(r), is a spherical distribution generally taken to be Gaussian, the width of the gaussian dictated by the parameter, KAPPa.  The charge distributions are situated on the ion lattice positions, but integrate to zero.  The potential from the distribution ro_1(r) is a short range potential evaluated in a direct real space summation (truncated at CTOFNB).  The diffuse charge distribution placed on the lattice sites reduces to the potential of the corresponding point charge at large r. ro_2(r), being a continuous distribution of Gaussians situated on the periodic lattice positions, is a smoothly varying function of r and thus is well approximated by a superposition of continuous functions.  This distribution is, therefore, expanded in a Fourier series and the potential is obtained by solving the Poisson equation.  The point of splitting the problem into two parts, is that by a suitable choice of the parameter KAPPa we can get very good convergence of both parts of the summation.  For the real space part of the energy, we choose kappa so that the complementary error function term, erfc(kappa*r) decreases rapidly enough with r to make it a good approximation to take only nearest images in the sum and neglect the value for which r > CTOFNB.  The reciprocal space sums are rapidly convergent and a spherical cutoff in k space is applied so that the sum over k becomes a sum over {l,m,n}, with (l**2+m**2+n**2) < or = to KSQMAX A large value of KAPPa means that the real space sum is more rapidly convergent but the reciprocal space sum is less rapid.  In practice one chooses KAPPa to give good convergence at the cutoff radius, CTOFNB.  KMAX is then chosen to such that the reciprocal space calculation converges.  The equation (KMAX/(box length)=KAPPa may be used as a rough guide.  Optimization with respect to the timing trade offs, ie.  how much time is spent in real space vs k-space should be performed before a lengthy production run.  The CCP5 notes in several articles in 1993 cover some possible optimization strategies and criteria although a simple line search will suffice.  Complete optimiztion of the ewald method for a particular application requires optimizing CTOFNB, KAPPa, and KMAX.  A discussion of optimization and error analysis can be found in Kolfka and Perram, Molecular Simulation, 9, 351 (1992).   For PME, see Feller, Pastor, Rojnuckarin, Bogusz, and Brooks. J. Phys. Chem., 100, 42, 17011 (1996) and some of Tom Darden's published work.              NIH/CIT Biowulf         CHARMM Documentation /   Rick_Venable@nih.gov
GX069-10-8652104	"Go forward to  Unsafe Simplifications . Go backward to  Default Simplifications . Go up to  Simplifying Formulas .   Algebraic Simplifications -------------------------  The `a s' command makes simplifications that may be too slow to do all the time, or that may not be desirable all of the time.  If you find these simplifications are worthwhile, you can type `m A' to have Calc apply them automatically.  This section describes all simplifications that are performed by the `a s' command.  Note that these occur in addition to the default simplifications; even if the default simplifications have been turned off by an `m O' command, `a s' will turn them back on temporarily while it simplifies the formula.  There is a variable, `AlgSimpRules', in which you can put rewrites to be applied by `a s'.  Its use is analogous to `EvalRules', but without the special restrictions.  Basically, the simplifier does `a r AlgSimpRules' with an infinite repeat count on the whole expression being simplified, then it traverses the expression applying the built-in rules described below.  If the result is different from the original expression, the process repeats with the default simplifications (including `EvalRules'), then `AlgSimpRules', then the built-in simplifications, and so on.   Sums are simplified in two ways.  Constant terms are commuted to the end of the sum, so that `a + 2 + b' changes to `a + b + 2'.  The only exception is that a constant will not be commuted away from the first position of a difference, i.e., `2 - x' is not commuted to `-x + 2'.  Also, terms of sums are combined by the distributive law, as in `x + y + 2 x' to `y + 3 x'.  This always occurs for adjacent terms, but `a s' compares all pairs of terms including non-adjacent ones.   Products are sorted into a canonical order using the commutative law. For example, `b c a' is commuted to `a b c'.  This allows easier comparison of products; for example, the default simplifications will not change `x y + y x' to `2 x y', but `a s' will; it first rewrites the sum to `x y + x y', and then the default simplifications are able to recognize a sum of identical terms.  The canonical ordering used to sort terms of products has the property that real-valued numbers, interval forms and infinities come first, and are sorted into increasing order.  The `V S' command uses the same ordering when sorting a vector.  Sorting of terms of products is inhibited when matrix mode is turned on; in this case, Calc will never exchange the order of two terms unless it knows at least one of the terms is a scalar.  Products of powers are distributed by comparing all pairs of terms, using the same method that the default simplifications use for adjacent terms of products.  Even though sums are not sorted, the commutative law is still taken into account when terms of a product are being compared.  Thus `(x + y) (y + x)' will be simplified to `(x + y)^2'.  A subtle point is that `(x - y) (y - x)' will *not* be simplified to `-(x - y)^2'; Calc does not notice that one term can be written as a constant times the other, even if that constant is -1.  A fraction times any expression, `(a:b) x', is changed to a quotient involving integers: `a x / b'.  This is not done for floating-point numbers like `0.5', however.  This is one reason why you may find it convenient to turn Fraction mode on while doing algebra; *Note Fraction Mode::.   Quotients are simplified by comparing all terms in the numerator with all terms in the denominator for possible cancellation using the distributive law.  For example, `a x^2 b / c x^3 d' will cancel `x^2' from both sides to get `a b / c x d'.  (The terms in the denominator will then be rearranged to `c d x' as described above.)  If there is any common integer or fractional factor in the numerator and denominator, it is cancelled out; for example, `(4 x + 6) / 8 x' simplifies to `(2 x + 3) / 4 x'.  Non-constant common factors are not found even by `a s'.  To cancel the factor `a' in `(a x + a) / a^2' you could first use `j M' on the product `a x' to Merge the numerator to `a (1+x)', which can then be simplified successfully.   Integer powers of the variable `i' are simplified according to the identity `i^2 = -1'.  If you store a new value other than the complex number `(0,1)' in `i', this simplification will no longer occur.  This is done by `a s' instead of by default in case someone (unwisely) uses the name `i' for a variable unrelated to complex numbers; it would be unfortunate if Calc quietly and automatically changed this formula for reasons the user might not have been thinking of.  Square roots of integer or rational arguments are simplified in several ways.  (Note that these will be left unevaluated only in Symbolic mode.)  First, square integer or rational factors are pulled out so that `sqrt(8)' is rewritten as `2 sqrt(2)'.  Conceptually speaking this implies factoring the argument into primes and moving pairs of primes out of the square root, but for reasons of efficiency Calc only looks for primes up to 29.  Square roots in the denominator of a quotient are moved to the numerator: `1 / sqrt(3)' changes to `sqrt(3) / 3'.  The same effect occurs for the square root of a fraction: `sqrt(2:3)' changes to `sqrt(6) / 3'.   The `%' (modulo) operator is simplified in several ways when the modulus `M' is a positive real number.  First, if the argument is of the form `x + n' for some real number `n', then `n' is itself reduced modulo `M'.  For example, `(x - 23) % 10' is simplified to `(x + 7) % 10'.  If the argument is multiplied by a constant, and this constant has a common integer divisor with the modulus, then this factor is cancelled out.  For example, `12 x % 15' is changed to `3 (4 x % 5)' by factoring out 3.  Also, `(12 x + 1) % 15' is changed to `3 ((4 x + 1:3) % 5)'.  While these forms may not seem ""simpler,"" they allow Calc to discover useful information about modulo forms in the presence of declarations.  If the modulus is 1, then Calc can use `int' declarations to evaluate the expression.  For example, the idiom `x % 2' is often used to check whether a number is odd or even.  As described above, `2 n % 2' and `(2 n + 1) % 2' are simplified to `2 (n % 1)' and `2 ((n + 1:2) % 1)', respectively; Calc can simplify these to 0 and 1 (respectively) if `n' has been declared to be an integer.   Trigonometric functions are simplified in several ways.  First, `sin(arcsin(x))' is simplified to `x', and similarly for `cos' and `tan'.  If the argument to `sin' is negative-looking, it is simplified to `-sin(x)', and similarly for `cos' and `tan'.  Finally, certain special values of the argument are recognized; See  Trigonometric and Hyperbolic Functions .  Trigonometric functions of inverses of different trigonometric functions can also be simplified, as in `sin(arccos(x))' to `sqrt(1 - x^2)'.  Hyperbolic functions of their inverses and of negative-looking arguments are also handled, as are exponentials of inverse hyperbolic functions.  No simplifications for inverse trigonometric and hyperbolic functions are known, except for negative arguments of `arcsin', `arctan', `arcsinh', and `arctanh'.  Note that `arcsin(sin(x))' can *not* safely change to `x', since this only correct within an integer multiple of `2 pi' radians or 360 degrees.  However, `arcsinh(sinh(x))' is simplified to `x' if `x' is known to be real.  Several simplifications that apply to logarithms and exponentials are that `exp(ln(x))', `e^ln(x)', and `10^log10(x)' all reduce to `x'. Also, `ln(exp(x))', etc., can reduce to `x' if `x' is provably real. The form `exp(x)^y' is simplified to `exp(x y)'.  If `x' is a suitable multiple of `pi i' (as described above for the trigonometric functions), then `exp(x)' or `e^x' will be expanded.  Finally, `ln(x)' is simplified to a form involving `pi' and `i' where `x' is provably negative, positive imaginary, or negative imaginary.  The error functions `erf' and `erfc' are simplified when their arguments are negative-looking or are calls to the `conj' function.   Equations and inequalities are simplified by cancelling factors of products, quotients, or sums on both sides.  Inequalities change sign if a negative multiplicative factor is cancelled.  Non-constant multiplicative factors as in `a b = a c' are cancelled from equations only if they are provably nonzero (generally because they were declared so; See  Declarations ).  Factors are cancelled from inequalities only if they are nonzero and their sign is known.  Simplification also replaces an equation or inequality with 1 or 0 (""true"" or ""false"") if it can through the use of declarations.  If `x' is declared to be an integer greater than 5, then `x < 3', `x = 3', and `x = 7.5' are all simplified to 0, but `x > 3' is simplified to 1. By a similar analysis, `abs(x) >= 0' is simplified to 1, as is `x^2 >= 0' if `x' is known to be real."
GX069-14-0078492	"Go forward to  Algebra Tutorial . Go backward to  Vector/Matrix Tutorial . Go up to  Tutorial .   Types Tutorial ==============  Calc understands a variety of data types as well as simple numbers. In this section, we'll experiment with each of these types in turn.  The numbers we've been using so far have mainly been either ""integers"" or ""floats"".  We saw that floats are usually a good approximation to the mathematical concept of real numbers, but they are only approximations and are susceptible to roundoff error.  Calc also supports ""fractions"", which can exactly represent any rational number.       1:  3628800    2:  3628800    1:  518400:7   1:  518414:7   1:  7:518414          .          1:  49             .              .              .                         .           10 !           49 RET         :              2 +            &  The `:' command divides two integers to get a fraction; `/' would normally divide integers to get a floating-point result.  Notice we had to type RET between the `49' and the `:' since the `:' would otherwise be interpreted as part of a fraction beginning with 49.  You can convert between floating-point and fractional format using `c f' and `c F':       1:  1.35027217629e-5    1:  7:518414          .                       .           c f                     c F  The `c F' command replaces a floating-point number with the ""simplest"" fraction whose floating-point representation is the same, to within the current precision.       1:  3.14159265359   1:  1146408:364913   1:  3.1416   1:  355:113          .                   .                    .            .           P                   c F      DEL       p 5 RET P      c F  (*) *Exercise 1.* A calculation has produced the result 1.26508260337. You suspect it is the square root of the product of `pi' and some rational number.  Is it?  (Be sure to allow for roundoff error!) See  1: Types Answer 1 . (*)  ""Complex numbers"" can be stored in both rectangular and polar form.       1:  -9     1:  (0, 3)    1:  (3; 90.)   1:  (6; 90.)   1:  (2.4495; 45.)          .          .             .              .              .           9 n        Q             c p            2 *            Q  The square root of -9 is by default rendered in rectangular form (`0 + 3i'), but we can convert it to polar form (3 with a phase angle of 90 degrees).  All the usual arithmetic and scientific operations are defined on both types of complex numbers.  Another generalized kind of number is ""infinity"".  Infinity isn't really a number, but it can sometimes be treated like one.  Calc uses the symbol `inf' to represent positive infinity, i.e., a value greater than any real number.  Naturally, you can also write `-inf' for minus infinity, a value less than any real number.  The word `inf' can only be input using algebraic entry.       2:  inf        2:  -inf       2:  -inf       2:  -inf       1:  nan      1:  -17        1:  -inf       1:  -inf       1:  inf            .          .              .              .              .       ' inf RET 17 n     *  RET         72 +           A              +  Since infinity is infinitely large, multiplying it by any finite number (like -17) has no effect, except that since -17 is negative, it changes a plus infinity to a minus infinity. (""A huge positive number, multiplied by -17, yields a huge negative number."")  Adding any finite number to infinity also leaves it unchanged.  Taking an absolute value gives us plus infinity again.  Finally, we add this plus infinity to the minus infinity we had earlier.  If you work it out, you might expect the answer to be -72 for this.  But the 72 has been completely lost next to the infinities; by the time we compute `inf - inf' the finite difference between them, if any, is indetectable. So we say the result is ""indeterminate"", which Calc writes with the symbol `nan' (for Not A Number).  Dividing by zero is normally treated as an error, but you can get Calc to write an answer in terms of infinity by pressing `m i' to turn on ""infinite mode.""       3:  nan        2:  nan        2:  nan        2:  nan        1:  nan      2:  1          1:  1 / 0      1:  uinf       1:  uinf           .      1:  0              .              .              .          .         1 RET 0          /       m i    U /            17 n *         +  Dividing by zero normally is left unevaluated, but after `m i' it instead gives an infinite result.  The answer is actually `uinf', ""undirected infinity.""  If you look at a graph of `1 / x' around `x = 0', you'll see that it goes toward plus infinity as you approach zero from above, but toward minus infinity as you approach from below.  Since we said only `1 / 0', Calc knows that the answer is infinite but not in which direction. That's what `uinf' means.  Notice that multiplying `uinf' by a negative number still leaves plain `uinf'; there's no point in saying `-uinf' because the sign of `uinf' is unknown anyway.  Finally, we add `uinf' to our `nan', yielding `nan' again.  It's easy to see that, because `nan' means ""totally unknown"" while `uinf' means ""unknown sign but known to be infinite,"" the more mysterious `nan' wins out when it is combined with `uinf', or, for that matter, with anything else.  (*) *Exercise 2.*  Predict what Calc will answer for each of these formulas:  `inf / inf', `exp(inf)', `exp(-inf)', `sqrt(-inf)', `sqrt(uinf)', `abs(uinf)', `ln(0)'. See  2: Types Answer 2 . (*)  (*) *Exercise 3.* We saw that `inf - inf = nan', which stands for an unknown value.  Can `nan' stand for a complex number?  Can it stand for infinity?  See  3: Types Answer 3 . (*)  ""HMS forms"" represent a value in terms of hours, minutes, and seconds.       1:  2@ 30' 0""     1:  3@ 30' 0""     2:  3@ 30' 0""     1:  2.          .                 .             1:  1@ 45' 0.""        .                                              .         2@ 30' RET          1 +               RET 2 /           /  HMS forms can also be used to hold angles in degrees, minutes, and seconds.       1:  0.5        1:  26.56505   1:  26@ 33' 54.18""    1:  0.44721          .              .              .                     .           0.5            I T            c h                   S  First we convert the inverse tangent of 0.5 to degrees-minutes-seconds form, then we take the sine of that angle.  Note that the trigonometric functions will accept HMS forms directly as input.  (*) *Exercise 4.* The Beatles' *Abbey Road* is 47 minutes and 26 seconds long, and contains 17 songs.  What is the average length of a song on *Abbey Road*?  If the Extended Disco Version of *Abbey Road* added 20 seconds to the length of each song, how long would the album be?  See  4: Types Answer 4 . (*)  A ""date form"" represents a date, or a date and time.  Dates must be entered using algebraic entry.  Date forms are surrounded by `< >' symbols; most standard formats for dates are recognized.       2:  <Sun Jan 13, 1991>                    1:  2.25      1:  <6:00pm Thu Jan 10, 1991>                 .          .       ' <13 Jan 1991>, <1/10/91, 6pm> RET           -  In this example, we enter two dates, then subtract to find the number of days between them.  It is also possible to add an HMS form or a number (of days) to a date form to get another date form.       1:  <4:45:59pm Mon Jan 14, 1991>     1:  <2:50:59am Thu Jan 17, 1991>          .                                    .           t N                                  2 + 10@ 5' +  The `t N' (""now"") command pushes the current date and time on the stack; then we add two days, ten hours and five minutes to the date and time.  Other date-and-time related commands include `t J', which does Julian day conversions, `t W', which finds the beginning of the week in which a date form lies, and `t I', which increments a date by one or several months.  See  Date Arithmetic , for more.  (*) *Exercise 5.* How many days until the next Friday the 13th?  *Note 5: Types Answer 5. (*)  (*) *Exercise 6.* How many leap years will there be between now and the year 10001 A.D.?  See  6: Types Answer 6 . (*)  An ""error form"" represents a mean value with an attached standard deviation, or error estimate.  Suppose our measurements indicate that a certain telephone pole is about 30 meters away, with an estimated error of 1 meter, and 8 meters tall, with an estimated error of 0.2 meters.  What is the slope of a line from here to the top of the pole, and what is the equivalent angle in degrees?       1:  8 +/- 0.2    2:  8 +/- 0.2   1:  0.266 +/- 0.011   1:  14.93 +/- 0.594          .            1:  30 +/- 1        .                     .                           .           8 p .2 RET       30 p 1          /                     I T  This means that the angle is about 15 degrees, and, assuming our original error estimates were valid standard deviations, there is about a 60% chance that the result is correct within 0.59 degrees.  (*) *Exercise 7.*  The volume of a torus (a donut shape) is `2 pi^2 R r^2' where `R' is the radius of the circle that defines the center of the tube and `r' is the radius of the tube itself.  Suppose `R' is 20 cm and `r' is 4 cm, each known to within 5 percent.  What is the volume and the relative uncertainty of the volume?  See  7: Types Answer 7 . (*)  An ""interval form"" represents a range of values.  While an error form is best for making statistical estimates, intervals give you exact bounds on an answer.  Suppose we additionally know that our telephone pole is definitely between 28 and 31 meters away, and that it is between 7.7 and 8.1 meters tall.       1:  [7.7 .. 8.1]  2:  [7.7 .. 8.1]  1:  [0.24 .. 0.28]  1:  [13.9 .. 16.1]          .             1:  [28 .. 31]        .                   .                            .         [ 7.7 .. 8.1 ]    [ 28 .. 31 ]        /                   I T  If our bounds were correct, then the angle to the top of the pole is sure to lie in the range shown.  The square brackets around these intervals indicate that the endpoints themselves are allowable values.  In other words, the distance to the telephone pole is between 28 and 31, *inclusive*.  You can also make an interval that is exclusive of its endpoints by writing parentheses instead of square brackets.  You can even make an interval which is inclusive (""closed"") on one end and exclusive (""open"") on the other.       1:  [1 .. 10)    1:  (0.1 .. 1]   2:  (0.1 .. 1]   1:  (0.2 .. 3)          .                .            1:  [2 .. 3)         .                                            .         [ 1 .. 10 )        &              [ 2 .. 3 )         *  The Calculator automatically keeps track of which end values should be open and which should be closed.  You can also make infinite or semi-infinite intervals by using `-inf' or `inf' for one or both endpoints.  (*) *Exercise 8.*  What answer would you expect from `1 / (0 .. 10)'?  What about `1 / (-10 .. 0)'?  What about `1 / [0 .. 10]' (where the interval actually includes zero)?  What about `1 / (-10 .. 10)'? See  8: Types Answer 8 . (*)  (*) *Exercise 9.*  Two easy ways of squaring a number are `RET *' and `2 ^'.  Normally these produce the same answer.  Would you expect this still to hold true for interval forms? If not, which of these will result in a larger interval? See  9: Types Answer 9 . (*)  A ""modulo form"" is used for performing arithmetic modulo M.  For example, arithmetic involving time is generally done modulo 12 or 24 hours.       1:  17 mod 24    1:  3 mod 24     1:  21 mod 24    1:  9 mod 24          .                .                .                .           17 M 24 RET      10 +             n                5 /  In this last step, Calc has found a new number which, when multiplied by 5 modulo 24, produces the original number, 21.  If M is prime it is always possible to find such a number.  For non-prime M like 24, it is only sometimes possible.       1:  10 mod 24    1:  16 mod 24    1:  1000000...   1:  16          .                .                .                .           10 M 24 RET      100 ^            10 RET 100 ^     24 %  These two calculations get the same answer, but the first one is much more efficient because it avoids the huge intermediate value that arises in the second one.  (*) *Exercise 10.*  A theorem of Pierre de Fermat says that `x^(n-1) mod n = 1' if `n' is a prime number and `x' is an integer less than `n'.  If `n' is *not* a prime number, this will *not* be true for most values of `x'.  Thus we can test informally if a number is prime by trying this formula for several values of `x'.  Use this test to tell whether the following numbers are prime: 811749613, 15485863.  *Note 10: Types Answer 10. (*)  It is possible to use HMS forms as parts of error forms, intervals, modulo forms, or as the phase part of a polar complex number.  For example, the `calc-time' command pushes the current time of day on the stack as an HMS/modulo form.       1:  17@ 34' 45"" mod 24@ 0' 0""     1:  6@ 22' 15"" mod 24@ 0' 0""          .                                 .           x time RET                        n  This calculation tells me it is six hours and 22 minutes until midnight.  (*) *Exercise 11.*  A rule of thumb is that one year is about `pi * 10^7' seconds.  What time will it be that many seconds from right now?  See  11: Types Answer 11 . (*)  (*) *Exercise 12.*  You are preparing to order packaging for the CD release of the Extended Disco Version of *Abbey Road*. You are told that the songs will actually be anywhere from 20 to 60 seconds longer than the originals.  One CD can hold about 75 minutes of music.  Should you order single or double packages? See  12: Types Answer 12 . (*)  Another kind of data the Calculator can manipulate is numbers with ""units"".  This isn't strictly a new data type; it's simply an application of algebraic expressions, where we use variables with suggestive names like `cm' and `in' to represent units like centimeters and inches.       1:  2 in        1:  5.08 cm      1:  0.027778 fath   1:  0.0508 m          .               .                .                   .           ' 2in RET       u c cm RET       u c fath RET        u b  We enter the quantity ""2 inches"" (actually an algebraic expression which means two times the variable `in'), then we convert it first to centimeters, then to fathoms, then finally to ""base"" units, which in this case means meters.       1:  9 acre     1:  3 sqrt(acre)   1:  190.84 m   1:  190.84 m + 30 cm          .              .                  .              .        ' 9 acre RET      Q                  u s            ' $+30 cm RET       1:  191.14 m     1:  36536.3046 m^2    1:  365363046 cm^2          .                .                     .           u s              2 ^                   u c cgs  Since units expressions are really just formulas, taking the square root of `acre' is undefined.  After all, `acre' might be an algebraic variable that you will someday assign a value.  We use the ""units-simplify"" command to simplify the expression with variables being interpreted as unit names.  In the final step, we have converted not to a particular unit, but to a units system.  The ""cgs"" system uses centimeters instead of meters as its standard unit of length.  There is a wide variety of units defined in the Calculator.       1:  55 mph     1:  88.5139 kph   1:   88.5139 km / hr   1:  8.201407e-8 c          .              .                  .                     .        ' 55 mph RET      u c kph RET        u c km/hr RET         u c c RET  We express a speed first in miles per hour, then in kilometers per hour, then again using a slightly more explicit notation, then finally in terms of fractions of the speed of light.  Temperature conversions are a bit more tricky.  There are two ways to interpret ""20 degrees Fahrenheit""---it could mean an actual temperature, or it could mean a change in temperature.  For normal units there is no difference, but temperature units have an offset as well as a scale factor and so there must be two explicit commands for them.       1:  20 degF       1:  11.1111 degC     1:  -20:3 degC    1:  -6.666 degC          .                 .                    .                 .         ' 20 degF RET       u c degC RET         U u t degC RET    c f  First we convert a change of 20 degrees Fahrenheit into an equivalent change in degrees Celsius (or Centigrade).  Then, we convert the absolute temperature 20 degrees Fahrenheit into Celsius.  Since this comes out as an exact fraction, we then convert to floating-point for easier comparison with the other result.  For simple unit conversions, you can put a plain number on the stack. Then `u c' and `u t' will prompt for both old and new units.  When you use this method, you're responsible for remembering which numbers are in which units:       1:  55         1:  88.5139              1:  8.201407e-8          .              .                        .           55             u c mph RET kph RET      u c km/hr RET c RET  To see a complete list of built-in units, type `u v'.  Press `M-# c' again to re-enter the Calculator when you're done looking at the units table.  (*) *Exercise 13.* How many seconds are there really in a year?  *Note 13: Types Answer 13. (*)  (*) *Exercise 14.* Supercomputer designs are limited by the speed of light (and of electricity, which is nearly as fast).  Suppose a computer has a 4.1 ns (nanosecond) clock cycle, and its cabinet is one meter across.  Is speed of light going to be a significant factor in its design?  See  14: Types Answer 14 . (*)  (*) *Exercise 15.*  Sam the Slug normally travels about five yards in an hour.  He has obtained a supply of Power Pills; each Power Pill he eats doubles his speed.  How many Power Pills can he swallow and still travel legally on most US highways? See  15: Types Answer 15 . (*)"
GX085-21-11158384	[index]   [keywords]   [category]   FPS2H    SUBROUTINE FPS2H (PRHS, BRHS, COEFU, NX, NY, AX, BX, AY, BY,                           IBCTY, IORDER, U, LDU)        Purpose      Solve Poisson's or Helmholtz's equation on a                    two-dimensional rectangle using a fast Poisson solver                   based on the HODIE finite-difference scheme on a                uniform mesh.                IMSL Name     FPS2H / DFPS2H  (Single/Double precision version)       GAMS   I2B1A1A   Keyword(s)   partial_differential_equation ;  laplace_equation ;  high_order_differences_by_identity_expansion ;  pde ;  partial_differential_equation   Usage        CALL FPS2H (PRHS, BRHS, COEFU, NX, NY, AX, BX, AY, BY,                              IBCTY, IORDER, U, LDU)                   Argument(s)        PRHS   - User-supplied FUNCTION to evaluate the right side of                    the partial differential equation.  The form is                 PRHS(X, Y), where               X      - X-coordinate value.  (Input)                   Y      - Y-coordinate value.  (Input)                   PRHS   - Value of the right side at (X,Y).  (Output)                    PRHS must be declared EXTERNAL in the calling program.         BRHS   - User-supplied FUNCTION to evaluate the right side of                    the boundary conditions.  The form is                   BRHS(ISIDE, X, Y), where                ISIDE  - Side number.  (Input)                           See IBCTY below for the definition of the                               side numbers.                  X      - X-coordinate value.  (Input)                   Y      - Y-coordinate value.  (Input)                   BRHS   - Value of the right side of the boundary                         condition at (X,Y).  (Output)                  BRHS must be declared EXTERNAL in the calling program.         COEFU  - Value of the coefficient of U in the differential               equation.  (Input)             NX     - Number of grid lines in the X-direction.  (Input)               NX must be at least 4.  See Remark 2 for further                restrictions on NX.            NY     - Number of grid lines in the Y-direction.  (Input)               NY must be at least 4.  See Remark 2 for further                restrictions on NY.            AX     - The value of X along the left side of the domain.               (Input)        BX     - The value of X along the right side of the domain.                      (Input)        AY     - The value of Y along the bottom of the domain.  (Input)        BY     - The value of Y along the top of the domain.  (Input)           IBCTY  - Array of size 4 indicating the type of boundary                 condition on each side of the domain or that the                solution is periodic.  (Input)                  The sides are numbered 1 to 4 as follows:                Side              Location                      1 - Right         (X = BX)                      2 - Bottom        (Y = AY)                      3 - Left          (X = AX)                      4 - Top           (Y = BY)                     There are three boundary condition types.                IBCTY       Boundary Condition                    1          Value of U is given.  (Dirichlet)                    2          Value of dU/dX is given (sides 1 and/or                                 3).  (Neumann) Value of dU/dY is given                                  (sides 2 and/or 4).                  3          Periodic.        IORDER - Order of accuracy of the finite-difference                      approximation.  (Input)                 It can be either 2 or 4.  Usually, IORDER = 4 is used.         U      - Array of size NX by NY containing the solution at the                   grid points.  (Output)         LDU    - Leading dimension of U exactly as specified in the                      dimension statement of the calling program.  (Input)                 Remark(s)     1. Automatic workspace usage is                     FPS2H    (NX+2)(NY+2)+(NX+1)(NY+1)(IORDER-2)/2+ 6(NX+                            NY)+NX/2+16                    DFPS2H   2(NX+2)(NY+2)+(NX+1)(NY+1)(IORDER-2)+ 12(NX+                            NY)+NX+32             Workspace may be explicitly provided, if desired, by use of             F2S2H/DF2S2H.  The reference is                  CALL F2S2H (PRHS, BRHS, COEFU, NX, NY, AX, BX, AY, BY,                              IBCTY, IORDER, U, LDU, UWORK, WORK)        The additional arguments are as follows:        UWORK  - Work array of size NX+2 by NY+2.  If the actual                 dimensions of U are large enough, then U and UWORK can                  be the same array.             WORK   - Work array of length (NX+1)(NY+1)(IORDER-2)/2+                  6(NX+NY)+NX/2+16.           2. The grid spacing is the distance between the (uniformly spaced)         grid lines.  It is given by the formulas HX = (BX-AX)/(NX-1) and        HY = (BY-AY)/(NY-1).  The grid spacings in the X and Y directions       must be the same, i.e., NX and NY must be such that HX equals HY.       Also, as noted above, NX and NY must both be at least 4.  To            increase the speed of the fast Fourier transform, NX-1 should be        the product of small primes.  Good choices are 17, 33, and 65.               3. If -COEFU is nearly equal to an eigenvalue of the Laplacian with        homogeneous boundary conditions, then the computed solution might       have large errors.            Chapter(s)   MATH/LIBRARY Differential Equations          Computer     crympu/SINGLE        Revised      May 30, 1991         Warranty     IMSL warrants only that IMSL testing has been applied                   to this code.  No other warranty, expressed or implied,                 is applicable.               Copyright    1991 by IMSL, Inc.  All Rights Reserved.
GX119-85-2614157	[index]   [keywords]   [category]   [parent]   Category A6C [Decomposition, construction]       PRIME       Decompose an integer into its prime factors.
GX168-03-5534074	"Proof of Goldbach's Conjecture Reza Javaherdashti School of Physics and Materials Engineering Monash University-Australia reza.javaherdashti@spme.monash.edu.au Abstract After certain subsets of Natural numbers called ""Range"" and ""Row"" are defined, we assume (1) there is a function that can produce prime numbers and (2) each even number greater than 2, like A, can be represented as the sum of n prime numbers. We show this by DC(A)  n. Each Row is similar to each other in properties,(so is each Range). It is proven that in an arbitrary Row for any even number greater than 2, DC(A)=2, that is to say, each prime number greater than two is the sum of two prime numbers. So Goldbach's conjecture is proved. 1.Historical Background: Of still-unsolved problems on prime numbers one can mention Goldbach's conjecture. Goldbach (1690-1764) in his letter to Euler in 1742, asked if any even number greater than 2 could be written as the sum of two prime numbers. Euler could not answer nor could he find any counter-example. The main problem with Goldbach's conjecture is that in most of theorems in arithmetic, prime numbers appear as products, however, in Goldbach's conjecture it is the addition of prime numbers that makes all the problem. In 1931, a young, not that famous Russian mathematician named Schnirelmann (1905-1938) proved that any positive integer could have been represented, at most, as the sum of 300,000 prime numbers. The reasoning was constructive and direct without giving any practical use to decompose a given integer into the sum of prime numbers. Some years after him, the Russian mathematician Vinogradoff by using and improving methods invented by the English mathematicians, Hardy and Littlewood, and their great Indian colleague Ramanujan, could decrease number of the mentioned prime numbers from 300,000 to 4. Vinogradoff's approach has been proved to be true for integers ""large enough"". With exact words, Vinogradoff proves that there exists an integer like N so that for any integer n>N, it can be represented, at most, as the sum of four prime numbers. He 1   gives noway to determine and measure N. Vingoradoff's method has actually proved that accepting the infinite integers that cannot be shown as the sum of, at most, four prime numbers, results in contradiction. 2.Method and Basic Assumptions: The method we use in our approach, relies on the following facts (or, interpretations): 1.Controversial points with Goldbach's conjecture are: 1.1.It seems as if there must be a kind of formula that can produce prime numbers. 1.2. After such a prime number-producing formula is found, one should look for its relationship with even numbers greater than 2. 2.Goldbach assumes that sum of prime numbers gives even numbers greater than 2; the problem is how to limit the number of such prime numbers with only two. To clarify the approach, we assume that: Assumption #1: There is a function like f (x) that produces prime numbers. Assumption #2: Each even number greater than 2, can be taken as to be the sum of n prime number where n is a Natural number. Using the above-mentioned assumptions, we define ""Row"" and ""Range"" as subsets of Natural numbers. Then, if DC (A) designates that how many even numbers are there that produce even number A greater than 2, we prove DC(A)=2, in other words, we will prove that there is only two even numbers whose addition results in an even number like A which is greater than 2. So that Goldbach's conjecture is proved. Our method consists of three parts: I. II. III. Basic concepts on ""Row"" and ""Range"". Basic definitions of f(x) and DC(A). Proof.  We will NOT use statistical data or tables of prime numbers in our method.  2   Part 1): Basic concepts on ""Row"" and ""Range"" 1.1.Definition of Row: Row-that we show as r(xi xf)- is a term used for representing any subset of Natural numbers, N, that has all of the properties below: I. r(xi xf)  N, that is, each ""Row"" is a subset of Natural numbers. If n[r(xi xf)] shows the number of elements of the set r(xi xf), then II is defined as: n[r(xi xf)] = d II. dN The above means that in a Row, number of elements is limited. (property of having a smallest and a greatest element in a Row): Each r(xi xf) has one ""smallest"" and a ""greatest"" element, that is, each r(xi xf), at most, has an ""smallest"" element like xi in r(xi xf) such that for all x r(xi.xf), x>xi In the same way, each r(xi xf) has one ""greatest"" element like xf such that for all x r(xi xf) : x < xf . So xf is the ""greatest element"" of r(xi xf) and there is no element larger than it. III. (property of an ordered Row): In each Row r(xi xf) all of its elements are orderable, from left to right, and from the smallest to the largest element. 1.1.1. Examples: A = {1,2,3,4} A is a Row so A = r(14) as xi = 1 and xf = 4 B = {25,26,27} B is a Row so B = r(2527) as xi = 25 and xf = 27 C = {4,3,2,1} C is NOT a Row; IV is not held. D = {5,9,10,11,14} D is NOT a Row; IV is not held. E = {49,51,53,55} Convention.1: 1- From now on, instead of r(xi xf), the symbol r(if) is used. 2- According to III, x< xi or x> xf is not defined in r(if). 3- Any r(if), schematically can be shown as follows: E is NOT a Row; IV is not held.  3   x  i  x  1  x  2  x  n  x  f  r(if) = { xi , x1 , x2 , .... , xn , x 1.2.Definition of Range:  f}  xn < x  f  Range-that we show as R(xI xF)-is a term used for representing any subseet of Natural numbers that has all of the properties below: [1]. R(xI xF)  N [2]. r(if)  R(xI xF) [3]. n[R(xI xF)] = D DN, D>d [4]. Each R(xI xF) has, at most, a ""smallest"" element shown as xi , and a ""greatest"" element xF ,ie; for each X R(xI xF): X < xF , X > x X-1< X< X+1 [6]. All the elements of a Range R(xI xF) can be ordered, from left to right and from the smallest to the largest element. 1.1.2.Examples: F = {1,2,3,...,98,99,100} G = {5,6,7,...,22,23} F is a Range so F = R(1100),r(110)  F,...so [2] is held. G is range so G = R(523) I  [5]. For each X R(xI xF) giving X  xI and X  xF :  H = {30,31,32,35,36,37,39,41,42,45} H is NOT a Range, [5] is not held. I = {31,32,50,33,50,1,2,4,10,2000} I, is NOT a Range,; -[2] is not held as only {1,2} and {31,32} have the smallest and the largest elements, so IV is not held for these subsets. -[5] is not held. -[6] is not held.  4   Convention.2: 1-From now on, R(xI xF) is shown as R(IF). 2-By considering [2] and [4], it appears that in some cases XI = xi or XF = xf ,for example, in F, XI = 1 and also in A, xi = 1 (A  F). 3-By using ""Row"" and ""Range"" concepts, N (natural numbers set) can be subdivided into subsets that have certain properties as R(IF)  N and r(if)  R(IF). There are infinite number of R(IF) sets but definite and limited number of r(IF) subsets, for instance, there are inifinite number of sets like R(1100), R(101200), R(201300) etc. but in each of these sets there are limited and definite number of r(if);as an example, in R(1100),there are ten subsets (=Rows) such as r(110), r(1120), r(2130),..., r(91100). So, any theorem that is proved or any conclusion that is made for arbitrary r(if) and R(IF), can then be generalised for all similar Rows and Ranges so that what is proven, will be applicable to whole Natural numbers. Convention.3: For each x which is an element of a Row r(if), we use the following symbolism: xr(if) or (x)r(if) and for each X which is an element of R(IF), we use the following symbolism: XR(IF) or (X)R(IF) And so forth. Convention.4: In a Row r(ij), its smallest element-that is xi can be shown as either (xi)r(ij) or A( i ) and its greatest element-xf-can be shown as (xf)r(ij) and so forth. Result of Convention.4: In a Row r(pq), A(p) is the smallest element. In a Row r(st), A(s) is the smallest element and so forth. Theorem.1 Take two Rows r(ij) and r(kl) in a range R(IF). Prove that for all xi and xf elements of these Rows, we have: (xf)r(ij)  p = (xi)r(kl) where p is a constant. Proof: Assume that p = 0, then (xf)r(ij) = (xi)r(kl). Now take R(IF) as:  5   (1) (r(ij)  R(IF) & (r(kl)  R(IF))R(IF) = r(ij) results in: (2) (xR(IF))  (xr(ij)) & (xr(kl))  r(kl), where "" "" is union sign,  as (xi)r(kl)r(kl) and (xf)r(ij)r(ij), then both (xi)r(kl) and (xf)r(ij) must be elements of R(IF) but in this case: 1.the difference between (xi)r(kl) and (xf)r(ij) will not be equal to unity ( [5] and IV are not held). 2.R(IF) will not be ordered ( [6] is not held) So, R(IF) will not be a Range but this is in contradiction with our assumption. Therefore, p0. If each element of r(ij) is smaller than each element of r(kl) then, (xf)r(ij) + p = (xi)r(kl) and so forth. Definition.1: If (xf)r(ij) + p = (xi)r(kl), r(ij) and r(kl) are called ""Successive Rows"". Part.2): Basic definitions of f(x) and DC(A Definition 2: We define a function f(x) so that for any x = a, f(a) be a prime number. Definition 3: The ""degree of complexity"" function that we show it as ""DC"" is the number of prime numbers to be added to each other with a + sign between each to yield an even number greater than two. DC will itself be a Natural number. 2.2.1.Example: -For 8 = 2 + 2 + 2 + 2 -For 8 = 5 + 3 -For 216 = 213 + 3 DC (8) = 4 DC (8) = 2 DC (216) = 2  Conclusion from definition 3: The least value for DC(A), where A is an even number greater than 2, is 2; ie, DC (A)  2. Definition 4: In any Row r(ij) of the Range R(IF), number of even numbers (2K), odd numbers (2K + 1) and prime numbers (f(x)) are shown, respectively, as (2K), (2K + 1), and f(x). So in the Range R(1100) and Row r(110), (2K) = 5 that is to say, (2,4,6,8,10), (2K + 1) = 5 ie (1,3,5,7,9) and f(x) = 4 (2,3,5,7).  6   Part.3): Proof Assumptions: 1) Assume in Row r(ij) of Range R(IF), there exists at least one prime number like f(x). 2) Assume in any Row r(ij), the number of even and odd numbers are equal to each other (in any Row there is as many odd numbers as there is even numbers). So in any Row r(ij) there exists odd and even numbers alternatively (after each odd number there is an even number and vice versa). 3) Assume in a Row r(ij), number of odd numbers be more than prime numbers in the same Row, in other words, any prime number greater than 2 is an odd number BUT any odd number is NOT a prime number. From assumptions 1) and 3), one concludes: (3) 1  f(x)  (2K + 1) For even numbers greater than 2, like A, degree of complexity function can be written as DC (A). According to the conclusion from definition 3, DC (A)  2, ie, at least two prime numbers must be added to each other to yield A. As A is an even number greater than 2, the number of even numbers that are required to be added to each other to yield A, will be less than the number of existing even number in the Row r(ij), so in r(ij) the number of prime numbers to be added up to yield A is: (4) DC (A)  (2K) By adding (2K + 1) to right-hand sides of inequalities (3) and (4) it yields: (5) f(x)  (2K + 1) + (2K + 1) (6) DC (A)  (2K) + (2K + 1) According to assumption 2) (2K) = (2K + 1); by applying this to (5) , it yields: (7) f(x)  (2K) + (2K + 1) by adding each side of (6) and (7) to each other , we take: (8) DC (A) + f(x)  2[(2K) + (2K + 1)] or (9) DC (A)  2[(2K) + (2K + 1)] - f(x) Combining the conclusion from definition 3 with inequality (9) yields: (10) 2  DC (A) 2[(2K) + (2K + 1)] - f(x) The above relation can be decomposed into the following three inequalities:  7   (11-1) DC (A) > 2 (11-2) DC (A) 2[(2K) + (2K + 1)] - f(x) (11-3) DC (A) = 2 We will prove that (11-1) and (11-2) will be resulting in contradictions so that they will not be held. Therefore, the only remaining relation will be (11-3) that states that the number of even numbers to be added up to yield an even number greater than 2, is two. Assume (11-1) holds, ie, DC > 2. This means: (12) DC (A) = a1 + a2 + i=m i =3    a  i  Where m shows total number of numbers-even, odd and prime numbers-existing in a given Row r(ij); ai (i = 1,2,3,...,m) shows the prime numbers to yield A. Relation (12) may be re-written as (13): (13) DC (A) = 2 + i=m i =n    a  i  Where n is an arbitrary number less than m. One should notice that in (12) a1 and a2 are two even numbers where in (13) some prime numbers like number like 2. Equation (13) yields: (14) DC (A)  2 =   i =n  i=m  a i are added to a   n  m  a  i   n  m  ai represents the number of prime numbers in a Row r(ij) which is less than total  number of existing prime numbers of r(ij), that is to say: (15)   n  m  a i  f(x)  replacing (14) into (15) yields: (16) DC (A)  2 = f(x) Assumption 3) of Part.3):Proof about odd and prime numbers gives: (17) m n    a i  (2K + 1)  replacing (14) into (17) yields: (18) DC (A)  2 = (2K + 1)  8   Or (19) DC (A)  (2K + 1) + 2 From (16), (20) is resulted: (20) DC (A)  f(x) + 2 By adding sides of (19) and (20) to each other: (21) 2DC (A)  (2K) + f(x) + 4 as DC (A) < 2DC (A), one may conclude (22). To let the inequality hold with more force, we add (2K) to right-hand side of (21) too; (22) 2DC (A)  (2K) + (2K + 1) f(x) + 4 The right-hand side of (22) may be written as (23): (23) 2[(2K) + (2K + 1)] - f(x) = [(2K) + (2K + 1) + f(x) + 4] + [(2K) + (2K + 1) - 2f(x) - 4] (24) (2K) + (2K + 1) + f(x) + 4 < 2[(2K) + (2K + 1)] - f(x) To combine (22) and (24) yields: (25) DC (A) < (2K) + (2K + 1) + f(x) + 4 < 2[(2K) + (2K + 1)] - f(x) The relation (25) results in: (26) DC (A) < 2[(2K) + (2K + 1)] - f(x) Inequality (26) resembles (11-2). So we will consider (26) more precisely: One sees that DC (A)  2[(2K) + (2K + 1)] - f(x) shows the number of prime numbers in a given Row r(ij) to be added to each other to result in a number like A, which is an even number greater than2. Therefore, 2[(2K) + (2K + 1)] - f(x) must be less than the number of existing odd numbers in r(ij) (Assumption 3) of Part.3):Proof). On the other hand, according to assumption 2) Part.3):Proof at least half of the total numbers in a Row r(ij) in other words, m -are existing odd numbers of r(ij). As it 2  was stated in (12), if m be total number of existing numbers in a Row r(ij), then: (27) 2[(2K) + (2K + 1)] - f(x)  m 2  as (2K) + (2K + 1) = m (Assumption 2) of Part.3):Proof)): (28) 2m - f(x)  (29) 1.5m  f(x) m 2  9   as m < 1.5m then: (30) m < 1.5m < f(x) or: (31) m < f(x) Inequality (31) is not held as it states that in a Row r(ij), the number of prime numbers of the Row is larger than total numbers of the Row, which is IMPOSSIBLE. In the same way, one may prove that if (26) is written as: DC (A) = 2[(2K) + (2K + 1)] - f(x), again we will come up with the contradiction stated as in (31). The above discussion shows that (11-2) is NOT held. One may show (25) as a combination of the following: (32-1) DC (A) > 2 (32-2) DC (A) < (2K) + (2K + 1) f(x) + 4 (32-3) DC (A) < 2[(2K) + (2K + 1)] - f(x) We call (32-1) through (32-3), as p, q and r, respectively so that we translate (25) to the logical expression (33)as a conjunction: (33) p ( q & r) where ""&"" represents conjunction sign. According to what we have gained so far:: 1.r is false, ie, relations (27) to (31) prove that : DC (A)  2[(2K) + (2K + 1)] - f(x) Is NOT held. 2.as r is false, then (q & r) is false. So p must be false also , that is to say: DC (A) > 2 Is NOT held. As conclusion; Conclusion #1: (11-1) isnot held so DC < 2 isnot true. Conclusion #2: (11-2) isnot held so DC (A)  2[(2K) + (2K + 1)] - f(x) isnot true. Conclusion #3: (11-3) holds as the only possibility so DC (A) = 2 is true. In fact Conclusion #3 states that, A, which is an even number greater than 2 can be written as the sum of two prime numbers. So Goldbach's conjecture is true.  10   Summary: By defining certain subsets in Natural numbers set, after all possibilities are considered, we prove that Goldbach's conjecture is held in one arbitrary . The proof can be generalised to all the subsets so that the conjecture is proven for all Natural . Numbers.  11"
GX220-50-2332810	Other matches ...                    The other matches can be divided into several groups:             Exact matches to one primer       Partial 3' end matches to one primer        Partial 5' end matches to one primer       Partial matches to both primers            The alignments in the BLAST result for short primer sequences generally     do not contain gaps due to the short query size and large gap penalty.                      It is difficult to generalize the analysis of the remaining hits since it is     dependent on the purpose of the search.            The first two groups of hits are primer annealing sites or potential annealing sites     where the primers can hybridize to prime the DNA synthesis if the condition is right.     Even though they are less a problem for PCR since there is no corresponding annealing     sites for the second primer, they should be considered if the primer is to be used     directly as probe or for probe labeling.                If one would like to use the primer to amplify homologous region from another organism,     one would need to examine the hits with alignments to both primers - partial hits connected by     hatched lines.
GX227-75-7754197	CHARMM c27b3 ewald.doc     File:  Ewald  -=-    Node:  Top    Up : ( commands.doc ) -=-   Next :  Syntax  -=-   Previous :  Top                         The Ewald Summation method    Invoking the Ewald summation for calculating the electrostatic interactions  can be specified any time the nbond specification parser is invoked.  See   the syntax section for a list of all commands that invoke this parser.    Prerequisite reading:  nbonds.doc   * Menu:  *  Syntax ::          Syntax of the Ewald summation specification *  Defaults ::        Defaults used in the specification *  Function ::        Description of the options *  Discussion ::      More general discussion of the algorithm    File:  Ewald  -=-    Node:  Syntax    Up :  Top  -=-   Next :  Defaults  -=-   Previous :  Top  [SYNTAX EWALD]  {  NBONds          }        {  nonbond-spec                   } {  UPDAte          }        {                                 } {  ENERgy          }        {                                 } {  MINImize        }        {                                 } {  DYNAmics        }        {                                 }   The keywords are:  nonbond-spec::= [ method-spec ]                 { [ NOEWald ]                                          }                {                                                      } method-spec::= {   EWALd [ewald-spec] { [ NOPMewald [std-ew-spec] ] } }                {                      {   PMEWald [pmesh-spec]      } }   ewald-spec::=   KAPPa real  [erfc-spec]  std-ew-spec::= { [ KMAX integer ]                        } KSQMAX integer                { KMXX integer KMXY integer KMXZ integer  }  pmesh-spec::=   FFTX int FFTY int FFTZ int  ORDEr integer [QCOR real (***) ]  erfc-spec::=    { SPLIne      { [EWMIn real] [EWMAx real] [EWNPts int] } }                 { INTErpolate {                                        } }                 {                                                        }                 { ABROmowitz                                             }                 { CHEBychev                                              }                 { EXACt_high_precision                                   }                 { LOWPrecision_exact                                     }                 { ERFMode int                                            }    File:  Ewald  -=-    Node:  Defaults    Up :  Top  -=-   Next :  Function  -=-   Previous :  Syntax  The defaults for the ewald summation are set internally and are currently set to NOEWald, KAPPa=1.0, KMAX=5, KSQMax=27, and NOPMewald, KAPPa=1.0, FFTX=FFTY=FFTZ=32, ORDEr=4, QCOR=1.0  Recommended values for Ewald are:    EWALD PMEWald KAPPa 0.34 ORDEr 6 -     FFTX intboxvx FFTY intboxvy FFTZ intboxvz  -    CTOFNB 12.0 CUTNB 14.0 QCOR 1.0(***)  Where intboxv* is an integer value similar to or larger than the corresponding unit cell dimension that has prime factors of 2,3, and 5 only (2,3 preferred). grid point spacing should be between 0.8 and 1.2 Angstroms.  These recommended values should give relative force errors of roughly 10**-5. To reduce the total PME cost at the expense of accuracy, decrease the cutoff distances while increasing KAPPa (keep the product near 4) reduces the real space cost.  To reduce the K-space cost, either reduce ORDEr from 6 to 4 or increase the grid spacing up to perhaps 1.5 Angstroms.  (***) The QCOR value should be 1.0 for vacuum, solid, or finite systems. For periodic systems in solution, it should be reduced (or set to zero) by an amount that depends on how the net charge is distributed and on the effective dielectric constant.  For a treatise on this correction term, see: S. Bogusz, T. Cheatham, and B. Brooks, JCP (1998) 108, 7070-7084 and references contained therein (esp. Hummer and Levy).    File:  Nbonds  -=-    Node:  Function    Up :  Top  -=-   Previous :  Defaults  -=-   Next :  Discussion   i)   The EWALD keyword invokes the Ewald summation for calculation of  electrostatic interactions in periodic, neutral systems.  The formulation of  the Ewald summation dictates that the primary system must be neutral.  If  otherwise, the summation is not formally correct and some  convergence problems may result.  The NOEWald (default) suppresses the Ewald  method for calculating electrostatic interactions.  Van der waals  options VSHIFT and VSWITCH are supported with ewald.  The algorithm currently supports the atom and group nonbond lists and the CRYSTAL facilty  must be used.  The PMEWald keyword invokes the Particle Mesh Ewald algorithm for the reciprocal space summation.  For details on the PME method, see J. Chem. Phys. 103:8577 (1995).  The EWALd algorithm is limited to CUBIC, TETRAGONAL, and ORTHORHOMBIC unit cells.  The PMEWald algorithm supports all unit cells that are supported by the CRYSTAL facility.   ii)  The KAPPa keyword, followed by a real number governs the width of the  Gaussian distribution central to the Ewald method.  An approximate value of kappa can be chosen by taking KAPPa=5/CTOFNB.  This is fairly conservative. Values of 4/CTOFNB lead to small force errors (roughly 10**-5).  See discussion section for details on choosing an optimum value of KAPPa.  iii) The KMAX key word is the number of kvectors (or images of the  primary unit cell) that will be summed in any direction.  It is the  radius of the Ewald summation.  For orthorombic cells, the value of  kmax may be independently specified in the x, y, and z directions with the keywords KMXX, KMXY, and KMXZ.  In the PME version, the number of  FFT grid points for the charge mesh is specified by FFTX, FFTY, and FFTZ.   iv) The KSQMax key word should be chosen between  KMAX squared and 3 times KMAX squared.   v) An appropriate, although not optimal, set of parameters can be  chosen by taking KAPPA=5/CTOFNB and KMAX=KAPPa*boxlength. The actual  values should then be performanced optimized for your particular system. For the PME method, FFTX should be approximately the box length in Angstroms. (for efficiency, FFTX should be a multiple of powers of 2,3, and 5).     IMPORTANT NOTE::: THE SUGGESTION THAT FFTX, FFTY, AND FFTZ HAVE    NO PRIME FACTORS OTHER THAN 2, 3, AND 5 SEEMS TO BE A REQUIREMENT.    LARGE ERRORS IN THE FORCE ARE OBSERVED WHEN THIS CONDITION IS NOT MET.    FUTURE VERSIONS OF CHARMM WILL FLAG THIS AS AN ERROR CONDITION.  ORDEr specifies the order of the B-spline interpolation, e.g. cubic is order 4 (default), fifth degree is ORDEr 6.  The ORDEr must be an even number and at least 4.   vi) EWALd runs in parallel on both shared (PARVECT) and distributed memory parallel computers.  PME runs in parallel on distributed memory computers.  vii) several algorithms are available for the calculation of the complimentary error function, erfc(x).  EXACt and LOWPrecision use an interative technique described in section 6.2 of Numerical Recipies.  ABRO and CHEB are polynomial approximations.  A lookup table (filled at the beginning of the simulation using the EXACt method) can be used with either a linear (INTE) of cubic  spline (SPLINe) interpolation.  SPLIne is recommended.  viii) Ewald with MMFF  A version of EWALD was developed for MMFF.  The usual MMFF electrostatic term: qq/(r+d)  is split into two terms:  qq/r -  qq*d/(r*(r+d)) The first term is handled by the Ewald method in the usual manner (real-space and k-space parts) and the second term is truncated at the cutoff distance using a switching function (from CTONNB to CTOFNB). Since the second term is quite small at the cutoff distance, the use of a switching function should not introduce significant artificial forces.    File:  Ewald  -=-    Node:  Discussion    Up :  Top  -=-   Previous :  Function  -=-   Next :  Top            The Ewald Summation in Molecular Dynamics Simulation   The electrostatic energy of a periodic system can be expressed by a lattice   sum over all pair interactions and over all lattice vectors excluding the i=j term in the primary box.  Summations carried out in this simple  way have been shown to be conditionally convergent.  The method developed by  Ewald, in essence, mathematically transforms  this fairly straightforward   summation to two more complicated but rapidly convergent sums.  One summation  is carried out in reciporcal space while the other is carried out in real  space.  Based on the formulation by Ewald, the simple lattice sum can be reformulated to give absolutely convergent summations which define the principal value of the electrostatic potential, called the intrinsic potential. Given the periodicity present in both crystal calculations and in dynamics  simulations using periodic boundary conditions,  the Ewald formulation becomes  well suited for the calculation of the electrostatic energy and force. If we  consider a system of point charges in the unit or primary cell, we can specify  its charge density by    ro(r) = sum_i [ q_i * delta(r-r_i)]   In the Ewald method  this distribution is replaced by two other distributions   ro_1(r) = sum_i [ q_i ( delta(r-r_i) - f(r-r_i)]  and  ro_2(r) = sum_i [q_i f(r-r_i)  such that the sum of the two recovers the original.  The distribution, f(r), is a spherical distribution generally taken to be Gaussian, the width of the gaussian dictated by the parameter, KAPPa.  The charge distributions are situated on the ion lattice positions, but integrate to zero.  The potential from the distribution ro_1(r) is a short range potential evaluated in a direct real space summation (truncated at CTOFNB).  The diffuse charge distribution placed on the lattice sites reduces to the potential of the corresponding point charge at large r. ro_2(r), being a continuous distribution of Gaussians situated on the periodic lattice positions, is a smoothly varying function of r and thus is well approximated by a superposition of continuous functions.  This distribution is, therefore, expanded in a Fourier series and the potential is obtained by solving the Poisson equation.  The point of splitting the problem into two parts, is that by a suitable choice of the parameter KAPPa we can get very good convergence of both parts of the summation.  For the real space part of the energy, we choose kappa so that the complementary error function term, erfc(kappa*r) decreases rapidly enough with r to make it a good approximation to take only nearest images in the sum and neglect the value for which r > CTOFNB.  The reciprocal space sums are rapidly convergent and a spherical cutoff in k space is applied so that the sum over k becomes a sum over {l,m,n}, with (l**2+m**2+n**2) < or = to KSQMAX A large value of KAPPa means that the real space sum is more rapidly convergent but the reciprocal space sum is less rapid.  In practice one chooses KAPPa to give good convergence at the cutoff radius, CTOFNB.  KMAX is then chosen to such that the reciprocal space calculation converges.  The equation (KMAX/(box length)=KAPPa may be used as a rough guide.  Optimization with respect to the timing trade offs, ie.  how much time is spent in real space vs k-space should be performed before a lengthy production run.  The CCP5 notes in several articles in 1993 cover some possible optimization strategies and criteria although a simple line search will suffice.  Complete optimiztion of the ewald method for a particular application requires optimizing CTOFNB, KAPPa, and KMAX.  A discussion of optimization and error analysis can be found in Kolfka and Perram, Molecular Simulation, 9, 351 (1992).   For PME, see Feller, Pastor, Rojnuckarin, Bogusz, and Brooks. J. Phys. Chem., 100, 42, 17011 (1996) and some of Tom Darden's published work.              NIH/CIT Biowulf         CHARMM Documentation /   Rick_Venable@nih.gov
GX227-77-6043563	CHARMM c28b2 ewald.doc     File:  Ewald  -=-    Node:  Top    Up : ( commands.doc ) -=-   Next :  Syntax  -=-   Previous :  Top                         The Ewald Summation method    Invoking the Ewald summation for calculating the electrostatic interactions  can be specified any time the nbond specification parser is invoked.  See   the syntax section for a list of all commands that invoke this parser.    Prerequisite reading:  nbonds.doc   * Menu:  *  Syntax ::          Syntax of the Ewald summation specification *  Defaults ::        Defaults used in the specification *  Function ::        Description of the options *  Discussion ::      More general discussion of the algorithm    File:  Ewald  -=-    Node:  Syntax    Up :  Top  -=-   Next :  Defaults  -=-   Previous :  Top  [SYNTAX EWALD]  {  NBONds          }        {  nonbond-spec                   } {  UPDAte          }        {                                 } {  ENERgy          }        {                                 } {  MINImize        }        {                                 } {  DYNAmics        }        {                                 }   The keywords are:  nonbond-spec::= [ method-spec ]                 { [ NOEWald ]                                          }                {                                                      } method-spec::= {   EWALd [ewald-spec] { [ NOPMewald [std-ew-spec] ] } }                {                      {   PMEWald [pmesh-spec]      } }   ewald-spec::=   KAPPa real  [erfc-spec]  std-ew-spec::= { [ KMAX integer ]                        } KSQMAX integer                { KMXX integer KMXY integer KMXZ integer  }  pmesh-spec::=   FFTX int FFTY int FFTZ int  ORDEr integer [QCOR real (***) ]  erfc-spec::=    { SPLIne      { [EWMIn real] [EWMAx real] [EWNPts int] } }                 { INTErpolate {                                        } }                 {                                                        }                 { ABROmowitz                                             }                 { CHEBychev                                              }                 { EXACt_high_precision                                   }                 { LOWPrecision_exact                                     }                 { ERFMode int                                            }    File:  Ewald  -=-    Node:  Defaults    Up :  Top  -=-   Next :  Function  -=-   Previous :  Syntax  The defaults for the ewald summation are set internally and are currently set to NOEWald, KAPPa=1.0, KMAX=5, KSQMax=27, and NOPMewald, KAPPa=1.0, FFTX=FFTY=FFTZ=32, ORDEr=4, QCOR=1.0  Recommended values for Ewald are:    EWALD PMEWald KAPPa 0.34 ORDEr 6 -     FFTX intboxvx FFTY intboxvy FFTZ intboxvz  -    CTOFNB 12.0 CUTNB 14.0 QCOR 1.0(***)  Where intboxv* is an integer value similar to or larger than the corresponding unit cell dimension that has prime factors of 2,3, and 5 only (2,3 preferred). grid point spacing should be between 0.8 and 1.2 Angstroms.  These recommended values should give relative force errors of roughly 10**-5. To reduce the total PME cost at the expense of accuracy, decrease the cutoff distances while increasing KAPPa (keep the product near 4) reduces the real space cost.  To reduce the K-space cost, either reduce ORDEr from 6 to 4 or increase the grid spacing up to perhaps 1.5 Angstroms.  (***) The QCOR value should be 1.0 for vacuum, solid, or finite systems. For periodic systems in solution, it should be reduced (or set to zero) by an amount that depends on how the net charge is distributed and on the effective dielectric constant.  For a treatise on this correction term, see: S. Bogusz, T. Cheatham, and B. Brooks, JCP (1998) 108, 7070-7084 and references contained therein (esp. Hummer and Levy).    File:  Nbonds  -=-    Node:  Function    Up :  Top  -=-   Previous :  Defaults  -=-   Next :  Discussion   i)   The EWALD keyword invokes the Ewald summation for calculation of  electrostatic interactions in periodic, neutral systems.  The formulation of  the Ewald summation dictates that the primary system must be neutral.  If  otherwise, the summation is not formally correct and some  convergence problems may result.  The NOEWald (default) suppresses the Ewald  method for calculating electrostatic interactions.  Van der waals  options VSHIFT and VSWITCH are supported with ewald.  The algorithm currently supports the atom and group nonbond lists and the CRYSTAL facilty  must be used.  The PMEWald keyword invokes the Particle Mesh Ewald algorithm for the reciprocal space summation.  For details on the PME method, see J. Chem. Phys. 103:8577 (1995).  The EWALd algorithm is limited to CUBIC, TETRAGONAL, and ORTHORHOMBIC unit cells.  The PMEWald algorithm supports all unit cells that are supported by the CRYSTAL facility.   ii)  The KAPPa keyword, followed by a real number governs the width of the  Gaussian distribution central to the Ewald method.  An approximate value of kappa can be chosen by taking KAPPa=5/CTOFNB.  This is fairly conservative. Values of 4/CTOFNB lead to small force errors (roughly 10**-5).  See discussion section for details on choosing an optimum value of KAPPa.  iii) The KMAX key word is the number of kvectors (or images of the  primary unit cell) that will be summed in any direction.  It is the  radius of the Ewald summation.  For orthorombic cells, the value of  kmax may be independently specified in the x, y, and z directions with the keywords KMXX, KMXY, and KMXZ.  In the PME version, the number of  FFT grid points for the charge mesh is specified by FFTX, FFTY, and FFTZ.   iv) The KSQMax key word should be chosen between  KMAX squared and 3 times KMAX squared.   v) An appropriate, although not optimal, set of parameters can be  chosen by taking KAPPA=5/CTOFNB and KMAX=KAPPa*boxlength. The actual  values should then be performanced optimized for your particular system. For the PME method, FFTX should be approximately the box length in Angstroms. (for efficiency, FFTX should be a multiple of powers of 2,3, and 5).     IMPORTANT NOTE::: THE SUGGESTION THAT FFTX, FFTY, AND FFTZ HAVE    NO PRIME FACTORS OTHER THAN 2, 3, AND 5 SEEMS TO BE A REQUIREMENT.    LARGE ERRORS IN THE FORCE ARE OBSERVED WHEN THIS CONDITION IS NOT MET.    FUTURE VERSIONS OF CHARMM WILL FLAG THIS AS AN ERROR CONDITION.  ORDEr specifies the order of the B-spline interpolation, e.g. cubic is order 4 (default), fifth degree is ORDEr 6.  The ORDEr must be an even number and at least 4.   vi) EWALd runs in parallel on both shared (PARVECT) and distributed memory parallel computers.  PME runs in parallel on distributed memory computers.  vii) several algorithms are available for the calculation of the complimentary error function, erfc(x).  EXACt and LOWPrecision use an interative technique described in section 6.2 of Numerical Recipies.  ABRO and CHEB are polynomial approximations.  A lookup table (filled at the beginning of the simulation using the EXACt method) can be used with either a linear (INTE) of cubic  spline (SPLINe) interpolation.  SPLIne is recommended.  viii) Ewald with MMFF  A version of EWALD was developed for MMFF.  The usual MMFF electrostatic term: qq/(r+d)  is split into two terms:  qq/r -  qq*d/(r*(r+d)) The first term is handled by the Ewald method in the usual manner (real-space and k-space parts) and the second term is truncated at the cutoff distance using a switching function (from CTONNB to CTOFNB). Since the second term is quite small at the cutoff distance, the use of a switching function should not introduce significant artificial forces.    File:  Ewald  -=-    Node:  Discussion    Up :  Top  -=-   Previous :  Function  -=-   Next :  Top            The Ewald Summation in Molecular Dynamics Simulation   The electrostatic energy of a periodic system can be expressed by a lattice   sum over all pair interactions and over all lattice vectors excluding the i=j term in the primary box.  Summations carried out in this simple  way have been shown to be conditionally convergent.  The method developed by  Ewald, in essence, mathematically transforms  this fairly straightforward   summation to two more complicated but rapidly convergent sums.  One summation  is carried out in reciporcal space while the other is carried out in real  space.  Based on the formulation by Ewald, the simple lattice sum can be reformulated to give absolutely convergent summations which define the principal value of the electrostatic potential, called the intrinsic potential. Given the periodicity present in both crystal calculations and in dynamics  simulations using periodic boundary conditions,  the Ewald formulation becomes  well suited for the calculation of the electrostatic energy and force. If we  consider a system of point charges in the unit or primary cell, we can specify  its charge density by    ro(r) = sum_i [ q_i * delta(r-r_i)]   In the Ewald method  this distribution is replaced by two other distributions   ro_1(r) = sum_i [ q_i ( delta(r-r_i) - f(r-r_i)]  and  ro_2(r) = sum_i [q_i f(r-r_i)  such that the sum of the two recovers the original.  The distribution, f(r), is a spherical distribution generally taken to be Gaussian, the width of the gaussian dictated by the parameter, KAPPa.  The charge distributions are situated on the ion lattice positions, but integrate to zero.  The potential from the distribution ro_1(r) is a short range potential evaluated in a direct real space summation (truncated at CTOFNB).  The diffuse charge distribution placed on the lattice sites reduces to the potential of the corresponding point charge at large r. ro_2(r), being a continuous distribution of Gaussians situated on the periodic lattice positions, is a smoothly varying function of r and thus is well approximated by a superposition of continuous functions.  This distribution is, therefore, expanded in a Fourier series and the potential is obtained by solving the Poisson equation.  The point of splitting the problem into two parts, is that by a suitable choice of the parameter KAPPa we can get very good convergence of both parts of the summation.  For the real space part of the energy, we choose kappa so that the complementary error function term, erfc(kappa*r) decreases rapidly enough with r to make it a good approximation to take only nearest images in the sum and neglect the value for which r > CTOFNB.  The reciprocal space sums are rapidly convergent and a spherical cutoff in k space is applied so that the sum over k becomes a sum over {l,m,n}, with (l**2+m**2+n**2) < or = to KSQMAX A large value of KAPPa means that the real space sum is more rapidly convergent but the reciprocal space sum is less rapid.  In practice one chooses KAPPa to give good convergence at the cutoff radius, CTOFNB.  KMAX is then chosen to such that the reciprocal space calculation converges.  The equation (KMAX/(box length)=KAPPa may be used as a rough guide.  Optimization with respect to the timing trade offs, ie.  how much time is spent in real space vs k-space should be performed before a lengthy production run.  The CCP5 notes in several articles in 1993 cover some possible optimization strategies and criteria although a simple line search will suffice.  Complete optimiztion of the ewald method for a particular application requires optimizing CTOFNB, KAPPa, and KMAX.  A discussion of optimization and error analysis can be found in Kolfka and Perram, Molecular Simulation, 9, 351 (1992).   For PME, see Feller, Pastor, Rojnuckarin, Bogusz, and Brooks. J. Phys. Chem., 100, 42, 17011 (1996) and some of Tom Darden's published work.              NIH/CIT Biowulf         CHARMM Documentation /   Rick_Venable@nih.gov
GX003-56-10894348	"HMMERCALIBRATE*     [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]      Table of Contents      FUNCTION   DESCRIPTION   EXAMPLE   OUTPUT   INPUT FILES   RELATED PROGRAMS   RESTRICTIONS   ALGORITHM   CONSIDERATIONS   COMMAND-LINE SUMMARY   ACKNOWLEDGEMENT   LOCAL DATA FILES   PARAMETER REFERENCE                       FUNCTION    [   Top  |  Next  ]          HmmerCalibrate ""calibrates"" a profile hidden  Markov model in order to  increase the sensitivity of  database searches performed using that  profile HMM as a query.   The program compares the  original  profile HMM with a large  number of randomly generated sequences  and computes the extreme value  distribution (EVD) parameters for this  simulated search.  The original  profile HMM is replaced with  a  new one that contains these  EVD parameters.        DESCRIPTION    [  Previous  |  Top  |  Next  ]          HmmerCalibrate provides a GCG interface  to the hmmcalibrate program of  Dr. Sean Eddy's HMMER  package.  It allows you  to access most of hmmcalibrate's  parameters from the GCG command  line.    HmmerCalibrate ""calibrates"" a profile HMM  by generating random sequences and  computing a raw  score for the comparison between  each sequence and the profile  HMM.  The program then  fits the  distribution of these scores to  an extreme value distribution, and  estimates the EVD parameters mu  and lambda for this distribution.   These parameters are inserted  into the profile HMM file.    When using a profile HMM  to search a sequence database  or using a sequence query  to search a profile  HMM database, the search is  more sensitive if the profile  HMM has been calibrated.   Calibration is  time-consuming because it is, in  a sense, equivalent to a  database search in itself.   However, the  calibration only has to be  performed once, as the extreme  value distribution parameters are stored  with  the profile HMM and will  be used whenever you perform  profile HMM-sequence database searches.        EXAMPLE    [  Previous  |  Top  |  Next  ]          Here is a session using  HmmerCalibrate to calibrate the hidden  Markov model profile made in  the  HmmerBuild example session:        %  hmmercalibrate    HMMERCALIBRATE what profile HMM ?   hsp70.hmm_g    Creating temp file for input to hmmcalibrate.   Calling hmmcalibrate to perform analysis ...  hmmcalibrate -- calibrate HMM search statistics HMMER 2.1.1 (Dec 1998) Copyright (C) 1992-1998 Washington University School of Medicine HMMER is freely distributed under the GNU General Public License (GPL). - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - HMM file:                 /usr/users/share/smith/hsp70.hmm_g Length distribution mean: 325 Length distribution s.d.: 200 Number of samples:        5000 random seed:              966630244 histogram(s) saved to:    [not saved] - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -  HMM    : hsp70 mu     :  -492.892303 lambda :     0.088041 max    :  -432.713989 //  %            OUTPUT    [  Previous  |  Top  |  Next  ]          Here is some of the  output file:      HMMER2.0 NAME  hsp70 LENG  677 ALPH  Amino RF    no CS    no MAP   yes COM   gcg_hmmbuild /usr/users/share/smith//hsp70.hmm__g hsp70.msf COM   gcg_hmmcalibrate /usr/users/share/smith/hsp70.hmm__g NSEQ  25 DATE  Fri Jul  9 14:09:29 1999 CKSUM 3252 XT      -8455     -4  -1000  -1000  -8455     -4  -8455     -4 NULT      -4  -8455 NULE     595  -1558     85    338   -294    453  -1158  ...  -1998   -644 EVD   -491.783325   0.094483 HMM        A      C      D      E      F      G      H  ...      W      Y          m->m   m->i   m->d   i->m   i->i   d->m   d->d    b->m   m->e          -368      *  -2150      1    482  -1538   -242    709  -1777   -345     14 ...  -1783  -1160    27      -   -149   -500    233     43   -381    399    106 ...  -294   -249      -    -18  -6880  -7922   -894  -1115   -701  -1378   -368      *      2    209  -1369   -338    519  -1590   -486    -48 ...  -1681  -1096    28      -   -149   -500    233     43   -381    399    106 ...  -294   -249      -    -18  -6880  -7922   -894  -1115   -701  -1378      *      *  ///////////////////////////////////////////////////////////////////////////////     675   -664  -1701     33   2728  -1813  -1361   -295 ...  -1992  -1378   717      -   -149   -500    233     43   -381    399    106 ...  -294   -249      -    -24  -6511  -7553   -894  -1115   -701  -1378      *      *    676   -576   -717  -2213  -1989  -1191  -1755  -1601 ...  -1918  -1514   718      -   -149   -500    233     43   -381    399    106 ...  -294   -249      -    -24  -6511  -7553   -894  -1115   -701  -1378      *      *    677  -1248  -2485   3484    210  -3124   -286   -821 ...  -3039  -2364   719      -      *      *      *      *      *      *      * ...      *      *      -      *      *      *      *      *      *      *      *      0 //        The profile HMM itself wasn't  changed but several new lines  were added to the file.   The two lines  labeled COM are present for  documentation purposes;  they contain the command  lines that were used  to create the original profile  HMM and to perform the  calibration.  The line labeled  EVD contains the  parameters mu and lambda that  describe the extreme value distribution  of the calibration search.   The  values on this line are  used by HmmerSearch and HmmerPfam.        INPUT FILES    [  Previous  |  Top  |  Next  ]          HmmerCalibrate requires as its only  input a file containing one  or more profile HMMs.        RELATED PROGRAMS    [  Previous  |  Top  |  Next  ]           PileUp  creates a multiple sequence  alignment from a group of  related sequences.   LineUp  is  a multiple  sequence editor used to create  multiple sequence alignments.   Pretty   displays multiple sequence  alignments.     ProfileMake  makes a profile from  a multiple sequence alignment.    ProfileSearch  uses the profile to  search a database for sequences  with similarity to the group  of aligned sequences.   ProfileSegments   displays optimal alignments between each  sequence in the  ProfileSearch  output  list and the group of  aligned sequences (represented by the  profile consensus).   ProfileGap  makes  optimal alignments  between one or more sequences  and a group of aligned  sequences represented as a profile.    ProfileScan   finds structural and sequence motifs  in protein sequences, using predetermined  parameters to  determine significance.    HmmerBuild makes a profile hidden  Markov model from a multiple  sequence alignment.  HmmerAlign  aligns one or more sequences  to a profile HMM.   HmmerPfam searches a database of  profile HMMs  with a sequence query in  order to identify known domains  within the sequence.  HmmerSearch  uses a  profile HMM as a query  to search a sequence database  for sequences similar to the  original aligned  sequences.  HmmerCalibrate calibrates a  hidden Markov model so that  database searches using it as  a  query will be more sensitive.   HmmerIndex creates a binary  GSI (""generic sequence index"") for  a  database of profile HMMs.   HmmerFetch retrieves a profile hidden  Markov model by name from  an  indexed database of profile HMMs.   HmmerEmit randomly generates sequences  that match a profile  HMM.  HmmerConvert converts between  different profile HMM file formats  and from profile HMM to  GCG profile file format.     MEME  finds conserved motifs in  a group of unaligned sequences  and saves these motifs as  a set of  profiles.  You can search  a database of sequences with  these profiles using the  MotifSearch   program.        RESTRICTIONS    [  Previous  |  Top  |  Next  ]          Unknown.        ALGORITHM    [  Previous  |  Top  |  Next  ]          See the Profile HMM Analysis  Essay for an introduction to  profile hidden Markov models and  the  terminology associated with them.    In effect, HmmerCalibrate performs a  preprocessing step that enables HmmerSearch  and HmmerPfam  to determine more accurately the  significance of the matches obtained  from a database search.   It  pre-calculates certain parameters that HmmerSearch  and HmmerPfam can use when  computing  E-values for the scores between  the profile HMM query and  each sequence in the database.             What Are E-Values and How  Are They Determined?          Like many other database searching  programs, HmmerSearch and HmmerPfam give  you an  estimate of the significance of  a score  X  obtained from  the search by calculating an  E-value  (expectation) from the score.   Simply put, the E-value is  the number of pairwise matches  expected to score  X  or  higher purely by chance when  searching a sequence database of  this size.    Calculation of E-values is possible  because the limiting distribution for  the scores obtained in a  search of a database of  mostly unrelated sequences is an  extreme value distribution.  Parameters  that describe a particular extreme  value distribution can be determined  empirically.  These EVD  parameters are then substituted into  the equation that is used  to calculate E-values from the  pairwise alignment scores.    In order to obtain these  EVD parameters, some programs (such  as  FastA ) fit the observed  distribution of scores to an  extreme data distribution on the  fly during the database search.   For  example, some use the distribution  of scores from the first  50,000 or 100,000 sequences of  the  database and fit this distribution  to an EVD.  Other  programs randomly sample the scores  from  the entire database and fit  the distribution of these scores  to an EVD.  Both  of these approaches  can be problematical because if  the database sequences (or the  subset of sampled database  sequences) are closely related, the  distribution of scores will deviate  from an extreme value  distribution and the E-values calculated  from the EVD will not  be accurate.        How Does HmmerCalibrate Calculate the  EVD Parameters?          HmmerCalibrate gets around this problem  by ""searching"" an artificial database  of sequences  that are not closely related  in order to estimate the  EVD parameters.  It randomly  generates a  large set of sequences, computes  the score between each sequence  and the profile HMM, fits  the  distribution of these scores to  an extreme value distribution, and  saves the parameters that  describe this EVD in the  profile HMM file.  If  a large enough number of  random sequences were  used, the parameters will be  very accurate.    Instead of having to calculate  the EVD parameters every time  a profile HMM is used  for a  database search, HmmerSearch and HmmerPfam  can simply read these EVD  parameters from  calibrated profile HMM files.    By default, HmmerCalibrate generates 5000  sequences with a variety of  lengths.  The length  distribution follows a Gaussian distribution  centered at 350 residues with  a standard deviation  of 350.  (Since sequences  must have a length of  at least one, the left  side of the length  distribution may be truncated.)  You can  change all of these values  by means of command-line  parameters.        What Happens If You Use  Uncalibrated Profile HMMs?          In general, when using calibrated  profile HMMs, E-values of 0.1  or less are very significant  hits.  If the query profile HMM  has not been calibrated, HmmerSearch  instead computes E-values  using an analytic upper bound  calculation that errs on the  side of caution to avoid  false positives.  These E-values are also reliable,  but because of the conservative  way they are calculated, remote  homolog in the sequence database  may be missed.         For more information on extreme  value distributions and the significance  of database search scores, see  Section 2.7 in Chapter 2  of  Biological Sequence Analysis  by  Richard Durbin, et al. (Cambridge  University Press, 1998).        CONSIDERATIONS    [  Previous  |  Top  |  Next  ]          Unless you specify a different  number with the  -SEQNUM  parameter,  5000 sequences are used to  obtain  the score distribution.  This  number was selected as a  trade-off between precision and computation  time.  You can obtain  more accurate estimates of the  EVD parameters by increasing the  number of  sequences, at the cost of  increased computation time.  You  should not reduce the number  of sequences  below about 1000 -- the  curve-fitting calculations for the extreme  value distribution may fail.    When using profile HMMs as  queries for database searches, E-values  of 0.1 or less usually  represent  very significant hits.  However,  be aware that database searches  performed using uncalibrated profile  HMMs may miss remote homologs.    To generate sequences, HmmerCalibrate uses  a random number generator that  is initialized by a seed  value.  By default, this  seed value is derived from  the system clock of your  computer, so each program  run will use a different  seed and thus generate a  somewhat different set of sequences.   If you want  HmmerCalibrate to generate the same  set of sequences each time,  you can set the seed  by means of the   -SEED  parameter.    If you would like to  save the uncalibrated HMM, you  should copy it to another  file, since  HmmerCalibrate will modify the input  HMM instead of creating a  new HMM.             Increasing Program Speed Using Multithreading          This program is multithreaded.   It has the potential to  run faster on a machine  equipped with  multiple processors because different parts  of the analysis can be  run in parallel on different  processors.  By default, the  program assumes you have one  processor, so the analysis is  performed using one thread.   You can use  -PROC essors  to  increase the number of threads  up to  the number of physical processors  on the computer.    Under ideal conditions, the increase  in speed is roughly linear  with the number of processors  used.  But conditions are  rarely ideal.  If your  computer is heavily used, competition  for the  processors can reduce the program's  performance.  In such an  environment, try to run  multithreaded programs during times when  the load on the system  is light.    As the number of threads  increases, the amount of memory  required increases substantially.  You may need to ask  your system administrator to increase  the memory quota for your  account if  you want to use more  than two threads.    Never use  -PROC essors  to set  the number of threads higher  than the number of physical  processors that the machine has  -- it does not increase  program performance, but instead uses  up  a lot of memory needlessly  and makes it harder for  other users on the system  to get processor  time.  Ask your system  administrator how many processors your  computer has if you aren't  sure.             COMMAND-LINE SUMMARY    [  Previous  |  Top  |  Next  ]          All parameters for this program  may be added to the  command line.  Use  -CHE ck   to view the summary  below and to specify parameters  before the program executes.   In the summary below, the  capitalized  letters in the parameter names  are the letters that you   must  type in order to  use the parameter.  Square brackets ([ and ])  enclose parameter values that are  optional.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.      Minimal Syntax: % hmmercalibrate [-INfile1=]hsp70.hmm_g -Default    Local Data Files:  None    Optional Parameters:    -SEQNUM=5000             sets the number of synthetic sequences to 5000 -LENgth=300              sets the length of the random sequences to 300 -MEAnlength=350          sets the mean length of the synthetic sequences to 350 -STDdevlength=350        sets the standard deviation of the sequence length                            distribution to 350 -SEED=317                sets the seed for the random number generator to 317 -HIStogram[=hsp70.hist]  saves the histogram of the scores to hsp70.hist -PROCessors=2            sets the maximum number of threads that the program                            will use to 2 -NOMONitor               doesn't display information about analysis parameters -BATch                   submits program to the batch queue            ACKNOWLEDGEMENT    [  Previous  |  Top  |  Next  ]          The programs comprising the HMMER  package are designed and implemented  by Dr. Sean Eddy of the  Washington University School of Medicine,  St. Louis, Missouri.  The GCG  front-end programs were  written by Christiane van Schlun  in collaboration with Dr. Eddy.        LOCAL DATA FILES    [  Previous  |  Top  |  Next  ]          None.        PARAMETER REFERENCE    [  Previous  |  Top  |  Next  ]          You can set the parameters  listed below from the command  line.  For more information,  see ""Using  Program Parameters"" in Chapter 3,  Using Programs in the User's  Guide.              Following some of the parameters  described below is a short  expression in parentheses.  These  are the  names of the corresponding parameters  used in the native HMMER  package.  Some of the  GCG  parameters are identical to the  original HMMER parameters, others have  been changed to fit GCG's  conventions.             -SEQNUM=5000      ( --num 5000 )         sets the number of synthetic  sequences to 5000 (must be  a positive integer).  The  default value is  5000;  higher numbers will give better  estimates of the EVD parameters,  lower values result in  faster computation time.  Values  below 1000 may cause the  curve-fitting calculations to fail.        -LEN gth= 300      ( --fixed 300 )         sets the length of  all   of the randomly generated sequences  to 300 residues (must be  a positive  integer).  For meaningful results,  the length must fall within  reasonable biological limits.  If  this  parameter is not used, the  random sequences will have a  length distribution that follows a  Gaussian (normal) distribution.  You  cannot use parameters  -MEA nlength  and   -STD devlength  with this option, they  will be ignored.        -MEA nlength =350      ( --meanlength 350 )         sets the mean length of  the synthetic sequences to 350  (must be a positive real  number).  The  default is 350.  If  option  -LEN gth  is specified as  well, this option will be  ignored.        -STD devlength =350      ( --sd 350 )         sets the standard deviation of  the synthetic sequence length distribution  to 350.  The value  must  be a positive real number.   The default is 350.   If option  -LEN gth  is  specified as well, this option  will be ignored.        -SEED=317      ( --seed 317 )         sets the seed for the  random number generator to 317  (must be a positive integer)  instead of  using the system clock to  create the seed.        -HIS togram=hsp70.hist      ( --histfile hsp70.hist )         saves a histogram of the  scores and the fitted theoretical  curve to a file named  hsp70.hist.        -PROC essors =2      ( --cpu 2 )         tells the program to use  2 threads on a multiprocessor  computer.  The default is  1.        -NOMON itor          suppresses the display of the  program's progress on the screen.        -BAT ch          submits the program to the  batch queue for processing after  prompting you for all required  user  inputs.  All output files  are written to your current  directory, unless you direct the  ouput to  another directory when you specify  the output file.                 Printed: February 5, 2001  11:35 (1162)           [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]       Documentation Comments:  doc-comments@gcg.com  Technical Support:  help@gcg.com      Copyright (c) 1982-2001  Genetics Computer Group  Inc.  A subsidiary of Pharmacopeia, Inc.  All rights reserved.    Licenses and Trademarks Wisconsin Package is a trademark of  Genetics Computer Group , Inc.  GCG and the GCG logo are registered trademarks of  Genetics Computer Group , Inc.    All other product names mentioned in this documentation may be trademarks, and if so, are trademarks or registered trademarks of their respective holders and are used in this documentation for identification purposes only.       www.gcg.com"
GX004-62-7800754	"MEME*     [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]      Table of Contents      FUNCTION   DESCRIPTION   EXAMPLE   OUTPUT   INPUT FILES   RELATED PROGRAMS   RESTRICTIONS   ALGORITHM   CONSIDERATIONS   SUGGESTIONS   ACKNOWLEDGEMENTS   COMMAND-LINE SUMMARY   LOCAL DATA FILES   PARAMETER REFERENCE                       FUNCTION    [   Top  |  Next  ]          MEME finds conserved motifs in  a group of unaligned sequences.   MEME saves these motifs  as a set of  profiles.  You can search  a database of sequences with  these profiles using the  MotifSearch   program.        DESCRIPTION    [  Previous  |  Top  |  Next  ]          MEME uses the method of  Bailey and Elkan (see ACKNOWLEDGEMENTS)  to identify likely motifs  within the input set of  sequences.  You may specify  a range of motif widths  to target, as well as  the  number of unique motifs to  search for.  MEME uses  Bayesian probability to incorporate prior  knowledge of the similarities among  amino acids into its predictions  of likely motifs.  The  resulting  motifs are output as profiles.   A profile is a  log-odds matrix used to judge  how well an unknown  sequence segment matches the motif.        EXAMPLE    [  Previous  |  Top  |  Next  ]          Here is a session with  MEME that was used to  find motifs in a group  of calcium-transporting  membrane proteins listed in the  file pircat.list.      %  meme    Find motifs in what sequences? @pircat.list   How many motifs should I search for (* 6 *) ?   What should I call the profile file (* meme.prf *) ?   What should I call the report file (* meme.meme *) ?   Reading sequences ...   PIR2:S39163                (      89 aa)   PIR2:A42764                (     919 aa)   PIR2:S71168                (     946 aa)   PIR1:PWBYR1                (     950 aa)   PIR2:S24359                (     994 aa)   PIR2:A32792                (     994 aa)   PIR2:A48849                (     994 aa)   PIR2:B31981                (     997 aa)     Identifying motifs in: 8 sequences   Shortest sequence (aa): 89    Longest sequence (aa): 997                 Total aa: 6883    Finding 1st motif    Testing starts of width 8 ... done    Testing starts of width 11 ... done    Testing starts of width 15 ... done    Testing starts of width 21 ... done    Testing starts of width 29 ... done    Testing starts of width 41 ... done    Testing starts of width 57 ... done      Running EM from 21 starting motifs ......... done    Finding 2nd motif    Testing starts of width 8 ... done ///////////////////////////////////////////////////////////   Search completed after finding the 6 motifs requested.                 Sequences searched: 8       Number of motifs identified: 6               Output profile file: meme.prf                     Output report: meme.meme  %                OUTPUT    [  Previous  |  Top  |  Next  ]          MEME generates a report and  a file containing one or  more ungapped GCG profiles.   (See RELATED  PROGRAMS for notes on how  this ""multiple profile file"" differs  from earlier versions of profile  files).    MEME's report file gives details  about the motifs that help  you analyze the validity and  usefulness of  the results.  The file  first lists the training set,  or input sequences.  (""Training  set"" is a common term  for a set of examples  from which an intelligent program  learns a general concept.) After  echoing the  parameters you specified, the file  gives a detailed description of  each motif found.  This  report includes  three different representations of the  motif: Two versions of a  letter-probability matrix, and a  consensus sequence showing all likely  letters for each position.   (A fourth representation is the  ungapped profile that is written  to the other output file.)  There are six different types  of information  presented:          The simplified letter-probability matrix shows  probabilities for each letter at  each position of the motif (Probabilities are multiplied by  10, and displayed as integers.   Values below 0.5 are  displayed as ':'.  Values  above 9.5 are displayed as  'a'.)     The information content bar graph  shows how many bits of  information are provided by each  position in the motif.  This  is a measure of how  well-conserved the positions of the  motif are.      The multilevel consensus sequence shows,  for each position, all letters  with a probability >= 0.2  of appearing in that position    The BLOCKS format section uses  Henikoff's BLOCKS format to display  occurrences of the motif within the sequences of the  training set.      The list of possible examples  shows the highest scoring matches  to the motif, with scores  and sequence context included.      The letter probability matrix shows  the probabilities for each letter  at each position of the  matrix. Note that this matrix is  transposed with respect to the  simplified letter-probability matrix.  That  is, the first row of  the simplified matrix corresponds to  the first column of this  matrix.       For more details about the  output, consult Tim Bailey's MEME  website at http://www.sdsc.edu/MEME.  (Note that the log-odds matrices  referred to at the website  correspond to the profiles that  appear in a  separate output file from GCG's  MEME.)  Here is some of the  output from the EXAMPLE:      ******************************************************************************** TRAINING SET ******************************************************************************** DATAFILE= @pircat.list ALPHABET= ACDEFGHIKLMNPQRSTVWY Sequence name           Weight Length  Sequence name           Weight Length -------------           ------ ------  -------------           ------ ------ PIR2:S39163             1.0000     89  PIR2:A42764             1.0000    919 PIR2:S71168             1.0000    946  PIR1:PWBYR1             1.0000    950 PIR2:S24359             1.0000    994  PIR2:A32792             1.0000    994 PIR2:A48849             1.0000    994  PIR2:B31981             1.0000    997 ********************************************************************************  meme  ******************************************************************************** MOTIF  1  width =  14 sites =  8.0 ******************************************************************************** Simplified     A  :::::::::::::: motif letter-  C  :a:::::::::::: probability    D  :::9:::::::::: matrix         E  ::::::::::::::                F  ::::::::::::::                G  ::::::9:::::::                H  ::::::::::::1:                I  8:::::::::::::                K  ::::9:::::1:::                L  ::::::::9:::::                M  :::::::::::::9                N  :::::::::::9::                P  ::::::::::::::                Q  ::::::::::::8:                R  ::::::::::::::                S  ::9:::::::1:::                T  :::::9:9:97:::                V  1:::::::::::::                W  ::::::::::::::                Y  ::::::::::::::           bits 6.2               5.6               5.0  *               4.4  *           * Information   3.7  *           * content       3.1  * ***** * * * (47.3 bits)   2.5 ********** ***               1.9 **************               1.2 **************               0.6 **************               0.0 --------------  Multilevel        ICSDKTGTLTTNQM consensus sequence  --------------------------------------------------------------------------------  Motif 1 in BLOCKS format -------------------------------------------------------------------------------- BL   MOTIF 1 width=14 seqs=8 PIR2:S39163 (   14) ICSDKTGTLTTNQM  1 PIR2:A42764 (  347) ICSDKTGTLTKNEM  1 PIR2:S71168 (  453) ICSDKTGTLTTNHM  1 PIR1:PWBYR1 (  368) ICSDKTGTLTSNHM  1 PIR2:S24359 (  348) ICSDKTGTLTTNQM  1 PIR2:A32792 (  348) ICSDKTGTLTTNQM  1 PIR2:A48849 (  348) ICSDKTGTLTTNQM  1 PIR2:B31981 (  348) ICSDKTGTLTTNQM  1 //  ---------------------------------------------------------------------------         Possible examples of motif 1 in the training set --------------------------------------------------------------------------- Sequence name             Start  Score                 Site -------------             -----  -----            -------------- PIR2:S39163                  14  57.51 SVETLGCTSV ICSDKTGTLTTNQM SVCKANACNS PIR2:A42764                 347  49.26 IVETLGCCNV ICSDKTGTLTKNEM TVTHILTSDG PIR2:S71168                 453  54.51 ACETMGSATT ICSDKTGTLTTNHM TVVKACICEQ PIR1:PWBYR1                 368  51.59 SVETLGSVNV ICSDKTGTLTSNHM TVSKLWCLDS PIR2:S24359                 348  57.51 SVETLGCTSV ICSDKTGTLTTNQM SVCRMFVIDK PIR2:A32792                 348  57.51 SVETLGCTSV ICSDKTGTLTTNQM SVCKMFIVDK PIR2:A48849                 348  57.51 SVETLGCTSV ICSDKTGTLTTNQM SVCKMFIIDK PIR2:B31981                 348  57.51 SVETLGCTSV ICSDKTGTLTTNQM SVCRMFILDR ---------------------------------------------------------------------------  letter-probability matrix: alength= 20 w= 14 n= 6779  0.007049  0.002044  0.002037  0.002293  0.005429  0.002439 . . .  0.002778  0.005443  0.961227  0.001396  0.002037  0.001528  0.001679 . . .  0.000830  0.015012  0.002823  0.003197  0.002442  0.001933  0.006176 . . .  0.001759  0.007101  0.001366  0.889213  0.027866  0.002153  0.005074 . . .  0.002383  0.006191  0.001517  0.002092  0.003289  0.001078  0.002866 . . .  0.001355  0.009921  0.002392  0.002885  0.002475  0.002042  0.004017 . . .  0.001481  0.014315  0.001548  0.006802  0.004851  0.001597  0.919485 . . .  0.001744  0.009921  0.002392  0.002885  0.002475  0.002042  0.004017 . . .  0.001481  0.005699  0.001894  0.001479  0.002568  0.011028  0.002253 . . .  0.003273  0.009921  0.002392  0.002885  0.002475  0.002042  0.004017 . . .  0.001481  0.016505  0.004503  0.006077  0.005728  0.003797  0.005281 . . .  0.002597  0.005424  0.001835  0.011030  0.003643  0.002797  0.005789 . . .  0.002762  0.013339  0.002372  0.006233  0.046657  0.002630  0.004246 . . .  0.002541  0.003377  0.001543  0.001401  0.001498  0.002749  0.001885 . . .  0.003170  ******************************************************************************** MOTIF  2  width =  21 sites =  7.0 ******************************************************************************** ////////////////////////////////   Search completed after finding the 6 motifs requested.            And here is an excerpt  from the profile file:      !!AA_PROFILE 2.0  (Peptide) .. { MEME v2.2 of: @pircat.list  Length: 14 !  Sequences: 8  MaxScore: 1.00  October 30, 1998 12:55 !PIR2:S39163  From: 14       To: 27       Weight: 1.000000 !PIR2:A42764  From: 347       To: 360       Weight: 1.000000 !PIR2:S71168  From: 453       To: 466       Weight: 1.000000 !PIR1:PWBYR1  From: 368       To: 381       Weight: 1.000000 !PIR2:S24359  From: 348       To: 361       Weight: 1.000000 !PIR2:A32792  From: 348       To: 361       Weight: 1.000000 !PIR2:A48849  From: 348       To: 361       Weight: 1.000000 !PIR2:B31981  From: 348       To: 361       Weight: 1.000000                           Gap: 1.00              Len: 1.00                      GapRatio: 0.0          LenRatio: 0.0 Cons   A      C      D      E      F      G      H  . . .   W      Y   Gap  Len }  I   -337   -315   -466   -476   -289   -482   -444 . . . -404   -355  100  100 ! 1  C   -374    572   -521   -493   -472   -536   -455 . . . -537   -530  100  100  S   -228   -268   -401   -467   -438   -348   -385 . . . -437   -421  100  100  D   -336   -373    410   -116   -422   -377   -258 . . . -397   -377  100  100  K   -356   -358   -462   -424   -522   -459   -349 . . . -403   -459  100  100  T   -288   -292   -416   -465   -430   -410   -377 . . . -426   -446  100  100  G   -235   -355   -292   -368   -465    372   -337 . . . -389   -422  100  100  T   -288   -292   -416   -465   -430   -410   -377 . . . -426   -446  100  100  L   -368   -326   -512   -460   -186   -494   -377 . . . -328   -331  100  100  T   -288   -292   -416   -465   -430   -410   -377 . . . -426   -446  100  100  T   -214   -201   -308   -344   -340   -371   -272 . . . -343   -365  100  100 ! 11  N   -375   -330   -222   -409   -384   -358   -105 . . . -339   -356  100  100  Q   -245   -293   -305    -41   -393   -402    124 . . . -286   -368  100  100  M   -443   -355   -520   -537   -387   -520   -454 . . . -320   -336  100  100 *       0      8      8      1      0      8      2 . . .    0      0 { MEME v2.2 of: @pircat.list  Length: 21 !  Sequences: 8  MaxScore: 1.00  October 30, 1998 12:57 ///////////////////////////////////////////////////////////////////////////////  *       7      9      6      7      6     12      1 . . .      0      2                INPUT FILES    [  Previous  |  Top  |  Next  ]          The input to MEME is  a set of either nucleotide  or protein sequences (not both).   The function of MEME  depends on whether your input  sequence(s) are protein or nucleotide.   Programs determine the type  of  a sequence by the presence  of either  Type: N  or   Type: P  on the last  line of the text heading  just  above the sequence.  If  your sequence(s) are not the  correct type, see  Appendix VI   for information  on how to change or  set the type of a  sequence.    MEME respects the  begin  and   end  attributes for controlling the  range of interest for sequences  in  list files (but see RESTRICTIONS,  below).  MEME also respects  the  strand  list file attribute  for  nucleotide sequences.        RELATED PROGRAMS    [  Previous  |  Top  |  Next  ]           PileUp  creates a multiple sequence  alignment from a group of  related sequences using progressive,  pairwise alignments.  It can  also plot a tree showing  the clustering relationships used to  create the  alignment.   ProfileMake  creates a  position-specific scoring table, called a   profile , that quantitatively  represents the information from a  group of aligned sequences.   The profile can then be  used for  database searching ( ProfileSearch ) or sequence  alignment ( ProfileGap ).  ProfileSearch uses  a  profile   (representing a group of aligned  sequences) as a query to  search the database for new  sequences with  similarity to the group.   The profile is created with  the program ProfileMake.   ProfileScan   uses a  database of profiles to find  structural and sequence motifs in  protein sequences.  ProfileGap makes  an  optimal alignment between a profile  and one or more sequences.    MEME's output can best be  appreciated by running the output  profiles through  MotifSearch , another  program in the Wisconsin Package.   You will probably want  to run MotifSearch at least  twice.  First,  you should use the profiles  to search the original training  set of sequences.  Second,  you may wish to  search a larger database to  identify similar sequences.  See  the documentation for MotifSearch for  details.        RESTRICTIONS    [  Previous  |  Top  |  Next  ]          You can analyze at most  1,000,000 residues at one time.    If you wish to use  both strands of nucleotide sequences,  you must specify the one-per  model (described  in ALGORITHM, below) via the   -ONEEX actly  parameter.    MEME cannot process multiple sequences  with the same name.   If MEME encounters a second  sequence with the identical name  as a previous one, it  will ignore the second.   Thus, you cannot analyze  several segments of a single  sequence by creating several list  file entries of that sequence  and  specifying different  begin  and  end   attributes for each entry.        ALGORITHM    [  Previous  |  Top  |  Next  ]          MEME implements the method of  Bailey and Elkan (see ACKNOWLEDGMENTS),  to find one or more  motifs that characterize a family  of sequences.  The core  of MEME is Expectation Maximization  (EM),  an unsupervised learning algorithm guaranteed  to converge to a local  maximum.  That is, any  motif  found by MEME will be  ""better"" (according to MEME's statistical  criteria) than any other motif  that  differs infinitesimally from the first.    One of the criteria applied  by MEME depends on your  choice of a model.   MEME can either a) favor  motifs that appear exactly once  in each sequence in the  training set (the one-per model);  b) favor motifs  that appear zero or one  time in each sequences in  the training set (the zero-or-one-per  model); or c) give  no preference to the number  of occurrences (the zero-or-more-per model).    MEME makes use of Dirichlet  priors in its EM calculations  for protein sequences.  These  are empirical  statistical measures of the interchangeability  of amino acids within subsequences  of similar function.  Suppose there are two amino  acid sequences, S1 and S2,  having the same length.   If the first residue in  S1 is I, and the  first residue in S2 is  V, then there is some  likelihood that S1 and S2  have the same  function, given their similarity in  the first position.  We  can estimate that likelihood by  analyzing the  set of subsequences whose functionality  is established.    A drawback to EM is  that the maximum it finds  is only local.  There  may be better solutions that  were  overlooked due to an unlucky  choice of the starting point  -- EM's initial guess at  the solution.  This is  a  nontrivial and heavily studied problem.   One approach is to  run the algorithm from a  large subset of  the possible starting points.   You may choose the subset  to be evenly distributed across  the solution  space, or to be randomly  selected.  In any case,  this may take a daunting  amount of time.    MEME refines this approach by  taking a carefully chosen subset  of possible solutions and running  a  single iteration of EM on  each.  It then chooses  one from among these as  its best candidate, and runs  EM to convergence from there.   When searching for a  starting point, MEME does not  consider all  possible starting points within the  range of widths it is  given; rather, it surveys starting  points at  particular steps within the range  given.  Thus, if using  the default range of 8  to 57, MEME will only  consider initial motifs whose widths  are in the set {8,  11, 15, 21, 28, 41,  57}.    Despite limiting the initial set  of widths under consideration, MEME  can find a motif of  any width in  the given range.  This  is due to a shortening  technique that trims low-information columns  from the  ends of the motif.   However, the motif will never  be shortened below the minimum  width specified for  the search.        CONSIDERATIONS    [  Previous  |  Top  |  Next  ]           Version 2.0 profile files      MEME generates a version 2.0  profile file, which permits multiple  profiles to be included in  one file.  Version 2.0 profile files include  an auxiliary data block (encased  in {}'s) prior to each  profile.  This block  contains parsable information, including the  width of the profile and  the column labels for the  log-odds  matrix.    When reading version 2.0 profile  files generated by MEME, most  GCG programs (e.g.   ProfileSearch ,  ProfileGap) will read only the  first profile found.  At  this time, the only exception  is  MotifSearch , which  reads and processes all of  the profiles.    Also note that MEME's profiles  always have Gap and Len  values of 100 -- MEME's  profiles should  always be thought of as  ungapped.  This is a  characteristic of MEME, not of  the version 2.0 profile file  format.    For more details about version  2.0 profiles, see  Appendix VII .     Time-complexity of the algorithm      MEME's algorithm for finding the  best initial motifs of width  W requires k * W  * n (2)   calculations, where k is an  unknown constant (probably between 10  and 100) and n is  the total number of  residues in the input set.   If you allow a  large range of widths, this  becomes very time-consuming.  Searching with the default range  of widths requires (8 +  11 + 15 + 21  + 20 + 41 +  57) = 173 iterations of  k  * n (2)  calculations.    In any event, running on  a training set of more  than 20 or 30 typical  proteins will require a lot  of processor  cycles.     Effects of the choice of  model      By default, MEME assumes the  zero-or-one-per model; that is, it  assumes that each motif occurs  at most  once in each sequence in  the search set, but may  not occur at all in  some sequences.  This runs  MUCH faster  than the zero-or-more model, in  which a motif may occur  any number of times in  a sequence.  It is  important  to understand that using the  zero-or-one-per model does not necessarily  prevent MEME from finding motifs  that are duplicated within a  sequence; however, the zero-or-more model  may rank such motifs higher  relative  to other candidates.     Multiple motifs      When told to look for  more than one motif, MEME  attempts to minimize the overlap  between the current  motif and any previously identified  motifs.        SUGGESTIONS    [  Previous  |  Top  |  Next  ]           Choosing the minimum and maximum  search widths      As noted under CONSIDERATIONS, the  algorithm slows down when searching  large ranges of widths.   If  you have some idea of  the width of the target  motifs, you can (and should)  restrict the range of allowable  widths.  This will save  a lot of computation, especially  if you can forego searching  beyond a width of 25  or 30.    If the training set may  include proteins that are not  related to the family of  interest, you might first run  with   -MINW idth  and  -MAXW idth  both set  to the same small number  (perhaps 10 for proteins), and  NMOtifs set  to 1 or 2.   (Be sure to use the  default one-or-zero-per model!) This may  find a motif (possibly part  of a larger  motif) that discriminates between family  and non-family members, allowing you  to remove the unrelated  proteins before running a more  exhaustive MEME over a larger  range of widths.     Finding repeats in a sequence      You can identify motifs within  a single sequence by specifying   -ZEROORM ore  to choose the zero-or-more-per  model (described in ALGORITHM).        ACKNOWLEDGEMENTS    [  Previous  |  Top  |  Next  ]          MEME was written by Dr.   Timothy L.  Bailey  of the San Diego Supercomputing  Center.  (Bailey, T.L., and  Elkan, C., (1994).  Fitting  a mixture model by expectation  maximization to discover motifs in  biopolymers.  Proceedings of the Second International  Conference on Intelligent Systems for  Molecular Biology, 28-36,  AAAI Press, Menlo Park, California.)    MEME was adapted for the  Wisconsin Package by Scott Swanson  with the assistance of Dr.   Bailey.        COMMAND-LINE SUMMARY    [  Previous  |  Top  |  Next  ]          All parameters for this program  may be added to the  command line.  Use  -CHE ck   to view the summary  below and to specify parameters  before the program executes.   In the summary below, the  capitalized letters  in the parameter names are  the letters that you  must   type in order to use  the parameter.  Square brackets  ([  and ]) enclose parameter values  that are optional.  For more information,  see  ""Using  Program Parameters""  in Chapter 3,  Using Programs in the User's  Guide.      Minimal Syntax: % meme [-INfile=]@pircat.list -Default  Prompted Parameters:  -BEGin=1 -END=100        sets the range of interest for all sequences -REVerse                 uses the reverse strand of all sequences [-OUTfile1=]meme.prf     specifies the output file of profiles [-OUTfile2=]meme.meme    specifies the output report file -NMOTifs=6               sets the maximum number of motifs to search for  Local Data Files:  -DATa=prior30.plib       specifies Dirichlet priors for proteins  Optional Parameters:  -ONEEXactly         requires each motif to occur exactly once in each sequence -ONEORZero          allows each motif to occur up to once in each sequence -ZEROORMore         allows motifs to occur any number of times in any sequence -TWOStrands         searches both strands of nucleotide sequence -MINWidth=8         requires motifs to be at least this wide -MAXWidth=57        limits motifs to a maximum of this width -EMTHReshold=.001   sets the convergence criterion for EM -MAXEMiterations=50 stops EM after this many iterations without convergence -NOSUMmary          suppresses report of run information to screen at exit -NOMONitor          suppresses screen trace during processing -NOREPort           suppresses creation of report file -BATch              submits program to the batch queue                LOCAL DATA FILES    [  Previous  |  Top  |  Next  ]          The files described below supply  auxiliary data to this program.   The program automatically reads  them from  a public data directory unless  you either 1) have a  data file with exactly the  same name in your current  working directory; or 2) name  a file on the command  line with an expression like   -DAT a 1=myfile.dat .  For  more information see see  Chapter 4, Using Data  Files  in the  User's Guide.  When processing  proteins, MEME  uses a data file of  Dirichlet priors for its Bayesian  statistics.  By default, the  file is GenRunData:prior30.plib.  Although it is possible to  specify your own priors, it  not advised unless you have  a very strong understanding  of MEME's inner workings.        PARAMETER REFERENCE    [  Previous  |  Top  |  Next  ]          You can set the parameters  listed below from the command  line.  For more information,  see  ""Using  Program Parameters""  in Chapter 3,  Using Programs in the User's  Guide.             -BEG in =1          sets the beginning position for  all input sequences.  When  the beginning position is set  from the  command line, MEME ignores beginning  positions specified for individual sequences  in a list file.        -END=100          sets the ending position for  all input sequences.  When  the ending position is set  from the  command line, MEME ignores ending  positions specified for sequences in  a list file.        -REV erse          sets the program to use  the reverse strand for each  input sequence.  When  -REV erse   or   -NOREV erse  is on the command  line, MEME ignores any strand  designation for individual  sequences in a list file.        -NMO tifs =6          gives the number of unique  motifs for which to search.        -ONEEX actly  specifies a model in  which each motif should occur  exactly once in every sequence  in the       training set.  If a  given motif gets a low  score in any sequence, it  is very unlikely to be  chosen.  This is the fastest model.        -ONEORZ ero          specifies a model in which  each motif should occur zero  or one times in any  sequence in the  training set.  If a  given motif scores well at  more than one position in  a sequence, the motif might  still be chosen, but the  additional scores ""hits"" will not  contribute to its score.   This is the default  model.  This model is  about two times slower than  the  -ONEEX actly  model.        -ZEROORM ore          specifies a model in which  each motif may occur any  number of times in any  sequence in the  training set.  In this  case, additional ""hits"" after the  first within a sequence will  contribute to the  motif's score.  This model  is about ten times slower  than the  -ONEEX actly  model.        -TWOS trands          searches forward and reverse strands  of nucleotide sequences.  This  parameter may be used only  with the  -ONEEX actly  parameter!        -MINW idth =8          specifies the smallest acceptable motif  for the search.  When  shortening the chosen motif, MEME  will NOT shorten below this  value.        -MAXW idth= 57          specifies the largest acceptable motif  for the search.  If   -MINW idth  is equal to  -MAXW idth ,  MEME will either find a  motif of that width, or  find nothing at all.        -EMTHR eshold =.001          gives a convergence criterion for  the EM phase of the  algorithm.  Raising this criterion  will make  MEME run faster, but give  inferior results.        -MAXEM iterations =50          overrules the convergence criterion given  by EMTHReshold.  That is,  if EM has failed to  converge to the EMTHReshold after  MAXEMiterations, the program will cut  off the calculation  and settle for its result  to that point.        -SUM mary          writes a summary of the  program's work to the screen  when you've used  -D efault  to  suppress  all program interaction.  A  summary typically displays at the  end of a program run  interactively.  You can suppress the summary  for a program run interactively  with  -NOSUM mary .    You can also use this  parameter to cause a summary  of the program's work to  be written in the  log file of a program  run in batch.        -MON itor          This program normally monitors its  progress on your screen.   However, when you use  -D efault   to suppress all program interaction,  you also suppress the monitor.   You can turn it  back on with  this parameter.  If you  are running the program in  batch, the monitor will appear  in the log file.        -NOREP ort          tells the program not to  generate a report file.        -BAT ch          submits the program to the  batch queue for processing after  prompting you for all required  user  inputs.  Any information that  would normally appear on the  screen while the program is  running  is written into a log  file.  Whether that log  file is deleted, printed, or  saved to your current  directory depends on how your  system manager has set up  the command that submits this  program to the batch queue.   All output files are  written to your current directory,  unless you  direct the output to another  directory when you specify the  output file.                 Printed: December 9, 1998  16:23 (1162)           [  Program Manual  |  User's Guide  |  Data Files  |  Databases  ]       Documentation Comments:  doc-comments@gcg.com  Technical Support:  help@gcg.com      Copyright (c) 1982-2001  Genetics Computer Group , Inc. A subsidiary of Pharmacopeia, Inc.  All rights reserved.    Licenses and Trademarks Wisconsin Package is a trademark of Genetics Computer Group, Inc.  GCG and the GCG logo are registered trademarks of Genetics Computer Group, Inc.    All other product names mentioned in this documentation may be trademarks, and if so, are trademarks or registered trademarks of their respective holders and are used in this documentation for identification purposes only.       www.gcg.com"
GX042-20-11610115	CHARMM c27b3 ewald.doc     File:  Ewald  -=-    Node:  Top    Up : ( commands.doc ) -=-   Next :  Syntax  -=-   Previous :  Top                         The Ewald Summation method    Invoking the Ewald summation for calculating the electrostatic interactions  can be specified any time the nbond specification parser is invoked.  See   the syntax section for a list of all commands that invoke this parser.    Prerequisite reading:  nbonds.doc   * Menu:  *  Syntax ::          Syntax of the Ewald summation specification *  Defaults ::        Defaults used in the specification *  Function ::        Description of the options *  Discussion ::      More general discussion of the algorithm    File:  Ewald  -=-    Node:  Syntax    Up :  Top  -=-   Next :  Defaults  -=-   Previous :  Top  [SYNTAX EWALD]  {  NBONds          }        {  nonbond-spec                   } {  UPDAte          }        {                                 } {  ENERgy          }        {                                 } {  MINImize        }        {                                 } {  DYNAmics        }        {                                 }   The keywords are:  nonbond-spec::= [ method-spec ]                 { [ NOEWald ]                                          }                {                                                      } method-spec::= {   EWALd [ewald-spec] { [ NOPMewald [std-ew-spec] ] } }                {                      {   PMEWald [pmesh-spec]      } }   ewald-spec::=   KAPPa real  [erfc-spec]  std-ew-spec::= { [ KMAX integer ]                        } KSQMAX integer                { KMXX integer KMXY integer KMXZ integer  }  pmesh-spec::=   FFTX int FFTY int FFTZ int  ORDEr integer [QCOR real (***) ]  erfc-spec::=    { SPLIne      { [EWMIn real] [EWMAx real] [EWNPts int] } }                 { INTErpolate {                                        } }                 {                                                        }                 { ABROmowitz                                             }                 { CHEBychev                                              }                 { EXACt_high_precision                                   }                 { LOWPrecision_exact                                     }                 { ERFMode int                                            }    File:  Ewald  -=-    Node:  Defaults    Up :  Top  -=-   Next :  Function  -=-   Previous :  Syntax  The defaults for the ewald summation are set internally and are currently set to NOEWald, KAPPa=1.0, KMAX=5, KSQMax=27, and NOPMewald, KAPPa=1.0, FFTX=FFTY=FFTZ=32, ORDEr=4, QCOR=1.0  Recommended values for Ewald are:    EWALD PMEWald KAPPa 0.34 ORDEr 6 -     FFTX intboxvx FFTY intboxvy FFTZ intboxvz  -    CTOFNB 12.0 CUTNB 14.0 QCOR 1.0(***)  Where intboxv* is an integer value similar to or larger than the corresponding unit cell dimension that has prime factors of 2,3, and 5 only (2,3 preferred). grid point spacing should be between 0.8 and 1.2 Angstroms.  These recommended values should give relative force errors of roughly 10**-5. To reduce the total PME cost at the expense of accuracy, decrease the cutoff distances while increasing KAPPa (keep the product near 4) reduces the real space cost.  To reduce the K-space cost, either reduce ORDEr from 6 to 4 or increase the grid spacing up to perhaps 1.5 Angstroms.  (***) The QCOR value should be 1.0 for vacuum, solid, or finite systems. For periodic systems in solution, it should be reduced (or set to zero) by an amount that depends on how the net charge is distributed and on the effective dielectric constant.  For a treatise on this correction term, see: S. Bogusz, T. Cheatham, and B. Brooks, JCP (1998) 108, 7070-7084 and references contained therein (esp. Hummer and Levy).    File:  Nbonds  -=-    Node:  Function    Up :  Top  -=-   Previous :  Defaults  -=-   Next :  Discussion   i)   The EWALD keyword invokes the Ewald summation for calculation of  electrostatic interactions in periodic, neutral systems.  The formulation of  the Ewald summation dictates that the primary system must be neutral.  If  otherwise, the summation is not formally correct and some  convergence problems may result.  The NOEWald (default) suppresses the Ewald  method for calculating electrostatic interactions.  Van der waals  options VSHIFT and VSWITCH are supported with ewald.  The algorithm currently supports the atom and group nonbond lists and the CRYSTAL facilty  must be used.  The PMEWald keyword invokes the Particle Mesh Ewald algorithm for the reciprocal space summation.  For details on the PME method, see J. Chem. Phys. 103:8577 (1995).  The EWALd algorithm is limited to CUBIC, TETRAGONAL, and ORTHORHOMBIC unit cells.  The PMEWald algorithm supports all unit cells that are supported by the CRYSTAL facility.   ii)  The KAPPa keyword, followed by a real number governs the width of the  Gaussian distribution central to the Ewald method.  An approximate value of kappa can be chosen by taking KAPPa=5/CTOFNB.  This is fairly conservative. Values of 4/CTOFNB lead to small force errors (roughly 10**-5).  See discussion section for details on choosing an optimum value of KAPPa.  iii) The KMAX key word is the number of kvectors (or images of the  primary unit cell) that will be summed in any direction.  It is the  radius of the Ewald summation.  For orthorombic cells, the value of  kmax may be independently specified in the x, y, and z directions with the keywords KMXX, KMXY, and KMXZ.  In the PME version, the number of  FFT grid points for the charge mesh is specified by FFTX, FFTY, and FFTZ.   iv) The KSQMax key word should be chosen between  KMAX squared and 3 times KMAX squared.   v) An appropriate, although not optimal, set of parameters can be  chosen by taking KAPPA=5/CTOFNB and KMAX=KAPPa*boxlength. The actual  values should then be performanced optimized for your particular system. For the PME method, FFTX should be approximately the box length in Angstroms. (for efficiency, FFTX should be a multiple of powers of 2,3, and 5).     IMPORTANT NOTE::: THE SUGGESTION THAT FFTX, FFTY, AND FFTZ HAVE    NO PRIME FACTORS OTHER THAN 2, 3, AND 5 SEEMS TO BE A REQUIREMENT.    LARGE ERRORS IN THE FORCE ARE OBSERVED WHEN THIS CONDITION IS NOT MET.    FUTURE VERSIONS OF CHARMM WILL FLAG THIS AS AN ERROR CONDITION.  ORDEr specifies the order of the B-spline interpolation, e.g. cubic is order 4 (default), fifth degree is ORDEr 6.  The ORDEr must be an even number and at least 4.   vi) EWALd runs in parallel on both shared (PARVECT) and distributed memory parallel computers.  PME runs in parallel on distributed memory computers.  vii) several algorithms are available for the calculation of the complimentary error function, erfc(x).  EXACt and LOWPrecision use an interative technique described in section 6.2 of Numerical Recipies.  ABRO and CHEB are polynomial approximations.  A lookup table (filled at the beginning of the simulation using the EXACt method) can be used with either a linear (INTE) of cubic  spline (SPLINe) interpolation.  SPLIne is recommended.  viii) Ewald with MMFF  A version of EWALD was developed for MMFF.  The usual MMFF electrostatic term: qq/(r+d)  is split into two terms:  qq/r -  qq*d/(r*(r+d)) The first term is handled by the Ewald method in the usual manner (real-space and k-space parts) and the second term is truncated at the cutoff distance using a switching function (from CTONNB to CTOFNB). Since the second term is quite small at the cutoff distance, the use of a switching function should not introduce significant artificial forces.    File:  Ewald  -=-    Node:  Discussion    Up :  Top  -=-   Previous :  Function  -=-   Next :  Top            The Ewald Summation in Molecular Dynamics Simulation   The electrostatic energy of a periodic system can be expressed by a lattice   sum over all pair interactions and over all lattice vectors excluding the i=j term in the primary box.  Summations carried out in this simple  way have been shown to be conditionally convergent.  The method developed by  Ewald, in essence, mathematically transforms  this fairly straightforward   summation to two more complicated but rapidly convergent sums.  One summation  is carried out in reciporcal space while the other is carried out in real  space.  Based on the formulation by Ewald, the simple lattice sum can be reformulated to give absolutely convergent summations which define the principal value of the electrostatic potential, called the intrinsic potential. Given the periodicity present in both crystal calculations and in dynamics  simulations using periodic boundary conditions,  the Ewald formulation becomes  well suited for the calculation of the electrostatic energy and force. If we  consider a system of point charges in the unit or primary cell, we can specify  its charge density by    ro(r) = sum_i [ q_i * delta(r-r_i)]   In the Ewald method  this distribution is replaced by two other distributions   ro_1(r) = sum_i [ q_i ( delta(r-r_i) - f(r-r_i)]  and  ro_2(r) = sum_i [q_i f(r-r_i)  such that the sum of the two recovers the original.  The distribution, f(r), is a spherical distribution generally taken to be Gaussian, the width of the gaussian dictated by the parameter, KAPPa.  The charge distributions are situated on the ion lattice positions, but integrate to zero.  The potential from the distribution ro_1(r) is a short range potential evaluated in a direct real space summation (truncated at CTOFNB).  The diffuse charge distribution placed on the lattice sites reduces to the potential of the corresponding point charge at large r. ro_2(r), being a continuous distribution of Gaussians situated on the periodic lattice positions, is a smoothly varying function of r and thus is well approximated by a superposition of continuous functions.  This distribution is, therefore, expanded in a Fourier series and the potential is obtained by solving the Poisson equation.  The point of splitting the problem into two parts, is that by a suitable choice of the parameter KAPPa we can get very good convergence of both parts of the summation.  For the real space part of the energy, we choose kappa so that the complementary error function term, erfc(kappa*r) decreases rapidly enough with r to make it a good approximation to take only nearest images in the sum and neglect the value for which r > CTOFNB.  The reciprocal space sums are rapidly convergent and a spherical cutoff in k space is applied so that the sum over k becomes a sum over {l,m,n}, with (l**2+m**2+n**2) < or = to KSQMAX A large value of KAPPa means that the real space sum is more rapidly convergent but the reciprocal space sum is less rapid.  In practice one chooses KAPPa to give good convergence at the cutoff radius, CTOFNB.  KMAX is then chosen to such that the reciprocal space calculation converges.  The equation (KMAX/(box length)=KAPPa may be used as a rough guide.  Optimization with respect to the timing trade offs, ie.  how much time is spent in real space vs k-space should be performed before a lengthy production run.  The CCP5 notes in several articles in 1993 cover some possible optimization strategies and criteria although a simple line search will suffice.  Complete optimiztion of the ewald method for a particular application requires optimizing CTOFNB, KAPPa, and KMAX.  A discussion of optimization and error analysis can be found in Kolfka and Perram, Molecular Simulation, 9, 351 (1992).   For PME, see Feller, Pastor, Rojnuckarin, Bogusz, and Brooks. J. Phys. Chem., 100, 42, 17011 (1996) and some of Tom Darden's published work.              NHLBI/LBC Computational Biophysics         CHARMM Documentation /   Rick_Venable@nih.gov
GX009-75-2492482	"Next:    Energy Function    Up:    Examples for Molecular     Previous:    A Nucleic Acid           Virus Structures or Structures with Many Identical Units             Molecular structures with many identical units can be generated using the principles discussed above.  However, it would be inefficient to generate the whole multimer in one generation protocol since the  segment statement uses a pairwise atom check.  Instead, a molecular structure file for a protomer should be generated.  Then,  the  duplicate statement should be used to create the multimer.   Assume that the ``protomer.psf"" file contains the molecular structure of a protomer with blank  segment name.   If a multimer coordinate file exists, one has to split the coordinates of  the multimer into several files, one for each protomer with disjoint  segment names.    The following shows an example for a trimeric structure  (ignore the ""multiple coordinates"" error messages).  structure @protomer.psf vector do (segid=""a"") ( segid "" "" ) coordinates @a.pdb                                      {* Read protomer a.*} duplicate segid=""b"" selection=( segid ""a"" ) end coordinates @b.pdb                                      {* Read protomer b.*} duplicate segid=""c"" selection=( segid ""a"" ) end coordinates @c.pdb                                      {* Read protomer c.*}       Note that if using the  NCS strict statement  (Section  16.2.1 ), one has to create only one protomer structure.   If a protomer coordinate file exists and one knows the appropriate transformations between the monomers, one should read the monomer, use the duplicate statement to duplicate the molecular structure as well as the coordinates, and apply appropriate coordinate transformations (marked by ... in the example below) to produce the other monomers.  structure @protomer.psf coordinate @protomer.pdb  vector do (segid=""a"") ( segid "" "" ) duplicate segid=""b"" selection=( segid ""a"" ) end coordinates rotate ... selection=( segid ""b"" end  coordinates translate ... selection=( segid ""b"" )  end    duplicate segid=""c"" selection=( segid ""a"" ) end coordinates rotate ... selection=( segid ""c"" end  coordinates translate ... selection=( segid ""c"" )  end               Web Manager   Sat Mar 11 09:37:37 PST 1995"
GX025-64-16370179	"Next:    Energy Function    Up:    Examples for Molecular     Previous:    A Nucleic Acid           Virus Structures or Structures with Many Identical Units             Molecular structures with many identical units can be generated using the principles discussed above.  However, it would be inefficient to generate the whole multimer in one generation protocol since the  segment statement uses a pairwise atom check.  Instead, a molecular structure file for a protomer should be generated.  Then,  the  duplicate statement should be used to create the multimer.   Assume that the ``protomer.psf"" file contains the molecular structure of a protomer with blank  segment name.   If a multimer coordinate file exists, one has to split the coordinates of  the multimer into several files, one for each protomer with disjoint  segment names.    The following shows an example for a trimeric structure  (ignore the ""multiple coordinates"" error messages).  structure @protomer.psf vector do (segid=""a"") ( segid "" "" ) coordinates @a.pdb                                      {* Read protomer a.*} duplicate segid=""b"" selection=( segid ""a"" ) end coordinates @b.pdb                                      {* Read protomer b.*} duplicate segid=""c"" selection=( segid ""a"" ) end coordinates @c.pdb                                      {* Read protomer c.*}       Note that if using the  NCS strict statement  (Section  16.2.1 ), one has to create only one protomer structure.   If a protomer coordinate file exists and one knows the appropriate transformations between the monomers, one should read the monomer, use the duplicate statement to duplicate the molecular structure as well as the coordinates, and apply appropriate coordinate transformations (marked by ... in the example below) to produce the other monomers.  structure @protomer.psf coordinate @protomer.pdb  vector do (segid=""a"") ( segid "" "" ) duplicate segid=""b"" selection=( segid ""a"" ) end coordinates rotate ... selection=( segid ""b"" end  coordinates translate ... selection=( segid ""b"" )  end    duplicate segid=""c"" selection=( segid ""a"" ) end coordinates rotate ... selection=( segid ""c"" end  coordinates translate ... selection=( segid ""c"" )  end               Web Manager   Sat Mar 11 09:37:37 PST 1995"
GX027-23-15136299	"CHARMM c27b2 struct.doc     File:  Struct  -=-    Node:  Top    Up : ( commands.doc ) -=-   Next :  Generate              Generation and Manipulation of the Structure (PSF)          The commands described in this node are used to construct and manipulate the PSF, the central data structure in CHARMM (see PSF.FCM).  The PSF holds lists giving every bond, bond angle, torsion angle, and improper torsion angle as well as information needed to generate the hydrogen bonds and the non-bonded list. It is essential for the calculation of the energy of the system. A separate data structure deals with symmetric images of the atoms.  See *note Images: ( images.doc ).          There is an order with which commands to generate and manipulate the PSF must be given.  First, segments in the PSF must be generated one at a time.  Prior to generating any segments, one must first have read a residue topology file, see *note read:( io.doc )Read.  To generate one segment, one must first read in a sequence using the READ command, see *note seq:( io.doc )Sequence.  Then, the GENERATE command must be given.          Once a segment is generated, it may be manipulated. This can be done in a very general way using the patch command. The patch command allows, for instance, the addition of disulfide bridges, changing the protonation state of a titratible residue or to make a histidine heme crosslink.          The PSF can be saved with the ""WRITE PSF"" command.  A PSF may be read with the ""READ PSF"" command.  The ""READ PSF"" command has an ""APPEnd"" option that allows the merging of individual PSF files.  In addition, the ""DELETE"" command allows the deletetion of atoms and all references to the deleted atoms.  * Menu:  *  Generate ::            Generating a segment *  Nbx ::                 Nonbond exclusion lists *  Patch ::               Multi purpose patch command to modify the PSF *  Autogen ::             Autogenerate angles and/or dihedrals after patches *  Delete ::              Deleting atoms from the PSF *  Rename ::              Renaming atoms, residues, or segments *  Join ::                Joining two adjacent segments to form one   File:  Struct  -=-    Node:  Generate    Up :  Top  -=-   Next :  Nbx  -=-   Previous :  Top          The Generate Command - Construct a Segment of the PSF  [Syntax GENErate segment]    GENErate [segid] { generate-spec        } [SETUp]                    {  DUPLicate segid     }  generate-spec::= [FIRSt pres] [LAST pres] [WARN] [ ANGLe   ] [ DIHEdrals ]                                                  [ NOANgle ] [ NODIhedral]                                  Function          This command uses the sequence of residues specified in the last READ SEQUuence command and the information stored in the residue topology file to add the next segment to the PSF. Each segment contains a list of all the bonds, angles, dihedral angles, and improper torsions needed to calculate the energy. It also assigns charges to all the atoms, sets up the nonbonded exclusions list, and specifies hydrogen bond donors and acceptors. Any internal coordinate which references atoms outside the range of the segment is deleted. This prevents any unexpected bonding of segments.         The FIRSt and LAST specifications define what patch-residues should be used for the terminating residues. If no specification is given, then the default patching as specified in the topology file will be used.         The WARN keyword, will list all elements that were deleted due to nonexistant atoms (usually references to the terminating residues).         The SETUp option will cause any internal coordinate table entries (IC) from the topology file to be appended to the main IC table.          The ANGLe (NOANgle) and DIHEdral (NODIhedral) options overide the autogeneration option specified in the topology files. This may be done to supress unwanted additional terms, or to add terms for specific residues.          NOTE: The solvent residues (TIP3, ST2, WAT) must be generated with the NOANgle and/or NODIhedral qualifier. This is only necessary for  the files which use the AUTOgenerate ANGLes and/or DIHEdrals as a default. This also means that a protein residue sequence and water molecules may not be combined in the same generate command. Also, there is a special ""READ SEQUence residue_type integer"" command where integer is the number of resudies of residue_type (often water molecules). This avoids the need to list the number of residues followed by the specification of each TIP3 residue name individually as is done with a protein.          For the DUPLicate segment option, the generate command MUST NOT be preceeded by a READ SEQUence command. This option will create a new segment which is identical (except for the segid) to an existing segment. This option is mainly intended for the use in setting up small crystals for viewing and other analysis.   File:  Struct  -=-    Node:  Nbx    Up :  Top  -=-   Next :  Patch  -=-   Previous :  Generate          Some pairs of atoms are excluded from the nbond exclusion lists because their interactions are described by other terms in the hamiltonian. By default directly bonded atoms and the 1-3 atoms of an angle are excluded from the nonbond calculation.  In addition the diagonal interactions of the six membered rings in tyrosine and phenylalanine were excluded from the nonbond calculation through charmm version 15 with RTOPH6. Hydrogen bonds, and dihedral 1-4 interactions are not excluded (note that other workers may differ from us on one or both of these points).          The list of nonbonded exclusion is generated in two steps.  First a preliminary list is made at generation by GENIC using any information that may be present in the topology file (for example, diagonal interactions in rings).  The second step is an automatic compilation of all the bond and angle interactions, followed by a sorting of the list, performed in MAKINB.  The list is stored in the linked list pair IBLO14/INB14, where IBLO14(i) points to the last exclusion in INB14 to atom i.  If the list is modified after MAKINB, then either MAKINB should be called again to resort the list, or care must be taken to see that the INB14 list is ascending with all INB14 entries having higher atom numbers than i and that all atoms have at least one INB entry.          MAKINB is called by default after any operation which changes internal coordinates such as generate, patch, or edit.          The exclusion list can be specified in three ways. First, interactions that are to be excluded can be placed in the topology file by listing the excluded atoms after the charge.  Second, NBXM mode can be specified as a qualifier to any of the commands which change internal coordinates.  Third, the default NBXM value can be specified in the parameter file.  The NBXM values and actions are (in the following ""include"" refers to what is being kept (included) in the exclusion list):          0        use the existing list (do nothing)         1 or -1  include nothing extra         2 or -2  include only 1-2 (bond) interactions         3 or -3  also include 1-3 (angle) interactions         4 or -4  also include 1-4 interactions automatically.         5 or -5  include up to 1-3 interactions as exclusions and process                  1-4 interactions using the 1-4 van der Waal parameters and                  reduced elecrostatics (E14FAC).           Negative values suppress the use of the information present in the topology file.  Positive values add to the information that was in the topology file.     File:  Struct  -=-    Node:  Patch    Up :  Top  -=-   Next :  Delete  -=-   Previous :  Nbx                          Patch command to modify PSF  [SYNTAX PATCh structure file]  Syntax (command level)          PATCh <pres-name> segid1 resid1 [, segid2 resid2 [,...                                          [, segid9 resid9]...]]                                           [SORT]                                            [SETUp]                                             [WARN]  Syntax (corresponding patch residue in RTF)          PRES <pres-name>          [GROUp]         [ATOM  <I><atomname>  <parameter type>   <charge> ]         [DELEte ATOM <I><atomname>]          [ [DELEte] BOND <I1> <I2> ]         [ [DELEte] ANGLe <I1> <I2> <I3> ]         [ [DELEte] DIHEdral <I1> <I2> <I3> <I4> ]         [ [DELEte] IMPRoper <I1> <I2> <I3> <I4> ]         [ [DELEte] DONOr  [<I1>] <I2> [[<I3> [<I4>]] ]         [ [DELEte] ACCEptor  <I1> [ <I2> [ <I3> ]] ]          [ IC  <I1> <I2> [*]<I3> <I4>   real real real real real ]         [ DELEte IC <I1> <I2> [*]<I3> <I4> ]       where I1, I2, I3, I4 refer to <I><atomname>.   Rules governing the patch procedure:  1) If an atom is being added via a PATCH at least one or more atoms    already existing in the residue to which the patch is being added    must be included in the PRES with an ATOM statement.  Unless     this(these) atoms are deleted using the DELEte ATOM command    internal terms associated with this atom which are already present     in the residue should NOT be included in the PRES.  2) if no <I> is specified before <atomname> the patch procedure assumes    that the atom should be in residue (segid1 resid1).  3) a '-', '+', '#' as a first letter in <atomname> tries to locate or add    the atom <atomname> in the previous, next, next of the next, residue    of residue (segid<I> resid<I>), respectively.  4) GROUP brackets in a patch residue have highest priority.  5) If no GROUP is specified, the group numbers of referenced, already    existing atoms remain unchanged. Added atoms are placed in the last group     of the referenced residue.  6) A GROUP statement in a patch residue CAN enclose atoms in different    referenced residues. However, if there is a conflict between    sequential residue AND group boundaries new residues MIGHT be created    with resid's and segid's referring to the referenced residues.    These cases are indicated by a message from MAPIC that a negative number    of residues were created. The user has to check the PSF explicitly    to decide whether the modifications done by PATCH are appropriate.  7) Along with the PSF the coordinates, comparision coordinates, harmonic    constraints, fixed atom list, internal coordinates (IC) are    mapped correctly.  8) THERE IS NO MAP OF NBONDS, HBONDS, SHAKE, DYNAMICS ETC.    THE ATOMNUMBERS ARE CHANGED.  9) Any bond, angle, etc referring to deleted atoms is itself deleted.    The bond, angle, etc lists are compressed.  10)Even if the AUTOgenerate ANGLe and/or DIHEdral option has been    invoked new angles and/or dihedrals have to be included in    the PRES when that particular patch is being called after    the GENErate statement.  The angles and/or dihedrals will    be generated automatically for any patch which is called    in the GENErate statement following the FIRSt or LAST     statements. NOTE: If angles and dihedrals are present in    a PRES which is called in a GENErate statement in which    AUTOgenerate ANGLes and/or DIHEdrals is being used those    angles and/or dihedrals will be invoked twice in the PSF    and, thus, be included twice when the energy is calculated.     The AUTOgenerate command (next) can be used to circumvent the above    problems, and removes the need for specifying angles and dihedrals    as part of a PRES definition.    File:  Struct  -=-    Node:  Autogen    Up :  Top  -=-   Next :  Delete  -=-   Previous :  Patch             Completely autogenerate all angles and/or dihedrals  AUTOgen   {  ANGLes     [ DIHEdrals ]  }           {  DIHEdrals  [ ANGLes    ]  }  Sets the angle and/or dihedral counts to zero in the PSF, and rebuilds the indicated list(s) of energy terms.  Intended to simplify the development of patches, since only bonding terms need to be specified in PRES definitions which are followed by this command.  Note that at least one keyword is required, but both may be specified, in either order.  WARNING: may be a problem if the PSF contains any water molecules.    File:  Struct  -=-    Node:  Delete    Up :  Top  -=-   Next :  Rename  -=-   Previous :  Autogen             Delete atoms or energy terms in the structure  [Syntax DELEte terms in structure file]  DELEte  {   ATOMs        atom-selection                 } [SORT]         {                                               }         { { BONDs              } double-atom-selection  }         { { ANGLes             }                        }         { { DIHEdrals          }                        }         { { IMPRoper-dihedrals }                        }         { { CONNectivity       }                        }                                   Function          The DELEte ATOM option deletes selected atoms and all references to them in PSF.   NOTE: THIS WILL CHANGE THE ATOM NUMBERING.  Note: If PERT is currently in use, this command only affects the active (lambda=1) PSF.  The reference PSF (lambda=0) is only modified by the PERT command.          For the internal energy terms, any entry that has an atom selected in both atom selections will be deleted. Note, if an atom is selected in both atom selections, all connections to this atom will be deleted, except for bonds. For a bond to be deleted, one of its atoms must appear in each of the atom selections. The CONN (connectivity) option will delete all bond, angles, dihedrals, and improper dihedrals. This option avoids the necessity of running the DELEte command four times when one wishes to break some connectivity.          The SORT option performs an optional sorting of the PSF after the deleted atoms have been mapped out.   File:  Struct  -=-    Node:  Rename    Up :  Top  -=-   Previous :  Delete  -=-   Next :  Join          RENAme - rename portions of the current PSF [SYNTAX RENAme structure file elements]           RENAme is invoked only from the main command parser and it includes the working PSF. Its syntax is;          RENAme  { SEGId }  new-name  atom-selection                 { RESId }                 { RESN  }                 { ATOM  }          Any atoms selected will have the corresponding ID modified. There is a check for duplicate SEGIDs, RESIDs, and atom names, but it wont stop you if BOMLEV is negative. Renaming ST2 will not change their status (except in the setup for SHAKE, which will be fixed soon).   File:  Struct  -=-    Node:  Join    Up :  Top  -=-   Previous :  Rename  -=-   Next :  Top                      Joining Two Adjacent Segments          For some operations, it is convenient to be able to join two adjacent segments together. This process has no effect on the energy terms, but just reorganizes naming and grouping of atoms into segments. This is especially useful with IMAGES so that all images in the PSF are identified only as a single segment.  Syntax:  JOIN  first_segment  [second_segment]  [ RENUmber ]           The second segment must follow the first sequentially in the PSF.  There is no checking for duplicate residue identifiers. The RENUmber option sets the resid for each residue of the composite segment to the relative index in that segment (just as it would have during a generate command).  If only a single segment is specified with the RENUmber option, then the resid's of this segment will be numbered sequentially.           NHLBI/LBC Computational Biophysics Section         CHARMM Documentation /   Rick_Venable@nih.gov"
GX035-87-8139355	Next:    Syntax   Up:    TopologyParameters and     Previous:    Example: Delete One           Duplicating the Molecular Structure                    The duplicate statement allows one to duplicate the molecular structure or  selected atoms of it.  The statement duplicates all   atom properties, coordinates, connectivities, bonds, angles, etc.  It has a renaming feature that allows one to specify a new segment or residue name for the duplicated atoms.             Syntax      Requirements      Example: Duplication of Side-Chain Atoms           Web Manager   Sat Mar 11 09:37:37 PST 1995
GX036-40-6124801	"CHARMM c27n1 struct.doc     File:  Struct  -=-    Node:  Top    Up : ( commands.doc ) -=-   Next :  Generate              Generation and Manipulation of the Structure (PSF)          The commands described in this node are used to construct and manipulate the PSF, the central data structure in CHARMM (see PSF.FCM).  The PSF holds lists giving every bond, bond angle, torsion angle, and improper torsion angle as well as information needed to generate the hydrogen bonds and the non-bonded list. It is essential for the calculation of the energy of the system. A separate data structure deals with symmetric images of the atoms.  See *note Images: ( images.doc ).          There is an order with which commands to generate and manipulate the PSF must be given.  First, segments in the PSF must be generated one at a time.  Prior to generating any segments, one must first have read a residue topology file, see *note read:( io.doc )Read.  To generate one segment, one must first read in a sequence using the READ command, see *note seq:( io.doc )Sequence.  Then, the GENERATE command must be given.          Once a segment is generated, it may be manipulated. This can be done in a very general way using the patch command. The patch command allows, for instance, the addition of disulfide bridges, changing the protonation state of a titratible residue or to make a histidine heme crosslink.          The PSF can be saved with the ""WRITE PSF"" command.  A PSF may be read with the ""READ PSF"" command.  The ""READ PSF"" command has an ""APPEnd"" option that allows the merging of individual PSF files.  In addition, the ""DELETE"" command allows the deletetion of atoms and all references to the deleted atoms.  * Menu:  *  Generate ::            Generating a segment *  Nbx ::                 Nonbond exclusion lists *  Patch ::               Multi purpose patch command to modify the PSF *  Autogen ::             Autogenerate angles and/or dihedrals after patches *  Delete ::              Deleting atoms from the PSF *  Rename ::              Renaming atoms, residues, or segments *  Join ::                Joining two adjacent segments to form one   File:  Struct  -=-    Node:  Generate    Up :  Top  -=-   Next :  Nbx  -=-   Previous :  Top          The Generate Command - Construct a Segment of the PSF  [Syntax GENErate segment]    GENErate [segid] { generate-spec        } [SETUp]                    {  DUPLicate segid     }  generate-spec::= [FIRSt pres] [LAST pres] [WARN] [ ANGLe   ] [ DIHEdrals ]                                                  [ NOANgle ] [ NODIhedral]                                  Function          This command uses the sequence of residues specified in the last READ SEQUuence command and the information stored in the residue topology file to add the next segment to the PSF. Each segment contains a list of all the bonds, angles, dihedral angles, and improper torsions needed to calculate the energy. It also assigns charges to all the atoms, sets up the nonbonded exclusions list, and specifies hydrogen bond donors and acceptors. Any internal coordinate which references atoms outside the range of the segment is deleted. This prevents any unexpected bonding of segments.         The FIRSt and LAST specifications define what patch-residues should be used for the terminating residues. If no specification is given, then the default patching as specified in the topology file will be used.         The WARN keyword, will list all elements that were deleted due to nonexistant atoms (usually references to the terminating residues).         The SETUp option will cause any internal coordinate table entries (IC) from the topology file to be appended to the main IC table.          The ANGLe (NOANgle) and DIHEdral (NODIhedral) options overide the autogeneration option specified in the topology files. This may be done to supress unwanted additional terms, or to add terms for specific residues.          NOTE: The solvent residues (TIP3, ST2, WAT) must be generated with the NOANgle and/or NODIhedral qualifier. This is only necessary for  the files which use the AUTOgenerate ANGLes and/or DIHEdrals as a default. This also means that a protein residue sequence and water molecules may not be combined in the same generate command. Also, there is a special ""READ SEQUence residue_type integer"" command where integer is the number of resudies of residue_type (often water molecules). This avoids the need to list the number of residues followed by the specification of each TIP3 residue name individually as is done with a protein.          For the DUPLicate segment option, the generate command MUST NOT be preceeded by a READ SEQUence command. This option will create a new segment which is identical (except for the segid) to an existing segment. This option is mainly intended for the use in setting up small crystals for viewing and other analysis.   File:  Struct  -=-    Node:  Nbx    Up :  Top  -=-   Next :  Patch  -=-   Previous :  Generate          Some pairs of atoms are excluded from the nbond exclusion lists because their interactions are described by other terms in the hamiltonian. By default directly bonded atoms and the 1-3 atoms of an angle are excluded from the nonbond calculation.  In addition the diagonal interactions of the six membered rings in tyrosine and phenylalanine were excluded from the nonbond calculation through charmm version 15 with RTOPH6. Hydrogen bonds, and dihedral 1-4 interactions are not excluded (note that other workers may differ from us on one or both of these points).          The list of nonbonded exclusion is generated in two steps.  First a preliminary list is made at generation by GENIC using any information that may be present in the topology file (for example, diagonal interactions in rings).  The second step is an automatic compilation of all the bond and angle interactions, followed by a sorting of the list, performed in MAKINB.  The list is stored in the linked list pair IBLO14/INB14, where IBLO14(i) points to the last exclusion in INB14 to atom i.  If the list is modified after MAKINB, then either MAKINB should be called again to resort the list, or care must be taken to see that the INB14 list is ascending with all INB14 entries having higher atom numbers than i and that all atoms have at least one INB entry.          MAKINB is called by default after any operation which changes internal coordinates such as generate, patch, or edit.          The exclusion list can be specified in three ways. First, interactions that are to be excluded can be placed in the topology file by listing the excluded atoms after the charge.  Second, NBXM mode can be specified as a qualifier to any of the commands which change internal coordinates.  Third, the default NBXM value can be specified in the parameter file.  The NBXM values and actions are (in the following ""include"" refers to what is being kept (included) in the exclusion list):          0        use the existing list (do nothing)         1 or -1  include nothing extra         2 or -2  include only 1-2 (bond) interactions         3 or -3  also include 1-3 (angle) interactions         4 or -4  also include 1-4 interactions automatically.         5 or -5  include up to 1-3 interactions as exclusions and process                  1-4 interactions using the 1-4 van der Waal parameters and                  reduced elecrostatics (E14FAC).           Negative values suppress the use of the information present in the topology file.  Positive values add to the information that was in the topology file.     File:  Struct  -=-    Node:  Patch    Up :  Top  -=-   Next :  Delete  -=-   Previous :  Nbx                          Patch command to modify PSF  [SYNTAX PATCh structure file]  Syntax (command level)          PATCh <pres-name> segid1 resid1 [, segid2 resid2 [,...                                          [, segid9 resid9]...]]                                           [SORT]                                            [SETUp]                                             [WARN]  Syntax (corresponding patch residue in RTF)          PRES <pres-name>          [GROUp]         [ATOM  <I><atomname>  <parameter type>   <charge> ]         [DELEte ATOM <I><atomname>]          [ [DELEte] BOND <I1> <I2> ]         [ [DELEte] ANGLe <I1> <I2> <I3> ]         [ [DELEte] DIHEdral <I1> <I2> <I3> <I4> ]         [ [DELEte] IMPRoper <I1> <I2> <I3> <I4> ]         [ [DELEte] DONOr  [<I1>] <I2> [[<I3> [<I4>]] ]         [ [DELEte] ACCEptor  <I1> [ <I2> [ <I3> ]] ]          [ IC  <I1> <I2> [*]<I3> <I4>   real real real real real ]         [ DELEte IC <I1> <I2> [*]<I3> <I4> ]       where I1, I2, I3, I4 refer to <I><atomname>.   Rules governing the patch procedure:  1) If an atom is being added via a PATCH at least one or more atoms    already existing in the residue to which the patch is being added    must be included in the PRES with an ATOM statement.  Unless     this(these) atoms are deleted using the DELEte ATOM command    internal terms associated with this atom which are already present     in the residue should NOT be included in the PRES.  2) if no <I> is specified before <atomname> the patch procedure assumes    that the atom should be in residue (segid1 resid1).  3) a '-', '+', '#' as a first letter in <atomname> tries to locate or add    the atom <atomname> in the previous, next, next of the next, residue    of residue (segid<I> resid<I>), respectively.  4) GROUP brackets in a patch residue have highest priority.  5) If no GROUP is specified, the group numbers of referenced, already    existing atoms remain unchanged. Added atoms are placed in the last group     of the referenced residue.  6) A GROUP statement in a patch residue CAN enclose atoms in different    referenced residues. However, if there is a conflict between    sequential residue AND group boundaries new residues MIGHT be created    with resid's and segid's referring to the referenced residues.    These cases are indicated by a message from MAPIC that a negative number    of residues were created. The user has to check the PSF explicitly    to decide whether the modifications done by PATCH are appropriate.  7) Along with the PSF the coordinates, comparision coordinates, harmonic    constraints, fixed atom list, internal coordinates (IC) are    mapped correctly.  8) THERE IS NO MAP OF NBONDS, HBONDS, SHAKE, DYNAMICS ETC.    THE ATOMNUMBERS ARE CHANGED.  9) Any bond, angle, etc referring to deleted atoms is itself deleted.    The bond, angle, etc lists are compressed.  10)Even if the AUTOgenerate ANGLe and/or DIHEdral option has been    invoked new angles and/or dihedrals have to be included in    the PRES when that particular patch is being called after    the GENErate statement.  The angles and/or dihedrals will    be generated automatically for any patch which is called    in the GENErate statement following the FIRSt or LAST     statements. NOTE: If angles and dihedrals are present in    a PRES which is called in a GENErate statement in which    AUTOgenerate ANGLes and/or DIHEdrals is being used those    angles and/or dihedrals will be invoked twice in the PSF    and, thus, be included twice when the energy is calculated.     The AUTOgenerate command (next) can be used to circumvent the above    problems, and removes the need for specifying angles and dihedrals    as part of a PRES definition.    File:  Struct  -=-    Node:  Autogen    Up :  Top  -=-   Next :  Delete  -=-   Previous :  Patch             Completely autogenerate all angles and/or dihedrals  AUTOgen   {  ANGLes     [ DIHEdrals ]  }           {  DIHEdrals  [ ANGLes    ]  }  Sets the angle and/or dihedral counts to zero in the PSF, and rebuilds the indicated list(s) of energy terms.  Intended to simplify the development of patches, since only bonding terms need to be specified in PRES definitions which are followed by this command.  Note that at least one keyword is required, but both may be specified, in either order.  WARNING: may be a problem if the PSF contains any water molecules.    File:  Struct  -=-    Node:  Delete    Up :  Top  -=-   Next :  Rename  -=-   Previous :  Autogen             Delete atoms or energy terms in the structure  [Syntax DELEte terms in structure file]  DELEte  {   ATOMs        atom-selection                 } [SORT]         {                                               }         { { BONDs              } double-atom-selection  }         { { ANGLes             }                        }         { { DIHEdrals          }                        }         { { IMPRoper-dihedrals }                        }         { { CONNectivity       }                        }                                   Function          The DELEte ATOM option deletes selected atoms and all references to them in PSF.   NOTE: THIS WILL CHANGE THE ATOM NUMBERING.          For the internal energy terms, any entry that has an atom selected in both atom selections will be deleted. Note, if an atom is selected in both atom selections, all connections to this atom will be deleted, except for bonds. For a bond to be deleted, one of its atoms must appear in each of the atom selections. The CONN (connectivity) option will delete all bond, angles, dihedrals, and improper dihedrals. This option avoids the necessity of running the DELEte command four times when one wishes to break some connectivity.          The SORT option performs an optional sorting of the PSF after the deleted atoms have been mapped out.   File:  Struct  -=-    Node:  Rename    Up :  Top  -=-   Previous :  Delete  -=-   Next :  Join          RENAme - rename portions of the current PSF [SYNTAX RENAme structure file elements]           RENAme is invoked only from the main command parser and it includes the working PSF. Its syntax is;          RENAme  { SEGId }  new-name  atom-selection                 { RESId }                 { RESN  }                 { ATOM  }          Any atoms selected will have the corresponding ID modified. There is a check for duplicate SEGIDs, RESIDs, and atom names, but it wont stop you if BOMLEV is negative. Renaming ST2 will not change their status (except in the setup for SHAKE, which will be fixed soon).   File:  Struct  -=-    Node:  Join    Up :  Top  -=-   Previous :  Rename  -=-   Next :  Top                      Joining Two Adjacent Segments          For some operations, it is convenient to be able to join two adjacent segments together. This process has no effect on the energy terms, but just reorganizes naming and grouping of atoms into segments. This is especially useful with IMAGES so that all images in the PSF are identified only as a single segment.  Syntax:  JOIN  first_segment  [second_segment]  [ RENUmber ]           The second segment must follow the first sequentially in the PSF.  There is no checking for duplicate residue identifiers. The RENUmber option sets the resid for each residue of the composite segment to the relative index in that segment (just as it would have during a generate command).  If only a single segment is specified with the RENUmber option, then the resid's of this segment will be numbered sequentially.           NHLBI/LBC Computational Biophysics Section         CHARMM Documentation /   Rick_Venable@nih.gov"
GX036-49-0625413	Next:    Requirements   Up:    Duplicating the Molecular     Previous:    Duplicating the Molecular           Syntax     DUPLicate {  < duplicate-statement >  } END   is  invoked from the main level of X-PLOR.  The END statement activates the deletion.   < duplicate-statement > :==     RESIdue= < residue-name >    specifies the  residue name of the duplicated atoms (default: same as original atoms).    SEGId= < segid-name >     specifies the  segment name of the duplicated atoms (default: same as original atoms).   SELEction= < selection >      selects the atoms that are        to be duplicated.               Web Manager   Sat Mar 11 09:37:37 PST 1995
GX036-63-2522970	"Next:    Structure Statement    Up:    Duplicating the Molecular     Previous:    Requirements          Example: Duplication of Side-Chain Atoms     The following example duplicates the atoms of a side chain. The duplicated atoms are identical to the original ones except for the  segment name.   The example can be used   to set up alternate conformations (see Section  12.8 ).   duplicate     selection=( resid 40 and not               ( name ca or name n or name c or name o ) )    segid=""ALT"" end            Web Manager   Sat Mar 11 09:37:37 PST 1995"
GX038-47-1286178	"NIH CHARMM c24n5 struct.doc     File:  Struct  -=-    Node:  Top    Up : ( commands.doc ) -=-   Next :  Generate              Generation and Manipulation of the Structure (PSF)          The commands described in this node are used to construct and manipulate the PSF, the central data structure in CHARMM (see PSF.FCM).  The PSF holds lists giving every bond, bond angle, torsion angle, and improper torsion angle as well as information needed to generate the hydrogen bonds and the non-bonded list. It is essential for the calculation of the energy of the system. A separate data structure deals with symmetric images of the atoms.  See *note Images: ( images.doc ).          There is an order with which commands to generate and manipulate the PSF must be given.  First, segments in the PSF must be generated one at a time.  Prior to generating any segments, one must first have read a residue topology file, see *note read:( io.doc )Read.  To generate one segment, one must first read in a sequence using the READ command, see *note seq:( io.doc )Sequence.  Then, the GENERATE command must be given.          Once a segment is generated, it may be manipulated. This can be done in a very general way using the patch command. The patch command allows, for instance, the addition of disulfide bridges, changing the protonation state of a titratible residue or to make a histidine heme crosslink.          In addition the DELETE command allows the deletetion of atoms and all references to the deleted atoms.  * Menu:  *  Generate ::            Generating a segment *  Nbx ::                 Nonbond exclusion lists *  Patch ::               Multi purpose patch command to modify the PSF *  Autogen ::             Autogenerate angles and/or dihedrals after patches *  Delete ::              Deleting atoms from the PSF *  Rename ::              Renaming atoms, residues, or segments *  Join ::                Joining two adjacent segments to form one   File:  Struct  -=-    Node:  Generate    Up :  Top  -=-   Next :  Nbx  -=-   Previous :  Top          The Generate Command - Construct a Segment of the PSF  [Syntax GENErate segment]    GENErate [segid] { generate-spec        } [SETUp]                    {  DUPLicate segid     }  generate-spec::= [FIRSt pres] [LAST pres] [WARN] [ ANGLe   ] [ DIHEdrals ]                                                  [ NOANgle ] [ NODIhedral]                                  Function          This command uses the sequence of residues specified in the last READ SEQUuence command and the information stored in the residue topology file to add the next segment to the PSF. Each segment contains a list of all the bonds, angles, dihedral angles, and improper torsions needed to calculate the energy. It also assigns charges to all the atoms, sets up the nonbonded exclusions list, and specifies hydrogen bond donors and acceptors. Any internal coordinate which references atoms outside the range of the segment is deleted. This prevents any unexpected bonding of segments.         The FIRSt and LAST specifications define what patch-residues should be used for the terminating residues. If no specification is given, then the default patching as specified in the topology file will be used.         The WARN keyword, will list all elements that were deleted due to nonexistant atoms (usually references to the terminating residues).         The SETUp option will cause any internal coordinate table entries (IC) from the topology file to be appended to the main IC table.          The ANGLe (NOANgle) and DIHEdral (NODIhedral) options overide the autogeneration option specified in the topology files. This may be done to supress unwanted additional terms, or to add terms for specific residues.          NOTE: The solvent residues (TIP3, ST2, WAT) must be generated with the NOANgle and/or NODIhedral qualifier. This is only necessary for  the files which use the AUTOgenerate ANGLes and/or DIHEdrals as a default. This also means that a protein residue sequence and water molecules may not be combined in the same generate command. Also, there is a special ""READ SEQUence residue_type integer"" command where integer is the number of resudies of residue_type (often water molecules). This avoids the need to list the number of residues followed by the specification of each TIP3 residue name individually as is done with a protein.          For the DUPLicate segment option, the generate command MUST NOT be preceeded by a READ SEQUence command. This option will create a new segment which is identical (except for the segid) to an existing segment. This option is mainly intended for the use in setting up small crystals for viewing and other analysis.   File:  Struct  -=-    Node:  Nbx    Up :  Top  -=-   Next :  Patch  -=-   Previous :  Generate          Some pairs of atoms are excluded from the nbond exclusion lists because their interactions are described by other terms in the hamiltonian. By default directly bonded atoms and the 1-3 atoms of an angle are excluded from the nonbond calculation.  In addition the diagonal interactions of the six membered rings in tyrosine and phenylalanine were excluded from the nonbond calculation through charmm version 15 with RTOPH6. Hydrogen bonds, and dihedral 1-4 interactions are not excluded (note that other workers may differ from us on one or both of these points).          The list of nonbonded exclusion is generated in two steps.  First a preliminary list is made at generation by GENIC using any information that may be present in the topology file (for example, diagonal interactions in rings).  The second step is an automatic compilation of all the bond and angle interactions, followed by a sorting of the list, performed in MAKINB.  The list is stored in the linked list pair IBLO14/INB14, where IBLO14(i) points to the last exclusion in INB14 to atom i.  If the list is modified after MAKINB, then either MAKINB should be called again to resort the list, or care must be taken to see that the INB14 list is ascending with all INB14 entries having higher atom numbers than i and that all atoms have at least one INB entry.          MAKINB is called by default after any operation which changes internal coordinates such as generate, patch, or edit.          The exclusion list can be specified in three ways. First, interactions that are to be excluded can be placed in the topology file by listing the excluded atoms after the charge.  Second, NBXM mode can be specified as a qualifier to any of the commands which change internal coordinates.  Third, the default NBXM value can be specified in the parameter file.  The NBXM values and actions are (in the following ""include"" refers to what is being kept (included) in the exclusion list):          0        use the existing list (do nothing)         1 or -1  include nothing extra         2 or -2  include only 1-2 (bond) interactions         3 or -3  also include 1-3 (angle) interactions         4 or -4  also include 1-4 interactions automatically.         5 or -5  include up to 1-3 interactions as exclusions and process                  1-4 interactions using the 1-4 van der Waal parameters and                  reduced elecrostatics (E14FAC).           Negative values suppress the use of the information present in the topology file.  Positive values add to the information that was in the topology file.     File:  Struct  -=-    Node:  Patch    Up :  Top  -=-   Next :  Delete  -=-   Previous :  Nbx                          Patch command to modify PSF  [SYNTAX PATCh structure file]  Syntax (command level)          PATCh <pres-name> segid1 resid1 [, segid2 resid2 [,...                                          [, segid9 resid9]...]]                                           [SORT]                                            [SETUp]                                             [WARN]  Syntax (corresponding patch residue in RTF)          PRES <pres-name>          [GROUp]         [ATOM  <I><atomname>  <parameter type>   <charge> ]         [DELEte ATOM <I><atomname>]          [ [DELEte] BOND <I1> <I2> ]         [ [DELEte] ANGLe <I1> <I2> <I3> ]         [ [DELEte] DIHEdral <I1> <I2> <I3> <I4> ]         [ [DELEte] IMPRoper <I1> <I2> <I3> <I4> ]         [ [DELEte] DONOr  [<I1>] <I2> [[<I3> [<I4>]] ]         [ [DELEte] ACCEptor  <I1> [ <I2> [ <I3> ]] ]          [ IC  <I1> <I2> [*]<I3> <I4>   real real real real real ]         [ DELEte IC <I1> <I2> [*]<I3> <I4> ]       where I1, I2, I3, I4 refer to <I><atomname>.   Rules governing the patch procedure:  1) If an atom is being added via a PATCH at least one or more atoms    already existing in the residue to which the patch is being added    must be included in the PRES with an ATOM statement.  Unless     this(these) atoms are deleted using the DELEte ATOM command    internal terms associated with this atom which are already present     in the residue should NOT be included in the PRES.  2) if no <I> is specified before <atomname> the patch procedure assumes    that the atom should be in residue (segid1 resid1).  3) a '-', '+', '#' as a first letter in <atomname> tries to locate or add    the atom <atomname> in the previous, next, next of the next, residue    of residue (segid<I> resid<I>), respectively.  4) GROUP brackets in a patch residue have highest priority.  5) If no GROUP is specified, the group numbers of referenced, already    existing atoms remain unchanged. Added atoms are placed in the last group     of the referenced residue.  6) A GROUP statement in a patch residue CAN enclose atoms in different    referenced residues. However, if there is a conflict between    sequential residue AND group boundaries new residues MIGHT be created    with resid's and segid's referring to the referenced residues.    These cases are indicated by a message from MAPIC that a negative number    of residues were created. The user has to check the PSF explicitly    to decide whether the modifications done by PATCH are appropriate.  7) Along with the PSF the coordinates, comparision coordinates, harmonic    constraints, fixed atom list, internal coordinates (IC) are    mapped correctly.  8) THERE IS NO MAP OF NBONDS, HBONDS, SHAKE, DYNAMICS ETC.    THE ATOMNUMBERS ARE CHANGED.  9) Any bond, angle, etc referring to deleted atoms is itself deleted.    The bond, angle, etc lists are compressed.  10)Even if the AUTOgenerate ANGLe and/or DIHEdral option has been    invoked new angles and/or dihedrals have to be included in    the PRES when that particular patch is being called after    the GENErate statement.  The angles and/or dihedrals will    be generated automatically for any patch which is called    in the GENErate statement following the FIRSt or LAST     statements. NOTE: If angles and dihedrals are present in    a PRES which is called in a GENErate statement in which    AUTOgenerate ANGLes and/or DIHEdrals is being used those    angles and/or dihedrals will be invoked twice in the PSF    and, thus, be included twice when the energy is calculated.     The AUTOgenerate command (next) can be used to circumvent the above    problems, and removes the need for specifying angles and dihedrals    as part of a PRES definition.    File:  Struct  -=-    Node:  Autogen    Up :  Top  -=-   Next :  Delete  -=-   Previous :  Patch             Completely autogenerate all angles and/or dihedrals  AUTOgen   {  ANGLes     [ DIHEdrals ]  }           {  DIHEdrals  [ ANGLes    ]  }  Sets the angle and/or dihedral counts to zero in the PSF, and rebuilds the indicated list(s) of energy terms.  Intended to simplify the development of patches, since only bonding terms need to be specified in PRES definitions which are followed by this command.  Note that at least one keyword is required, but both may be specified, in either order.  WARNING: may be a problem if the PSF contains any water molecules.    File:  Struct  -=-    Node:  Delete    Up :  Top  -=-   Next :  Rename  -=-   Previous :  Autogen             Delete atoms or energy terms in the structure  [Syntax DELEte terms in structure file]  DELEte  {   ATOMs        atom-selection                 } [SORT]         {                                               }         { { BONDs              } double-atom-selection  }         { { ANGLes             }                        }         { { DIHEdrals          }                        }         { { IMPRoper-dihedrals }                        }         { { CONNectivity       }                        }                                   Function          The DELEte ATOM option deletes selected atoms and all references to them in PSF.   NOTE: THIS WILL CHANGE THE ATOM NUMBERING.          For the internal energy terms, any entry that has an atom selected in both atom selections will be deleted. Note, if an atom is selected in both atom selections, all connections to this atom will be deleted, except for bonds. For a bond to be deleted, one of its atoms must appear in each of the atom selections. The CONN (connectivity) option will delete all bond, angles, dihedrals, and improper dihedrals. This option avoids the necessity of running the DELEte command four times when one wishes to break some connectivity.          The SORT option performs an optional sorting of the PSF after the deleted atoms have been mapped out.   File:  Struct  -=-    Node:  Rename    Up :  Top  -=-   Previous :  Delete  -=-   Next :  Join          RENAme - rename portions of the current PSF [SYNTAX RENAme structure file elements]           RENAme is invoked only from the main command parser and it includes the working PSF. Its syntax is;          RENAme  { SEGId }  new-name  atom-selection                 { RESId }                 { RESN  }                 { ATOM  }          Any atoms selected will have the corresponding ID modified. There is a check for duplicate SEGIDs, RESIDs, and atom names, but it wont stop you if BOMLEV is negative. Renaming ST2 will not change their status (except in the setup for SHAKE, which will be fixed soon).   File:  Struct  -=-    Node:  Join    Up :  Top  -=-   Previous :  Rename  -=-   Next :  Top                      Joining Two Adjacent Segments          For some operations, it is convenient to be able to join two adjacent segments together. This process has no effect on the energy terms, but just reorganizes naming and grouping of atoms into segments. This is especially useful with IMAGES so that all images in the PSF are identified only as a single segment.  Syntax:  JOIN  first_segment  [second_segment]  [ RENUmber ]           The second segment must follow the first sequentially in the PSF.  There is no checking for duplicate residue identifiers. The RENUmber option sets the resid for each residue of the composite segment to the relative index in that segment (just as it would have during a generate command).  If only a single segment is specified with the RENUmber option, then the resid's of this segment will be numbered sequentially.      CHARMM .doc  Homepage     Information and HTML Formatting Courtesy of:  NIH/NHLBI/LBC Computational Biophysics Section  FDA/CBER/OVRR Biophysics Laboratory"
GX042-58-12852016	"CHARMM c28b2 struct.doc     File:  Struct  -=-    Node:  Top    Up : ( commands.doc ) -=-   Next :  Generate              Generation and Manipulation of the Structure (PSF)          The commands described in this node are used to construct and manipulate the PSF, the central data structure in CHARMM (see PSF.FCM).  The PSF holds lists giving every bond, bond angle, torsion angle, and improper torsion angle as well as information needed to generate the hydrogen bonds and the non-bonded list. It is essential for the calculation of the energy of the system. A separate data structure deals with symmetric images of the atoms.  See *note Images: ( images.doc ).          There is an order with which commands to generate and manipulate the PSF must be given.  First, segments in the PSF must be generated one at a time.  Prior to generating any segments, one must first have read a residue topology file, see *note read:( io.doc )Read.  To generate one segment, one must first read in a sequence using the READ command, see *note seq:( io.doc )Sequence.  Then, the GENERATE command must be given.          Once a segment is generated, it may be manipulated. This can be done in a very general way using the patch command. The patch command allows, for instance, the addition of disulfide bridges, changing the protonation state of a titratible residue or to make a histidine heme crosslink.          The PSF can be saved with the ""WRITE PSF"" command.  A PSF may be read with the ""READ PSF"" command.  The ""READ PSF"" command has an ""APPEnd"" option that allows the merging of individual PSF files.  In addition, the ""DELETE"" command allows the deletetion of atoms and all references to the deleted atoms.  * Menu:  *  Generate ::            Generating a segment *  Nbx ::                 Nonbond exclusion lists *  Patch ::               Multi purpose patch command to modify the PSF *  Autogen ::             Autogenerate angles and/or dihedrals after patches *  Delete ::              Deleting atoms from the PSF *  Rename ::              Renaming atoms, residues, or segments *  Join ::                Joining two adjacent segments to form one   File:  Struct  -=-    Node:  Generate    Up :  Top  -=-   Next :  Nbx  -=-   Previous :  Top          The Generate Command - Construct a Segment of the PSF  [Syntax GENErate segment]    GENErate [segid] { generate-spec        } [SETUp]                    {  DUPLicate segid     }  generate-spec::= [FIRSt pres] [LAST pres] [WARN] [ ANGLe   ] [ DIHEdrals ]                                                  [ NOANgle ] [ NODIhedral]                                  Function          This command uses the sequence of residues specified in the last READ SEQUuence command and the information stored in the residue topology file to add the next segment to the PSF. Each segment contains a list of all the bonds, angles, dihedral angles, and improper torsions needed to calculate the energy. It also assigns charges to all the atoms, sets up the nonbonded exclusions list, and specifies hydrogen bond donors and acceptors. Any internal coordinate which references atoms outside the range of the segment is deleted. This prevents any unexpected bonding of segments.         The FIRSt and LAST specifications define what patch-residues should be used for the terminating residues. If no specification is given, then the default patching as specified in the topology file will be used.         The WARN keyword, will list all elements that were deleted due to nonexistant atoms (usually references to the terminating residues).         The SETUp option will cause any internal coordinate table entries (IC) from the topology file to be appended to the main IC table.          The ANGLe (NOANgle) and DIHEdral (NODIhedral) options overide the autogeneration option specified in the topology files. This may be done to supress unwanted additional terms, or to add terms for specific residues.          NOTE: The solvent residues (TIP3, ST2, WAT) must be generated with the NOANgle and/or NODIhedral qualifier. This is only necessary for  the files which use the AUTOgenerate ANGLes and/or DIHEdrals as a default. This also means that a protein residue sequence and water molecules may not be combined in the same generate command. Also, there is a special ""READ SEQUence residue_type integer"" command where integer is the number of resudies of residue_type (often water molecules). This avoids the need to list the number of residues followed by the specification of each TIP3 residue name individually as is done with a protein.          For the DUPLicate segment option, the generate command MUST NOT be preceeded by a READ SEQUence command. This option will create a new segment which is identical (except for the segid) to an existing segment. This option is mainly intended for the use in setting up small crystals for viewing and other analysis.   File:  Struct  -=-    Node:  Nbx    Up :  Top  -=-   Next :  Patch  -=-   Previous :  Generate          Some pairs of atoms are excluded from the nbond exclusion lists because their interactions are described by other terms in the hamiltonian. By default directly bonded atoms and the 1-3 atoms of an angle are excluded from the nonbond calculation.  In addition the diagonal interactions of the six membered rings in tyrosine and phenylalanine were excluded from the nonbond calculation through charmm version 15 with RTOPH6. Hydrogen bonds, and dihedral 1-4 interactions are not excluded (note that other workers may differ from us on one or both of these points).          The list of nonbonded exclusion is generated in two steps.  First a preliminary list is made at generation by GENIC using any information that may be present in the topology file (for example, diagonal interactions in rings).  The second step is an automatic compilation of all the bond and angle interactions, followed by a sorting of the list, performed in MAKINB.  The list is stored in the linked list pair IBLO14/INB14, where IBLO14(i) points to the last exclusion in INB14 to atom i.  If the list is modified after MAKINB, then either MAKINB should be called again to resort the list, or care must be taken to see that the INB14 list is ascending with all INB14 entries having higher atom numbers than i and that all atoms have at least one INB entry.          MAKINB is called by default after any operation which changes internal coordinates such as generate, patch, or edit.          The exclusion list can be specified in three ways. First, interactions that are to be excluded can be placed in the topology file by listing the excluded atoms after the charge.  Second, NBXM mode can be specified as a qualifier to any of the commands which change internal coordinates.  Third, the default NBXM value can be specified in the parameter file.  The NBXM values and actions are (in the following ""include"" refers to what is being kept (included) in the exclusion list):          0        use the existing list (do nothing)         1 or -1  include nothing extra         2 or -2  include only 1-2 (bond) interactions         3 or -3  also include 1-3 (angle) interactions         4 or -4  also include 1-4 interactions automatically.         5 or -5  include up to 1-3 interactions as exclusions and process                  1-4 interactions using the 1-4 van der Waal parameters and                  reduced elecrostatics (E14FAC).           Negative values suppress the use of the information present in the topology file.  Positive values add to the information that was in the topology file.     File:  Struct  -=-    Node:  Patch    Up :  Top  -=-   Next :  Delete  -=-   Previous :  Nbx                          Patch command to modify PSF  [SYNTAX PATCh structure file]  Syntax (command level)          PATCh <pres-name> segid1 resid1 [, segid2 resid2 [,...                                          [, segid9 resid9]...]]                                           [SORT]                                            [SETUp]                                             [WARN]  Syntax (corresponding patch residue in RTF)          PRES <pres-name>          [GROUp]         [ATOM  <I><atomname>  <parameter type>   <charge> ]         [DELEte ATOM <I><atomname>]          [ [DELEte] BOND <I1> <I2> ]         [ [DELEte] ANGLe <I1> <I2> <I3> ]         [ [DELEte] DIHEdral <I1> <I2> <I3> <I4> ]         [ [DELEte] IMPRoper <I1> <I2> <I3> <I4> ]         [ [DELEte] DONOr  [<I1>] <I2> [[<I3> [<I4>]] ]         [ [DELEte] ACCEptor  <I1> [ <I2> [ <I3> ]] ]          [ IC  <I1> <I2> [*]<I3> <I4>   real real real real real ]         [ DELEte IC <I1> <I2> [*]<I3> <I4> ]       where I1, I2, I3, I4 refer to <I><atomname>.   Rules governing the patch procedure:  1) If an atom is being added via a PATCH at least one or more atoms    already existing in the residue to which the patch is being added    must be included in the PRES with an ATOM statement.  Unless     this(these) atoms are deleted using the DELEte ATOM command    internal terms associated with this atom which are already present     in the residue should NOT be included in the PRES.  2) if no <I> is specified before <atomname> the patch procedure assumes    that the atom should be in residue (segid1 resid1).  3) a '-', '+', '#' as a first letter in <atomname> tries to locate or add    the atom <atomname> in the previous, next, next of the next, residue    of residue (segid<I> resid<I>), respectively.  4) GROUP brackets in a patch residue have highest priority.  5) If no GROUP is specified, the group numbers of referenced, already    existing atoms remain unchanged. Added atoms are placed in the last group     of the referenced residue.  6) A GROUP statement in a patch residue CAN enclose atoms in different    referenced residues. However, if there is a conflict between    sequential residue AND group boundaries new residues MIGHT be created    with resid's and segid's referring to the referenced residues.    These cases are indicated by a message from MAPIC that a negative number    of residues were created. The user has to check the PSF explicitly    to decide whether the modifications done by PATCH are appropriate.  7) Along with the PSF the coordinates, comparision coordinates, harmonic    constraints, fixed atom list, internal coordinates (IC) are    mapped correctly.  8) THERE IS NO MAP OF NBONDS, HBONDS, SHAKE, DYNAMICS ETC.    THE ATOMNUMBERS ARE CHANGED.  9) Any bond, angle, etc referring to deleted atoms is itself deleted.    The bond, angle, etc lists are compressed.  10)Even if the AUTOgenerate ANGLe and/or DIHEdral option has been    invoked new angles and/or dihedrals have to be included in    the PRES when that particular patch is being called after    the GENErate statement.  The angles and/or dihedrals will    be generated automatically for any patch which is called    in the GENErate statement following the FIRSt or LAST     statements. NOTE: If angles and dihedrals are present in    a PRES which is called in a GENErate statement in which    AUTOgenerate ANGLes and/or DIHEdrals is being used those    angles and/or dihedrals will be invoked twice in the PSF    and, thus, be included twice when the energy is calculated.     The AUTOgenerate command (next) can be used to circumvent the above    problems, and removes the need for specifying angles and dihedrals    as part of a PRES definition.    File:  Struct  -=-    Node:  Autogen    Up :  Top  -=-   Next :  Delete  -=-   Previous :  Patch             Completely autogenerate all angles and/or dihedrals  AUTOgen   {  ANGLes     [ DIHEdrals ]  }           {  DIHEdrals  [ ANGLes    ]  }  Sets the angle and/or dihedral counts to zero in the PSF, and rebuilds the indicated list(s) of energy terms.  Intended to simplify the development of patches, since only bonding terms need to be specified in PRES definitions which are followed by this command.  Note that at least one keyword is required, but both may be specified, in either order.  WARNING: may be a problem if the PSF contains any water molecules.    File:  Struct  -=-    Node:  Delete    Up :  Top  -=-   Next :  Rename  -=-   Previous :  Autogen             Delete atoms or energy terms in the structure  [Syntax DELEte terms in structure file]  DELEte  {   ATOMs        atom-selection                 } [SORT]         {                                               }         { { BONDs              } double-atom-selection  }         { { ANGLes             }                        }         { { DIHEdrals          }                        }         { { IMPRoper-dihedrals }                        }         { { CONNectivity       }                        }                                   Function          The DELEte ATOM option deletes selected atoms and all references to them in PSF.   NOTE: THIS WILL CHANGE THE ATOM NUMBERING.  Note: If PERT is currently in use, this command only affects the active (lambda=1) PSF.  The reference PSF (lambda=0) is only modified by the PERT command.          For the internal energy terms, any entry that has an atom selected in both atom selections will be deleted. Note, if an atom is selected in both atom selections, all connections to this atom will be deleted, except for bonds. For a bond to be deleted, one of its atoms must appear in each of the atom selections. The CONN (connectivity) option will delete all bond, angles, dihedrals, and improper dihedrals. This option avoids the necessity of running the DELEte command four times when one wishes to break some connectivity.          The SORT option performs an optional sorting of the PSF after the deleted atoms have been mapped out.   File:  Struct  -=-    Node:  Rename    Up :  Top  -=-   Previous :  Delete  -=-   Next :  Join          RENAme - rename portions of the current PSF [SYNTAX RENAme structure file elements]           RENAme is invoked only from the main command parser and it includes the working PSF. Its syntax is;          RENAme  { SEGId }  new-name  atom-selection                 { RESId }                 { RESN  }                 { ATOM  }          Any atoms selected will have the corresponding ID modified. There is a check for duplicate SEGIDs, RESIDs, and atom names, but it wont stop you if BOMLEV is negative. Renaming ST2 will not change their status (except in the setup for SHAKE, which will be fixed soon).   File:  Struct  -=-    Node:  Join    Up :  Top  -=-   Previous :  Rename  -=-   Next :  Top                      Joining Two Adjacent Segments          For some operations, it is convenient to be able to join two adjacent segments together. This process has no effect on the energy terms, but just reorganizes naming and grouping of atoms into segments. This is especially useful with IMAGES so that all images in the PSF are identified only as a single segment.  Syntax:  JOIN  first_segment  [second_segment]  [ RENUmber ]           The second segment must follow the first sequentially in the PSF.  There is no checking for duplicate residue identifiers. The RENUmber option sets the resid for each residue of the composite segment to the relative index in that segment (just as it would have during a generate command).  If only a single segment is specified with the RENUmber option, then the resid's of this segment will be numbered sequentially.           NHLBI/LBC Computational Biophysics         CHARMM Documentation /   Rick_Venable@nih.gov"
GX046-39-12013332	"NIH CHARMM c26n1 struct.doc     File:  Struct  -=-    Node:  Top    Up : ( commands.doc ) -=-   Next :  Generate              Generation and Manipulation of the Structure (PSF)          The commands described in this node are used to construct and manipulate the PSF, the central data structure in CHARMM (see PSF.FCM).  The PSF holds lists giving every bond, bond angle, torsion angle, and improper torsion angle as well as information needed to generate the hydrogen bonds and the non-bonded list. It is essential for the calculation of the energy of the system. A separate data structure deals with symmetric images of the atoms.  See *note Images: ( images.doc ).          There is an order with which commands to generate and manipulate the PSF must be given.  First, segments in the PSF must be generated one at a time.  Prior to generating any segments, one must first have read a residue topology file, see *note read:( io.doc )Read.  To generate one segment, one must first read in a sequence using the READ command, see *note seq:( io.doc )Sequence.  Then, the GENERATE command must be given.          Once a segment is generated, it may be manipulated. This can be done in a very general way using the patch command. The patch command allows, for instance, the addition of disulfide bridges, changing the protonation state of a titratible residue or to make a histidine heme crosslink.          The PSF can be saved with the ""WRITE PSF"" command.  A PSF may be read with the ""READ PSF"" command.  The ""READ PSF"" command has an ""APPEnd"" option that allows the merging of individual PSF files.  In addition, the ""DELETE"" command allows the deletetion of atoms and all references to the deleted atoms.  * Menu:  *  Generate ::            Generating a segment *  Nbx ::                 Nonbond exclusion lists *  Patch ::               Multi purpose patch command to modify the PSF *  Autogen ::             Autogenerate angles and/or dihedrals after patches *  Delete ::              Deleting atoms from the PSF *  Rename ::              Renaming atoms, residues, or segments *  Join ::                Joining two adjacent segments to form one   File:  Struct  -=-    Node:  Generate    Up :  Top  -=-   Next :  Nbx  -=-   Previous :  Top          The Generate Command - Construct a Segment of the PSF  [Syntax GENErate segment]    GENErate [segid] { generate-spec        } [SETUp]                    {  DUPLicate segid     }  generate-spec::= [FIRSt pres] [LAST pres] [WARN] [ ANGLe   ] [ DIHEdrals ]                                                  [ NOANgle ] [ NODIhedral]                                  Function          This command uses the sequence of residues specified in the last READ SEQUuence command and the information stored in the residue topology file to add the next segment to the PSF. Each segment contains a list of all the bonds, angles, dihedral angles, and improper torsions needed to calculate the energy. It also assigns charges to all the atoms, sets up the nonbonded exclusions list, and specifies hydrogen bond donors and acceptors. Any internal coordinate which references atoms outside the range of the segment is deleted. This prevents any unexpected bonding of segments.         The FIRSt and LAST specifications define what patch-residues should be used for the terminating residues. If no specification is given, then the default patching as specified in the topology file will be used.         The WARN keyword, will list all elements that were deleted due to nonexistant atoms (usually references to the terminating residues).         The SETUp option will cause any internal coordinate table entries (IC) from the topology file to be appended to the main IC table.          The ANGLe (NOANgle) and DIHEdral (NODIhedral) options overide the autogeneration option specified in the topology files. This may be done to supress unwanted additional terms, or to add terms for specific residues.          NOTE: The solvent residues (TIP3, ST2, WAT) must be generated with the NOANgle and/or NODIhedral qualifier. This is only necessary for  the files which use the AUTOgenerate ANGLes and/or DIHEdrals as a default. This also means that a protein residue sequence and water molecules may not be combined in the same generate command. Also, there is a special ""READ SEQUence residue_type integer"" command where integer is the number of resudies of residue_type (often water molecules). This avoids the need to list the number of residues followed by the specification of each TIP3 residue name individually as is done with a protein.          For the DUPLicate segment option, the generate command MUST NOT be preceeded by a READ SEQUence command. This option will create a new segment which is identical (except for the segid) to an existing segment. This option is mainly intended for the use in setting up small crystals for viewing and other analysis.   File:  Struct  -=-    Node:  Nbx    Up :  Top  -=-   Next :  Patch  -=-   Previous :  Generate          Some pairs of atoms are excluded from the nbond exclusion lists because their interactions are described by other terms in the hamiltonian. By default directly bonded atoms and the 1-3 atoms of an angle are excluded from the nonbond calculation.  In addition the diagonal interactions of the six membered rings in tyrosine and phenylalanine were excluded from the nonbond calculation through charmm version 15 with RTOPH6. Hydrogen bonds, and dihedral 1-4 interactions are not excluded (note that other workers may differ from us on one or both of these points).          The list of nonbonded exclusion is generated in two steps.  First a preliminary list is made at generation by GENIC using any information that may be present in the topology file (for example, diagonal interactions in rings).  The second step is an automatic compilation of all the bond and angle interactions, followed by a sorting of the list, performed in MAKINB.  The list is stored in the linked list pair IBLO14/INB14, where IBLO14(i) points to the last exclusion in INB14 to atom i.  If the list is modified after MAKINB, then either MAKINB should be called again to resort the list, or care must be taken to see that the INB14 list is ascending with all INB14 entries having higher atom numbers than i and that all atoms have at least one INB entry.          MAKINB is called by default after any operation which changes internal coordinates such as generate, patch, or edit.          The exclusion list can be specified in three ways. First, interactions that are to be excluded can be placed in the topology file by listing the excluded atoms after the charge.  Second, NBXM mode can be specified as a qualifier to any of the commands which change internal coordinates.  Third, the default NBXM value can be specified in the parameter file.  The NBXM values and actions are (in the following ""include"" refers to what is being kept (included) in the exclusion list):          0        use the existing list (do nothing)         1 or -1  include nothing extra         2 or -2  include only 1-2 (bond) interactions         3 or -3  also include 1-3 (angle) interactions         4 or -4  also include 1-4 interactions automatically.         5 or -5  include up to 1-3 interactions as exclusions and process                  1-4 interactions using the 1-4 van der Waal parameters and                  reduced elecrostatics (E14FAC).           Negative values suppress the use of the information present in the topology file.  Positive values add to the information that was in the topology file.     File:  Struct  -=-    Node:  Patch    Up :  Top  -=-   Next :  Delete  -=-   Previous :  Nbx                          Patch command to modify PSF  [SYNTAX PATCh structure file]  Syntax (command level)          PATCh <pres-name> segid1 resid1 [, segid2 resid2 [,...                                          [, segid9 resid9]...]]                                           [SORT]                                            [SETUp]                                             [WARN]  Syntax (corresponding patch residue in RTF)          PRES <pres-name>          [GROUp]         [ATOM  <I><atomname>  <parameter type>   <charge> ]         [DELEte ATOM <I><atomname>]          [ [DELEte] BOND <I1> <I2> ]         [ [DELEte] ANGLe <I1> <I2> <I3> ]         [ [DELEte] DIHEdral <I1> <I2> <I3> <I4> ]         [ [DELEte] IMPRoper <I1> <I2> <I3> <I4> ]         [ [DELEte] DONOr  [<I1>] <I2> [[<I3> [<I4>]] ]         [ [DELEte] ACCEptor  <I1> [ <I2> [ <I3> ]] ]          [ IC  <I1> <I2> [*]<I3> <I4>   real real real real real ]         [ DELEte IC <I1> <I2> [*]<I3> <I4> ]       where I1, I2, I3, I4 refer to <I><atomname>.   Rules governing the patch procedure:  1) If an atom is being added via a PATCH at least one or more atoms    already existing in the residue to which the patch is being added    must be included in the PRES with an ATOM statement.  Unless     this(these) atoms are deleted using the DELEte ATOM command    internal terms associated with this atom which are already present     in the residue should NOT be included in the PRES.  2) if no <I> is specified before <atomname> the patch procedure assumes    that the atom should be in residue (segid1 resid1).  3) a '-', '+', '#' as a first letter in <atomname> tries to locate or add    the atom <atomname> in the previous, next, next of the next, residue    of residue (segid<I> resid<I>), respectively.  4) GROUP brackets in a patch residue have highest priority.  5) If no GROUP is specified, the group numbers of referenced, already    existing atoms remain unchanged. Added atoms are placed in the last group     of the referenced residue.  6) A GROUP statement in a patch residue CAN enclose atoms in different    referenced residues. However, if there is a conflict between    sequential residue AND group boundaries new residues MIGHT be created    with resid's and segid's referring to the referenced residues.    These cases are indicated by a message from MAPIC that a negative number    of residues were created. The user has to check the PSF explicitly    to decide whether the modifications done by PATCH are appropriate.  7) Along with the PSF the coordinates, comparision coordinates, harmonic    constraints, fixed atom list, internal coordinates (IC) are    mapped correctly.  8) THERE IS NO MAP OF NBONDS, HBONDS, SHAKE, DYNAMICS ETC.    THE ATOMNUMBERS ARE CHANGED.  9) Any bond, angle, etc referring to deleted atoms is itself deleted.    The bond, angle, etc lists are compressed.  10)Even if the AUTOgenerate ANGLe and/or DIHEdral option has been    invoked new angles and/or dihedrals have to be included in    the PRES when that particular patch is being called after    the GENErate statement.  The angles and/or dihedrals will    be generated automatically for any patch which is called    in the GENErate statement following the FIRSt or LAST     statements. NOTE: If angles and dihedrals are present in    a PRES which is called in a GENErate statement in which    AUTOgenerate ANGLes and/or DIHEdrals is being used those    angles and/or dihedrals will be invoked twice in the PSF    and, thus, be included twice when the energy is calculated.     The AUTOgenerate command (next) can be used to circumvent the above    problems, and removes the need for specifying angles and dihedrals    as part of a PRES definition.    File:  Struct  -=-    Node:  Autogen    Up :  Top  -=-   Next :  Delete  -=-   Previous :  Patch             Completely autogenerate all angles and/or dihedrals  AUTOgen   {  ANGLes     [ DIHEdrals ]  }           {  DIHEdrals  [ ANGLes    ]  }  Sets the angle and/or dihedral counts to zero in the PSF, and rebuilds the indicated list(s) of energy terms.  Intended to simplify the development of patches, since only bonding terms need to be specified in PRES definitions which are followed by this command.  Note that at least one keyword is required, but both may be specified, in either order.  WARNING: may be a problem if the PSF contains any water molecules.    File:  Struct  -=-    Node:  Delete    Up :  Top  -=-   Next :  Rename  -=-   Previous :  Autogen             Delete atoms or energy terms in the structure  [Syntax DELEte terms in structure file]  DELEte  {   ATOMs        atom-selection                 } [SORT]         {                                               }         { { BONDs              } double-atom-selection  }         { { ANGLes             }                        }         { { DIHEdrals          }                        }         { { IMPRoper-dihedrals }                        }         { { CONNectivity       }                        }                                   Function          The DELEte ATOM option deletes selected atoms and all references to them in PSF.   NOTE: THIS WILL CHANGE THE ATOM NUMBERING.          For the internal energy terms, any entry that has an atom selected in both atom selections will be deleted. Note, if an atom is selected in both atom selections, all connections to this atom will be deleted, except for bonds. For a bond to be deleted, one of its atoms must appear in each of the atom selections. The CONN (connectivity) option will delete all bond, angles, dihedrals, and improper dihedrals. This option avoids the necessity of running the DELEte command four times when one wishes to break some connectivity.          The SORT option performs an optional sorting of the PSF after the deleted atoms have been mapped out.   File:  Struct  -=-    Node:  Rename    Up :  Top  -=-   Previous :  Delete  -=-   Next :  Join          RENAme - rename portions of the current PSF [SYNTAX RENAme structure file elements]           RENAme is invoked only from the main command parser and it includes the working PSF. Its syntax is;          RENAme  { SEGId }  new-name  atom-selection                 { RESId }                 { RESN  }                 { ATOM  }          Any atoms selected will have the corresponding ID modified. There is a check for duplicate SEGIDs, RESIDs, and atom names, but it wont stop you if BOMLEV is negative. Renaming ST2 will not change their status (except in the setup for SHAKE, which will be fixed soon).   File:  Struct  -=-    Node:  Join    Up :  Top  -=-   Previous :  Rename  -=-   Next :  Top                      Joining Two Adjacent Segments          For some operations, it is convenient to be able to join two adjacent segments together. This process has no effect on the energy terms, but just reorganizes naming and grouping of atoms into segments. This is especially useful with IMAGES so that all images in the PSF are identified only as a single segment.  Syntax:  JOIN  first_segment  [second_segment]  [ RENUmber ]           The second segment must follow the first sequentially in the PSF.  There is no checking for duplicate residue identifiers. The RENUmber option sets the resid for each residue of the composite segment to the relative index in that segment (just as it would have during a generate command).  If only a single segment is specified with the RENUmber option, then the resid's of this segment will be numbered sequentially.      CHARMM .doc  Homepage     Information and HTML Formatting Courtesy of:  NIH/NHLBI/LBC Computational Biophysics Section  FDA/CBER/OVRR Laboratory of Biophysics"
