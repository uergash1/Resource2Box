id	content
GX235-09-13601406	"Building and Installing Software Packages for Linux   Building and Installing Software Packages for Linux  Table of Contents Building and Installing Software Packages for Linux.....................................................................................1 Mendel Cooper --- http://personal.riverusers.com/~thegrendel/ ...........................................................1 1.Introduction...........................................................................................................................................1 2.Unpacking the Files..............................................................................................................................1 3.Using Make...........................................................................................................................................1 4.Prepackaged Binaries............................................................................................................................1 5.Termcap and Terminfo Issues ...............................................................................................................1 6.Backward Compatibility With a.out Binaries.......................................................................................1 7.Troubleshooting....................................................................................................................................2 8.Final Steps .............................................................................................................................................2 9.First Example: Xscrabble ......................................................................................................................2 10.Second Example: Xloadimage............................................................................................................2 11.Third Example: Fortune......................................................................................................................2 12.Fourth Example: Hearts......................................................................................................................2 13.Fifth Example: XmDipmon................................................................................................................2 14.Where to Find Source Archives..........................................................................................................2 15.Final Words .........................................................................................................................................2 16.References and Further Reading.........................................................................................................2 17.Credits.................................................................................................................................................3 1. Introduction..........................................................................................................................................3 10. Second Example: Xloadimage...........................................................................................................3 11. Third Example: Fortune.....................................................................................................................4 12. Fourth Example: Hearts.....................................................................................................................6 13. Fifth Example: XmDipmon.............................................................................................................11 14. Where to Find Source Archives.......................................................................................................13 15. Final Words ......................................................................................................................................14 16. References and Further Reading......................................................................................................14 17. Credits..............................................................................................................................................15 2. Unpacking the Files...........................................................................................................................16 3. Using Make........................................................................................................................................17 4. Prepackaged Binaries.........................................................................................................................19 4.1 Whats wrong with rpms?.................................................................................................................19 4.2 Problems with rpms: an example.....................................................................................................21 5. Termcap and Terminfo Issues ............................................................................................................22 6. Backward Compatibility With a.out Binaries....................................................................................22 6.1 An Example.....................................................................................................................................23 7. Troubleshooting.................................................................................................................................23 7.1 Link Errors.......................................................................................................................................24 7.2 Other Problems................................................................................................................................25 7.3 Tweaking and fine tuning................................................................................................................27 7.4 Where to go for more help...............................................................................................................27 8. Final Steps ..........................................................................................................................................28 9. First Example: Xscrabble ...................................................................................................................28  i   Building and Installing Software Packages for Linux Mendel Cooper --- http://personal.riverusers.com/~thegrendel/ v1.91, 27 July 1999  This is a comprehensive guide to building and installing ""generic"" UNIX software distributions under Linux. Additionally, there is some coverage of ""rpm"" and ""deb"" pre-packaged binaries.  1.Introduction 2.Unpacking the Files 3.Using Make 4.Prepackaged Binaries  4.1 Whats wrong with rpms?  4.2 Problems with rpms: an example  5.Termcap and Terminfo Issues 6.Backward Compatibility With a.out Binaries  6.1 An Example  Building and Installing Software Packages for Linux  1   Building and Installing Software Packages for Linux  7.Troubleshooting     7.1 7.2 7.3 7.4 Link Errors Other Problems Tweaking and fine tuning Where to go for more help  8.Final Steps 9.First Example: Xscrabble 10.Second Example: Xloadimage 11.Third Example: Fortune 12.Fourth Example: Hearts 13.Fifth Example: XmDipmon 14.Where to Find Source Archives 15.Final Words 16.References and Further Reading  7.Troubleshooting  2   Building and Installing Software Packages for Linux  17.Credits Next Previous Contents Next Previous Contents  1. Introduction Many software packages for the various flavors of UNIX and Linux come as compressed archives of source files. The same package may be ""built"" to run on different target machines, and this saves the author of the software from having to produce multiple versions. A single distribution of a software package may thus end up running, in various incarnations, on an Intel box, a DEC Alpha, a RISC workstation, or even a mainframe. Unfortunately, this puts the responsibility of actually ""building"" and installing the software on the end user, the de facto ""system administrator"", the fellow sitting at the keyboard -- you. Take heart, though, the process is not nearly as terrifying or mysterious as it seems, as this guide will demonstrate.  Next Previous ContentsNextPreviousContents  10. Second Example: Xloadimage This example poses an easier problem. The xloadimage program seemed a useful addition to my set of graphic tools. I copied the xloadi41.gz file directly from the source directory on the CD included with the excellent X User Tools book, by Mui and Quercia. As expected, tar xzvf unarchives the files. The make, however, produces a nasty-looking error and terminates.  gcc -c -O -fstrength-reduce -finline-functions -fforce-mem -fforce-addr -DSYSV -I/usr/X11R6/include -DSYSPATHFILE=\""/usr/lib/X11/Xloadimage\"" mcidas.c In file included from /usr/include/stdlib.h:32, from image.h:23, from xloadimage.h:15, from mcidas.c:7: /usr/lib/gcc-lib/i486-linux/2.6.3/include/stddef.h:215: conflicting types for `wchar_t' /usr/X11R6/include/X11/Xlib.h:74: previous declaration of `wchar_t' make[1]: *** [mcidas.o] Error 1 make[1]: Leaving directory `/home/thegrendel/tst/xloadimage.4.1' make: *** [default] Error 2  17.Credits  3   Building and Installing Software Packages for Linux The error message contains the essential clue. Looking at the file image.h, line 23... #include    Aha, somewhere in the source for xloadimage, wchar_t has been redefined from what was specified in the standard include file, stdlib.h. Let us first try commenting out line 23 in image.h, as perhaps the stdlib.h include is not, after all, necessary. At this point, the build proceeds without any fatal errors. The xloadimage package functions correctly now.  NextPreviousContentsNextPreviousContents  11. Third Example: Fortune This example requires some knowledge of C programming. The majority of UNIX/Linux software is written in C, and learning at least a little bit of C would certainly be an asset for anyone serious about software installation. The notorious fortune program displays up a humorous saying, a ""fortune cookie"", every time Linux boots up. Unfortunately (pun intended), attempting to build fortune on a Red Hat distribution with a 2.0.30 kernel generates fatal errors.  ~/fortune# make all  gcc -O2 -Wall -fomit-frame-pointer -pipe -c fortune.c -o fortune.o fortune.c: In function `add_dir': fortune.c:551: structure has no member named `d_namlen' fortune.c:553: structure has no member named `d_namlen' make[1]: *** [fortune.o] Error 1 make[1]: Leaving directory `/home/thegrendel/for/fortune/fortune' make: *** [fortune-bin] Error 2  Looking at fortune.c, the pertinent lines are these. 11. Third Example: Fortune 4   Building and Installing Software Packages for Linux if (dirent->d_namlen == 0) continue; name = copy(dirent->d_name, dirent->d_namlen);  We need to find the structure dirent, but it is not declared in the fortune.c file, nor does a grep dirent show it in any of the other source files. However, at the top of fortune.c, there is the following line.  #include    This appears to be a system library include file, therefore, the logical place to look for dirent.h is in /usr/include. Indeed, there does exist a dirent.h file in /usr/include, but that file does not contain the declaration of the dirent structure. There is, however, a reference to another dirent.h file.  #include    At last, going to /usr/include/linux/dirent.h, we find the structure declaration we need.  struct dirent { long __kernel_off_t unsigned short char limits.h! */ };  d_ino; d_off; d_reclen; d_name[256]; /* We must not include  Sure enough, the structure declaration contains no d_namelen, but there are a couple of ""candidates"" for its equivalent. The most likely of these is d_reclen, since this structure member probably represents the length of something and it is a short integer. The other possibility, d_ino, could be an inode number, judging by its name and type. As a matter of fact, we are probably dealing with a ""directory entry"" structure, and these elements represent attributes of a file, its name, inode, and length (in blocks). This would seem to validate our guess. Let us edit the file fortune.c, and change the two d_namelen references in lines 551 and 553 to d_reclen. Try a make all again. Success. It builds without errors. We can now get our ""cheap thrills"" from fortune.  NextPreviousContentsNextPreviousContents  11. Third Example: Fortune  5   Building and Installing Software Packages for Linux  12. Fourth Example: Hearts Here is the hoary old game of Hearts, written for UNIX systems by Bob Ankeney sometime in the '80's, revised in 1992 by Mike Yang, and currently maintained by Jonathan Badger. Its predecessor was an even older Pascal program by Don Backus of Oregon Software, later updated by Jeff Hemmerling. Originally intended as a multiplayer client, it also works well in single-player mode against computer opponents. The graphics are nice, though the game lacks sophisticated features and the computer players are not particularly strong. All the same, it seems to be the only decent Hearts game available for UNIX and Linux machines even at this late date. Due to its age and lineage, this package is particularly difficult to build on a Linux system. It requires solving a long and perplexing series of puzzles. It is an exercise in patience and determination. Before beginning, make certain that you have either the motif or lesstif libraries installed.  xmkmf make  client.c: In function `read_card': client.c:430: `_tty' undeclared (first use client.c:430: (Each undeclared identifier client.c:430: for each function it appears client.c: In function `scan': client.c:685: `_tty' undeclared (first use make: *** [client.o] Error 1  in this function) is reported only once in.) in this function)  These are the culprits in the file client.c:  #ifndef SYSV (buf[2] != _tty.sg_erase) && (buf[2] != _tty.sg_kill)) { #else (buf[2] != CERASE) && (buf[2] != CKILL)) { #endif   In client.c, add  12. Fourth Example: Hearts  6   Building and Installing Software Packages for Linux #define SYSV  at line 39. This will bypass the reference to _tty. make  client.c:41: sys/termio.h: No such file or directory make: *** [client.o] Error 1   The include file termio.h is in the /usr/include directory on a Linux system, rather than the /usr/include/sys one, as was the case on older UNIX machines. Therefore, change line 41 of client.c from #include    to #include    make  gcc -o hearts -g -L/usr/X11R6/lib client.o hearts.o select.o connect.o sockio.o start_dist.o -lcurses -ltermlib /usr/bin/ld: cannot open -ltermlib: No such file or directory collect2: ld returned 1 exit status make: *** [hearts] Error 1   Modern Linux distributions use the terminfo and/or termcap database, rather than the obsolete termlib one. Edit the Makefile. Line 655: CURSES_LIBRARIES = -lcurses -ltermlib  changes to: 12. Fourth Example: Hearts 7   Building and Installing Software Packages for Linux CURSES_LIBRARIES = -lcurses -ltermcap  make  gcc -o xmhearts -g -L/usr/X11R6/lib xmclient.o hearts.o select.o connect.o sockio.o start_dist.o gfx.o -lXm_s -lXt -lSM -lICE -lXext -lX11 -lPW /usr/bin/ld: cannot open -lXm_s: No such file or directory collect2: ld returned 1 exit status   The main lesstif library is libXm, rather than libXm_s. Therefore, edit the Makefile. In line 653: XMLIB = -lXm_s $(XTOOLLIB) $(XLIB) -lPW  changes to: XMLIB = -lXm $(XTOOLLIB) $(XLIB) -lPW  make  gcc -o xmhearts -g -L/usr/X11R6/lib xmclient.o hearts.o select.o connect.o sockio.o start_dist.o gfx.o -lXm -lXt -lSM -lICE -lXext -lX11 -lPW /usr/bin/ld: cannot open -lPW: No such file or directory collect2: ld returned 1 exit status make: *** [xmhearts] Error 1   Round up the usual suspects. There is no PW library. Edit the Makefile. Line 653: 12. Fourth Example: Hearts 8   Building and Installing Software Packages for Linux XMLIB = -lXm $(XTOOLLIB) $(XLIB) -lPW  changes to: XMLIB = -lXm $(XTOOLLIB) $(XLIB) -lPEX5  (The PEX5 lib comes closest to PW.)  make  rm -f xmhearts gcc -o xmhearts -g -L/usr/X11R6/lib xmclient.o hearts.o select.o connect.o sockio.o start_dist.o gfx.o -lXm -lXt -lSM -lICE -lXext -lX11 -lPEX5  The make finally works (hurray!).   Installation: As root,  [root@localhost hearts]# make install install -c -s hearts /usr/X11R6/bin/hearts install -c -s xmhearts /usr/X11R6/bin/xmhearts install -c -s xawhearts /usr/X11R6/bin/xawhearts install in . done   Test run: rehash (We're running the tcsh shell.) xmhearts 12. Fourth Example: Hearts 9   Building and Installing Software Packages for Linux localhost:~/% xmhearts Can't invoke distributor!   From README file in the hearts package:  Put heartsd, hearts_dist, and hearts.instr in the HEARTSLIB directory defined in local.h and make them world-accessible.  From the file local.h:  /* where the distributor, dealer and instructions live */ #define HEARTSLIB ""/usr/local/lib/hearts""  This is a classic case of RTFM.  As root, cd /usr/local/lib mkdir hearts cd !$ Copy the distributor files to this directory. cp /home/username/hearts/heartsd . cp /home/username/hearts/hearts_dist . cp /home/username/hearts/hearts.instr .   Try another test run. xmhearts 12. Fourth Example: Hearts 10   Building and Installing Software Packages for Linux It works some of the time, but more often than not crashes with a dealer died! message.   The ""distributor"" and ""dealer"" scan the hardware ports. We should thus suspect that those programs need root user privileges. Try, as root, chmod u+s /usr/local/lib/heartsd chmod u+s /usr/local/lib/hearts_dist (Note that, as previously discussed, suid binaries may create security holes.) xmhearts  It finally works!  Hearts is available from Sunsite.  NextPreviousContentsNextPreviousContents  13. Fifth Example: XmDipmon  Bullwinkle: Hey Rocky, watch me pull a rabbit out of my hat. Rocky: But that trick never works. Bullwinkle: This time for sure. Presto! Well, I'm gettin' close. Rocky: And now it's time for another special feature. --- ""Rocky and His Friends""  XmDipmon is a nifty little application that displays a button showing the status of an Internet connection. It flashes and beeps when the connection is broken, as is all too often the case in on rural telephone systems. Unfortunately, XmDipmon works only with dip, making it useless for those people, the majority, who use chat to connect. 13. Fifth Example: XmDipmon 11   Building and Installing Software Packages for Linux Building XmDipmon is not a problem. XmDipmon links to the Motif libraries, but it builds and works fine with Lesstif. The challenge is to alter the package to work when using chat. This involves actually tinkering with the source code, and necessarily requires some programming knowledge.  ""When xmdipmon starts up, it checks for a file called /etc/dip.pid (you can let it look at another file by using the -pidfile command line option). This file contains the PID of the dip deamon (dip switches itself into deamon mode once it has established a connection)."" --- from the XmDipmon README file  Using the -pidfile option, the program can be directed to check for a different file upon startup, one that exists only during a successful chat login. The obvious candidate is the modem lock file. We could therefore try invoking the program with xmdipmon -pidfile /var/lock/LCK..ttyS3 (this assumes that the modem is on com port #4, ttyS3). This only solves part of the problem, however. The program continually monitors the dip daemon, and we need to change this so it instead polls a process associated with chat or ppp. There is only a single source file, and fortunately it is well-commented. Scanning the xmdipmon.c file, we find the getProcFile function, whose header description reads as follows.  /***** * Name: * Return Type: * Description:   *****/  getProcFile Boolean tries to open the /proc entry as read from the dip pid file.  We are hot on the trail now. Tracing into the body of the function...  /* we watch the status of the real dip deamon */ sprintf(buf, ""/proc/%i/status"", pid); procfile = (String)XtMalloc(strlen(buf)*sizeof(char)+1); strcpy(procfile, buf); procfile[strlen(buf)] = '\0';  The culprit is line 2383: sprintf(buf, ""/proc/%i/status"", pid); ^^^^^^^^^^^^^^^^^^^^^  This checks whether the dip daemon process is running . So, how can we change this to monitor the pppd 13. Fifth Example: XmDipmon 12   Building and Installing Software Packages for Linux daemon instead? Looking at the pppd manpage: FILES /var/run/pppn.pid (BSD or Linux), /etc/ppp/pppn.pid (others) Process-ID for pppd process on ppp interface unit n.  Change line 2383 in xmdipmon.c to: sprintf(buf, ""/var/run/ppp0.pid"" );  Rebuild the revised package. No problems with the build. Now test it with the new command line argument. It works like a charm. The little blue button indicates when a ppp connection to the ISP has been established, and flashes and beeps when the connection is broken. Now we have a fully functional chat monitor.  XmDipmon can be downloaded from Ripley Linux Tools.  NextPreviousContentsNextPreviousContents  14. Where to Find Source Archives Now that you are eager to use your newly acquired knowledge to add utilities and other goodies to your system, you may find them online at the Linux Applications and Utilities Page, or on one of the very reasonably priced CD ROM archives by Red Hat, InfoMagic, Linux Systems Labs, Cheap Bytes, and others. A comprehensive repository of source code is the comp sources UNIX archive. Much UNIX source code is posted on the alt.sources newsgroup. If you are looking for particular source code packages, you may post on the related alt.sources.wanted newsgroup. Another good place to check is the comp.os.linux.announce newsgroup. To get on the Unix sources mailing list, send a subscribe message there. Archives for the alt.sources newsgroup are at the following ftp sites:  ftp.sterling.com/usenet/alt.sources/  wuarchive.wustl.edu/usenet/alt.sources/articles  src.doc.ic.ac.uk/usenet/alt.sources/articles  14. Where to Find Source Archives  13   Building and Installing Software Packages for Linux  NextPreviousContentsNextPreviousContents  15. Final Words To sum up, persistence makes all the difference (and a high frustration threshold certainly helps). As in all endeavors, learning from mistakes is critically important. Each misstep, every failure contributes to the body of knowledge that will lead to mastery of the art of building software.  NextPreviousContentsNextPreviousContents  16. References and Further Reading  BORLAND C++ TOOLS AND UTILITIES GUIDE, Borland International, 1992, pp. 9-42. [One of the manuals distributed with Borland C++, ver. 3.1. Gives a fairly good intro to make syntax and concepts, using Borland's crippled implementation for DOS.] DuBois, Paul: SOFTWARE PORTABILITY WITH IMAKE, O'Reilly and Associates, 1996, ISBN 1-56592-226-3. [This is reputed to be the definitive imake reference, though I did not have it available when writing this article.] Frisch, Aeleen: ESSENTIAL SYSTEM ADMINISTRATION (2nd ed.), O'Reilly and Associates, 1995, ISBN 1-56592-127-5. [This otherwise excellent sys admin handbook has only sketchy coverage of software building.] Hekman, Jessica: LINUX IN A NUTSHELL, O'Reilly and Associates, 1997, ISBN 1-56592-167-4. [Good all-around reference to Linux commands.] Lehey, Greg: PORTING UNIX SOFTWARE, O'Reilly and Associates, 1995, ISBN 1-56592-126-7. Mayer, Herbert G.: ADVANCED C PROGRAMMING ON THE IBM PC, Windcrest Books, 1989, ISBN 0-8306-9363-7. [An idea-filled book for the intermediate to advanced C programmer. Superb coverage of algorithms, quirks of the language, and even amusements. Unfortunately, out of print.] Mui, Linda and Valerie Quercia: X USER TOOLS, O'Reilly and Associates, 1994, ISBN 1-56592-019-8, pp. 734-760.  15. Final Words  14   Building and Installing Software Packages for Linux Oram, Andrew and Steve Talbott: MANAGING PROJECTS WITH MAKE, O'Reilly and Associates, 1991, ISBN 0-937175-90-0. Peek, Jerry and Tim O'Reilly and Mike Loukides: UNIX POWER TOOLS, O'Reilly and Associates / Random House, 1997, ISBN 1-56592-260-3. [A wonderful source of ideas, and tons of utilities you may end up building from the source code, using the methods discussed in this article.] Stallman, Richard M. and Roland McGrath: GNU MAKE, Free Software Foundation, 1995, ISBN 1-882114-78-7. [Required reading.] Waite, Mitchell, Stephen Prata, and Donald Martin: C PRIMER PLUS, Waite Group Press, ISBN 0-672-22090-3,. [Probably the best of the introductions to C programming. Extensive coverage for a primer. Newer editions now available.] Welsh, Matt and Lar Kaufman: RUNNING LINUX, O'Reilly and Associates, 1996, ISBN 1-56592-151-8. [Still the best overall Linux reference, though lacking in depth in some areas.]  The man pages for dpkg, gcc, gzip, imake, ldconfig, ldd, make, nm, patch, rpm, shar, strip, tar, termcap, terminfo, and xmkmf.  The BZIP2 HOWTO, by David Fetter. The Glibc2 HOWTO, by Eric Green The LINUX ELF HOWTO, by Daniel Barlow. The RPM HOWTO, by Donnie Barnes. The StarOffice miniHOWTO, by Matthew Borowski.  [These HOWTOs should be in the /usr/doc/HOWTO or /usr/doc/HOWTO/mini directory on your system. Updated versions are available in text, HTML, and SGML format from the LDP site, and usually from the respective authors' home sites.]  NextPreviousContents Next PreviousContents  17. Credits The author of this HOWTO would like to thank the following persons for their helpful suggestions, corrections, and encouragement.  17. Credits  15   Building and Installing Software Packages for Linux  R. Brock Lynn  Michael Jenner  Fabrizio Stefani Kudos also go to the fine people who have translated this HOWTO into Italian and Japanese. And, of course, thanks, praise, benedictions and hosannahs to Greg Hankins and Tim Bynum of the Linux Documentation Project, which has made all this possible.  Next PreviousContentsNextPreviousContents  2. Unpacking the Files You have downloaded or otherwise acquired a software package. Most likely it is archived (tarred) and compressed (gzipped), in .tar.gz or .tgz form (familiarly known as a ""tarball""). First copy it to a working directory. Then untar and gunzip it. The appropriate command for this is tar xzvf filename, where filename is the name of the software file, of course. The de-archiving process will usually install the appropriate files in subdirectories it will create. Note that if the package name has a .Z suffix, then the above procedure will serve just as well, though running uncompress, followed by a tar xvf also works. You may preview this process by a tar tzvf filename, which lists the files in the archive without actually unpacking them. The above method of unpacking ""tarballs"" is equivalent to either of the following:  gzip -cd filename | tar xvf -  gunzip -c filename | tar xvf - (The '-' causes the tar command to take its input from stdin.) Source files in the new bzip2 (.bz2) format can be unarchived by a bzip2 -cd filename | tar xvf -, or, more simply by a tar xyvf filename, assuming that tar has been appropriately patched (refer to the Bzip2 HOWTO for details). Debian Linux uses a different patch for tar, one written by Hiroshi Takekawa, so that the -I, --bzip2, --bunzip2 options work with that particular tar version. [Many thanks to R. Brock Lynn and Fabrizio Stefani for corrections and updates on the above information.]  Sometimes the archived file must be untarred and installed from the user's home directory, or perhaps in a certain other directory, such as /, /usr/src, or /opt, as specified in the package's config info. Should you get an error message attempting to untar it, this may be the reason. Read the package docs, especially the README and/or Install files, if present, and edit the config files and/or Makefiles as necessary, consistent with the installation instructions. Note that you would not ordinarily alter the Imake file, since this could have unforseen consequences. Most software packages permit automating this process by running make install to emplace the binaries in the appropriate system areas.  2. Unpacking the Files  16   Building and Installing Software Packages for Linux  You might encounter shar files, or shell archives, especially in the source code newsgroups on the Internet. These remain in use because they are readable to humans, and this permits newsgroup moderators to sort through them and reject unsuitable ones. They may be unpacked by the unshar filename.shar command. Otherwise the procedure for dealing with them is the same as for ""tarballs"".   Some source archives have been processed using nonstandard DOS, Mac, or even Amiga compression utilities such zip, arc, lha, arj, zoo, rar, and shk. Fortunately, Sunsite and other places have Linux uncompression utilities that can deal with most or all of these. Occasionally, you may need to update or incorporate bug fixes into the unarchived source files using a patch or diff file that lists the changes. The doc files and/or README file will inform you should this be the case. The normal syntax for invoking Larry Wall's powerful patch utility is patch < patchfile. You may now proceed to the build stage of the process.  NextPreviousContentsNextPreviousContents  3. Using Make The Makefile is the key to the build process. In its simplest form, a Makefile is a script for compiling or building the ""binaries"", the executable portions of a package. The Makefile can also provide a means of updating a software package without having to recompile every single source file in it, but that is a different story (or a different article). At some point, the Makefile launches cc or gcc. This is actually a preprocessor, a C (or C++) compiler, and a linker, invoked in that order. This process converts the source into the binaries, the actual executables. Invoking make usually involves just typing make. This generally builds all the necessary executable files for the package in question. However, make can also do other tasks, such as installing the files in their proper directories (make install) and removing stale object files (make clean). Running make -n permits previewing the build process, as it prints out all the commands that would be triggered by a make, without actually executing them.  Only the simplest software uses a generic Makefile. More complex installations require tailoring the Makefile according to the location of libraries, include files, and resources on your particular machine. This is especially the case when the build needs the X11 libraries to install. Imake and xmkmf accomplish this task. An Imakefile is, to quote the man page, a ""template"" Makefile. The imake utility constructs a Makefile appropriate for your system from the Imakefile. In almost all cases, however, you would run xmkmf, a shell script that invokes imake, a front end for it. Check the README or INSTALL file included in the software 3. Using Make 17   Building and Installing Software Packages for Linux archive for specific instructions. (If, after dearchiving the source files, there is an Imake file present in the base directory, this is a dead giveaway that xmkmf should be run.) Read the Imake and xmkmf man pages for a more detailed analysis of the procedure. Be aware that xmkmf and make may need to be invoked as root, especially when doing a make install to move the binaries over to the /usr/bin or /usr/local/bin directories. Using make as an ordinary user without root privileges will likely result in write access denied error messages because you lack write permission to system directories. Check also that the binaries created have the proper execute permissions for you and any other appropriate users. Invoking xmkmf uses the Imake file to build a new Makefile appropriate for your system. You would normally invoke xmkmf with the -a argument, to automatically do a make Makefiles, make includes, and make depend. This sets the variables and defines the library locations for the compiler and linker. Sometimes, there will be no Imake file, instead there will be an INSTALL or configure script that will accomplish this purpose. Note that if you run configure, it should be invoked as ./configure to ensure that the correct configure script in the current directory is called. In most cases, the README file included with the distribution will explain the install procedure. It is usually a good idea to visually inspect the Makefile that xmkmf or one of the install scripts builds. The Makefile will normally be correct for your system, but you may occasionally be required to ""tweak"" it or correct errors manually.  Installing the freshly built binaries into the appropriate system directories is usually a matter of running make install as root. The usual directories for system-wide binaries on modern Linux distributions are /usr/bin, /usr/X11R6/bin, and /usr/local/bin. The preferred directory for new packages is /usr/local/bin, as this will keep separate binaries not part of the original Linux installation. Packages originally targeted for commercial versions of UNIX may attempt to install in the /opt or other unfamiliar directory. This will, of course, result in an installation error if the intended installation directory does not exist. The simplest way to deal with this is to create, as root, an /opt directory, let the package install there, then add that directory to the PATH environmental variable. Alternatively, you may create symbolic links to the /usr/local/bin directory.  Your general installation procedure will therefore be:        Read the README file and other applicable docs. Run xmkmf -a, or the INSTALL or configure script. Check the Makefile. If necessary, run make clean, make Makefiles, make includes, and make depend. Run make. Check file permissions. If necessary, run make install.  Notes:  You would not normally build a package as root. Doing an su to root is only necessary for installing 3. Using Make 18   Building and Installing Software Packages for Linux the compiled binaries into system directories.  After becoming familiar with make and its uses, you may wish to add additional optimization options passed to gcc in the standard Makefile included or created in the package you are installing. Some of these common options are -O2, -fomit-frame-pointer, -funroll-loops, and -mpentium (if you are running a Pentium cpu). Use caution and good sense when modifying a Makefile!  After the make creates the binaries, you may wish to strip them. The strip command removes the symbolic debugging information from the binaries, and reduces their size, often drastically. This also disables debugging, of course.  The Pack Distribution Project offers a different approach to creating archived software packages, based on a set of Python scripting tools for managing symbolic links to files installed in separate collection directories. These archives are ordinary tarballs, but they install in /coll and /pack directories. You may find it necessary to download the Pack-Collection from the above site should you ever run across one of these distributions.  NextPreviousContentsNextPreviousContents  4. Prepackaged Binaries  4.1 Whats wrong with rpms? Manually building and installing packages from source is apparently so daunting a task for some Linux users that they have embraced the popular rpm and deb or the newer Stampede slp package formats. While it may be the case that an rpm install normally runs as smoothly and as fast as a software install in a certain other notorious operating system, some thought should certainly be given to the disadvantages of self-installing, prepackaged binaries. First, be aware that software packages are normally released first as ""tarballs"", and that prepackaged binaries follow days, weeks, even months later. A current rpm package is typically at least a couple of minor version behind the latest ""tarball"". So, if you wish to keep up with all the 'bleeding edge' software, you might not wish to wait for an rpm or deb to appear. Some less popular packages may never be rpm'ed. Second, the ""tarball"" package may well be more complete, have more options, and lend itself better to customization and tweaking. The binary rpm version may be missing some of the functionality of the full release. Source rpm's contain the full source code and are equivalent to the corresponding ""tarballs"", and they likewise need to be built and installed using either of the rpm --recompile packagename.rpm or rpm --rebuild packagename.rpm options. Third, some prepackaged binaries will not properly install, and even if they do install, they could crash and core-dump. They may depend on different library versions than are present in your system, or they may be 4. Prepackaged Binaries 19   Building and Installing Software Packages for Linux improperly prepared or just plain broken. In any case, when installing an rpm or deb you necessarily trust the expertise of the persons who have packaged it. Finally, it helps to have the source code on hand, to be able to tinker with and learn from it. It is much more straightforward to have the source in the archive you are building the binaries from, and not in a separate source rpm.  Installing an rpm package is not necessarily a no-brainer. If there is a dependency conflict, an rpm install will fail. Likewise, should the rpm require a different version of libraries than the ones present on your system, the install may not work, even if you create symbolic links to the missing libraries from the ones in place. Despite their convenience, rpm installs often fail for the same reasons ""tarball"" ones do. You must install rpm's and deb's as root, in order to have the necessary write permissions, and this opens a potentially serious security hole, as you may inadvertently clobber system binaries and libraries, or even install a Trojan horse that might wreak havoc upon your system. It is therefore important to obtain rpm and deb packages from a ""trusted source"". In any case, you should run a 'signature check' (against the MD5 checksum) on the package, rpm --checksig packagename.rpm, before installing. Likewise highly recommended is running rpm -K --nopgp packagename.rpm. The corresponding commands for deb packages are dpkg -I | --info packagename.deb and dpkg -e | --control packagename.deb.  rpm --checksig gnucash-1.1.23-4.i386.rpm  gnucash-1.1.23-4.i386.rpm: size md5 OK  rpm -K --nopgp gnucash-1.1.23-4.i386.rpm  gnucash-1.1.23-4.i386.rpm: size md5 OK For the truly paranoid (and, in this case there is much to be said for paranoia), there are the unrpm and rpmunpack utilities available from the Sunsite utils/package directory for unpacking and checking the individual components of the packages. Klee Diene has written an experimental dpkgcert package for verifying the integrity of installed .deb files against MD5 checksums. It is available from the Debian ftp archive. The current package name / version is dpkgcert_0.2-4.1_all.deb. The Jim Pick Software site maintains an experimental server database to provide dpkgcert certificates for the packages in a typical Debian installation. In their most simple form, the commands rpm -i packagename.rpm and dpkg --install packagename.deb automatically unpack and install the software. Exercise caution, though, since using these commands blindly may be dangerous to your system's health! Note that the above warnings also apply, though to a lesser extent, to Slackware's pkgtool installation utility. All ""automatic"" software installations require caution.  4. Prepackaged Binaries  20   Building and Installing Software Packages for Linux The martian and alien programs allow conversion between the rpm, deb, Stampede slp, and tar.gz package formats. This makes these packages accessible to all Linux distributions. Carefully read the man pages for the rpm and dpkg commands, and refer to the RPM HOWTO, TFUG's Quick Guide to Red Hat's Package Manager, and The Debian Package Management Tools for more detailed information.  4.2 Problems with rpms: an example Jan Hubicka wrote a very nice fractal package called xaos. At his home page, both .tar.gz and rpm packages are available. For the sake of convenience, let us try the rpm version, rather than the ""tarball"". Unfortunately, the rpm of xaos fails to install. Two separate rpm versions misbehave. rpm -i --test XaoS-3.0-1.i386.rpm error: failed dependencies: libslang.so.0 is needed by XaoS-3.0-1 libpng.so.0 is needed by XaoS-3.0-1 libaa.so.1 is needed by XaoS-3.0-1  rpm -i --test xaos-3.0-8.i386.rpm error: failed dependencies: libaa.so.1 is needed by xaos-3.0-8  The strange thing is that libslang.so.0, libpng.so.0, and libaa.so.1 are all present in /usr/lib on the system tested. The rpms of xaos must have been built with slightly different versions of those libraries, even if the release numbers are identical. As a test, let us try installing xaos-3.0-8.i386.rpm with the --nodeps option to force the install. A trial run of xaos crashes. xaos: error in loading shared libraries: xaos: undefined symbol: __fabsl  Let us stubbornly try to get to the bottom of this. Running ldd on the xaos binary to find its library dependencies shows all the necessary shared libraries present. Running nm on the /usr/lib/libaa.so.1 library to list its symbolic references shows that it is indeed missing __fabsl. Of course, the absent reference could be missing from one of the other libraries... There is nothing to be done about that, short of replacing one or more libraries. Enough! Download the ""tarball"", XaoS-3.0.tar.gz, available from the ftp site, as well as from the home 4.2 Problems with rpms: an example 21   Building and Installing Software Packages for Linux page. Try building it. Running ./configure, make, and finally (as root) make install, works flawlessly. This is one of an number of examples of prepackaged binaries being more trouble than they are worth.  NextPreviousContentsNextPreviousContents  5. Termcap and Terminfo Issues According to its man page, ""terminfo is a data base describing terminals, used by screen-oriented programs..."". It defines a generic set of control sequences (escape codes) used to display text on terminals, and makes possible support for different terminal hardware without the need for special drivers. The terminfo libraries are located in /usr/share/terminfo on modern Linux distributions. The terminfo database has largely supplanted the older termcap and the totally obsolete termlib ones. This is usually of no concern for program installation except when dealing with a package that requires termcap. Most Linux distributions now use terminfo, but still retain the older termcap libraries for compatibility with legacy applications (see /etc/termcap). Sometimes there is a special compatibility package that needs to be installed to facilitate use of termcap linked binaries. Very occasionally, an #define termcap statement might need to be commented out of a source file. Check the appropriate doc files for your particular distribution for definitive information on this.  NextPreviousContentsNextPreviousContents  6. Backward Compatibility With a.out Binaries In a very few cases, it is necessary to use a.out binaries, either because the source code is not available or because it is not possible to build new ELF binaries from the source for some reason. As it happens, ELF installations almost always have a complete set of a.out libraries in the /usr/i486-linuxaout/lib directory. The numbering scheme for a.out libraries differs from that of ELF ones, cleverly avoiding conflicts that could cause confusion. The a.out binaries should therefore be able to find the correct libraries at runtime, but this might not always be the case.  5. Termcap and Terminfo Issues  22   Building and Installing Software Packages for Linux Note that the kernel needs to have a.out support built into it, either directly or as a loadable module. It may be necessary to rebuild the kernel to enable this. Moreover, some Linux distributions require installation of a special compatibility package, such as Debian's xcompat for executing a.out X applications.  6.1 An Example Jerry Smith wrote a very handy rolodex program some years back. It uses the Motif libraries, but fortunately is available as a statically linked binary in a.out format. Unfortunately, the source requires numerous tweaks to rebuild using the lesstif libraries. Even more unfortunately, the a.out binary bombs on an ELF system with the following error message. xrolodex: can't load library '//lib/libX11.so.3' No such library  As it happens, there is such a library, in /usr/i486-linuxaout/lib, but xrolodex is unable to locate it at run time. The simple solution is to provide a symbolic link in the /lib directory: ln -s /usr/i486-linuxaout/lib/X11.so.3.1.0 libX11.so.3  It turns out to be necessary to provide similar links for the libXt.so.3 and libc.so.4 libraries. This needs to be done as root, of course. Note that you should make absolutely certain you will not overwrite or cause version number conflicts with pre-existing libraries. Fortunately, the new ELF libraries have higher version numbers than the older a.out ones, to anticipate and forestall just such problems. After creating the three links, xrolodex runs fine. The xrolodex package was originally posted on Spectro, but seems to vanished from there. It may currently be downloaded from Sunsite as a tar.Z format source file [512k].  NextPreviousContentsNextPreviousContents  7. Troubleshooting If xmkmf and/or make succeeded without errors, you may proceed to the next section. However, in ""real life"", few things work right the first time. This is when your resourcefulness is put to the test.  6.1 An Example  23   Building and Installing Software Packages for Linux  7.1 Link Errors  Suppose make fails with a Link error: -lX11: No such file or directory, even after xmkmf has been invoked. This may mean that the Imake file was not set up properly. Check the first part of the Makefile for lines such as: LIB= INCLUDE= LIBS= -L/usr/X11/lib -I/usr/X11/include/X11 -lX11 -lc -lm  The -L and -I switches tell the compiler and linker where to look for the library and include files, respectively. In this example, the X11 libraries should be in the /usr/X11/lib directory, and the X11 include files should be in the /usr/X11/include/X11 directory. If this is incorrect for your machine, make the necessary changes to the Makefile and try the make again.  Undefined references to math library functions, such as the following: /tmp/cca011551.o(.text+0x11): undefined reference to `cos'  The fix for this is to explicitly link in the math library, by adding an -lm to the LIB or LIBS flags in the Makefile (see previous example).   Yet another thing to try if xmkmf fails is the following script: make -DUseInstalled -I/usr/X386/lib/X11/config  This is a sort of bare bones equivalent of xmkmf.  In a very few cases, running ldconfig as root may be the solution:  # ldconfig updates the shared library symbolic links. This may not be necessary .  Some Makefiles use unrecognized aliases for libraries present in your system. For example, the build may require libX11.so.6, but there exists no such file or link in /usr/X11R6/lib. Yet, there is a libX11.so.6.1. The solution is to do a ln -s /usr/X11R6/lib/libX11.so.6.1 /usr/X11R6/lib/libX11.so.6, as root. This may need to be followed by a ldconfig.   Sometimes the source needs the older release X11R5 libraries to build. If you have the R5 libs in 7.1 Link Errors 24   Building and Installing Software Packages for Linux /usr/X11R6/lib (you were given the option of having them when first installing Linux), then you need only ensure that you have the links that the software needs to build. The R5 libs are named libX11.so.3.1.0, libXaw.so.3.1.0, and libXt.so.3.1.0. You generally need links, such as libX11.so.3 -> libX11.so.3.1.0. Possibly the software will also need a link of the form libX11.so -> libX11.so.3.1.0. Of course, to create a ""missing"" link, use the command ln -s libX11.so.3.1.0 libX11.so, as root.   Some packages will require you to install updated versions of one or more libraries. For example, the 4.x versions of the StarOffice suite from StarDivision GmbH were notorious for needing a libc version 5.4.4 or greater. Even the more recent StarOffice 5.0 will not run after installation with the new glibc 2.1 libs. Fortunately, the newer StarOffice 5.1 solves these problems. If running an older version of StarOffice you would, as root, need to copy one or more libraries to the appropriate directories, remove the old libraries, then reset the symbolic links (check the latest version of the StarOffice miniHOWTO for more information on this). Caution: Exercise extreme care in this, as you can render your system nonfunctional if you screw up. You can usually find the latest updated libraries at Sunsite.  7.2 Other Problems  An installed Perl or shell script gives you a No such file or directory error message. In this case, check the file permissions to make sure the file is executable and check the file header to ascertain whether the shell or program invoked by the script is in the place specified. For example, the scrip may begin with: #!/usr/local/bin/perl  If Perl is in fact installed in your /usr/bin directory instead of the /usr/local/bin one, then the script will not run. There are two methods of correcting this. The script file header may be changed to #!/usr/bin/perl, or a symbolic link to the correct directory may be added, ln -s /usr/bin/perl /usr/local/bin/perl.  Some X11 software requires the Motif libraries to build. The standard Linux distributions do not have the Motif libraries installed, and at present Motif costs an extra $100-$200 (though the freeware Lesstif also works in many cases). If you need Motif to build a certain package, but lack the Motif libraries, it may be possible to obtain statically linked binaries. Static linking incorporates the library routines in the binaries themselves. This results in much larger binary files, but the code will run on systems lacking the libraries.  When a package requires libraries not present on your system for the build, it will result in link errors 7.2 Other Problems 25   Building and Installing Software Packages for Linux (undefined reference errors). The libraries may be expensive proprietary ones or difficult to find for sone other reason. In that case, obtaining a statically linked binary either from the author of the package or from a Linux user group may be the easiest to implement fix.   Running a configure script creates a strange Makefile, one seemingly unrelated to the package you are attempting to build. This means the wrong configure ran, one found somewhere else in your path. Always invoke configure as ./configure to prevent this.   Most Linux distributions have changed over to the libc 6 / glibc 2 libraries from the older libc 5. Precompiled binaries that worked with the older library may bomb if you have upgraded your library. The solution is to either recompile the applications from the source or to obtain newer precompiled binaries. If you are in the process of upgrading your system to libc 6 and are experiencing problems, refer to Eric Green's Glibc 2 HOWTO.  Note that there are some minor incompatibilities between glibc versions, so a binary built with glibc 2.1 may not work with glibc 2.0, and vice versa.  Sometimes it is necessary to remove the -ansi option from the compile flags in the Makefile. This enables gcc's extra, non-ANSI features, and allows building packages that require these extensions. (Thanks to Sebastien Blondeel for pointing this out.)  Some programs require having setuid root, in order to run with root privileges. The command to implement this is chmod u+s filename, as root (note that the program must already be owned by root). This has the effect of setting the setuid bit in the file permissions. This issue comes up when the program accesses the system hardware, such as a modem or CD ROM drive, or when the SVGA libs are invoked from console mode, as in one particularly notorious emulation package. If a program works when run by root, but gives access denied error messages to an ordinary user, suspect this as the cause.  Warning: A program with setuid as root may pose a security risk to your system. The program runs with root privileges and thus has the potential for doing significant damage. Make certain that you know what the program does, by looking at the source if possible, before setting the setuid bit.  7.2 Other Problems  26   Building and Installing Software Packages for Linux  7.3 Tweaking and fine tuning You may wish to examine the Makefile to make certain that the best compilation options for your system are invoked. For example, setting the -O2 flag chooses the highest level of optimization and the -fomit-frame-pointer flag results in a smaller binary (though debugging will then be disabled). Do not play around with this unless you know what you are doing, and in any case, not until after a trial build works.  7.4 Where to go for more help In my experience, perhaps 25% of applications build ""right out of the box"". Another 50% or so can be ""persuaded"" to build with an effort ranging from trivial to herculean. That still means a significant number of packages will not build no matter what. Even then, the Intel ELF and/or a.out binaries for these might possibly be found at Sunsite or the TSX-11 archive. Red Hat and Debian have extensive archives of prepackaged binaries of most of the popular Linux software. Perhaps the author of the software can supply the binaries compiled for your particular flavor of machine.  Note that if you obtain precompiled binaries, you will need to check for compatibility with your system:  The binaries must run on your hardware (i.e., Intel x86).  The binaries must be compatible with your kernel (i.e., a.out or ELF).  Your libraries must be up to date.  Your system must have the appropriate installation utility (rpm or deb). If all else fails, you may find help in the appropriate newsgroups, such as comp.os.linux.x or comp.os.linux.development. If nothing at all works, at least you gave it your best effort, and you learned a lot.  NextPreviousContentsNextPreviousContents  7.3 Tweaking and fine tuning  27   Building and Installing Software Packages for Linux  8. Final Steps Read the software package documentation to determine whether certain environmental variables need setting (in .bashrc or .cshrc) and if the .Xdefaults and .Xresources files need customizing. There may be an applications default file, usually named Xfoo.ad in the original Xfoo distribution. If so, edit the Xfoo.ad file to customize it for your machine, then rename (mv) it Xfoo and install it in the /usr/lib/X11/app-defaults directory, as root. Failure to do this may cause the software to behave strangely or even refuse to run. Most software packages come with one or more preformatted man pages. As root, copy the Xfoo.man file to the appropriate /usr/man, /usr/local/man, or /usr/X11R6/man directory (man1 - man9), and rename it accordingly. For example, if Xfoo.man ends up in /usr/man/man4, it should be renamed Xfoo.4 (mv Xfoo.man Xfoo.4). By convention, user commands go in man1, games in man6, and administration packages in man8 (see the man docs for more details). Of course, you may deviate from this on your own system, if you like. A few packages will not install the binaries in the appropriate system directories, that is, they are missing the install option in the Makefile. Should this be the case, you can install the binaries manually by copying the binaries to the appropriate system directory, /usr/bin, /usr/local/bin or /usr/X11R6/bin, as root, of course. Note that /usr/local/bin is the preferred directory for binaries that are not part of the Linux distribution's base install. Some or all of the above procedures should, in most cases, be handled automatically by a make install, and possibly a make install.man or make install_man. If so, the README or INSTALL doc file will specify this.  NextPreviousContentsNextPreviousContents  9. First Example: Xscrabble Matt Chapman's Xscrabble seemed like a program that would be interesting to have, since I happen to be an avid ScrabbleTM player. I downloaded it, uncompressed it, and built it following the procedure in the README file: xmkmf make Makefiles make includes make  Of course it did not work...  8. Final Steps  28   Building and Installing Software Packages for Linux gcc -o xscrab -O2 -O -L/usr/X11R6/lib init.o xinit.o misc.o moves.o cmove.o main.o xutils.o mess.o popup.o widgets.o display.o user.o CircPerc.o -lXaw -lXmu -lXExExt -lXext -lX11 -lXt -lSM -lICE -lXExExt -lXext -lX11 -lXpm -L../Xc -lXc BarGraf.o(.text+0xe7): BarGraf.o(.text+0x29a): BarGraf.o(.text+0x2ff): BarGraf.o(.text+0x375): BarGraf.o(.text+0x3e7): etc. etc. etc... undefined undefined undefined undefined undefined reference reference reference reference reference to to to to to `XtAddConverter' `XSetClipMask' `XSetClipRectangles' `XDrawString' `XDrawLine'  I enquired about this in the comp.os.linux.x newsgroup, and someone kindly pointed out that apparently the Xt, Xaw, Xmu, and X11 libs were not being found at the link stage. Hmmm... There were two main Makefiles, and the one in the src directory caught my interest. One line in the Makefile defined LOCAL_LIBS as: LOCAL_LIBS = $(XAWLIB) $(XMULIB) $(XTOOLLIB) $(XLIB) Here were references to the libs not being found by the linker. Looking for the next reference to LOCAL_LIBS, I saw on line 495 of that Makefile: $(CCLINK) -o $@ $(LDOPTIONS) $(OBJS) $(LOCAL_LIBS) $(LDLIBS) $(EXTRA_LOAD_FLAGS)  Now what were these LDLIBS? LDLIBS = $(LDPOSTLIB) $(THREADS_LIBS) $(SYS_LIBRARIES) $(EXTRA_LIBRARIES)  The SYS_LIBRARIES were: SYS_LIBRARIES = -lXpm -L../Xc -lXc  Yes! Here were the missing libraries. Possibly the linker needed to see the LDLIBS before the LOCAL_LIBS... So, the first thing to try was to modify the Makefile by transposing the $(LOCAL_LIBS) and $(LDLIBS) on line 495, so it would now read: $(CCLINK) -o $@ $(LDOPTIONS) $(OBJS) $(LDLIBS) $(LOCAL_LIBS) $(EXTRA_LOAD_FLAGS) ^^^^^^^^^^^^^^^^^^^^^^^  I tried running make again with the above change, and lo and behold, it worked this time. Of course, Xscrabble still needed some fine tuning and twiddling, such as renaming the dictionary and commenting out some assert statements in one of the source files, but since then it has provided me with many hours of 8. Final Steps 29   Building and Installing Software Packages for Linux pleasure.  [Note that a newer version of Xscrabble is now available in rpm format, and this installs without problems.]  You may e-mail Matt Chapman, and download Xscrabble from his home page.  Scrabble is a registered trademark of the Milton Bradley Co., Inc.  NextPreviousContents  8. Final Steps  30"
GX059-95-1313711	"Copyright © 1997 Specialized Systems Consultants, Inc.   For information regarding copying and distribution of this material see the  Copying License .              Welcome to Linux Gazette!       Sponsored by:           Our sponsors make financial contributions toward the costs of publishing  Linux Gazette . If you would like to become a sponsor of  LG , e-mail us at  sponsor@ssc.com .            Table of Contents Issue #16                The Front Page    The MailBag      Help Wanted -- Article Ideas   General Mail     More 2 Cent Tips     Checking if You're Boot   XV vs Xli   Bash Shell Scripting     News Bytes       News in General   Software Announcements     The Answer Guy , by James T. Dennis    SATAN URL Correction   EDI on Linux   zmodem   Running the Internet with Linux   Respawning Too Fast   Problems with Keyboard Mapping   Modem Speed   Duplicating a Linux Installed Hard Drive   Using Linux Box as a Firewall     A brief Introduction to the kunf Library , by Marc Welz  Clueless at the Prompt: A Column for New Users , by Mike List  CeBit'97, March 13-19 , by Belinda Frazier  Dynamic IP Web Solution Using Geocities Web Account , by Henry H. Lu  Graphics Muse , by Michael J. Hammel  LGEI Interviews the LG Editor , by Francesco De Carlo  More Linux Security , by Andrew Berkheimer  New Release Reviews , by Larry Ayers    An Alternate to Ghostview   XEmacs 19.15     SuSE Linux Installation & Getting Started , by Larry Ayers  UniForum'97 March 12-14  by Marjorie L. Richardson  Weekend Mechanic , by John M. Fisk  The Back Page      About This Month's Authors   Not Linux                                 The Answer Guy                    Weekend Mechanic                   TWDT 1 (text)   TWDT 2 (HTML)  are files containing the entire issue: one in text format, one in HTML.  They are provided  strictly as a way to save the contents as one file for later printing in the format of your choice;  there is no guarantee of working links in the HTML version.          Got any  great  ideas for improvements!  Send your  comments, criticisms, suggestions and ideas.     This page written and maintained by the Editor of  Linux Gazette ,   gazette@ssc.com        ""Linux Gazette... making Linux just a little more fun! ""             The Mailbag!    Write the Gazette at   gazette@ssc.com     Contents:     Help Wanted -- Article Ideas                  Help Wanted -- Article Ideas    Date: Tue, 25 Mar 1997 16:32:30 -0600 Subject:   great         From: Francisco Benavides,   >txmfrbg@txm.ericsson.se      The work being done with the LG is great!  As for ideas, taking into  account that most known applications are those which are for the PCs   ( DOS based or Windog based ) why not a section dedicated to those  ( like me ) that wish that soon we will get a Linuz that will be  filesystem wise, a Linux wich will run DOS applications without having to distinguish from those meant for Linux/Unix, and things like that.    -- Bye/Francisco :)             Date: Wed, 05 Mar 97 11:24:23 -0500    Subject:   Request     From: Bill R. Williams,   brw@etsu-tn.edu     Actually, this is more a request than a ""Letter to the Editor""; however,  you may use it as/if you see fit.    A fundamental element of security is the use of ""shadow"" passwords.   Linux (and some commercial un*x!) systems do not necessarily include  this feature by default.  (I have thus far always used Slackware and it  does not install with the Shadow Password Suite (SPS) configured.)    I consider SPS absolutely essential to any un*x (Linux) system which is  accessable by users.  In other words:  No, I don't need it on my home  Linux because that system is not connected to a network and I'm the only  one using it.  While there are worse things than having to install the  SPS it is a task that I really dread.  Makes me very nervous.    So here's a question for those of you who have evaluated the various  Linux distributions:  Do any of the distributions provide Linux with the  SPS installed and all the appropriate utilities and other pre-built  packages built against the SPS?  (Such as sudo and wu-ftpd.)    A related question which is not immediately obvious:  Using a given  distribution -- Red Hat or Debian or whatever -- are there any potential  hazards in bringing in packages which may not be part of that  distribution?  Since I have no experience with anything other than  Slackware I do not know what is involved in the packaging software used  by other vendors; however, I am aware that some vendors do have  utilities which can track the levels of various components.  If I were  to install some software package which might not be part of the  ""installed"" distribution what is the probability that I will ""step on""  the original installation's package tracking?  As a trivial example:   Suppose I want to install 'Doom' from my old Slackware CD-ROM onto my  ""Miranda v0.01"" distribution of Linux.  Am I going to have a problem  over this when I go to update my ""Miranda"" with a new release?  (Linus  had a new ""Miranda"" in January!  See, it could happen.  ;-)    And on an entirely different subject... There has GOT to be, somewhere, a utility which can be used to CORRECTLY  configure the monitor settings for XFree!  I have tried.  I really have.   Every time I come across an item on this subject I read and study it,  but no matter how hard I try I can't seem to get it through my thick  head as to what's what.  The supplied servers can figure out the video  cards with no problem, but then there's the stuff dealing with the  monitor and refresh rates and Hz and KHz and bandwidth and dot clocks  and... this is where I lose it completely.  Something with heuristic  abilities which would allow me to just type in everything in my  monitor's manual which the program would parse out into the significant  lines for the XF86config file such than when I start X I have *no* modes  which cause the output to skew off to the side and thereby causing me to  worry that I've fried the tube.  (*sigh*)   I have the new X (v3.4?) with the graphic setup utility.  Better.   But there are *still* modes which are frightening to see.  ""...push down  one place it just bubbles up somewhere else.""    Comments, articles, and/or suggestions on all the above from the fine  folks at ""Linux Journal"" and the readers thereof will be much  appreciated!    Bill R. Williams                Date: Sat, 01 Mar 1997 20:49:13 -0800    Subject:   X Windows Depth...Linear Addressing Problem.      From: Nicky Wilson,  benson@znet.com      After fiddling with the xf86config file in a concerted effort to coax X into displaying 16 bit color, I was dismayed to learn that with my current hardware (16 megs RAM and a Cirrus Logic GL-5426) 16 bit color is *impossible*...not because of any hardware  incapability, but because of a certain limitation of X Windows  itself...a problem with linear addressing.  Seems that to have 16 bit color under X, one must have linear addressing enabled,  which only works if the system has *no more than 14 megs RAM*.    (*blink*)    So I'm just two megs from the 16 bit color I so took for granted under Win95.  I can't even pull out two megs (downgrading my  system to work under Linux?!) because of my one 16 meg memory chip.    There has *got* to be a way.  I was hoping to work on my graphics stuff under Linux, but 256 colors just doesn't cut it.    Does anyone at Linux Gazette have a solution?  I heard something about making a two meg ""memory hole"" (?), or a program that fools  the system into thinking that there's less RAM than there actually  is.  Any ideas?  (I wonder if the X development team are working on this problem?)    Thanks for any input.         Your Friendly Local Neighborhood Novice,    Nicky             Date: Sat, 15 Mar 1997 03:41:04 GMT    Subject:   Soundcard under Linux      From: L Hatch,  tn00607@ibm.net     After recompiling my kernel I managed to get my soundcard working under Linux ... the only problem is that I have to boot into dos first to set up the card ... the card is softset through my autoexec bat ... its an ESS Audiodrive .. any suggestions    Another question as well ... I want to connect two machines together using a modem dialup connection .. I want to be able to dial from a standard comm prg under dos, win, win95, etc and turn control of the terminal over to the person on the  other end so that they can use a linux shell in their comm prg ... managed to do it under dos by getting a mdm connection and then doing a ctty com2: at the command prompt to turn control over to them ... they would get a C:> and be able to enter commands, and get the output in their comm prg ... any suggestions of how to do it under linux thanks             Date: Mon, 17 Mar 1997 15:11:45 -0800    Subject:   Stupid question      From: Steve Arnold,  sarnold@rain.org     Howdy:  I just searched your site looking for an answer, but failing  that, I'll just ask directly:    What the heck is the screen-blanker that runs under the console by  default (ie, what is the name, where is it started, etc)?    In the old RedHat 2.1 (kernel 1.2.13) it was disabled after X starts, but  in the new Redhat 4.0 (kernel 2.0.28) it still kicks in under X, even  when running xlock or something similar.    What binary and what switch do I throw to disable the console  screen-blanker under X?    Thanks in advance, Steve Arnold             Date: Sun, 23 Mar 1997 11:55:35 -0500 (EST)   Subject:   Linux Question      From: Peter Pereira Stamford,   stamford@bme.unc.edu      Hi, I am a gazette reader and have a question that might be of interest to others too.  It's a mixture of hardware + software problem.  Before I sent this mail I did a quick overview of all the gazette's table of contents and Linux How-To's.  I didn't find any help in these two places.  If this is a common question and I missed it please forgive me.    With the spread of different systems, many can end up owning several small monitors.  Instead of acquiring a new, bigger, more expensive,  monitor one can use two monitors that can work as one big screen.     I am trying to install a second monitor to effectively get this  bigger screen, since I have an extra monitor and card.  I'm not trying to display the same image on both monitors.  It is my understanding that MetroX (comes with my redhat version) permits me to have X divided into multiple virtual screens (forgive the lack of the official technical terms) and view two X virtual screens side by side on separate the monitors (I'm sure others Xservers do the same).  Thus I can have different applications opened in each virtual screen avoiding clutering.  (I'm tring to be precise because I have tried to get info before and was missunderstood).    My work place has an extra monitor and video card that I am  willing to take advantage of.  But currently when I have both video cards installed, I can't BOOT.  I have been told that this is because only one of the video BIOS is accepted by ROM BIOS, requiring the second video BIOS to be turned off. My cards don't have this option (I don't think). Others told me that it is a setting on the mother board.     The software configuration of Metro-X for this seems easy and intuitive, but how do I set up the hardware?  Maybe an explanation on X86Free on this would be good, but my problem is setting up the hardware.   Could you please help?   If I need a special card is there a recommended one?    Thanks for any help, Peter.                   General Mail               Date: Tue, 04 Mar 1997 20:02:22 -0500    Subject:   broken issue14      From: Pinwu Xu,  pxu@perigee.net      Hi there,       It's true that the issue14.html was broken. But one can fix it using the  Netscape editor (or save/print directly from the editor). That  works for me.         Thanks for your excellent work.    -- Pinwu Xu             Date: Wed, 05 Mar 1997 18:39:17 -0800    Subject:   thanks      From: arne,  asnow@cdepot.net         Just a note to say thanks for your work on the Linux Gazette. I'm a brand new Linux user and I have found the articles geared toward the new user invaluable. Thanks again.    Arne, Rocky Road Ranch             Date: Sun, 09 Mar 1997 16:08:06 -0500    Subject:   Love the service      From: Thomas L. Gossard,   tgossard@ix.netcom.com      I've been using Linux for aprox. 2 years now and have been a subscriber to ""Linux Journal"" for about a year of that.  I like what you have even better.  I love the 2 cent section, has great tips and ideas.  If you sold this as a magazine on the news stands or subscription I would be an avid buyer.  As it is I've got this link at the top of my bookmarks.  Keep up the great job.    Thomas L. Gossard             Date: Sun, 09 Mar 1997 01:19:54 -0600   Subject:   Netscape      From: Anthony Scott,   ascott@Interaccess.com     Could you please tell me where Netscape for Linux is located....How much does is cost.    thx, tony (You can download it free from Netscape's home page. --Ed.)              Date: Sat, 8 Mar 1997 18:25:28    Subject:   Thanks      From: Lance A. DeVooght,   devooght@flash.net      Just a note of gratitude for all your hard work in producing the BEST online magazine! Also, kudos to the sponsor, Infomagic. Rest assured I won't forget them next time I'm going to make a software purchase. And finally, I am very impressed with the fine writers you've assembled.     In Your Debt,      Lance DeVooght             Date: Thu, 20 Mar 1997 11:01:23 +0100 (GMT+0100)    Subject:   Good non-fiction book! The Cuckoo's egg     From: Tomas Brostroem,  tbc@rcc.se      A nice book that should interest all Linux-fans. ""The cuckoo's egg"" by Cliff (Clifford) Stoll.    Computer-security at it's worst.    I.m.h.o. the best non-fiction book I've ever read.    Regards, Tomas            Published in Linux Gazette Issue 16, April 1997                     This page written and maintained by the Editor of  Linux Gazette ,  gazette@ssc.com   Copyright © 1997 Specialized Systems Consultants, Inc.                ""Linux Gazette... making Linux just a little more fun!  ""                More 2¢ Tips!    Send Linux Tips and Tricks to   gazette@ssc.com       Contents:     How to ftp Back Home   Checking if You're Boot   XV vs Xli   Bash Shell Scripting      Bash Shell Script 1      Bash Shell Script 2      Bash Shell Script 3                   How to ftp Back Home     Date:Sat Mar 30 14:23:24 (PST)  From:Phil Hughes phil@ssc.com    Many businesses place a firewall between the Internet and the inside systems. This is good protection and it just makes good sense. One common firewalling technique is to serverly restrict access through the firewall from the outside but allow a user on the inside to do most anything through the firewall to the outside.   When I am at home, I routinely need to move files between home and work. But, because of the firewall, I can ftp from work to home but not the other way around. What this means is that I need to establish an interactive connection (using ssh) from home to work and then initiate the ftp from work to home.   So far, so good. But, what I call ""home"" consists of various locations, all connected with a dial-up connection through one of four ISPs. All four ISPs use dynamic IP addresses meaning that each time I connect I have a different IP address for my home system. Even though the ISP knows what the current IP address for my system, the name server at work doesn't.   The solution is to enter the IP address of my home system into the ftp command at work. First, I need to find out what the IP address is. To do that, I execute the ifconfig command on my home system:   $ /sbin/ifconfig  lo        Link encap:Local Loopback             inet addr:127.0.0.1  Bcast:127.255.255.255  Mask:255.0.0.0           UP BROADCAST LOOPBACK RUNNING  MTU:2000  Metric:1           RX packets:19 errors:0 dropped:0 overruns:0           TX packets:19 errors:0 dropped:0 overruns:0  eth0      Link encap:10Mbps Ethernet  HWaddr 02:60:8C:8F:A2:08           inet addr:198.186.207.131  Bcast:198.186.207.255  Mask:255.255.255.0           UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1           RX packets:969719 errors:0 dropped:0 overruns:0           TX packets:971132 errors:0 dropped:0 overruns:0           Interrupt:9 Base address:0x280 Memory:d8000-da000   ppp0      Link encap:Point-Point Protocol             inet addr:206.125.79.118  P-t-P:204.157.220.30  Mask:255.255.255.0           UP POINTOPOINT RUNNING  MTU:296  Metric:1           RX packets:5434 errors:0 dropped:0 overruns:0           TX packets:5545 errors:0 dropped:0 overruns:0 $    The inet addr for the ppp0 interface (206.125.79.118) is the number I need. Now, on my system at work I enter:   $ ftp 206.125.79.118    ftp then prompts for a login and password. I enter my standard login and password for my home system and ftp is up and running.                   Checking if You're Root      Date: Sun Mar 23 23:20:51 1997 (PST)   From: Kevin Lyda  kevin@faxint.com         In the march gazette raul miller suggested that the most portable way to test if you're root is [ -w / ].  that won't work if you're root file system is read only.  [ -w /var ] might be a better method.   kevin                XV vs Xli      Date:Wed Mar 5 16:32:49 1997(PST)   From:Michael Hammel,  mjhammel@emass.com     I wasn't aware of Xli (rather, I haven't looked at it), however your statement that xv can only tile image on the background.  xv  allows qutie a bit of command line control.  I use the following to put up a background image at work (non-tiled, takes up the whole background):   xv -root -max -quit /export/home/mjhammel/lib/images/emass3.tga    The initial image is 601x339, with a root display of 1152x900.  Since the original image is 24bpp the enlargement is very accurate in  details.    Michael J. Hammel                Bash Shell Scripting      Date:Thu Mar 20 12:22;34 1997(PST)   From:Paul Sephton   paul@inet.co.ca     I have been enjoying the fruits of the Linux Gazette for a number of years now.  Recently, I had one of my users accidentally type rm *>bak, and immediately noticed something was amiss by the incoherent screams eminating from her office.   In an attempt to ensure this would not have the same disasterous effect again, and to protect my eardrums in future, I spent a couple of days excersising my bash shell scripting skills, and came up with what I believe to be a decent mechanism for maintaining versioned backups.   My attitude with regard to the normal cludges like aliasing rm and so on, is that it will not protect you against other programs which unlink files. (To date I have yet to write a C program that shells rm in order to unlink a file :)   Whilst writing the set of three scripts, it dawned on me that although some more complex tools do exist which perform the same sort of function, the Linux community might be interested in what I did.     Although it's not much more than a creative excersise in the use of the 'find' command, and suffers from the usual limitation of being restricted to the one file system, I include the three scripts for your perusal and possible inclusion in the gazette at your discretion.   Don't hesitate to contact me if you need more information.   Kind regards, and many thanks for the gazette.   Paul Sephton              Bash Shell Script 1     #!/bin/sh if [ -z ""$SAFEDEL"" ];then SAFEDEL=/u/safedel fi    NDAYS=5                        #Erase files after 2 days MAXVER=6                       # Start Overwriting versins at this count BINDIR=$SAFEDEL/bin            # Binaries directory DATADIR=$SAFEDEL/data          # Where links are to go LOGFILE=$BINDIR/safedel.log    # Output messages go here ERRLOG=$BINDIR/safedel.err     # Error output messages go here DIRLIST=$BINDIR/safedel.dirs   # List of directories found here LOCKFILE=$BINDIR/safedel.lock  # Lockfile to prevent re-entry  #  Process the file $1 by creating a symbolic link in the data directory #  and an entry for the file in the index. process-file() { SRC=`dirname $1` FNAME=`basename $1` VERSION=0 if [ ! -d $DATADIR$SRC ]; then mkdir -p $DATADIR$SRC #  OWNER=`find -name $SRC -printf ""%u""` #  chown $OWNER $FNAME:$VERSION fi   cd $DATADIR$SRC   while [ -f $FNAME:$VERSION ]; do   VERSION=$[ $VERSION + 1 ]   done   if ! ln $1 $FNAME:$VERSION 2>> $LOGFILE; then echo ""Could not link file $FNAME:$VERSION"" >> $LOGFILE     return fi  echo -e ""Linked $FNAME:$VERSION \t \tin $SRC"" >> $LOGFILE return }   # Erase a file erase-file() {   echo ""Unlinking $1 $2"" >> $LOGFILE   rm -f $1   FN=`echo $1 | cut -f 1 -d ':'` if ! { echo ""$ERASED"" | grep ""$FN"" - } ; then     ERASED=""$ERASED $FN""   fi    return } # We want the version numbers to follow on each other, so that the next # file we create gets a bigger version number. This makes sure they follow. reorganise() {   if [ -z $1 ]; then     return   fi   FN=$1   FILE_LIST=`ls $FN:* | sort -n -t: -k2`   if [ ""$FILE_LIST"" = "":*"" ]; then     echo ""All [$FN:*] files erased"" >> $LOGFILE     return   fi   echo -e ""File list to be moved is:\n$FILE_LIST"" >>$LOGFILE   VERSION=0   for FNAME in $FILE_LIST; do     if [ ""$FNAME"" != ""$FN:$VERSION"" ]; then       echo ""Moving $FNAME $FN:$VERSION"" >>$LOGFILE       mv $FNAME ""$FN:$VERSION""       VERSION=$[ $VERSION + 1 ]     fi   done }  # The main shell script starts here...  cd $BINDIR if [ -f $LOCKFILE ]; then   exit 0 fi touch $LOCKFILE date >> $LOGFILE cat $DIRLIST | (   while read SRC ; do     if [ `echo $SRC | cut -b 1` != ""#"" ]; then       echo ""Finding files in $SRC"" >> $LOGFILE       echo ""Point 1 ($SRC)""       for FNAME in `find $SRC -type f -xdev -links 1 -print`; do         process-file $FNAME       done     fi   done   ERASED=""""   echo ""Point 2""   for FNAME in `find $DATADIR -type f -links 1 -ctime $NDAYS -print`; do     erase-file $FNAME ""(older than $NDAYS days)""   done   echo ""Point 3""   for FNAME in `find $DATADIR -type f -name ""*:$MAXVER"" -print`; do     FN=`echo $FNAME | cut -f 1 -d ':'`     erase-file $FN:0 ""Too many versions (VERSION > $MAXVER)""   done   echo ""Point 4""   for FNAME in ""$ERASED""; do     reorganise $FNAME   done ) 2> $ERRLOG > /dev/null rm -f $LOCKFILE                 Bash Shell Script 2        #!/bin/sh CURRDIR=`pwd`/ if [ -z $SAFEDEL ]; then   SAFEDEL=/u/safedel fi  DATADIR=$SAFEDEL/data BINDIR=$SAFEDEL/bin cd $DATADIR$CURRDIR if [ -z ""$1"" ]; then   echo   echo ""Restores files unintentionally deleted""   echo   echo ""Useage <salvage <filename>[:version] [dest]> from within the directory""   echo ""       in which the file was deleted.""   echo   echo ""The following is a list of your backed up files and their versions:""   echo ""  Salvageable Files:""   find . -xdev -type f -maxdepth 1 -links 1 -printf ""%P\n"" | column    echo ""  Files Currently in Use:""   find . -xdev -type f -maxdepth 1 -not -links 1 -printf ""%P\n"" | column  else   FN=`echo ""$1:end"" | cut -f 1 -d ':'`   VER=`echo ""$1:end"" | cut -f 2 -d ':'`   EXIST=`find $CURRDIR -name ""$FN""` #  echo ""[$EXIST]""   if [ -n ""$EXIST"" ]; then     echo ""Incorrect file specification: File(s) are not deleted. ($FN)""     exit 0   fi   if [ ""$VER"" = ""end"" -o ""$VER"" = ""*"" ]; then     VER=""""   fi   FILE_LIST=`find . -name ""$FN:*"" -printf ""%f ""`   FLIST="""" #  echo ""FILE_LIST is $FILE_LIST""   for FNAME in $FILE_LIST; do     FN=`echo ""$FNAME:end"" | cut -f 1 -d ':'`     FOUND=0 #    echo ""Looking for [$FN] in [$FLIST]""     for F in $FLIST; do       if [ ""$F"" = ""$FN"" ]; then         FOUND=1       fi     done     if [ ""$FOUND"" = ""0"" ]; then       FLIST=""$FLIST $FN""     fi   done #  echo ""FLIST is $FLIST""   for FNAME in $FLIST; do     if [ -z ""$VER"" ]; then       VERSION=0       NEXTVER=1       while [ -f $FNAME:$NEXTVER ]; do         VERSION=$NEXTVER         NEXTVER=$[ $NEXTVER + 1 ]       done     else       VERSION=$VER     fi      if [ ! -f $FNAME:$VERSION ]; then        echo ""File $FNAME:$VERSION not found""       exit 0     fi      if [ -z ""$2"" ]; then       DEST=$CURRDIR$FNAME     else       DEST=$CURRDIR$2     fi      if ln $FNAME:$VERSION $DEST 2> /dev/null; then       echo ""File $FNAME:$VERSION successfully recovered""     else       echo ""Cannot link $FNAME:$VERSION to $DEST""     fi   done fi                 Bash Shell Script 3        #!/bin/sh  if [ -z $SAFEDEL ]; then   SAFEDEL=/u/safedel fi  BINDIR=$SAFEDEL/bin            # Binaries directory DATADIR=$SAFEDEL/data          # Where links are to go  # Erase a file reorganise() {   if [ -z $1 ]; then     return   fi   FN=`echo ""$1:end"" | cut -f 1 -d ':'`   FILE_LIST=`ls $FN:* | sort -n -t: -k2`   if [ ""$FILE_LIST"" = "":*"" ]; then     echo ""All [$FN:*] files erased""      return   fi #  echo -e ""File list to be moved is:\n$FILE_LIST""    VERSION=0   for FNAME in $FILE_LIST; do     if [ ""$FNAME"" != ""$FN:$VERSION"" ]; then       echo ""Moving $FNAME $FN:$VERSION""        mv $FNAME ""$FN:$VERSION""       VERSION=$[ $VERSION + 1 ]     fi   done }  # The main shell script starts here...  CURRDIR=`pwd`/  echo ""Safedel: Purging extra versions in $CURRDIR""  cd $BINDIR find $DATADIR$CURRDIR -type f -maxdepth 1 -links 1 -exec rm {} \; for FNAME in `find $DATADIR$CURRDIR -type f -maxdepth 1 -print`; do   reorganise $FNAME done             Published in Linux Gazette Issue 16, April 1997                        This page maintained by the Assistant Editor of  Linux Gazette ,  gazette@ssc.com   Copyright © 1997 Specialized Systems Consultants, Inc.                ""Linux Gazette... making Linux just a little more fun! ""             Contents:     News in General   Software Announcements                 News in General                Hardware Forums in Dallas, Texas     Readers in the Dallas, Texas area may be interested in two forums for purchasing hardware that may not exist in other areas. The first is the North Texas PC Users Group meeting. This monthly meeting is held at the Infomart in Dallas (I-35E at Oak Lawn). The meeting is held on one Saturday a month and opens at 8:00 AM. A number of reputable local vendors show up to sell hardware and software. (In fact, a few months ago the vendor area was moved from the basement to a larger room because they were running out of space.) Prices at the NTPCUG meeting are generally cheaper than these vendors have in their own stores, and these vendors offer warranties and support as well. Call NTPCUG at ? to find out when the next meeting is. And stop by the local Linux User's Group booth and say hi, or ask them to load Linux on your newly purchased machine for free.   The other venue is truly unique. The First Saturday Sale is a monthly flea market held (surprise) on the first Saturday of every month. It is held outdoors under the Ross Street bridge. Take the Pearl Ave. exit to get there. Hang a left on Ross and follow the crowd. Selling officially starts at 6:00 AM, but feel free to show up earlier.   Again, many of the vendors own local storefronts and offer the same service and warranty their storefront customers receive.   While these markets may not be the best place for a beginner to shop, a knowledgeable buyer can walk away from either of these markets with a crate of new gear at significant discounts.     -Matthew Mucker    Bedford, Texas                COMDEX/Spring '97                       Come For          the Linux Pavilion at COMDEX/Spring '97                                     Linux International (LI) will be hosting a Linux Pavilion at   COMDEX/Spring '97, which runs from June 2 - 5 in Atlanta, GA.                                   On June 7 & 8, the weekend following COMDEX/Spring '97, LI and the Atlanta Linux Enthusiasts (ALE), in cooperation with COMDEX,  will be hosting the Atlanta Linux Showcase. The Atlanta Linux Showcase will feature vendors of Linux hardware, software, and services as well as conference sessions on various Linux topics.  Attendees of COMDEX will be admitted to the showcase floor for free, and pre-registrants to the Atlanta Linux Showcase will receive free passes to the COMDEX trade show floor.   Some of the vendors on the showcase floor are:     Red Hat Software, Inc.  Caldera, Inc.  Linux Journal (Specialized Systems Consultants, Inc.)  Linux Hardware Solutions  Digital Equipment Corporation    The Atlanta Linux Showcase will be held at the Inforum in downtown Atlanta, GA, just a few blocks away from the Georgia World Congress Center, site of COMDEX/Spring '97.  The show floor will be open from 9 a.m. to 5 p.m. on Saturday, June 7, and from 9 a.m. to 3 p.m. on Sunday, June 8.  The conference sessions will run concurrently.   The Inforum is located at 250 Williams St., Atlanta, GA.   More information on the Atlanta Linux Showcase can be found at    http:www.ale.org/showcase      More informaiton on COMDEX/Spring '97 can be found at    http://www.comdex.com/comdex/owa/event_home?v_event?id=26                  Announcing IT Horizon '97 Symposiom    The Fisher Center for Information Technology and Management, Walter A. Hass School of Business , UC Berkley announces:  IT Horizon '97 Symposiom, Workshop and Solutions Showcase   ""From the NC to the Networked Enterprise:   Thin Clients, Robust Servers, Universal Access""   June 9-11   Red Lion Hotel, San Jose, CA    Send you submission(s) by April 4, 1997 to Deborah Murray, Director-Professional Training, UniForum Association, 2901 Tasman Drive, Suite 205, Santa Clara, CA 95054 -OR- E-mail to   dmurray@uniforum.org                 Linus News      Linus Torvalds received Uniforum's ""Lifetime Achievement Award"" for his work on Linux.  Linus (as always) pointed out that he would accept the award, but that it really belonged to the entire Linux development community.  The award, which has been presented annually since 1983, recognizes individuals or groups whose work has significantly advanced the cause of open systems over time, or has had an immediate and positive impact on the industry with long term ramifications.  To give the idea of others who have received it, James Gosling also accepted an award at this meeting for his work on Java.  Linus was in good company.   You can see pictures of him receiving the award at:    http://daily.comdex.com/events/uf97/photos3.htm                HOWTO Update     A major update of the Linux Commercial HOWTO, a listing of commercial software products for Linux, has been published.  The new release includes new categories, descriptions of more software packages than ever and updates of existing entries.   The listing can be obtained from its primary site at   http://www.cyrius.com/tbm/Commercial-HOWTO  and from LDP mirrors all around the world.                Software Announcements                Announcing Decision PCCOM8    Announcing the availability of a Linux driver for the  Decision PCCOM8 multiport serial card.   Signum Support, a company specialising in free software support and Linux, was approached by MYDATA Automation AB, a Swedish robotics company, to write a Linux device driver for the Decision PCCOM8 multi-port serial card. The driver and was written by Christer Weinigel (wingel@signum.se) and Mikael Cardell (mc@signum.se). Any questions regarding this driver can be sent to   pccom8@signum.se               Announcing the Shuttle Connection (EPST)    Signum Support, a company specialising in free software support and Linux, was approached by MYDATA Automation AB, a Swedish robotics company, to write a Linux device driver for a parallel port SCSI interface.  This driver for the Shuttle Connection was written by Christer Weinigel wingel@signum.se  at Signum Support.  This driver can be found as  ftp://ftp.signum.se/pub/epst/epst-0.9.diff   The diff was made against a version 2.0.29 kernel.  This driver (probably)  still contains bugs and should be considered as ALPHA software.  Please note that there exists two incompatible devices, both which are called `Shuttle Connection'.  To find out what model you have, take a look at the sticker on the back of the device, you ought to see either `EPSA' or `EPST' written on it.  This driver is works with the EPST model; if you own an EPSA model, take a look at   http://www.torque.net/epsa.html  where you'll find a device driver for that device.   Any questions regarding this driver can be sent to    epst@signum.se                  New Release of mtools     Announcing a new release of mtools, a collection of utilities to access MS-DOS disks from Unix without mounting them.  Mtools-3.3 fixes a typo in mdel, which made it command unusuable.  Mtools supports Win'95 style long file names, OS/2 Xdf disks and 2m disks (store up to 1992k on a high density 3 1/2 disk).  The most notable new feature (over 3.1) is FAT 32 support. There is also mpartition, a simple partitioning programing to setup Zip and Jaz media on non-PC machines (SunOs, Solaris and HP/UX).   Mtools can currently be found at the following places:     http://linux.wauug.org/pub/knaff/mtools    http://www.club.innet.lu/~year.mtools     and soon at:     ftp://prep.ai.mit.edu/pub/gnu/mtools-3.3.src.tar.gz     ftp://pub/Linux/utils/disk-management/mtools-3.3.src.tar.gz   ftp://tsx-11.mit.edu/pub/linux/wources/usr.bin/mtools-3.3.src.tar.gz      There is an mtools mailing list at   mtools@linux.wauug.org .  To subscribe to it, send a message containing 'subscribe mtools' in its body to  majordomo@linux.wauug.org.              gv 2.9.4 Announcement      gv 2.9.4 is now available.  gv allows to view and navigate through PostScript and PDF documents on an X display by providing a user interface for the ghostscript interpreter. It may be obtained either from its homepage at:    http://wwwthep.physic.uni-mainz.de/~plass/gv/""   or via anonymous ftp from:      ftp://thep.physik.uni-mainz.de/pub/gv    Please note that gv is derived from Tim Theisen's ghostview 1.5.   gv surely works on           Linux (gcc 2.7.2.1)         OpenVMS AXP (DECC 5.2,DECC 5.0)        I also got reports of happy users on           Solaris         FreeBSD         NetBSD         Digital UNIX         SunOS         HP/UX         Irix         OSF/1     gv requires Kaleb Keithley's Xaw3d widget set.    VMS users will find everything needed to install this widget set at    the locations listed above.  For Unix users working on a system not equipped with this widget set    the page  http://wwwthep.physik.uni-mainz.de/~plass/gv/Xaw3d.html   may     provide some assistance when trying to install it.               SafePassage Web Proxy     Oakland, CA -- C2Net Software, Inc., and UK Web, Ltd., announced  the 1.0 release of a new product, ""SafePassage Web Proxy."" This product, developed entirely outside of the United States, provides full-strength, non-escrowed cryptography for users of any standard web browser.   SafePassage is an enhancement for ""export"" browsers, an add-on product that works with any standard web browser. Acting as an intermediary, or proxy, it intercepts weakly encrypted connections on their way out and transforms them to use full-strength cryptography.  ""The weak connection never leaves your PC,"" explains Parekh, ""it gets decrypted and then re-encrypted with a full-strength cipher.""   SafePassage provides secure connections using strong cryptography for any browser that supports standard SSL tunneling, a feature normally used by firewall software. It currently runs on Windows 3.1, Windows 95, and Windows NT.   Evaluation versions of SafePassage can be downloaded at no cost from UK Web's site at:  http://stronghold.ukweb.com/safepassage  It is currently unavailable for distribution within the US and Canada, but a domestic version will be made available in the near future. A single- user license is $49, prices for volume licensing start at $995 for fifty users.              Announcing Turbo Vision 0.3    Turbo Vision (or TV, for short) is a library that provides an application framework.  With TV you can write a beautiful object-oriented character-mode user interface in a short time.  TV is available in C++ and Pascal and is a product of Borland International. It was developed to run on MS-DOS systems, but today it is available for many other platforms (ported by independent programmers).  This port is based on the Borland 2.0 version with fixes.   Main changes from version 0.2 to 0.3    Added support for the FreeBSD operating system.  Added support for colored output.  evMouseAuto event fixed.  Some bugs fixed.    Where to download the library      ftp://sunsite.unc.edu/incoming/Linux/   ftp://ftp.cdrom.com/pub/FreeBSD/incoming/     If you don't want to wait the file to be moved to the destination directories, you can download a copy of it from:  ftp://ftp.cdrom.com/pub/FreeBSD/incoming/tvision-0.3.tar.gz               Announcing the Release of TeamWave Workplace 1.0     TeamWave Software Ltd. is pleased to announce the release of TeamWave Workplace 1.0, an Internet groupware product that lets you work  together with colleagues in real-time or asynchronously, using Macintosh, Windows or Unix platforms.  Check us out at  http://www.teamwave.com                Release of Samba SMB File Server    The release of Samba SMB File Server has been announced.  The server includes support for Western European Languages in filenames served by Samba, allowing Western European users of Microsoft Windows(tm) products to store native language filenames on their UNIX file servers.   Although this is a new minor version release, there have been many bugfixes and improvements from previous releases.    The new verson is available on a GNU gziped tar file from    ftp://samba.anu.edu.au/pub/samba/samba-1.9.16p11.tar.gz     and should be available from mirror sites throughout the world shortly. For details see the main Web site  for information about Samba, at :   http://samba.canberra.edu.au/pub/samba               Announcing UNIPEN-related Software Package     UPTOOLS3  This is to announce the new release of the UNIPEN-related  software package (works great on Linux, too):  This UNIX software is mainly intended for researchers in on-line handwriting recognition. It allows for a hierarchical annotation of on-line handwritten data coming from XY digitizers or pen computers. The software is _not_ intended for processing off-line (i.e., optically scanned) handwriting data.  The purpose of this software is to stimulate the use of the UNIPEN file format for on-line handwriting recognition research. This is the same data format as is used within the UNIPEN recognizer benchmark project  http://hwr.nici.kun.ml/unipen/      upview-An X-Windows program for quickly visualizing                UNIPEN files.  upread-A program for transforming or extracting data                from any UNIPEN file.   upworks-A large program using Tcl/Tk on X-Windows for                browsing through UNIPEN files, and editing or                entering .SEGMENTS. Time series of essential signals               can be viewed. There are many options for changing                graphical attributes (such as the color of segments).   uni2animgif-A program for transforming data from any UNIPEN                file into animated GIF images.  unipen2eps-A program for transforming data from any UNIPEN                file into encapsulated PostScript.    An introduction to UPTOOLS3 can be found at:   http://hwr.nici.kun.nl/uniopen/uptools3    The new software is available via ftp at:   ftp://ftp.nici.kun.nl:/pub/INIPEN/tools/uptools3.tar.gz               Announcing Ghostscript System 0.2.0       The Display Ghostscript System is a free software implementation of a Display PostScript(tm) System.  A Display PostScript System provides a device-independent imaging model for displaying information on a screen. The imaging model uses the PostScript language which has powerful graphics capabilities and frees the programmer from display-specific details like screen resolution and color issues.    The Display Ghostscript System is composed of a PostScript interpreter (Ghostscript), the Client library, and the pswrap translator.     The Display Ghostscript System uses a client/server architecture. Applications are linked with the Client library which communicates with the PostScript interpreter residing in the server.  The application utilizes the procedures and data structures in the Client library which are independent of the actual PostScript interpreter.      The pswrap translator allows you to take custom PostScript language programs and wrap them with a C function interface thus allowing your applications to call them directly.  pswrap programs are generally more efficient then performing the same PostScript program purely with the Client library procedures.   The dgs-0.2.0.tar.gz distribution file has been placed on  ftp://ftp.gnustep.org/pub/gnustep    The program requires gcc 2.7.2.1 or higher.   The `.tar' file is compressed with GNU gzip.  Gzip can be obtained by anonymous ftp at any of the GNU archive sites.   For info about FTP via email, send email to  ftpmail@decwrl.declcom  with no subject line, and two-line body with line one `help' and line two `quit'.   The most recent (not necessarily tested) snapshots of the library will be placed in  ftp://alpha.gnu.ai.mit.edu.gnu/gnustep               GA Plug-In for NExS Spreadsheet Available Now      X Engineering Software Systems (XESS Corp.) announces the immediate availability of a genetic algorithm (GA) plug-in for its NExS spreadsheet. Those interested in the genetic algorithm plug-in can download the source code and a PostScript manual from www.xess.com. A free, 30-day version of the NExS spreadsheet and the new conNExions-BETA API can also be downloaded for the HP/UX, AIX, Digital UNIX, SunOS, Solaris and Linux platforms.   Genetic algorithms (GA) solve optimization problems by modeling potential solutions as chromosomes which can breed with one another to produce better solutions through the forces of natural selection.   The GA plug-in provides one new NExS function: @GENALG(...) which optimizes a fitness function that is affected by a group of 1/0 variables in the sheet. Any NExS function or combination of functions can be used to specify the fitness function.   The GA plug-in interacts with the NExS spreadsheet through the conNExions-BETA API. The source code for the plug-in is being made available for modification and customization.              Annouunicing MkLinux DR2.1      We are pleased to announce the release of MkLinux DR2.1. DR2.1 includes support for the Power Macintosh 601/NuBus 601/PCI bus and 604/PCI bus systems: the Power Macintosh 6100, 7100, and 8100; 7200; 7500, 7600, 8200, 8500, and 9500.  (Support for 603-based systems is forthcoming but is not yet available.  DR2.1 does not yet support Powerbooks or most Performas at this time.)   DR2.1 is our third Developer Release of MkLinux and the first Release to be included in our Reference Release, published by Prime Time Freeware (PTF). The MkLinux Reference Release consists of a 360-page book and 2 CD-ROMs: the Apple MkLinux DR2.1 disc and PTF's Reference disc, packed with lots of interesting and useful reference material.  (The two CD-ROMs are each also sold separately.)   The MkLinux Reference Release is available by mail order from PTF and other vendors, and is also available through many technical bookstores, as are the individual discs.  Contact Prime Time Freeware for details at info@ptf.com or visit their Web site at www.ptf.com.   MkLinux is available both on CD-ROM and by anonymous ftp download from   ftp://ftp.mklinux.apple.com  and our various mirror sites. (Please be patient with the mirror sites; it may take some of them a while to get DR2.1 ready for downloading!).   With the release of DR2.1, DR2 will no longer be available or supported. We will retain the DR2 ""Help and Support"" information on our Web pages, but DR2 itself will be removed from our FTP server.    Check out the Web site at: http://www.mklinux.apple.com/DR2.1  for more information on this release.  All Readme files from the DR2.1 Distribution, including the Release Notes (Readme First) and the Installation Guide (How to Install MkLinux) are reproduced on our Web pages.              Metro-X 3.1.5 Now Shipping     Metro Link is now shipping Metro-X 3.1.5. This is an updated version of Metro-X 3.1.2 for Linux, which is a commercial X server replacement for use with XFree86. It contains various fixes and support for the following additional cards:         Diamond Stealth 64 Graphics 2200       Diamond Stealth 64 Video VRAM V1.xx (TI 3026 DAC)       Diamond Stealth 64 Video VRAM V3.xx (IBM DAC)       ELSA WINNER 1000TRIO/V (TRIO64V+)       ELSA Winner 2000AVI       ELSA Winner 2000PRO/X (TI 3026 DAC)       Number Nine I-128 series 2       Toshiba Tecra 720CDT (CHIPS 65550)    For a complete list of supported cards, see our cardlist:     http://www.metrolink.com/products/metrox/cardlist.html   For more details look at the complete product description:    http://www.metroling.com/products.metrox.ess.html    PRICE FOR LINUX VERSION:   New Purchase: $99    Upgrade from earlier release: $69     CONTACT INFORMATION:    Metro Link, Inc.  http://www.metrolink.com  and  sales@metrolink.com            Published in Linux Gazette Issue 16, April 1997                       This page written and maintained by the Assistant Editor of  Linux Gazette ,  gazette@ssc.com   Copyright © 1997 Specialized Systems Consultants, Inc.                ""Linux Gazette... making Linux just a little more fun! ""                   The Answer Guy        By James T. Dennis,  jimd@starshine.org   Starshine Technical Services,   http://www.starshine.org/           Contents:     SATAN URL Correction   EDI on Linux   zmodem   Running the Internet with Linux   Respawning Too Fast   Problems with Keyboard Mapping   Modem Speed   Duplicating a Linux Installed Hard Drive   Using Linux Box as a Firewall               SATAN URL Correction        From: Richard White,  whiter@digex.net  In the Linux Journal #14, you made reference to ftp.cs.perdue.edu...(grin) Doesn't exist. I think that it was supposed to be ftp.cs.purdue.edu.     -- Richard D. White, Business Connectivity Technical Support         Yes!  That was, of course, a typo.    But other than that -- did you find the info useful?         Yes. Very. I've just downloaded SATAN and a few of the other security tools. I work in customer service for leased lines and I occasionally assist customers in configuring their firewalls. Learning what holes there are and how to plug them is very worthwhile knowledge.         Have you tried cops (Dan Farmer's earlier host based  auditing package) or Tiger (Texas A&M University)?    Have you gotten tripwire running?  I (and most of the   rest of the Linux community that's tried it) had a   little trouble with Tripwire.  I had fussed it into  submission a number of months ago -- forgotten about  it.  Then recently I had to fetch and build a new   copy.      I encountered the same problems building it -- and the  same problems with the README.linux  I found myself   muttering that someone -- anyone -- ought to prepare  a proper set of patches that allow the Linux user to  just compile the thing with minimal effort.    Now I'm not a programmer (although I do ""play one   on the 'net"") so I really didn't feel qualified to   do this.  However I never have been able to inspire  or manage much of a volunteer effort in others so  I did it myself.    Creating a set of patches involved teaching myself  how to use CVS (version control system).  I'm thinking  of writing up an article on using CVS to track local  changes in downloaded source trees and cutting diffs  so you can share the work you do with others on the  net.    Naturally I'd use tripwire as one example --   probably pgp as another.  I'm also planning on   importing my kernel sources into CVS.    If your interested you could get my patch and let  me know if it works.  It's about 150 lines of text  that seems to work for me using Larry Wall's standard  'patch' program.   -- Jim             EDI On Linux        From: Adam Morrisom,   adam@morrison.iserv.net    I have just got management to permit me to install our first Linux box,  right next to our not-so-mighty RS/6000.  So far it has operated flawlessly (which is exactly what I expected).  And suddenly Linux is a possible solution for jst about every problem we have (they loved the price tag).  Now I have to implement EDI, and I was wondering if any software is available for Linux, I haven't been able to find anything, on the software map, sunsite or any where else. Any pointers or people to contact would be greatly appreciated.         Adam,         You certainly put in an good entry in Jim's  ""Stump the techie"" contest.    I've heard of EDI (electronic data interchange) and   vaguely recalled that it is a data format specification  for electronic commerce (mostly in the mainframe world  where X.25 predominates over TCP/IP).    However I haven't heard of any projects or products  being available specifically for Linux.    Here's a few web pages that I did dig up that might  help:     St. Paul Software Products - UNIX    Shad's Bookmark file    Premenos Technology Corporation       More About Electronic Data Interchange (EDI)    RFC Archives -- RFC1767 (link dead 2-Apr-2001: article removed)   TSI International    1994 EDI-L (Electronic Data Interchange Issues)     Mailing List Archive: Re: PC based EDI    Uniforum: 1995 Index       I hope these help.  Basically it looks like there are   not ""shrinkwrap"" or ""off-the-shelf"" EDI packages for any  platform. Good luck.       One approach you may take is to contact the publishers   or authors of your existing EDI applications and see if   they can do the port for you.   -- Jim           zmodem        Help answer guy!  I cannot download from the net!  Here's the story:  - I run linux v2.0.0.  I am using minicom v1.71.  I have NOT touched my    file transfer protocols since I installed, so they would be the    default configs.       I hate debugging serial line problems.    Here's the basic litany for solving modem problems:    What happens at lower speeds?  What IRQ is this serial  line using?  What sort of UART is installed?   What are the flow control settings?  Does the cable  have conductors for all of the flow control signals?  How is the modem configured (hardware and init strings)?    minicom 1.71 is pretty old.  I have 1.75 here -- and  there may be even newer versions up on sunsite.    Incidentally -- you should probably upgrade to   Linux kernel version 2.0.29 or so.    Your problem may not be related to either of these  factors -- but it won't hurt to upgrade.    The first thing I'd check is Minicom's configuration  for init strings and flow control.  Try an init string  of:     AT&C1&D2       ... (which I remember from years of supporting    PCAnywhere as well as seeing it in my current   configuration).  These set the modem's behavior   for the DCD (device carrier detect) and flow control.   I don't remember which is which and what the other   numbers do -- look them up in your modem's manual if    you're curious).    Then make sure that minicom's ""Serial port setup""  specifies ""Hardware Flow Control"" is ""on.""    When having problems with serial lines and modems I  find it handy to get the digital equivalent of a   ""second opinion.""  -- Do you run any other comm  software on this system (pppd, uucp/cu, mgetty --  dial-in, seyon)?  Do those work reliably when transferring  data (putting the line under load)?    I'd suggest getting a copy of C-Kermit from Columbia   University  kermit.columbia.edu          .  No offense to   Miguel van Smoorenburg but minicom was having problems  on my system, too.  C-Kermit is doesn't have any of the   full screen, ncurses ""feel"" to it but does a good solid  job of talking to the modem.  It's scripting capabilities  are also far more advanced than minicom's 'runscript' --  and has features that would be to force 'minicom' to   do through an 'expect' script (for example).    Do you have another account on another system (BBS or  ISP)?  Do your file transfers work O.K. to or from   there?  The problem may be with your ISP rather than  at your end.    What if you try a different protocol -- such as  kermit?  Kermit is often characterized as ""slow""  compared to zmodem -- but this is largely because   it's default is tuned for the very noisy, unreliable   connections that were common when it was created  (almost 20 years ago).     After checking with another comm. program I'd look a   little lower.  Using the commands:     stty -a < /dev/modem       ... and      setserial -a /dev/modem      (both of these assuming you have a ""modem"" link to   the appropriate  /dev/ttyS*  entry on your system).    Make sure that your stty reports crtscts (for the   flow control).  Then make sure that the cable between  your computer and your modem has all those pins  connected.    Double check that you don't have an IRQ conflict.  These  are insidious in that they may not show up until the  port is under load.    In addition check to see that you have a high speed   UART (16550AFN) on that port.    Next I'd check the modem's configuration.  You can  see some of that with AT&V (which on many Hayes  modems dumps the configuration date and S-register  values to your terminal).  Look at the Init strings  that you are using in Minicom and look in the   modem manual for recommended init strings for similar  software.     After checking all of that I'd shutdown and boot  up in DOS (if you don't have a copy of DOS you can   consider downloading a copy of Caldera's OpenDOS.  I'm not sure what the licensing terms will be -- but  I did read that we're all invited to play with it for   90 days).  Along with a copy of DOS you also need  a Telix, Qmodem, Procomm, or other comm. package.  There are many of these in shareware -- Telix is my  personal favorite.    (Note:  I am not advocating use of these packages  without respect to their licenses.  If you choose to   continue to use Telix or OpenDOS -- even for the   occasional troubleshooting session; please read and   abide by their licensing and registration.  Yes,  I have fully legal copies of Telix (DOS and Windows)).    In any event I like to check from plain old DOS  since the old real mode program loader is so   minimal.  You could try building a Linux kernel   with no support for TCP/IP and stripping out all   of the device drivers except the serial and console   support and booting that in single user mode ... and   that still isn't close.    The idea is to see if any of your other devices or  hardware features are conflicting.        i am a best internet shell account, i believe iris but i don't   know the version.        I'm guessing that you mean that your account is at  best.com and that they are running Irix (SGI).  (Which is interesting -- since I would have guessed  Sun/Solaris for them -- but what do I know).    Note:  Irix and Solaris are not known for sterling  serial line support.  They are currently geared for  ethernet TCP/IP support -- on the assumption that   most sites will use terminal servers (small dedicate  devices that convert serial connections to telnet  sessions).  Consequently I've heard that the copies  of rz/sz that ship with these should routinely be   replace with newer sources from the 'net.       i have a usrobotics sportster 28.8 modem         Internal or external?   Personally I don't like the Sportster series.  Their Courier's are nice (but spendy).  I currently  use a Practical Peripherals -- but my next modem will  probably be a Zyxel.       I type sz <filename>      things go along fine until about 40k than i will get a couple of different     error messages:       BAD CRC:0       sometimes followed by another attempt at downloading    (usually only a bit or two) than the same error OR       GARBAGE COUNT EXCEEDED:0       followed by a time-out.  AARRGH!  what the heck is going on?  u can email me privately if you would  prefer, as this is probably a totally common problem and i am just not  looking in the right place!          My guess would that you don't have a high speed UART.  Or that your flow control isn't properly set.    The reason I guess this is that 40K is a reasonable  amound of data for the modem to get and buffer while  you system does a context switch.  The buffer overruns  (in a 16450 -- older, low-speed UART) could easily be  fatal to the transfer in the first context switch.    With the 16550 UART -- the UART has a 16 byte FIFO   buffer.  That's enough for the UART to change   the state on the handshaking lines (lowering the   CTR -- clear to receive -- line) and enough still  store the incoming data while the other system  responds (stops sending).    At 28.8Kbps coming into a 16450's (one byte!) buffer  the sender will have tossed a lot of bits out before   getting the message (that your system is dropping   them all on the floor).    I am copying this to the Linux Gazette *because* it  is a common problem.  Most of us in the real world  use modem -- we don't have T1's or ISDN/ethernet  bridges (actually I do have a Tracell WebRamp but   I'm not using it yet).  So we are still stuck fighting   with these problems.    I'm hoping that USB (IEEE 1394 ""Firewire"") actually   takes off in the next year.  It's been hanging in the   wings, timidly for about two years now and it's LONG   overdue.    Has anyone out there run a USB board under Linux?       For those who are lost about ""Firewire"" refer to:      USAR Systems -- Fireware Info     The IEEE-1394 High Performance Serial Bus  -- Adaptec's FAQ     IEEE 1394 Trade Assoc. -- Firewire, USB, serial bus      If you have any Linux news on this topic -- mail it to    tag@starshine.org .    --Jim            Running the Internet with Linux        From:Ricardo Romero   rromero@netfriendly.com   Hi, my name is Ricardo Ribeiro Romero and i live in Brazil, i try to run  INTERNET from linux but this not run, you may help-me?  Tks,     Romero, Ricardo         At the risk of seeming unfriendly, Romero, I'd have to  suggest that you might want to look for a local consultant  or computer specialist to help you.    Questions to a publication -- particularly a free publication  which is entirely supported by the volunteer efforts of the  writers and the generous sponsorship of SSC have to be   fairly specific and of reasonably broad interest.    Any reasonable distribution of Linux includes all of the  utilities you need to connect to the Internet as a client  and all of the utilities that most people would ever want  to be a service provider.      It is not clear from your message whether you are trying   to set your system up as a server/provider or as a client  or both.    There are several good books that go into broad coverage  of Networking with Linux (which is largely the same as   networking under other forms of Unix).  My personal favorite  would be the Linux Documentation Project's Network Administrator's  Guide (LDP NAG for short).  This is available electronically  (as text, postscript, TeX, or HTML) and is probably on any   set of CD's that you'd buy.  You can also purchase a professionally  bound and printed copy from O'Reilly & Associates (among others).    Along with that O'Reilly also publishes a book called something  like: ""Getting Connecting: Establishing a Presence on the Internet""   (That would be the ""Pig"" book) by Kevin Dowd).  If you're trying  to set yourself up as an ISP or if your want to have a   dedicated connection to the net (say for your office) than   this is probably what you want.    Personally I recommend that most small business and private  people avoid ""dedicated"" or ""permanent/full-time"" connections  to the 'net.  It's much less expensive to configure UUCP for   mail and news -- and look at virtual hosting and/or co-location  for serving up web pages and other services.  This can be   supplemented with demand dialed PPP (using scripts or diald)  to provide the web access -- over a modem or via ISDN.    One of the big benefits of ISDN is the lower latency.  A   modem connection takes about 30 seconds to 1 minute to  dial, ring, connect, and negotiate.  ISDN can do that in   about 3 seconds.  You'll be much less reluctant to hang  up and quit hogging your ISP's phone line if you know that  you can get back in about 3 seconds.    In addition to the lower expense running your site as a   disconnected network relieves you of quite a bit of the  security concerns associated with a full time net connection.  Sure -- your PPP link is inherently bi-directional (people  can connect back to your through it and attempt to exploit  the same services that they my attack on a fully connected  site).  However you'll be there to notice any additional  load or any anomalies -- and your whole site is considerably  less attractive to crackers anyway.    (People who connect their Linux systems to the 'net via PPP   really should take a 1 hr course on securing their hosts.  Maybe I'll crank out an article on that sometime).   Romero,    Back to your question.  Please try reading up about   these connections and/or consider hiring a local consultant.  I don't know anything about the phonesystems in Brazil --   and I get a little sketchy about ISP's if I get more than  about 200 miles inland from the Pacific Coast.      --Jim            Respawning too Fast        From: Igor Markov  imarkov@math.ucla.edu  My question is about the infamous ""Resapawning too fast"" message from init. This message appears in my /var/log/messages every 5 minutes (of course!) for xdm I'm just guessing that this is for ""The Answer Guy""   init: Id ""x"" respawning too fast: disabled for 5 minutes   However, xdm is running (I see it in ps output and I don't have problems using it).        You don't show the appropriate lines from your  your /etc/inittab but they should look something like:     # Run xdm in runlevel 5 (and 4 for me)   x:45:respawn:/usr/bin/X11/xdm -nodaemon    (Note: I run xdm in 4 and 5 which unusual -- but   4 is my custom default -- with 12 VCs, xdm in VC13  -- accessed by the right alt-key + F1 -- and syslog  output on VC 15, VC14 is used for stray open commands  or to redirect pesky output from backgrounded processes).    My guess would be that you don't have the -nodaemon  switch on yours. (Try adding it).     If I'm mistaken than the troubleshooting will be  more involved.  Check with the vendor for your  distribution of Linux and see if they have some   patches.      Red Hat users may want to look at:     http://www.redhat.com/support/docs/errata.html    ... to see what's been fixed since your CD was burned.     Also you may want to look in your xdm-config file  (/etc/X11/xdm/xdm-config -- if you're lucky -- otherwise  it could be in .... /usr/X11R6/....????).    The best introduction to xdm I've ever found was in  _The_Shell_Hacker's_Guide_to_X_and_Motif_ from John  Wiley & Sons.        It seems that init tries to spawn a second xdm.  I couldn't confirm or reject this hypothesis...    (egrep xdm /etc/* /etc/*/*  did not show anything promising)   Thank you         Respawning too fast indicates that the program  is exiting (pretty much immediately) and that init  figures that there must be some bad problem.  For  example if getty is respawning it may be that it's  attempt to grab the serial line is failing (like  there is no serial driver configured in your kernel  and you forgot to load the module -- or something like that).    If xdm is loading and forking off a daemon (it's default)  then this will look like an exit/failure to init.  The  -nodaemon will force xdm to run from the console in which  init started it (not try to ""background"" itself as it would  do if you ran it from a command line).    The fact that your copy is working suggests this -- but when   you log out of your xdm session you might have to way upto   five minutes for init to decide to try xdm again (unless  your xdm logout configuration is doing the respawning or  something weird).   --Jim            Problems with Keyboard Mapping        From: Gilbert R. Payson   g.payson@edina.xnc.com   Hello.  I have three (okay, four) linux machines in Germany.  My problem is this:  In Xwindows, my keyboard mapping is almost perfect.  But, there are a few problems:      @ doesn't work. It brings me to the last edited line (like an up-arrow) How can I fix this?      thanx!  -gil        I think you want to look at the xmodmap command.  You'll also want to look at the following HOW-TO   documents:     Keyboard HOWTO    Key Setup mini-HOWTO       --Jim           Modem Speed        From:Scott Atwood  atwood@cs.stanford.edu    I'd like to make a comment regarding a question from ""The Answer Guy""  column in issue 13 of Linux Gazette about combining modems to increase  speed.  This question reflects a common misconception of equating  bandwidth with speed.  Latency is a much more important measure of  percieved speed, especially in interactive applications, such as  telnet sessions, and web browsing.  Combining modems will increase  bandwidth, but latency will remain unaffected.  For a more complete  treatment of this subject, see:    http://rescomp.stanford.edu/~cheshire/rants/Latency.html  an essay by Stuart Cheshire, author of Bolo.          I finally got around to reading your article.  It was  very interesting.    I thought I had warned the reader that doubling his  bandwidth would only help on large, bulk transfers --  but perhaps I overlooked it.   --Jim            Duplicating a Linux Installed Hard Disk         I have installed slackware on my PC and I'm completely satisfied. I want  to duplicate my linux installed hard disk : Can I use my 1st hard disk  as a source and copy all of its contents to a 2nd blank linux-formated  hard disk? If I put this 2nd disk into another PC, it will boot Linux   normally?        You can just use the 'dd' (""disk dump"" or ""data dump"")  command on the raw devices.  This will work if the two drives  are identical with no bad sectors.    Many years ago I'd have said you were an idiot to even consider  it.  Now I'd recommend against in much milder language.    The difference is that modern drives -- IDE and SCSI are   capable of autotranslation (so the BIOS and often the   Unix/Linux disk drivers don't need to know the true  geometry of the disk.  Most drives these days also have   spare sectors on every track -- during a low level format   spares are mapped into use for any bad sector on a particular  track.  Using this scheme (which is normally completely   transparent to the host machine -- it's all in the drive's  electronics) it is rare to see any bad sectors on a drive  (until all the spares for a given track are used up).    So it is technical feasible to do this.    However I'd say that you're much safer to spend a little  more time and ""do it right.""    Use fdisk to partition the new drive (presumably to set its  partitions to match those on your first drive.  You can   do this without downing the system.  I personally prefer to  follow the advice and reboot after writing a new partition   table -- but that's probably a force of habit from too  many years of DOS and OS/2.    Then do a mke2fs -c /dev/hdbX  (where X is the partition  number) for each of these new partitions.    Then do a:       mount /dev/hdbX /mnt/tmp   find . -mount | cpio -pvum  /mnt/tmp      ... to each of them.    Now your are almost done.  The only problem is that  your lilo boot map (on your existing drive) probably  doesn't match the lilo configuration on the new one.    The most reliable way of dealing with that is to   take the new drive to the new system -- boot from a   rescue floppy  using the root=/dev/hdaX command  line parameters (on the lilo prompt line from the   rescue floppy) and edit the /etc/lilo.conf.  Then  run lilo and reboot.    That's all there is to it.  That's about seven steps  (with 3 of them being repeated for each filesystem on   the drive(s).  The amount of time this takes is dwarfed  by the actual task of opening your case and getting the  jumpers on the new drive working right (which is far worse  for IDE than most SCSI in my experience).    Why is this better?  Well it deals with bad blocks and  small difference in geometry.  It also ensures that the   new copy is defragmented.  Other than that -- it just   ""feels"" like a better way.     --Jim            Using the Linux Box as a Firewall        From: Tim Gray   timgray@lambdanet.com      Hi, I have a small problem that might affect others out there..  I am trying to get my linux box to act as a ""firewall"" of sorts for  my wife's Windows 95 computer. (I haven't been able to get her to   switch yet)  I installed ne2000 compatable boards in each, ran cable, installed   everything as per  per linux network administrators guide.  The problem I have is   getting Packets  destined for internet to go out the modem line when it's not connected.   I need a way to have linux automatically fire up my dial-up connection when   it sees that the remote computers want to use it. and possibly kill the   connection after a period of non use.     Thank you.  Tim        This arrangement is referred to a a ""Proxy"" server --  which is only a component of certain firewall architectures.    Specifically you appear to be trying to set up a ""dial on   demand Masquerading proxy host.""  (if I understand you  correctly).    The first tool you need for this is called 'diald' --  (the 'dial daemon').    The most recent version that I know of is at:      ftp://sunsite.unc.edu/pub/Linux/system/network/serial/    ... and is named:       diald-0.16.tar.gz      I just set this up (literally while this draft was  loaded in my mailer).  It was suprisingly easy.    Just edited the make file (just to change the   LIBDIR, BINDIR, etc directories to point at /usr/local/...)  did a make and a make install.  Then I created a file   named /etc/diald.conf with just the 'lock' directive in it.  I did this so I can more readily support multiple diald  configurations -- as I'll explain presently:    I created a /etc/diald/ directory and put in a   file like:    device /dev/modem connect ""chat -f /etc/ppp/connect"" speed 38400 modem defaultroute crtscts redial-timeout 120 connect-timeout 120 mode ppp dynamic local 192.168.1.1 remote 192.168.1.2 include /usr/lib/diald/standard.filter      Obviously yours will differ in a few spots.  the -f parameter to your connect line should point  to whatever chat script you use manually.  You might  change the device line -- although I highly recommend  that you consistently configure all of your packages to   use /dev/modem (which is just a symlink to the real  serical device on my system).      I currently have diald, pppd (manual), uucp, kermit,  minicom, and mgetty all sharing this modem and properly  using the same lock files throughout.    The local and remote addresses are apparently arbitrary --  I use addresses that are listed in RFC1918 (nee 1597)  which reserves several sets of addresses which the   IANA/InterNIC promise not to give out to ""real"" internet  sites.    Then added the following two lines to my /etc/rc.local:      modprobe slip   /usr/local/sbin/diald -f /etc/diald/rahul      (Where the rahul file is the one I've listed above and  refers to one of my PPP providers).        Once you have your system reliably dialing your provider  on demand -- the next step is to get routing working  from your wife's system to the internet.    I would recommend bringing up the ppp connection manually  and doing all the routing/masquerading/proxying configuration   and testing with the line ""nailed"" up.      --Jim             Copyright © 1997, James T. Dennis    Published in Issue 16 of the Linux Gazette April 1997                                ""Linux Gazette... making Linux just a little more fun! ""                  A Brief Introduction to the  kunf  Library   By Marc Welz,  mwelz@sar8.ee.uct.ac.za      Why ?  The kunf library is an attempt to set up a uniform way of accessing configuration data. Currently most large applications have their own configuration files - these files are likely to have a varying syntax and have no well-specified location. On the other hand small programs and scripts have no configuration files at all - they have values hard-coded  into them which sometimes can be overridden from the command line or through environment variables. This entire setup seems somewhat suboptimal - it can be quite daunting to the novice user.    The kunf library attempts change this - it tries to manage configuration data on behalf of the program or script. Instead of each application implementing its own resource file parser, an application calls a  set of library functions (in the case of a shell script that would be  a call to a utility program) which then return the configuration data.   Each piece of configuration data has a name (actually a sort of path)  which identifies it. This makes that data independent of any particular location or configuration file. Once an application requests a data item, the library looks up the value in a location transparent manner and  (optionally) performs a set of translations on the value. Then the value is returned to the calling code.   This approach should have the advantage that there is a consistent way of accessing configuration data - data for different applications can be modified with the same utility and the economics of scale  should make it possible to construct more sophisticated maintenance  tools that would be feasible for a single application. Novice  users would not need to have to learn the location of the resource files.      How ?  Once you have   downloaded , extracted ( tar -xzvf filename ) and installed (a  make ; make install  should suffice) the library, you should be able to make use of the shell and C interface without too much difficulty:   >From a shell script you can use the utility  kunfenv  to place a particular piece of configuration data into the environment. For example, the template configuration files contain an entry for the nntpserver variable which is stored as  news:nntp:nntpserver . A shell script can access that information with a statement like:   #!/bin/bash # evaluate the result of a call to kunfenv  eval `kunfenv news:nntp:nntpserver` # Now we have the variable as news_nntp_nntpserver echo ""My nntpserver is $news_nntp_nntpserver""      A C program can access the same data with the following piece of  code:   #include <kunf.h>   ...   char *str;   kunfig_open(NULL,KUNFIG_OPEN_STANDARD);      str=kunfig_findvalue(3,""news"",""nntp"",""nntpserver"");   printf(""My nntpserver is %s\n"",str);   kunfig_close();    Do not forget to link the program with the directive  -lkunf .   The configuration file editor can be used to modify the value of  news:nntp:nntpserver  entry. One simply invokes the editor by typing  kunfedit , navigates down to the nntpserver entry (select the  news  entry ...), modifies the value (hit the escape key to move off a field) and saves it (press escape several times - it will ask you if you want to save).      More ?  There exists a  web page  which contains more information on this library. You can also   ftp  the entire  package directly. The library is released under the GNU Copyleft.  You can contact the author at his  difficult-to-spam-address .            Copyright © 1997, Marc Welz    Published in Issue 16 of the Linux Gazette, April 1997                                      ""Linux Gazette... making Linux just a little more fun! ""                 CLUELESS at the Prompt: A Column for New Users   By Mike List,  troll@net-link.net              Welcome to installment 3 of Clueless at the Prompt:  A Column for New Users.       Thanks for the encouraging e-mail.In response to several requests, here is a little information to help you get your feet wet.      Multitasking     If you are familiar with that other windowing thing, you may be aware of  the concept of multitasking. Using a single computer to do several applications at once is a highly desireable trait of an OS.     It's fairly obvious how to accomplish this in a windowing environment, but not so obvious at the shell prompt.Here's some of the details.   When you start a program at the shell prompt, you can stop it by typing      Ctrl-Z   Whereupon you will be returned to the shell prompt. Then type:      bg   which will restart thet program or job in the (b)ack(g)round and allow you to run another job while that kernel ccompiles, without changing to a different VC. You probably know that you can change VCs by using the      Alt-F2   through F6. Each one of these can also be used in the manner that I have described, to the extent that you can run yourself out of resources in a  fit of deep hack mode euphoria if you aren't careful.If you get really exuberant you could even forget what all you have going. Relax, you can find them all by typing:      jobs   which will list all jobs running in the background, much like the       ps    command lists all processes that are using your precious memory and  CPU to a nub.    Mount      When you boot up linux your file system or rather your hard drive must be mounted, so that the file system can be read and acted on.Your floppy drive, tape backup, or CD-ROM may not be automatically mounted, so you  could have need of the mount utility.For instance:      mount -t ext2 /dev/fd0 /mnt  or  mount -t msdos /dev/fd0 /mnt   will mount your floppy drive that dos calls a: to a directory called /mnt from where you can access files on floppy disks. In the first example, the /mnt directory can be read in the ext2 filesystem, while the sescond reads floppies written in msdos format.To read the contents of the floppy drive, which is now /mnt you can type:      cd /mnt    then,      ls    or       less filename      In a similar manner, you can mount your other floppy drives, tape drives, CDROMs, or other read write devices.These devices can be unmounted using the       umount /dev/fd0  or /dev/whateveryoumounted   command.     Some timesavers....    Here are a few  tips that can make your linux life a little easier.   When you first logon to linux there are some commands that make use of optional switches,which you may not know or be sure of. You might make a typo in your command that you don't catch until after you hit enter. To try it again without retyping the whole command, just tap the up arrow key, which will bring back the previous command so that you can return to the scene of the crime and replace the mistyped or mistaken characters. In fact if you tap enter several times you can go back to what you did several commands previous.   To change back to a directory you have just left, or to scan subdirectories, you can use :      c -   in the following manner. change from your /home directory to the main  trunk directory:      cd /   then, to look at the top level of each directory, for instance:      cd usr   then:      ls   If you didn't find what you were looking for, just:      cd -   and you will find yourself at the trunk / again. Unfortunately you can only go one layer deep, but it is still useful when you install a source package and want to check out the contents of each of the subdirectories. Sometimes, atleast at first, you may not know how to stop a program or process that's running, but you are unwilling to let it slowly eat up your memory or CPU overhead. You can type:      ps  -a   to get a list of all running processes, make note of the pid (Process ID) number and type:      kill pidnumber      for instance   kill 2395   But there is an easier way. Browse through the LSM (Linux Software Map) for a utility , actually a nicety called die-1.1 . You can unpack this into a directory or use installpkg dopkg or what ever your single package installation utility is. Then look for the /die-1.1 and cd to it. It contains a couple of files, a source file,        die11.c   and a documentation file,      die.doc   Assuming that you installed the GCC compiler, just type:     gcc -o die die11.c   hit enter and presto you've compiled a utility called die.Just mv this to a directory in your path, and if you like, mv the die .doc to /usr/doc or somewhere it can be with its other help text friends( but not man pages  they'll pick on it unmercifully).Next time you're in a quandary about how to gun down a process just type:      die commandname   and it will do the deed. To find out more about die just type:      die   with no argument and it will give you a summary of the commands you can try the up arrow keys on  ; ) (this emoticon is the only one that doesn't make me nauseous)      Disclaimer  You have probaly noticed this column doesn't have as much content as the previous two, presumably since linux is really an easy OS to learn so  my curve isn't as steep, or maybe it's the fact that I have gone half crazy trying to install a DECvt220 to a serial port and it refuses to cooperate   I guess I made a mistake when I said I made a mistake about the mkdir command in DOS. Several people sent me mail that mkdir -md, rmdir-rd and a couple ohers are synonymous with linux commands. One fella told me he made symbolic links to several DOS commands so he can use them without  having to learn new but similar commands. Sick, but ingenious.      Next Time- Let me know what you would like to see in here and I'll try to oblige just e-mail troll@net-link.net   me and ask, otherwise I'll just write about what gave me trouble and how I got past it.    TTYL, Mike List                  Copyright © 1997, Mike List    Published in Issue 16 of the Linux Gazette, April 1997                                      ""Linux Gazette... making Linux just a little more fun! ""                 CeBit'97, March 13-19   By Belinda Frazier, Associate Publisher  Linux Journal            CeBIT Photo Album          CeBIT is the world's largest computer fair, bringing together vendors and attendees from many different countries.  If you picture landscaped fairgrounds with 27 halls for vendors and even more auxiliary buildings with stores and restaurants and then add 650,000 people to the picture, all visiting the location  over seven days, you are starting to get an image of CeBIT '97.  CeBIT took place in the Messegelande [umlaut over a] in Hannover, Germany, March 13th to 19th, 1997.    This was my first time attending CeBIT, and my goal was to look at the Linux vendors and possibly talk about Linux to vendors  whose software already ran under other Unix platforms. I also wanted to see what such a huge computer fair would be like and contrast it to the US's largest computer fair, Comdex, in Las Vegas, which I have attended the past seven years.   My first stop was Hall 11 to visit Caldera, Inc. Caldera's booth was easily recognizable as a Linux booth because of ""Tux"" the penguin, (well, a stuffed rendition of Tux) sitting on top of one of the monitors.  Caldera's booth was crowded with people every time I visited it.    Attendees were interested in Caldera's OpenLinux products and getting information about Linux and Linux products. The 1500  Linux Journal Buyer's Guides  given away by Caldera and their affiliated booths during CeBIT also seemed to be a hit with attendees. Caldera also provided information about OpenDOS 7.01, which is free for non-commercial and educational use. Caldera's booth staff talked about recent announcements such as the upcoming port of Netscape software to OpenLinux, and the port of StarOffice 3.1 to OpenLinux.    A German television station, Bayerischer Rundfunk, filmed a short tv show about Linux at the Caldera booth.  The ""tv host"" Jurgend Plate warmed up for a few minutes while the film crew continued to set up equipment. Before they started filming, after I identified myself as the Associate Publisher of Linux Journal, Jurgend hollered to me that LJ was ""das beste Magazin auf der Welt!"" I was told by Sebastian Hetze of LunetIX, that Jurgend Plate had been  excited about Linux for years, and that his exuberance over Linux was real.   A second Linux stop for me was at the large Star Office booth in Hall 2 that demonstrated among its many different ports,  StarOffice on OpenLinux.   At the third Linux stop, the large Software AG booth,  there was a signpost saying Datenbanktechnologie and the second sign down said ""ADABAS & LINUX"". Tux sat proudly on top of the workstation here by the Caldera OpenLinux Base. Nathan Guinn gave me a free review copy of the single-user  version of LunetIX's ADABAS, an SQL Database, which I passed along to the editor of Linux Journal.    A fourth company with a Linux product was NAG Ltd,  which among its other products, provided information on their Linux Fortran 90 Compiler.   Other companies, such as LST Software, GmBH and LunetIX had representatives at the show, mostly working out of Caldera's booth.   There was some press coverage about Linux.  In the special CeBIT section of the Newspaper called ""COMPUTER & KOMMUNIKATION"" there was a full-page article titled ""Linux schultert Microsoft-Anwendungen"" which covered the capability of Microsoft Applications to run under Linux using Windows Binary Application Interface (WABI).   All in all, CeBIT was an informative, busy, intensive, show.  Next time I should try it without crutches resulting from a sprained ankle. I should also mention the color shows and performances in some booths, including a musical story (D2-Musical) with  ""Princess Digital, the Queen of the World"", the artistic acrobats at VIAG Interkom, and many cabaret-style performances, which added a fun, colorful, entertaining diversion during CeBIT.                Copyright © 1997, Belinda Frazier    Published in Issue 16 of the Linux Gazette, April 1997                                      ""Linux Gazette... making Linux just a little more fun! ""                Dynamic IP Web Solution Using Geocities Web Account     by Henry H Lu,  fasta@geocities.com      http://www.geocities.com/SiliconValley/Lakes/3171/              Since I published an article ""Setting Up a Dynamic IP Web Server"" in Linux Gazette issue #10, I have lost all the free school web accounts. Because I need a permenent web page to bridge the linux dynamic web server at home, I have been lucky to found out that Geocities free web account can be used with a little bit hack. Geocities free web account with 2MB space and free email can be obtained at  http://www.geocities.com  .    Geocities web page can be updated by ftp method. However, geocities ftp procedure requires that *.html files are ftped with asii mode and *.jpg, *.tgz files are ftped by binary mode. I found out that if I use the wrong mode, web pages can not be updated. It took about 10 minutes in my test to update ( or overwrite) the web page after the updated file was ftped, so that you have to be patient to wait for your result with Geocities account.    ---------------------------------------------    The following is the ftp part of scripts in file web_up, web_down:    web_up:     if echo -e ""ascii\ncd /pub/homestead\nput up.html dynamic.html"" \     | /usr/bin/ftp -v geocities     web_down:     if echo -e ""ascii\ncd /pub/homestead\nput down.html dynamic.html"" \     | /usr/bin/ftp -v geocities     Source files like ppp-up and ppp-down are also updated to reflect the change.    The following sentence can be added to file /etc/ppp/ppp-up in order to use email to tell us current IP address of your linux box:    mail -s ""$4"" fasta@geocities.com < /etc/add    -------------------------------------------------    In conclusion, although it is not as convenient as the typical unix shell account to update the web page by using free Geocities web account, it serves us well for bridge to our dynamic web server at home with zero cost. For detailed information, please read my original article in issue #10, and check out my new web page for updated source code.                 Copyright © 1997, Henry H. Lu    Published in Issue 16 of the Linux Gazette, April 1997                                      ""Linux Gazette... making Linux just a little more fun! ""                                                                        Set your browser to the width of the line below for best viewing.                       © 1996 by      mjh                                                                  muse:          v;  to become absorbed in thought     n;  [ fr. Any of the nine sister goddesses of learning and the     arts in Greek Mythology ]: a source of inspiration        elcome    to the Graphics Muse!  Why a ""muse""?     Well, except for the sisters aspect, the above definitions are   pretty much the way I'd describe my own interest in computer graphics:     it keeps me deep in thought and it is a daily source of inspiration.                    [ Graphics Mews ]   [ Musings ]   [ Resources ]                         his   column is dedicated to the use, creation, distribution, and dissussion of   computer graphics tools for Linux systems.               I'm sort of taking a break from the Muse this month.  Work is really  gearing up and I've been quite busy there.  I'm also not confident   enough in my knowledge of RenderMan Shaders that I feel I could do  the topic justice this month.  So I'm postponing the 2nd in the 3  part series one month.  I  will  be doing the next two articles,  I just need a little more time to get them right.  I'll also still be doing the HF-Lab review.  The POV-Ray tips I'm   not certain I'll do myself.  I may see if I can talk someone from  the IRTC-L mailing list into writing something up there.  I haven't  been using POV-Ray 3.0 in awhile.  My attention has been focused on  BMRT.            So, all there is this month is a few announcements taken from the  various newsgroups and info thats been passed to me directly.                                                        Disclaimer:   Before I get too far into this I should note that any of the news items I   post in this section are just that - news.  Either I happened to run    across   them via some mailing list I was on, via some Usenet newsgroup, or via   email from someone.  I'm not necessarily endorsing these products (some of   which may be commercial), I'm just letting you know I'd heard about    them in the past month.                        Gifmap Image Navigator            Gifmap is a package which supports making image collections available on   the Web. It recurses through directory trees, building HTML pages,   imagemap files, and client-side/server-side maps to allow the user to   navigate through collections of thumbnail images (somewhat similar to   xv's Visual Schnauzer) and select the image to view with a mouse click.            Obtain gifmap from        ftp://ftp.wizards.dupont.com/pub/ImageMagick/gifmap    or via the Web from the Gifmap web page at       http://www.cyberramp.net/~bfriesen/gifmap/ .    The Gifmap web page   contains some sample pages you can browse through to give you an idea of   what Gifmap can do.  It also contains the gifmap documentation.             Gifmap is written in PERL and is compatable with PERL versions 4 and 5.   Gifmap uses the ImageMagick package and therefore requires that the   ImageMagick package be installed. ImageMagick version 3.8.0 or later is   recommended.                                MPEG file player v0.2               There was a very brief announcement for this package on       comp.os.linux.announce  which stated that   the program can work with Pentium-60 32MB machines.   I don't know why it wouldn't work with other systems, but   thats what the announcement said.           This file player supports MPEG layer 1, 2, 3 and Wave files   and uses pthreads (thus it requires libpthread.so).   Check       http://adam.kaist.ac.kr/~jwj95/    or       ftp://sunsite.unc.edu/pub/Linux/       apps/sound/splay-0.2.tar.gz .                            Microform has rev'd their VARKON package               VARKON is a high level development tool for   CAD and engineering applications developed by   Microform, Sweden.  It was first reported in last months   Graphics Muse.  Mircoform has since rev'd the   package to 1.14F and added new demo applications.    The new version is available at:       http://www.microform.se .                            MpegTV Player 1.0               MpegTV Player 1.0 is a realtime software MPEG Video Player   with audio/sync.                This major release has many improvements over earlier   versions, including better performances, better image   quality, better error resilence, improved GUI and new   features.          Key features:      High performances on Pentiums (25 frames/sec on P6-200)     Support for 8-bit, 16-bit and 24-bit display.     High Audio and Video quality     Fast random access     Frame capture     Takes advantage of multiprocessor platforms     Handles errors gracefully     Works in streaming/network environment     VCR-like graphic front-end (using the Xforms library)     Graphic front-end can be customized     Player can be controlled by any application via a simple API       MpegTV is a commercial application, but a free evaluation copy   is available from        http://www.mpegtv.com/download.html .  More information   is available from       http://www.mpegtv.com/player.html .                                The GS4500 scanner driver has been updated to Version 2.0               The GS4500 scanner driver is a device driver (loadable module)    for the Genius handheld scanners GS4500 and GS4500A (and    probably the GS4000).  Version 2.0 includes much improved    support for the GS4500A.   It also includes serious bug fixes. So everybody with a 2.0.x   kernel should update. (If you still run a 1.2.x kernel stay with   version 1.4 !)                Also included is a modified version of xscan. Like the name suggests   it lets you scan under X11 with your GS4500.    You can get it from        http://swt-www.informatik.uni-hamburg.de/       ~1willamo/linux.html .   It should also be in the Sunsite and tsx-11 archives by now.                             ImageMagick rev'd yet again - 3.8.3.               No word as to what this release is for, however.  Its nice to   see such ongoing development on this very fine set of tools.  I    just wonder if monthly releases is really necessary.                                      Did You Know?            John Bradley has now got an official home for xv on the web:       http://www.trilon.com/xv/ .  There isn't very much there   yet except the xv source distributions and links to some patches,   but that will probably change over time.                                                               No Musings this month.  I'll have some stuff for next month, though.   I promise.                                       The following links are just starting points for finding more information about computer graphics and multimedia in general for Linux systems.  If you have some application specific information for me, I'll add them to my other pages or you can contact the maintainer of some other web site.  I'll consider adding other general references here, but application or site specific information needs to go into one of the following general  references and not listed here.         Linux Graphics mini-Howto        Unix Graphics Utilities          Linux Multimedia Page        Some of the Mailing Lists and Newsgroups I keep an eye on and where I get alot of the information in this column:        The Gimp User and Gimp Developer Mailing Lists .       The IRTC-L discussion list        comp.graphics.rendering.raytracing        comp.graphics.rendering.renderman        comp.os.linux.announce            Future Directions    Next month:      BMRT Part 2: Shaders    Height Fields with HF-Lab       Let me know what you'd like to hear about!              Copyright © 1997, Michael J. Hammel    Published in Issue 16 of the Linux Gazette, April 1997                                      ""Linux Gazette... making Linux just a little more fun! ""              I recently did an e-mail interview, in the guise of Editor of  Linux Gazette , for the Italian Edition of  Linux Gazette . I know it sounds strange, but the Italian edition is basically our  LG  with a few additions such as this interview. (I really wasn't interviewing myself.) The questions were presented to me by Francesco De Carlo, a member of the faculty of Computer Science at University of BARI, Italy and the Director of the Italian Edition of  Linux Gazette , which can be found at  http://www.media.it/LUGBari/index.html .    -- Marjorie L. Richardson, Editor              LGEI Interviews the  Linux Gazette  Editor   By Francesco De Carlo,  fdecarlo@mailbox.media.it            Francesco : When and why did SSC decide to publish  Linux Gazette  in the current version? Originally,  LG  was edited only as an extra-curricular activity by John M. Fisk.    Margie : During the summer of 1996, John Fisk decided he no longer had the time to keep  Linux Gazette  up in the fashion it deserved.  LG  had become very popular, and readers were wanting it to come out on regular monthly basis. Between school and work, John just didn't have time to do this, so he put out feelers looking for someone to take it over. We responded and he accepted us as the right people to continue  LG .    Margie : SSC responded to John because we had always felt that  Linux Gazette  was a worthy and necessary asset to the Linux community. We did not want to see it either go away or be taken over by someone who would turn it into a commercial enterprise. We promised John that  LG  would remain free and it has.    Francesco : What kind of relationship does the  LG  have with his ""big brother""  Linux Journal ? Some exchanges of articles, writers, ...?    Margie : Yes,  Linux Gazette  and  Linux Journal  do a lot of sharing. As of February 1 of this year, I am Editor of both  Linux Journal  and  Linux Gazette . Every month we use an article from  LG  in  Linux Journal , and occasionally, I will use articles from  LJ  in  LG --usually those about conferences and other events surrounding Linux. And yes, I have authors who write for both magazines, most notably the regular contributors of columns to  LG :  Larry Ayers, John Fisk and Michael Hammel.  Linux Gazette 's Answer Guy, Jim Dennis, has done an interview with Stronghold's Sameer Parekh, which will be appearing in the August issue of  Linux Journal .    Francesco : Are authors wishing to write for  LG  contacted by you or do they send articles to you? That is:  do you prepare a list of the subjects that will be discussed in the next issue of  LG , or can users  send you any article, on any topic?    Margie :  LG  is managed very casually; authors can send me articles on any topic and I will include them. Whatever comes in during the month goes in the next issue. There is no focus other than Linux. Also, I do not edit the articles; they are posted just as the authors send them.    Francesco : Are you alone in producing  LG ? Or do you have a real ""editorial office"" with real ""editors"" and ""reporters""? If yes, how do you make it function?    Margie : I have no real editors or reporters to help. I depend on outside authors in the Linux community to make their contributions, and the wonderful thing is, they do. Some months I have more material than others (January was really packed), but I've never been short. I have gotten a lot of help with graphics and HTML from SSC's webmaster, Michael Montoure. Beginning this month, I have a new assistant, Amy Kukuk, who will be helping out by doing the  News Bytes  column and perhaps more.    Francesco : What are your plans for the near future? Introducing a new  LG  with a renewed graphic look, new articles and so on?    Margie : I intend to continue posting  Linux Gazette  each month and promoting it wherever I can. I feel it is even more of an asset than ever to both new and experienced Linux users.    Margie : Our look seems to change periodically. With the March issue, we dropped the spiral that caused so many problems. Michael is inventive, and we mainly add things as we come up with them.    Margie : We have two new columns that will be appearing regularly, ""The Answer Guy"" by Jim Dennis, and ""Clueless at the Prompt, A Column for New Users"", by Mike List. Both columns are good for new users looking for help.    Margie :  Linux Gazette  is free for the readers, but is not free for SSC. To help defray the publishing cost,  LG  has begun accepting sponsors. A small acknowledgment of these sponsors will be made on the Front Page. Our first sponsor is InfoMagic--our thanks to them for their help.    Francesco : What do you think about our LGEI? Is it a good idea and, above all, can it help Italian Linux users to better understand this OS?    Margie : I think LGEI is wonderful! It'a great way to spread the word about Linux to all Italy. With our regular columns and articles, as well as all the tips and tricks people send us, I feel LGEI is an invaluable resource to Italian Linux users, just as our English version is to Linux users worldwide.            Copyright © 1997, Francesco De Carlo    Published in Issue 16 of the Linux Gazette, April 1997                                      ""Linux Gazette... making Linux just a little more fun! ""                 More Linux Security    By Andrew Berkheimer,  andy@tho.org           Here you go, yet another article on Linux security. Some new tidbits for all to enjoy, reinforcement of some key points, and clarification of some things which I though were a bit misrepresented in previous articles. Note that this is geared towards a slightly novice audience, more experience users will probably find themselves bored out of their minds at times.    So you've got your system up and running, connected to the net, maybe running an ftp server or some other service.  But you've heard all these nasty stories of people having their computers cracked for no apparent reason, and you're just a tad bit nervous.  You want to start securing your system from outside intruders, but where to begin?  Contrary to popular belief, securing your system can actually be fun, and if nothing else, informative. So it's time to begin!    First and foremost, stay informed! Jay mentioned reading CERT, but I would argue that this is not enough. CERT does not release information  until they have verified that it is a problem and most of the big-name vendors have provided patches to fix the problem. This can often cause lag times of months between a hole being found and the CERT announcement. There are a number of good mailing lists which I would recommend subscribing to, including bugtraq, linux-security, and linux-alert (subscription information is at the end of the article), where security holes are often discussed and found long before CERT starts talking about them - the crackers know about these places, so should you.    Now onto some real meat. The first concern is to try and protect  yourself from attacks from unknown outsiders who may stumble upon your system and see it as an invitation to test out their cracking skills. One of the first  things you want to check is for unused daemons running on you system. There's  really no reason to be running nfsd if you're not NFS serving to anywhere,  now is there? There are two places that you will need to check out: the  configuration file for the inet super server (typically /etc/inetd.conf),  and the system bootup scripts (located in /etc/rc.d, /etc/rc2.d, or some  similar directory).     In inetd.conf, comment out with a # the lines for any service you don't really need to provide...the r* services (rlogind, rshd, rexecd, etc) are good candidates, as well as other typically unused ones like echo,  daytime, and chargen. For most people, leaving in telnetd, ftpd, and maybe  pop3d should be sufficient for the moment. Maybe fingerd too, though be careful, finger can give out a lot of information about your computer which can be to a potential crackers advantage. Once you finish editing your inetd.conf, restart inetd by running ""killall -HUP inetd"" to get it to reread the configuration.    In your bootup scripts you may see references to things like portmap, ypserv, rpc.mountd, and rpc.nfsd. Unless you are a NFS or NIS server, you have no need for these and should not run them...in many cases the ""out of the box"" versions of these programs have some pretty nasty security vulnerabilities.  Also look for sendmail (if you're not receiving mail directly you don't need to run it), and httpd (only want this if you're running a web server).    So, you've worked hard to get the list of unnecessary servers down... time to start adding/upgrading software again. First and foremost, make sure you are running the most recent version of NetKit, which contains most of the typically network servers for Linux like telnetd, fingerd, etc. The current version as of this writing is 0.09, it is available in ftp://ftp.uk.linux.org/pub/linux/Networking/base. The most recent version fixes a few known security flaws in earlier versions.    In general, you want to try and keep everything else up to date too: check http://www.sendmail.org for updates to sendmail (any time a new version comes out nowadays, it is almost always to fix a security problem), as well as http://www.apache.org for updates to the apache httpd server, etc.    However, there is still the problem of password sniffers grabbing your password if you telnet to your system from some other outside network. Telnet, FTP, POP, and just about any other standard protocol out there will transmit your password in plaintext. There are a couple of ways around this available in external software packages. I'll look at OPIE and ssh here.    First of all there's OPIE, also known as One-time Passwords In Everything, a package created by the US Naval Research Labs and currently maintained by The Inner Net. The idea behind one time passwords is that when you login to a system from remote, it will give you a prompt like this:     stroke login: andy  otp-md5 271 st6747  Response:    Instead of just typing in your password right away over the connection, you would instead run a key generating program on your local machine, with the parameters given in the ""challenge"" of the login prompt (the challenge here being otp-md5 271 st6747). You type your password into the local program (where it can't be grabbed by packet sniffers), and the key generator  produces a unique password which you login with. This unique, one-time password will only work once, so even if someone grabs it in a packet sniffer, it won't do them any good. The OPIE package is available at  ftp://ftp.nrl.navy.mil/pub/security/opie/ with more information.    There's also another pretty popular package, ssh. The ssh package replaces those evil rlogind, rexecd, rshd, etc. programs with sshd, which has the same functionality, but it encrypts all communications, making it very hard in deed for a packet sniffer to get anything useful. More information about the package can be found at http://www.cs.hut.fi/ssh/.    In addition to these two, there are a number of more involved, complicated methods designed for sitewide networks, labs, and the like, which are a tad overkill for one single host (this includes things like  Kerberos V and the like).    That about wraps up the protecting yourself from outside crackers, but you still have to worry about other users on your own system (or even outside crackers if they manage to get access to a shell on your system).  Typically you will hear a lot about ""buffer overflow"" security holes. These are essentially times when a binary doesn't check to see if the data it is storing into a character buffer can fit into the memory it is being put into. A carefully written program can take advantage of this and overwrite other parts of memory, causing other programs to be executed. Normally this isn't a problem until you get into setuid root binaries. Since setuid root binaries will initially run with root privileges, then any binary executed by the program will also be run as root. So if there is a buffer overflow which is used to run /bin/sh as root, then blammo, any random joe suddenly has a root shell to do what they please with.    There are also programs which have what are called race conditions, or times when they are doing something which may be used to a crackers advantage if the program happens to be running as root. Through some bit of trickery, it might very well be possible for them to get a root shell. The bottom line: setuid root binaries are not the greatest things in the world, keep the number of setuid root binaries on your system to a bare minimum.    To protect yourself from buffer overflows, there isn't too much you can do but keep up to date with information being made available about possible security holes and fixing them ASAP.  If you have some programming experience, you also probably want to actually look through the source code and check for buffer overflows yourself: you just may find one that no one else knows about yet.     Also, an important point: you should very rarely trust binaries that you just get off the net from an untrusted unknown source, especially if you are going to be running those binaries as root. This is how the Bliss ""virus"" spread, combined with a buffer overflow in some commonly found setuid root  games. Under any Unix, root is a very powerful user, so while normal viruses can't exist under Unix because users typically cannot modify system binaries, a program like Bliss is designed to try and exploit known buffer overflows to get root access to be able to modify root owned binaries.    And just as a last reminder, here are some points I can't help but  reinforce.If you think you've been compromised, then disconnect from the net immediately, analyze your logs, and replace any binaries which you think may have been compromised, maybe even reinstalling your system (after backing up important data). And always remember to keep your passwords hard to guess and change them regularly.     Besides all this, I can't begin to emphasize the importance of  GETTING INFORMED and then STAYING INFORMED. There are many good books on the topic of computer security, I'd especially recommend _Computer Security  Basics_ from O'Reilly and Associates for those with a beginning interest in security. And keeping current with some of the more popular security mailing lists will do you a world of good.  There is also a Linux Security FAQ available online at http://www.aoy.net/Linux/Security/, which is a good  source of information. Some final advice: never get the feeling that your system is ""perfectly secure"" - you're just inviting a break-in that way.    Oh, about those mailing lists I mentioned earlier. Information about linux-alert and linux-security can be found at the Linux Security WWW I just mentioned (http://www.aoy.net/Linux/Security/). Information about bugtraq may be found at http://www.geek-girl.com/bugtraq/index.html. There are also a lot of other things which can be said about security, delving into firewalls and other packet filtering, IP spoofing protection, more fine grained access control to net services, and many other areas, but those are topics for another place and time.        -Andrew Berkheimer      andy@tho.org, aberkhei@tjhsst.edu     Summary of Resources Mentioned                       netkit: ftp://ftp.uk.linux.org/pub/linux/Networking/base/                 sendmail: http://www.sendmail.org/                   apache: http://www.apache.org/                     opie: ftp://ftp.nrl.navy.mil/pub/security/opie/                      ssh: http://www.cs.hut.fi/ssh/       linux security www: http://www.aoy.net/Linux/Security/    linux-alert list info: http://www.aoy.net/Linux/Security/LinuxAlertList.html linux-security list info:    http://www.aoy.net/Linux/Security/LinuxSecurityList.html        bugtraq list info: http://www.geek-girl.com/bugtraq/                    Copyright © 1997, Andrew Berkheimer    Published in Issue 16 of the Linux Gazette, April 1997                                      ""Linux Gazette... making Linux just a little more fun! ""               GV: An Alternative to Ghostview    by Larry Ayers    I imagine that most Linux users have tried more than one distribution at one time or another.  I've tried several, and after configuring a new installation to my liking and learning its idiosyncrasies I'm reminded that Linux is... Linux! Distributions make installation and package management easier, but once you're up and running the differences aren't really noticeable.      These days what I find interesting about distributions is the choice of software packages to be found in them.  You would think that all of the distributions would offer the same software; after all, it's mostly freely available stuff from the 'net, available to anyone.  There is a core group of applications which nearly all distributions provide, useful and high-quality packages such as XV, XFree86, and Ghostscript.  But there is quite a variance when you get down to the smaller, less basic and less necessary packages. Every distribution I've tried has contained software which none of the others had included.   Recently I've been using the Debian distribution.  While installing packages I came across something called ""GV"", which seemed to be some sort of Postscript viewer.  I installed it and learned that this viewer was developed using Ghostview as a base, but it's much easier to use. Unlike Ghostview, GV can also display PDF files.   Due to the fact that most computer monitors are wider horizontally than vertically it's not feasible to read a standard page of a document and see the entire height of the page at once.  GV deals with this by showing a small rendition of the viewing window to the left of the page and highlighting the visible portion.  Clicking the left mouse button anywhere on the displayed page and dragging it smoothly scrolls the page up and down, while the miniature schematic rendition window shows you where you are on the page. If your window is too narrow to display the full width the mouse can scroll left-to-right as well.   Here's a screenshot of GV displaying a page of the included Postscript documentation:        One of GV's optional features (it can be toggled from the menubar) is aliased fonts. When this is turned on font characters are displayed very crisply.   Ghostview has traditionally been supplied as the default Postscript file viewer.  I've found it to be awkward to use; it seems when I have the magnification adjusted so that the print is legible, the window is so large that it is difficult to navigate around the document. GV deals with this problem (which I imagine has affected anyone with a monitor smaller than 21""!) in a nicely intuitive way.   GV is a good example of the dynamics of the free software movement. Several years ago Timothy Thieson wrote the Ghostview program; it was a good program in its time, but has been static for some time now.  After all, writing a piece of free software doesn't necessarily entail revising and updating it forever!  But the source was still available and eventually Johannes Plass adopted it, with GV as the result.  Then the program came to the attention of Helmut Geyer and he made a Debian package of GV, bringing the software to a new group of users.  Developers don't have to re-invent the wheel, as there is probably code archived somewhere which will provide a head-start on any sort of application.    Obtaining GV    GV can be obtained in source form from   this German FTP site .  I believe the Xaw3d widget set is required in order to compile the source.  The Debian version can be FTP'ed from   the main Debian site  or one of its mirrors.      Copyright © 1997, Larry Ayers    Published in Issue 16 of the Linux Gazette, April 1997     Last modified: Sun 30 Mar 1997                                       ""Linux Gazette... making Linux just a little more fun! ""                     XEmacs 19.15    by Larry Ayers    The developers of XEmacs, the independently-maintained offshoot of GNU Emacs, have released a new version of this versatile editor.  Version 19.15 is the last of the 19.xx series; in the future developmental efforts will be focussed on the 20.xx series, which up to the present has been evolving in parallel with version 19.   Aside from many bug-fixes, a good deal of the changes in this version involve updates to many of the large extension packages which come bundled with the editor.  Quite a large bundle it is, weighing in at over eighteen megabytes, tarred and gzipped.   Among the new features are:         Incorporation of the TM package,which gives MIME reading and writing       support to mail and usenet news packages.    Updated versions of Gnus, W3, VM, CC-Mode, Python-mode, and Hyperbole.    Incorporation of the Auctex TeX/LateX editing package.    The Custom utility, which attempts to standardise package customization.    Many documentation updates.    New version of hm--html-menus, which has an Info file now    New fancier version of time.el, which shows the time, system load, and       mail status in the mode-line.    Replacement of Angeftp and dired with EFS, which merges the two.    A new Message mode, used by the various mail and news packages.    Many improvements in configuration and compilation from source.    Updated Viper (vi-emulation) mode.    Enhancements and bugfixes for many other packages and modes.      The members of the XEmacs team have changed with this release; former maintainer Chuck Thompson has passed the torch to Steve Baur.  The other maintainers are now Martin Buchholz and Kyle Jones (author of the VM mail package), with Bob Weiner, Chuck Thompson, Ben Wing and Bill Perry helping out as well.   It's interesting to note how the developers of the various extension packages and of XEmacs itself have attempted to maintain a certain parallelism with Gnu Emacs development.  Most extensions, even those written primarily with XEmacs in mind, have support for Gnu Emacs built in.  The XEmacs team attempts to incorporate new features and bug fixes from Gnu Emacs development into their version; I wonder if the opposite is true?    Installation     Binary packages for 19.15 are available at  the XEmacs FTP site , but there are several reasons why compiling your own can be advantageous.  XEmacs uses a configure script to adapt the makefiles to your machine.  There are many possible switches or parameters which can be given to the script depending on your needs.  The editor supports inlined JPEG, GIF, XPM, and PNG images; support for any of these can be disabled. If you don't plan on running the W3 browser or using the MIME capabilities of VM or Gnus (combined with TM) this might be a good idea. Sound support is another frill which not everyone will want. These optional features aren't a burden if you have a memory-laden and powerful machine, but they aren't really necessary and can be dispensed with if the resources to use them are insufficient.  The toolbar (and even X-Windows support) can be disabled by the configure script if you want a leaner, less memory-hungry executable.   You will need about 80 mb. of disk space to compile from source; luckily most of that can be reclaimed afterwards.   There's no denying that an XEmacs installation occupies quite a chunk of disk space.  A new shell-script called  gzip-el.sh  is supplied with version 19.15 which uses the Gnu  find  utility to recursively probe the various LISP subdirectories, gzipping all  *.el  files which have a corresponding byte-compiled  *.elc  file.  This alone will save about fourteen megabytes!     If you have no intention of ever modifying or reading those  *.el  Lisp files you could just delete them all, but that might be rash.  Sometimes the only documentation for a mode or function is buried in one of those files; others can be modified to suit your preferences.  A better alternative is to become  root  and, wielding  rm , dispose of some of the Lisp packages which you don't think you'll ever need.  Try to avoid the /lisp/prim directory, though, as the essential core files live there.  I don't know how many times I've removed the Energize, VMS, and MH-E directories from past installations; I'm sure I'll be removing them again in the future. A promised feature of version 20.1 (which will be the next major release) is the separation of some of these packages from the main distribution.  This will allow the core of XEmacs to be obtained separately, allowing the user to decide which of the extensions to download, depending upon his or her needs.   Customization    Anyone who has used XEmacs for very long, especially for writing code, likely has had the desire to come up with a set of syntax-highlighting colors which are both pleasing to the eye and functional.  In XEmacs, a ""face"" is a combination of font and color specifications for a certain category of text. There are many of these defined; each mode tends to have several of its own as well as sharing system-wide faces.  It can be quite a time-consuming job setting these in your  ~/.emacs  file, especially if you use a dark background, in which case many of the default colors won't have sufficient contrast.  XEmacs 19.14 allowed face modifications by means of the  edit-faces  command.  This utility works well, appending the changes to your  ~/.emacs  file.  Unfortunately the format they are saved in is particularly difficult to read if you ever wanted to make a single change manually; the lines are very long and the syntax is obtuse and thickety.   Per Abrahamsen, maintainer of Auctex (another of the bundled packages), has written the Custom package in an effort to simplify the customization of XEmacs and its many extensions.  After typing  esc-x customize  a buffer appears with menu entries for not only faces but other user-definable variables. These entries are categorized by package; selecting one causes a cascading sub-menu to appear. The first category is just ""Emacs"", which allows global settings to be made.  In order for a package to be included in the Customize buffer the programmer must include hooks in the LISP code.  Most of the larger packages, such as Gnus, the VM mail-reader, W3, and EFS (the new successor to AngeFTP) have been adapted in this way.   It is wise to back up any  .emacs  or  .xemacs-options  files which you are fond of before fooling around with any such auto-customizing utilities.  That tempting ""Options"" menu with all its choices will cheerfully overwrite your  .xemacs-options  file if you impulsively select the ""Save Options"" item.  Remember, you can always cut-and-paste from the generated file into your real one, then move it back.  The  Custom  package is more forgiving: it appends its results to the end of your  .emacs  file.  I've noticed that often when an XEmacs package such as  Custom  or  W3  appends to your init file it will drop down several lines from the bottom entry before writing its lines.  If you are looking at the file, curious as to what changes have been made, scroll down past the end; it's easy to miss an addition if it's lurking down amongst the superfluous empty lines which XEmacs has a penchant for adding to the end of a file.   One technique which is useful for customizing XEmacs, Fvwm2, or any complex piece of Linux software is to assume a different identity.  Just create a new user (with  adduser  or equivalent) and log in to the new account.  This way you have a clean slate and can modify, cut and paste with abandon, all the while knowing you can return to your normal login account if things go awry. The sample  .emacs  file which is found in the  /etc  subdirectory of the XEmacs distribution can serve as a good starting point, especially if you are new to Emacs-type editors in general.   Miscellaneous Notes    To accommodate users who run XEmacs on a grayscale or limited-color display, the XEmacs team has included toolbar icons which are rather plain. I suspect that most XEmacs users eventually turn off the toolbar (the keyboard commands are faster) but if you'd like replacement icons which are well-designed, color-map-eating and very stylish, the  AfterStep FTP site  has a set of them, in the file  NeXT.XEmacs.tar.gz . (A pox on mixed-case filenames!)  These can be dropped right in to the [XEmacs-root]/etc/toolbar directory, overwriting the old ones. Here's a cropped screenshot:            The XEmacs documentation is voluminous, but there are so many obscure modes and features included that to document them all would add megabytes to the distribution (plus someone would have to volunteer to do it!). You would be surprised at what can be found while browsing through the directories of Lisp files.  As an example, the other day I happened upon a file called  xpm-mode.el  in the /lisp/modes directory.  Curious, I loaded the file into XEmacs and saw that it is a colorized mode for directly editing xpm icon-files.  This is quite an interesting mode, but I'd never heard of it; it was contributed to the XEmacs maintainers by Joe Rumsey and Rich Williams in 1995. Here's a sample window:       There are all sorts of obscure modes and packages buried in the  lisp  subdirectories; grepping for various keywords will turn up some interesting files.    Conclusion    I've been following the late stages of this XEmacs beta cycle and I'm impressed by the amount of work involved in putting together such a large, complex package. The developers and beta-testers deserve kudos for their efforts.   If you would like to try it out, the source is currently available at  the home XEmacs site .  This site will probably be crowded during the first week or two after the release; if you are unable to log on a list of mirror sites will be displayed.  If you would rather not download the massive archive file, just wait a few weeks and I'm sure the distribution will show up on various distribution and FTP-archive CDROMs.     Copyright © 1997, Larry Ayers    Published in Issue 16 of the Linux Gazette, April 1997     Last modified: Sun 30 Mar 1997                                           ""Linux Gazette... making Linux just a little more fun! ""                 UniForum'97, March 12-14   By Marjorie L. Richardson,  gazette@ssc.com            UniForum Photo Album          My trip to San Francisco to attend UniForum'97 was very satisfyng as I got to see two great luminaries of our time--the Hale-Bopp comet and Linus Torvalds. Hale-Bopp was visible in the pre-dawn sky on March 12  and 13. Linus was visible at the Keynote speech on March 13 and was  definitely the brighter of the two.   The president of UniForum, Tom Mace, was present to welcome Linus, and  Douglas Michaels of SCO presented Linus with UniForum's Achievement Award. The award itself is a clear, pyramid-shaped trophy, about which Linus said he was pleased to have something ""physical"" to show for his work. Linus' acceptance speech was brief and self-effacing as usual. He referred to himself as the ""spider at the center of the web"" with many others working around him. Tove and their 3 month old baby girl, Patricia Miranda, had accompanied Linus and both tolerated my pushiness in taking pictures. After the keynote, Linus and Tove made the rounds of the Exhibit Hall, visiting all their fans in the Linux Pavillion. Tove confided that they were enjoying the weather (no snow), but that the arrival of their furniture had been delayed by a bad storm that had forced the ship back to Germany.   Mitchell Kertzman of Sybase gave a vibrant keynote speech that morning,  in which he ignored Linux as a possible factor in a paradigm shift that  might topple Microsoft. Perhaps he hasn't heard that Linus' goal is ""world domination"". Kertzman compared today's software industry to the automobile industry of the fifties--that it is designing products to be obsolete in 3 years, while consumers are wanting long  term reliability. Sounds to me like consumers are looking for Linux.   While 7000 people had pre-registered for UniForum, only about 75% of those actually attended. Perhaps they went to one of the competing shows such as Internet World. At any rate, at times the floor was crowded with attendees, while at other times (particularly toward the end of the day) it was quite empty. The Linux Pavillion was placed in the right rear corner of the floor, yet it seemed to me that most attendees were gravitating over to check out this upstart operating system that dares to be freely available. SSC gave away their stock of magazines and bumper stickers, as well as displaying t-shirts, reference cards and the new ""Tux"" mugs. IBM and Lucent Technologies both had central positions on the floor, but I saw many people passing them by to visit Digital to check out both the Alpha and Jon ""maddog"" Hall's new Linux setup for Digital's Intel box. Jon is providing us with a short article about this setup that will appear next month.   I attended two of the talks: one on Electronic Document Interchange and one on high speed Internet access. Both were well presented and full of good information. I was particularly impressed with Jeff Wilbur's thoughts on the directions that access to the Internet will take in the future (i.e., cable modems, xDSL, satellite, ISDN), and so asked him for an article.    Since UniForum'97 was my first conference as Editor of Linux Journal, I met many people that I had only heard about before, including Joel Goldberg of InfoMagic (who is a sponsor of Linux Gazette), Mark Bolzern of WGS, Adam Richter of Yggdrasil, and of course, Jon ""maddog"" Hall of Digital. Jon introduced me to Ted Cook of BRU, who told me of his plan to give away Bru software to Linux User Groups at the upcoming Linux Expo and to groups that are members of  G.L.U.E.     On Wednesday night Joanne Wagner, one of our advertising representatives, and I attended a press conference/party put on by XiGraphics--free food and drink, always a plus. The press conference was held to announce the recent name change (from X Inside) and the latest release of Xi's Accelerated X software. The president and founder of the company, Thomas Roell, gave a short presentation in which he described the directions he envisions for Xi Graphics.   All in all, I had a good time at the conference and a pleasant stay in San Francisco.            Copyright © 1997, Marjorie L. Richardson    Published in Issue 16 of the Linux Gazette, April 1997                                      ""Linux Gazette... making Linux just a little more fun! ""                   Welcome to The Linux Weekend Mechanic!   Published in the April 1997 Edition of the Linux Gazette    Copyright (c) 1997 John M. Fisk <fiskjm@ctrvax.vanderbilt.edu>  The Linux Gazette is Copyright(c) 1997   Specialized Systems Consultants Inc.           Time To Become...  The Linux Weekend Mechanic!                             You've made it to the weekend and things have finally slowed down.  You     crawl outa bed, bag the shave 'n shower 'cause it's Saturday, grab that     much needed cup of caffeine (your favorite alkaloid), and shuffle down     the hall to the den.  It's time to fire up the Linux box, break out the     trusty 'ol Snap-On's, pop the hood, jack 'er up, and do a bit of     overhauling!          Table of Contents          Welcome to the April 1997 Weekend Mechanic!       More Wallpapering ideas...       Wallpapering with  xlock ...?!       System Logging Ideas...       Closing Up The Shop              Welcome to the April 1997 Weekend Mechanic!     Hey, c'mon in!    Thanks for dropping by!  How y'all been doing?    I don't know about you, but life around the Fisk household has been pretty busy of late.  I've been having a great semester at   MTSU  and enjoying my classes which are predictably starting to crescendo in unison into a frenzy of activity.  And we're all starting to ""mood synchronize..."" :-)    I apologize that the articles and such in this edition are going to be a bit short and hurried.  I've got a couple hours' worth of time before we leave to visit family and I'll see what I can get written up.  I've got a growing notebook full of ideas about which I'd like to write.  Which reminds me...    Have I preached recently on the virtues of keeping a notebook...    You say,  I haven't...?!  :-)    Well, y'all just settle back in for a few minutes while I loosen the belt, take a deep breath, and start in!    Seriously, I'm convinced that keeping a notebook, journal, or just a stash of note and ideas you've come across and jotted down is like  brushing and flossing:  it's good for hygiene .  Mental hygiene, that is.  It'll help prevent ""Programmer Pattern Baldness"", the kind that comes from pulling your hair out trying to remember just the exact invocation of some  obscure, and recalcitrant, system utility or repairing that delicately situated configuration file that you were going to make such a  small little change to...     Having notes as to what you did to some configuration file; having a hardcopy printout of the docs/manual pages/README files on some utility; or just having a command line invocation scribbled out on the back of the phone bill envelope and stuff into the back of your notebook may REALLY save your ""nether parts"" some day.    And lest you think that I'm more obsessive-compulsive, anal-retentive than I really am... I've actually got a small pile of legal pads sitting on the shelf next to the computer desk that has all those stream-of-consciousness type scribblings and notes.  It's not very well organized, there's a huge amount of redundancy, and some of the stuff is totally illegible or frankly incoherent (probably penned during moments of questionable lucidity at 2:00 AM...). Still, this stuff has come in mighty handy from time to time and it's amusing and instructive to look it over now and then.      I've also found that keeping more or less detailed notes of installation (which I've managed to do quite frequently over the past couple years) have come in VERY handy when I've sat down to sketch out a new installation.  I've worked out my own partitioning scheme that's been useful for me, developed my own archiving and upgrading scheme, and so forth based on these notes.    Also, as I alluded to above, it's pretty useful to keep a stash of hardcopy printouts of various README's, manual pages, and so forth.  While I appreciate the versatility of online documentation -- info, man pages, HTML, and so forth, nothing beats having a booklet in your hot little hand that you can read without having to wait for Netscape to finish consuming your entire colormap before it loads... :-)     (I know, I know... you've been there, done that, got the t-shirt... :-)     Seriously, having a printout to write all over and mark up is pretty handy. If you keep all those things in some kind of notebook, binder, file folder, or whatever, you'll probably save yourself some aggravation in the future.    Just a thought...    Anyway, I'm done now.  So, without further ado...     On with the show!     Hope you enjoy!    John M. Fisk  Nashville, TN  Friday, 28 March 1997           More Wallpapering Ideas...     After the February WM column,  Irek Koziol  wrote about the wallpapering  ideas that I'd mentioned:      Date: Wed, 12 Feb 1997 15:28:28 -0600  From: Irek Koziol <cft-inc@worldnet.att.net>  Subject: X Window Wallpaper     I was using:    xv -quit -root -max  image.gif      (If enlarging image is a goal to fit the whole screen ).    Could you please comment on it, and make a followup in LG?    Cordially, George.      Well, let's see what we can say about this...    First,  John Bradley's  ubiquitous xv program is a definite must-have utility and a veritable ""Swiss Army Knife"" of graphics goodies.  It has, as all good UN*X programs do, a bazillion command line options that could occupy a lifetime of study and reflection.  Fortunately, those that you need to know to be productive are limited, and in the confines of the present discussion, can be narrowed down to a manageable number.    Just for the fun of it, start up X and try something like:    xv -help      Then stand back...    When you do this, xv disgorges something like:    Usage: xv [-] [-/+24] [-/+2xlimit] [-/+4x3] [-/+8] [-/+acrop] [-aspect w:h] [-best24]     [-bg color] [-black color] [-bw width] [-/+cecmap] [-cegeometry geom]     [-/+cemap] [-cgamma rval gval bval] [-cgeometry geom] [-/+clear] [-/+close]     [-/+cmap] [-cmtgeometry geom] [-/+cmtmap] [-crop x y w h] [-cursor char#]     [-DEBUG level] [-dir directory] [-display disp] [-/+dither] [-drift dx dy]     [-expand exp | hexp:vexp] [-fg color] [-/+fixed] [-flist fname]     [-gamma val] [-geometry geom] [-grabdelay seconds] [-gsdev str]     [-gsgeom geom] [-gsres int] [-help] [-/+hflip] [-hi color] [-/+hist]     [-/+hsv] [-icgeometry geom] [-/+iconic] [-igeometry geom] [-/+imap]     [-/+lbrowse] [-lo color] [-/+loadclear] [-/+max] [-/+maxpect] [-mfn font]     [-/+mono] [-name str] [-ncols #] [-/+ninstall] [-/+nodecor] [-/+nofreecols]     [-/+nolimits] [-/+nopos] [-/+noqcheck] [-/+noresetroot] [-/+norm]     [-/+nostat] [-/+owncmap] [-/+perfect] [-/+poll] [-preset #] [-quick24]     [-/+quit] [-/+random] [-/+raw] [-rbg color] [-rfg color] [-/+rgb] [-RM]     [-rmode #] [-/+root] [-rotate deg] [-/+rv] [-/+rw] [-slow24] [-/+smooth]     [-/+stdcmap] [-tgeometry geom] [-/+vflip] [-/+viewonly] [-visual type]     [-/+vsdisable] [-vsgeometry geom] [-/+vsmap] [-/+vsperfect] [-wait seconds]     [-white color] [-/+wloop] [filename ...]        Impressive... eh?    Whoops!  Whoa there!!  Don't leave me yet...    This isn't as bad as it looks.  Trust me... :-)    The basic command line options you'll need to do a bit of root window wallpapering can be limited to the following:    -root  -rmode [0-9]  -max  -maxpect  -quit      Now, you can go on and do more fancy things, but the above options will certainly get you going.  So, let's take a quick look at what each of these means.      -root    Display the image in the root window instead of in a separate window.  How the image is displayed depends on the setting of the  -rmode   option (which defaults to 0).       -rmode  [0-9]   Specifies how xv will display the image in the root window if the   -root  option has been given.  There are currently ten different  modes which are indicated by using a number from 0 to 9.  To see a listing  of what these modes are, you can give an argument of -1 to the   -rmode  option and xv will complain a bit and display the  information concerning the  real  options:    xv -root -rmode -1 ~/images/wallpaper/forest.gif xv: unknown root mode '-1'.  Valid modes are:  0: tiling  1: integer tiling  2: mirrored tiling  3: integer mirrored tiling  4: centered tiling  5: centered on a solid background  6: centered on a 'warp' background  7: centered on a 'brick' background  8: symmetrical tiling  9: symmetrical mirrored tiling         Pretty slick, eh?      This is where the  serious coolness  comes in.  You can not only  specify your favorite 'ol image to brighten up your X window, but you can  do all sorts of nifty things to it as well.      So, I know what you're thinking... "" How in the world do I know  what each of these means...?! ""      Glad you asked.      The easiest way to find out what each of these options does is to start  xv, select a file to display, and then use the  Root  menu item to  select the various types of root window displays:             The Root menu item will display the same listing as you saw above.  You  can use the file browser to locate a file to play with, and then select  the various menu options to see what they do.  Once you've hit upon an  option that you like, jot down which one it is.  For instance, if you  liked the ""integer mirrored tiling"" effect, you'd use something  like:     xv -rmode 3 -quit ~/images/wallpaper/forest.gif         And xv would wallpaper your root window with the forest.gif image using  integer mirrored tiling.      And you thought this was going to be hard... :-)      One last note:  if you use the  -rmode  option, you don't have to  specify the  -root  option as well as this is implicit in   -rmode        -max    Another option, which Irek alluded to was the  -max  option.  What this does is stretch the image so as to fit in the root window,  without respect to the original image aspect.  So, for example, if you had  an image that was 920x740 and you were running at 1024x768, using this  option would cause the image to be ""stretched"" to fit into  1024x768.  Now, depending on your original image, this could look a bit  funny, I suppose, but at least it'd get the whole thing in.       -maxpect    This is quite similar to the above  except  that it preserves the  image aspect.  So, assuming that you were using the same 920x740 image  mentioned above, using the  -maxpect  option would scale the  image up, but would keep the width:height aspect ration the same.  In this  case, it's likely that the image would be stretched to a height of 768,  while the width would be something less than 1024.       -quit    Ahhh...  this  is the magic word that says, ""Open  Sesame!""... ""please...""      This option causes xv to display the first image given on the command line  and then quietly exit once it's done.  This is how you can add a stanza to  a script or startup file and have xv wallpaper the root window and  peacefully terminate once this is done.         See, that wasn't so bad, now was it.  So, tying it all together:  suppose that you had a directory off your home dir called ""/images/wallpaper/"" that you put your wallpaper collection in.  You want to use that nifty forest.gif image and have it integer tiled.  Easy as cake:   xv -rmode 1 -quit ~/images/wallpaper/forest.gif       Viola! , instant gratification! :-)    Now, you can easily do this from any xterm or rxvt command line.  Heck, you can do this from emacs or vi if you know how to execute a shell command...     (pssss...!  Hey buddy... yeah, you.  If you're using vi, just try something like:    :!xv -rmode 1 -quit ~/images/wallpaper/forest.gif   and you're golden).    The more convenient way to do this is to put it in one of your start up scripts.  I've recently started using FVWM-95 and so this would go in my  ~/.fvwm2rc95 file under the ""InitFunction"" heading:   AddToFunc ""InitFunction"" ""I"" Module FvwmAuto 200 +                        ""I"" Module FvwmButtons +                        ""I"" Module FvwmTaskBar +                        ""I"" Exec syslogtk -geometry +2+2 & +                        ""I"" Exec rxvt -ls -sb -sl 400 -fn 9x15 -geometry 80x32 & +                        ""I"" Exec /usr/X11/bin/xv -rmode 1 -quit ~/forest.gif &      Other window managers will have their own initialization files that will need to be customized.  RTFM.    And speaking of RTFM, there's an  extensive  manual that John Bradley has provided with xv.  ""Everything You Always Wanted To Know About XV, And Were Afraid To Ask..."".  On my 'ol Slackware '96 distribution, the documentation gets installed to /usr/doc/xv and the file to have a look at is the  xvdocs.ps  file.  It's a HUGE postscript document describing the program and all of its options and operations in detail.  If you're using xv much at all, this is required reading.  You can use one of the postscript viewers such as  ghostscript  or my current favorite,  MGV , to view the file.    Here are just a couple other thoughts on the subject of wallpapering...     Keep the number of image colors small.     If you haven't noticed, one of the more annoying things about X is that it's remarkably easy to ""use up the colormap"".  Programs like Netscape are notorious for allocating a hoggish number of entries, leaving other programs unable to allocate colors, OR, having to install their own private colormaps.  When this happens, you end up with that migraine-grinding, wildly psychedelic color flashing when you move from one window to the next.    One way to help prevent this is to use images with a small number of colors. To determine how many colors are being use, load the image and watch the status message that xv will print in the control window.  Another option, and one that's easy to use on the command line, is to use the  xli  program:   xli -ident forest.gif forest.gif is a 256x256 GIF89a image with 32 colors      To limit the number of colors, use XV's Save function and, if you're saving the image in GIF format, you can select the ""Reduced Color"" option. You can also use the excellent  ImageMagick  suite of graphics tools: use the ""convert"" program with the  -colors  option to specify the desired maximum number of colors to use:   convert -colors 24 forest.gif forest_rc.gif    is one way to accomplish this.  If you're handy with the  NetPBM  utilities, then I'm sure that you can do a similar thing.     Add wallpapering to your favorite buttonbar or menu.     Got a  collection  of favorite images and just can't decide which one you like?  Do you change your wallpaper more often than your socks?  Do yourself a favor:  add this stuff to your favorite menu or buttonbar and have it available at a whim's notice!    For example, if you're using FVWM-95 and the FvwmButtons module, you could add something like:   *FvwmButtons forest gif.xpm  Exec """" xv -rmode -1 -quit ~/wallpaper/forest.gif & *FvwmButtons clouds gif.xpm  Exec """" xv -rmode -1 -quit ~/wallpaper/clouds.gif & *FvwmButtons trees gif.xpm  Exec """" xv -rmode -1 -quit ~/wallpaper/trees.gif & *FvwmButtons space gif.xpm  Exec """" xv -rmode -1 -quit ~/wallpaper/space.gif & *FvwmButtons GTO  gif.xpm  Exec """" xv -rmode -1 -quit ~/wallpaper/GTO.gif &    and so forth.    Now, you can change the root window as easy as clicking on the buttons!  You can also do something like this with menus.  Just create your own custom submenu and add it to your present menu.    Also, even if you're not using a window manager that provides its own buttons, (such as OpenWindows), you can still use programs such as  tkgoodstuff  or  tycoon  as ""aftermarket add-on's"" and end up with a splendid buttonbar nonetheless.  You can find these programs at any well-stocked Linux FTP archive or simply do an Alta-Visa or Yahoo search for them.    So, how about that?  Think that this will give you something to do for a while?  Messing around with this stuff can be a HUGE time sink, so for those dreary rainy April Saturday afternoons, just tell your spouse that you're going to be busy all day doing a bit of ""wallpapering...""    Enjoy!    John           Wallpapering with  xlock ...!?     Yup... :-)    Since we're on the subject of wallpapering anyway, I thought I'd throw this out for what it's worth.    There are actually quite a variety of ways to spiff up your dull and lifeless root window.  And if you're still using that hideous black and white cross-hatch when X starts...    We're here to the rescue!!  Hang on!    From all of the various doodles and scribblings that that I've made over the past couple months on the subject, there seems to be AT LEAST three basic things that you can do with wallpapering your root window:      Color or color+texture   Images   Animations      You can easily try colors or colors+textures by using the  xsetroot  program.  Use the  -solid  option with the name of a color to set the root window color to some value.  Also, try using the  -mod [x] [y]  option which gives you a plaid texture.  You need to specify an x and y value for the pattern, which are numbers between 0 and 16.  You also can specify the foreground and background colors to use with this using the  -fg  and  -bg  options, respectively.    We've talked at some length about using an image in the root window using a program such as  xv .  See the previous article in this months column for all the gory details.  FWIW, you can also use the  xsetroot  with the  -bitmap [filename]  option to use a black and white bitmap image if you'd like.    Finally, you can use animations on your root window.  There are all kinds of nifty little doodad's and thingamabob's around to do such things.  My favorite is the  xearth  program, although I've fooled with and enjoyed the  xfishtank  and the  xantfarm  programs as well.  You should be able to find these at your friendly neighborhood Linux FTP site or on that Christmas CD your spouse reluctantly bought for you... :-)    Here's  yet another  suggestion that you might not have tried...    Did you know that you can use the  xlock  program as wallpaper?      No, seriously...  You gotta give this a try!    The xlock program has almost as many command line options as xv.  Again, if you invoke it with the secret password...   xlock --help xlock:  bad command line option ""--help""  usage:  xlock [-help] [-resources] [-display displayname] [-name resourcename]     [-/+mono] [-/+nolock] [-/+remote] [-/+allowroot] [-/+enablesaver]     [-/+allowaccess] [-/+grabmouse] [-/+echokeys] [-/+usefirst] [-/+v]     [-/+inwindow] [-/+inroot] [-/+timeelapsed] [-/+install] [-delay usecs]     [-batchcount num] [-cycles num] [-saturation value] [-nice level]     [-timeout seconds] [-lockdelay seconds] [-font fontname] [-bg color]     [-fg color] [-username string] [-password string] [-info string]     [-validate string] [-invalid string] [-geometry geom] [-/+use3d]     [-delta3d value] [-right3d color] [-left3d color] [-program programname]     [-messagesfile filename] [-messagefile filename] [-message string]     [-mfont fontname] [-imagefile filename] [-gridsize] [-neighbors] [-mode ant     | bat | blot | bouboule | bounce | braid | bug | clock | demon | eyes     | flag | flame | forest | galaxy | geometry | grav | helix | hop | hyper     | image | kaleid | laser | life | life1d | life3d | lissie | marquee | maze     | mountain | nose | petal | puzzle | pyro | qix | rock | rotor | shape     | slip | sphere | spiral | spline | swarm | swirl | triangle | wator     | world | worm | blank | random]  Type xlock -help for a full description.      Impressive...    (... and if you're wondering why I didn't try the  xlock -help  option as it suggested, the reason is that of brevity.  Try this yourself to get the FULL description!)    The options that you want are the  -inroot  and the  -mode [name]   options.  To install your favorite galaxy, pyro, blot, rock, rotor, swarm, or whathaveyou onto your root window, just do something like:   xlock -inroot -mode swarm &      And stand back and enjoy the show.  Of course, you can get a bit dizzy watching some of these, but it's kinda fun watching the bats careen around and the swarm chasing that one little bugger all over the screen.  Add a couple invocations like this to your favorite 'ol buttonbar or menu and you'll be the envy of all your neighbors.  People will think you're pretty cool...  Maybe you'll get a promotion... The cute gal/guy in the dorm next door will tell all their friends that you just  wrok their world!...   Maybe your complexion will clear up... Who knows...?  It's worth a try... :-)    So, what do you think?  Got any other ideas or suggestions?  If you do, drop me a note and I'll be glad to include it in the next column.  Who knows, maybe we'll have to write a mini-HOWTO on X Window wallpapering... :-)    See ya!    John           System Logging Ideas...     Several months ago, I had someone run a Satan attack on my home Linux system (a standalone PC connected via dialup PPP to the INTERNET) shortly after I'd gotten a dialup connection.  The idiot got no information as I had sendmail configured for remote mail queuing.  Without going into all the details, suffice it to say that after getting pretty angry about this and making several phone calls and sending email demands of explanations, the perpetrator remains anonymous.    Now, there are several things that I know next to nothing about, and UN*X/Linux security is one of them.  For my standalone system, I closed a couple holes by simply no longer loading up either inetd or sendmail at system boot.  I mention this not so much to talk about security as to segue into the topic of system logging.    After this incident, I starting wondering how to keep track of ""what's going on"" with my system in terms of processes running, login attempts, debugging/error messages, and so forth.  One solution to this was provided by a reader quite some time ago which involved dumping ALL system logging information to an unused VT by adding a stanza such as the following to /etc/syslog.conf:   *.*    /dev/tty9    I won't go into the details of this except to mention that this sends all logging information to VT number 9.      It occurred to me a bit later that I could also dump this information to a file and then run  tail  on it to see a continuous printout of the information.  Under X, this is accomplished easily by running an xterm or rxvt and then running tail on the system logging file.  To do this, you could:      Set up syslogd to print ALL logging information to a file by adding  the following to your /etc/syslog.conf:    *.*    /dev/tty9 *.*    /var/adm/syslog      This gives you a file with logging information from all facilities and  from all all levels.       Starting up an xterm or rxvt and getting a tail process running on the  logging file.  You'll obviously need read permissions on the file in order  to do this:    rxvt -sb -sl 200 -e tail -n 50 -f /var/adm/syslog &       My own preference is to use rxvt since it enjoys a much smaller memory  footprint than xterms typically do.  The  -sb  option gives me a  very handsome scrollbar;  -sl 200  saves 200 lines of output at a  time;  and the  -e  option instructs rxvt to execute everything  following it on the command line.      After doing this you can decrease the window size substantially by using a  small font.  Depending on how rxvt was compiled, you may be able to  interactively change the font size using the  ALT-<  key  combination (or the  ALT-> ) -- on rxvt version 2.18 this  causes a smaller font to be used.  You can also specify which font to use  when you invoke rxvt itself using the  -fn  option.  Using a six  or seven point font gives you a small, but still readable window.         Now, if you start up a second rxvt and run  top  in it, you'll find that this will give you a good idea of what's going on with your system.  On my box, this looks like:         Obviously, there are MUCH more elegant and sophisticated solutions than running a couple rxvt's with top and tail.  However, this is VERY easy to setup and, if you add a stanza to do this in your window manager configuration file, or add this to a menu or buttonbar, then it's very convenient as well.    I've also tinkered around with writing a small tcl/tk script that some of you might be interested in.  The  syslogtk  script is a VERY simple little program that allows you to easily view any of the logging files under /var/adm.  On startup, it adds a menu item for each readable, regular file under /var/adm which will then allow you to view that file.  It also automagically loads the /var/adm/syslog file.  I've added a couple buttons to resize the text window, move to the head and end of the file, and to update the logging (this was a bit of a kludge since I found that the  tail  process would ""hang"" after pppd terminated.  Any ideas as to why this would happen... anyone?)    I've used this for the past little bit and really like it -- especially since it lets me quickly see the status of things such as mail and print jobs. Here's a screen dump of it in its ""normal"" and ""maximized"" states:        The  syslogtk  program minimized.        The  syslogtk  program maximized.    I'm sorry that I don't have a lot of time to discuss this simple utility more. If you're interested in it, the sources are available here.  You can save the following link to file OR simply load it up in your browser and save it as a text file:   syslogtk tcl source     As usual, this comes with ABSOLUTELY NO WARRANTEE:  if anything breaks, you get to keep both pieces... :-)    I'm hoping, when I have a bit more time, to write up a simple guide to setting up and using system logging with the excellent  sysklogd  package.  For the time being, you're on your own.  BTW, I wrote syslogtk under tcl/tk versions 7.6/4.2 -- there's nothing terribly fancy in them so it'll likely work under older and newer versions as well.  Have a look at the beginning of the script file for items that you might want to customize, especially the file that gets loaded when the program starts.  The code isn't terribly robust at the moment, so if it can't find something, it'll likely just whine and do nothing...    Well, that should about do it!    Hope you have fun.  If you have any ideas or suggestions, drop me a note OR, better yet, drop the LG editor (Marjorie Richardson at SSC) a letter or article!    Cheers,    John           Closing Up The Shop     Well, again, I'm sorry that the articles have been a bit more rushed than I'd hoped this month.  I just got back from visiting Bill and Sandy Emmett -- my wife's brother and his wife and their kids -- over Easter Weekend.  We had a great time and even got to do a bit of Linux'ing!  I recently bought some old computer parts ""As Is"" from the church my wife and I attend and, after a bit of card swapping and cable twiddling, I managed to get a working 486DX/4 100 box working.  I also found that it came with an Artisoft AE/2 NIC.    Hmmm... Serious Fun on the Horizon, Good Buddy...    My brother-in-law outfitted me with an old WD-8003 card he had lying around and we were able to get some basic networking set up under Linux and Win95. So, I'm going to be learning a bit of networking!  YeeeeHaaaa!!    That is, if I ever manage to get my schoolwork done so that I can pass Calc III and Software Engineering... :-(    We'll have to see.    The other bit of news is that I'm planning on heading out to the 'ol  1997 Linux Expo  at NCSU again this year!      Time for a road trip!! :-)    I'm getting seriously excited about this as the speaker roster looks like a ""Heavy-Weight Who's Who's in the Linux Community"" round up.  The conference talks all look interesting and, if this is anything like last year's Expo, it should just be a WHOLE LOTTA FUN.  If any of you still haven't heard about this and you're within any kind of driving, flying, running, hitchhiking, or crawling distance from North Carolina State Univ., then by all means...    GO!!    There's all kinds of information available at the   Linux Expo  site.  I know that they've put in a HUGE amount of work on this together with the folks at  RedHat Software, Inc. .  Drop by the page and get the low down on speakers,  exhibitors, events, conference talks, and so forth.    Several of us from 'ol Middle Tenn State Univ. are planning on taking a road trip and making a weekend of this.  We'll be walking around with our pocket protectors and name badges like the rest of you... if you happen to see:      Brad Curtis   Steven Edwards (aka ""Maverick"")   John Hoover   or, Your's Truly...      Walk right up, introduce yourself, and shake a hand!  We'd love to chat with you.  If I get the chance, I'll bring along the 'ol Canon and try to get some shots of the going's on.  If I can get my hands on a scanner, I might even put a couple of these up in the next column (with the permission of the Expo folks, of course).    Anyway, hope to see you all there!!    Take care, Happy Linux'ing, and Best Wishes,    John M. Fisk  Nashville, TN  Sunday, March 30, 1997          If you'd like,  drop me a note at:    John M. Fisk    <fiskjm@ctrvax.vanderbilt.edu>       Last Modified: $Date: 2002/10/09 22:24:17 $                 Copyright © 1997, John M. Fisk    Published in Issue 16 of the Linux Gazette, April 1997                                         Copyright © 1997 Specialized Systems Consultants, Inc.  For information regarding copying and distribution of this material see the  Copying License .              Contents:     About This Month's Authors   Not Linux                   About This Month's Authors                  Larry Ayers  Larry Ayers lives with his family on a small farm in Northeast Missouri; he is a woodworker, fiddler and general jack-of-all-trades.      John M. Fisk  John Fisk is most noteworthy as the former editor of the  Linux Gazette . After three years as a General Surgery resident and Research Fellow at the Vanderbilt University Medical Center, John decided to "":hang up the stethoscope"":, and pursue a career in Medical Information Management. He's currently a full time student at the Middle Tennessee State University and hopes to complete a graduate degree in Computer Science before entering a Medical Informatics Fellowship. In his dwindling free time he and his wife Faith enjoy hiking and camping in Tennessee's beautiful Great Smoky Mountains. He has been an avid Linux fan, since his first Slackware 2.0.0 installation a year and a half ago.      Michael J. Hammel  Michael J. Hammel, is a transient software engineer with a background in everything from data communications to GUI development to Interactive Cable systems--all based in Unix. His interests outside of computers include 5K/10K races, skiing, Thai food and gardening. He suggests if you have any serious interest in finding out more about him, you visit his home pages at http://www.csn.net/~mjhammel. You'll find out more there than you really wanted to know.       Mike List   Mike List is a father of four teenagers, musician, printer (not laserjet), and recently reformed technophobe, who has been into computers since April,1996, and Linux since July.      Henry H. Lu  Henry H. Lu has a M.S. of Biophysics, University of Minnesota and a B.S. of Physics, Nankai University. He is currently working as contract bioinformatics analyst in HIV database of  Los Alamos National Lab in New Mexico USA, and has developed Java / HTML, C/C++, perl, shell applications and system tools  for work (Solaris environment) at home Linux box or remote login to  workstation at Lab. For fun, he likes to hack some of systems/networking programs, use Linux  to learn on-line university courses  (Operating systems / system programming, Network), and write  Java/HTML for my own web page.      Marc Welz  Marc lives in Cape Town, South Africa. He thinks that it must be one of the most beautiful  cites in the world. He should be working on his MSc, but tends to be distracted by Table Mountain, Linux or anything else.                Not Linux               Thanks to all our authors, not just the ones above, but also those who wrote giving us their tips and tricks and making suggestions. Thanks also to our new mirror sites.    Amy Kukuk was a great help this month, putting together News Bytes, More 2 Cent Tips and The Answer Guy. I'm going to be giving her more and more each month.      I've had a lot of fun going to see the ""Star Wars"" movies again. Space movies are so much more fun at a theater. I was amazed to discover that I can remember the first time I had seen each of them (theatre, company, etc.). I was pleased to see so many kids there enjoying the epic for the first time on a big screen. Riley and I had a lot of fun competing to see who recognized new scenes first (nudge, nudge). I thought they did a pretty smooth job of inserting the scenes without being annoyingly noticeable. I still have to wonder how the people of Tatooie kept the streets clean with dinosaurs as pack animals?    Have fun!           Marjorie L. Richardson  Editor,  Linux Gazette   gazette@ssc.com                     Linux Gazette  Issue 16, April 1997, http://www.ssc.com/lg/   This page written and maintained by the Editor of  Linux Gazette ,   gazette@ssc.com"
GX043-69-7303009	9. First Example: Xscrabble    Matt Chapman's  Xscrabble  seemed like a program that would be interesting to have, since I happen to be an avid Scrabble TM  player. I downloaded it, uncompressed it,  and built it following the procedure in the README file:         xmkmf      make Makefiles      make includes      make      Of course it did not work...       gcc -o xscrab -O2 -O -L/usr/X11R6/lib  init.o xinit.o misc.o moves.o cmove.o main.o xutils.o mess.o popup.o widgets.o display.o user.o CircPerc.o -lXaw -lXmu -lXExExt -lXext -lX11 -lXt -lSM -lICE -lXExExt -lXext -lX11 -lXpm -L../Xc -lXc  BarGraf.o(.text+0xe7): undefined reference to `XtAddConverter' BarGraf.o(.text+0x29a): undefined reference to `XSetClipMask' BarGraf.o(.text+0x2ff): undefined reference to `XSetClipRectangles' BarGraf.o(.text+0x375): undefined reference to `XDrawString' BarGraf.o(.text+0x3e7): undefined reference to `XDrawLine' etc. etc. etc...      I enquired about this in the   comp.os.linux.x  newsgroup, and someone kindly pointed out that apparently the Xt, Xaw, Xmu, and X11 libs were not being found at the link stage. Hmmm...  There were two main Makefiles, and the one in the  src  directory caught my interest. One line in the Makefile defined LOCAL_LIBS as: LOCAL_LIBS = $(XAWLIB) $(XMULIB) $(XTOOLLIB) $(XLIB) Here were references to the libs not being found by the linker.  Looking for the next reference to LOCAL_LIBS, I saw on line 495 of that Makefile:          $(CCLINK) -o $@ $(LDOPTIONS) $(OBJS) $(LOCAL_LIBS) $(LDLIBS) $(EXTRA_LOAD_FLAGS)      Now what were these LDLIBS?          LDLIBS = $(LDPOSTLIB) $(THREADS_LIBS) $(SYS_LIBRARIES) $(EXTRA_LIBRARIES)      The SYS_LIBRARIES were:     SYS_LIBRARIES = -lXpm -L../Xc -lXc      Yes! Here were the missing libraries.  Possibly the linker needed to see the LDLIBS before the LOCAL_LIBS... So, the first thing to try was to modify the Makefile by transposing the $(LOCAL_LIBS) and $(LDLIBS) on line 495, so it would now read:            $(CCLINK) -o $@ $(LDOPTIONS) $(OBJS) $(LDLIBS) $(LOCAL_LIBS) $(EXTRA_LOAD_FLAGS)                          ^^^^^^^^^^^^^^^^^^^^^^^      I tried running  make  again with the above change, and lo and behold, it worked this time. Of course,  Xscrabble still needed some fine tuning and twiddling, such as renaming the dictionary and commenting out some assert statements in one of the source files, but since then it has provided me with many hours of pleasure.      [Note that a newer version of Xscrabble is now available in rpm format, and this installs without problems.]        You may e-mail   Matt Chapman , and download  Xscrabble  from his   home page .                   Scrabble is a registered trademark of the Milton Bradley Co., Inc.
GX056-06-2633233	Next   Previous   Contents     9. First Example: Xscrabble    Matt Chapman's  Xscrabble  seemed like a program that would be interesting to have, since I happen to be an avid Scrabble TM  player. I downloaded it, uncompressed it,  and built it following the procedure in the README file:         xmkmf      make Makefiles      make includes      make      Of course it did not work...       gcc -o xscrab -O2 -O -L/usr/X11R6/lib  init.o xinit.o misc.o moves.o cmove.o main.o xutils.o mess.o popup.o widgets.o display.o user.o CircPerc.o -lXaw -lXmu -lXExExt -lXext -lX11 -lXt -lSM -lICE -lXExExt -lXext -lX11 -lXpm -L../Xc -lXc  BarGraf.o(.text+0xe7): undefined reference to `XtAddConverter' BarGraf.o(.text+0x29a): undefined reference to `XSetClipMask' BarGraf.o(.text+0x2ff): undefined reference to `XSetClipRectangles' BarGraf.o(.text+0x375): undefined reference to `XDrawString' BarGraf.o(.text+0x3e7): undefined reference to `XDrawLine' etc. etc. etc...      I enquired about this in the   comp.os.linux.x  newsgroup, and someone kindly pointed out that apparently the Xt, Xaw, Xmu, and X11 libs were not being found at the link stage. Hmmm...  There were two main Makefiles, and the one in the  src  directory caught my interest. One line in the Makefile defined LOCAL_LIBS as: LOCAL_LIBS = $(XAWLIB) $(XMULIB) $(XTOOLLIB) $(XLIB) Here were references to the libs not being found by the linker.  Looking for the next reference to LOCAL_LIBS, I saw on line 495 of that Makefile:          $(CCLINK) -o $@ $(LDOPTIONS) $(OBJS) $(LOCAL_LIBS) $(LDLIBS) $(EXTRA_LOAD_FLAGS)      Now what were these LDLIBS?          LDLIBS = $(LDPOSTLIB) $(THREADS_LIBS) $(SYS_LIBRARIES) $(EXTRA_LIBRARIES)      The SYS_LIBRARIES were:     SYS_LIBRARIES = -lXpm -L../Xc -lXc      Yes! Here were the missing libraries.  Possibly the linker needed to see the LDLIBS before the LOCAL_LIBS... So, the first thing to try was to modify the Makefile by transposing the $(LOCAL_LIBS) and $(LDLIBS) on line 495, so it would now read:            $(CCLINK) -o $@ $(LDOPTIONS) $(OBJS) $(LDLIBS) $(LOCAL_LIBS) $(EXTRA_LOAD_FLAGS)                          ^^^^^^^^^^^^^^^^^^^^^^^      I tried running  make  again with the above change, and lo and behold, it worked this time. Of course,  Xscrabble still needed some fine tuning and twiddling, such as renaming the dictionary and commenting out some assert statements in one of the source files, but since then it has provided me with many hours of pleasure.      [Note that a newer version of Xscrabble is now available in rpm format, and this installs without problems.]        You may e-mail   Matt Chapman , and download  Xscrabble  from his   home page .                   Scrabble is a registered trademark of the Milton Bradley Co., Inc.                Next   Previous   Contents
GX047-96-7980282	"""Linux Gazette... making Linux just a little more fun! ""             Contents:     News in General   Software Announcements                 News in General                Hardware Forums in Dallas, Texas     Readers in the Dallas, Texas area may be interested in two forums for purchasing hardware that may not exist in other areas. The first is the North Texas PC Users Group meeting. This monthly meeting is held at the Infomart in Dallas (I-35E at Oak Lawn). The meeting is held on one Saturday a month and opens at 8:00 AM. A number of reputable local vendors show up to sell hardware and software. (In fact, a few months ago the vendor area was moved from the basement to a larger room because they were running out of space.) Prices at the NTPCUG meeting are generally cheaper than these vendors have in their own stores, and these vendors offer warranties and support as well. Call NTPCUG at ? to find out when the next meeting is. And stop by the local Linux User's Group booth and say hi, or ask them to load Linux on your newly purchased machine for free.   The other venue is truly unique. The First Saturday Sale is a monthly flea market held (surprise) on the first Saturday of every month. It is held outdoors under the Ross Street bridge. Take the Pearl Ave. exit to get there. Hang a left on Ross and follow the crowd. Selling officially starts at 6:00 AM, but feel free to show up earlier.   Again, many of the vendors own local storefronts and offer the same service and warranty their storefront customers receive.   While these markets may not be the best place for a beginner to shop, a knowledgeable buyer can walk away from either of these markets with a crate of new gear at significant discounts.     -Matthew Mucker    Bedford, Texas                COMDEX/Spring '97                       Come For          the Linux Pavilion at COMDEX/Spring '97                                     Linux International (LI) will be hosting a Linux Pavilion at   COMDEX/Spring '97, which runs from June 2 - 5 in Atlanta, GA.                                   On June 7 & 8, the weekend following COMDEX/Spring '97, LI and the Atlanta Linux Enthusiasts (ALE), in cooperation with COMDEX,  will be hosting the Atlanta Linux Showcase. The Atlanta Linux Showcase will feature vendors of Linux hardware, software, and services as well as conference sessions on various Linux topics.  Attendees of COMDEX will be admitted to the showcase floor for free, and pre-registrants to the Atlanta Linux Showcase will receive free passes to the COMDEX trade show floor.   Some of the vendors on the showcase floor are:     Red Hat Software, Inc.  Caldera, Inc.  Linux Journal (Specialized Systems Consultants, Inc.)  Linux Hardware Solutions  Digital Equipment Corporation    The Atlanta Linux Showcase will be held at the Inforum in downtown Atlanta, GA, just a few blocks away from the Georgia World Congress Center, site of COMDEX/Spring '97.  The show floor will be open from 9 a.m. to 5 p.m. on Saturday, June 7, and from 9 a.m. to 3 p.m. on Sunday, June 8.  The conference sessions will run concurrently.   The Inforum is located at 250 Williams St., Atlanta, GA.   More information on the Atlanta Linux Showcase can be found at    http:www.ale.org/showcase      More informaiton on COMDEX/Spring '97 can be found at    http://www.comdex.com/comdex/owa/event_home?v_event?id=26                  Announcing IT Horizon '97 Symposiom    The Fisher Center for Information Technology and Management, Walter A. Hass School of Business , UC Berkley announces:  IT Horizon '97 Symposiom, Workshop and Solutions Showcase   ""From the NC to the Networked Enterprise:   Thin Clients, Robust Servers, Universal Access""   June 9-11   Red Lion Hotel, San Jose, CA    Send you submission(s) by April 4, 1997 to Deborah Murray, Director-Professional Training, UniForum Association, 2901 Tasman Drive, Suite 205, Santa Clara, CA 95054 -OR- E-mail to   dmurray@uniforum.org                 Linus News      Linus Torvalds received Uniforum's ""Lifetime Achievement Award"" for his work on Linux.  Linus (as always) pointed out that he would accept the award, but that it really belonged to the entire Linux development community.  The award, which has been presented annually since 1983, recognizes individuals or groups whose work has significantly advanced the cause of open systems over time, or has had an immediate and positive impact on the industry with long term ramifications.  To give the idea of others who have received it, James Gosling also accepted an award at this meeting for his work on Java.  Linus was in good company.   You can see pictures of him receiving the award at:    http://daily.comdex.com/events/uf97/photos3.htm                HOWTO Update     A major update of the Linux Commercial HOWTO, a listing of commercial software products for Linux, has been published.  The new release includes new categories, descriptions of more software packages than ever and updates of existing entries.   The listing can be obtained from its primary site at   http://www.cyrius.com/tbm/Commercial-HOWTO  and from LDP mirrors all around the world.                Software Announcements                Announcing Decision PCCOM8    Announcing the availability of a Linux driver for the  Decision PCCOM8 multiport serial card.   Signum Support, a company specialising in free software support and Linux, was approached by MYDATA Automation AB, a Swedish robotics company, to write a Linux device driver for the Decision PCCOM8 multi-port serial card. The driver and was written by Christer Weinigel (wingel@signum.se) and Mikael Cardell (mc@signum.se). Any questions regarding this driver can be sent to   pccom8@signum.se               Announcing the Shuttle Connection (EPST)    Signum Support, a company specialising in free software support and Linux, was approached by MYDATA Automation AB, a Swedish robotics company, to write a Linux device driver for a parallel port SCSI interface.  This driver for the Shuttle Connection was written by Christer Weinigel wingel@signum.se  at Signum Support.  This driver can be found as  ftp://ftp.signum.se/pub/epst/epst-0.9.diff   The diff was made against a version 2.0.29 kernel.  This driver (probably)  still contains bugs and should be considered as ALPHA software.  Please note that there exists two incompatible devices, both which are called `Shuttle Connection'.  To find out what model you have, take a look at the sticker on the back of the device, you ought to see either `EPSA' or `EPST' written on it.  This driver is works with the EPST model; if you own an EPSA model, take a look at   http://www.torque.net/epsa.html  where you'll find a device driver for that device.   Any questions regarding this driver can be sent to    epst@signum.se                  New Release of mtools     Announcing a new release of mtools, a collection of utilities to access MS-DOS disks from Unix without mounting them.  Mtools-3.3 fixes a typo in mdel, which made it command unusuable.  Mtools supports Win'95 style long file names, OS/2 Xdf disks and 2m disks (store up to 1992k on a high density 3 1/2 disk).  The most notable new feature (over 3.1) is FAT 32 support. There is also mpartition, a simple partitioning programing to setup Zip and Jaz media on non-PC machines (SunOs, Solaris and HP/UX).   Mtools can currently be found at the following places:     http://linux.wauug.org/pub/knaff/mtools    http://www.club.innet.lu/~year.mtools     and soon at:     ftp://prep.ai.mit.edu/pub/gnu/mtools-3.3.src.tar.gz     ftp://pub/Linux/utils/disk-management/mtools-3.3.src.tar.gz   ftp://tsx-11.mit.edu/pub/linux/wources/usr.bin/mtools-3.3.src.tar.gz      There is an mtools mailing list at   mtools@linux.wauug.org .  To subscribe to it, send a message containing 'subscribe mtools' in its body to  majordomo@linux.wauug.org.              gv 2.9.4 Announcement      gv 2.9.4 is now available.  gv allows to view and navigate through PostScript and PDF documents on an X display by providing a user interface for the ghostscript interpreter. It may be obtained either from its homepage at:    http://wwwthep.physic.uni-mainz.de/~plass/gv/""   or via anonymous ftp from:      ftp://thep.physik.uni-mainz.de/pub/gv    Please note that gv is derived from Tim Theisen's ghostview 1.5.   gv surely works on           Linux (gcc 2.7.2.1)         OpenVMS AXP (DECC 5.2,DECC 5.0)        I also got reports of happy users on           Solaris         FreeBSD         NetBSD         Digital UNIX         SunOS         HP/UX         Irix         OSF/1     gv requires Kaleb Keithley's Xaw3d widget set.    VMS users will find everything needed to install this widget set at    the locations listed above.  For Unix users working on a system not equipped with this widget set    the page  http://wwwthep.physik.uni-mainz.de/~plass/gv/Xaw3d.html   may     provide some assistance when trying to install it.               SafePassage Web Proxy     Oakland, CA -- C2Net Software, Inc., and UK Web, Ltd., announced  the 1.0 release of a new product, ""SafePassage Web Proxy."" This product, developed entirely outside of the United States, provides full-strength, non-escrowed cryptography for users of any standard web browser.   SafePassage is an enhancement for ""export"" browsers, an add-on product that works with any standard web browser. Acting as an intermediary, or proxy, it intercepts weakly encrypted connections on their way out and transforms them to use full-strength cryptography.  ""The weak connection never leaves your PC,"" explains Parekh, ""it gets decrypted and then re-encrypted with a full-strength cipher.""   SafePassage provides secure connections using strong cryptography for any browser that supports standard SSL tunneling, a feature normally used by firewall software. It currently runs on Windows 3.1, Windows 95, and Windows NT.   Evaluation versions of SafePassage can be downloaded at no cost from UK Web's site at:  http://stronghold.ukweb.com/safepassage  It is currently unavailable for distribution within the US and Canada, but a domestic version will be made available in the near future. A single- user license is $49, prices for volume licensing start at $995 for fifty users.              Announcing Turbo Vision 0.3    Turbo Vision (or TV, for short) is a library that provides an application framework.  With TV you can write a beautiful object-oriented character-mode user interface in a short time.  TV is available in C++ and Pascal and is a product of Borland International. It was developed to run on MS-DOS systems, but today it is available for many other platforms (ported by independent programmers).  This port is based on the Borland 2.0 version with fixes.   Main changes from version 0.2 to 0.3    Added support for the FreeBSD operating system.  Added support for colored output.  evMouseAuto event fixed.  Some bugs fixed.    Where to download the library    ftp://sunsite.unc.edu/incoming/Linux   ftp://ftp.cdrom.com/pub/FreeBSD/incoming     If you don't want to wait the file to be moved to the destination directories, you can download a copy of it from:  ftp://ftp.cdrom.com/pub/FreeBSD/incoming/tvision-0.3.tar.gz               Announcing the Release of TeamWave Workplace 1.0     TeamWave Software Ltd. is pleased to announce the release of TeamWave Workplace 1.0, an Internet groupware product that lets you work  together with colleagues in real-time or asynchronously, using Macintosh, Windows or Unix platforms.  Check us out at  http://www.teamwave.com                Release of Samba SMB File Server    The release of Samba SMB File Server has been announced.  The server includes support for Western European Languages in filenames served by Samba, allowing Western European users of Microsoft Windows(tm) products to store native language filenames on their UNIX file servers.   Although this is a new minor version release, there have been many bugfixes and improvements from previous releases.    The new verson is available on a GNU gziped tar file from    ftp://samba.anu.edu.au/pub/samba/samba-1.9.16p11.tar.gz     and should be available from mirror sites throughout the world shortly. For details see the main Web site  for information about Samba, at :   http://samba.canberra.edu.au/pub/samba               Announcing UNIPEN-related Software Package     UPTOOLS3  This is to announce the new release of the UNIPEN-related  software package (works great on Linux, too):  This UNIX software is mainly intended for researchers in on-line handwriting recognition. It allows for a hierarchical annotation of on-line handwritten data coming from XY digitizers or pen computers. The software is _not_ intended for processing off-line (i.e., optically scanned) handwriting data.  The purpose of this software is to stimulate the use of the UNIPEN file format for on-line handwriting recognition research. This is the same data format as is used within the UNIPEN recognizer benchmark project  http://hwr.nici.kun.ml/unipen/      upview-An X-Windows program for quickly visualizing                UNIPEN files.  upread-A program for transforming or extracting data                from any UNIPEN file.   upworks-A large program using Tcl/Tk on X-Windows for                browsing through UNIPEN files, and editing or                entering .SEGMENTS. Time series of essential signals               can be viewed. There are many options for changing                graphical attributes (such as the color of segments).   uni2animgif-A program for transforming data from any UNIPEN                file into animated GIF images.  unipen2eps-A program for transforming data from any UNIPEN                file into encapsulated PostScript.    An introduction to UPTOOLS3 can be found at:   http://hwr.nici.kun.nl/uniopen/uptools3    The new software is available via ftp at:   ftp://ftp.nici.kun.nl/pub/INIPEN/tools/uptools3.tar.gz               Announcing Ghostscript System 0.2.0       The Display Ghostscript System is a free software implementation of a Display PostScript(tm) System.  A Display PostScript System provides a device-independent imaging model for displaying information on a screen. The imaging model uses the PostScript language which has powerful graphics capabilities and frees the programmer from display-specific details like screen resolution and color issues.    The Display Ghostscript System is composed of a PostScript interpreter (Ghostscript), the Client library, and the pswrap translator.     The Display Ghostscript System uses a client/server architecture. Applications are linked with the Client library which communicates with the PostScript interpreter residing in the server.  The application utilizes the procedures and data structures in the Client library which are independent of the actual PostScript interpreter.      The pswrap translator allows you to take custom PostScript language programs and wrap them with a C function interface thus allowing your applications to call them directly.  pswrap programs are generally more efficient then performing the same PostScript program purely with the Client library procedures.   The dgs-0.2.0.tar.gz distribution file has been placed on  ftp.gnustep.org/pub/gnustep    The program requires gcc 2.7.2.1 or higher.   The `.tar' file is compressed with GNU gzip.  Gzip can be obtained by anonymous ftp at any of the GNU archive sites.   For info about FTP via email, send email to  ftpmail@decwrl.declcom  with no subject line, and two-line body with line one `help' and line two `quit'.   The most recent (not necessarily tested) snapshots of the library will be placed in  ftp://alpha.gnu.ai.mit.edu.gnu/gnustep               GA Plug-In for NExS Spreadsheet Available Now      X Engineering Software Systems (XESS Corp.) announces the immediate availability of a genetic algorithm (GA) plug-in for its NExS spreadsheet. Those interested in the genetic algorithm plug-in can download the source code and a PostScript manual from www.xess.com. A free, 30-day version of the NExS spreadsheet and the new conNExions-BETA API can also be downloaded for the HP/UX, AIX, Digital UNIX, SunOS, Solaris and Linux platforms.   Genetic algorithms (GA) solve optimization problems by modeling potential solutions as chromosomes which can breed with one another to produce better solutions through the forces of natural selection.   The GA plug-in provides one new NExS function: @GENALG(...) which optimizes a fitness function that is affected by a group of 1/0 variables in the sheet. Any NExS function or combination of functions can be used to specify the fitness function.   The GA plug-in interacts with the NExS spreadsheet through the conNExions-BETA API. The source code for the plug-in is being made available for modification and customization.              Annouunicing MkLinux DR2.1      We are pleased to announce the release of MkLinux DR2.1. DR2.1 includes support for the Power Macintosh 601/NuBus 601/PCI bus and 604/PCI bus systems: the Power Macintosh 6100, 7100, and 8100; 7200; 7500, 7600, 8200, 8500, and 9500.  (Support for 603-based systems is forthcoming but is not yet available.  DR2.1 does not yet support Powerbooks or most Performas at this time.)   DR2.1 is our third Developer Release of MkLinux and the first Release to be included in our Reference Release, published by Prime Time Freeware (PTF). The MkLinux Reference Release consists of a 360-page book and 2 CD-ROMs: the Apple MkLinux DR2.1 disc and PTF's Reference disc, packed with lots of interesting and useful reference material.  (The two CD-ROMs are each also sold separately.)   The MkLinux Reference Release is available by mail order from PTF and other vendors, and is also available through many technical bookstores, as are the individual discs.  Contact Prime Time Freeware for details at info@ptf.com or visit their Web site at www.ptf.com.   MkLinux is available both on CD-ROM and by anonymous ftp download from   ftp://ftp.mklinux.apple.com  and our various mirror sites. (Please be patient with the mirror sites; it may take some of them a while to get DR2.1 ready for downloading!).   With the release of DR2.1, DR2 will no longer be available or supported. We will retain the DR2 ""Help and Support"" information on our Web pages, but DR2 itself will be removed from our FTP server.    Check out the Web site at: http://www.mklinux.apple.com/DR2.1  for more information on this release.  All Readme files from the DR2.1 Distribution, including the Release Notes (Readme First) and the Installation Guide (How to Install MkLinux) are reproduced on our Web pages.              Metro-X 3.1.5 Now Shipping     Metro Link is now shipping Metro-X 3.1.5. This is an updated version of Metro-X 3.1.2 for Linux, which is a commercial X server replacement for use with XFree86. It contains various fixes and support for the following additional cards:         Diamond Stealth 64 Graphics 2200       Diamond Stealth 64 Video VRAM V1.xx (TI 3026 DAC)       Diamond Stealth 64 Video VRAM V3.xx (IBM DAC)       ELSA WINNER 1000TRIO/V (TRIO64V+)       ELSA Winner 2000AVI       ELSA Winner 2000PRO/X (TI 3026 DAC)       Number Nine I-128 series 2       Toshiba Tecra 720CDT (CHIPS 65550)    For a complete list of supported cards, see our cardlist:     http://www.metrolink.com/products/metrox/cardlist.html   For more details look at the complete product description:    http://www.metroling.com/products.metrox.ess.html    PRICE FOR LINUX VERSION:   New Purchase: $99    Upgrade from earlier release: $69     CONTACT INFORMATION:    Metro Link, Inc.  http://www.metrolink.com  and  sales@metrolink.com            Published in Linux Gazette Issue 16, April 1997                       This page written and maintained by the Assistant Editor of  Linux Gazette ,  gazette@ssc.com   Copyright © 1997 Specialized Systems Consultants, Inc."
GX251-79-4164492	Advanced Bash-Scripting Guide: A complete guide to shell scripting, using Bash Prev Chapter 36. Endnotes Next 36.2. About the Author Who is this guy anyhow? The author claims no credentials or special qualifications,  other than a compulsion to write.            [1]   This book is somewhat of a departure from his other major work,    HOW-2 Meet Women: The Shy Man's Guide to  Relationships . He has also written the  Software-Building  HOWTO . A Linux user since 1995 (Slackware 2.2, kernel 1.2.1),  the author has emitted a few  software truffles, including the  cruft   one-time pad encryption utility, the  mcalc   mortgage calculator, the  judge   Scrabble adjudicator, and the  yawl   word gaming list package. He got his start in programming using  FORTRAN IV on a CDC 3800, but is not the least bit nostalgic  for those days. Living in a secluded desert community with wife and dog,          he cherishes human frailty. Notes [1] Those who can, do. Those who can't... get an    MCSE. Prev Home Next Author's Note Up Tools Used to Produce This Book
GX186-21-0713819	"README for XFree86 4.1.0 on OpenBSD    :   Running X   Previous:   Configuring X for Your Hardware   Next:   Kernel Support for X         6. Running X     6.1. Starting xdm, the display manager   To start the display manager, log in as root on the console and type: `` xdm -nodaemon ''.   You can start xdm automatically on bootup by changing the line     xdm_flags=NO            # for normal use: xdm_flags=""""      to:    xdm_flags=""""            # for normal use: xdm_flags=""""      in  /etc/rc.conf .     Note that the binary distributions of XFree86 for OpenBSD on ftp.xfree86.org and its mirrors don't include support for the XDM-AUTHORIZATION-1 protocol, because of the US export  rules.     6.2. Running X without the display manager   The easiest way for new users to start X windows is to type: `` startx >& startx.log ''.  Error messages are lost unless you redirect them because the server takes over the screen.   To get out of X windows, type: `` exit '' in the console xterm. You can customize your X by creating  .xinitrc ,  .xserverrc , and  .twmrc  files in your home directory as described in the xinit and startx man pages.       README for XFree86 4.1.0 on OpenBSD    :   Running X   Previous:   Configuring X for Your Hardware   Next:   Kernel Support for X"
GX212-24-11982881	"README for XFree86 4.0 on OpenBSD    :   Running X   Previous:   Configuring X for Your Hardware   Next:   Kernel Support for X         6. Running X     6.1. Starting xdm, the display manager   To start the display manager, log in as root on the console and type: `` xdm -nodaemon ''.   You can start xdm automatically on bootup by changing the line     xdm_flags=NO            # for normal use: xdm_flags=""""      to:    xdm_flags=""""            # for normal use: xdm_flags=""""      in  /etc/rc.conf .     Note that the binary distributions of XFree86 for OpenBSD on ftp.xfree86.org and its mirrors don't include support for the XDM-AUTHORIZATION-1 protocol, because of the US export  rules.     6.2. Running X without the display manager   The easiest way for new users to start X windows is to type: `` startx >& startx.log ''.  Error messages are lost unless you redirect them because the server takes over the screen.   To get out of X windows, type: `` exit '' in the console xterm. You can customize your X by creating  .xinitrc ,  .xserverrc , and  .twmrc  files in your home directory as described in the xinit and startx man pages.       README for XFree86 4.0 on OpenBSD    :   Running X   Previous:   Configuring X for Your Hardware   Next:   Kernel Support for X"
GX184-51-14054868	"README for XFree86 4.3.99.901 on OpenBSD    :   Running X   Previous:   Configuring X for Your Hardware   Next:   Kernel Support for X         6. Running X     6.1. Starting xdm, the display manager   To start the display manager, log in as root on the console and type: `` xdm -nodaemon ''.   You can start xdm automatically on bootup by changing the line     xdm_flags=NO            # for normal use: xdm_flags=""""      to:    xdm_flags=""""            # for normal use: xdm_flags=""""      in  /etc/rc.conf .     Note that the binary distributions of XFree86 for OpenBSD on ftp.xfree86.org and its mirrors don't include support for the XDM-AUTHORIZATION-1 protocol, because of the US export  rules.     6.2. Running X without the display manager   The easiest way for new users to start X windows is to type: `` startx >& startx.log ''.  Error messages are lost unless you redirect them because the server takes over the screen.   To get out of X windows, type: `` exit '' in the console xterm. You can customize your X by creating  .xinitrc ,  .xserverrc , and  .twmrc  files in your home directory as described in the xinit and startx man pages.       README for XFree86 4.3.99.901 on OpenBSD    :   Running X   Previous:   Configuring X for Your Hardware   Next:   Kernel Support for X"
GX010-92-2040426	Pileated woodpecker                 Dryocopus pileatus
GX225-69-8469202	"README for XFree86 4.0.2 on OpenBSD    :   Running X   Previous:   Configuring X for Your Hardware   Next:   Kernel Support for X         6. Running X     6.1. Starting xdm, the display manager   To start the display manager, log in as root on the console and type: `` xdm -nodaemon ''.   You can start xdm automatically on bootup by changing the line     xdm_flags=NO            # for normal use: xdm_flags=""""      to:    xdm_flags=""""            # for normal use: xdm_flags=""""      in  /etc/rc.conf .     Note that the binary distributions of XFree86 for OpenBSD on ftp.xfree86.org and its mirrors don't include support for the XDM-AUTHORIZATION-1 protocol, because of the US export  rules.     6.2. Running X without the display manager   The easiest way for new users to start X windows is to type: `` startx >& startx.log ''.  Error messages are lost unless you redirect them because the server takes over the screen.   To get out of X windows, type: `` exit '' in the console xterm. You can customize your X by creating  .xinitrc ,  .xserverrc , and  .twmrc  files in your home directory as described in the xinit and startx man pages.       README for XFree86 4.0.2 on OpenBSD    :   Running X   Previous:   Configuring X for Your Hardware   Next:   Kernel Support for X"
GX062-48-2014483	"Copyright © 1996-97 Specialized Systems Consultants, Inc.  linux@ssc.com                 Welcome to Linux Gazette!       Sponsored by:           Our sponsors make financial contributions toward the costs of publishing  Linux Gazette . If you would like to become a sponsor of  LG , e-mail us at  sponsor@ssc.com .                    Table of Contents   June 1997 Issue #18                The Front Page    The MailBag      Help Wanted -- Article Ideas   General Mail     More 2 Cent Tips     A Fast and Simple Printing Tip   Grepping Files ina Directory Tree   ViRGE Chipset   Maintaining Multiple X Sessions   Automatic File Transfers   Setting Up Newsgroups   Color Application in X   X With 256 Colors   Video Cards on the S3/ViRGE   C Source With Line Numbers   ncftp Vs. ftplib   Domain & Dynamic IP Names   netcfg Tool   Putting Links to Your Dynamic IP   Hard Disk Duplication   Untar and Unzip     News Bytes       News in General   Software Announcements     The Answer Guy , by James T. Dennis    Networking Problems   Fetchmail   Procmail   Tcl/tlk Dependencies   /var/log/messages   OS Showdown   Adding Linux to a DEC XLT-366   Configuration Problems of a Soundcard   Procmail Idea and Question   UUCP/Linux on Caldera   ActiveX For Linux   What Packages Do I Need?   Users And Mounted Disks   [q] Map Left Arrow to Backspace   Adding Programs to Pull Down Menus   Linux and NT   pcmcia 28.8 Modems and Linux 1.2.13 Internet Servers     bash Strng Manipulations , by Jim Dennis  Brave GNU World , by Michael Stutz  Building Your Linux Computer Yourself , by Josh Turial  Cleaning Up Your /tmp, The Safe Way , by Guy Geens  Clueless at the Prompt: A Column for New Users , by Mike List  DiskHog: Using Perl and the WWW to Track System Disk Usage , by Ivan Griffin  dosemu & MIDI: A User's Report , by Dave Phillips  Graphics Muse , by Michael J. Hammel  New Release Reviews , by Larry Ayers    Bomb: An Interactive Image Generator      On-The_Fly Disk Compression   Xlock and Xlockmore     Red Hat Linux: Linux Installation and Getting Started , by Henry Pierce  SQL Server and Linux: No Ancient Heavenly Connections, But... , by Brian Jepson  The Weekend Mechanic , by John M. Fisk  The Back Page      About This Month's Authors   Not Linux               A.L.S.                  The Answer Guy                           The Weekend Mechanic                  TWDT 1 (text)   TWDT 2 (HTML)  are files containing the entire issue: one in text format, one in HTML.  They are provided  strictly as a way to save the contents as one file for later printing in the format of your choice;  there is no guarantee of working links in the HTML version.          Got any  great  ideas for improvements!  Send your  comments, criticisms, suggestions and ideas.     This page written and maintained by the Editor of  Linux Gazette ,   gazette@ssc.com    ""Linux Gazette... making Linux just a little more fun! ""             The Mailbag!    Write the Gazette at   gazette@ssc.com     Contents:     Help Wanted -- Article Ideas   General Mail                 Help Wanted -- Article Ideas                Date: Wed May 28 11:16:14 1997  Subject: Help wanted: 2.1.40 will not boot  From: Duncan Simpson,  D.P.Simpson@ecs.soton.ac.uk    2.1.40 dies after displaying the message Checking whether the WP bit is honored even in supervisor mode...   A few prints hacked in later reveals that in enters the page fault handler, detects the bootup test and gets to the end of the C (do_fault in traps.c). However it never gets back to continue booting---exactly where it gets lost is obscure.   Anyone have any ideas/fixes?   Duncan               Date: Fri, 16 May 1997 16:17:47 -0400  Subject: CD-ROMs  From: James S Humphrye,  humpjs@aur.alcatel.com    I just found the LG today, and I have read most of the back issues... Great job so far! Lots of really useful info in here!   Now to my ""problem"". I installed Slackware 3.0, which went just fine. I had XFree86 and all the goodies working perfectly (no, really, it all worked just great!) Then I upgraded my machine to a P150, and installed a Trident 9660) PCI video card. Then the X server wasn't happy any more. So...I upgraded the kernel sources to 2.0.29, got all the required upgrades for GCC, etc. I built a new kernel, and it was up and running...sort of.   Despite having compiled in support for both IDE and SCSI CDROMs, I can only get the IDE one to work. I have edited the rc.* scripts, launched kerneld, run depmod -s, and all the other things the docs recommend.   I have rebuilt the kernel to zdisk about 25 times, trying different combinations of built-in and module support, all to no avail. When the  system boots, the scsi host adapter is not detected (it is an AHA1521, located on a SB16/SCSI-2 sound card, and it worked fine under 1.2.13 & 1.3.18 kernels)  When the aha152x module tries to load, it says it does not recognize scd0 as a block device. If I try to mount the SCSI unit, it says ""init_module: device or resource busy"". Any advice would be welcome. What I want is to at least be able to use the SCSI CDROM under Linux, or better yet, both it and the IDE CDROM...   There are also a bunch of messages generated by depmod about unresolved symbols that I don't understand, as well as a bunch of lines generated by modprobe that say ""cannot locate block-major-XX"" (XX is a major number, and the ones I see are for devices not installed or supported by the kernel) The second group of messages may be unimportant, but I don't know..   Thanks in advance, Steve              Date: Mon, 26 May 1997 12:18:40 -0700  Subject: Need Help From Linux Gazette  From: Scott L. Colantonio,  scott@burbank.k12.ca.us    Hi...  We have Linux boxes located at the remote schools and the district office.  All remote school clients (Mac, WinNT, Linux) attempting to access the district office Linux boxes experience a 75 second delay on each transaction.  On the other hand, we do not experience any delay when district office clients (Mac, WinNT, Linux) attempt to access the remote school Linux boxes.  The delay began when we moved all the remote school clients to a separate network (and different ISP) than the district office servers.   To provide a map, consider this:   remote school <-> city hall city hall <-> Internet Internet <-> district office   We experience a 75 second delay:   remote school client -> city hall -> Internet -> District office Linux box   We do not experience any delay: remote school client -> city hall -> Internet   We do not experience any delay: city hall -> Internet -> District office Linux box   We do not experience any delay: District office client -> Internet -> city hall -> remote school Linux box  ...   The remote schools use a Linux box at City Hall for the DNS.   In effect, the problem is isolated to the remote school clients connecting to the district office Linux boxes, just one hop away from city hall.   As a result, the mail server is now a 75 second delay away from all educators in our district.  Our Cisco reps do not think, after extensive tests, that this is a router configuration problem.   I setup a Microsoft Personal web server at the district office to test if the delay was universal to our route.  Unfortunately, there was no delay when remote school clients attempted to access the MS web server.   Is this a known Linux network problem? Why is this a one-way problem?   Any help would be greatly appreciated.   Scott L. Colantonio             Date: Thu, 1 May 1997 16:16:58 -0700  Subject: inetd   From: Toby Reed,  toby@eskimo.com     I have a question for the inetd buffs out there...perhaps something like xinetd or a newer version has the capability to do the job, but what I want is this:   normal behavior: connect to inetd look in /etc/inetd.conf run program  enhanced behavior: connect to inetd find out what hostname used to connect to inetd look in /etc/inetd.conf.hostname if it exists, if not, use /etc/inetd.conf run program listed in /etc/inetd.conf    So if dork1.bob.com has the same IP address as dork2.bob.com, inetd would still be able to distinguish between them. In other words, similar to the VirtualHost directive in Apache that allows you to make virtual hosts that have the same IP address, except that with inetd.   Or, depending on the hostname used to access inetd, inetd could forward the request to another address.   This would be extremely useful in many limited-budget cases where a multitude of IPs are not available. For example, in combination with IP masquerading, would allow a lan host to be accessed transparently both ways on all ports, so long as it was accessed by a hostname, not an IP address. No port masquerading or proxies would be required unless the service needed was very very special. Even non-inetd httpd servers would work with this kind of redirection because the forwarded connection would still be handled by httpd on the machine with the masqueraded machine.   Anyone know if this already exists or want to add to it so I can suggest it to the inetd group?   -Toby             Date: Thu, 8 May 1997 08:05:03 -0700 (PDT)  Subject: S3 Virge Video Board  From: Tim Gray & Family,  timgray@lambdanet.com    I have a Linux box using a S3 Virge video board with 4 meg Ram.  The problem is that X refuses to start with no other color depth than 8bpp.  As X is annoying at 8bpp (Color flashing on every window and several programs complain about no free colors) Is there a way to FORCE X to start in 16 bpp?   using the command ....   startx -bpp 16 does not work and erasing the 8bpp entry in the XF86Config file causes X to self destruct. Even changing the Depth from 8 to 16 causes errors..  Anyone have experience with this X server?               Date: Fri, 9 May 1997 09:20:05  Subject: Linux and NT  From: Greg McNichol,  mcnichol@mcs.net    I am new to LINUX (and NT 4.0 for that matter) and would like any and all  information I can get my hands on regarding the dual-boot issue. Any help  is appreciated.   --Greg             Date: Wed, 14 May 1997 00:02:04  Subject: Help with CD-ROM   From: Ralph,  ralphs@kyrandia.com    I'm relatively new to Linux...not a coder or anything like that...just like messing with new things....anyways I have been running Linux for about a year now and love the H*** out of it. About two weeks ago I was testing some HD's I picked up used with this nifty plug and play bios I got and when I went to restore the system back to normal and now my CD-Rom does not work in Linux...I booted back into 95 and it still worked so I tried forcing the darn thing nothing, nada , zero. I booted with the install disks and still no CD-Rom...its on the 2nd eide set for cable select I tried removing the 2nd hard drive and moving it there still nothing....can anyone give me some more suggestions to try?              Date: Thu, 15 May 1997 12:40:27 -0700  Subject: Programming in C++  From: Chris Walker,  crwalker@cc.weber.edu    Hi, I'm Chris Walker.  I'm an undergrad computer science major at Weber State University. During my object oriented programming class Linux was brought up. The question was asked ""if c++ is so good for programs that are spread over different files or machines, why are Linux and Unix programmed in c not c++?"" I was hoping that you may have an answer.  Has anyone converted Linux source to c++, would there be any advantages/disadvantages?   Thanks,  Chris Walker              Date: Thu, 15 May 1997 11:27:17 -0700 (PDT)  Subject: Programming Serial Ports  From: Celestino Rey Lopez,  claude@idecnet.com    First of all congratulations for your good job in the Linux Gazette. I'm interested in programming the serial ports in order to get data from other computers or devices. In other Unixes it is possible, via ioctl, to ask the driver to inform a process with a signal every time a character is ready in the port. For example, in HP-UX, the process receive a SIGIO signal. In Linux SIGIO means input/output error. Do you know where can I get information about this matter? Is there any books talking about that?   Thanks in advance and thanks for providing the Linux community with lot of tricks, ideas and information about this amazing operating system.   Yours,  Celestino Rey Lopez.                 General Mail                Date:Fri, 16 May 1997 10:53:18   Subject: Response to VGA-16 Server in LG Issue 17  From: Andrew Vanderstock,  Andrew.van.der.Stock@member.sage-au.org.au    I'll look into it, even though VGA_16 has a very short life. Yes, he is correct, there isn't much in the way of testing dual headedness with a herc card and VGA16, as both are getting quite long in the tooth. VGA_16 disappears in a few months to reappear as the argument -bpp 4 on most display adapters. One bug fixer managed to re-enable Herc support in the new source tree a while back, so there may be life there yet.    Also, there was one 2c issue that was a little out of whack in regards to linear addressing. The Cirrus chipsets are not fabulous, but many people have them built into their computers (laptops, HP PC's etc).    All I can suggest is that he try startx -- -bpp 16 and see if that works. If it doesn't have a look at the release notes for his chipset. If all else fails, report any XFree bugs to the bug report cgi on www.xfree86.org   I'll ask the powers that be if I can write an article for you on XFree86 3.3, the next version of the current source tree, as it is due soon. How many words are your articles generally?   Andrew Vanderstock               Date: Sat, 24 May 1997 01:32:29 -0700  Subject: Secure Anonymous FTP setup mini-howto spotted, then lost  From: Alan Bailward,  ajb@direct.ca    I saw once on a friend of mines linux box, running Slackware 3.1, in /usr/docs/faq/HOWTO/mini, a mini-howto on how to setup a secure anonymous FTP server.  It detailed how to setup all the directories, permissions, and so on, so you could upload, have permissions to write but not delete on your /incoming, etc etc etc.  It looked like a great doc, but for the life of me I can't find it!  I've looked on the slackware 3.2 cdrom, the 3.1 cdrom, searched all through the net, but to no avail.  As I am trying to setup an anonymous ftp site now, this would be invaluable... I'd feel much better reading it than 'chmod 777'ing all over the place :)   If anyone has seen this document, or knows where it is, please let me know.  Or even if there is another source of this type of information, I would sure appreciate it sent to me at  ajb@direct.ca    Thanks a lot, and keep on Linuxing!   alan              Date: Mon, 26 May 1997 13:21:20 +0800  Subject: Tuning XFree86  From: Soh Kam Yung,  kysoh@ctlsg.creaf.com    I've been reading Linux Gazette since day one and it has been great. Keep up the good work.   I've been seeing comments and letters in the Gazette from people who are having trouble with their XFree86.  Well, here's a tip for those not satisfied with the way their screen looks (offset to one side, too high/wide, etc.).   While looking through the XFree86 web site for tips on how to tweak my XF86 configuration, I noticed a reference to a program called xvidtune. Not many people may have heard about it, but it is a program used to tune your video modes.  Among its features include:    the ability to modify your graphics screen 'on-the-fly'.  You can move the screen, strech/compress it vertically or horizontally and see the results.   it can generate a modeline of the current screen setting.  Just copy it into the correct area of your XF86Config file and the next time you start up the XFree86 server, the screen will come up the way you like it.    Just run xvidtune and have fun with it!  But be careful: as with XFree86 in general, it does not guarantee that the program will not burn your monitor by generating invalid settings.  Fortunately, it has a quick escape (press 'r' to restore your previous screen settings).   Regards, -- Soh Kam Yung              Date: Fri, May 30 1997 12:34:23  Subject: Certification and training courses for Linux   From: Harry Silver,  hsilver@pyx.net    I am currently on a mailing list for consultants for Red Hat Linux. One of my suggestions to that list is contained below. I truly hope as part of a broader international initiative, Linux International will pick up the ball on this one so as to ensure that Linux generically will survive. I truly hope that someone from your organization will follow up both with myself and with the Red Hat consulting mailing list as to a more generic Linux support effort in this  area. All that would be required is gathering up the  manuals from the older Unixware CNE course and 'porting' them to Linux and creating an HTMLized version. This  along with online testing could easily generate a reasonable  revenue stream for the generic Linux  group involved.   Respectfully,   MY SUGGESTION: About two years ago, Novell still had Unixware before sending it over to the care of SCO. At the time Unix  was under the stewardship of Novell, a Unixware CNE course was developed. Since, Ray Noorda of Caldera and former CEO  of Novell is also an avid supporter of Linux as well as the  good folks at Red Hat and other distributions, rather than  RE-INVENT the wheel so to speak, wouldn't it make more sense  to pattern certification AFTER the Unixware CNE courses by  'porting' the course to Linux GENERICALLY ?    Harley Silver              Date: Fri, 24 May 1996 11:39:25 +0200  Subject: Duplicating a Linux Installed HD  From: Dietmar Kling,  kling@tao.de    Hello.  I did duplicate my Hard disk before you release this articles for it. A friend of mine new to linux tried to do it, too using your instructions. But we discovered, when he copied my root partition, that he couldn't compile anything on his computer afterwards. A bug in libc.so.5.2.18 prevented his old 8 MB Machine from runnig make or gcc. it always aborted with an error. After updating libc.so5.2.18 and running ldconfig the problem was solved.   We had a SuSe 4.0 installation.   Dietmar                Date: Sat, 10 May 1997 16:09:29 +0200 (MET DST)  Subject: Re: X Color Depth  From: Roland Smith,  rsmit06@ibm.net    In response to Michael J. Hammel's 2cent tip in issue #17:  I disagree that a 16bit display displays less colors than a 8 bit display.    Both kinds of displays use a colormap. A color value is nothing more than an index into a color map, which is an array of red,green,blue triplets, each 8 bits. The amount of colors that can be shown simultaneously depends on the graphics hardware.   An 8bit display has an eight bit color value, so it can maximally have 256 different color values. The color map links these to 256 different colors which can be displayed simultaneously. Each of these 256 colors can be one of the 2^24 different colors possible with the 3*8 bits in each colormap entry (or color cell, as it is called).   A 16bit display has a sixteen bit color value, which can have 2^16=65536 different values. The colormap links these to 65535 different, simultaneously visible, colors (out of 2^24 possible colors). (actually it's a bit more difficult than this, but thats beyond the  point).    So both a 8 and 16 bit display can show 2^24=16.7*10^6 colors. The difference lies in the number of colors they can show *at once*.   Regards, Roland              Date: Fri, May 30 1997 13:24:35  Subject: Using FTP as a shell-command with ftplib   From: Walter Harms,  Walter.Harms@Informatik.Uni-Oldenburg.DE  ...   Any drawbacks? Of course, for any ftp session you need a user/paswdr. I copy into public area using anonymous/email@ others >will need to surly a password at login, what is not very useful for regular jobs or you have to use some kind of public login but still I think it's easier and >better to use than the r-cmds.    -- walter                 Date: Mon, 12 May 1997 17:05:09 -0700  Subject: RE: Using ftp Commands in Shellscript  From: James Boorn,  jboorn@optum.com    I recommend you depend on .netrc for ftp usernames and passwords for automated ftp.   James Boorn                Date: Thu, 29 May 1997 09:09:35 -0500  Subject: X limitation to 8 Bit Color (Response to Gary Masters)  From: Omegaman,  omegam@COMMUNIQUE.NET    I read your question in Linux Gazette regarding an X limitation to 8 bit  color when the system has more that 14 megs of RAM. Where did you find that information? I ask because my system has 24 megs of RAM, and I run 16 bit color all the time. One difference between our  systems is that I am using a Diamond Stealth 64 video card.    Gary,  Just caught this letter in Linux Gazette.  This limitation is specific to Cirrus Logic cards, particularly those on the ISA bus and some on VLB (ie. old systems -- like mine. Since you're using a Diamond Stealth 64, you don't have this limitation.   Full details are in the readme.cirrus file contained in the XFree86 Documentation.  Some cirrus owners may be able to overcome this limitation.  See  http://xfree86.org               Date: Fri, May 30 1997 8:31:25  Subject: Response to Gary Masters  From: Ivan Griffin,  Ivan Griffin@ul.ie    From: Gary Masters  gmasters@devcg.denver.co.us    I read your question in Linux Gazette regarding an X limitation to 8 bit color when the system has more than 14 megs of RAM. Where did you find that information? I ask because my system has 24 megs of RAM, and I run 16 bit color all the time. One difference between our systems is that I am using a Diamond Stealth 64 video card.     XFree86 needs to be able to map video memory in at the end of physical memory linearly. However, ISA machines cannot support greater than 16MB in this fashion - so if you have 16 or greater MB or RAM, you cannot run XFree86 in higher than 8 bit color.   Ivan               Published in Linux Gazette Issue 18, June 1997                     This page written and maintained by the Editor of  Linux Gazette ,  gazette@ssc.com   Copyright © 1997 Specialized Systems Consultants, Inc.             More 2¢ Tips!    Send Linux Tips and Tricks to   gazette@ssc.com       Contents:     A Fast and Simple Printing Tip   Grepping Files in a Directory Tree   ViRGE Chipset   Maintaining Multiple X Sessions   Automatic File Transfers   Setting Up Newsgroups   Color Application in X   X With 256 Colors   Video Cards on the S3/ViRGE   C Source With Line Numbers   ncftp Vs. ftplib   Domain & Dynamic IP Names   netcfg Tool   Putting Links to Your Dynamic IP   Hard Disk Duplication   Untar and Unzip                   Monitoring a ftp Download.       Date: Tue, 27 May 1997 09:57:20 -0400  From: Bob Grabau  bob_grabau@fmso.navy. mil    Here is a tip for monitoring a ftp download. in another virtual console enter the following script:  while : do clear ls -l <filename that you are downloading> sleep 1 done    This virtual console can be behind (if you are using X) any other window and just showing a line of text. This will let you know if your download is done or stalled. This will let you do other things, like reading the Linux Gazette.  When you type this in, you wll get a > prompt after the first line and continue until you enter the last line.   --  Bob Grabau                Logging In To X Tip       Date: Mon, 26 May 1997 10:17:12 -0500 (CDT)  From: Tom Barron  barron@usit.net    Xlogin.mini-howto    Several people regularly use my Linux system at home (an assembled-from- components box containing a 133 Mhz Pentium, 2Gb of disk, 32Mb of memory, running the Slackware distribution) -- my step-son Stephen, who's learning to program and likes using X, my younger step-son Michael, who likes the X screen-savers and games like Doom, my wife Karen, who prefers the generic terminalness of the un-X'd console, and myself -- I like to use X for doing software development work since it lets me see several processes on the screen at once.  I also like to keep an X screen saver running when no-one is using the machine.     I didn't want to run  xdm  (an X-based login manager), since Karen doesn't want to have to deal with X.  She wants to be at the console when she logins in and not have to worry about where to click the mouse and such.  But I wanted to have a simple way of getting into X when I login without having to start it up manually.    Here's what I came up with:       In my .profile (my shell is bash), I put:  if [ ""$DISPLAY"" = """" ]; then     cal > ~/.month    xinit .Xsession > /dev/null 2>&1    clear    if [ ! -f .noexit ]; then       exit    fi  else     export TTY=`tty`    export TTY=`expr ""$TTY"" : ""/dev/tty\(.*\)""`    export PS1=""<$LOGNAME @ \h[$TTY]:\w> \n$ ""    export PATH=${PATH}:~/bin:.    export EDITOR=emacs    export WWW_HOME=file://localhost/home/tb/Lynx/lynx_bookmarks.html    export DISPLAY     alias cls=""clear""    alias dodo=""$EDITOR ~/prj/dodo""    alias e=""$EDITOR""    alias exit="". ~/bin/off""    alias l=""ls -l""    alias lx=""ls -x""    alias minicom=""minicom -m""    alias pg=less    alias pine=""export DISPLAY=;'pine'""    alias prj="". ~/bin/prj""    alias profile=""$EDITOR ~/.profile; . ~/.profile""  fi      When I first login, on the console, $DISPLAY is not yet set, so the    first branch of the if statement takes effect and we start up X.    When X terminates, we'll clear the screen and, unless the file    .noexit exists, logout.  Running cal and storing the output in    .month is in preparation for displaying a calender in a window    under X.    Once X comes up, $DISPLAY  is  set.   My .Xsession file contains:  : xsetroot -solid black fvwm & oclock -geometry 75x75-0+0 & xload -geometry 100x75+580+0 & emacs -geometry -0-0 & xterm -geometry 22x8+790+0 -e less ~/.month & color_xterm -font 7x14 -ls -geometry +5-0 & exec color_xterm -font 7x14 -ls -geometry +5+30 \    -T ""Type 'exit' in this window to leave X""       So when my color_xterms run, with -ls as an argument (which says to    run a login shell), they run .profile again.  Only this time    $DISPLAY is set, so they process the else half of the if, getting    the environment variables and aliases I normally expect.                    xlock Tip       Date: Mon, 26 May 1997 10:14:12 -0500 (CDT)  From: Tom Barron  barron@usit.net    Xscreensaver.mini-howto    Several people regularly use my Linux system at home (an assembled-from- components box containing a 133 Mhz Pentium, 2Gb of disk, 32Mb of memory, running the Slackware distribution) -- my step-son Stephen, who's learning to program and likes using X, my younger step-son Michael, who likes the X screen-savers and games like Doom, my wife Karen, who prefers the generic terminalness of the un-X'd console, and myself -- I like to use X for doing software development work since it lets me see several processes on the screen at once.  I also like to keep an X screen saver running when no-one is using the machine.       I didn't want to run  xdm  (an X-based login manager), since Karen doesn't want to have to deal with X.  She wants to be at the console when she logins in and not have to worry about where to click the mouse and such.  But I wanted to have a simple way of starting up the X-based screensaver xlock when I (or anyone) logged out to the console login.    Here's what I did (as root):       I created a user called xlock.  It has no password and its home    directory is /usr/local/xlock.  Its shell is bash.     In xlock's .profile, I put   if [ ""$DISPLAY"" = """" ]; then     xinit .Xsession > /dev/null 2>&1    clear    exit  fi     In xlock's .Xsession, I put  : exec xlock -nolock -mode random     Now, anybody can login xlock and instantly bring up the X screen-saver.  The ""random"" keyword tells it to select a pattern to display at random, changing it every so often.  When a key is pressed or a mouse button clicked, the screensaver process exits, the X session is ended, and control returns to the console login prompt.    In my next article, I show how I arranged to jump into X from the console login prompt just by logging in (i.e., without having to start X manually).                Hex Dump       Date: Sat, 24 May 1997 00:29:20 -0400  From: Joseph Hartmann  joeh@arakis.sugar-river.net                 Hex Dump by Joseph L. Hartmann, Jr.   This code is copyright under the GNU GPL by Joseph L. Hartmann, Jr.   I have not been happy with Hex Dump.  I am an old ex-DOS user, and am familiar with the HEX  ... ASCII  side-by-side presentation.   Since I am studying awk and sed, I thought it would be an interesting excercise to write this type of dump.     Here is a sample of what you may expect when you type the (script) command ""jhex  "" to the shell:  0000000  46 69 6c 65 6e 61 6d 65  0000000 F i l e n a m e 0000008  3a 20 2f 6a 6f 65 2f 62  0000008 :   / j o e / b 0000010  6f 6f 6b 73 2f 52 45 41  0000010 o o k s / R E A 0000018  44 4d 45 0a 0a 62 6f 6f  0000018 D M E . . b o o 0000020  6b 2e 74 6f 2e 62 69 62  0000020 k . t o . b i b 0000028  6c 69 6f 66 69 6e 64 2e  0000028 l i o f i n d . 0000030  70 65 72 6c 20 69 73 20  0000030 p e r l   i s    If you like it, read on....  The 0000000 is the hexadecimal address of the dump 46 is the hexadecimal value at 0000000 69 is the hexadecimal value at 0000001 6c is the hexadecimal value at 0000002 ...and so on.    To the right of the repeated address,  ""F i l e n a m e"" is the 8 ascii equivalents to the hex codes you see on the left.     I elected to dump 8 bytes in one row of screen output. The following software is required: hexdump, bash, less and gawk.   gawk is the GNU/Linux version of awk.   There are four files that I have installed in my /joe/scripts directory, a directory that is in my PATH environment.     The four files are: combine  -- an executable script: you must ""chmod +x combine"" jhex     -- an executable script: you must ""chmod +x jhex"" hexdump.dashx.format   -- a data file holding the formatting   information for the hex bytes. hexdump.perusal.format -- a data file holding the formatting   information for the ascii bytes.   Here is the file jhex:  hexdump -f /joe/scripts/hexdump.dashx.format $1 > /tmp1.tmp hexdump -f /joe/scripts/hexdump.perusal.format $1 > /tmp2.tmp gawk -f /joe/scripts/combine /tmp1.tmp > /tmp3.tmp less /tmp3.tmp rm /tmp1.tmp rm /tmp2.tmp rm /tmp3.tmp    Here is the file combine:  # this is /joe/scripts/combine -- it is invoked by /joe/scripts/jhex {  getline < ""/tmp1.tmp""    printf(""%s  "",$0)    getline < ""/tmp2.tmp""    print  }   Here is the file hexdump.dashx.format:             ""%07.7_ax  "" 8/1 ""%02x ""  ""\n""    Here is the file hexdump.perusal.format:             ""%07.7_ax ""  8/1  ""%_p "" ""\n""      I found the ""sed & awk"" book by Dale Dougherty helpful.   I hope you find jhex useful. To make it useful for yourself, you will have to replace the ""/joe/scripts"" with the path of your choice.  It must be a path that is in your PATH, so that the  scripts can be executed from anyplace in the directory tree.    A trivial note: do not remove the blank line from the                  hexdump.dasx.format and hexdump.perusal.format                 files: it will not work if you do!   A second trivial note: when a file contains many characters all of                        same kind, the line-by-line display will                        be aborted and the display will look similar                        to the example below:  0000820  75 65 6e 63 65 20 61 66  0000820 u e n c e   a f 0000828  74 65 72 20 74 68 65 20  0000828 t e r   t h e 0000830  0a 20 20 20 20 20 20 20  0000830 . 0000838  20 20 20 20 20 20 20 20  0000838 *  * 0000868  20 20 20 20 20 6c 61 73  0000868           l a s 0000870  74 20 72 65 63 6f 72 64  0000870 t   r e c o r d    Instead of displaying *all* the 20's, you just get the   *  *  .    I don't like this myself, but I have reached the end of my competence (and/or patience), and therefore, that's the way it is!                 A Fast and Simple Printing Tip      Date: Fri, 23 May 1997 07:30:38 -0400  From: Tim Bessell  tbessell@buffnet.net    I have been using Linux for about a year, as each day passes and my knowledge increases, my Win95 patitions decrease.  This prompted me to by a notebook, which of course is loaded with Windows.  Currently these two machines are NOT networked :-(  But that doesn't mean I can't print a document created in Word for Windows, Internet Explorer, etc., without plugging my printer cable into the other machine.   My solution is rather simple.  If you haven't already, add a new printer in the Windows control panel, using the driver for the printer that is connected to your Linux box.  Select ""FILE"" as the port you wish to print to and give it a name, eg: Print File (HP Destjet 540).  Now print your document to a floppy disk file, take it to the Linux machine, and issue a command simular to:  cat filename > /dev/lp1.  Your document will be printed with all the formatting that was done in Windows.   Enjoy,    Tim Bessell                                                                                                Grepping Files in a Directory Tree      Date: Wed, 21 May 1997 21:42:34   From: Earl Mitchell  earlm@Terayon.COM    Ever wonder how you can grep certain files in a directory tree for a particular string. Here's example how   grep foo `find . -name \*.c -print`    This command will generate a list of all the .c files in the current working directory or any of its subdirectories then use this list of files for the grep command. The grep will then search those files for the string ""foo"" and output the filename and the line containing ""foo"".    The only caveat here is that UNIX is configured to limit max chars in a command line and the ""find"" command may generate a list of files to huge for shell to digest when it tries to run the grep portion as a command line. Typically this limit is 1024 chars per command line.   -earl                 ViRGE Chipset      Date: Wed, 30 Apr 1997 22:41:28   From: Peter Amstutz  amstpi@freenet.tlh.fl.us      A couple suggestions to people with video cards based on the ViRGE Chipset...     XFree 3.2 has a ViRGE server!  I have heard a number of people complain about XFree's lack of ViRGE support.  Yo GUYZ!  That's because your wonderful Linux CD has XFree86 3.1.2 WHICH IS NOT THE MOST RECENT VERSION!   There is a minor hack you can make to svgalib 1.12.10 to get it to reconignize your nice S3 based card as actually being such.  The s3/ViRGE chip is, in the words of some guy at C|Net, ""basically a S3 Trio 64 with a 3d engine bolted on top.""  Unfortunately, it returns a card code totally different to the Trio64.  With just a minor little bit of hacking, you too can do 1024x768x16bpp through svgalib.  Get the source, untar it & everything.  Go into the main source directory, and with your favorite editor, open up s3.c (or it maybe vga.c it has been sometime since I did this and I do not have the source now in front of me)  Now, search for the nice little error message it gives you when it says something like ""S3 chip 0x(some hex number) not reconignized.""  Above it there should be a switch()/case statement that figures out which card it is.  Find the case statement that matches a Trio64.  Insert a fall-through case statement that matches the code your card returns, so svgalib treats it as a Trio64! You're home free!  Recompile, re-install libraries, and now, what we've all been waiting for, test 640x480x256!  640x480x16bpp!  800x600x24bpp!  YES!!!     Note: this trick has not been authorized, reconignized, or in any way endorsed, recommended, or even considered by the guy(s) who wrote svgalib in the first place.  (that last version of svgalib is over a year old, so I don't expect there to be any new versions real soon) It works for me, so I just wanted to share it with the Linux community that just might find it useful.  Peter Amstutz                 Maintaining Multiple X Sessions     Date: Sun, 04 May 1997 21:02:10 +0200  From: David Kastrup  dak@neuroinformatik.ruhr-uni-bochum.de      Suppose you have an X running, and want to start another one (perhaps for a different user).   startx alone will complain.   Writing  startx -- :1  will work, however (if screen 0 is already taken).  Start another one with  startx -- :2  if you want.  You want that to have hicolor, and your Xserver would support it?   Then start it rather with  startx -- -bpp 16 :2    Of course, if no Xserver is running yet, you can get a non-default depth by just starting with  startx -- -bpp 16  or  startx -- -bpp 8   or whatever happens to be non-standard with you.   --  David Kastrup                Automatic File Transfer      Date: Sat, 3 May 1997 12:58:11 +0200 (MDT)  From: Gregor Gerstmann  gerstman@tfh-berlin.de      Hi there, Here is a small tip concerning the 'automatic' file transfer; Linux Gazette Issue 17, May 1997. Everything is known stuff in Unix and Linux. To 'automate' file transfer for me means to minimize the load on the remote server as well as my own telephone costs - you have to pay for the time you think if or not to get a special file, for changing the directories and for the time to put the names into the PC. The procedure is called with the address as parameter and generates a protocol.  #!/bin/bash # date > prot # ftp -v $1 >> prot # # date >> prot #    Ftp now looks if a .netrc file exists; in this file I use macros written in advance and numbered consecutively:  ... machine ftp.ssc.com login anonymous password -gerstman@tfh-berlin.de macdef T131 binary prompt cd ./pub/lg pwd dir . C131.2 get lg_issue17.tar.gz SSC17  macdef init $T131 bye ...    Now I first get the contents of several directories via dir . C131... and, to have some book-keeping, logically use the same numbers for the macros and the directories. The protocol shows, if I am really in the directory I wished to. Until the next session begins, the file C131... is used to edit the last .netrc file, therefore the names will always be typed correctly. If you are downloading under DOS from your account the shorter names are defined in the .netrc file. Everything is done beforehand with vi under Linux.   Dr.Werner Gerstmann                Setting Up Newsgroups      Date: Mon, 05 May 1997 16:19:05 -0600  From: ""Michael J. Hammel""  mjhammel@emass.com      But I just can't seem to find any documentation explaining  how to set up local newsgroups. smtpd and nntpd are running, but the manpages won't tell anything about how to set up ng's    smtpd and nntpd are just transport agents.  They could just as easily transport any sort of message files as they do mail or NetNews files.  What you're looking for is the software which manages these files on your local system (if you want newsgroups available only locally then you need to have this software on your system).  I used to use CNEWS for this.  I believe there are some other packages, much newer than CNEWS, that might make it easier.  Since I haven't used CNEWS in awhile I'm afraid I can't offer any more info than this.    Michael J. Hammel                           Color Applications in X      Date: Tue, 06 May 1997 09:25:01 -0400 (EDT)  From: Oliver Oberdorf  oly@borg.harvard.edu      Saw some X Window tips, so I thought I'd send this one along..   I tend to use lots of color rich applications in X.  After cranking up XEmacs, Gimp, etc., I find that I quickly run out of palette on my 8-bit display.  Most programs don't behave sensibly when I run out of colors - for example, CGoban comes up  black and white and realaudio refuses to run at all (not enough  colors to play sound, I suppose.    I've found I can solve these problems by passing a ""-cc 4"" option to the X server.  This tells it to pretend I have a bigger pallete and to pass back closest matches to colors when necessary. I've never run out of colors since then.   There are caveats: programs that check for a full colormap and install their own (color flashing) will automatically do so. This includes netscape and XForms programs (which I was running with private color maps anyway).  My copy of LyriX makes the background black.  Also, I tried Mosaic on a Sun and had some odd color effects.   oly                X With 256 Colors              Date: Tue, 06 May 1997 09:40:10 -0400 (EDT)  From: Oliver Oberdorf  oly@borg.harvard.edu      I forgot to add that the -cc 4 can be used like this:  startx -- -cc 4   (I use xdm, so I don't have to do it this way)   sorry about that   oly                Video Cards on the S3/ViRGE      Date: Mon, 05 May 1997 20:44:13 -0400  From: Peter Amstutz  amstpi@freenet.tlh.fl.us     A couple suggestions to people with video cards based on the S3/ViRGE Chipset... (which is many video cards that ship with new computers that claim to have 3D accelerated graphics.  Don't believe it.  The 3D graphics capability of all ViRGE-based chips sucks.  They make better cheap 2D accelerators)     XFree 3.2 has a ViRGE server!  I have heard a number of people complain about XFree's lack of ViRGE support.  Yo GUYZ!  That's because your wonderful Linux CD has XFree86 3.1.2 WHICH IS NOT THE MOST RECENT VERSION!   There is a minor hack you can make to svgalib 1.12.10 to get it to reconignize your nice S3 based card as actually being such.  The s3/ViRGE chip is, in the words of some guy at C|Net, ""basically a S3 Trio 64 with a 3d engine bolted on top."" (as noted, the 3D engine is really slow) Unfortunately, it returns a card ID code totally different to the Trio64. But, drum roll please, with just a little bit of hacking, you too can do 1024x768x16bpp through svgalib!  Just follow these E-Z steps:  I)Get the source, untar it & everything.   II) Go into the main source directory, and with your favorite editor (vim forever!), open up s3.c  III) Now, search for the nice little error message  ""S3: Unknown chip id %02x\n""  around line 1552.  Above it there should be a switch()/case statement that figures out which card it you have based on an ID code.  Find the case statement that matches a Trio64.  Insert a fall-through case statement that matches the code your card returns, so svgalib treats it as a Trio64!  Like this: (starts at line 1537 of s3.c)       case 0x11E0:   s3_chiptype = S3_TRIO64;   break; becomes      case 0x11E0:      case 0x31E1:   s3_chiptype = S3_TRIO64;   break;  Replace 0x31E1 with the appropriate ID if your card returns a different code.   Save it!  You're home free!  Recompile, re-install libraries, and now, what we've all been waiting for, test some svga modes!  640x480x256! 640x480x16bpp! 800x600x24bpp!  YES!!!   But wait!  One thing to watch out for.  First, make sure you reinstall it in the right place!  Slackware puts libvga.a in /usr/lib/, so make sure that is that file that you replace.  Another thing: programs compiled with svgalib statically linked in will have to be rebuilt with the new library, otherwise they will just go along in their brain dead fashion blithely unaware that your card is not being used to nearly it's full potential.   Note: this hack has not been authorized, reconignized, or in any way endorsed, recommended, or even considered by the guy(s) who wrote svgalib. The last version of svgalib is over a year old, so I don't expect there to be any new versions real soon.  It works for me, so I just wanted to share it with the Linux community that just might find it useful.  This has only been tested on my machine, using a Diamond Stealth 3D 2000, so if you have a different ViRGE-based card and you have problems you're on your own.   No, there are no Linux drivers that use ViRGE ""accelerated 3D"" features.  It sucks, I know (then again, the 3D performance of ViRGE chips is so bad you're probably not missing much)   Peter Amstutz                  C Source with Line Numbers      Date: 5 May 1997  From:  joeh@sugar-river.net      I wanted to print out a c source with line numbers.  Here is one way to do it:   Assuming you are using bash, install the following function in your .bashrc file.     jnl () {            for args          do            nl -ba $args > /tmp.tmp          done          lpr /tmp.tmp        }    ""nl"" is a textutils utility that numbers the lines of a file.   ""-ba"" makes sure *all* the lines (even the empty lines) get numbered.   /tmp.tmp is my true ""garbage"" temporary file, hence I write over it, and send it to the line printer.   For example to print out a file ""kbd.c"", with line numbers:  jnl kdb.c     There are probably 20 different methods of accomplishing the same thing, but when you don't even have *one* of them in your bag of tricks, it can be a time-consuming detour.   Note: I initially tried to name the function ""nl"", but this led to       an infinite loop.  Hence I named it jnl (for Joe's number lines).   Best Regards,  Joe Harmann                 ncftp Vs. ftplib      Date: Thu, 08 May 1997 13:30:04 -0700  From: Igor Markov  imarkov@math.ucla.edu      Hi, I read your 2c tip in Linux gazette regarding ftplib.   I am not sure why you recommend downloading ftpget, while another package, actually, a single program, which is available on many systems does various ftp services pretty well.   I mean ncftp (""nikFTP""). It can do command line, it can work in the mode of usual ftp (with the ""old"" or ""smarter"" interface"") and it also does full-screen mode showing ETA during the transfer. It has filename and hostname completion and a bunch of other niceties, like remembering passwords if you ask it to.   Try man ncftp on your system (be in Linux or Solaris) ... also, ncftp is available from every major Linux archive (including ftp.redhat.com where you can find latest RPMs)    Hope this helps, Igor                 Domain and Dynamic IP Names      Date: Thu, 08 May 1997 13:52:02 -0700  From: Igor Markov  imarkov@math.ucla.edu      I have a dial-up with dynamic IP and it has always been an incontinence for me and my friends to learn my current IP address (I had an ftp script which put the address every 10 minutes into ~/.plan file on my acct at UCLA, then one could get the address by fingering the account).   However, recently I discovered a really cool project  http://www.ml.org  which     can give you a dynamic IP name, i.e. when your  computer gets a new IP address, it needs to  contact www.ml.org and update its record.    Once their nameserver reloads its tables (once every 5-10mins!) your computer can be accessed by the name you selected when registered.   For example, my Linux box has  IP name math4.dyn.ml.org         Caveat: if you are not online, the name can point to  a random computer. In my case, those boxes are most often wooden (i.e. running Windoze ;-) so you would get ""connection refused"".   In general, you need some kind of authentication scheme (e.g. if you telnet to my computer, it would say ""Office on Rodeo Drive"")   allows you to register domain name for free (e.g. you can register an alternative name for your computer at work which has a constant IP)    offer nameserver support for free (if you need it)          Isn't that cool ?   Cheers,         Igor               netcfg Tool      Date: Sat, 10 May 1997 11:55:28 -0400  From: Joseph Turian  turian@idt.net      I used Redhat 4.0's netcfg tool to install my PPP connection, but found that I could only use the Internet as root. I set the proper permissions on my scripts and the pppd (as stated in the PPP Howto and the Redhat PPP Tips documents), but I still could not use any Internet app from a user's account. I then noticed that a user account _could_ access an IP number, but could not do a DNS lookup. It turns out that I merely had to chmod ugo+r /etc/resolv.conf                 Putting Links to Your Dynamic IP      Date: Wed, 28 May 1997 13:24:45  From: Nelson Tibbitt  nelson@interpath.com      Sometimes it might be useful to allow trusted friends to connect to your personal Linux box over the Internet. An easy way to do this is to put links to your IP address on a full-time web server, then give the URL to whomever. Why would you want to do that?  Well, I do it so my sister can telnet to Magnon, my laptop, for a chat whenever I'm connected.   However it might prove difficult if, like me, your ISP assigns your IP address dynamically.  So I wrote a short script to take care of this...  The script generates an html file containing my local IP address then uploads the file via ftp to a dedicated web server on which I have rented some web space.  It runs every time a ppp connection is established, so the web page always contains my current IP, as well as the date/time I last connected.   This is pretty easy to set up, and the result is way cool.  Just give my sis (or anyone else I trust) the URL... then she can check to see if I'm online whenever she wants, using Netscape from her vax account at RIT.   If I am connected, she can click to telnet in for a chat.   Here's how it works....    determine local IP address  write an html file containing date/time and links to the IP address that has been assigned  upload the html file to a dedicated web server using ftp (and a .netrc file)    To get ftp to work, I had to create a file named .netrc in my home directory with a line that contains the ftp login information for the remote server.  My .netrc has one line that looks like this:   machine ftp.server.com login ftpusername password ftppassword    For more information on the .netrc file and its format, try ""man ftp"". Chmod it 700 (chmod 700 .netrc) to prevent other users from reading the file. This isn't a big deal on my laptop, which is used primarily by yours truly.  But it's a good idea anyway.   Here's my script.  There might be a better way to do all of this, however my script works pretty well. Still, I'm always interested in ways to improve  my work, so if you have any suggestions or comments, feel free to send me an email.     #!/bin/sh # *** This script relies on the user having a valid local .netrc *** # *** file permitting automated ftp logins to the web server!!   *** # # Slightly modified version of: # Nelson Tibbitt's insignificant bash script, 5-6-97 # nelson@interpath.com # # Here are variables for the customizing... # Physical destination directory on the remote server # (/usr/apache/htdocs/nelson/ is the httpd root directory at my virtual domain) REMOTE_PLANDIR=""/usr/apache/htdocs/nelson/LinuX/Magnon"" # Desired destination filename REMOTE_PLANNAME=""sonny.htm"" # Destination ftp server # Given this and the above 2 variables, a user would find my IP address at # http://dedicated.web.server/LinuX/Magnon/sonny.htm REMOTE_SERVER=""dedicated.web.server"" # Local (writable) temporary directory TMPDIR=""/usr/tmp"" # Title (and header) of the html file to be generated HTMLHEAD=""MAGNON"" # Existing image on remote server to place in html file.. # Of course, this variable isn't necessary, and may be commented out. If commented out, # you'll want to edit the html file generation below to prevent an empty image from appearing # in your web page. HTMLIMAGE=""/LinuX/Magnon/images/mobile_web.gif"" # Device used for ppp connection PPP_DEV=""ppp0"" # Local temporary files for the html file/ftp script generation TFILE=""myip.htm"" TSCPT=""ftp.script"" # Used to determine local IP address on PPP_DEV #  There are several ways to get your IP, this was the first command-line method I came # up with.   It works fine here.  Another method, posted in May 1997 LJ  (and which looks # much cleaner) is this: #  `/sbin/ifconfig | awk 'BEGIN { pppok = 0} \ #   /ppp.*/ { pppok = 1; next } \ #  {if (pppok == 1 ) {pppok = 0; print} }'\ #  | awk -F: '{print $2 }'| awk  '{print $1 }'` GETMYIP=$(/sbin/ifconfig | grep -A 4 $PPP_DEV \   | awk '/inet/ { print $2 } ' | sed -e s/addr://) # Used to place date/time of last connection in the page FORMATTED_DATE=$(date '+%B %-d, %I:%M %p') # # # Now, do it!  First give PPP_DEV time to settle down... sleep 5 echo ""Current IP: $GETMYIP""  # Generate the html file... # Edit this part to change the appearance of the web page. rm -f $TMPDIR/$TFILE echo ""Writing $REMOTE_PLANNAME"" echo >$TMPDIR/$TFILE echo ""<html><head><title>$HTMLHEAD</title></head><center>""   >>  $TMPDIR/$TFILE echo ""<body bgcolor=#ffffff><font size=+3>$HTMLHEAD</font>""  >>  $TMPDIR/$TFILE # Remove the <imgtag in the line below if you don't want an image echo ""<p><img src='$HTMLIMAGE' alt='image'<p>The last ""     >>  $TMPDIR/$TFILE echo ""time I connected was <b>$FORMATTED_DATE</b>, when the "" >> $TMPDIR/$TFILE echo ""Net Gods dealt <b>$GETMYIP</bto Magnon. <p><a href=""  >> $TMPDIR/$TFILE echo ""http://$GETMYIP target=_top>http://$GETMYIP</a><p>""     >> $TMPDIR/$TFILE echo ""<a href=ftp://$GETMYIP target=_top>ftp://$GETMYIP""  >> $TMPDIR/$TFILE echo ""<p><a href=telnet://$GETMYIP>telnet://$GETMYIP</a><br>"" >> $TMPDIR/$TFILE echo ""(Telnet must be properly configured in your browser.)""  >> $TMPDIR/$TFILE # Append a notice about the links.. echo ""<p>The above links will only work while I'm connected."" >> $TMPDIR/$TFILE  # Create an ftp script to upload the html file  echo ""put $TMPDIR/$TFILE"" $REMOTE_PLANDIR/$REMOTE_PLANNAME > $TMPDIR/$TSCPT  echo ""quit"" >$TMPDIR/$TSCPT  # Run ftp using the above-generated ftp script (requires valid .netrc file for ftp login to work)  echo ""Uploading $REMOTE_PLANNAME to $REMOTE_SERVER...""  ftp $REMOTE_SERVER > $TMPDIR/$TSCPT &/dev/null  # The unset statements are probably unnecessary, but make for a clean 'look and feel'   echo -n ""Cleaning up... "" rm -f $TMPDIR/$TFILE ; rm -f $TMPDIR/$TSCPT unset HTMLHEAD HTMLIMAGE REMOTE_SERVER REMOTE_PLANDIR REMOTE_PLANNAME unset GETMYIP FORMATTED_DATE PPP_DEV TMPDIR TFILE TSCPT echo ""Done.""  exit                     Hard Disk Duplication      Date: Tue, 27 May 1997 11:16:32   From: Michael Jablecki  mcablec@ucsd.edu     Shockingly enough, there seems to be a DOS product out there that will happily make ""image files"" of entire hard disks and copy these image files onto blank hard disks in a sector-by-sector fashion.  Boot sectors and partition tables should be transferred exactly.  See:  http://www.ingot.com  for more details.  Seagate (I think...) has also made a program that does the duplication in one step - transfers all of one hard disk to another identical disk.  I'm not sure which of these products works with non-identical disks.   Hope this helps.   Michael Jablecki                Untar and Unzip      From: Paul   Oh, here's a little tidbit of info to pass on, this has been bugging me for a while.  Often times when people send in tips 'n' tricks, it requires one to untar and unzip an archive.  It usually suggested that this be done in one of several cumbersome ways:   gzcat foo.tar.gz | tar zxvf -  or 1. gunzip foo.tar.gz  2. tar xvf foo.tar  or some other multi-step method.  There is a much easier, time-saving, space saving method.  The version of tar shipped with most distributions of Linux is from the FSF GNU project.  These people recognized that most tar archives are usually gzipped and provided a 'decompress' flag to tar. This is equivalent to the above methods:   tar zxvf foo.tar.gz  This decompress the tar.gz file on the fly and then untars it into the current directory, but it also leaves the original .tar.gz alone.  However, one step I consider essential that is usually never mentioned, is to look at what's in the tar archive prior to extracting it.  You have no idea whether the archiver was kind enough to tar up the parent directory of the files, or it they just tarred up a few files.  The netscape tar.gz is a classic example.  When that's untarred, it dumps the contents into your current directory.  Using:   gtar ztvf foo.tar.gz  allows you to look at the contents of the archive prior to opening it up and potetially writing over files with the same name.  At the very least, you will know what's going on and be able to make provisions for it before you mess something up.  For those who are adventurous, (X)Emacs is capable of not only opening up and reading a tar.gz file, but actually editing and re-saving the contents of these as well.  Think of the time/space savings in that!  Seeya, Paul            Published in Linux Gazette Issue 18, June 1997                           This page maintained by the Editor of  Linux Gazette ,  gazette@ssc.com   Copyright © 1997 Specialized Systems Consultants, Inc.        ""Linux Gazette... making Linux just a little more fun! ""             Contents:     News in General   Software Announcements                 News in General                Atlanta Linux Showcase     Linus Torvalds, the ""Kernel-Kid"" and creator of Linux, Jon ""Maddog"" Hall, Linux/Alpha team leader and inspiring Linux advocate, David Miller, the mind behind Linux/SPARC, and Phil Hughes, publisher of Linux Journal, and many more will speak at the upcoming Atlanta Linux Showcase.   For more information on the Atlanta Linux Showcase and to reserve your seat today, please visit our web site at  http://www.ale.org.showcase               Linux Speakers Bureau     SSC is currently putting together a Linux Speaker's Bureau.   http://www.ssc.com/linux/lsb.html     The LSB is designed to become a collage of speakers specializing in Linux. Speakers who specialize in talks ranging from novice to advanced - technical  or business are all welcome.  The LSB will become an important tool for   organizers of trade show talks, computer fairs and general meetings, so if  you are interested in speaking at industry events, make sure to visit the  LSB WWW page and register yourself as a speaker.   We welcome your comments and suggestions.                   The Linux System Administrator's Guide (SAG)     The Linux System Administrator's Guide (SAG) is a book on system administration targeted at novices. Lars Wiraenius has been writing it for some years, and it shows. He has made an official HTML version, available at the SAG home page at:    http://www.iki.fi/liw/linux/sag    Take a Look!              Free CORBA 2 ORB For C++ Available     The Olivetti and Oracle Research Laboratory has made available the first public release of omniORB (version 2.2.0). We also refer to this version as omniORB2.   omniORB2 is copyright Olivetti & Oracle Research Laboratory. It is free software. The programs in omniORB2 are distributed under the GNU General Public Licence as published by the Free Software Foundation. The libraries in omniORB2 are distributed under the GNU Library General Public Licence.   For more information take a look at  http://www.orl.co.il/omniORB .   Source code and binary distributions are available from   http://www.orl.co.uk/omniORB/omniORB.html                 The Wurd Project     The Wurd Project, a SGML Word Processor for the UNIX environment (and hopefully afterwards, Win32 and Mac) is currently looking for developers that are willing to participate in the project.  Check out the site at:  http://sunsite.unc.edu/paulc/wp    Mailing list archives are available, as well as the current source, documentation, programming tools and various other items can also be found at the above address.               Linus in Wonderland     Check it out...   Here's the online copy of Metro's article on Linus...    http://www.metroactive.com/metro/cover/linux-9719.html    Enjoy!               Software Announcements               BlackMail 0.24     Announcing BlackMail 0.24.  This is a bug-fix release over the previous release, which was made public on April 29th.     BlackMail is a mailer proxy that wraps around your existing mailer (preferrably smail) and provides protection against spammers, mail forwarding, and the like.   For those of you looking for a proxy, you may want to look into this.  This is a tested product, and works very well.  I am interested in getting this code incorporated into SMAIL, so if you are interested in doing this task, please feel free.   You can download blackmail from  ftp://ftp.bitgate.com .   You can also view the web page at  http://www.bitgate.com .              CDE--Common Desktop Environment for Linux     Red Hat Software is proud to announce the arrival of Red Hat's TriTeal CDE for Linux.  Red Hat Software, makers of the award-winning, technologically advanced Red Hat Linux operating system, and TriTeal Corporation, the industry leader in CDE technology, teamed up to bring you this robust, easy to use CDE for your Linux PC.   CDE includes  Red Hat's TriTeal CDE for Linux provides users with a graphical environment to access both local and remote systems.   It gives you icons, pull-down menus, and folders.    Red Hat's TriTeal CDE for Linux is available in two versions.  The Client Edition gives you everything you need to operate a complete licensed copy of the CDE desktop, incluidng the Motif 1.2.5 shared libraries.  The Developer's Edition allows you to perform all functions of the Client Edition, and also includes a  complete integrated copy of OSF Motif version 1.2.5, providing a complete development environment with static and dynamically linked libraries, Motif Window Manager, and sample Motif Sources.     CDE is an RPM-based product, and will install easily on Red Hat and other RPM-based Linux systems.  We recommend using Red Hat Linux 4.2 to take full advantage of CDE features.  For those who do not have Red Hat 4.2, CDE includes several Linux packages that can be automatically installed to improve its stability.    Order online at:  http://www.redhat.com  Or call 1-888-REDHAT1 or (919) 572-6500.              TCFS 2.0.1     Announcing the release 2.0.1 of TCFS (Transparent Cryptographic File System) for Linux. TCFS is a cryptographic filesystem developed here at Universita' di Salerno (Italy). It operates like NFS but allow users to use a new flag X to make the files secure (encrypted). Security engine is based on DES, RC5 and IDEA.   The new release works in Linux kernel space, and may be linked as  kernel module. It is developed to work on Linux 2.0.x kernels.   A mailing-list is available at  tcfs-list@mikonos.dia.unisa.it .  Documentation is available at  http://mikonos.dia.unisa.it/tcfs . Here you can find instructions for installing TCFS and docs on how it works. Mirror site is available at  http://www.globenet.it  and  http://www.inopera.it/~ermmau.tcfs                 Qddb 1.43p1     Qddb 1.43p1 (patch 1) is now available  Qddb is fast, powerful and flexible database software that runs on UNIX platforms, including Linux.  Some of its features include:     Tcl/Tk programming interface  Easy to use, you can have a DB application completely up and  running in about 5 minutes, using nxqddb.  CGI interface for quick and easy online databases/guestbooks/etc...  Fast, and powerful searching capability  Report generator  Barcharts and graphs  Mass mailings with Email, letters and postcards    Qddb-1.43p1 is the first patch release to 1.43.  This patch fixes a few minor problems and a searching bug when using cached secondary searching.   To download the patch file:  ftp://ftp.hsdi.com/pub/qddb/sources/qddb-1.43p1.patch    For more information on Qddb, visit the official Qddb home page:  http://www.hsdi.com/qddb                Golgotha     AUSTIN, TX- Crack dot Com, developers of the cult-hit Abuse and the anticipated 3D action/strategy title Golgotha, recently learned that Kevin Bowen, aka Fragmaster on irc and Planet Quake, has put up the first unofficial Golgotha web site.   The new web site can be found at  http://www.planetquake.com/grags/golgotha , and there is a link to the new site at  http://crack.com/games/golgotha . Mr. Bowen's web site features new screenshots and music previously available only on irc.   Golgotha is Crack dot Com's first $1M game and features a careful marriage of 3D and 2D gameplay in an action/strategy format featuring new rendering technology, frantic gameplay, and a strong storyline. For more information on Golgotha, visit Crack dot Com's web site at  http://crack.com/games/golgotha .   Crack dot Com is a small game development company located in Austin, Texas.  The corporation was founded in 1996 by Dave Taylor, co-author of Doom and Quake, and Jonathan Clark, author of Abuse.               ImageMagick-3.8.5-elf.tgz     ImageMagick-3.8.5-elf.tgz is now out.   This version brings together a number of minor changes made to accomodate PerlMagick and lots of minor bugs fixes including multi-page TIFF decoding and writing PNG.   ImageMagick (TM), version 3.8.5, is a package for display and interactive manipulation of images for the X Window System. ImageMagick performs, also as command line programs, among others these functions:    Describe the format and characteristics of an image   Convert an image from one format to another   Transform an image or sequence of images   Read an image from an X server and output it as an image file   Animate a sequence of images   Combine one or more images to create new images   Create a composite image by combining several separate images   Segment an image based on the color histogram   Retrieve, list, or print files from a remote network site     ImageMagick supports also the Drag-and-Drop protocol form the OffiX package and many of the more popular image formats including JPEG, MPEG, PNG, TIFF, Photo CD, etc.  Check out:  ftp://ftp.wizards.dupont.com/pub/ImageMagick/linux                Slackware 3.2 on CD-ROM      Linux Systems Labs, The Linux Publishing Company is pleased to announce  Slackware 3.2 on CD-ROM  This CD contains Slackware 3.2 with 39 security fixes and patches since  the Official Slackware 3.2 release.  The CD mirrors the slackware ftp site as of April 26, 1997.  Its a great way to get started with Linux or update the most popular Linux distribution.     This version contains the 2.0.29 Linux kernel, plus recent versions of these (and other) software packages:    Kernel modules 2.0.29  PPP daemon 2.2.0f  Dynamic linker (ld.so) 1.8.10  GNU CC 2.7.2.1  Binutils 2.7.0.9  Linux C Library 5.4.23  Linux C++ Library 2.7.2.1  Termcap 2.0.8  Procps 1.01  Gpm 1.10  SysVinit 2.69  Shadow Password Suite 3.3.2 (with Linux patches) Util-linux 2.6      LSL price:     $1.95      Ordering Info:  http://www.lsl.com               mtools     A new release of mtools, a collection of utilities to access MS-DOS disks from Unix without mounting them.   Mtools can currently be found at the following places:   http://linux.wauug.org/pub/knaff/mtools   http://www.club.innet.lu/~year3160/mtools   ftp://prep.ai.mit.edu/pub/gnu    Mtools-3.6 includes the features such as Msip -e which now only ejects Zip disks when they are not mounted, Mzip manpage, detection of bad passwords and more.  Most GNU software is packed using the GNU `gzip' compression program. Source code is available on most sites distributing GNU software.  For more information write to  gnu@prep.ai.mit.edu   or look at:  http://www.gnu.ai.mit.edu/order/ftp.html               CM3     CM3 version 4.1.1 is now available for Unix and Windows platforms: SunOS, Solaris, Windows NT/Intel, Windows 95, HP/UX, SGI IRIX, Linux/ELF on Intel, and Digital Unix on Alpha/AXP. For additional information, or to download an evaluation copy, contact Critical Mass, Inc. via the Internet at info@cmass.com or on the World Wide Web at   http://www.cmass.com    newsBot:  Extracts exactly what you want from your news feed.  Cuts down  on ""noise"". Sophisticated search algorithms paired with  numerous filters cut out messages with ALL CAPS, too many $ signs,  threads which won't die, wild cross posts and endless discussions  why a Mac is superior to a Chicken, and why it isn't. newsBot is at:   http://www.dsb.com/mkt/newsbot.html    mailBot:  Provides itendical functionality but reads mailing lists and e-zines instead of news groups. Both are aimed at responsible Marketers and Information managers. The *do not* extract email addresses and cannot be mis-used for bulk mailings. mailBot is at:  http://www.dsb.com/mkt/mail.bot.html     siteSee:  A search engine running on your web server and using the very same  search technology: a very fast implementation of Boyer Moore. siteSee differs from other search engines in that it does not require creation and maintenance of large index files. It also becomes an integrated part of your site design. You have full control over page layout. siteSee is located at:   http://www.dsb.com/publish/seitesee.html               linkCheck     linkCheck:  A hypertext link checker, used to keep your site up to date. Its  client-server implementation allows you to virtually saturate your comms link without overloading your server. LinkCheck is fast at reading and parsing HTML files and builds even large deduplicated lists of 10,000 or more cross links faster than interpreted languages take to load. linkCheck is at:   http://www.dsb.com/maintain/linkckeck.html     All products require Linux, SunOS or Solaris. And all are sold as ""age ware"": a free trial license allows full testing. When the license expires, the products ""age"", forget some of their skills, but they still retain about 80% of their functionality.   A GUI text editor named ""Red"" is available for Linux. The editor has a full graphical interface, supports mouse and key commands, and is easy to use.   These are some of Red's features that might be interesting:     Graphical interface   Full mouse and key support   40 step undo (and redo)   User-definable key bindings   Automatic backup creation   Cut/paste exchange with other X Windows applications   On-line function list, help and manual     It can be downloaded free in binary form or with full source code.    ftp://ftp.cs.su.oz.au/mik/red   Also, take a look at the web site at:    http://www.cs.su.oz.au/~mik/red-manual/red-main-page.html    The web site also includes a full Manual - have a look if you are interested.              Emacspeak-97++     Announcing Emacspeak-97++ (The Internet PlusPack). Based on InterActive Accessibility technology, Emacspeak-97++ provides a powerful Internet ready audio desktop that  integrates Internet technologies including Web surfing and messaging into all aspects of the electronic desktop.   Major Enhancements in this release include:    Support for WWW ACSS (Aural Cascading Style Sheets)  Audio formatted output for rich text  Enhanced support for browsing tables  Support for speaking commonly used ISO Latin characters  Speech support for the  Emacs widget libraries  Support for SGML mode  Emacspeak now has an automatically generated users manual thanks to Jim Van Zandt.    Emacspeak-97++ can be downloaded from:   http://cs.cornell.edu/home/raman/emacspeak   ftp://ftp.cs.cornell.edu/pub/raman/emacspeak               Published in Linux Gazette Issue 18, May 1997                       This page written and maintained by the Editor of  Linux Gazette ,  gazette@ssc.com   Copyright © 1997 Specialized Systems Consultants, Inc.        ""Linux Gazette... making Linux just a little more fun! ""                   The Answer Guy        By James T. Dennis,  jimd@starshine.org   Starshine Technical Services,   http://www.starshine.org/           Contents:     Networking Problems   Fetchmail   Procmail   Tcl/tlk Dependencies   /var/log/messages   OS Showdown   Adding Linux to a DEC XLT-366   Configuration Problems of a Soundcard   Procmail Idea and Question   UUCP/Linux on Caldera   ActiveX For Linux   What Packages Do I Need?   Users And Mounted Disks   [q] Map Left Arrow to Backspace   Adding Programs to Pull Down Menus   Linux and NT   pcmcia 28.8 Modems and Linux 1.2.13 Internet Servers               Tcl/tlk Dependencies      From: David E. Stern,  lptsua@i/wasjomgtpm/edu     The end goal: to install FileRunner, I simply MUST have it! :-)   My intermediate goal is to install Tcl/Tk 7.6/4.2, because FileRunner needs these to install, and I only have 7.5/4.1 . However, when I try to upgrade tcl/tlk, other apps rely on older tcl/tk libraries, atleast that's what the messages allude to:     libtcl7.5.so is needed by some-app        libtk4.1.so is needed by some-app   (where some-app is python, expect, blt, ical, tclx, tix, tk, tkstep,...)   I have enough experience to know that apps may break if I upgrade the libraries they depend on. I've tried updating some of those other apps, but I run into further and circular dependencies--like a cat chasing it's tail.    In your opinion, what is the preferred method of handling this scenario? I must have FileRunner, but not at the expense of other apps.        It sounds like you're relying too heavily on RPM's.  If you can't afford to risk breaking your current stuff,  and you ""must"" have the upgrade you'll have to do some  stuff beyond what the RPM system seems to do.    One method would be to grab the sources (SRPM or tarball)  and manually compile the new TCL and tk into /usr/local  (possibly with some changes to their library default   paths, etc).  Now you'll probably need to grab the   FileRunner sources and compile that to force it to use the  /usr/local/wish or /usr/local/tclsh (which, in turn, will  use the /usr/local/lib/tk if you've compiled it all right).    Another approach is to set up a separate environment   (separate disk, a large subtree of an existing disk  -- into which you chroot, or a separate system entirely)  and test the upgrade path where it won't inconvenience you  by failing.  A similar approach is to do a backup, test your  upgrade plan -- (if the upgrade fails, restore the backup).    This is a big problem in all computing environments (and  far worse in DOS, Windows, and NT systems than in most   multi-user operating systems.  At least with Unix you have  the option of installing a ""playpen"" (accessing it with the  chroot call -- or by completely rebooting on another partition  if you like).      Complex interdepencies are unavoidable unless you require that  every application be statically linked and completely self-sufficient  (without even allowing their configuration files to be separate.  So this will remain an aspect of system administration where  experience and creativity are called for (and a good backup  may be the only thing between you and major inconvenience).  -- Jim             Networking Problems      From: Bill Johnson,  b_johnson@cel.co.chatham.ga.us     I have two networking problems which may be related.  I'm using a  dial-up (by chat) ppp connection.   1) pppd will not execute for anyone without root privilege, even  though it's permissions are set rw for group and other.        I presume you mean that it's *x* (execute) bit is set.  It's *rw* bits should be disabled -- the *w* bit ESPECIALLY.    If you really want pppd to be started by users (non-root)  you should write a small C ""wrapper"" program that executes  pppd after doing a proper set of suid (seteuid) calls and   sanity checks.  You might be O.K. with the latest suidperl  (though there have been buffer overflows with some versions  of that.    Note that the file must be marked SUID with the chmod command  in order for it to be permitted to use the seteuid call  (unless ROOT is running it, of course).    Regardless of the method you use to accomplish your SUID of   pppd (even if you just set the pppd binary itself to SUID):    I suggest you pick or make a group (in /etc/group) and make  the pppd wrapper group executable, SUID (root owned), and   completely NON-ACCESSIBLE to ""other""  (and make sure to just  as the ""trusted"" users to the group.    'sudo' (University of Colorado, home of Evi Nemeth) is a   generalized package for provided access to privileged programs.  You might consider grabbing it and installing it.    I'd really suggest diald -- which will dynamically bring the   link up and down as needed.  Thus your users will just try to  access their target -- wait a long time for dialing, negotiation,  etc (just like pppd only a little faster) and away you go  (until your connection is idle long enough to count as a   ""timeout"" for diald.    2) http works, and mail works, and telnet works, but ftp does not  work.  I can connect, login, poke around, and all that.  But when I  try to get a file, it opens the file for writing on my machine and  then just sits there.  No data received, ever.  Happens with  Netscape, ftp, ncftp, consistently, at all sites. Even if user is  root.  Nothing is recorded in messages or in ppp-log.   /etc/protocols, /etc/services and all that seems to be set up  correctly.  Any suggestions?        Can you dial into a shell account and do a kermit   or zmodem transfer?  What does 'stty -a < /dev/modem'   say?  Make sure you have an eight-bit clean session.  Do you have 16550 (high speed) UARTS.    Do you see any graphics when you're using HTTP?  (that would suggest that binary vs. text is not the   problem).    -- Jim             Fetchmail      From: Zia Khan,  khanz@foxvalley.net     I have a question regarding fetchmail. i've been successful at using it to send and recieve mail from my ISP via a connection to their POP3 server. there is a slight problem though. the mail that i send out has in its from: field my local login and local hostname e.g. ruine@clocktower.net. when it should be my real email address khanz@foxvalley.net those who recieve my message recieve an non existant email address to reply to. is there any way in modifying this behavior? i've been investigating sendmail with hopes it may have have a means of making this change,to little success.         Technically this has nothing to do with fetchmail or POP.  'fetchmail' just *RECIEVES* your mail -- POP is just the   protocol for storing and picking up your mail.  All of your  outgoing mail is handles by a different process.    Sendmail has a ""masquerade"" feature and an ""all_masquerade""  feature which will tell it to override the host/domain portions  of the headers addresses when it sends your mail.  That's  why my mail shows up as ""jimd@starshine.org"" rather than   ""jimd@antares.starshine.org.""     The easy way to configure modern copies of sendmail is to use  the M4 macro package that comes with it.  You should be able to   find a file in /usr/lib/sendmail-cf/cf/     Mine looks something like:  divert(-1) include(`../m4/cf.m4') VERSIONID(`@(#)antares.uucp.mc  .9 (JTD) 8/11/95') OSTYPE(`linux')  FEATURE(nodns) FEATURE(nocanonify) FEATURE(local_procmail) FEATURE(allmasquerade) FEATURE(always_add_domain) FEATURE(masquerade_envelope)  MAILER(local) MAILER(smtp)  MASQUERADE_AS(starshine.org) define(`RELAY_HOST', a2i) define(`SMART_HOST', a2i) define(`PSEUDONYMS', starshine|antares|antares.starshine.org|starshine.org)     (I've removed all the UUCP stuff that doesn't apply to you  at all).     Note:  This will NOT help with the user name -- just the host and   domain name.  You should probably just send all of your outgoing   mail from an account name that matches your account name at your  provider.  There are other ways to do it  -- but this is the   easiest.    Another approach would require that your sendmail ""trust""  your account (with a define line to add your login ID as one  which is ""trusted"" to ""forge"" their own ""From"" lines in   sendmail headers.  Then you'd adjust your mail-reader to   reflect your provider's hostname and ID rather than your local  one.  The details of this vary from one mailer to another --  and I won't give the gory details here).    Although I said that this is not a fetchmail problem -- I'd  look in th fetchmail docs for suggestions.  I'd also read  (or re-read) the latest version of the E-Mail HOW-TO.    -- Jim             Procmail      Justin Mark Tweedie,  linda@zanet.co.za       Our users no not have valid command shells in the /etc/passwd file (they have /etc/ppp/ppp.sh). I would like the users to use procmail to process each users mail but .forward returns an error saying user does not have a vaild shell.   The .forward file has the following entry  |IFS=' '&&exec /usr/local/bin/procmail -f-||exit 75 #justin    How can I make this work ???  Cheers Justin         I suspect that its actually 'sendmail' that issuing the  complaint.    Add the ppp.sh to your /etc/shells file.  procmail will still use /bin/sh for processing the   recipes in the .procmailrc file.    Another method would be to use procmail as your local  delivery agent.  In your sendmail ""mc"" (m4 configuration   file) you'd use the following:   FEATURE(local_procmail)     (and make sure that your copy of procmail is in a place  where sendmail can find it -- either using symlinks or  by adding:   define(`PROCMAIL_PATH', /usr/local/your/path/to/procmail);     Then you don't have to muss with .forward files at all.  'sendmail' will hand all local mail to procmail which will  look for a .procmailrc file.    Another question to as is whether you want to use your   ppp.sh has a login shell at all.  If you want people to   login in and be given an automatic PPP connection I'd look  at some of the cool features of mgetty (which I haven't   used yet -- but seen in the docs).    These allow you to define certain patterns that will be   caught by 'mgetty' when it prompts for a login name --   so that something like Pusername will call .../ppplogin  while Uusername will login with with 'uucico' etc.    If you want to limit your customers solely to ppp services  and POP (with procmail) then you've probably can't do it in  any truly secure or reasonably way.  Since the .procmailrc  can call on arbitrary external programs -- the user with a   valid password and account can access other services on the   system.  Also the ftp protocol can be subverted to provide  arbitrary interactive access -- unless it is run in a   'chroot' environment -- one which would make the processing  of updating the user's .procmailrc and any other .forward or  configuration files a hassle.    It can be done -- but it ultimately is more of a hassle than   it's worth.  So if you want to securely limit your customers'  from access to interactive services and arbitrary commands  you'll want to look at a more detailed plan than I could   write up here.   -- Jim               /var/log/messages     From: Mike West,  mwest@netpath.net    Hi Jim,  This may seem like a silly question, but I've been unable to find any  HOW-TOs or suggestions on how to do it right.  My question is, how should  I purge my /var/log/messages file?  I know this file continues to grow.   What would be the recommended way to purge it each month?  Also, are  there any other log files that are growing that I might need to know  about?  Thanks in advance Jim.          I'm sorry to have dropped the ball on your message.  Usually when I don't answer a LG question right away  it's because I have to go do some research.  In this case  it was that I knew exactly what I wanted to say -- which would be  ""read my 'Log Management' article in the next issue of LG""     However haven't finished the article yet.  I have finished   the code.    Basically the quick answer is:       rm /var/log/messages   kill -HUP $(cat /var/run/syslog.pid)    (on systems that are configured to conform to the FSSTND   and putting a syslog.pid file in /var/run).    The HUP signal being send to the syslogd process is to   tell it to close and re-open its files.  This is necessary   because of the way that Unix handles open files.  ""unlinking"" a file (removing the directory entry for it)  is only a small part of actually removing it.  Remember that  real information about a file (size, location on the device,  ownership, permissions, and all three date/time stamps for   access, creation, and modification) is stored in the   ""inode.""  This is a unique, system maintained data structure.  One of the fields in the inode is a ""reference"" or ""link""   count.  If the name that you supplied to 'rm' was the only  ""hard link"" to the file than the reference count reaches  zero.  So the filesystem driver will clear the inode and  return all the blocks that were assigned to that file to the  ""free list"" -- IF THE FILE WASN'T OPEN BY ANY PROCESS!    If there is any open file descriptor for the file -- then  the file is maintained -- with no links (no name).  This   is because it could be critically bad to remove a file out  from under a process with no warning.    So, many daemons interrupt a ""Hang-up"" signal (sent via  the command 'kill -HUP') as a hint that they should  ""reinitialize in some way.  That usually means that they   close all files, re-read any configuration or options files  and re-open any files that they need for their work.    You can also do a        cp /dev/null /var/log/messages    .. and you get away without doing the 'kill -HUP'.    I don't really know why this doesn't get the syslog   confused -- since it's offset into the file is all   wrong.  Probably this generates a ""holey"" file -- which  is a topic for some other day.    Another quick answer is:    Use the 'logrotate' program from Red Hat.    (That comes with their 4.1 distribution -- and   is probably freely usable if you just want to    fetch the RPM from their web site.  If you don't   use a distribution that support RPM's you can    get converters that translate .rpm files into   tar or cpio files.  You can also just use   Midnight Commander to navigate through an RPM    file just like it was a tar file or a directory).    The long answer looks a little more like:   #! /bin/bash ## jtd: Rotate logs  ## This is intended to run as a cron job, once per day ## it renames a variety of log files and then prunes the ## oldest.  cd /var/log TODAY=$(date +%Y%m%d) # YYYYMMDD convenient for sorting  function rotate {  cp $1 OLD/${1}.$TODAY  cp /dev/null $1  }  rotate maillog rotate messages rotate secure rotate spooler rotate cron  ( echo -n ""Subject: Filtered Logs for:  "" ; date ""+%a %m/%d/%Y"" echo; echo; echo; echo ""Messages:"" /root/bin/filter.log /root/lib/messages.filter  OLD/messages.$TODAY  echo; echo; echo ""Cron:"" /root/bin/filter.log /root/lib/cron.filter OLD/cron.$TODAY  echo; echo; echo ""--""; echo ""Your Log Messaging System"" echo; echo; echo ) | /usr/lib/sendmail -oi -oe  root ## End of rotate.logs      That should be fairly self explanatory except for the   part at the end with the (....) | sendmail ....  stuff.  The parenthese here group the output from all  of those commands into the pipe for sendmail -- so the  provide a whole message for sendmail.  (Otherwise  only the last echo would go to sendmail and the  rest would try to go to the tty of the process that ran  this -- which (when cron runs the job) will generate a  different -- much uglier -- piece of mail.    Now there is one line in the sendmail group that bears  further explanation:  /root/bin/filter.log /root/lib/messages.filter  OLD/messages.$TODAY    This is a script (filter.log) that I wrote -- it   takes a data file (messages.filter) that I have created  in little parts over several weeks and still have to   update occasionally.    Here's the filter.log script:   #!  /usr/bin/gawk -f  # filter.log  # by James T. Dennis   # syntax filter.log patternfile  datafile [datafile2 .....]   # purpose -- trim patterns, listed in the first filename  # from a series of data files (such as /var/adm/messages)  # the patterns in the patternfile should take the form  # of undelimited (no '/foo/' slashes and no ""foo"" quotes)          # Note:  you must use a '-' as the data file parameter if          # if you to process stdin (use this as a filter in a pipe         # otherwise this script will not see any input from it!  ARGIND == 1  {    # ugly hack.   # allows first parameter to be specially used as the   # pattern file and all others to be used as data to   # be filtered; avoids need to use   # gawk -v patterns=$filename ....  syntax.  if ( $0 ~/^[ \t]*$/ ) { next }  # skip blank lines   # also skip lines that start with hash   # to allow comments in the patterns file.  if ( $0 !~ /^\#/ ) { killpat[++i]=$0 }}  ARGIND > 1 {   for( i in killpat ) {     if($0 ~ killpat[i]) { next }}}    ARGIND > 1 {    print FNR "": "" $0 }     That's about eight lines of gawk code.    I hope the comments are clear enough.  All this  does is reads one file full of pattern, and then  use that set of patterns as a filter for all of the  rest of the files that are fed through it.    Here's an excerpt from my ~root/lib/messages.filter  file:  ... ..? ..:..:.. antares ftpd\[[0-9]+\]: FTP session closed ... ..? ..:..:.. antares getty\[[0-9]+\]: exiting on TERM signal ... ..? ..:..:.. antares innd: .* ... ..? ..:..:.. antares kernel:[ \t]* ... ..? ..:..:.. antares kernel:   Type: .*      Basically those first seventeen characters on each   line match any date/time stamp -- the antares   obviously matches my host name and the rest of each  line matches items that might appear in my messages   file that I don't care about.    I use alot of services on this machine.  My filter  file is only about 100 lines long.  This scheme trims  my messages file (several thousand lines per day)  down to about 20 or 30 lines of ""different"" stuff  per day.    Everyone once in awhile I see a new pattern that   I add to the patterns list.    This isn't an ideal solution.  It is unreasonable to   expect of most new Linux users (who shouldn't ""have to""  learn this much about regular expressions to winnow   the chaff from their messages file.  However it is  elegant (very few lines of code -- easy to understand  exactly what's happening).    I thought about using something like swatch or some other  log management package -- but my concern was that these are  looking for ""interesting things"" and throwing the rest   away.  Mine looks for ""boring things"" and whatever is   left is what I see.  To me anything that is ""unexpected""  is interesting (in my messages file) -- so I have to use a   fundamentally different approach.   I look at these messages files as a professional sysadmin.  They may warn me about problems before my users notice them.   (incidentally you can create a larger messages file that  handles messages for many hosts -- if you are using   remote syslogging for example).    Most home users can just delete these files with abandon.   They are handy diagnostics -- so I'd keep at least a few  days worth of them around.     -- Jim              OS Showdown      From: William Macdonald  will@merchant.clara.net  Subject: OS showdown     Hi, I was reading one of the British weekly computing papers this week and there was an article about a shoot out between Intranetware and NT.  This was to take place on 20th May in the Guggenhiem museum in NYC.         Intranetware sounds interesting.  Sadly I think it may be  too little, too late in the corporate world.  However, if   Novell picks the right pricing strategy and niche they may be   able to come back in from the bottom.    I won't talk about NT -- except when someone is paying me   for the discomfort.         The task was to have a system offering an SQL server that could process 1 billion transasctions in a day.  This was supposed to be 10 time what Visa requires and 4 time what a corporation like American Airlines.  It was all about proving that these OSs could work reliably in a mission critical environment.          If I wanted to do a billion SQL transactions a day I'd probably   look at a Sun Starfire running Solaris.  The Sun Starfire  has 64 SPARC (UltraSPARC's??) running in parallel.    Having a face off between NT and Netware (or ""Intra"" Netware   as they've labelled their new release) in this category is   really ignoring the ""real"" contenders in the field of SQL.    Last I heard the world record for the largest database system  was owned by Walmart and ran on Tandem mini-computers.  However  that was several years ago.         I haven't seen the follow up article yet so I can't say what the result was.  The paper was saying it was going to be a massive comp with both the boss' there etc.         Sounds like typical hype to me.  Pick one or two companies  that you think are close to you and pretend that your small  group comprises the whole market.       How would linux fair in a comp like this ??  The hardware resources were virtually unlimited.  I think the NT box was a compaq 5000 (proliant ??).  Quad processors, 2 GB RAM, etc.        The OS really doesn't have to much to do with the SQL   performance.  The main job of the OS in running an SQL   engine is to provide system and file services as fast as  possible and stay the heck out of the way the real work.    The other issue is that the hardware makes a big difference.  So a clever engineer could make a DOG of a OS still look   like a charging stallion -- by stacking the hardware in  his favor.    If it was me -- I'd think about putting in a few   large (9 Gig) ""silicon disks.""  A silicon disk is really  a bunch of RAM that's plugged into a special controller  that makes it emulate a conventional IDE or SCSI hard   drive.  If you're Microsoft or Novell and you're serious   about winning this (and other similar) face offs -- the  half a million bucks you spend on the ""silicon disks""   may pay for itself in one showing.    In answer to your question -- Linux, by itself, can't   compete in this show -- it needs an SQL server.  Postgres  '95 is, from what I've seen and heard, much too lightweight  to go up against MS SQL Server -- and probably no match for  whatever Novell is using.  mSQL is also pretty lightweight.  Mind you P'gres '95 and mSQL are more than adequate for   most businesses -- and have to offer a price performance  ratio that's unbeatable (even after figuring in ""hidden""  and ""cost of ownership"" factors).  I'm not sure if Beagle  is stable enough to even run.    So we have to ask:     What other SQL packages are available for Linux?    Pulling out my trusty _Linux_Journal_1997_Buyers's_Guide_  (and doing a Yahoo! search) I see:     Solid    Just Logic Technologies     YARD Software GmbH       That's all that are listed in the Commercial-HOWTO  However -- here's a few more:     Infoflex --   (which goes into my Lynx hall of shame list --   it was quite a challenge reading that without   resorting to a GUI).   DBIX Information  -- (SQL Server???)      InterSoft (Essential -- SQL Engine)   Byte Designs Home on the Internet   (ISAM with ODBC/SQL gateways)   SQLGate User's Guide  -- (Embedding SQL in HTML)   April-15-1995 DATAMATION: International  -- Article on Linux     Sadly the ""big three"" (Informix, Oracle, and Sybase)   list nothing about Linux on their sites.  I suspect they   still consider themselves to be ""too good"" for us -- and   they are undoubtedly tangled in deep licensing aggreements  with SCO, Sun, HP, and other big money institutions.  So  they probably view us as a ""lesser threat"" -- (compared  to the 800 lb gorilla in Redmond).  Nonetheless -- it doesn't  look like they are willing to talk about Linux on their   web pages.    I'd also like to take this opportunity to lament the   poor organization and layout of these three sites.  These  are the large database software companies in the world --  and they can create a simple, INFORMATIVE web site.  Too   much ""hype"" and not enough ""text.""    (My father joked:  ""Oh! you meant 'hypertext' -- I thought  it was 'hype or text'""  -- Obviously too many companies  hear it the same way and choose the first option of a   mutually exclusive pair).     -- Jim                Adding Linux to a DEC XLT-366      From: Alex Pikus of WEBeXpress  alex@webexpress.net    I have a DEC XLT-366 with NTS4.0 and I would like to add Linux to it.  I have been running Linux on an i386 for a while.  I have created 3 floppies:    Linload.exe and MILO (from DEC site)  Linux kernel 2.0.25  RAM disk    I have upgrade AlphaBIOS to v5.24 (latest from DEC) and added a Linux boot option that points to a:\         You have me at a severe disadvantage.  I'll be running  Linux on an Alpha based system for the first time next  week.   So I'll have to try answering this blind.       When I load MILO I get the ""MILO>"" prompt without any problem.  When I do ""show"" or ""boot ..."" at the MILO>"" I get the following result ... SCSI controller gets identified as NCR810 on IRQ 28 ... test1 runs and gets stuck ""due to a lost interrupt"" and the system hangs ... In WinNTS4.0 the NCR810 appears on IRQ 29.             My first instinct is the ask if the autoprobe code in  Linux (Alpha) is broken.  Can you use a set of command-line  (MILO) parameters to tell pass information about your   SCSI controller to your kernel?  You could also see about  getting someone else with an Alpha based system to compile  a kernel for you -- and make sure that it has values in   it's scsi.h file that are appropriate to your system -- as  well as insuring that the corrective drivers are built in.       How can make further progress here?         It's a tough question.  Another thing I'd look at   is to see if the Alpha system allows booting from a  CD-ROM.  Then I'd check out Red Hat's (or Craftworks')  Linux for Alpha CD's -- asking each of them if they   support this sort of boot.    (I happened to discover that the Red Hat Linux 4.1 (Intel)  CD-ROM was bootable when I was working with one system that   had an Adaptec 2940 controller where that was set as an   option.  This feature is also quite common on other Unix  platforms such as SPARC and PA-RISC systems -- so it is   a rather late addition to the PC world).     -- Jim                  Configuration Problems of a Soundcard         From: Stuby Bernd,  eacj1049@inuers17.inue.uni-stuttgart.de    Hello there,  First I have to metion that my Soundcard (MAD16 Pro from Shuttle Sound System with an OPTi 82C929 chipset) works right under Windows. I tried to get my Soundcard configured under Linux 2.0.25.with the same  Parameters as under Windows but as I was booting the new compiled Kernel the Soundcard whistled and caused terrible noise. The same happened as I compiled the driver as a module and installed it in the kernel. In the 'README.cards' file the problem coming up just with this Soundcard is mentioned (something like line 3 mixer channel). I don't know what to do with this information and how to change the sounddriver to getting it working right. May be there's somebody who knows how to solve this problem or where I can find more information.   With best regards Bernd         Sigh.  I've never used a sound card in my machine.  I have a couple of them floating around -- and will  eventually do that -- but for now I'll just have to   depend on ""the basics""    Did you check the    Hardware-HOWTO ? I see the MAD16 and this chipset listed there.  That's encouraging. How about the    Soundcard-HOWTO ?   Unfortunately this has no obvious reference to your   problem.  I'd suggest browsing through it in detail.  Is your card a PnP (plug and ""pray"")?  I see notes  about that being a potential source of problems.  I also noticed a question about ""noise"" being ""picked  up"" by the sound card    http://sunsite.unc.edu/LDP/HOWTO/Sound-HOWTO-6.html#ss6.23   That might not match your probelm but it's worth looking at.    Did you double check for IRQ and DMA conflicts?   The thing I hate about PC sound cards is that most of them  use IRQ's and DMA channels.  Under DOS/Windows you used to be  able to be fairly sloppy about IRQ's.  When your IRQ conflicts  caused conflicts the symptoms (like system lockups) tend to   get lost in the noise of other problems (like system lockups  and mysterious intermittent failures).  Under Linux these   problems usually rear their ugly heads and have nowhere to   hide.     Have you contacted the    manufacturer  of the card?   I see a Windows '95 driver.  No technical notes on   their sound cards -- and no mention of anything other   than Windows on their web site (that I could find).  That would appear to typify the ""we only do Windows""  attitude of so many PC peripherals manufacturers.   I've blind copied their support staff on this -- so  they have the option to respond.    If this is a new purchase -- and you can't resolve the   issue any other way -- I'd work with your retailer or  the manufacturer to get a refund or exchange this with  hardware that meets your needs.   An interesting side note.  While searching through   Alta Vista  on   Yahoo!  I found a page that described itself as   The Linux Ultra Sound Project .   Perhaps that will help you choose your next PC sound system  (if it comes to that).   -- Jim               Procmail Idea and Question         From: Larry Snyder,  larrys@lexis-nexis.com     Just re-read your excellent article on procmail in the May LJ.   (And yes, I've read both man pages :-).  What I want to try is:     Ignore the header completely  Scan the body for  [*emov* *nstruction*]  or  remove@*   /dev/null anything that passes that test    This should be a MUCH cheaper (in cpu cycles) way of implementing a spam filter than reading the header then going through all the possible domains that might be applicable.  Most of the headers are forged in your  average spam anyway....   Not my idea, but it sounds good to me.  What do you think, and how would  I code a body scan in the rc?          I think it's a terrible idea.    The code would be simple -- but the patterns you suggest  are not very specific.    Here's the syntax (tested):     :0 B   * (\[.*remove.*instruction.*\]|\[.*remove@.*\])   /dev/null     ... note the capital ""B"" specifies that the recipe   applies to the ""Body"" of the message --  the line   that starts with an asterisk is the only conditional  (pattern) the parentheses enclose/group the regular  expression (regex) around the ""pipe"" character.  The  pipe character means ""or"" in egrep regex syntax. Thus  (foo|bar) means ""'foo' or 'bar'""    The square brackets are a special character in regexes  (where they enclose ""classes"" of characters).  Since   you appeared to want to match the literal characters  -- i.e. you wanted your phrases to be enclosed in  square brackets -- I've had to ""escape"" them in my  pattern -- so they are treated literally and not taken  as delimiters.      The * (asterisk) character in the regex means  ""zero or more of the preceding element"" and the . (dot or   period) means ""any single character"" --  so the   pair of them taken together means ""any optional characters""  If you use a pattern line like:     * foo*l     ... it can match fool fooool and fooooolk and even fol but   not forl or foorl.  The egrep man page is a pre-requisite to  any meaningful procmail work.  Also O'Reilly has an entire  book (albeit a small one) on regular expressions.    The gist of what I'm trying to convey is that .* is needed  in regex'es -- even though you might use just * in shell  or DOS ""globbing""  (the way that a shell matches filenames  to ""wildcards"" is called ""globbing"" -- and generally does  NOT use regular expressions -- despite some similarities   in the meta characters used by each).    Not also that the * token at the beginning of this line  is a procmail thing.  It just identifies this as being  a ""condition"" line.  Lines in procmail recipes usually start  with a token like a : (colon), a * (asterisk), a | (pipe) or  a ! (bang or exclammation point) -- any that don't   may consist of a folder name (either a file or a directory)  or a shell variable assignment (which are the lines with  = (equal signs) somewhere on them.    In other words the * (star) at the begining of that line  is NOT part of the expression -- it's a token that tells  the procmail processor that the rest of the line is a regex.     Personally I found that confusing when I first started with  procmail.    Back to your original question:    I'm very hesitant to blindly throw mail away.   I'd consider filing spam in a special folder which is   only review in a cursory fashion.  That would go something  like this:     :0 B:   * (\[.*remove.*instruction.*\]|\[.*remove@.*\])   prob.spam     Note that I've added a trailing : (colon) to the start  of the recipe.  This whole :x FLAGS business is a throwback  to an early procmail which required each recipe to specify  the number of patterns that followed the start of a recipe.  Later :0 came to mean ""I didn't count them -- look at the  first character of each line for a token.""  This means that  procmail will can forward through the patterns and -- when  one matches -- it will execute ONE command line at the end  of the recipe (variable assignments don't count).      I'm sure none of that made any sense.  So :0 starts a   recipe, the subsequent * ... lines provide a list of patterns,  and each recipe ends with a folder name, a pipe, or a   forward (a ! -- bang thingee).  The : at the *END* of the :0 B  line is a signal that this recipe should use locking -- so that  to pieces of spam don't end up interlaced (smashed together)  in your ""prob.spam"" mail folder.  I usually use MH folders  (which are directories in which each message takes up a single  file -- with a number for a filename).  That doesn't require  locking -- you'd specify it with a folder like:     :0    * ^TO.*tag   linux.gazette/.     ... (notice the ""/."" (slash, dot) characters at the end of this).    Also note that folder names don't use a path.  procmail  defaults to using Mail (like elm and pine).  You can set  the MAILDIR variable to over-ride that -- mine is set to  $HOME/mh.  To write to /dev/null (where you should NOT  attempt to lock the file!) you must use a full path  (I suppose you could make a symlink named ""null"" in your  MAILDIR or even do a mknod but....).  When writing procmail  scripts just think of $MAILDIR as your ""current"" directory  (not really but...) and either use names directly under it  (no leading slashes or dot/slash pairs) or use a full path.    The better answer (if you really want to filter  mail that looks like spam) is to write an auto-responder.  This should say something like:     The mail you've sent to foo has been trapped  by a filtering system.  To get past the filter  you must add the following line as the first  line in the body of your message:      ......    ... Your original message follows:      ......     ... using this should minimize your risks.  Spammers  rely on volume -- no spammer will look through thousands  of replies like this and manually send messages with the  requisite ""pass-through"" or ""bypass"" directive to all of   them.  It's just not worth it.  At the same time your  friends and business associates probably won't mind pasting  and resending (be sure to use a response format that   ""keeps"" the body -- since your correspondents may get  irritated if they have to dig up their original message for  you.    Here's where we can work the averages against the spammer.  He uses mass mailings to shove their message into our view  -- we can each configure our systems to require unique   (relatively insecure -- but unique) ""pass codes"" to reject  ""suspicious"" mail.  Getting the ""pass codes"" on thousands  of accounts -- and using them before they are changed -- is  not a task that can be automated easily (so long as we each  use different explanations and formatting in our ""bypass""  instructions.    More drastic approaches are:      Require that all incoming mail be PGP, PEM or    S/MIME signed -- and that the signatories    signature be on your mail keyring.  (Enhancements    would allow anyone to add themselves to your    mail keyring if they got thier signature ""counter    signed"" by anyone on one of your other keyrings).     (Return any unsigned mail with a message of   explanation).     Test all incoming mail against a list of    associates and friends -- accept anything from   them.  Test all remaining mail against a list of    know spammers -- reject those with an error   message.  Respond to all remaining mail to    explain your anti-spam policy -- and provide   ""bypass"" instuctions (so they can add themselves   to your accept list).     Compare the ""mail"" and ""envelope"" addresses   (the From: and From_ (space) header lines).   Reject any that are inconsistent.     Upgrade to a recent sendmail and configure the   ""reverse lookup"" and the ""rejection mailer table""   features (which I haven't done yet -- so I    know NOTHING about).     I hope some of these ideas help.    Here is a copy of one of my autoresponders for your   convenience:  :0 * < 1000 * !^FROM_DAEMON * !^X-Loop:[    ]*info@starshine.org * ^Subject:[    ]*(procmail|mailbot) | ((formail -rk -A ""Precedence: junk"" \ -A ""X-Loop: info@starshine.org"" ; \ echo ""Mail received on:"" `date`)  \ | $HOME/insert.doc -v file=$DOC/procmail.tutorial ) | $SENDMAIL -t -oi -oe      I realize this looks ugly.  The first condition is to  respond only to requests that are under 1K in size.  (An earlier recipe directs larger messages to me).  The next two try to prevent reponses to mail lists and  things like ""Postmaster@..."" (to prevent some forms of  ""ringing"") and check against the ""eXtended"" (custom)   header that most procmail scripts use to identify   mail loops.  The next one matches subjects of ""procmail""  or ""mailbot.""    If all of those conditions are met than the message is   piped to a complex command (spread over four lines -- it  has the trailing ""backslash"" at the end of each of those --  to force procmail to treat it all as a single logical line:     This command basically breaks down like so:      (( formail -rk ...      ... the two parenthese have to do with how the   data passes through the shell's pipes.  Each set   allows me to group the output from a series of   commands into each of my pipes.     .... the formail command creates a mail header   the -r means to make this a ""reply"" and the -k   means to ""keep"" the body.  The two -A parameters are   ""adding"" a couple of header lines.  Those are enclosed   in quotes because they contain spaces.     ... the echo command adds a ""timestamp"" to when   I received the mail.  The `date` (backtick ""date"")   is a common shell ""macro expansion"" construct --   Korn shell and others allow one to use the $(command)   syntax to accomplish the same thing.     Now we close the inner group -- so formail's output --   and the echo's output are fed into my little awk   script:  insert.doc.  This just takes a parameter   (the -v file=) and scans its input for a blank line.   After the first blank line insert.doc prints the    contents of ""file.""  Finally it then just prints   all of the rest of it's input.     Here's a copy of insert.doc:   #! /usr/bin/gawk -f /^[ \t]*$/ && !INSERTED { print; system(""cat "" file ); INSERTED=1} 1     ... that's just three lines:  the pattern matches any line  with nothing or just whitespace on it.  INSERTED is a variable  that I'm using as a flag.  When those to conditions are met  (a blank line is found *and* the variable INSERTED has not  yet been set to anything) -- we print a blank line, call  the system() function to cat the contents of a file -- whose  name is stored in the 'file' variable, and we set the   INSERTED flag.  The '1' line is just an ""unconditional true""  (to awk).  It is thus a pattern that matches any input --   since no action is specified (there's nothing in braces on   that line) awk takes the default action -- it prints the   input.     In awk the two lines:      1     ... and     {print}      ... are basically the same.  They both match    every line of input that  reaches them and they   both just print that and continue.    ... Back to our ugly procmail recipe.  'insert.doc'  has now ""inserted"" the contents of a doc file between  formail's header and the body of the message that was  ""kept.""  So we combine all of that and pipe it into   the local copy of sendmail.  procmail thoughtfully presets  the variable $SENDMAIL -- so we can use it to make our   scripts (recipes) more portable (otherwise they would   break when written on a system with /usr/lib/sendmail and  moved to a system that uses /opt/local/new/allman/sendmail  (or some silly thing like that)).    The switches on this sendmail command are:     -t (take the header from STDIN)  -oi (option: ignore lines that contain just a dot)  -oe (option: errors generate mail)     ... I'll leave it as an exercise to the reader to look  those up in the O'Reilly ""bat"" book (the ""official"" Sendmail   reference).    There are probably more elegant ways to do the   insertion.  However it is a little messy that   our header and our ""kept"" body are combined in   formail's output.  If we had a simple shell syntax  for handling multiple file streams (bash has this   feature -- but I said *simple*) then it would be   nice to change formail to write the header to one  stream and the body to another.  However we also want  to avoid creating temp files (and all the hassles   associated with cleaning up after them).  So -- this is  the shortest and least resource intensive that I've  come up with.     So that's my extended tutorial on procmail.    I'd like to thank Stephen R. van den Berg (SRvdB)  (creator of procmail), Eric Allman (creator of sendmail),  and Alan Stebbens (an active contributor to the procmail  mailing list -- and someone who's written some nice  extensions to SmartList).    Alan Stebbens' web pages on mail handling can be found  at:  http://reality.sgi.com/aks/mail       -- Jim              UUCP/Linux on Caldera        From: David Cook,  david_cook@VNET.IBM.COM    We have spoken before on this issue over the caldera-users list (which I dropped because of too much crap).  I recently gave up on Caldera's ability to support/move forward and acquired redhat 4.1.   All works well, except I cannot get uucico & cu to share properly the modem under control of uugetty. Other comm programs like minicom and seyon have no problem with it.   Both uucico and cu connect to the port and tell me that they cannot change the flow control !? and exit.    If I kill uugetty, both uucico and cu work perfectly.   In your discussion on the caldera newsgroup of Nov 2/96 you don't go into the details of your inbound connection, but you mention ""mgetty"" as opposed to uugetty.   What works/why doesn't mine?  What are pros/cons of mgetty?   By the way, I agree wholeheartedly with your rational for UUCP. Nobody else seems to apreciate the need for multiple peer connections and the inherit security concerns with bringing up an unattended TCP connection with an ISP.   Dave Cook, IBM Global Solutions.         The two most likely problems are:    lock files  or   permissions    There are three factors that may cause problems with   lock files:  location, name, and format.    For lock files to work you must use the same device   names for all access to a particular device -- i.e. if   you use a symlink named 'modem' to access your modem  with *getty -- then you must use the same symlink for   your cu, uucico, pppd, minicom, kermit, seyon, etc.    (or you must find some way to force them to map the  device name to a properly named LCK..* file).     You must also configure each of these utilities to look  for their lock files in the same location -- /var/lock/  under Red Hat.  This configuration option may need to be  done at compile time for some packages (mgetty) or it   might be possible to over-ride it with configuration   directives (Taylor UUCP) or even command line options.    The other things that all modem using packages have to   agree on is the format of the lock file.  This is normally  a PID number of the process that creates the lock.   It can  be in ""text"" (human readable) or ""binary"" form.      Some packages never use the contents of the lock file --   its mere existence is sufficient.  However most Linux/Unix   packages that use device lock files will verify the validity   of the lock file by reading the contents and checking the process  status of whatever PID they read therefrom.  If there is   ""no such process"" -- they assume that it is a ""stale"" lock  file and remove it.      I currently have all of my packages use text format and   the /dev/modem symlink to /dev/ttyS1 (thus if I move my  modem to /dev/ttyS2 or whatever -- say while migrating  everything to a new machine -- all I have to change is   the one symlink).  My lock files are stored in /var/lock/    Permissions are another issue that have to be co-ordinated  among all of the packages that must share a modem.  One   approach is to allow everyone write access to the modem.  This, naturally, is a security whole large enough to steer  an aircraft carrier through.    The most common approach is to make the /dev/ node owned  by uucp.uucp or by root.uucp and group writable.  Then we   make all of the programs that access it SGID or SUID (uucp).    Here are the permissions I currently have set:  $ ls -ald `which uucico` `which cu`  /dev/modem /dev/ttyS* /var/lock -r-sr-s---   1 uucp     uucp       /usr/bin/cu -r-sr-s---   1 uucp     uucp       /usr/sbin/uucico lrwxrwxrwx   1 uucp     uucp       /dev/modem -> /dev/ttyS1 crw-rw----   1 root     uucp       /dev/ttyS0 crw-rw-r--   1 root     uucp       /dev/ttyS1 crw-------   1 root     tty        /dev/ttyS2 crw-rw----   1 root     uucp       /dev/ttyS3 drwxrwxr-x   6 root     uucp       /var/lock     On the next installation I do I'll probably experiment  with tightening these up a little more.  For example I  might try setting the sticky bit on the /var/lock directory  (forcing all file removals to be by the owner or root).  That might prevent some programs from removing stale   lock files (they would have to be SUID uucp rather than   merely SGID uucp).    'cu' and 'uucico' are both SUID and SGID because they   need access to configuration files in which passwords  are stored.  Those are mode 400 -- so a bug in minicom  or kermit won't be enough to read the /etc/uucp/call   file (for example).  uucico is started by root run   cron jobs and sometimes from a root owned shell at   the console.  cu is called via wrapper script by members  of a modem group.    Things like pppd, diald, and mgetty are always exec'd by  root (or SUID 'root' wrappers).  mgetty is started by   init and diald and pppd need to be able to set routing  table entries (which requires root).  So they don't need  to be SUID anything.  (If you want some users to be able to   execute pppd you can make it SUID or you can write a simple  SUID wrapper or SUID perl script.  I favor perl on my home   system and I make the resulting script inaccessible (unexecutable)  by ""other"".  At customer sites with multi-user systems I   recommend C programs as wrappers -- a conservative approach  that's been re-justified by recent announcements of new   buffer overflows in sperl 5.003).    Oddly enough ttyS2 is the null modem that runs into the   living room.  I do a substantial portion of my writing  while sitting in my easy chair watching CNN and SF   (Babylon 5, Deep Space 9, Voyager that stuff).      Permissions are a particularly ugly portion of Unix  since we rightly don't trust SUID things (with all of the  buffer overflows, race conditions between stat() and open()  calls and complex parsing trickery (ways to trick embedded  system(), popen() and other calls that open a shell behind  the programmer's back -- and are vulnerable to the full range  of IFS, SHELL, alias, and LD_* attacks).    However I'm not sure that the upcoming Linux implementation  of ACL's will help with this.  I really need to read more  about the planned approach.  If it follows the MLS (multi-  layer security) model of DEC and other commercial Unix   implementations -- then using them make the system largely  unusable for general-purpose computing (i.e. -- cast them  solely as file servers).    From what I've read some of the problem is inherent in basing   access primarily on ID and ""group member ship"" (really an   extension of ""identity"").  For a long time I racked my brains  to try to dream up alternative access control models -- and   the only other one I've heard of is the ""capabilities"" of  KeyKOS, Multics, and the newer Eros project.    Oh well -- we'll see.  One nice thing about having the  Linux and GNU project consolidating some much source code  in such a small number of places is that it may just be   possible to make fundamental changes to the OS design and  ""fix"" enough different package to allow some those changes  to ""take"" (attain a critical mass).   -- Jim                                             ActiveX for Linux         To: John D. Messina,  messina@bellatlantic.net    I was recently at the AIIM trade show in New York.  There was nothing for Linux there, but I happened to wander over to the cyber cafe that was set up.  I happened to be reading last month's Linux Gazette when a Microsoft employee walked up behind me.  He was excited to find someone who was knowledgeable about Linux - he wanted to get a copy for himself.        I presume that you're directing this to the ""Linux Gazette  Answer Guy.""       Anyway, we got to talking and he told me that Linux was getting so popular that Microsoft had decided to port ActiveX to Linux.  Do you know if, in fact, this is true?  If so, when might we see this port completed?       I have heard the same story from other Microsoft   representatives (once at a Java SIG meeting where  the MS group was showing off their J++ package).    This doesn't tell me whether or not the rumor is   ""true"" -- but it does suggest that it is an   ""officially condoned leak.""  Even if I'd heard an  estimated ship date (I heard this back in Nov. or  Dec.) I wouldn't give it much credence.     (That is not MS bashing by the way --   I consider ship dates from all software   companies and groups -- even our own    Linus and company -- to be fantasies).    To be honest I didn't pursue the rumor.  I asked  the gentlemem I spoke to what ActiveX provides that  CGI, SSI (server side includes), XSSI (extended   server side includes), FastCGI, SafeTCL, Java and   JavaScript don't.  About the only feature they could   think of is that it's from Microsoft.  To be honest   they tried valiantly to describe something -- but I   just didn't get it.      So, your message as prompted me to ask this question  again.  Switching to another VC and firing up Lynx and  my PPP line (really must get that ISDN configured one   of these dasy) I surf on over to MS' web site.      After a mildly amusing series of redirects (their sites   seems to be *all* .ASP (active server procedures?) files)  I find my self at a reasonably readable index page.  That's  hopeful -- they don't qualify for my ""Lynx Hall of Shame""  nomination.  I find the ""Search"" option and search on the  single keyword ""Linux.""    ""No Documents Match Query""    ... hmm.  That would be *too* easy wouldn't it.  So I search  on ActiveX:    ""No Documents Match Query""    ... uh-oh!  I thought this ""Search"" Feature would search   massive lists of press releases and ""KnowlegeBase"" articles  and return thousands of hits.  Obviously MS and I are   speaking radically different languages.    Let's try Yahoo!    So I try ""+ActiveX +Linux.""       Even more startling was the related rumor -- that   I heard at the same Java SIG meeting.  The Microsoft  reps there announced Microsoft's intention to port  IE (Internet Explorer) to Unix.  They didn't say which  implementations of Unix would be the recipients of this  dubious honor -- but suggested that Linux was under  serious consideration.    (We can guess that the others would include SCO, Solaris,  Digital, and HP-UX.  Some of MS' former bed partners  (IBM's AIX) would likely be snubbed -- and more ""obscure""  OS' (like FreeBSD???), and ""outmoded"" OS' like SunOS  are almost certainly to be ignored).    It appears that the plan is to port ActiveX to a few  X86 Unix platforms -- and use that to support an IE  port (I bet IE is in serious trouble without ActiveX))    They'll run the hype about this for about a year before  shipping anything -- trying to convince people to wait a   little longer before adopting any other technologies.    ""No! Joe!  Don't start that project in Java -- wait a   couple of months and those ""Sun"" and ""Linux"" users will  be able to use the ActiveX version.""    Some Links on this:     PC WEEK : ActiveX moving to Unix; Netscape support lags   ActiveX--Zendetta     ANTENNA ActiveX Mini-HOWTO    This last one is amusing since it displays a footer at the  end of every page:    ""This server is: Digital Multia VX40 - Running RedHat Linux""   Here's one that meets my criteria for ""Hall of Shame"",   Connected Place Ltd . Now here's one that meets my criteria for ""Hall of Shame"".   It contained no text on the main index page -- all icons.    The only reference to Linux on the site seemed to be in   the Keywords tag:       <META Name=""KEYWORDS"" Content=""....>    (Which repeated every term about four times -- this tag was   a half a screenful long).  Unfortunately it showed up   first in the hits list (first page in English that is --  the one French page that preceded just had an ""I've moved  notice"" -- or maybe it was a ""You're a silly goat"" message  -- my French never was that good).   Jason't Programmer Corner   ... which started with the words,  ""ActiveX Sucks!""    ... and said nothing else on the matter.  However,  it doesn't make it into the Hall of Shame -- because  the page is well organized, easily read -- only two  ""un-ALT'd"" icons on several pages of information -- and  has many good Linux and other links.  Even the ""hit counter""  works in Lynx saying,    ""You are visitor number 253 since 8.4.97""      Everybody who uses NetNews or E-Mail should read the little  essay on ""Good Subject Lines.""   A promising page which I didn't have time to properly  peruse is    Sean Michael Mead's Computer Programming Links     which had ""ActiveX"" in the Meta, Keywords tag --  but no obvious links to ActiveX content.    There was alot of good info on Java, Linux, HTML,  Ada, TCL and many other topics.  I wouldn't be surprised  if there was something about ActiveX somewhere below  this page.      Suggestion: Sean -- Install Glimpse!    (I've copied many of the owners/webmasters at the   sites I'm referring to here).   ActiveX Resources ,   only had one reference to Linux.  This noted that  the ""Liquid Reality Toolkit"" is a ""is a set of Java class   libraries that gives you VRML functionality.""   Sounds interesting and wholly unrelated to ActiveX.     Conclusion:   Microsoft's mumblings to Linux users about porting IE and  ActiveX to Linux is interesting.  The mumbling is more   interesting than any product they deliver is likely to be.    I still don't know what ActiveX ""does"" well enough to   understand what ""supporting ActiveX under Linux"" would mean.    It seems that ActiveX is a method of calling OCX and DLL  code.  That would imply that *using* ActiveX controls on   Linux would require support for OCS and DLL's -- which would   essentially mean porting all of the Windows API to work  under Linux.    Now I have alot of trouble believing that Microsoft will  deliver *uncompromised* support for Windows applications  under Linux or any other non-Microsoft OS.      Can you imaging Bill Gates announcing that he's writing a   multi-million dollar check to support the WINE project?    If that happens I'd suggest we call in the Air Force with   instructions to rescue the poor man from whatever UFO   snatched him -- and get the FBI to arrest the imposter!    What's amazing is that this little upstart collection of  freeware has gotten popular enough that the largest software  company in the world is paying any attention to it at all.    Given Microsoft's history we have to assume that any   announcement they make regarding Linux is carefully   calculated to offer them some substantial benefit in  their grand plan.  That grand plan is to dominate the   world of software -- to be *THE* software that controls  everything (including your toaster and your telephone)  (and everyone???).    This doesn't mean that we should react antagonistically  to these announcements.  The best bet -- for everyone  who must make development or purchasing plans  for any  computer equipment -- is to simply cut through as much  of the hype as possible and ask:    What are the BENEFITS of the package   that is shipping NOW?    Don't be swayed by people who talk about FEATURES  (regardless of whether they are from from Microsoft,   the local used car lot, or anywhere else).    The difference between BENEFITS and FEATURES is simply  this --     Benefits are relevant to you.    The reason software publishers and marketeers in general  push ""features"" is because they are engaged in MASS   marketing.  Exploring and understanding individual   set of requirements is not feasible in MASS marketing.    (Personally one of the features that I find to be a   benefit in the Linux  market is the lack of hype.  I   don't have to spend time translating marketese and   advertisian into common English).     I hope this answers your question.  The short answers are:     Is it true (that MS is porting ActiveX to *ix)?      The rumor is widespread by their employees    -- but there are no ""official"" announcements    that can be found on their web site with     their own search engine.     When might we see it?     Who nows.  Let's stick with NOW.    Finally let me ask this:   What would you do with ActiveX support under Linux?  Have you tried WABI?  Does ActiveX work under Windows 3.1  and/or Windows 3.11?  Would you try it under WABI?    What are your requirements (or what is your wishlist)?    (Perhaps the Linux programming community can     meet your requirements and/or fullfill your     wishes more directly).            What Packages Do I Need?         From: buck,  buck@athenet    I just installed Redhat 4.1 and was not sure what packages that I really needed so I installed a lot just to be safe. The nice thing is that Redhat 4.1 has the package manager that I can use to safely remove items. Well seeing as how my installation was about 400 megs I really need to clean house here to reclaim space. Is is save to remove the developement packages and a lot of the networking stuff that I installed. And what about the shells and window managers that I don't use. I have Accelerated X so I know that I can get rid of a lot off the X stuff. I need my space back!        Since you just installed this -- and haven't had much time  to put alot of new, unrecoverable data on it -- it should be  ""safe"" to do just about anything to it.  The worst that will  happen if you trim out to much is that you'll have to re-install.    I personally recommend the opposite approach.  Install the   absolute minimum you think is usable.  Then *add* packages  one at a time.    I also strongly suggest creating a /etc/README file.    Create it *right after* you reboot you machine following  the install process.  Make a dated note in there for   each *system* level change you make to your system.  (My rule of thumb is that anything thing I edited   or installed as 'root' is a ""system"" level change).    Most of my notes are in the form of comments near the top  of any config files or scripts that support them. Typical   notes in /etc/README would be like:        Sun Apr 13 15:32:00 PDT 1997: jimd     Installed mgetty.  See comments in     /usr/local/etc/mgetty/*.config.    Sun May  4 01:21:11 PDT 1997: jimd     Downloaded 2.0.30 kernel.    unpacked into /usr/local/src/linux-2.0.30    and replace /usr/src/linux symlink     accordingly.     Picked *both* methods of TCP SYN    cookies.  Also trying built-in kerneld    just about everything is loadable modules.    Adaptec SCSI support has to be built-in    though.     Needed to change rc files to do the    mount of DOS filesystem *after* rc.modules.      ... etc.     Notice that these are free form -- a date, and login  name (not ROOT's id -- but whoever is actualy doing  work as root).  I maintain a README even on my   home machines.      The goal is to keep notes that are good enough that   I could rebuild my system with all the packages I   currently use -- just using the README. It tells me   what packages I installed and what order   I installed them in.  It notes what things seemed   important to me at the time (like the note that   trying to start a kernel whose root filesystem is on  a SCSI disk requires that the kernel be compile with  that driver built-in -- easy to overlook and time consuming  to fix if you forget it).    Sometime I ask myself questions in the README -- like:    ""Why is rnews throttling with this error:...""   (and an excerpt from my /var/log messages).    This is handy if you later find that you need to correlate  an anomaly on your system with some change made by your  ISP -- or someone on your network.    Of course you could succumb to the modern trend -- buy  another disk drive.  I like to keep plenty of those  around.  (I have about 62Mb of e-mail currently cached  in my mh folders -- that's built up since I did a fresh  install last August -- with a few megs of carry over from  my previous installation).   -- Jim                                             Users and Mounted Disks         To: John E. (Ned) Patterson,  jpatter@flanders.mit.edu ,br>    As a college student on a limited budget, I am forced to comprimise between Win95 and Linux.  I use linux for just about everything, but need the office suite under Win95 since I can't afford to buy something for Linux.  (Any recommendations you have for cheep alternatives would be appreciated, but that is not the point of the question.)         I presume you mean MS Office.  (Caps mean a bit here).  I personally have managed to get by without a couple of   Office (Word or Excel) for some time.  However I realize   that many of us have to exchange documents with    ""less enlightened""  individuals (like professors  employers and fellow students).    So getting MS Office so you can handle .DOC and .XLS   (and maybe PowerPoint) files is only a venial sin in   the Church of Linux (say a few ""Hail Tove's"" and go in  peace).    As for alternatives:  Applixware, StarOffice, CliqSuite,  Corel Application Suite (in Java), Caldera's Internet Office  Suite, and a few others are out there.  Some of them can   do some document conversions from (and to??) .DOC format.     Those are all applications suites.  For just spreadsheets  you have Xess, Wingz and others.    In addition there are many individual applications.  Take a look at the Linux Journal Buyer's Guide Issue for  a reasonably comprehensive list of commercial applications  for Linux (and most of the free was as well).    Personally I use vi, emacs (in a vi emulation mode -- to   run M-x shell, and mh-e), and sc (spreadsheet calculator).    Recently I've started teaching myself TeX -- and I have  high hopes for LyX though I haven't even seen it yet.    Unfortunately there is no good solution to the problem of   proprietary document formats. MS DOC and MS XLS files are  like a stranglehold on corporate America.  I can't really   blame MS for this -- the competition (including the   freeware community) didn't offer a sufficiently attractive  alternative.  So everyone seems to have stepped up to the  gallows and stuck their own necks in it.    ""Owning"" an ubiquitous data format is the fantasy of   every commercial software company.  You're customers will  pass those documents around to their associates, vendors,  even customers, and *expect* them to read it.  Obviously   MS is trying to leverage this by ""integrating"" their   browser, mailer, spreadsheet, and word processors together  with OLE, DSOM, ActiveX and anything else they can toss  together.    The idea is to blur everything together so that customers  link spreadsheets and documents into their web pages and  e-mail -- and the recipients are then forced to have the  same software.  Get a critical mass doing that and   ""everyone"" (except a few fringe Unix weirdos like me)  just *HAS* to belly up and buy the whole suite.    This wouldn't be so bad -- but then MS has to keep revenues  increasing (not just keep them flowing -- but keep them  *increasing*).  So we get upgrades.  Each component of your  software system has to be upgraded once every year or two --  and the upgrade *MUST* change some of the data (a one way  conversion to the new format) -- which transparently makes  your data inaccessible to anyone who's a version behind.     Even that wouldn't be so bad.  Except that MS also has its  limits.  It can't be on every platform (so you can't access  that stuff from your SGI or your Sun or your HP 700 or your  OS/400).  Not that MS *couldn't* create applications for  these platforms.  However that might take away some of Intel's  edge -- and MS can't *OWN* the whole OS architecture on your  Sun, SGI, HP or AS/400.    But enough of that diatribe.  Let's just say -- I don't  like proprietary file formats.       I mount my Win95 partition under /mnt/Win95, and would like to have write permission enabled for only certain users, much like that which is possible using AFS.  Recognizing that is not terribly feasable, I have resorted to requireing root to mount the partition manually, but want toi be able to write to it as a random user, as long as it is mounted.  The rw option for mount does not seem to cut the mustard, either.  it allows write for root uid and gid, but not anyone else. Any suggestions?        You can mount your Win95 system to be writable by a   specific group.  All you have to do is use the right  options.  Try something like:  mount -t umsdos -w -ogid=10,uid=0,umask=007 /dev/hda1 /mnt/c     (note: you must use numeric GID and UID values here  -- mount would look them up by name!)    This will allow anyone in group 10 (wheel on my system)  to write to /mnt/c.    There are a few oddities in all of this.  I personally  would prefer to see a version of 'mount' -- or an option  to 'mount' that would mount the target with whatever   permissions and modes the underlying mount point had  at mount time.  In other words, as an admin., I'd like to  set the ownership and permissions on /mnt/c to something  like joeshmo user with a mode of 1777 (sticky bit set).  Then I'd use a command like:     mount -o inherit /mnt/c /dev/hda1     Unfortunately I'm not enough of a coder to feel comfortable  make this change (yet) and my e-mail with the current   maintainer of the Linux mount (resulting from the last time  I uttered this idea in public) suggests that it won't come  from that source.    (While we were at it I'd also add that it would be nice  to have a mount -o asuser -- which would be like the   user option in that it would allow any user (with access  to the SUID mount program) to mount the filesystem.  The  difference would be that the resulting mount point would be  owned by the user -- and the nodev, nosuid etc, options would  be enforced.)    Getting back to your question:    Another way to accomplish a similar effect (allowing  some of your users to put files on under you /mnt/Win95  directory) would be to create a /usr/Win95 directory --  allow people to write files into that and use a   script to mirror that over to the /mnt/Win95 tree.    (Personally I think the whole this is pretty dangerous   -- so using the -o gid=... is the best bet).    -- Jim             [q] Map Left Arrow to Backspace        To:  wenbing@statcan.ca    I have a client who would like to use the left arrow key to backspace  and erase characters to the left of the cursor. Is this possible? And how? Thanks for an answer.         Read the Keyboard-HOWTO (section 5).   The loadkeys and xmodmap man pages, and the   Backspace-Mini-HOWTO are also related to this. It is   possible to completely remap your keys in Linux and in   X Windows.  You can also set up keybindings that are   specific to bash (using the built in bind command) and  to bash and other programs that use the ""readline""   library using the .inputrc file.    The Keyboard-HOWTO covers all of this.   -- Jim             Adding Programs to the Pull Down Menus         To: Ronald B. Simon,  rbsimon@anet.bna.boeing.com    I have written several utility programs that I use all the time.  I  would like to add them to either the Application or Utility ""pull  down"" menu of the Start menu.  Could you address this in your Linux  Gazette article?         I assume you are referring to the menus for your   X ""Window Manager.""    Since you don't specify which window manager you're using  (fvwm, fvwm95, twm, gwm, ctwm, mwm, olwm, TheNextLevel ---  there are lots of wm's out there) -- I'll have to guess  that you're using fvwm (which is the default) on most  XFree86 systems.  The fvwm95 (which is a modification of  fvwm to provide a set of menus and behaviors that is   visually similar to that of Windows '95) uses the same   file/menu format (as far as I know).    The way you customize the menus of almost any wm is to   edit (possibly creating) an rc file.  For fvwm that would be  ~/.fvwmrc    Here's an excerpt from mine (where I added the Wingz   demo):  Popup ""Apps""         Exec    ""Wingz""         exec /usr/local/bin/wingz &         Nop     """"         Exec    ""Netscape""      exec netscape &         Exec    ""Mosaic""        exec Mosaic &         Nop     """"         Exec    ""Elm""           exec xterm -e elm &         Nop     """" EndPopup   You'd just add a line like:   Exec ""Your App"" exec /path/to/your/app &   .... to this.   If you add a line like:   PopUp ""My Menu"" MyMenu   ... and a whole section like:  PopUp ""MyMenu""  Exec ""One App"" exec /where/ever/one.app &  Exec ""Another Toy""   exec /my/bin/toy & EndPopUp      ... you'll have created your on submenu.   Most other Window Managers have similar features and   man pages to describe them.   -- Jim             Linux and NT         To: Greg C. McNichol,  greg_c_mcnichol@em.fcnbd.com    I am new to LINUX (and NT 4.0 for that matter) and would like any and all  information I can get my hands on regarding the dual-boot issue. Any help  is appreciated.         More than you wanted to know about:   Booting Multiple Operating Systems    There are several mini-HOW-TO documents specifically  covering different combinations of multi-boot.  Here's  some that can be found at:    http://www.linuxresources.com//LDP/HOWTO/HOWTO-INDEX.html      Linux+DOS+Win95 mini-HOWTO     How to use Linux and DOS and Windows95 together.           Updated 10 September 1996.   Linux+DOS+Win95 mini-HOWTO            How to use Linux and OS/2 and DOS together.           Updated 20 May 1996.   Linux+OS2+DOS mini-HOWTO            How to use Linux and DOS and OS/2 and Win95 together.           Updated 6 March 1996.   Linux+DOS+Win95+OS2            How to use Linux and Windows95 together.           Updated 25 June 1996.    Linux+WinNT mini-HOWTO            How to use Linux and WindowsNT together.           Updated 19 February 1997.    Linux+WinNT++ mini-HOWTO  by Kurt Swendson   How to use Linux and WindowsNT together, with NT preinstalled.           Updated 21 December 1996.      Personally I think the easiest approach to make   Linux co-exsist with any of the DOS derived OS'  (Win  '95, OS/2, or NT) is to use Han Lerman's  LOADLIN package.  Available at ""Sunsite"":   ftp://sunsite.unc.edu/pub/Linux/system/Linux-boot/lodlin16.tgz   (85k)     To use this -- start by installing a copy of DOS  (or Win '95).  Be sure to leave some disk space  unused (from DOS/Win '95's perspective) -- I like  to add whole disks devoted to Linux.    Now install Linux on that 2nd, 3rd or nth hard drive --  or by adding Linux partitions to the unused portion of  whichever hard drives you're already using.  Be sure to   configure Linux to 'mount' your DOS partition(s)  (make them accessible as parts of the Unix/Linux directory  structure).  While installing be sure to answer ""No""  or ""Skip"" to any questions about ""LILO""  (Feel free to   read the various HOW-TO's and FAQ's so you'll understand  the issues better -- I'd have to give a rather complete  tutorial on PC Architecture, BIOS boot sequence and   disk partitioning to avoid oversimplifying this last item)    Once you're done with the Linux installation find and   install a copy of LOADLIN.EXE.  The LOADLIN package   is a DOS program that loads a Linux kernel.  It can be  called from a DOS prompt (COMMAND.COM or 4DOS.COM) or   it can be used as a INSTALL directive in your CONFIG.SYS   (which you'd use with any of the multi-boot features  out there -- including those that were built into DOS  6.x and later).  After installation you'd boot into DOS  (or into the so-called ""Safe-Mode"" for Windows '95) and  call LOADLIN with a batch file like:    C:   CD \LINUX   LOADLIN.EXE RH2013.KRN root=/dev/hda2 .....     (Note the value of your root= parameter must correspond  to the Linux device node for the drive and partition on  which you've installed Linux.  This example shows the   second partition on the first IDE hard drive.  The first  partition on the second IDE drive would be /dev/hdb1  and the first ""logical"" partition within an extended partition  of your fourth SCSI hard drive would be /dev/sdd5.  The  PC Architecture specifies room for 4 partitions per drive.  Exactly one of those (per drive) may be an ""extended"" partition.  An extended partition may have an arbitrary number of   ""logical"" drives.  The Linux nomenclature for logical drives  always starts at 5 since 1 through 4 or reserved for the   ""real"" partitions).    The root= parameter may not be necessary in some cases  since the kernel has a default which was compiled into  it -- and which might have been changed with the rdev   command.  rdev is a command that ""patches"" a Linux kernel  with a pointer to it's ""root device.""    This whole concept of the ""root device"" or ""root filesystem""  being different than the location of your kernel may be   confusing at first.  Linux (and to a degree other forms  of Unix) doesn't care where you put you kernel.  You can   put it on a floppy.  That floppy can be formatted with a DOS,   Minix or ext2 filesystem -- or can be just a ""raw"" kernel  image.  You can put your kernel on ANY  DOS filesystem  so long as LOADLIN can access it.    LOADLIN and LILO are ""boot loaders""  they copy the   kernel into RAM and execute it.  Since normal DOS  (with no memory managers loaded -- programs like EMM,  QEMM, and Windows itself) has no memory protection  mechanisms it is possible to load an operating sytem   from a DOS prompt.  This is, indeed, how the Netware 3.x  ""Network Operating System"" (NOS) has always been loaded  (with a ""kernel"" image named SERVER.EXE).  It is also  how one loads the TSX-32 (a vaguely VMS like operating   system for 386 and later PC's).    My my example RH2013.KRN is the name of a kernel file.  Linux doesn't care what you name it's kernel file.  I  use the convention of naming mine LNXvwyy.KRN -- where  v is the major version number, w is the minor version and  yy is the build.  LNX is for a ""general use"" kernel that  I build myself, RH is a kernel I got from a RedHat CD,  YGG would be from an Yggdrasil, etc).    One advantage of using LOADLIN over LILO is that can  have as many kernels and your disk space allows.  You can  have them arranged in complex hierarchies.  You can have as  many batch files passing as many different combinations of   of kernel parameters as you like.  LILO is limited to  16 ""stanzas"" in its /lilo.conf file.    The other advantage of LOADLIN over LILO is that it is  less scary and hard to understand for new users.  To them  Linux is just a DOS program that you have to reboot to get   out of.  It doesn't involve any of that mysterious   ""master boot record"" stuff like a computer virus.    A final advantage of LOADLIN over LILO is that LOADLIN  does not require that the root file system be located   on a ""BIOS accessible"" device.  That's a confusing   statement -- because I just tossed in a whole new   concept.  The common system BIOS for virtually ALL   PC's can only see one or two IDE hard drives (technically   ST-506 or compatible -- with a WD8003 (???) or register   compatible controller -- however ST-506 (the old MFM and  RLL drives) haven't been in use on PC's since the XT)  To ""see"" a 3rd or 4th hard drive -- or any SCSI hard   drive the system requires additional software or firmware  (or an ""enhanced BIOS"").  There is a dizzying array of   considerations in this -- which have almost as many   exceptions.  So to get an idea of what is ""BIOS"" accessible  you should just take a DOS boot floppy -- with no CONFIG.SYS  at all -- and boot off of it.  Any drive that you can't see  is not BIOS accessible.    Clearly for the vast majority of us this is not a problem.  For the system I'm on -- with two IDE drives, two internal  SCSI drives, one internal CD reader, an external SCSI   hard drive, a magneto optical drive, a 4 tape DAT autochanger  and a new CD-Writer (which also doubles as a CD reader, of  course) -- with all of that it makes a difference.     Incidentally this is not an ""either/or"" proposition.  I have LILO installed on this system -- and I have  LOADLIN as well.  LILO can't boot my main installation  (which is on the SCSI drives.  But it can boot a second  minimal root installation -- or my DOS or OS/2 partitions.    (I'm not sure the OS/2 partition is still there -- I   might have replaced that with a FreeBSD partition at  some point).    Anyway -- once you have DOS and Linux happy -- you can   install NT with whatever ""dual boot"" option it supports.  NT is far less flexible about how it boots.  So far as   I know there is no way to boot into DOS and simply  run NT.    It should be noted that loading an OS from DOS (such as  we've described with LOADLIN, or with FreeBSD's FBSDBOOT.EXE  or TSX-32's RUNTSX.EXE) is a ONE WAY TRIP!   You load them  from a DOS prompt -- but DOS is completely removed from   memory and there is no way to exit back to it.  To get back  to DOS you much reboot.  This isn't a new experience to   DOS users.  There have been many games, BBS packages and  other pieces of software that had not ""exit"" feature.    (In the case of Netware there is an option to return to   DOS -- but it is common to use an AUTOEXEC.NCF (netware  control file) that issues the Netware command REMOVE DOS  to free up the memory that's reserved for this purpose).    In any event those mini-HOWTO's should get you going.  The rest of this is just background info.     -- Jim             pcmcia 28.8 Modems and Linux 1.2.13 Internet Servers         To: Brian Justice     I was browsing the web and noticed your web page on Linux.  I am not  familar with Linux but have an ISP who uses the software on their  server.    I was wondering if anyone at your organization knew of any problems with         I'm the only one at my organization -- Starshine is a   sole proprietorship.       Pentium notebooks with 28.8 modems connecting to Linux 1.2.13 internet  servers that would do the following:       drop connection at 28.8 after connected for several minutes      have trouble on the initial connection or reconnection          It sounds like you're saying that the Pentium Notebook  is running some other OS -- like Windows or DOS and that  it is using a PCMCIA modem to dial into another system  (with unspecified modem and other hardware -- but which   happens to run Linux).    If that's the case then you're troubleshooting the  wrong end of the connection.    First identify which system is having the problem --  use the Pentium with the ""piecemeal"" (PCMCIA) modem to  call a BBS or other ISP at 28.8.  Try several.      Does your Pentium sytem have problems with all or most of them?      If so then it is quite likely a problem with the combination   of your Pentium, your OS, and your piecemeal modem.      Try booting the Pentium off of a plain boring copy of DOS   (with nothing but the PCMCIA drivers loaded).  Repeat the   other experiments.  Does it still fail on all or most of  them?    If so then it is probably the PCMCIA drivers.         Regular desktop 28.8 modems seem to work fine.  I have a few 14.4 PCMCIA modems that seem to work fine.   Would incorrect settings cause this?  Or could this be a program glitch that doesn't support these 28.8 modems due to the low level of the release?  I noticed their are higher versions of Linux out there.         ""incorrect settings"" is a pretty vague term.  Yes. The   settings on your hardware *AND THEIRS* and the settings  in your software *AND THEIRS* has to be right.    Yes.  The symptoms of incorrect settings (in the server   hardware, the modem hardware, the OS/driver software or the   applications software *AT EITHER END OF THE CONNECTION* could   cause sufficiently sporadic handshaking that one or the other   modem in a connection ""gives up"" and hangs up on the other.        The BIG question is ""Have you heard of any 28.8 PCMCIA modem problems with Linux internet servers? ""  If so, could you drop me a few lines so I can talk this over with my ISP.   If not , do you know of any other sites or places I can check for info about this subject.         I've heard of problems with every type of modem for every  type of operating system running on every platform.  None of them has been specific to PCMCIA modems with   Linux.  I've operated a couple of large BBS' (over a 100  lines on one and about 50 on the other) and worked with  a number of corporate modem pools and remote access servers.    I don't understand why your ISP would want a note from  me before talking to you.    It sounds like your asking me to say:    ""Oh yeah!  He shouldn't be running Linux there!""   ... or to say""    ""1.2.13!  That fool -- he needs to upgrade to 2.0.30!""   ... so you can then refer this ""expert"" opinion to some  support jockey at your ISP.    Now if you mean that your ISP is running Linux 1.2.13  on a Pentium laptop with PCMCIA modems -- and using that  as a server for his internet customers -- I'd venture to   say that this is pretty ludicrous.    If you were running Linux on your laptop and having problems   with your PCMCIA modem I wouldn't be terribly surprised.  PCMCIA seems to be an unruly specification -- and the designers  of PCMCIA equipment seem to have enough trouble in their   (often unsuccessful) attempts to support simple DOS and  Windows users.  The programmers that contribute drivers for  Linux often have to work with incomplete or nonexistent   specifications for things like video cards and chipsets --  and PCMCIA cards of any sort.    I mostly avoid PCMCIA -- it is a spec that is ill-suited  to any sort of peripheral other than *MEMORY CARDS*  (which is, after all, what the letters MC stand for in this  unpronounceable stream of gibberish that I dubbed ""piecemeal""  a few years ago).       Any help would be appreciated.         I could provide much better suggestions if I had more  information about the setup.  I could even provide  real troubleshooting for my usual fees.    However, if the problem really is specific to your  connections with your ISP (if these same 28.8 ""piecemeal""  modems work fine with say -- your Cubix RAS server or  your favorite neighborhood BBS), then you should probably  work with them to resolve it (or consider changing  ISP's).    As a side note:  Most ISP's use terminal servers on their  modem banks.  This means that they have their modems plugged  into a device that's similar to a router (and usually made be  a company that makes routers).  That device controls the  modems and converts each incoming session into an rlogin or  ""8-bit clean"" telnet session on one more more ethernet  segments.      Their Unix or other ""internet servers"" don't have any   direct connections to any of the normal modems.  (Sometimes   an sysadmin will connnect a modem directly to the serial ports  of one or more of these systems -- for administrative access  so they can call on a special number and bypass the terminal   servers, routers, etc).    It's possible that the problem is purely between the two  brands of modems involved.  Modern modems are complex  devices (essentiall dedicated microcomputers) with substantial  amounts of code in their firmware.  Also the modem business  sports cutthroat competition -- with great pressure to add  ""enhancements,"" a lot of fingerpointing, and *NO* incentive   to share common code bases for interoperability's sake.  So slight ambiguities in protocol specification lead to   sporadic and chronic problems.  Finally we're talking about  analog to digital conversion at each end of the phone line.  The phone companies have *NO* incentive to provide good  clean (noise free) phone lines to you and your ISP.  They make  a lot more money on leased lines -- and get very little  complaint for ""voice grade"" line quality.    The problem is that none of us should have been using modem  for the last decade.  We should have all had digital signals  coming into our homes a long time ago.  The various phone  companies (each a monopoly in it's region -- and all stemming  from a small set of monopolies) have never had any incentive  to implement this, every incentive NOT to (since they can charge  a couple grand for installationn and several hundred per month  on the few T1's they to do sell -- and they'll never approach  that with digital lines to the home.  They do, however, have   plenty of money to make their concerns heard in regulatory  bodies throughout the government.  So they cry ""who's going  to pay for it?"" so loudly and so continuously that no one can  hear the answer of the American people. Our answer should be   ""You (monopolies) will pay for it -- since we (the people)   provided you with a legal monopoly and the funds to build OUR  copper infrastructure""  (but that answer will never be heard).    If you really want to read much more eloquent and much   better researched tirades and diatribes on this topic --  subscribe to Boardwatch magazine and read Jack Rickard  (the editor) -- who mixes this message with new information  about communications technology every month.      -- Jim                 Copyright © 1997, James T. Dennis    Published in Issue 18 of the Linux Gazette June 1997                        ""Linux Gazette... making Linux just a little more fun! ""                 bash String Manipulations   By Jim Dennis,  jimd@starshine.org        The  bash  shell has many features that are  sufficiently obscure you almost never see them used.  One of the problems is that the man page offers no examples.    Here I'm going to show how to use some of these features to do the sorts of simple string manipulations that are commonly  needed on file and path names.    Background    In traditional Bourne shell programming you might see references to the  basename  and  dirname  commands. These perform simple string manipulations on their arguments. You'll also see many uses of  sed  and  awk  or  perl -e  to perform simple string manipulations.   Often these machinations are necessary perform on lists of filenames and paths. There are many specialized programs that are conventionally included with Unix to perform these sorts of utility functions:   tr ,  cut ,  paste , and  join .  Given a filename like  /home/myplace/a.data.directory/a.filename.txt   which we'll call  $f  you could use commands like:      dirname   $f     basename   $f     basename   $f  .txt     ... to see output like:     /home/myplace/a.data.directory  a.filename.txt  a.filename    Notice that the GNU version of  basename  takes an  optional parameter.  This handy for specifying a filename ""extension"" like  .tar.gz  which will be stripped off of the output.  Note that  basename  and  dirname  don't verify that these parameters  are valid filenames or paths.  They simple perform simple string operations on a single argument. You shouldn't use wild cards with them -- since  dirname  takes exactly one argument (and complains if given more) and  basename  takes one argument and an optional one which is not a filename.    Despite their simplicity these two commands are used frequently in  shell programming because most shells don't have any built-in string handling functions -- and we frequently need to refer to just the directory or just the file name parts of a given full file specification.    Usually these commands are used within the ""back tick"" shell operators like   TARGETDIR=`dirname $1` .  The ""back tick"" operators are equivalent to the  $(...)  construct.  This latter construct is valid in Korn shell and  bash  -- and I find it easier to read (since I don't have to squint at me screen wondering which direction the ""tick"" is slanted).    A Better Way    Although the  basename  and  dirname  commands embody the ""small is beautiful"" spirit of Unix -- they may push the envelope towards the ""too simple to be worth a separate program"" end of simplicity.    Naturally you can call on  sed ,  awk , TCL or  perl  for more flexible and complete string handling. However this can be overkill -- and a little ungainly.    So,  bash  (which long ago abandoned the ""small is beautiful"" principal and went the way of  emacs ) has some built in syntactical candy for doing these operations.  Since  bash  is the default shell on Linux systems then there is no reason not to  use these features when writing scripts for Linux.       If your concerned about portability to other shells and  systems -- you may want to stick with  dirname ,   basename , and  sed      The  bash  Man Page    The  bash  man page is huge.  In contains a complete reference to the ""readline"" libraries and how to write a  .inputrc  file (which I think should all go in a separate man page) -- and a run down of all the  csh  ""history"" or  bang!  operators (which I think should be replaced with a simple statement like: ""Most of the  bang!  tricks that work in  csh  work the same way in  bash "").    However, buried in there is a section on  Parameter Substitution  which tells us that $foo is really a shorthand for ${foo} which is  really the simplest case of several ${foo :operators } and similar constructs.    Are you confused, yet?    Here's where a few examples would have helped.  To understand the  man page I simply experimented with the echo command and several  shell variables.  This is what it all means:       Given:    foo=/tmp/my.dir/filename.tar.gz            We can use these expressions:    path = ${foo%/*}      To get: /tmp/my.dir (like  dirname )    file = ${foo##*/}      To get: filename.tar.gz (like  basename )    base = ${file%%.*}      To get: filename     ext  = ${file#*.}      To get: tar.gz         Note that the last two depend on the   assignment made in the second one   Here we notice two different ""operators"" being used inside the  parameters (curly braces).  Those are the  #  and the  %  operators.  We also see them used as single characters and in pairs. This gives us four combinations for trimming patterns off the  beginning or end of a string:   ${variable%pattern}     Trim the shortest match from the end    ${variable##pattern}     Trim the longest match from the beginning    ${variable%%pattern}     Trim the shortest match from the end    ${variable#pattern}     Trim the shortest match from the beginning          It's important to understand that these use shell ""globbing"" rather than ""regular expressions"" to  match  these patterns.  Naturally a simple string like ""txt"" will match sequences of exactly those three characters in that sequence -- so the difference between ""shortest"" and ""longest"" only applies if you are using a shell  wild card in your pattern.   A simple example of using these operators comes in the common question of copying or renaming all the *.txt to change the  .txt to .bak (in MS-DOS' COMMAND.COM that would be REN *.TXT *.BAK).   This is complicated in Unix/Linux because of a fundamental difference in the programming API's.  In most Unix shells the expansion of a wild card pattern into a list of filenames (called ""globbing"") is done by the shell -- before the command is executed.  Thus the command normally sees a list of filenames (like ""foo.txt bar.txt etc.txt"") where DOS (COMMAND.COM) hands external programs a pattern like *.TXT.     Under Unix shells, if a pattern doesn't match any filenames the parameter  is usually left on the command like literally.  Under  bash  this is a user-settable option.  In fact, under  bash  you can disable shell ""globbing"" if you like -- there's a simple option to do this. It's almost never used -- because commands like  mv , and  cp  won't work properly if their arguments are passed to them in this manner.   However here's a way to accomplish a similar result:      for i in *.txt; do cp $i ${i%.txt}.bak; done      ... obviously this is more typing. If you tried to create a shell function or alias for it -- you have to figure out how to  pass this parameters.  Certainly the following seems simple enough:      function cp-pattern {  for i in $1; do cp $i ${i%$1}$2; done      ... but that doesn't work like most Unix users would expect.  You'd have to pass this command a pair of specially  chosen , and  quoted  arguments like:      cp-pattern '*.txt' .bak      ... note how the second pattern has no wild cards and how the first is quoted to prevent any shell globbing.  That's fine for something you might just use yourself -- if you remember to quote it right.  It's  easy enough to add check for the number of arguments and to ensure that there is at least one file that exists in the $1 pattern.  However it  becomes much harder to make this command reasonably safe and robust.   Inevitably it becomes less ""unix-like"" and thus more difficult to use with other Unix tools.   I generally just take a whole different approach.  Rather than trying to use  cp  to make a backup of each file under a slightly changed name I might just make a directory (usually using the date and my login ID as a template) and use a simple  cp  command to copy all my target files into the new directory.   Another interesting thing we can do with these ""parameter expansion"" features is to iterate over a list of components in a single variable.   For example, you might want to do something to traverse over every  directory listed in your path -- perhaps to verify that everything listed therein is really a directory and is accessible to you.   Here's a command that will echo each directory named on your path on it's own line:      p=$PATH  until [ $p = $d ]; do d=${p%%:*}; p=${p#*:}; echo $d; done      ... obviously you can replace the  echo $d  part of this command with anything you like.    Another case might be where you'd want to traverse a list of directories that were all part of a path.  Here's a command pair that echos each directory from the root down to the ""current working directory"":      p=$(pwd)  until [ $p = $d ]; do p=${p#*/}; d=${p%%/*}; echo $d; done      ... here we've reversed the assignments to  p  and  d  so that we skip the root directory itself -- which must be ""special cased"" since it appears to be a ""null"" entry if we do it the other way.  The  same problem would have occurred in the previous example -- if the value assigned to  $PATH  had started with a "":"" character.     Of course, its important to realize that this is not the only, or  necessarily the best method to parse a line or value into separate  fields.  Here's an example that uses the old  IFS  variable (the ""inter-field separator in the Bourne, and Korn  shells as well as   bash ) to parse each line of  /etc/passwd  and extract  just two fields:          cat /etc/passwd | ( \    IFS=: ; while read lognam pw id gp fname home sh; \     do echo $home \""$fname\""; done \     )       Here we see the parentheses used to isolate the contents in a subshell -- such that the assignment to IFS doesn't affect our current shell. Setting the IFS to a ""colon"" tells the shell to treat that character as  the separater between ""words"" -- instead of the usual ""whitespace"" that's assigned to it.  For this particular function it's very important that IFS consist solely of that character -- usually it is set to ""space,"" ""tab,"" and ""newline.   After that we see a typical  while read  loop -- where we read values from each line of input (from  /etc/passwd  into seven variables per line.  This allows us to use any of these fields that we need from within the loop.  Here we are just using the   echo  command -- as we have in the other examples.   My point here has been to show how we can do quite a bit of  string parsing and manipulation directly within  bash  -- which will allow our shell scripts to run faster with less overhead and may be easier than some of the more complex sorts of pipes and  command substitutions one might have to employ to pass data to the various external commands and return the results.    Many people might ask:  Why not simply do it all in  perl ?  I won't dignify that with a response.  Part of the beauty of Unix is that each user has many options about how they choose to program something. Well written scripts and programs interoperate regardless of what particular scripting or programming facility was used to create them.  Issue the command  file /usr/bin/*  on your system and and you may be  surprised at how many Bourne and C shell scripts there are in there   In conclusion I'll just provide a sampler of some other   bash  parameter expansions:       ${parameter:-word}   Provide a default if  parameter  is unset or null.   Example:           echo ${1:-""default""}   Note:  this would have to be used from within a functions or shell script -- the point is to show  that some of the parameter substitutions can be use with shell numbered arguments.   In this case the string ""default"" would be returned if the function or script was called with no $1 (or if all of the  arguments had been  shift ed out of existence.           ${parameter:=word}   Assign a value to  parameter  if it was previously  unset or null.   Example:           echo ${HOME:=""/home/.nohome""}    ${parameter:?word}   Generate an error if  parameter  is unset or null by  printing  word  to  stdout .    Example:          : ${HOME:=""/home/.nohome""}          ${TMP:?""Error: Must have a valid Temp Variable Set""}                  This one just uses the shell ""null command"" (the : command) to evaluate the expression.  If the variable doesn't exist or has a  null value -- this will print the string to the standard error file handle and exit the script with a return code of one.   Oddly enough -- while it is easy to redirect the standard error of processes under  bash  -- there doesn't seem to be an easy portable way to explicitly generate message or redirect output  to  stderr.  The best method I've come up with is to use  the /proc/ filesystem (process table)  like so:      function error { echo ""$*"" > /proc/self/fd/2 }     ...  self  is always a set of entries that refers to the current process -- and  self/fd/  is a directory full of the currently open file descriptors.  Under Unix and DOS every process is given the following pre-opened file descriptors:  stdin, stdout, and stderr.           ${parameter:+word}         Alternative value.        ${TMP:+""/mnt/tmp""}                  use /mnt/tmp instead of $TMP but do nothing if TMP was        unset.  This is a weird one that I can't ever see myself        using.  But it is a logical complement to the ${var:-value}         we saw above.     ${#variable}   Return the length of the variable in characters.    Example:         echo The length of your PATH is ${#PATH}                  Copyright © 1997, Jim Dennis   Published in Issue 18 of the Linux Gazette, June 1997                              ""Linux Gazette... making Linux just a little more fun! ""                 Brave GNU World: Towards A Bioregional, Community-based Linux Support Net   By Michael Stutz,  stutz@dsl.org         I believe there's strong potential now for the growing LUG phenomenon to intertwingle with both the Linux Documentation Project and the Linux support network of the c.o.l.* newsgroups and create the next ""level"" of support for Linux. The net result of this would be a self-documenting, technical  support, training and social network on an Internet-wide scale (perhaps some would say that's what it already is -- then I mean it would be the same only exponentially better). Right now, I see a lot of work (documentation, debugging, support) being duplicated. If these efforts could be combined (LUG + LDP + c.o.l.*), it would eliminate a lot of this excess work; the net result would would be greater than its parts, a synergy.   Many LUGs give demos and post the notes on their web servers. That information is diffused across many obscure sites, but bringing these efforts together with the LDP folks, I wonder if a new breed of HOWTOs (DEMOs?) could be created; a common indexing scheme could have a list of all demos or tutorials ever given at any LUG, both searchable and listed by subject or other criteria.   And while the c.o.l.* newsgroups are invaluable for a great many things, sometimes local help is preferable. With the right organization, community-based LUGs could be the first stop for a Linux user's questions and problems, with an easy forwarding mechanism to go up a chain to be broadcast to the next larger bioregion, then continent-wide and finally, if the question is still not answered, world-wide.   By not duplicating the work, we'll be freeing up our time to develop even more things than the current rate, plus the increased support net, replete with documentation and local support, will allow for a greater user base. More ideas could be implemented to strengthen this base, such as ""adopt-a-newbie"" programs. For instance, there's a guy in town named Rockie who's in this rock band called Craw; I once saw in a zine he published that he was starting a volunteer initiative to collect old donated computer equipment, refurbish them, and make them available to musicians who otherwise wouldn't be able to use computers. Why not take that a step further and make them Linux boxes? Not only would you get a non-corporate, rock-solid OS, but you'd have an instant support network in your own town. This kind of community-based approach seems the best way to ""grow"" GNU/Linux at this stage.   This community-based LUG network would be capable of handling any and all GNU/Linux support, including the recently-discussed Red Hat Support Initiative, as well as Debian support, Slackware support, etc. It's above and beyond any single ""distribution"" and in the interest of the entire Linux community.   I think the key to all this is planning. It need not happen all at once. It's happening already, with local LUGs making SQL databases of LUG user's special interests and/or problems, and their own bioregional versions of the Consultants-HOWTO, etc. What is needed most of all is a formal protocol, a set of outlines and guidelines, that all LUGs, when ready, can initiate -- from technical details such as ""What format to develop the database?"" to everything else. It need not be centralized -- like the rest of Linux, it will probably come together from all points in the network -- but our base is large enough now that taking a look at the various Linux efforts from a biological and geographical community-based standpoint, and re-coordinating from there, is something that only makes sense.    Copyright (C) 1997 Michael Stutz; this information is free; it may be redistributed and/or modified under the terms of the GNU General Public License, either Version 2 of the License, or (at your preference) any later version, and as long as this sentence remains.            Copyright © 1997, Michael Stutz   Published in Issue 18 of the Linux Gazette, June 1997                              ""Linux Gazette... making Linux just a little more fun! ""                 Building Your Linux Computer Yourself   By Josh Turial,  josht@janeshouse.com         I've been in the habit for years of building my own PCs, partly for the cost savings, partly because I'm a geek, and partly (mostly), because I've found the best way to tune a system exactly to my liking is to pick only and exactly the parts that I need. Once I discovered Linux a couple of years ago, I had the perfect match for my hobby. I'll lay out on these pages what I've learned by trial and error, what to look for in a DIY computer, and how to best mix-and-match according to your desires and budget.   For starters, the key to building your own system is to find the best sources for parts. Computer Shopper is probably the DIY bible, crammed with mail--order ads from companies selling parts. I prefer the face-to-face purchase, myself. Most of my buying takes place at the ubiquitous ""computer flea markets"" that take place every month or so in most major metropolitan areas. In Greater Boston (my stomping grounds), there are two major shows put on; KGP and Northern. These are held in halls around the metro area, and there's one every few weeks within driving distance.  Typically, many vendors attend all the shows in a given area.   Most vendors are pretty reliable in my area (your mileage may vary), and are usually willing to play the deal game. This is where your objectives come into play.   Fortunately, Linux isn't too picky about the hardware it runs on--just about any old CPU will suffice. The major areas of concern are in deciding whether or not to use IDE or SCSI drives and what type of video card to install. Assuming that you will use a standard Linux distribution, the screaming video card that plays Doom at warp speed under DOS may not be supported by Xfree 86. For instance, the immensely popular Trident 9440 VGA chipset only recently became supported by X, though it shipped with Windows 95and OS/2 drivers. Anyhow, in making these decisions, I have a simple checklist:    Will the system only run Linux, or will you dual-boot another OS?   Are you going to power-use the system?   Will you connect to the Internet over a network, or will you use a modem and dial-up?    The answers to these questions should help determine what you need to purchase. First off, let's cover processor type/speed and RAM. Linux is somewhat more efficient in its consumption of system resources than DOS (or pretty much any other Intel OS), so you may not necessarily need the screaming Pentium 200 that you need for your Windows 95 system. In the Pentium class processors, currently the 100 and 133 MHz Pentiums are the best values in bang-for-the-buck specs. Both chips are well under $200, and the 100 MHz processor is close to $100. I tend to suggest those processors that operate on a 66 MHz motherboard bus clock (like the above two chips--the P166 and P200 are also in that category). Generally speaking, the faster clock speed of the Pentium 120 and 150 are offset by the slower 60 MHz bus and higher price. A good PCI motherboard to accompany the chip costs about $100 to $150. Stick with boards that use the Intel chipset for safest results, though I have had good luck with other vendors.   If you don't need to go Pentium class, there are some bargains out there.  AMD makes some very good 486 chips, running at up to 120 MHz. This is about equivalent in horsepower to the original Pentiums, but without the math errors. The most recent system I built uses a hybrid motherboard (one older VL-bus slot, 4 PCI slots), and has an AMD 5x86-133 chip. This processor is kind of a cross between a 486 and a Pentium, and competes very well with the Pentium Overdrive upgrades that Intel sells to 486 owners. The 5x86's performance is roughly on a par with a Pentium-90, and motherboard/processor combined cost roughly $100 (as opposed to about $150 for the Overdrive itself).   Basically; you can factor out the price/performance scale like this:         ProcessorBus    Performance      Price       486 (66-120MHz) VL bus    low-decent    $75-$100       5x86VL PCI or both   low-end Pentium    $100-$120       Pentium 100PCI only    Good for multiple OS     $200-$250        Pentium 133PCI only   Fast Linux, games'll rock    $300-$350       Pentium 166PCI only   Wow, that's fast!   $475-$550       Pentium 200PCI only   Ahead ludicrous speed, cap'n!   $700+       Pentium ProPCI only   If you need it, buy it built...         When you buy the motherboard, there is another factor that has recently become worth considering: what form factor do you use? Newer Pentium and Pentium Pro-based motherboards are often available in the ATX form factor.  The board is easier to service, and the cases are easier to take apart. ATX boards and cases are a little tougher to find, but there is no real cost difference between ATX and the traditional Baby-AT form factor, so you may wish to consider the ATX alternative at purchase time.   If you buy the motherboard and case from the same vendor, often they will mount it in the case for you. If you do it ourself, be careful to make sure that the power supply is properly connected, both to the motherboard and to the power switch. Power supplies have two keyed connectors attaching them to the motherboard. It is difficuly, but not impossible, to wire them wrong (I have a friend who did), so make sure the black wires on the power leads are touching on the inside:  ADD DIAGRAM HERE  The motherboard also should be connected to the case with at least two spacers that screw down in addition to all the plastic posts that will be in the case kit. This insures that cards fit properly, and keeps the board stable.   Besides the processor/motherboard combination, there are other performance issues, of course. RAM is finally cheap enough that you should buy at least 16 MB worth (about $100 at current street prices). Linux will run OK in 8 MB (and even 4 MB is OK for text-based work), but why scrimp there when it costs so little to do it right? If you buy from a show vendor, make sure they test it in front of you. Any reputable vendor has their own RAM tester.  Generally, there is no real price difference between conventional fast-page RAM and the slightly faster EDO variety, but make sure your motherboard uses the type of RAM you're buying. Most better motherboards will happily auto-detect the type of RAM you use and configure themselves correctly. But you can't mix, so make sure you only install one type, whatever that is.  Newer Pentium chipsets support the newer SDRAM, which promises even more speed. I have not yet tried it in a system, so I cannot tell you whether or not that is so. Buy 32 MB if you can afford it--you won't regret it.   There's also the IDE-SCSI decision. IDE interfaces are built into most modern motherboards, so it costs nothing extra. And IDE hard drives are a little cheaper, and IDE CD-ROMs are fast, cheap (under $80 for a 4x drive), and easy to set up. But the controllers only support four devices total (two ports, with two devices each), and each IDE channel is only as fast as the slowest device on it (meaning you really can only have two hard drives, and the CD-ROM has to go on channel 2). And modern multitasking OSs like Linux can't get their best performance out of IDE. But it's cheap and easy. SCSI is higher performance, and has none of IDE's restrictions (up to 7 devices per controller, no transfer rate limit beyond the adapter's), but the controller will set you back $70 (for a basic Adaptec 1522) to $200 (a PCI controller) plus. The drives don't cost much more, and you can only get the highest performance drives in SCSI versions. SCSI CD-ROM drives are a little harder to find, but the basic 4x drive will only cost you about $125. And SCSI tape drives (you were planning to back up your data, weren'>t you?), are much easier to install and operate than their non-SCSI counterparts (faster, too). I'd say the decision is one to be made after you've priced the rest of the system out. If you can afford it, SCSI will make for a better system in the long run.   The video card decision is also an important one. The critical part of this decision is picking a card that uses a chipset (the actual brains of the card) which is supported by XFree86, the standard Linux XWindows with most distributions. A few distributions (Caldera, Red Hat) ship with commercial X implementations that have a little more flexibility in video support. I find S3-based video cards to be the most universally supported--the S3 driver in XFree86 is very solid and works even with most of the generic, no-name video cards on the market. The S3 cards generally have a large (about 1.5"" x 1.5"") chip with the S3 brand name prominently displayed on it. Diamond and Number Nine make extensive use of S3 chips in their video card lines, to name a couple of brands. Among other SVGA chipset makers, Cirrus and Trident are also well-supported. Only the latest X versions include support for the popular Trident 9440 chips, so be careful before buying a video card with that chipset. XFree86 includes a very complete readme with the status of support for most video cards/chipsets, so consult it if you have any questions.   Your sound card (if you want one) is a relatively simple decision. The SoundBlaster 16 is the defacto standard for sound cards, and is supported by virually all software. Some motherboards even include the SB16 chipset on them. If at all possible, buy your card in a jumpered version, rather than the SoundBlaster 16 Plug-and-Play that is popular today. Most vendors have jumpered versions available. There are also SB16-compatible cards out on the market, and they are definitely worth considering. Expect to pay around $80 for your sound card.   Possibly the choice that'll get me in the most trouble is the Ethernet card selection (if your system is going on a LAN). A Novell NE2000 clone is the cheapest choice you can make (the clones cost around $20), but most clones will hang the machine at boot time if the kernel is probing for other Ethernet card brands when the NE2000 is set to its default address of 300h. The solution is to either boot from a kernel with no network support (then recompile the kernel without the unneeded drivers), or to move the address of the NE2000 to another location. I've used 320h without problems to avoid this hang.   But the best way around the problem is to use a major-brand card. I currently rely on 3Com's EtherLink III series cards (the 3C5x9), which are universally supported, and software-configurable (from DOS, so keep a DOS floppy around). It's available in ISA or PCI versions, ISA being cheaper. This card costs around $90 from most vendors. I know that's more expensive than some motherboards, but it's a worthwhile investment.   If you are using dial-up access to the Internet instead (or just want a modem anyways), you can approach buying a modem with two alternatives. If your motherboard has built-in serial ports (almost all the non-VL bus boards do), then you could buy an external modem. I prefer them to internal modems, since the possibility of setting an address incorrectly is then gone, ad you can always tell if it is working from the status lights on the front of the modem.  Internal modems generally cost a little less, but there's a greater risk of accidentally creating an address or interrupt conflict in the process of installing it. An additional problem is that many modems sold now are plug-and-play compatible. Unless you're already running Windows 95, P&P is a scourge on the Intel computing world (Macs do P&P in a fashion that actually works). Because most Intel-based OSs need to know the interrupt and memory location of peripherals at boot time, any inadverdent change caused by a P&P device can adversely impact the boot process.  Linux can find many devices regardless (SCSI controllers, most Ethernet cards), but serial ports and sound devices are hard-mapped to interrupts at the OS level. So try to make sure that any such devices can be operated in a non-P&P mode, or in the case of modems, buy an external one if possible to avoid the situation entirely.   Remember, there are really two bottom-line reasons to build your Linux box yourself. One is to save money (and I hope I've shown you how to do that), but the real main reason is to have fun. Computing is a fun hobby, and building the system yourself can be a fun throwback to the early days when a computer was bought as a bag of parts and a schematic. I've been building machines like this for several years, and never had trouble--not to mention that I've gotten away with bringing in a lot of stuff under my wife's nose by buying them a part at a time! (Oops, the secret's out) So, for your next computer, give homebrewing a whirl. It'ss easier than you think, and what better companion for a free, home-brewed OS than a cheap, home-brewed PC?            Copyright © 1997, Josh Turiel   Published in Issue 18 of the Linux Gazette, June 1997                              ""Linux Gazette... making Linux just a little more fun! ""                 Cleaning Up Your /tmp...The Safe Way   By Guy Geens,  ggeens@iname.com        Introduction    Removing temporary files left over in your  /tmp  directory, is not as easy as it looks like. At least not on a multi-user system that's connected to a network.    If you do it the wrong way, you can leave your system open to attacks that could compromise your system's integrity.    What's eating my disk space?    So, you have your Linux box set up. Finally, you have installed everything you want, and you can have some fun! But wait. Free disk space is slowly going down.    So, you start looking where this disk space is going to. Basically, you will find the following disk hogs:      Formatted man pages in /var/catman ;     The  /tmp  and  /var/tmp  hierarchies.      Of course, there are others, but in this article, I'll concentrate on these three, because you normally don't lose data when you erase the contents. At the most, you will have to wait while the files are regenerated.    The quick and dirty solution    Digging through a few man pages, you come up with something like this:     find /var/catman -type f -atime 7 -print | xargs -- rm -f --    This will remove all formatted man pages that have not been read for 7 days. The  find  command makes a list of these, and sends them to the  xargs . x args  puts these files on the command line, and calls  rm -f  to delete them. The double dashes are there so that any files starting with a minus will not be misinterpreted as options.    (Actually, in this case, find prints out full path names, which are guaranteed to start with a /. But its better to be safe than sorry.)    This will work fine, and you can place this in your crontab file or one of your start-up scripts.    Note that I used  /var/catman  in the previous example. You might be thinking ``So, why not use it for  /tmp ?'' There is a good reason for this. Let me start by elaborating on the difference between  /var/catman  and  /tmp  directories. (The situation for  /var/tmp  is the same as for /tmp. So you can change all instances of  /tmp  by  /var/tmp  in the following text.)    Why /var/catman is easy    If you look at the files in  /var/catman , you will notice that all the files are owned by the same user (normally  man ). This user is also the only one who has write permissions on the directories. That is because the only program that ever writes to this directory tree is  man  . Let's look at  /usr/bin/man :     -rwsr-sr-x 1 man man 29716 Apr 8 22:14 /usr/bin/man*    (Notice the two letters `s' in the first column.)    The program is running setuid man, i.e., it takes the identity and privileges of this `user'. (It also takes the group privileges, but that is not really important in our discussion.)  man  is not a real user: nobody will ever log in with this identity. Therefore, man (the program) can write to directories a normal user cannot write to.    Because you know all files in the directory tree are generated by one program, it is easy to maintain.    And now /tmp    In  /tmp , we have a totally different situation. First of all, the file permissions:    drwxrwxrwt 10 root root 3072 May 18 21:09 /tmp/    We can see that  everyone  can write to this directory: everyone can create, rename or delete files and directories here.    There is one limitation: the `sticky bit' is switched on. (Notice the t at the end of the first column.) This means a user can only delete or rename files owned by himself. This prohibits users peskering each other by removing the other one's temporary files.    If you were to use the simple script above, there are security risks involved. Let me repeat the simple one-line script from above:    find /tmp -type f -atime 7 -print | xargs -- rm -f --    Suppose there is a file  /tmp/dir/file , and it is older than 7 days.     By the time  find  passes this filename to  xargs , the directory might have been renamed to something else, and there might even be another directory  /tmp/dir .    (And then I didn't even mention the possibility of embedded newlines. But that can be easily fixed by using -print0 instead of -print.)   All this could lead to a wrong file being deleted, Either intentionally or by accident. By clever use of symbolic links, an attacker can exploit this weakness to delete some important system files.   For an in-depth discussion of the problem, see the Bugtraq mailing list archives. (Thread `` [linux-security] Things NOT to put in root's crontab'' ).    This problem is inherently linked with find's algoritm: there can be a long time between the moment when find generates a filename internally and when it is passed on to the next program. This is because find recurses subdirs before it tests the files in a particular directory.    So how do we get around this?    A first idea might be:    find ... -exec rm {} \;    but unfortunately, this suffers from the same problem, as the `exec' clause passes on the full pathname.    In order to solve the problem, I wrote this  perl script  , which I named  cleantmp .    I will explain how it works, and why it is safer than the aforementioned scripts.    First indicate I'm using the File::Find module. After this statement, I can call the &find subroutine.    use File::Find;     Then do a chroot to  /tmp . This changes the root directory for the script to  /tmp . It will make sure the script can't access any files outside of this hierarchy.    Perl only allows a chroot when the user is root. I'm checking for this case, to facilitate testing.    # Security measure: chroot to /tmp  $tmpdir = '/tmp/';  chdir ($tmpdir) || die ""$tmpdir not accessible: $!"";  if (chroot($tmpdir)) { # chroot() fails when not run by root   ($prefix = $tmpdir) =~ s,/+$,,;  $root = '/';  $test = 0;  } else {  # Not run by root - test only  $prefix = '';  $root = $tmpdir;  $test = 1;  }    Then we come to these lines:    &find(\&do_files, $root);   &find(\&do_dirs, $root);    Here, I let the find subroutine recurse through all the subroutines of /tmp. The functions do_files and do_dirs are called for each file found. There are two passes over the directory tree: one for files, and one for directories.     Now we have the function  do_files .    sub do_files {  (($dev,$ino,$mode,$nlink,$uid,$gid) = lstat($_)) &&  (-f _ || -l _ ) &&  (int(-A _) > 3) &&  ! /^\.X.*lock$/ &&  &removefile ($_) && push @list, $File::Find::name;  }    Basically, this is the output of the find2perl program, with a little changes.    This routine is called with $_ set to the filename under inspection, and the current directory is the one in which it resides. Now let's see what it does. (In case you don't know perl: the && operator short-circuits, just like in C.)      The first line gets the file's parameters from the kernel;     If that succeeds, we check if it is a regular file or a symbolic link (as opposed to a directory or a special file);     Then, we test if the file is old enough to be deleted (older than 3 days);     The fourth line makes sure X's lockfiles (of the form  /tmp/.X0-lock  are not removed;     The last line will remove the file, and keep a listing of all deleted files.       The removefile subroutine merely tests if the $test flag is set, and if not, deletes the file.     The do_dirs subroutine is very similar to this one, and I won't go into the details.     A few remarks    I use the access time to determine the file's age. The reason for this is simple. I sometimes unpack archives into my /tmp directory. When it creates files, tar gives them the date they had in the archive as the modification time. In one of my earlier scripts, I did test on the mtime. But then, I was looking in an unpacked archive, at the same time when cron started to clean up. (Hey?? Where did my files go?)     As I said before, the script checks for some special files (and also directories in do_dirs). This is because they are important for the system. If you have a separate /tmp partition, and have quota installed on it, you should also check for quota's support files - quota.user and quota.group.    The script also generates a list of all deleted files and directories. If you don't want this output, send the output to  /dev/null .     Why this is safe    The main difference with the find constructions I have shown before is this: the file to be deleted is not referenced by its full pathname. If the directory is renamed while the script is scanning it, this doesn't have any effect: the script won't notice this, and delete the right files.     I have been thinking about weaknesses, and I couldn't find one. Now I'm giving this to you for inspection. I'm convinced that there are no hidden security risks, but if you do find one,  let me know .              Copyright © 1997, Guy Geens   Published in Issue 18 of the Linux Gazette, June 1997                              ""Linux Gazette... making Linux just a little more fun! ""                By Mike List,  troll@net-link.net      Welcome to installment 5 of Clueless at the Prompt: a new column for new users.      Getting Serious   If you've been experimenting with linux, reading all the docs you can get your hands on, downloading software to try, and generally cleaning up after the inevitable ill advised rm as root, you are probably starting to get enough confidence in linux to use it to do more than browse the internet. After all, why use Gates when you can jump the fences? This month I'm going to discuss some strategies for damage control, and how you can safely upgrade without losing valuable files and configurations, as well as some more general scouting around the filesystem.                                        Partitions as Safety Devices  If you have your entire linux installation on one partition, or partition, you could be putting your files and accmulated data in jeopardy as well as making the business of upgrading more difficult.   I understand that some distributions, notably Debian, are capable of upgrading any part of the system's component software without a full install, but I'm running Slackware, and it's generally recommended that when certain key system components are upgraded, a full reinstall is the safest way to avoid conflicts between old and new parts. What to do when the time comes can be much simpler if you have installed at least your /home direcory on a separate partition.   When you do a fresh install you are asked to describe mount points for your partitions. You are also asked if you want to format those partitions. If your /home directory doesn't contain much in the way of system files you can opt to skip formatting it, thereby reducing the chance that you'll have to use your backup to recover lost files in those directories. No, I'm not suggesting tht you don't have to backup your /home or other personal files, since there is no reliable undelete for linux that I'm aware of at this time. However, if you are just experimenting with linux and using a separate OS to do your important work and it's located on another disk, you may not feel to compelled to backup much in the way of linux files. Sooner or later though, if you are committed(or ought to be :) ) enough to linux to drop the other system, you WILL want to rethink that omission.     Formatting Floppies  When you format a floppy disk in MSDOS you do several operations in one fell swoop. You erase files, line up the tracks, sectors, etc, and install a MSDOS compatible filesystem. Another thing to recognize is that MS mounts the floppy drive as a device, while in linux the device is mounted as a part of the filesystem, to a specific directory.    There is a suite of utilities called mtools that can be used to create DOS formatted floppies, as well as some other MS specific operations, but I haven't had a lot of fun with it. I use the standard utilities instead Here is how I format a floppy disk:       fdformat /dev/fd0xxx   where xxx is the full device name. My floppy drive is /dev/fd0u1440 but your mileage may vary. Try ls'ing your /dev directory to see. I installed from floppies, so I'm not real sure about CDROM installation   but I took note of the drive specified to install the system. When the drive finishes formatting, you can type:       mkfs -t msdos /dev/fd0xxxx   once again if necessary adding any specifiers. Your disk should be formatted.     Writing to your Floppy Disk  You are probably sitting there with a newly msdos formatted floppy disk and wondering how to write to it. If you use mtools, you are on your own, but don't feel bad you will save some steps, ie. mount and umount the floppy drive before and after writing to the drive, but it seems that I always fail to remember some option when I try to use mtools, so I don't use them. I type :       mount -t msdos /dev/fd0xxxx /mnt   you can specify another mount point besides /mnt if you would like, perhaps a different mount point for each filesystem type that you might want to use, ext2, or minix for example, but if you or people that you work with use MS the msdos format might be the best, at least for now.   You can put an entry in your /etc/fstab that specifies the mount point for your floppy drive, with a line that looks something like:       /dev/fd0         /mnt      msdos       rw,user,noauto  0   0    This particular line will keep the floppy drive from mounting on bootup (noauto), and allow users to mount the drive. You should take the time to alert your users that they MUST mount and umount /dev/fd0 each time they change a disk, otherwise they will not get a correct ls when they try to read from the mount point. Assuming that this line is added to the /etc/fstab file the correct command for mounting the drive is:       mount /dev/fd0     which will automatically choose /mnt as the mount point.To read from the drive, the present working directory must be changed by:       cd /mnt   after which the contents of the disk can be read or written to>  Linux is capable of reading files from several filesystem types, so it's a pretty good first choice, since you can share files with DOS users.   Anyway, assuming you didn't get any error messages, you are ready to copy a file to the disk using the:        cp anyfile.type /mnt   assuming tha /mnt is the mount point that you specified in the mount command, you should have  copied the file to your floppy disk. Try:       ls /mnt   you should see the file you just cp'ed. if not, you should retry the mount command, but if you didn't get any error messages when you tried to mount the drive, you should be OK. To verify that you did write to the floppy instead of the /mnt directory, (there is a difference, if no drive is mounted it's just a directory) you can:       umount /dev/fd0xxxx   and then try:       ls /mnt   upon which you should get a shell prompt. If you get the file name that you tried to copy to floppy, merely rm it and try the whole routine again. If you find this confusing, read up on mtools by:      info mtools   You may like what you see, give them a try. As I said I haven't had much luck with them, but basically the mformat command should do the abovementioned format tasks in one pass. Mcopy should likewise copy the named file to the floppy without the need to separately mount the drive.     Other Filesystems  There are several filesystems, as mentioned above that can be read by  linux. Minix, ext2, ext, xiaf, vfat, msdos(I'm still a little bit foggy on the difference between these two).Still others can be read with the use of applications, amiga for instance. That's why it makes sense to split up what is a single step process in DOS.    Humbly acknowledging...  I got a lot of mail regarding the locate command, which I'm woefully guilty of spreading misinformation about. The real poop is that locate is a byproduct of a  command, updatedb, which can be run at any time. It is run as default in the wee hours of the morning from /usr/bin/crontab, which is where I got the idea to leave the computer on overnight.    Next Time- Let me know what you would like to see in here and I'll try to oblige just e-mail troll@net-link.net   me and ask, otherwise I'll just write about what gave me trouble and how I got past it.    TTYL, Mike List              Copyright © 1997, Mike List   Published in Issue 18 of the Linux Gazette, June 1997                              ""Linux Gazette... making Linux just a little more fun! ""                 DiskHog: Using Perl and the WWW to Track System Disk Usage   By Ivan Griffin,  Ivan.Griffin@ul.ie         An irksome job that most system administrators have to perform at some stage or other is the implementation of a disk quota policy.  Being a maintainer of quite a few machines (mostly Linux and Solaris, but also including AIX) without system enforced quotas, I needed an automatic way of tracking disk quotas.  To this end, I created a Perl script to regularly check users disk  usage, and compile a list of the largest hoggers of disk space.  Hopefully, in this way, I can politely intimidate people into reducing the size of their home directories when they get ridiculously large.      The  du  command summarises disk usage for a given directory hierarchy. When run in each users home directory, it can report how much disk space the user is occupying.  At first, I had written a shell script to run  du  on a number of user directories, with an awk back-end to provide nice formatting of the output.  This proved difficult to maintain if new users were added to the system.  Users home directories were unfortunately located in different places on each operating system.      Perl provided a convenient method of rewriting the shell / awk scripts into a single executable, which not only provided more power and flexibility but also ran faster!  Perl's integration of standard Unix system calls and C library functions (such as  getpwnam()  and  getgrname() ) makes it perfectly suited to tasks like this.  Rather than provide a tutorial on the Perl language, in this article I will describe how I used Perl as a solution to my particular need.  The complete source code to the Perl script is shown in listing 1.      The first thing I did was to make a list of the locations in which users home directories resided, and isolate this into a Perl array.  For each sub-directory in the directories listed in this array, a disk usage summary was required.  This was implemented by using the Perl system command to spawn off a process running  du .      The  du  output was redirected to a temporary file.  The temporary file was named using the common $$ syntax, which is replaced at run time by the PID of the executing process.  This guaranteed that multiple invocations of my disk usage script (while unlikely) would not clobber each others temporary working data.      All the sub-directories were named after the user who owned the account.  This assumption made life a bit easier in writing the Perl script, because I could skip users such as  root ,  bin , etc.      I now had, in my temporary file,  a listing of a disk usage and username, one pair per line of the file.  I wanted to split these up into an associated hash of users and disk usage, with users as the index key.  I also wanted to keep a running total of the entire disk usage, and also the number of users.  Once Perl had parsed all this information from the temporary file, I could delete it.      I decided the Perl script would dump its output as an HTML formatted page. This allowed me great flexibility in presentation, and also permitted the information to be available over the local intranet - quite useful when  dealing with multiple heterogeneous environments.      Next I had to work out what information I needed to present.  Obviously the date when the script had run was important, and a sorted table listing disk usage from largest to smallest was essential.   Printing the  GCOS  information field from the password file allowed me to view both real names, and usernames.  I also decided it might be nice to provide a hypertext link to the users homepage, if one existed.  So extracting their official home directory from the password file, and adding on to it the standard user directory extensions to it (typically  public_html  or  WWW ) allowed this.       Sorting in Perl usually involves the use of the spaceship operator (  <=> ).  The sort function sorts a list and returns the sorted list value.  It comes in many forms, but the form used in the code is:      sort sub_name list       where  sub_name  is a Perl subroutine.   sub_name  is call during element comparisons, and it must return an integer less than, equal to, or greater than zero, depending on the desired order of the list elements.  sub_name  may also be replaced with an inline block of Perl code.      Typically sorting numerically ascending takes the form:      @NewList = sort { $a <=> $b } @List;       whereas sorting numerically descending takes the form:      @NewList = sort { $b <=> $a } @List;       I decided to make the page a bit flashier by adding a few of those omnipresent coloured ball GIFs.  Green indicates that the user is within allowed limits. Orange indicates that the user is in a danger buffer zone -  no man's land, from which they are dangerously close to the red zone.  The red ball indicate a user is over quota, and depending on the severity multiple red balls may be awarded to really greedy, anti-social users.      Finally, I plagued all the web search engines until I found a suitable GIF image of a pigglet, which I included on the top of the page.      The only job left was to include the script to run nightly as a cron job. It needed to be run as root in order to accurately assess the disk usage of each user - otherwise directory permissions could give false results. To edit roots cron entries (called a  crontab ), first ensure you have the environment variable  VISUAL  (or  EDITOR ) set to your favourite editor.  Then type      crontab -e       Add the line from listing 2 to any existing crontab entries.  The format of crontab entries is straightforward.  The first five fields are integers, specifying the minute (0-59), hour (0-23), day of the month (1-31), month of the year (1-12) and day of the week(0-6, 0=Sunday).  The use of an asterix as a wild-card to match all values is permitted, as is specifying a list of elements separated by commas, or a range specified by start and end (separated by a minus).  The sixth field is the actual program to being scheduled.      A script of this size (which multiple invocations of  du ) takes some time to process.  As a result, it is perfectly suited for scheduling under cron - I have it set to run once a day on most machines (generally during the night, which user activity is low).   I believe this script shows the potential of using Perl, Cron and the WWW to report system statistics. Another variant of it I have coded performs an analysis of web server log files.  This script has served me well for many months, and I am confident it will serve other sysadmins too.        #!/usr/local/bin/perl -Tw  # $Id: issue18.html,v 1.2 2002/10/09 22:24:18 lg Exp $ # # Listing 1: # SCRIPT:       diskHog # AUTHOR:       Ivan Griffin (ivan.griffin@ul.ie) # DATE:         14 April 1996 # # REVISION HISTORY: #   06 Mar 1996 Original version (written using Bourne shell and Awk) #   14 Apr 1996 Perl rewrite #   01 Aug 1996 Found piggie image on the web, added second red ball #   02 Aug 1996 Added third red ball #   20 Feb 1997 Moved piggie image :-)  # # outlaw barewords and set up the paranoid stuff # use strict 'subs'; use English;  $ENV{'PATH'} = '/bin:/usr/bin:/usr/ucb'; # ucb for Solaris dudes $ENV{'IFS'} = '';  # # some initial values and script defines # $NumUsers = 0;  $Total = 0;  $Position = 0;   $RED_ZONE3 = 300000; $RED_ZONE2 = 200000; $RED_ZONE = 100000; $ORANGE_ZONE = 50000;  $CRITICAL = 2500000; $DANGER   = 2200000;  $TmpFile = ""/var/tmp/foo$$""; $HtmlFile = '>/home/sysadm/ivan/public_html/diskHog.html'; $PerlWebHome = ""diskHog.pl"";  $HtmlDir = ""WWW""; $HtmlIndexFile = ""$HtmlDir/index.html""; $Login = "" ""; $HomeDir="" ""; $Gcos = ""A user"";  @AccountDirs = ( ""/home/users"", ""/home/sysadm"" ); @KeyList = ();  @TmpList = ();  chop ($Machine = `/bin/hostname`); # chop ($Machine = `/usr/ucb/hostname`); # for Solaris   # # Explicit sort subroutine # sub by_disk_usage {     $Foo{$b} <=> $Foo{$a};  # sort integers in numerically descending order }   # # get disk usage for each user and total usage # sub get_disk_usage  {     foreach $Directory (@AccountDirs)     {         chdir $Directory or die ""Could not cd to $Directory\n"";         # system ""du -k -s * >> $TmpFile""; # for Solaris          system ""du -s * >> $TmpFile"";     }      open(FILEIN, ""<$TmpFile"") or die ""Could not open $TmpFile\n"";      while (<FILEIN>)     {         chop;         ($DiskUsage, $Key) = split(' ', $_);          if (defined($Foo{$Key}))         {             $Foo{Key} += $DiskUsage;         }         else         {             $Foo{$Key} = $DiskUsage;              @TmpList = (@KeyList, $Key);             @KeyList = @TmpList;         };          $NumUsers ++;         $Total += $DiskUsage;     };      close(FILEIN);     unlink $TmpFile; }   # # for each user with a public_html directory, ensure that it is # executable (and a directory) and that the index.html file is readable # sub user_and_homepage  {     $User = $_[0];      ($Login, $_, $_, $_, $_, $_, $Gcos, $HomeDir, $_) = getpwnam($User)         or return ""$User</td>"";      if ( -r ""$HomeDir/$HtmlIndexFile"" )     {         return ""$Gcos <a href=\""/~$Login\"">($User)</a>"";     }     else     {         return ""$Gcos ($User)</td>"";     }; }  # # generate HTML code for the disk usage file # sub html_preamble {     $CurrentDate = localtime;      open(HTMLOUT, $HtmlFile) or die ""Could not open $HtmlFile\n"";     printf HTMLOUT <<""EOF""; <!DOCTYPE HTML PUBLIC ""-//IETF//DTD HTML 3.0//EN"">  <!--   -- Automatically generated HTML   -- from $PROGRAM_NAME script   --   -- Last run: $CurrentDate   -->  <html> <head> <title> Disk Hog Top $NumUsers on $Machine </title> </head>  <body bgcolor=""#e0e0e0""> <h1 align=center>Disk Hog Top $NumUsers on $Machine</h1>  <div align=center> <table> <tr>     <td valign=middle><img src=""images/piggie.gif"" alt=""[PIGGIE!]""></td>     <td valign=middle><em>This is a <a href=$PerlWebHome>Perl</a>         script which runs<br>         automatically every night</em><br></td> </tr> </table>  <p> <b>Last run started</b>: $StartDate<br> <b>Last run finished</b>: $CurrentDate </p>  <p> <table border=2> <tr> <th>Status</th> <td> EOF      if ($Total > $CRITICAL)      {         print HTMLOUT ""CRITICAL!!! - Reduce Disk Usage NOW!"";     }     elsif (($Total <= $CRITICAL) && ($Total > $DANGER))     {         print HTMLOUT ""Danger - Delete unnecessary Files"";     }     else     {         print HTMLOUT ""Safe"";     }       printf HTMLOUT <<""EOF""; </td> </tr> </table> </P>  <hr size=4>  <table border=2 width=70%%>     <tr>         <th colspan=2>Chart Posn.</th>         <th>Username</th>         <th>Disk Usage</th>     </tr>  EOF }  # # # sub html_note_time {     $StartDate = localtime; }    # # for each user, categorize and display their usage statistics # sub dump_user_stats {     foreach $Key (sort by_disk_usage @KeyList)     {         $Position ++;          print HTMLOUT <<""EOF"";     <tr>\n         <td align=center> EOF          #         # colour code disk usage         #         if ($Foo{$Key} > $RED_ZONE)          {             if ($Foo{$Key} > $RED_ZONE3)             {                 print HTMLOUT ""        <img src=images/ball.red.gif>\n"";             }              if ($Foo{$Key} > $RED_ZONE2)             {                 print HTMLOUT ""        <img src=images/ball.red.gif>\n"";             }              print HTMLOUT ""        <img src=images/ball.red.gif></td>\n"";         }         elsif (($Foo{$Key} <= $RED_ZONE) && ($Foo{$Key} > $ORANGE_ZONE))         {             print HTMLOUT ""        <img src=images/ball.orange.gif></td>\n"";         }         else         {             print HTMLOUT ""        <img src=images/ball.green.gif></td>\n"";         }          print HTMLOUT <<""EOF"";          <td align=center>$Position</td> EOF          print HTMLOUT ""        <td align=center>"";         print HTMLOUT &user_and_homepage($Key);         print HTMLOUT ""</td>\n"";          print HTMLOUT <<""EOF"";         <td align=center>$Foo{$Key} KB</td>     </tr>  EOF     }; }  # # end HTML code # sub html_postamble {     print HTMLOUT <<""EOF"";     <tr>         <th></th>         <th align=left colspan=2>Total:</th>         <th>$Total</th>     </tr> </table>  </div>  <hr size=4> <a href=""/"">[$Machine Home Page]</a>  </body> </html> EOF       close HTMLOUT ;  # # ownership hack #     $Uid = getpwnam(""ivan"");     $Gid = getgrnam(""users"");      chown $Uid, $Gid, $HtmlFile; }   # # main() #  &html_note_time; &get_disk_usage; &html_preamble; &dump_user_stats; &html_postamble;  # all done!       Listing 1. diskHog.pl script source.          0 0 * * * /home/sysadm/ivan/public_html/diskHog.pl       Listing 2. root's crontab entry.            Figure 1. diskHog output.                      Copyright © 1997, Ivan Griffin   Published in Issue 18 of the Linux Gazette, June 1997                              ""Linux Gazette... making Linux just a little more fun! ""                dosemu & MIDI: A User's Report   By Dave Phillips,  dlphilp@bright.net          First, the necessary version info:    Linux kernel 2.0.29  dosemu 0.66.1  Sound Driver 3.5.4   And then there's the hardware:    AMD 486/120  MediaVision Pro Audio Spectrum 16 (PAS16) soundcard w. MIDI interface adapter  Music Quest MQX32M MIDI interface  two Yamaha TX802 synthesizers      dosemu   is an MS-DOS emulator for Linux. The  on-line manual  describes it as  ""...a user-level program which uses certain special features of the Linux kernel and the 80386 processor to run MS-DOS in what we in the biz call a DOS box. The DOS box, a combination of hardware and software trickery, has these capabilities:        the ability to virtualize all input/output and processor control instructions      the ability to support the word size and addressing modes of the iAPX86 processor family's real mode, while still running within the full protected mode environment      the ability to trap all DOS and BIOS system calls and emulate such calls as are necessary for proper operation and good performance      the ability to simulate a hardware environment over which DOS programs are accustomed to having control.       the ability to provide MS-DOS services through native Linux services; for example, dosemu can provide a virtual hard disk drive which is actually a Linux directory hierarchy.   The hardware component of the DOS box is the 80386's virtual-8086 mode, the real mode capability described above. The software component is dosemu.""    I installed version 0.66.1 because I read that it supported MIDI, and I was curious to find whether I would be able to run my favorite DOS MIDI sequencer, Sequencer Plus Gold from  Voyetra . Installation proceeded successfully, and after some initial fumbling (and a lot of help from the Linux newsgroups), I was running some DOS programs under Linux.    However, the MIDI implementation eluded me. I followed the directions given in the dosemu package: they are simple enough, basically setting up a link to /dev/sequencer. But since Sequencer Plus requires a Voyetra API driver, I ran into trouble: the VAPI drivers wouldn't load.    I tried to use the VAPIMV (Voyetra API for Media Vision) drivers, but they complained that MVSOUND.SYS wasn't loaded. These drivers are specific to the PAS16 soundcard, so I was puzzled that they couldn't detect MVSOUND.SYS (which was indeed successfully loaded by config.sys). I also tried using the SAPI drivers, Voyetra's API for the SoundBlaster: the PAS16 has a SB emulation mode which I had enabled in MVSOUND.SYS, but those drivers wouldn't load, again complaining that MVSOUND.SYS wasn't installed. VAPIMQX, the driver for the MQX32M, refused to recognize any hardware but a true MQX. Checking the Linux sound driver status with 'cat/dev/sndstat' reported my MQX as installed, but complete support for the sound driver (OSS/Free) has yet to be added to dosemu.   Since MVSOUND.SYS was indeed installed (I checked it in dosemu using MSD, the Microsoft Diagnostics program), and since the MIDI interface on the soundcard was activated, I began to wonder whether that interface could be used. I tested the DOS MIDI programming environment  RAVEL , which is ""hardwired"" internally to only an MPU-401 MIDI interface: to my surprise and satisfaction, the soundcard's MIDI interface worked, and I now had a DOS MIDI program working under Linux.  Following that line of action, I figured that the Voyetra native MPU driver just might load. I tried VAPIMPU: it failed, saying it couldn't find the interrupt. I added the command-line flag /IRQ:7 and the driver loaded. I now had a Voyetra MIDI interface device driver loaded, but would Sequencer Plus Gold run ?   Not only does Sequencer Plus run, I am also able to use Voyetra's Sideman D/TX patch editor/librarian for my TX802s. And I can run RAVEL, adding a wonderful MIDI programming language to my Linux music & sound arsenal.    All is not perfect: RAVEL suffers the occasional stuck note, and the timing will burp while running Seq+ in xdos, particularly when the mouse is moved. The mouse is problematic with Seq+ in xdos anyway, sometimes locking cursor movement. Since my configuration for the dosemu console mode doesn't support the mouse, that problem doesn't arise there. Switching to another console is possible; this is especially useful if and when dosemu crashes. Also, programs using VGA ""high"" graphics will crash, but I must admit that I have barely begun to tweak the video subsystem for dosemu. It may eventually be possible to run Sound Globs, Drummer, and perhaps even M/pc, but for now it seems that only the most straightforward DOS MIDI programs will load and run without major problems.    And there is a much greater problem: only version 1.26 of the VAPIMPU driver appears to work properly. A more recent version (1.51) will not load, even with the address and interrupt specified at the command-line. However, Rutger Nijlunsing has mentioned that he is working on an OSS/Free driver for dosemu which would l"
GX053-38-5326462	"Copyright © 1996-97 Specialized Systems Consultants, Inc.  linux@ssc.com                Welcome to Linux Gazette!              Published by:                     Sponsored by:                        Our sponsors make financial contributions toward the costs of publishing  Linux Gazette . If you would like to become a sponsor of  LG , e-mail us at  sponsor@ssc.com .           ""Linux Gazette... making Linux just a little more fun! ""             The Mailbag!    Write the Gazette at   gazette@ssc.com     Contents:     Help Wanted -- Article Ideas   General Mail                 Help Wanted -- Article Ideas                Date: Mon, 18 Aug 1997 00:25:47 -0400  From: Anthony Wilson  anthony@pisces.globalserve.net  Subject: Difficulty running programmes   I am using Linux Slackware 3.0 with kernel version 2.0.  I am running    a LAN and whenever I try to run a script or a program that I created on the server, I get a command not found error, even though I have read write permissions on the file in my own directory.  If I transfer that same file to another Linux box on this LAN, I can run it without any problems.   Is there an easy fix to this problem?   Thank you.   Anthony Wilson              Date: Wed, 20 Aug 1997 06:00:38 +0200  From: Denny  denny@ele.kth.se  Subject: Connecting to dynamic IP via ethernet   Hello. I want to connect my Linux box to our ethernet ring here at my company. The problem is that they(we) use dynamic IP adresses, and I don't know how to get an adress. I use win95 on one partition on my pc, from where it works fine to connect. I know the IP adress to the DCHP-server (that the one who distributes the IP-adresses, right?) but how do I do to get assigned an IP-adress from Linux? I got so tired of trying, that I finally just assigned an adress myself and hey, somethings work. I can use telnet and ftp but X takes 15 minutes to start, and emacs likewise. I can't wait that amount and also I'm sure there are several thing that don't work. Please, if you know how to do, explain carefully, I'm not all that good at linux and tcp/ip hacking.  Denny                 Date: Fri, 15 Aug 1997 09:47:03 -0500  From: Cory Sticha  csticha@apci.net  Subject: Printing PostScript to a DeskJet 682C   I've got a question that I'd to have answered. I've got an HP DeskJet 682C printer that I'd like to use to print pages out from Netscape. Unfortunately, the printer only recognizes text and PCL 3, while Netscape only uses PostScript. Is there a filter that is capable of converting PostScript to PCL 3. Also, to print text to this printer, I have to pipe the file that I want to print to todos and then pipe that to the printer. How can I automate this? Thank you very much in advance for any help that you can give me.    Cory Sticha, SrA, USAF                Date: Mon, 04 Aug 1997 14:12:42 +1000  From: Marcus B  marcus@cwi.net.au  Subject: Problem with adaptec 2940U   Answer: RedHat versions <4.0 use older kernels which don't have aic7xxx support, I found this out the hard way, back when the aic7xxx driver was only being developed, if you are talking about a version of RedHat that uses 2.0.x kernels, then they get loaded in as a module (when it asks what type of SCSI host adapter you have), if this is not loading then it might be an idea to check if it is sharing an IRQ with another device in windows 95 (if you are unlucky enough to have it!), and manually change it.  The aic7xxx driver is very new (>2.x kernels only) but there are problems on some hardware configurations.              Date: Wed, 6 Aug 97 20:55:49 BST  From: George russell  george.russell@clara.net  Subject: Linux Help needed to connect to Internet   I am a new Linux user, and inexperienced in Unix environments.  My aim in using Linux is to connect to the internet without needing to use Windows, in order to learn about Linux and update my linux setup (Slackware Linux Toolkit March 1997, which I will install again soon).  I have had X Windows and Netscape Navigator 3.01 installed,and will do so again after a hard disc upgrade.  I am unable to connect to the internet. Could anyone help me to do this? My modem is on COM2, and works under windows as a generic modem. I know the number of my ISP, that my IP address is server assigned.  I have the IP addresses of the primary and secondary DNS, and have my own username and password.  Is there anyhing else I need to know, and can anyone help me with this?  I would be very grateful for all assistance given.               Date: Wed, 06 Aug 1997 15:35:20 -0700  From: Luke  luke@holdens.org  Subject:LILO Problems    I have this 2 gig scsi drive. I have Linux and Windows 95 on my system. 95 is on the first gig and Linux is on the 2nd. Lilo gives me problems with booting Linux from the second gig. And windows just will not see it. Its a old scsi disk. So I cant use sector compadibility mode. Right now. I use Lodlin (and some 95 proggy) to drop out of 95 and kick linux in. Eather this or I have to use a installation floppy (I cant load lilo on a floppy because it gives me disks problems there too) You know of any boot managers that I can gain access to that can read the entire disk? I know the NT boot loader can do this. But there is no point in loading NT for this task. Another problem I have is this. I have a Windows NT box as a proxy server for my internet connection. (I can't convert it to Linux, it's not my box) I can get Windows 95 to send all ip requests threw the proxy using the ms proxy client. (ex: quake over the net) But with Linux I can't seem to do that. I have used Netscape a bit for this purpose. But I still can't do anything else. Is there a way to get Linux to work over a proxy itself? I could just dail into my ISP va PPP. But I already have a 10 megabit connection to them. What's the point of using a modem. Is there a way I can get around this problem? Another question I have is can I make a swap from an image or some other media. I don't want to kill my Linux partition to gain this. But, I have a 16 meg swap partition and 16 megs of ram. Trying to run progams like Wabi is of no use. They don't seem to have enough memory. Is there a way to add more swap space with out disturbing the exsisting partitions? Well thank you for your time. Long live LINUX!!!   Luke Holden               Date: Sat, 09 Aug 1997 23:14:04 -0400  From: David Nghiem   Subject: Pointers   Hey all,  Do you guys know of any information regarding programming a game in Linux on the X11 platform? I want to use it as a cross developer for some DOS games. The main issue here is this: How do I display my output?   Laterz,  Dave.              Date: Fri, 08 Aug 1997 20:03:21 -0400  From: Raymond E. Rogers  rrogers@voyager.net  Subject: Apllixware -- Fax   I bought applixware some time ago and found that I was supposed to roll my own Fax interface.  Somebody at work suggested just setting up a ""printer"" for fax.  Logical to me.  As I don't do Linux for a living or a hobby; it would be nice if somebody could write and article on how to do it.   Or point me to instructions.  I looked around and was unable to find any.  There is supposed to be instructions in how to make netscape do standard PGP/RSA digital signatures that can be verified on any PGP system, not just inside of netscape.  Simple instructions on this would be nice.    If I get around to doing these things first, I will write an article on how I did it.   Enjoy  Ray      (An article entitled ""Faxing from the Web"" will be included in the upcoming November issue of Linux Journal. While the magazine won't be out until next month, the listings that go with it (including his front end) are available at   ftp://ftp.ssc.com/pub/lj/listings/issue43/2044.tgz . Since the author was not using Applixware, I'm not sure how much his code will help, but check it out, it may be just what you need. --Editor)                   General Mail                Date: Wed, 30 Jul 1997 12:22:41 -0700  From: Tom Schenck  tschenck@concentric.net  Subject: Organize and overtake!   Well, I'm pretty sure there are people doing this, but not very fast or efficiently. We need a stable, friendly, easy-to-install system that comes equiped with applications that allow the user to begin working right away, and configure without programming knowledge!   Yes, it's *nix. Yes, it's a programmers environment. Yes, it doesn't HAVE to be terse, hard to configure, etc.   Hell, maybe I'll have to do it!                Date: Fri, 22 Aug 97 21:09:09 BST  From: Duncan Simpson  feynmen.ecs.soton.ac.uk     Subject: M$ word   Those who need to read a word document might like to get the latest version of wqord2x by anonymous ftp from amil.telstar.net in the pub/duncan directory. Note the machine's main job is a mail redirection service, which sends me the logs, amoung other things!!   Duncan                Date: Sun, 10 Aug 1997 13:56:23 -0600 (MDT)  From: Michael J. Hammel  mjhammel@csn.net  Subject: MS quote   This comes via a Mac friend of mine.  We should look closely at aligning with the Mac users of the world.  They hate MS almost as much as we do.  :-)  From: EvangeList  evangelist@apple.com    This tidbit is from: Dave Reiser,  dbr@ptd.net   In a page 1 article in the July 28, 1997 Computerworld there's an article ENTITLED ""Microsoft Declares War"" about how MS has announced that it will not ship the Java class libraries.  I absolutely howled when I read this quote:  ""'We have no intention of shipping another bloated operating system and forcing that down the throats of our Windows customers'"" [attributed to Paul Maritz, Microsoft Group Vice President]  Are they feeling guilty about the fact that they've already rammed one bloated operating system down their customers' throats?  --  Michael J. Hammel                From mjhammel@csn.net Fri Aug  8 21:48:52 1997  Date: Fri, 08 Aug 1997 23:00:22 -0600  Subject: Descent 3D for Linux?    Linux has always been the perfect platform for games, it's just very few developers (id and Crack.com are the only two worth mentioning that I know of) know that.   Actually I think many of the developers know the value of Linux, but there is no marketing proof that a Linux port will make money.  As many others have said in the past, we need certifiable numbers to prove the market exists and that its willing to spend money on commercial products.  I don't have any info on it, but I'd love to know if either Id or Crack.com made any money on their Linux ports.  And I'd like to know if it was enough, in their eyes, to warrant future ports.  I've a gut feeling the Id guys may have done their port simply because they liked the idea and did it for fun, but thats just an unsubstantiated hunch.   I just got back from SIGGRAPH today and after having talked to many engineers from lots of different companies I can say that nearly all are *very* aware of Linux and most (that I talked to) are using it.  One engineer from Cosmos Software, the new division at SGI, said they'd probably be happy to let someone do the port of the new Cosmo Player 1.0  to Linux (although he wasn't sure how to go about getting that done).  Most of the companies at the conference who are Unix aware are also Linux aware.  They just need a little proof that the market will return their investment within a reasonable time frame.   One of the things I decided to do while I was at SIGGRAPH was to write an article outlining how to begin to get reasonable market figures for Linux with respect to graphics tools and games (other vertical markets are a bit out of my league).  I'm sketching this out now and will probably submit it to the Linux Journal in September or October.  Much of it resolves around the use of simple Multimedia applications. Anyway, once we have the numbers to back us up, it will be a little easier to convince game developers to include Linux ports of their software.   -- Michael J. Hammel                Date: Fri, 08 Aug 1997 22:36:23 -0600  From: Michael J. Hammel  mjhammel@csn.net  Subject: Firewire and DV   I just got back from SIGGRAPH.  To my knowledge there are no plans for Firewire support for Linux, but I have to admit I didn't specifically go looking for it.  I'm not even completely sure what it is (although thought it was just another 3D chipset).  I've been on a personal crusade to get Linux noticed as a terrific platform for image processing and graphic arts tools, and that includes (eventually) Digital Video (DV) tools.  However, although there are quite a large number of tools for doing computer graphics (including plenty of support for OpenGL, both commercially and in the freeware MesaGL package), I've not seen any DV style tools.  I'd say its a little early for such tools on a commercial basis since more basic tools are not commercially supported yet.  But its certainly something I'll continue to keep an eye on and do my best to encourage.   DV tools would work as well on Linux as any other high-end Unix system, but tools like graphics tablets and scanners need better support before we'll get into DV tools.  We also need a decent GUI toolkit.  Motif is ok, but a bit bloated.  Most of the other toolkits don't have enough printed documentation available yet.  While at SIGGRAPH, Mark Kilgard told me that there is a new toolkit that sits on top of GLUT that might be a good basis for a more advanced toolkit.  I haven't had time to look at it yet (I just got back today).  Anyway, I hope this helps a little.  If you find any DV tools or have contacts that could use a little polite prodding, feel free to drop me a line.   -- Michael J. Hammel                  Date: Wed, 27 Aug 1997 09:04:22 -0700 (PDT)  From: Riley Eller  RILEYE@datalight.com    It took Linus to make it happen  It took everyone to make it right  It takes HOWTOs to make it work  It takes the Gazette to make it FUN  Thank You Linux Gazette :-)   Riley Eller  Newbie Jihad Warrior                  Published in Linux Gazette Issue 21, September 1997                     This page written and maintained by the Editor of  Linux Gazette ,  gazette@ssc.com   Copyright © 1997 Specialized Systems Consultants, Inc.         ""Linux Gazette... making Linux just a little more fun!  ""                More 2¢ Tips!    Send Linux Tips and Tricks to   gazette@ssc.com       Contents:     Changing Video Modes   Colormap Questions   Netcat!   Starting and Stopping Services   A New Tool for Linux   Of Logs and Other Things   Calculator Tip   Another Way to View Tarred Files   Script Ease   Syslog Thing   Sorta E-mail-to-FAx...Well, to-Printer   Setting Xterm Title to Current Process   CVS                   Changing Video Modes      Date: Fri, 08 Aug 1997 22:41:05 -0600  From: Michael J. Hammel  mjhammel@csn.net    I don't know how AccelX and XiGraphics and MetroX handle these things.   AccelX is ( I think) a PC graphics company.  You might mean Xaccel, which is the actual program name for Xi Graphics X server.  Its product name is ""AcceleratedX"".   Xi Graphics is the company name.   As for how Xaccel changes its video modes - try CTRL-ALT-+ (thats a plus sign).  I believe that cycles through the various modes.  Check the man pages or manual to be certain.  I believe MetroX does similar, but the keystroke is probably different.   --                Colormap Question        Date: Fri, 08 Aug 1997 23:47:31 -0600  From: Michael J. Hammel  mjhammel@csn.net    The question was ""can you force an X application to use its own colormap in some way other than using a command line option"".  The answer is:  it depends (aint it always the case?).   An applications ability to use its own colormap is not a ""builtin"" part of X.  Colormaps are part of X, but the application still has to add code to make use of colormaps.  So if the application doesn't have any code specifically for handling colormaps (for example, my XPostitPlus doesn't have any such code) then neither the command line or any other method will force it to use a private colormap.  The default for applications (like XPostitPlus) is to use the default colormap, and thats why you often see applications with weird colors that you can't get rid of till you exit some other application.   Now, if the application *does* have code to deal with colormaps, it can also make the use of the private colormap a user configurable option.  X provides a mechanism for making an option either a command line option (eg. -usePrivateColormap) or an X resource.  X resources can be specified in X resource files (like .Xdefaults) or on the command line using the -xrm option.  X is so configurable that the number of ways for a user to supply configuration information can often be quite confusing, both for the user and the developer.  In any case, its up to the programmer to make any of these methods available.  None is available by default simply becaue its ""an X windows program"".   The correct thing for an application to do is to allow the user to configure the use of the private colormap in at least one way and to provide a best-guess default for determining if a private colormap would be the best thing to do or not if the user doesn't provide a preference.  Few applications do this, however.  The GIMP does.  So do XV and Netscape.  Even my own programs aren't very good at this, although I intend to get much better in the very near future.   As for an X column, well, I'd love to see one.  We just need to convince some X hack to spend a little time writing articles instead of code. Thats kinda hard to do.  I'll probably be adding some X coding tidbits to my Muse column, but only with respect to using Motif or OpenGL in graphical and multimedia applications.   Hope this helps a little.   -- Michael                 Netcat!      Date: 01 Aug 1997 15:46 EDT  From: Jean-Philippe Sugarbroad  da1wizard@geocities.com    I was going through back issues of the Linux Gazette and I remembered a program I use quite frequently... netcat.  This program enables you to open sockets and connect or listen with them - all from a shell script!  It's a great way to quickly fetch web pages or see if a server is running... It even has UDP 'connection' mode and zero-io mode (which closes the connection as soon as it succeeds...).  The UDP mode even uses a TCP connection to check round-trip time :)  I love it!   Jean-Philippe Sugarbroad                Starting and Stopping Services       Date: Tue, 5 Aug 1997 18:55:19 -0600 (CST)  From: Terrence Martin  twm139@its.to    I was just reading the August version of Linux Journal and I noticed refrence to rebooting the system after making changes to the /etc/syslog.conf file in order for those changes to take affect. This is contrary to a feature that is the main reason I use Linux at home and at work.   It is only generally necessary to reboot Linux to add/remove hardware or when installing a new kernel. In the specific case of syslogd(8) you can inform the server to reread it's initialization file by sending it a SIGHUP signal.  eg. kill -HUP `cat /var/run/syslogd.pid`    This will work with many of the servers available for Linux including (most) httpd(8), named(8), and inetd(8).    Sometimes however it is preferable to actually restart these services. In Slackware I believe most of your services are placed in a single script and this makes it a little more difficult to pick and choose which services to stop and start.    In RedHat it is a little more modular. In the directory /etc/rc.d/init.d are the scripts that are run on bootup to start various services.    These scripts allow you to start and stop various services just as if you had shutdown and rebooted your machine. eg.  # /etc/rc.d/init.d/named.init stop  # /etc/rc.d/init.d/named.init start    This will start and stop the name service.   The scripts supplied with RedHat are not too complex compared to similar scripts I have seen on other systems. They can usually be adapted to new services that you may wish to have start on bootup, without complicating the rc.local file and giving you much finer control.   If you examine the soft links in /etc/rc.d/rc0.d through /etc/rc.d/rc6.d you will notice that they link to the files in /etc/rc.d/init.d. Each of these numbers on these directories refer to a ""runlevel"".   As the system boots the /etc/inittab tells the init process which directories to examine to determine which services to start up, most systems not running xdm will end at runlevel 3, otherwise it is runlevel 5.    All of the files(softlinks) in runlevel 3 beginning with 'S' are executed in order of occurance in the directory, this is controlled by giving each a number ie  S30syslog -> ../init.d/syslog comes before  S40cron -> ../init.d/cron.init.   Note: Links with the same number are executed in lexical order.   The sequence may be important depending what services depend on other services.   I put most of the services I add in runlevel 3, as I usually boot into multiuser mode. You then should add the approriate script link to /etc/rc6.d as those are the files that are executed on shutdown. Note the convention here is to begin all soft link names with 'K'. ie    K10named.init -> ../init.d/named.init    Again these scripts are executed on order with the highest number being last to run.    The net effect of all these links is that with an 'S' preceding the soft link the script is run with the argument ""start"" and with a 'K' it is run with the argument ""stop"".   Over the last two weeks I have set up and configured a news server, web server, name server, sshd server, updated the syslog.conf file plus a hundred other little tweaks on our RedHat 4.x box and I have not had to reboot once. In fact the system has not been rebooted since we added a new CPU and SCSI card 31 days ago...I love Linux :)...   Regards  Terrence Martin           A New Tool for Linux       Date: Fri, 22 Aug 1997 08:29:59 -0500  From: Ian  Beth13@mail.utexas.edu    The version posted in issue 20 assumes you have exec access to ALL dirs under the one you 'TREE'   Here's a modified version which works even in cases of unreadable folders:  -------------------------------- cut here -------------- #!/bin/sh #         @(#) tree      1.1  30/11/95       by Jordi Sanfeliu #                                         email: mikaku@arrakis.es # #         Initial version:  1.0  30/11/95 #         Next version   :  1.1  24/02/97   Now, with symbolic links #         Patch by       :  Ian Kjos, to support unsearchable dirs #                           email: beth13@mail.utexas.edu # #         Tree is a tool for view the directory tree (obvious :-) ) # search () {    for dir in `echo *`    do       if [ -d $dir ] ; then          zz=0          while [ $zz != $deep ]          do             echo -n ""|   ""             zz=`expr $zz + 1`          done          if [ -L $dir ] ; then             echo ""+---$dir"" `ls -l $dir | sed 's/^.*'$dir' //'`          else             echo ""+---$dir""             if cd $dir ; then                deep=`expr $deep + 1`                search    # with recursivity ;-)                numdirs=`expr $numdirs + 1`             fi          fi       fi    done    cd ..    if [ $deep ] ; then       swfi=1    fi    deep=`expr $deep - 1` }  # - Main - if [ $# = 0 ] ; then    cd `pwd` else    cd $1 fi echo ""Initial directory = `pwd`"" swfi=0 deep=0 numdirs=0 zz=0  while [ $swfi != 1 ] do    search done echo ""Total directories = $numdirs""   -------------------------------- cut here --------------     The changes are to put the ""cd $dir"" as the predicate of an IF statement, NOT IN A SUBSHELL, and the recursive part is the switched clause. This prevents infinite recursion in the case of an unreadable or unexecable dir.                 Of Logs and Other Things      Date: Sun, 10 Aug 1997 21:47:39 +0200  From: D. Emilio Grimaldo T.  grimaldo@panama.iaehv.nl    Hi,     I recently saw on the August issue of Linux Gazzete and some previous issues about the handling of system logs. Well, it doesn't have to be complicated, in fact I have written a very useful script/package that has been around for a couple of years, it is called Chklogs and is used by major network providers, companies and small-time users of Linux systems. In fact it is going to be featured in the Linux Journal some time this year. IT fulfills all the log handling needs. For more information see  http://www.iaehv.nl/users/grimaldo/info/    Catch the link to Chklogs     Best Regards,      Emilio                 Calculator Tip     Date: Sun, 27 Jul 1997 23:43:37 +0200 (MET DST) From: Hans Zoebelein  zocki@goldfish.cube.net    Hello Linux Gazetters,   Here comes a real cheap command line calculator. Since shell scripts do only integer calculation, you are stuck if you want floating point precision.   You also want to do sometimes stuff like 'how much is  1200*3/7' at the commandline without firing up a full  blown GUI calculator.   Just for that work you can use the  calcme  command line  calculator, which is hacked in perl. Dont forget that a shell  thinks differently about 10*3 than a calculator. So do it as  10\*3 or ""10*3"".   The icing of the cake is the optional formatting. If you supply something like  %.3f  as second parameter, the output is nicely  formatted as floating point number and up/down rounded correctly  after 3 decimals.   You also can do a  calc 10/3 %20.6f  which returns a string  with 6 digits and 20-6=14 spaces like  ______________3.3333 .  So formatting of lists in shell scripts is real fun now.       Enjoy!  Hans     #!/usr/bin/perl  # # The ultimate command line calculator :-^ # Usage calcme <string_to_calculate> [<output_format>] #  # Input is a string like (10+3)/7 or ""(10 + 3) / 7"" # Output is the calculated result of the string (sic!). # Optional formatting can supplied as 2nd parameter.   if (@ARGV == 0 || @ARGV > 2) {    die(""Usage: $0 <\""formula_to_calculate\""> [<output_format>]\n""); }   $format = """"; $calcme = $ARGV[0]; (@ARGV == 2) && ($format = $ARGV[1]);   $output = eval($calcme);  if(@ARGV == 1) {    print(STDOUT ""$output\n""); } else {    printf(STDOUT ""$format\n"", $output); } exit(0);     -- Hans                  Another Way to View Tarred Files     Date: Sat, 02 Aug 1997 02:18:07 +1000 (GST) From: Gerald J Arce  garce@starcommand.mang.net    In issue 19, I read a 2 cents tip regarding viewing a tarred file.  I use less instead..  ex: tar tzf foo.tar.gz  less foo.tar.gz   Less typing (grin).                Script Ease            Date: Wed, 6 Aug 1997 01:54:19 +0200 (GMT+0200) From: Trucza Csaba  ctrucza@cemc.soroscj.ro    Hi all,  As a programmer-wannabe, I do a lot of typing. To ease at least the  beginning of each source file (which is mainly the same: include-s,  define-s, imports and stuff), I wrote a script to automatize this. For  the quality of the script please read the notice at the end of my mail.   (file: se) ---------cut here--------------- #!/bin/sh # #  source editor (se) # # usage: se <filename> <type> # # WARNINGS: #  1. do not supply extension: #   se MyProg.java will make a MyProg.java.java!!! # #  2. manually create the  #   SE_HOME_DIR,  #   SE_HOME_DIR/temp, #   SE_HOME_DIR/templates # # man se: # # create two files for each type of the source you want to se. # the script will copy the first file+filename+second file into a new # file (you got it?:-) # # so: if you want java, create two files: # # templates/java.1: # # ---8<--- # public class # --->8--- # (Do not put a newline at the end!) # # templates/java.2 # # ---8<--- # { #  public static void main(String args[]){ #  } # } # --->8--- #  # the script for se MyProg java (or jus se MyProg if the last time you # used java as type) will create a new file called MyProg.java: # # public class MyProg # { #  public static void main(String args[]){ #  } # } # # examine and modify at will # # author: Trucza Csaba ctrucza@cemc.soroscj.ro # # this script may be full of errors #  SE_HOME_DIR=~/.source-editor LAST_USED=$SE_HOME_DIR/last_used  if [ -f $LAST_USED ] ; then  SE_DEFAULT_TYPE=`cat $LAST_USED` fi  case $# in  0)  echo ""no parameter""  if [ -z $SE_DEFAULT_TYPE ] ; then   SE_DEFAULT_TYPE=java  fi  FILE_TYPE=$SE_DEFAULT_TYPE  FILENAME=~/.source-editor/temp/temp.$FILE_TYPE  ;;  1)  echo ""filename""  if [ -z $SE_DEFAULT_TYPE ] ; then   SE_DEFAULT_TYPE=java  fi  FILE_TYPE=$SE_DEFAULT_TYPE  FILENAME=$1.$FILE_TYPE   ;;  2)  echo ""name and type""  FILE_TYPE=$2  FILENAME=$1.$FILE_TYPE  ;; esac  echo ""FILE_TYPE=""$FILE_TYPE echo ""FILENAME=""$FILENAME   if [ -f $FILENAME ]; then  echo file exists else  build-template $FILE_TYPE $1  mv ~/.source-editor/templates/$FILE_TYPE.template $FILENAME fi echo $FILENAME echo $FILE_TYPE > $LAST_USED  jstar -tab 4 $FILENAME ---------cut here---------------     The second script is a simple backup script, to back all the sources up  and edit the tracking file.    (file: backup) ---------cut here--------------- #!/bin/sh # #  kind of backup with kind of version control # usage: backup # # backs up the current directory (well not all of it, just your # programs)  # # 1. creates a dir named backup (or whatever) # 2. in this directory will be a tracking file, a plain text file #  in which you can write some comments every backup # 3. optionally in the file named filelist you can write the names of # the files you want to back up # 4. examine and modify at will # # author: Trucza Csaba ctrucza@cemc.soroscj.ro # # this script may be full of errors #  # # where to back up # if [ -z $BACKUPDIR ] ; then  BACKUPDIR=backup fi  if [ ! -d $BACKUPDIR ] ; then  mkdir $BACKUPDIR fi  # # last version backed up #  LAST_FILE=$BACKUPDIR/last  if [ -f $LAST_FILE ] ; then  VERSION=`cat <$LAST_FILE` else  VERSION=0 fi let VERSION=$VERSION+1  # # prepare next backup directory #  NEXT_DIR=$BACKUPDIR/ver.$VERSION  mkdir $NEXT_DIR  # # get files to back up #  LIST_FILE=$BACKUPDIR/filelist  if [ -f $LIST_FILE ] ; then  cp `cat $LIST_FILE` $NEXT_DIR else # # if no filelist found, backup C and Java files # modify as you wish #  cp *.c $NEXT_DIR >/dev/null 2>&1  cp *.h $NEXT_DIR >/dev/null 2>&1  cp *.java $NEXT_DIR >/dev/null 2>&1 fi  # # update last #  echo $VERSION >$LAST_FILE  # # edit trackfile #  TRACK=$BACKUPDIR/track  echo >> $TRACK echo >> $TRACK echo ""====================================================================="">> $TRACK date >> $TRACK echo ""Version: ""$VERSION >>$TRACK  # # here use your favorite editor :) # jstar $TRACK ---------cut here---------------     They should be self-explanatory.  but, These scripts should not be used  for design or development of nuclear,  chemical, biological, weapons or missile technology, or any other places  where humans can be hurt                 Syslog Thing     Date: Thu, 07 Aug 1997 15:00:29 -0700  From: Kent Friis  dk5f@ehs.dk    In issue 20, I saw a 2c tip regarding syslog, Including changing the config  file, and REBOOTING. Now wait a minute, I thought this was Linux. How can one get uptime's of 300+ days, if you need to reboot every time you change a config file.   The solution is simply to edit the config file, and kill -HUP (pid of syslogd).   You should NEVER need to reboot, except to install a new kernel.   Kent Friis.                Sorta E-mail-to-Fax...Well to-Printer     Date: Fri, 8 Aug 1997 20:04:30 +0500 (PKT)  From: Tee Emm  tm@super.net.pk    Hello,   I can bet that many of you readers will try out this tip atleast for once. Here we go:   I work at an ISP here in Pakistan with 4 more shift engineers. We have offices in three different locations and, although email and talk are used very frequently, we sometime require ABSOLUTELY IMMEDIATE responce from the other office. Emails remain unchecked and talk request are sometimes ignored because the other party might be busy doing something else on a talk-disabled terminal. Well, you cannot ignore a Panasonic Dotmatrix printer printing out messages in your control center!   One of my so-to-say boss talked of having a utility which will poll a POP3 mailbox every few seconds and printing out any mail that might be in the box. He, being a visual basic guru, started writing a windows based application that would do the required. I, being a die hard Linux creature, started thinking how I can do the same on my dear Linux box. Well, it took me a day to ponder on this issue and when I clicked, it was just a breeze! Sixteen key strokes and I was ready with my system. I yelled 'Windoz Suxs, Linux Rules'!   I edited the /etc/aliases file and keyed in the following line:  urgent:  ""| lpr""   saved, the file and did a 'newaliases' and bingo! Any mail sent to urgent@super.net.pk was immediately printed on the screaming dot matrix printer. My boss was duly stunned!   (Note: You must have your 'lpr' command working before you can go ahead with this tip.)   Tariq Mustafa,                Setting Xterm Title to Current Process     Date: Tue, 12 Aug 1997 01:09:02 -0500 (CDT)  From: Rob Mayoff  mayoff@dqd.com    I saw this tip the Gazette:   Hi, after searching (to no avail) for a way to display the currently executing process in the xterm on the xterm's title bar, I resorted to changing the source of bash2.0 to do what I wanted. from line 117 of eval.c in the source, add the lines marked with # (but don't include the #)    If you use ksh instead of bash, you can get the same effect without changing the source:   typeset -A Keytable trap -- 'eval ""${Keytable[${.sh.edchar}]}""' KEYBD [[ ""$TERM"" == xterm ]] && \ Keytable[$'\r']=$'[[ -n ${.sh.edtext} ]] && print -n ""\E]2;${.sh.edtext}\a""'    You can download ksh (the POSIX-compliant Korn shell) for free from     http://www.research.att.com/orgs/ssr/book/reuse                  CVS     Date: Thu, 14 Aug 1997 11:08:27 -0400  From: Paul Rensing  paulr@dragonsys.com    Mario Storti wrote:    Using shar + RCS to Backup Set of Source Files     Hi, RCS (see rcs(1)) is a very useful tool that allows to store versions of a file by storing only the differences between successive versions. In this way I can make a large amounts of backups of my source files but with a negligible amount of storage. I use it all the time, even for TeX files!! However, when you are working with a set of source files (*.c, shell or Perl scripts, I work mainly with Fortran .f and Octave *.m files) what I want is to make backups of the whole set of files in such a way that you can recover the state of the whole package at a given time. I know that there is a script called rcsfreeze around, but I know that it has problems, for instance if you rename, delete or create new files, it is not guaranteed to recover the same state of the whole set.    I think a good way to handle this is by ""upgrading"" to CVS. CVS is a version control system built on top of RCS and was designed specifically to handle version control of large trees of files (the company who wrote it was a Sun VAR and handled the > 1000 files which they regularly received from Sun).   Once you have the project set up, you could simply do ""cvs commit"" from the top directory of a project, and CVS will check in all the changes to all the controlled files in the tree. If you are using this for ""backup"", you would only need to keep a copy of the CVS ""repository"".   Paul Rensing             Published in Linux Gazette Issue 21, September 1997                           This page maintained by the Editor of  Linux Gazette ,  gazette@ssc.com   Copyright © 1997 Specialized Systems Consultants, Inc.        ""Linux Gazette... making Linux just a little more fun! ""             Contents:     News in General   Software Announcements                 News in General                Linux® Trademark Resolution        Ownership of Linux® Trademark Resolved    Monterey, California, August 20, 1997 - A long standing dispute over ownership of the Linux® operating system trademark has been resolved. As a result of litigation brought by a group of five Linux companies and individuals against William R. Della Croce, Jr. of Boston, Massachusetts, Della Croce has assigned ownership for the registered mark to Linux Torvalds, the original author of Linux, as part of the a settlement agreement.   The plaintiffs in the suit were Linus Torvalds; specialized Systems Systems Consultants, Inc. (the  Linux Journal  of Seattle; Yggdrasil computing, Inc. in San Jose; Linux International, Amherst, NH; and Work Group Solutions of Aurora, CO. Non-plaintiffs Red Hat Software, Inc., Metrolink Inc., and Digital Equipment Corporation supported the litigation and contributed to the cost of the litigation.   The five plaintiffs brought suit against Della Croce in the U.S. Trademark Trial and Appeals Board, in November 1996. Della Croce had obtained registration of the Linux mark in September 1995, which created a storm of protests by the Linux community, who felt the mark belonged to Torvalds or the Linux community and not to any individual. In an attempt to correct the situation, the plaintiffs retained the internationally known intellectual property law firm of Davis & Schroeder of Monterey, California, who handled the case on a greatly reduced fee bases, as a service to the Linux community.   The five plaintiffs, through their attorneys, announced that (1) the matter has been settled by the assignment of the mark to Linus Torvalds, on behalf of all Petitioners and Linux users, and the dismissal with prejudice of the pending PTO Cancellation Proceeding; and (2) that Respondent was reimbursed for his trademark filing fees and costs by Petitioners. The other terms of the Settlement Agreement are confidential.   All inquiries should be referred to Petitioners' law firm, Davis & Schroeder at 408-649-1122 or by email at  ggd@iplawyers.com . A copy of the original Cancellation Petition filed in the TTAB, can be found at  http://www.iplawyers/text/linux.htm .               Linux Journal  1996 Back Issue CD-ROM       Linux Journal  announced the release and ship date of their 1996 back-issue CD-ROM. It will be available September 17, 1997.  LJ 's first back-issue CD-ROM will consist of twelve issuews of  Linux Journal  published during 1996. Features covered in 1996 include; systems administration, World Wide Web, back-ups, Linux distribution comparisons, software development, shell programming, getting new users started, graphics and several other topics.    An HTML interface will allow you to access the CD-ROM infromation using any World Wide Web browser. For those that don't have a World Wide Web browser,  gzilla , has been included on the CD-ROM.   Linux Journal 's 1996 back issues CD-ROM is $19.95 plus shipping and handling and can be ordered directly from  Linux Journal .   For more information take a look at  http://www.linuxjournal.com/ .              Vi Mugs       You might be interested in the vi reference mugs found at   http://www2.cic.net/~gpoulos/vimug_main.html . Check them out!                New Mailing List        Check out a new mailing list for Linux users to help each other with problems.. To subscribe send email to majordomo@ourweb.net with the following in the body: subscribe linuxlst              Linux Aptitude Test      There is a project which is trying to establish a quantitative measure  to assist in determining a person's knowledge and general usefulness in Linux setup, configuration, and maintenance. The project is aiming to create a test that can be used to assess an employee's strenths and general understanding of Linux.   Take a look at  http://www.icv.net/LAT                Software Announcements                 The Hawkeye Project         ""Hawkeye"" is the name of a new Linux Web server program, which has recently been released to the public. IT is an Internet/Intranet server suite, implementing  Internet protocols for information interchange.  A short list of the most important functions of Hawkeye:     HTTP 1.0 Server, HTTP 1.1 coming soon  POP3 / SMTP Server (E-Mail)   NNTP Server (Newsgroups)   FTP Server (File area)      Hawkeye is running under the LINUX operating system and requires the Linux SQL database MySQL  http://www.tcs.se . Hardware requirements are much like what you would need to build a normal Linux system. For optimal performance, we recommend a Pentium machine withat least 16 Megabytes of RAM. Hawkeye itself uses very little Harddisk space, so the size depends mainly on your site.  Check it out on the  Hawkeye Web Home Site                LinkScan 3.1 Released         Electronic Software Publishing Corporation introduced a number of new features in LinkScan version 3.1. There is added ability to check hyperlinks that are embedded within Adobe Acrobat PDF files and enhanced TapMap features such as...    Free evaluation copies of LinkScan 3.0 may be downloaded  from the company's website at:    http://www.elsop.com/linkscan               Published in Linux Gazette Issue 21, September 1997                       This page written and maintained by the Editor of  Linux Gazette ,  gazette@ssc.com   Copyright © 1997 Specialized Systems Consultants, Inc.          ""Linux Gazette... making Linux just a little more fun! ""                   The Answer Guy        By James T. Dennis,  jimd@starshine.org   Starshine Technical Services,   http://www.starshine.org/           Contents:     Linux Control Panel   Linux Command Line Arguments   More Random Crashes   More on Disk Defrag   X-Windows is Crashing   Lunx and Frames   More on ftpd   DNS Problem   Sendmail   Linux PPP Server   Linux/Unix Emulator   LILO Concerns   Crypt   Apache 1.2.1   PPP and Internet MCI   Enabling Automounter on a Linux Notebook   XLocks Monitor   Pop3d That Doesn't Use /etc/passwd   Configuration of Two Ethernet Cards   Attaching a Colsole to a PC               Linux Control Panel        To:  ggonzale@ix.netcom.com    I have recently installed RedHat Linux ver 4.2 on my pc . My problem is that I cannot get the control-panel to work when I run startx or XDM . The panel comes up but I am unable to activiate any buttons in control-panel . I don't know what I did wrong or what to check ! Please help...           Are you running it as root?  Are there any interesting error messages in /var/log/messages?  Are there any interesteing error messages back on the text  console from which you ran ""startx"" (you can switch out  of XFree86 with {Ctrl}+{Alt}+{Fx} -- where {Fx} is the   function key that corresponds to any of you other virtual  consoles).  Are you sure you installed the Python and  related libraries (last I heard all of the Red Hat GUI  control panel stuff is written in Python).    As I've said several times -- I'm not a Red Hat specialist  (although that is what I'm running here at the moment) and  I barely use X (since I vastly prefer old fashion text mode).    Have they ever gotten a support line running that can   answer questions that are specific to their code?  (Hey!  I wouldn't even object to a paid support line -- if it   was good).      Thank you for responding to my question I will look into the areas you suggested . However I have one other question that is how would I activate my modem from a Linux command line? I thought I needed the xwindow to do that in the first place.            One of the virtues of Unix is that you don't need X Windows  to do anything except run X applications -- there are other  ways to access graphics (SVGALib, MGR) use your mouse (GPM)  do cut and paste (GPM/select, 'screen'), provide task/session  switching (virtual consoles, and 'screen'), do screen management  ('splitvt', emacs) etc.    In answer to your question regarding modems:   There are a number of programs that are included with the   typical Linux distribution that may use your modem:       pppd is the PPP daemon -- it usually uses the 'chat'    command to talk to the modem.     minicom is a vaguely Telix like ncurses terminal emulation   package (Telix is a popular shareware MS-DOS program).     It provides a fullscreen, color interface.     'cu' is a ""call utility"" usually associated with UUCP.   It uses the UUCP configuration files for information    about your modem -- if you have those configured.  It's   a very limited communications package -- that's only   virtue is that it is small.     UUCP is a suite of programs -- of which the uucico   program actually talks to the modem.  You almost certainly   are not planning on using this.  However UUCP was (and   still is) used as a mail, file, and netnews transport   protocol for years before TCP/IP existed.  I still use it   for my mail.     C-Kermit is a communications package from Columbia    University.  You can fetch it freely -- but it can't be   included with Linux (or other) CD-ROM collections of    software due to it's licensing model.  If you decide you    like it you should buy a copy of the C-Kermit book by   Frank da Cruz (the program's principal architect and    head of the project since it's foundation).     C-Kermit is also a scripting language and can be used   as a telnet or rlogin client, and Kermit is a file   transfer protocol which can be used by C-Kermit over    any communications channel that it can establish.  I    wrote an article for SysAdmin Magazine on the subject   just a couple of months ago.     There are other program that access your modem if    you want to use them, There's a SLIP package which   usually controls the modem via 'dip' -- there's    a variety of different ""getty"" implementations which   ""Get a tty"" (terminal) so that you can log in from a    terminal, or another system running a terminal package.     I use mgetty which not only allows incoming dial-up   data connections but adds support for FAX and even   voice/DTMF with some modems.  That package also includes   ""sendfax"" -- a program for outgoing faxes. efax is    another package for support FAXes under Linux.    Judging  from your earlier    question regarding the  Red  Hat  Control   Panel  I suspect  that   you're  just interested  in  configuring   your system  for  PPP  access  to  your Internet  service provider (ISP).  There is a script floating around (on  http://sunsite.unc.edu somewhere)  called 'pppsetup'.  I think  this will allow  you to setup   your PPP configuration  from a  text  console  (I used  plain    old 'vi'  and  made  my   own  configuration files -- so I've  never used this -- though I've  seen it recommended many times).    There are several HOW-TO's on configuring PPP (and SLIP) which  can be found at  http://sunsite.unc.edu/LDP/HOWTO  Look for the  ones that refer to ""PPP"" and ""ISP.""    Hope all of that helps.    -- Jim               Linux Command Line Arguments        From: Ronald B. Simon  ronald.b.simon@boeing.com    Where can I find a list of the linux boot command line arguments? e-mail addresses:           Look in the following HOW-TO document:    BootPrompt HOWTO  http://sunsite.unc.edu/LDP/HOWTO/BootPrompt-HOWTO.html     -- Jim              More Random Crashes         Date: Fri, 01 Aug 1997 14:40:06 -0700  From: sloth  sloth7@hotmail.com    Hi, I wrote to you a while ago with a problem regarding random crashes  while installing Linux... I recently tried again, with exactly the same  hardware but a different hard disk and the whole thing worked fine.  unfortunately, the hdd i used was only and 80mb conner :). The hard disk  i want to use is a 2.1 gb Quantum Fireball. When I try on this hard disk  the computer locks up at a different place each time during the  installation ( but only when it is decompressing the files). I have an  IDE Hard disk controller.   h/w list:    Intel Pentium 150 CPU  Intel Triton VX m/b  S3 Virge 3d graphics card  16mb EDO RAM  2.1gb Quantum Fireball  onboard (ide) hdd controller  24x IDE CDROM    any help would be much appreciated.  cheers, sloth...           This new information about your situation suggests two  possibilities:     1) Your HD is bad -- possibly it has some bad    sectors that the drive electronics haven't    mapped out, or possibly it's something more     subtle.     2) Your controller (IDE) is incompatible with your    HD and/or the combination of your HD and CD drive.         Some notes:    Any IDE drive that's over 540Mb requires an EIDE (enhanced IDE)  controller/BIOS.  There have been cases where specific IDE   devices weren't compatible with one another -- where a particular  combination of devices couldn't share the same IDE channel.    So, try getting a new EIDE controller and disabling the   interface on the motherboard (or configuring the new on as  a ""secondary"" IDE channel.  Try running  the two devices on the  new EIDE controller if you can get it installed as the primary  (but don't blindly trust the motherboard documentation -- I've  heard that some of the ""disable me"" settings on some boards just  don't work). Then try running the CD-ROM drive and the hard disk  on separate channels (controllers).    If you can get a copy of Spinrite or the Norton Utilities for   DOS then you might install a small DOS partition and run that on  your Fireball.  It might be able to map out any bad sectors.    If you get a new controller (which will be less expensive then   buying either of the software packages I just mentioned) I'd   try a a QuickPath Portfolio or a GSI brand multi-funtion card with   4 high speed (16550 UART) serial ports.  The QuickPath is an ISA  card (rather than taking up one of your PCI slots for a set of   relatively slow interfaces) and is what I'm using in a couple of   my machines here.  It combines floppy, four serial, two parallel,   two IDE channels and a game port (for 13 devices in all).    Hope that helps.  Unfortunately the diversity and cheapness  of PC hardware results in a diversity of inexplicable   incompatibilities and a common ""cheapness"" in quality that's  imposed by the competition.  So, as much as I hate to recommend  ""black magic"" experiments in new hardware -- it's frequently the  most effective approach.   -- Jim             More on Disk Defrag         Date: Mon, 4 Aug 1997 20:27:11 +0200  From: Markus Enzenberger  Markus.Enzenberger@physik.uni-muenchen.de    ...them in any Linux books that I have consulted. Is disk degragmentation not needed in maintaining a Linux file system?          No, disk fragmentaion is a particular problem of the DOS FAT file system and its descendants. You can see the fragmentation status of one your partitions by running the e2fsck file system check program as root  on an unmounted partition. It is run every boot time too. It will report  the amount of non-contiguous files.   - Markus            X-Windows is Crashing         Date: Sun, 13 Jul 1997 19:34:12 -0700  From: Gerramie Dinsel gerr@weaveworld.unix.net      Hello. I am searching all over for an answer or a pointer to this problem:   I upgraded my memory from 18 megs to 48. Now, X-Windows crashes on me when I load FVWM2.. Odd, because XDM loads fine and will sit there, waiting, without crashing for as long as you want. Also, console mode works wonderfully...   Can you offer any help? Gerramie Dinsel             The first guess might be that the new memory is bad --  and that you normal (console) usage -- and the overhead of   xdm just doesn't ""land"" on the bad chips.    One way to test this would be to do something from  console mode that will use *a lot* of memory.  make's  -j switch (to parallelize as many gcc processes as   memory allows) is a good way to test for this sort  of thing.  Just make a new kernel (no need to even to  an install of it -- just the make is fine).    If that runs O.K. than we have linked the problem   X -- possibly to any graphical use of the card beyond  xdm's.  So we try to run X with no window manager and  a minimal configuration file (no setting of special   root images like xli, xloadimage, or xsetroot, no   -16bpp or any of that).      It could be that your video card uses a region of   address space (a video frame buffer).  Look carefully  in the configuration settings, or call the manufacturer's  tech support.  That's the most likely problem.    If you have access to another, simpler video card -- try swapping  it in and seeing if that helps.  If it does than you need to  reconfigure that video card or use one that's better behaved.    If that doesn't help then it's just anyone's guess what's  happening.  Try rearranging the adapters in your card cage -- it  may be that the video card is emanating some noise or crosstalk  that's affecting your RAM.  Re-arranging adapters used to be  a time honored sport among PC technicians.  I think it's more  rare in the PCI era -- but you don't even mention what sort of  bus your using -- and I have no information about your hardware.  Besides -- it can't hurt.    If it still doesn't work try switching to 32Mb.  This might   be some weird chipset bug on your amount of RAM.  More systems  work with 16 or 32Mb of RAM than with 24 or 48Mb.    There are a plethora of parameters you can pass to the   kernel for excluding specific memory address ranges from   its use.  They might help -- but I'd hate to have to experiment  with them.    -- Jim              Lynx and Frames         Date: Tue, 05 Aug 1997 02:48:26 -0700  From: Scott  omegam@COMMUNIQUE.NET    Hey Jim,    Caught this quote in your article:    (Warning for Lynx users -- both of these sites use frames and   neither bothers to put real content in  the ""noframes"" section -- Yech!)     Current versions of lynx support frames and tables in a fairly nice and elegant fashion.  They even handle cookies.    Check out  http://lynx.browser.org    Just thought you should know.  Sure, I use Netscape for some of my browsing and I hope to begin using Mnemonic soon.  But for really fast, heavy-content oriented browsing, lynx on the console or in a color-xterm does the trick.   Scott           Oh,  I  know that  Lynx  2.7.1  can  handle frames, by  simply  showing you  a list of  the available frames as   a set of hot  points at the top of the rendered page.  I use Lynx for almost  all of my web browsing.    The problem is that the HTML  editors used by many sites don't  put   meaningful names on the   frames so you  get  a list of:  frame01.html,  frame02.html,  etc.  instead of something like:  navigation.html, main.html, toolbar.html etc.    It's  as irritating as those  sites that use large tableaus of  image  icons with no  Alt="""" attributes or imagemaps that with  no sane information in  the .map file.  (The current Lynx  can  also handle most types of image maps.     -- Jim             More on ftpd         Date: Tue, 05 Aug 1997 01:59:18 -0700  From: Benjamin Peikes  benp@npsa.com    Jim,    I am currently trying to set up some user accounts on our webserver so that other people working on their sites can ftp their files up and down easily. I am using wu.ftpd and have set up the line   guestgroup ftponly   in /etc/ftpaccess. I have also added the group into /etc/group and added the users name to the group.  The problems is that everything seems to work correctly except that ls and dir return nothing during an ftp session.    ftpd chroot's to the correct directory.  ftpd changes to the correct home directory.  you can upload and download files without any problems if you know  the name of the files you want.  I have made the directories world rwx just to make sure it wasn't  a permissions problem.    I'm so close that it's driving me nuts. The main problem arises when people need to transfer entire directories. Most of them are using GUI driven ftp clients and the lack of directory listings kill those clients. I know there must be a simple solution. Any help would be great.   Ben            You're probably having problems with the shared libraries  or devices that are typically required by the ls command.  Some version of ls require that you have a /dev/null and/or  a /dev/tcp in order to work properly.  Most versions of ls  require some shared libraries and all of them require the  existence of some of /etc/passwd and /etc/group files (even   with completely fictional data in them) in order to resolve   UID numbers into symbolic ownership information to display in   long listings.    For real information about setting up wu-ftpd on any platform  look at the following resources:    http://www.landfield.com/wu-ftpd/    http://www.cetis.hvu.nl/~koos/we-ftpd-faq.html    (Or,  send mail  with subject of ""send faq"" no quotes, body ignored).    ... and information about the guestgroups feature in particular  can be found at:    http://www.landfield.com/wu-rtpd/guest-howto.html     ... or   ftp://ftp/fni/com/pub/wu-ftpd/guest-howto     A document describing virtual ftp servers:   http://www.westnet.com/providers/multi-wu-ftpd.txt     Ftpaccess on virtual ftp servers  ftp://ftp.meme.com/pub/software/wu-ftpd-2.4.2/README.ALT.FTPACCESS    Hope that covers it.   --  Jim                DNS Problem         Date: Mon, 04 Aug 1997 18:31:36 -0700  From: Dr Ceezaer  ceezaer@cyberspace.org    (Ping doesn't work -- but /etc/resolv.conf and /etc/hosts.conf are correct and nslookup works).    It used to work before I upgraded my library files (/lib and /usr/lib) so I don't think there is an error in /et/resolv.cfg   Well... I've solved the problem. First I re-installed Linux on a small 120 MB harddisk. By comparing all relevant directories I found that I had a file called libc.so.5 (no symlink) in /usr/X11R6/lib plus the normal one in /lib. By removing the file /usr/X11R6/lib/libc.so.5 it all works again :)            Ahh the mysteries of the shared libraries.  I've always   wondered how the dynamic loading code searches for these .so   (shared object) files.  However I've never wondered enough to  leave stray copies of them laying around.     Well... I would need such a HOWTO, I didn't even got chroot to run...            The only real trick is to do a 'cd' before trying to execute  the command -- otherwise your process is very confused becuase   it can't access its current working directory (cwd).    The other problem is that your target program must be  contained in the chroot tree with any shared libraries  and usually it will need a set of /etc/ files including the  termcap and maybe a set of /usr/lib/terminfo files.    -- Jim             Sendmail         Date:Sun, 10 aug 1997 14:4457 -0700  From: Stephen P. Smith  ssmith1@vilma.bcasd.az.honeywell.com    When I send mail (using the mail program) to someone my reply to address is wrong. What sendmail is sending is account@computername.isp.com What I want is popaccount@isp.com What do I need to change to fix this   Stephen Smith            You use the ""masquerade"" feature in your local sendmail  configuration.  I recommend that you use the m4 macro  package to reate a new sendmail configuration.    First copy the old configuration. I like to use RCS --  the revision control system to track changes to my   configuration files.  Here's how you'd do that:    (As root)    # cd /etc   # mkdir RCS      (unless you already have one)   # ci sendmail.cf     (checks the cf file into the RCS directory)   # co -l sendmail.cf    (checks it back out, locked for editing)     Now you want to create a sendmail ""mc"" file.  This is a file  that uses sendmail specific macros -- which is then processed  by the m4 program to generate the full sendmail.cf.  A typical  sendmail.cf is over a 1000 lines long -- a typical ""mc"" file  is less than 20.    Under my Red Hat installation the sample ""mc"" files are located  in /usr/lib/sendmail-cf/cf/.  You can put yours there, or  you might use /usr/local/lib/sendmail (and perhaps add a symlink  under the other path).  This helps maintain the separation between  your local changes and the distribution's files ""as shipped.""    I name my ""mc"" files after my hostnames -- so mine is ""antares.mc.""  It looks like this:  divert(-1) include(`../m4/cf.m4') VERSIONID(`@(#)antares.uucp.mc .9 (JTD) 8/11/95') OSTYPE(`linux')  FEATURE(nodns) FEATURE(nocanonify) FEATURE(mailertable) FEATURE(local_procmail) FEATURE(allmasquerade) FEATURE(always_add_domain) FEATURE(masquerade_envelope)  MAILER(local) MAILER(smtp) MAILER(uucp)  MASQUERADE_AS(starshine.org) SITECONFIG(uucp.antares, starshine.org, U)  define(`UUCP_RELAY', a2i) define(`UUCPNAME', starshine) define(`UUCPNODES', a2i) define(`RELAY_HOST', a2i) define(`RELAY_MAILER',uucp) define(`SMART_HOST', uucp-dom:mailer) define(`PSEUDONYMS', starshine|antares|antares.starshine.org|starshine.org) undefine(`BITNET_RELAY')      I've seen some of these that end each line with a 'dnl' --  which is a macro to ""do newline"" -- I don't bother with that.    You'll want to ignore all the UUCP references and my   SITECONFIG line (mine is also a UUCP reference -- so yours  will be different -- preserve whatever is in the samples that  mathc your current configuration).    What your interested in here is the various ""masquerade"" lines.  Now you'd just 'cd' to the directory where you've created this  ""mc"" file and issue a command like:     m4 < $MYFILE > /etc/sendmail.cf     (where you replace $MYFILE with whatever you named your ""mc""  file, of course).    It's also possible to to simply add a line like:   DMisp.com     ... directly to your /etc/sendmail.cf.  DM ""defines masquerading"" to be for ""isp.com"" (from your  earlier example).  This is easier, on the one hand --  but learning the m4 configuration method will serve you   well if you ever have to do upgrades to your sendmail --  and it's a valuable skill if you ever have to administer  Unix systems as (or as part of) your work.    There are a variety of HOWTO's on configuring your mail  to work well with your ISP.  I don't have my PPP connection  up at the moment -- but you should search the SSC web site  (http://www.ssc.com) for the the HOWTO archive and look for  the strings ""ISP"" and ""mail.""   -- Jim            Linux PPP Server         Date: Sun, 10 Aug 1997 05:34:45 -0700  From:  sengir@ozemail.com.au      I have a Linux PPP server but I can not get my Windows95 client to do the ""automatic"" login. Sure, I can get it all to work if I check ""bring up terminal window after connecting"".    All I have is the login: prompt, followed by the Password: prompt then right into PPP.     What gives ?   TIA   -Rob            Here's a URL that talks about getting Linux   mgetty to work with Microsoft's infamous ""AutoPPP"":   ISP Resources - mgetty info(AutoPPP)     For more general information about mgetty look at:  Mgetty + Sendfax Documentation Centre    -- Jim              Linux/Unix Emulator         Date: Sun, 10 Aug 1997 05:30:18 -0700  From: Jun Liu  stefan@public.sta.net.cn    Hi, Dear James,   First I'd like express my gratitude for your great work on the Linux Gazette. But for the Linux/Unix Emulator, I think you're somehow wrong. Actually there do exist at least one such product as far as I know. When I was staying in Japan, I've learned there're quite some people there use a software called BOW (namely BSD on Windows ), which is a BSD emulator for Windows. Check out  http://www.ascii.co.jp/superascii/bow  if you do know Japanese.  In short, this is a BSD kernel emulator for 4.4BSD-Lite based BSD Unix program. It's said most BSD binaries (x86 certainly,character mode applications only, no X, no debuggers like gdb) can be run unmodified.            Actually, there has been quite a bit of work on supporting  Unix under NT.  Cygnus Support (http://www.cygnus.com) has  made quite a bit of progress with their    GNU-Win32 Project     A couple of other sources worth noting are:   OpenNT 2.0 Server Data Sheet    UNIX to NT Resource Center     There was also a paper presented at the Anaheim USENIX  conference this year:             Title: Porting UNIX to Windows NT          Author: David G. Korn   Pages: 43-57   Publisher: USENIX   Proceedings: 1997 Annual Technical Conference   Date: January 6-10, 1997   Location: Anaheim, CA   Institution: AT&T Labs-Research      The advantages are, you have the rich development environment from Unix, and the nice( ? ) UI from Windows as well as lots of Windows applications around all at the same time. It's said BOW Version 1.5 which is Windows95 compatible, is already published last year in May as a book and available in Japanese bookstores, priced at 9,800 yen with one floppy disk and one CD-ROM.   Hope this can be helpful.  Best regards.  Stefan            Again, in the article to which you refer I was asking  what the original person was asking for.  Many Unix packages  have been ported to NT, Windows '95, and DOS (emacs, perl,  awk, most of the simple commands like grep, cp, find, and   a couple of shells: Korn, bash) -- and it would certainly be  possible to host some binaries under (ELF, iBCS).      At what point to NT become Unix?     -- Jim             LILO Concerns         Date: Sun, 10 Aug 1997 03:50:35 -0700  From: Tibs  tjf1@acpub.duke.edu    I have been looking all over for an answer to my linux question...nobody  seems able to help so I thought I'd ask you (liked the LG web stuff very  much).  I am about to take the plunge and install linux but I am  concerned about how LILO will work on my system.  I have two IDE drives  on my system.  The first is 1 gig and I have DOS, Win95, etc. on it and  that's what I boot to.  The second is divided into two 1.5 gig  partitions, and 1 500 meg partition.  I planned on putting linux on that  last 500 meg partition.              First:  you'll want to learn how to use paragraphs.  Break your question down into short steps so we can   read it (particularly when we're doing the reading at  3:30 in the morning after hacking all day)     ....   The problem is that in order for my computer to  recognize the full 3.5 gig capacity of the second hard drive, the hard  drive installation floppy (it's a Maxtor) installed something called  EZ-BIOS.  So booting to DOS or Win95 now works and my BIOS recognizes all  3.5 gigs of the space.  When I boot to a floppy I have to use the EZ-BIOS  ""boot to a:"" option otherwise I can only access the first partition on  the second drive.  So when I install linux and add LILO, will LILO start  doing stuff after the EZ-BIOS stuff loads?  If so then it is not a  problem but if LILO starts before EZ-BIOS does it's thing, then I don't  think I'll be able to access my 500 meg partition.  And since that's  wherelinux would be, that would be a bit of a problem.            You're using an alternative master boot program which   will be incompatible with any other boot software.     You should use LOADLIN and forget all about LILO.    I've written about LOADLIN several times in this column --  so please look back through some of the pack issues for details.    So I guess my question would be: 1. do you know anything about this EZ-BIOS stuff and it's compatibility  with linux (the Maxtor people aren't helping with linux questions)            The EZ-BIOS and the old Ontrack Disk Manager and similar  drivers were originally created to allow DOS to see larger  partitions (which they did by hooking into the BIOS Int 13H  disk access routines before DOS was loaded -- by replacing the  MBR).  They have always been a bad idea.    Now that DOS supports partitions larger than 32Mb these  programs have a different purpose -- to allow older   systems to see IDE drives that are larger than 512Mb.  The BIOS interface only supports a maximum of 1024 cylinders  of up to 64 sectors each.  A typical drive is less than 16 heads.  This ""geometry"" gives a maximum of about 528Mb.  It's possible  to ""lie"" to some BIOS' and double the number of heads -- or  even go up do 255 ""virtual heads"" -- the drive electronics will  simply translate for you.     Essentially this is how SCSI and EIDE drives give you access to  larger disks (up to about 9Gb).    Your other alternative is to get an EIDE controller and get  rid of the non-standard software (sofware which isn't supported   under OS that I know of, Linux, any Unix, FreeBSD, NT,  OS/2 or anything other than DOS).     2.  is there some workaround that would still let me use linux if EZ-BIOS  would be a problem (like using a boot floppy everytime I wanted to use  linux, or something like that)           You can probably just use LOADLIN.  However you might have to   cook up some weird boot time parameters (you can store them  in the bathc file that invokes LOADLIN) to tell the kernel what  the drive geometry really is -- so it doesn't step on anything.    Here are the two HOWTO documents you want to read:   Large Disk mini-HOWTO    Loadlin+Win95 mini-HOWTO     -- Jim             Crypt         Date: Fri, 08 Aug 1997 20:47:11 -0700  From: David Saccon,  dasac@speed.it       Hi; I'm a Linux enthusiast bla bla bla, compliments for the  good work, etc etc.            Well,  charmed I'm sure!      I don't know if an e-mail to this address is the right way to  ask you a question.            It isn't really -- but most of the readers of Linux  Gazette's ""The Answer Guy"" column haven't see the ""tag@""  address that I currently prefer.    Please feel free to get rid of this mail if it bugs you. Anyway, my question is: where can I find an implementation of  the fine tool ""crypt"" for Linux ? You know, ""crypt <myfile >myfile.x password"", and back to the  clear text the same way.            I'm not sure that the traditional Unix 'crypt' command is  all that ""fine.""  I'd suggest that you obtain a copy of  PGP from one of the international sites that carry it.    (Please don't obtain it from any of my ""free"" fellow   U.S. citizens -- since it would be illegal for them to   exercise this particular form of free speech at this time.  I'd like to apologize for the ludicrous attitude my government  takes with regards to cryptographic software -- feel free to   refer to the ""Electronic Freedom Frontier"" (http://www.eff.org)  for more information about that).     I haunted the internet for days but couldn't find it. I also tried something like this:   include ""stdio.h"" include ""unistd.h"" void main(int argc, char ** argv )  { puts(crypt(argv[1], argv[2])) }   but it doesn't work the same way.   Help!  Thank you  Davide Saccon            There is a library function named ""crypt"" which is technically  a ""hash"" rather than a cryptographic function -- it's used to   compute the hash of a password for comparison to that which is  stored in the second field each entry in the /etc/passwd file.    I've heard that the program named 'crypt' varies from one Unix   implementation to another.  I think its currently not included  in many Linux distributions to the export (U.S. ITAR and related)  restrictions to which I alluded earlier.  Since many of the   companies that produce these distributions are U.S. they would  have to ensure that their products were for ""domestic use"" only  if they were to include this on their CD's and in their FTP sites.    Here are a few sites I picked off of Yahoo!    International PGP FAQ   Guida Pratica a PGP  Guida Pratica a PGP  PGP User's Guide (in Italian -- 250K)   The Crypto Chamber -- Italian   Cryptographer's WorkBench .    There are other strong cryptographic products available   internationally for other purposes.  I think the new Linux  ""TCFS"" (transparent cryptographic filesystem) is being done  in Italy.  TCFS is apparently similar to Matt Blaze's research  on CFS -- it allows a Linux admin to create filesystems that   are encrypted in such a away that users can have confidence that  no other user access their files.  Given its design is should be  difficult even for the root user to compromise the cryptographic  integrity of any local user -- and it should be impractical for   remote systems.    Here's some more links for that:   Transparent Cryptographic File System Project Page    TCFS    TCFA FAQ v1.7.7     Come to think of it STEL (a secure telnet) was also done in  Italy.  Seems that a lot of work on cryptography is coming out  of your country.  Obviously your government hasn't been   interferring in this work.  If you'd like to look at the sources  for STEL I'd FTP over to ftp://idea.sec.dsi.unimi.it/cert-it/    Another set of useful cryptographic resources are in Eric A.   Young's free implementation of Netscape's SSL (secure sockets   layer) specification and a set of related applications   (like ssltelnet and sslftp):    SSLeay: SSLeay and SSLapps FAQ  SSLeay: SSLeayand SSLapps FAQ     (This set of pages is an excellent resource for anyone that  wants to learn anything about SSL).    Eric's work was instrumental in the development of the  Stronghold web server by C2 Software Inc. (http://www.c2.net)  (I recently published an interview with C2's founder, Sameer  Parekh, in Linux Journal, if your interested).    And, of course, no discussion of Internet cryptography tools  would be complete without a mention of Tatu Ylongen's SSH   ssh (Secure Shell)   ssh FAQ    -- Jim             Apache 1.2.1         Date: Mon, 11 Aug 1997 13:53:14 -0700  From: Alf Stockton  stockton@acenet.co.za     I am playing with Apache 1.2.1 and have it running well except that it won't run cgi scripts.  If I give the full path in the command line of the browser the CGIs run fine but the server cannot/does not run these CGIs when I expect it to. Where can I turn for help? The Apache team don't appear too interested. I suspect that one of my config files is wrong but don't know enough to tell which.            I wouldn't necessarily say that the Apache team isn't   ""interested.""  However, they far more interested in   providing the software than in answering questions about   it.    It sounds like you don't have your ""ScriptAlias"" set up  correctly -- or you're trying to access a CGI script that  isn't stored in one of the proper ""ScriptAlias"" directories.    Here are links to the relevant documentation pages at the   Apache site (http://www.apache.org):       Apache: Configuration: ScriptAlias   http://www.apache.org/docs/mod/mod_alias.html#scriptalias      Apache: FAQ: How do I enable CGI execution in directories   other than the ScriptAlias?   http://www.apache.org/docs/misc/FAQ.html#CGIoutsideScriptAlias     Another possibility is that you have built it with no CGI  support.  Apache has many compile-time configuration options  -- include a large list of ""modules"" that can ben enabled or  disabled.  However I'm sure that it would take some work to  build Apache with no CGI support -- so I think this possibility  is remote.    -- Jim             Red Hat Questions         From: Brent Johnson  brent@saturn.msstate.edu      So are you the answer guy and can you answer a very important question for me?           I appear to have been dubbed ""The Answer Guy"" (it wasn't  a self-appointment -- but I did volunteer for it).    I can certainly answer any question.  Answering it correctly  and usefully are not as sure a bet -- but I'll try.      I first heard about RedHat's Linux distribution about a year ago and there was no way Slackware could compete to the easy installation procedure, RPMS, and other great features included in RedHat.   But, ever since I moved to RedHat Ive had a terrible gcc compiler problem. This has happened to me on two different machines... on the first Id assumed it was some memory problem (as in hardware), but now Im on a totally different machine that has (or shouldnt have) any memory problem.   Everytime I try and compile anything (Apache 1.2.1 for example)... it gets to about the 3rd or 4th .c file, and it bombs out with the following error:   gcc -c -Iregex  -O2 -DLINUX=2   util_date.c gcc -c -Iregex  -O2 -DLINUX=2   util_snprintf.c gcc: Internal compiler error: program cc1 got fatal signal 11 make: *** [util_snprintf.o] Error 1    It happens at different times on different .c files when compiling different things.  Any help would be greatly appreciated... a Unix system with a defective compiler or defective hardware is almost useless!   - Brent           I notice that you haven't told me *which version* of Red Hat  you're working with.  However I've used 3.03, 4.0, 4.1, and  4.2 -- and I think I remember playing with an earlier one before  3.03 and I never saw this behavior from gcc.    I did get it from my original copy of minicom anytime I was  running in an extended video mode and trying to use the   dialer (and not when issuing the same dialing function as  a direct ATDT command from the terminal window).  In this  case I suspect there was a bug in the ncurses calls being   made by minicom.  In any event I switched to CKermit and   forgot all about it.    In your case the signal 11 (SEGV) is probably not caused  by curses/ncurses calls.    Do you have a swap partition or file?  If so, have you tried   disabling it (possibly creating a new one temporarily)?  If   you have a defect on the disk you could get a SEGV from some  piece of data/code that gets swapped out, read back in  (with errors) and subsequently used by the running process.    If you don't have a swap partition or file you might just be  running out of RAM completely.  gcc does use up quite a bit  of memory -- so I'd suggest at least 32Mb virtual memory   (RAM + swap) available when running it (you could certainly  ask the FSF for more specific recommendations -- this is   just my unsubstantiated and untested suggestion).    When you installed, did you let Red Hat's install routine  perform thorough block checking while it was making filesystems?  If not, try re-installing and enabling that (in case you hit  some bad spots on your disk and you have corrupted gcc   binaries).    This is extremely unlikely to be related to your distribution,  but you could try installing Slackware to see if its gcc  works on this system -- or you could try booting up in   single user mode and just run a few test ""make's"" from   a simple shell line (no emacs M-x shell mode, no X Windows,  no ""integrated dev. environment"" nothing else running).    If you still get SEGV's then, you want to find some other  sort of memory intensive program to run as a test -- to see  what else will die.  It may be worth extracting the RAM and  taking it to a good hardware tester -- and/or removing any  ethernet cards or unecessary adapters for other tests.    These sorts of things can be very frustrating to track down  regardless of OS.  If you have a copy of DOS and an old copy  of Norton Utilities (version 8 or later) you could boot that  up and run NDIAGS.EXE.  There are several other diagnostics  packages that were available before it -- but NU is still my  personal favorite untill the Linux crowd does up a suite of  them.  Unfortunately the results of any software diagnostics   package aren't definitive -- they can detect trouble -- but   they can't ""prove"" that there isn't any hardware problem.    I suppose, for some systems, particularly some 386's and  386SX's, you might also try twiddling the CMOS ""wait states""  settings.  Those used to make a difference -- particularly   with earlier generations of ""3-chip"" SIMM's.  Apparently   in the early attempts to use SIMM's with three chips  (two four bit chips and a parity bit chip) there were some  slight timing differences between the ""signal settling""   characteristics -- so the parity bit wouldn't ""settle""   before the system was trying to read the memory.  This resulted  in parity errors if the systems were set for ""zero wait states""  -- and was generally solved by changing the CMOS settings.    (I've never heard of a Pentium system or any system using  72-pin SIMM's having these problems -- but that doesn't   mean it's not worth looking in your ""advanced"" CMOS and   trying some experiments therein).    I hope some of this helps.   -- Jim             PPP and Internet MCI         From: Demosthenes  radams@capaccess.org  Subject: Re: PPP and InternetMCI     Hey there, I've been reading through your column from August in the Linux Gazette, and ran across the gentleman's question regarding GTE's internet services.   I'm trying to switch over to MCI from a local ISP, and I'm having some of the oddest connection problems. I use PAP currently with my local ISP, and MCI is supposed to use PAP/CHAP (one, the other, or both :P). I beleive i have everything setup properly, as I don't get any rejections from PAP/CHAP, but after a few seconds of modem activity with the server, MCI just hangs up. I did misspell something before, and got a PAP rejection, and I've got full debugging logs regarding the connection, but I can't make much sense of them. I know the server isn't asking for MS-CHAP (chap 80, vs chap 05). It looks like it dies during the configuration. I'm not sure.   Do you have any information regarding connecting to InternetMCI via Linux? MCI tech support is clueless, and I can't even get someone that knows how their own software works on the phone.   Any help would be highly appreciated, and I'd be more than glad to share my debugging logs if you think they will help.   Thanks again!   Russell Adams           My first impulse is to say ""vote with your feet.""  Fire off a polite, assertive, note to their VP of Customer  Service and go find a Linux/Unix friendly ISP with quality  tech support (and maybe spend a little more in the process).    My provider isn't the cheapest -- and isn't even the friendliest  -- but they understand Unix and they provide quality service   (refusing to structure their rates to ""compete"" with an   unreasonable ""quality of service"" -- i.e. I get few busy signals).    That bit of non-technical advice aside I'd ask:    What are your MTU and related parameters?    You could send the logging output -- but it would probably  be as incomprehensible to me as it is to you.  I've never  set up a PAP/CHAP system (yet).  However I'll look at them  and suggest some experiments.    -- Jim             Enabling Automounter on a Linux Notebook         From: Dennis Dai  gqdai@intergate.bc.ca      Hi, Jim   I think I need to ask you for help. My problem is:   Originally I have a 1.6G HD. Last month I bought a new one (3.2G) in order to accommodate linux and NT. I placed the swap partition in the very last part of the new harddisk (it seems that this is a bad idea, isn't it?) which is hdc8 and initialized it without problem. After a while, I made a new NTFS partition for NT which resides in front of the swap partition (I installed NT system on one of my original HD's partition which is hda7), then I moved some of my data on the new NTFS partition. But after I booted up to linux, I realized that the swap partition didn't initialized properly, so I issue a command like this:   mkswap /dev/hdc8    And this was how I screwed up things. Actually the new NTFS partition became hdc8, and the original swap partition became hdc9. Now I can't access the new NTFS partition from NT!    Immediately after I issued that command, I realized that I made a big mistake so I issued a ""free"" command and it showed that the swap partition (which is my NTFS partition) was not used.   So I think I still have hope to retrieve the data on my NTFS partition. I know they are still there, just I can't get them out.   I posted this to linux newsgroups, and received some kind response that suggested me to use linux fdisk to change the partition type to NT one. But I did check that, it is still NTFS (actually HPFS under linux fdisk). Others suggested me to zero out the first 512 byte of that partition as part of the recovery, but since I am not quite familiar with that I didn't dare to do that.    So I hope you can get me out of the hole. Thanks in advance.            Well, I haven't done regular data recovery for a few  years (since I left Symantec' Peter Norton Tech Support  Department).  It's not something that I can do via e-mail  (or for free) -- and I don't know diddly about the internals  of NTFS (or HPFS or ext2fs for that matter).    You best bet, of course, is to have recent backups from  which you can recover.  I don't know why they were suggesting  that you blast the boot record (the first 512 bytes of a   partition is the ""logical boot record"" or ""superblock"" while  the first 512 bytes of a drive is the ""master boot record""  or MBR).  Perhaps they believe that NT will be able to   recover from this.  If I was to do anything with the LBR  I'd go to a different machine, create a new NTFS partition  that was indentical in size and configuration to the one you  think you've damaged, and use a disk editor (or a Linux   dd command) to cut and paste that from the other machine onto  the allegedly damaged partition.    Before doing much of that I'd suggest do a dump to tape  of the entire raw device (using 'dd').  This may allow you  to return to the current state of brokenness after you've   made unsuccessful attempts at repair.    I don't recommend these procedures (disk surgery) unless  the data on that drive is very important to you (and otherwise  unreproducable) or you really like playing with hex editors.    If it's of considerable financial value to you -- I'd suggested  making a dump tape, extracting the drive from the system and   sending it to a data recovery specialist.    -- Jim              X Locks Monitor         From: Gord Urquhart  urquhart@Newbridge.COM    I have found when playing with my Xconfig I could get my monitor (MAG15) to go into power saving state (with a resulting black monitor) when I changed the pre and post sections of the horizontal scan line timings (I can't remember the proper names of these), to certain values.    gord u.            ... and? ...    You can also cause a monitor to permanently damage itself  if you play with those long (wrong) enough.  This is well   known and noted in the XFree86 configuration file.      So, what's the point of this message? Or is it just a   stray observation?    -- Jim              Pop3d That Doesn't Use /etc/passwd         From: Benjamin Peikes  benp@npsa.com     Do you know if there is a pop3d that does not use /etc/passwd? I want to set up mail only accounts for some people but in.pop3d that I have uses /etc/passwd. I want to set up accounts that sendmail knows how to deliver for but I don't want to put these people in /etc/passwd because then I have to worry about all the other services on the machine. Have you heard of some daemon that will do this, or a set of packages that will do this type of seperate user management? Thanks.   Ben            Ultimately this issue of restricting specific classes  of users to specific services on a system is goes   way beyond the particular services you pick.  PAM  (the pluggable authentication modules) is supposed  to solve this problem eventually.  That is already   included with recent versions of the RedHat distributions  (and with recent Solaris releases).  However it is   still evolving -- so few of us have any idea how to   ""do it right.""  (A fact which leads to an understandable  lack of confidence in recommending it).    So, getting back to the original question:       What POP daemon supports a user/password   database that's distinct from the one used   by other Unix services (/etc/passwd)?    I've heard the rumor that this can be done in qpopper  but I'd like to confirm that.  So I go to Yahoo! and  issue the ""+qpopper +account"" search and get:    There is:   http://www.hdshg.com/fixes/mail_patch/     ... which is supposed to be a patch to qpopper to   allow this.  However I couldn't connect to  and I   couldn't find any mirror of it even after several   hours of trying.    I traversed a number of links searching on strings  like ""+pop3 +passwd +passwd +separate"" and various  permuations.  This was the only firm reference I found.    Another approach would be to create a custom chroot  environment.  This isn't as hard as it sounds.  The  hard part is making your binary statically linked or  including the necessary libraries.  The other thing  you'll have to consider is whether you want the POP-only  accounts to use their own ""virtual mail host"" (requires  an IP alias or an additional interface) or whether you  your smtpd to run in the same chroot ""jail"" -- then   requiring any local account holders to also use   POP (perhaps using the fetchmail client to the   ""localhost"" target).    Here are some of the links that have more information  on mail and POP in general.     Harker's sendmail References Page   Mr. Harker gives seminars and classes in sendmail    Free Servers from Eudora: Servers   Qualcomm, publishers of Eudora, also are the source of qpopper.    POP/IMAP FAQ     Passwdd/Passwd -- An authentication Daemon/Client      This isn't mail related specfically -- but relates to   alternative authentication model -- a passwd daemon running  on a privileged TCP port via inetd.  It shows examples for  supporting Eudora/APOP and using alternate passwd files.    /pub/smtpd directory -- Similar to TIS FWTK smapd     Running a simpler, perhaps unprivileged smtpd to toss  incoming mail into the queue is considered to be a good  idea -- for isolating sendmail (which is large, powerful,  complex, and has a long history of compromises).   http://www.qmail.org  The qmail Page    An alternative to running sendmail at all.  I won't   get into this debate -- I'm just including it in this list  because I'll receive lots of unnecessary mail if I don't.    MH Message Handler Home Page     The Rand MH is a particular mail user agent -- actually a  set of programs for working with mail from a shell command  line.  There are several packages that provide full screen  interfaces to this -- including an emacs mode/package,   mh-e, which is what I use.    Scripts and Patches for ISP's    4th UNIX SECURITY SYMPOSIUM  -- Sendmail w/o Superuser     How to Get There From Here  -- Scaling e-mail to the enterprise    Linux: Server-Linux FAQ      I hope all of this helps.   -- Jim             Configuration of Two Ethernet Cards         From: Carlos Gonzalez Andrade  cglez@cfe.gob.mx  Date: Mon, 11 Aug 1997 23:40:16 -0700     Hi Jim.   I have a question about some problems i have while I was seting up  2 ether cards.   first . the device eth1 is not recognized when I add the line         append =  ether=0,0,eth1  into the lilo.conf.           You should consider putting the I/O base address, the   IRQ, and any DMA or memory address information into  this append clause in place of those zero's.    You can test these by entering them at the LILO prompt  (interactively, during boot) before editing the /etc/lilo.conf  file.      second . What files are necesary to set up to configure  two IP address for my machine and get runing my gateway?    I will apreciate your answer            This depends on which distribution you're using and  how closely you want to stick to their configuration   conventions.  Minimally all you need is a script file   (typically located under /etc/rc.d/ and invoked by the  rc.local) with calls to the 'ifconfig,' and a 'route add'  command or two.  Under Red Hat's SysV init system you'd   leave your rc.d files alone and edit some file under  your /etc/sysconfig/network-scripts/ directory (ifcfg-eth0,  and ifcfg-eth1 if I recall correctly -- it should be obvious  by browsing through those files).      -- Jim             Attaching a Console to a PC         To: Benjamin Peikes  benp@npsa.com  Date: Mon, 11 Aug 1997 23:14:37 -0700   Jim,   I'm not sure if you are the right person to ask but I figured you would be a good place to start. I have a handful of PC's that I need to be able to watch as they boot. What I would like to do is connect a dumb terminal(old laptop) to a rs-232 switch box and then be able to switch to any of the machines as I boot them.  I was wondering if you knew any way to do this. Thanks.    Ben Peikes          It is possible to use a serial terminal as a console  for Linux -- given some patches.  With some PC hardware  you'll have to leave the video card in their -- though   you don't need a monitor attached.    Unfortunately I don't remember where I saw these patches.  I'd so a search on ""+Linux +serial +console""  (using the  Yahoo! convention of preceding ""required"" terms with   ""plus"" signs).   -- Jim             Copyright © 1997, James T. Dennis    Published in Issue 21 of the Linux Gazette September 1997                          ""Linux Gazette... making Linux just a little more fun! ""                  CLUELESS at the Prompt: A new column for new users   by Mike List,  troll@net-link.net       Welcome to installment 7 of Clueless at the Prompt: a new column for new users.    Well it's starting to happen.My learning curve is starting to settle down, and if you have been following this column, yours is too, although depending on what you want from Linux, you may have many more questions. At this point you probably are feeling more comfortable using the online resources like the comp.os.linux.??? newsgroups and some of the Linux pages that are hanging out there for you to glean info from.  Some of my regular stops are:      Linux Users Support Team     Linuxnow.com     Walnut Creek ftp archive     Sunsite ftp archive          If you use a browser the first time you visit the ftp sites you can get a good feel for the directory breakdown, but if you want to download large files ie. distributions, you should use the command line ftp, in my experience, it's faster.  Speaking of the command line ftp program, here are a few tips that can make things go more quickly. You may already be familiar with some or all, but if not, just type ...  ftp [ftp.cdrom.com]  or whichever site you wish to visit. you will get a prompt to give a username, most commonly  anonymous , followed by one for a password usually your e-mail address.  If you have used a browser to check out these sites previously, you can  cd  to the desired directory.If not,  cd pub  usually is a good start.  ls  will show you whatis contained in that directory.If you are in a VC rather than an xterm, you can use the SHIFT+PageUp  keys to scroll back, sinceyou will get a screenful or more of filenames that will just shoot by.This may or may not work in an xterm.   If you want to download the files to a directory other than your current directory,  lcd [directoryname]   will direct the downloads to that location.  hash  will give you a display of #  marks, one for each block rerieved, usually 1024 bytes.You can use this to check the progress of your download.    bell  will send an audible signal when your file is finished downloading.   get [filename]  will start your download, mget  will retrieve everything in the current directory if you have an empty directory of the same name in your destination directory(the one you ""cd'ed"" to). You will be prompted for each  file  as the previous one finishes loading.  when you finish downloading, type  bye . That will close the connection.    Config, dot and .rc files    There are many ways that your linux programs can be altered to your liking, or just to make it work the way it should. Last time I gave an example of how to customize  FVWM , but it hardly scratched the surface of all the things that can be done to make your linux environment truly yours.    If you type:  ls -a , you'll see several files that start with "" . "". These are typically configurable files that among other things, create aliases for shell commands, set environment variables, geometry of X applications, and other similar functions.   Some of these ""dotfiles""have eluded my attempts to alter them in the ways I'd like, but others have been extremely compliant. Some of the no-gos (for me)  include  .bashrc and .bash.profile . I'm sure someone will e-mail me and tell me why my aliases don't work, even though I edited the file exactly as shown in the""Bible"". Others like the aforementioned  .fvwmrc  have had extemely gratifying results.Maybe my colleagues at  ""The Answer Guy""  and  ""The Weekend Mechanic""  can shed alittle more light on the subject. In the meantime, backup your dot files before altering them, by  cp 'ing them to, say .foo.old to keep serious problems at bay, should your editing fail to yield the desired results.  Some of the ""dot files"" you might want to take a look at  for possible tailoring (depending on what you have installed)include your .bash.profile, your .bashrc, or .rc files for any shell you might use, .xinitrc, your window manager's .rc file, browser .rc and .bookmark files.  If you have root privilege. there are many more you have access to but be careful - some files have their own ways of being altered for instance  crontabs -e  is the way to edit your crontab which has the capability of taking care of routine maintenance at off hours  upatedb  to create a database for the  find  and  locate  commands. Usually run in the wee hours of the morning, this could be configured to run at bootup or every 12 hours or at the end of a workday. This would assure that all of the current day's work would be easily located the next day.    The  /etc/ppp/ip-up and  ip-down  files can cause certain functions when a ppp connection is established. If you don't have one already, you can probably write one that will be noticed by the current software. The same goes for the  .bashrc  and  .bash_profile , with the above caveat in mind.   For the most part, the lines you need to enter or alter  will be essentially the same as you would use at the command line, and sometimes it will be as easy as removing the  #  from the beginning of the line.         Don't use a .bat!     One 'dot file that you can't edit to your liking, but could be useful just the same is  .bash_history . If you  cat .bash_history | sort>[filename]  then  less filename you will get an idea of what commands are used most often. You can then use this information to create shell scripts or aliases in your .bashrc or .bash.profile or other shell.rc files and save a few keystrokes.     Keep those e-mails coming in, but just so you know, I don't run linux on a new pentium with all the bells and whistles and I don't know much about stuff I haven't used, so I might not be able to help you much with tape drives, CDroms, SCSI peripherals and the like. I'll do my best to point you in the right direction,but I use a 486/66 box with IDE drives and a floppy(3.5""), a vga monitor, a cirruslogic 5428 videocard, internal modem, and an 8bit soundblaster card.I mention this, not to beg for new hardware (although...), but to give you some kind of idea what kind of hardware questions I might be of help with.   I invite questions, suggestions, reasonable criticism and just plain e-mail:  troll@net-link.net   See you next month!            Copyright © 1997, Mike List   Published in Issue 21 of the Linux Gazette, September 1997                              ""Linux Gazette... making Linux just a little more fun! ""                 A Non-Technical Look Inside the EXT2 File System   By Randy Appleton,  randy@euclid.nmu.edu        Introduction    Everyone wants a fast computer. However, not everyone realizes that one of the most important factors of computer performance is the speed of the file system. Regardless of how fast your CPU is, if the file system is slow then the whole computer will also seem slow. Many people with very fast Pentium Pro's but slow disk drives and slower networked file systems rediscover this fact daily.    Luckily, Linux has a very fast file system called the  Extended File System Version 2 (EXT2) . The EXT2 file system was created by Remy Card (card@masi.ibp.fr). This article will show you how the EXT2 file system is organized on disk and how it gets it's speed.    Disk Layout    Goals    There are several objectives when deciding how to lay data out upon a disk.     First and foremost, the data structure should be  recoverable . This means that if there is some error while writing data to the disk (like a silly user pulling the power cord) the entire file system is not lost. Although loosing the data currently being written is often acceptable, loosing all the data on the disk is not.     Secondly, the data structure must allow for an  efficent implementation  of all needed operations. The hardest operation to implement is normally the hard link. When using a hard link, there are more than one directory entry (more than one file name) that points to the same file data. Accessing the data by any of the valid file names should produce the same data.     Another hard operation involves deleting an open file. If some application has a file open for access, and a user deletes the file, the application should still be able to access the file's data. The data can be cleared off the disk only when the last application closes the file. This behavior is quite unlike DOS/Windows, where deleting a file means that applications who have already begun to access the file loose all further access. Applications that use this UNIX behavior concerning deleted files are more common than one might think, and changing it would break many applications.    Thirdly, a disk layout should minimize seek times by  clustering  data on disk. A drive needs more time to read two pieces of data that are widely seperated on the disk than the same sized pieces near each other. A good disk layout can minimize disk seek time (and maximize performance) by clustering related data close together. For example, parts of the same file should be close together on disk, and also near the directory containing the file's name.    Finally, the disk layout should  conserve disk space . Consurving disk space was more important in the past, when hard drives were small and expensive. These days, consurving disk space is not so important. However, one should not waste disk space unnecessarily.    Partitions    Partitions are the first level of disk layout. Each disk must have one or more partitions. The operating system pretends each partition is a seperate logical disk, even though they may share the same phyical disk. The most common use of partitioning is allow more than one file system to exist on the same physical disk, each in its own partition. Each partition has its own device file in the  /dev  directory (e.g.  /dev/hda1, /dev/hda2 , etc.). Every EXT2 file system occupies one partition, and fills the whole partition.    Groups    The EXT2 file system is divided into  groups , which are just sections of a partition. The division into groups is done when the file system is formatted, and cannot change without reformatting. Each group contains related data, and is the unit of clustering in the EXT2 file system. Each group contains a  superblock,  a  group descriptor , a  block bitmap , an  inode bitmap , an  inode table , and finally  data blocks , all in that order.    Superblock    Some information about a file system belongs to the file system as a whole, and not to any particular file or group. This information includes the total number of blocks within the file system, the time it was last checked for errors, and so on. Such information is stored in the  superblock .    The first superblock is the most important one, since that is the one read when the file system is mounted. The information in the superblock is so important that the file system cannot even be mounted without it. If there were to be a disk error while updating the superblock, the entire file system would be ruined. Therefore, a copy of the superblock is kept in each group. If the first superblock becomes corrupted, the redundent copies can be used to fix the error by using the command  e2fsck .    Group Descriptors and Bitmaps    The next block of each group is the  group descriptor . The group descriptor stores information on each group. Within each group descriptor is a pointer to the table of inodes (more on inodes in a moment) and  allocation bitmaps  for inodes and data blocks.     An allocation bitmap is simply a list of bits describing which blocks or inodes are in use. For example, data block number 123 is in use if bit number 123 in the data bitmap is set. Using the data and inode bitmaps, the file system can determine which blocks and inodes are in current use and which are available for future use.    Inodes and Such    Each file on disk is associated with exactly one  inode . The inode stores important information about the file including the create and modify times, the permissions on the file, and the owner of the file. Also stored is the type of file (regular file, directory, device file like / dev/ttyS1 , etc) and where the file is stored on disk.     The data in the file is not stored in the inode itself. Instead, the inode points to the location of the data on disk. There are fifteen pointers to data blocks within each inode. However, this does not mean that a file can only be fifteen blocks long. Instead, a file can be millions of blocks long, thanks to the indirect way that data pointers point to data.    The first thirteen pointers point directly to blocks containing file data. If the file is thirteen or fewer blocks long, then the file's data is pointed to directly by pointers within each inode, and can be accessed quickly. The fourteenth pointer is called the indirect pointer, and points to a block of pointers, each one of which points to data on the disk. The fifteenth pointer is called the doubly indirect pointer, and points at a block containing many pointers to blocks each of which points at data on the disk. Perhaps the picture below will make things clear.     Figure showing the pointers between an inode and it's associated data.    This scheme allows direct access to all the data of small files (files less than fourteen blocks long) and still allows for very large files with only a few extra accesses. As the table below shows, almost all files are actually quite small. Therefore, almost all files can be accessed quickly with this scheme.        File Size (bytes)    0-768    769-1.5K    1.5K - 3K    3K - 6K    6K-12K    12K and up        Occurence (%)    38.3    19.8    14.2    9.4    7.1    10.1        Cumulative (%)    38.3    58.1    72.3    81.7    89.8    99.9        Table showing occurence of various file sizes.    Inodes are stored in the inode table, which is at a location pointed to by the group descriptor within each group. The location and size of the inode table is set at format time, and cannot be changed without reformatting. This means that the maximum number of files in the file system is also fixed at format time. However, each time you format the file system you can set the maximum number of inodes with the  -i  option to  mke2fs .    Directorie>    No one would like a file system where files were accessed by inode number. Instead, people want to give textual names to files. Directories associate these textual names with the inode numbers used internally by the file system. Most people don't realize that directories are just files where the data is in a special directory format. In fact, on some older UNIXs you could run editors on the directories, just to see what they looked like internally (imagine running  vi /tmp ).     Each directory is a list of directory entries. Each directory entry associates one file name with one inode number, and consists of the inode number, the length of the file name, and the actual text of the file name.     The root directory is always stored in inode number two, so that the file system code can find it at mount time. Subdirectories are implemented by storing the name of the subdirectory in the name field, and the inode number of the subdirectory in the inode field. Hard links are implemented by storing the same inode number with more than one file name. Accessing the file by either name results in the same inode number, and therefore the same data.    The special directories ""."" and "".."" are implemented by storing the names ""."" and "".."" in the directory, and the inode number of the current and parent directories in the inode field. The only special treatment these two entries recieve is that they are automatically created when any new directory is made, and they cannot be deleted.    The File System in Action    The easiest way to understand the EXT2 file system is to watch it in action.    Accessing a file    To explain the EXT2 file system in action, we will need two things: a variable that holds directories named DIR, and a path name to look up. Some path names have many components (e.g.  /usr/X11/bin/Xrefresh ) and others do not (e.g. / vmlinuz ).    Assume that some process wants to open a file. Each process will have associated with it a current working directory. All file names that do not start with ""/"" are resolved relative to this current working directory and DIR starts at the current working directory. File names that start with ""/"" are resolved relative to the root directory (see  chroot  for the one exception), and DIR starts at the root directory.    Each directory name in the path to be resolved is looked up in DIR as it's turn comes. This lookup yields the inode number of the subdirectory we're interested in.    Next the inode of the subdirectory is accessed . The permissions are checked, and if you have access permissions, then this new directory becomes DIR. Each subdirectory in the path is treated the same way, until only the last component of the path remains.     When the last component of the pathname is reached, the variable DIR contains the directory that actually holds the file name we've been looking for. Looking in DIR tells us the inode number of the file. Accessing this final inode tells where the data for the file is stored. After checking permissions, you can access the data.    How many disk accesses were needed to access the data you wanted? A reasonable maximum is two per subdirectory (one to look up the name, the other to find the inode) and then two more for the actual file name itself. This effort is only done at file open time. After a file has been opened, subsequent accesses can use the inode's data without looking it up again. Further,  caching  eliminates many of the accesses needed to look up a file (more later).          Put the starting directory in DIR. Put the pathname in PATH. While (PATH has one than one component)     Take one component off PATH.     Find that component in DIR yielding the INODE.     If (permissions on INODE are not OK)         Return ERROR     Set DIR = INODE End-While Take the last component off PATH yielding FILENAME. Find FILENAME in DIR yielding INODE. If (permission on INODE are not OK)      Return ERROR Store INODE with the process for quick later lookup. Return SUCCESS.          Pseudo-code for opening a file.    Allocating New Data    When a new file or directory is created, the EXT2 file system must decide where to store the data. If the disk is mostly empty, then data can be stored almost anywhere. However, performance is maximized if the data is clustered with other related data to minimize seek times.    The EXT2 file system attempts to allocate each new directory in the group containing it's parent directory, on the theory that accesses to parent and children directories are likely to be closely related. The EXT2 file system also attempts to place files in the same group as their directory entries, because directory accesses often lead to file accesses. However, if the group is full, then the new file or new directory is placed in some other non-full group>    The data blocks needed to store directories and files can found by looking in the data allocation bitmap. Any needed space in the inode table can be found by looking in the inode allocation bitmap.    Caching    Like most file systems, the EXT2 system relies very heavily on caching. A  cache  is a part of RAM dedicated to holding file system data. The cache holds directory information, inode information, and actual file contents. Whenever an application (like a text editor or a compiler) tries to look up a file name or requests file data, the EXT2 system first checks the cache. If the answer can be found in the cache, then the request can be answered very quickly indeed without using the disk.     The cache is filled with data from old requests. Therefore, if you request data that you have never requested before, the data will not be in the cache, and must be retrieved from disk. Luckily, most of the time most people ask for data they have used before. These repeat requests are answered quickly from the cache, saving the disk drive much effort while providing the user quick access.    Of course, each computer has a limited amount of RAM available. Most of that RAM is used for other things like running applications, leaving perhaps 10% to 30% of total RAM available for the cache. When the cache becomes full, the oldest unused data (least recently used data) is thrown out. Only recently used data remains in the cache.     Since larger caches can hold more data, they also can satisfy a larger number of requests. The figure below shows a typical curve of the total cache size versus the percent of all requests that can be satisfied from the cache. As you can see, using more RAM for caching increase the number of requests answered from the cache, and therefore increase the apparent speed of the file system.     Figure #1: A typical curve of total cache   size vs. the number of requests satisfied from the cache.    Conclusion    It has been said that one should make things as simple as possible, but no simpler. The EXT2 file system is rather more complex than most people realize, but this complexity results in both the full set of UNIX operations working correctly, and good performance. The code is robust and well tested, and serves the Linux community well. We all owe a debt of thanks to M. Card.    Sources for More Information    The data for the figures in this paper can all be found in my dissertation  Improving File System Performance with Predictive Caching . See the URL   http://euclid.nmu.edu/~randy  .    An excellent paper with more technical detail can be found at  http://step.polymtl.ca/~ldd/ext2fs/ext2fs_toc.html  .    Some performance data can be found at  http://www.silkroad.com/linux-bm.html  .             Copyright © 1997, Randy Appleton   Published in Issue 21 of the Linux Gazette, September 1997                              ""Linux Gazette... making Linux just a little more fun! ""                 Fvwm Configuration in Different Environments using cpp   By Gerd Bavendiek,  bav@rw.sni.de       Do you use Linux at home ? In the office ? On a laptop ?  Do you use fvwm 2.xx or fvwm95 as your windowmanager ?   If yes, you should read on.          Perhaps you have read my article about  Using a     Laptop in Different Environments . There I described an    easy way to setup a Linux laptop to boot into different    network configurations. I mentioned that setting up a shell  variable called  PROFILE  is useful not only for  configuring the network but also the windowmanager.    Why should you do that ?   Your windowmanager needs to be configured quite different when you are using it on a laptop with 600x420 pixel or on a 17""-monitor with 1024x768 pixel. This is a rather basic difference - there may be others. Think of using your system in a network environment. There it will be handy to have a taskbar labeled appropiate to  rlogin -sessions.  After fiddling some time with patching different fvwm configuration files on different machines I found this to be a pain. A typical  .fvwm95rc  is about 900 lines. Keeping several of them in sync is not the thing I like.   Generating ~/.fvwm95rc using cpp   My solution is simple: Use  cpp , the C-preprocessor ! fvwm 2.xx as well as fvwm95 are configured by a central file.  fvwm95 is derived from fvwm, so the basic idea applies to both. Let me show you the details using fvwm95. I keep my fvwm95 configuration in the file  ~/.fvwm95rc-cpp .         You can use the system default setup in  /etc/X11/fvwm95/system.fvwm2rc95  as starting point.  Look at this code fragment from my  .xinitrc  (For me,  .xsession  is linked to  .xinitrc ):   ... # I need the value of PROFILE for generating .fvwm95rc # netenv contains an assignment like e.g. PROFILE=32 if [ -r /tmp/netenv ]; then . /tmp/netenv fi  # Now the actual .fvwm95rc is generated depending on the value of PROFILE cpp -lang-c++ -D PROFILE=$PROFILE ~/.fvwm95rc-cpp ~/.fvwm95rc  exec fvwm95 # exec saves the extra memory for a no longer useful shell ... ...                The shell variable  PROFILE  contains the information about the current       environment. The file  /tmp/netenv  is set up by  init  when going to run       level 2. I described this in the article mentioned above.  Obviously you need  cpp , which comes either as an extra package or as part of  gcc . Yes, I know that there is a module  FvwmCpp  (which calls  cpp ) - but I never managed to get it work.                      One advantage of the old-fashioned style of configuration files is       that you can put comments in.  You really should do this !  All that       hidden dot files in your home directory make up your personal       environment (these files will never be touched by a system       update). Having comments will make it easier to maintain this   environment.    system.fvwm95rc  comes in shell style comment syntax (so does  fvwm). You can't feed this into  cpp . I didn't like       traditional c-style comments in a configuration file, so I switched       all these comment lines               # this is a useful comment                into c++-style comments               // this is a useful comment                      (hail emacs !). Calling  cpp  with          -lang-c++                tells  cpp  to preprocess c++-code. A hint for those, who are not       familiar with  cpp :  cpp  strips off the comment lines of the input       file. You probably will get output with a lot of blank lines.    Examples how to use cpp-syntax         Now let us have a look inside my  .fvwm95rc-cpp .       Of course, everything herein is strongly a matter of personal taste.          I don't like to stress my eyes. So I hate small letters, I barely can  read them in the evening of a long day ... So my desktop has 4x2 pages.  Each page is assigned to one application (or a few). I use   <Alt><F1>  to  <F8>  to   switch quickly between pages. Using the fabulous fvwm95 mini icons my  screen holds the  FvwmTaskBar  and on the right hand side a column  holding some icons. This way I can maximize the application window.          The  screenshot  should make it clear.    Defining geometry         One important application is xemacs for me. So I define a mini button       in the  FvwmButtons  section like this:               *MiniButtons -   mini-edit.xpm        Exec  ""Xemacs"" /usr/bin/xemacs \                                       -geometry EMACS_GEO &                       EMACS_GEO  is to be substituted by        cpp . I put all the  #define  in the        beginning of my  .fvwm95rc-cpp . Basically it reads like this               #if PROFILE == 30 || PROFILE == 31 || PROFILE == 32  #define EMACS_GEO 80x25+0+480 #else #define EMACS_GEO 96x31+0+767 #endif                      Whenever I'm on my laptop,  PROFILE  equals 30, 31       oder 32 (at home, in the office, on customers site). The       LCD-Display has 600x420 pixel. My other systems have 17"" monitors and       there I use 1024x768. The +0+480 or +0+767 pops up the xemacs window       on the leftmost page on the bottom row of my 4x2 desktop. But this is       true only when being on the very first page while clicking the       icon. I'm shure, this could be improved.                With defining         Key F5  A M GotoPage 0 1                      I can conveniently switch to my xemacs window using   without       leaving the keyboard.                      Launching applications                Being at home or in the office, I have usually some  rlogin  sessions to       some well known machines. Being on a customers site I frequently have       to work with high availability configurations mostly consisting of two       machines. I call them always abba and bebe. See how this can be set       up (shortened for clarity):   DestroyFunc ""InitFunction""  #if PROFILE == 30 AddToFunc ""InitFunction"" \   ""I"" Exec xsetroot -solid turquoise4 -cursor_name top_left_arrow & + ""I"" Exec xconsole -font 6x10 -geometry XCONSOLE_GEO -sb -file /dev/xconsole & + ""I"" Exec rxvt -geometry 94x28+0+0 -fn DEF_FONT -ls -sb -vb \                            -title TERMWIN_ID1 -n TERMWIN_ID1 -cr Yellow3 & + ""I"" Exec rxvt -geometry TERMWIN_GEO2 -fn DEF_FONT -ls -sb  -vb \                           -title TERMWIN_ID2 -n TERMWIN_ID2 -cr Red3 & + ""I"" Exec rxvt -geometry TERMWIN_GEO3 -fn DEF_FONT -ls -sb  -vb \                           -title TERMWIN_ID3 -n TERMWIN_ID3 -cr Magenta3 & + ""I"" Module FvwmButtons MiniButtons + ""I"" Module FvwmTaskBar + ""I"" Module FvwmAuto 700 + ""I"" Module FvwmPager 0 0 #elif PROFILE == 10 ... #else AddToFunc ""InitFunction"" \ ... ... + ""I"" Exec rxvt -geometry 94x28+0+0 -fn DEF_FONT -ls -sb -vb \                           -title TERMWIN_ID1 -n home -cr Yellow3 & + ""I"" Exec rxvt -geometry TERMWIN_GEO2 -fn DEF_FONT -ls -sb  -vb \                           -title TERMWIN_ID2 -n TERMWIN_ID2 -cr Red3 & + ""I"" Exec rxvt -geometry TERMWIN_GEO3 -fn DEF_FONT -ls -sb  -vb \                           -title TERMWIN_ID3 -n TERMWIN_ID3 -cr Magenta3 & + ""I"" Exec rxvt -geometry TERMWIN_GEO4 -fn DEF_FONT -ls -sb  -vb \                           -title TERMWIN_ID4 -n TERMWIN_ID4 -cr Green3 & + ""I"" Exec rxvt -geometry TERMWIN_GEO5 -fn DEF_FONT -ls -sb  -vb \                           -title TERMWIN_ID5 -n TERMWIN_ID5 -cr Blue3 & ... ... #endif        The terminal geometry und identifiers are defined as follows:       #if PROFILE == 10 #define TERMWIN_ID1 bav@nana #define TERMWIN_ID2 nana #define TERMWIN_ID3 lulu #elif PROFILE == 20 ... #elif PROFILE == 30 ...#define TERMWIN_ID1 bav@lulu #elif PROFILE == 31 ... #elif PROFILE == 32 #define TERMWIN_ID1 bav@lulu #define TERMWIN_ID2 lulu #define TERMWIN_ID3 abba #define TERMWIN_ID4 bebe #define TERMWIN_ID5 abba #endif      Conclusion   Screen geometry and network environment differ from one machine to       another. Everyone, who wants to have  one        configuration file for his fvwm 2.xx or fvwm95 to reflect these       differences, should consider to use  cpp  as shown.          Perhaps you know, that  xrdb(1)  also can       make use of  cpp . So        you can preprocess your  ~/.Xdefaults  achieving the discussed advantages.         I hope you will find these ideas somehow useful !          Kind regards          Gerd                Gerd Bavendiek              Copyright © 1997, Gerd Bavendiek   Published in Issue 21 of the Linux Gazette, September 1997                               ""Linux Gazette... making Linux just a little more fun! ""                  Impressions reading Peter H. Salus `A Quarter Century of UNIX'         By Leif Erlingsson  < leif@lege.com >             I have been involved with Unix and the Internet since '88, and  with Linux since '95, but it isn't until reading Peter H.  Salus' `A Quarter Century of UNIX' during this summer vacation  that I see where Linux fits in into the last 25 years of  operating systems development.    Unix came about as a revolt against cumbersome propriety  operating systems shipped by the various hardware-vendors.  In contrast, Unix was developed by a handful of people.  An  example of a ""huge"" software project in the development of  Unix is `awk'--developed by three people.    UNICS (original name) was developed at Bell Telephone  Laboratories in the Summer 1969 - Fall 1970.  Ken Thompson was  the initiator and Dennis Ritchie and Rudd Canaday were active  contributors.   The intent was to create a pleasant computing environment for  themselves. The hope was that others would like it also.   The basic notion at the Labs (in Dennis Ritchie's words as  quoted from the book),     was and is to hire people who generate their own   good ideas and carry them out....    The Bell Telephone Laboratories staff (BTL) were supposed to  discover or invent new things.  There was always management  encouragement.    It turned out Unix was easy to use and understand when  compared to the competition. It was extremely compact. It  wasn't until much later that anything and everything the user  wanted was supplied (like vi, emacs, X, ksh, csh,... :-)).    The single most important factor behind Unix' popularity was  that in the beginning the source code was practically free.  Thus it was used in education and as a base for derivate  systems.  The universities loved it.  Later, when AT&T realized  that they had in Unix something of great value and tried to  capitalize on that, universities were forbidden to use the  source code in education. This motivated Andy Tanenbaum to write  MINIX, from whence Linus Torvalds got his inspiration to write a  kernel for his Intel 386, the kernel that later became Linux.    Bell Telephone Laboratories (50/50 owned by AT&T and Western  Electric Company) was, by the so called ""consent decree"" of  Jan 24, 1956 (entered into because of the Sherman Antitrust  Act and a complaint filed by the Department of Justice in  Jan 14, 1949), required to reveal what patents it held and  supply information about them to competitors.  Also, the terms  of the decree required BTL to license to anyone at nominal fees.  So we have this ""consent decree"" to thank for the phenomenal  spread of Unix!     BTL had the following support policy:     no advertising    no support    no bug fixes    payment in advance    This forced the users to band together, which resulted in  better and more responsive support than any vendor could have  managed.  Also, an ""us"" (users) against ""them"" (vendors)  mentality formed, reinforced by actions taken by AT&T to  stifle ""the Unix problem"".     This is very important:  Unix begat Internet!    For a long time no one in business took Unix seriously.  For AT&T it was just a legal problem.  It was run on VAX'es,  but it took the Digital Equipment Corporation about a decade  to learn how to support a Unix system as opposed to a Virtual  Machine system because of the NIH syndrome. (NIH = Not  Invented Here.)    Does it sound like Linux or does it [sound like Linux] ?  :-)    On 20 Nov 1974, the U.S. government filed a new antitrust  action against AT&T, Western Electric, and Bell Telephone  Labs.  The settlement reached in 1984 dissolved Western  Electric, formed the ""Baby Bells"" and reorganized AT&T Bell  Laboratories into Bell Telephone Labs.    AT&T was now permitted to enter the hardware and software  computer business.  AT&T sharply raised Unix license fees ...     One reaction was Richard M. Stallman's Free Software Foundation  with it's GNU (Gnu is Not Unix) project, that has given the  world a wealth of free versions of Unix systems programs.  Another is Keith Bostic's CSRG project to create a license  free version of Unix.  Today, all free Unix clones except  Linux use the CSRG code, and all free Unix clones use the GNU  code, Linux included.    This is very important:  Internet begat GNU and CSRG, and  therefore the free Unixes, Linux included.  And Unix begat  Internet, so therefore,           Unix begat  Linux.  Also, as we all know, Linux is continually developed  on the Internet by a looseknit band of programmers from around  the world, each doing their little piece -- truly users banded  together!    So where do Microsoft and others fit into this picture?  DOS/Windows is just one of many systems sprung out of the  fountain of Truth -- though there is much debate as to how  much truth has rubbed off on them. :-)     There is a huge cultural barrier between the Unix camp and  the other guys.  It took DEC a decade before the DEC Unix  Engineering Group was formed, and when it was, it was located  in a separate location from the rest of the company.    Salus tells the story in the book:   there was a lot of animosity towards Unix up and down the  company at DEC.  Armando Stettner relates how Dave Cutler,  one of DEC's engineering elite, at one point got two Unix  engineers, Armando Stettner himself and Bill Shannon, to  drive down to his office 20 minutes away to help him with,  Armando thinks it was, some SRI package on top of VMS.  They got there and Cutler was in his office.  Armando and  Bill sat down at a terminal, and it just didn't do what  they expected it to do.  Cutler asked them how it was, and  Armando replied that it didn't work.  To this Cutler said  ""Well, thank you very much"" and they were dismissed.  Cutler then called their Senior Group Manager and chewed  him out and said Armando and Bill were sorry excuses for  engineers and he never wanted to see them in Spitbrook  (his office) again.  Armando believes that Cutler's  disdain has been reflected in his work ever since.  Armando says:     Cutler was doing yet another OS based on a new   architecture called Prism, not Unix, during   Digital's internal RISC wars.  Initially,   Cutler's OS wasn't portable, but was culturally   compatible with VMS.  There is a lot of stuff   in NT that I think can be traced to Prism.   [Cutler went to work for Microsoft around 1983.]        To round this off I'd like to itemize a few general factors  for the success of Unix:     Simplicity     Small projects     No restrictions put on creativity     Freedom     Free source     Fun     Collect a lot of great ideas that are around plus   some original ideas and put them together in a very   interesting, powerful way.     Users supporting themselves     Internet     Portability     Universality     Stability -- i.e., the antithesis of the continuous   change needed to keep the DOS/Windows personal computer   market alive.  System programs don't need to change.   Well designed OS's don't need fundamental changes.   No need to do Windows 95 this year, Windows 97 the next   and then NT.  Just stick with what works!     ""Us against them"" -- thanks AT&T, DEC and Microsoft!        There must be a fundamental difference of thinking between  the free software camp and the other guys:     The first mind-set is to share in order to gain.  The other  mind-set is hoarding out of fear that something is going to be  taken away.  Out of the latter mind-set springs the correct  business-types managing their various copy-protected products,  while from the sharing win-win culture, where each person's  efforts becomes a multiplier toward a common goal, springs an  open and nonconformistic, somewhat anarchistic type of person.  The two often do not like or understand each other.        (This article is copyright Leif Erlingsson.  As long as  this copyright notice is preserved, and any cuts clearly  marked as such, the author hereby gives his consent to  any and everybody to use this text.)    (The book `A Quarter Century of UNIX' is Copyright  1994 by  Addison-Wesley Publishing Company, Inc.)            Copyright © 1997, Leif Erlingsson    Published in Issue 21 of the Linux Gazette, September 1997                              ""Linux Gazette... making Linux just a little more fun! ""                 Installing Linux on an IBM ThinkPad 365XD Notebook   By Sam Trenholme,  set@reality.samiam.org       My latest roadstop in the quest for the perfect affordable portable computer stops with the IBM ThinkPad 365XD notebook.  Hawked from Egghead for only $1000, and with successful reports of sticking X on this thing form the 'net, I proceeded to install Linux on this beast.  The install was one of the more difficult Linux installs I have had, with a number of problems:    First problem:    *Booting directly in to the RedHat install from the CD-ROM, the install   could not see the CD-ROM.   The CD-ROM in a ThinkPad 365xd is a standard IDE CD-ROM.  For unknown reasons this CD-ROM was invisible when I booted into the install directly from the CD-ROM.  Making a RedHat install boot disk and booting from that resolved the concern.  The CD-ROM was visible, and I was able to install normally.   Second problem 2:    * RedHat crashed in the middle of the install.   RedHat seems to do that sometimes, for very mysterious reasons.  On the first install, RedHat crashed.  I had to go back to square one and completely reinstalled.  The second install of RedHat 4.2 went without incident, resulting in a functional RedHat system.   Third problem:    * After installing LILO, the ThinkPad refuses to boot from the   hard disk.   After mutch futzing, I discovered that the BIOS refused to boot from the hard disk if it saw more than one primary partition.  I configured fdisk thusly:   I made one primary partition the Linux partition, then made the swap partition the extended partition.  I did this as follows:     I deleted all pre-existing partitions  I added the main partition, making sure enough space was set aside for  swap.  I used 'n' to create the new partition, and 'p' to indicate that it was a primary partition.  I then added an extended partition, having the extended partition take up the rest of the hard disk--my swap space.  I then added a logical partition, which was the swap space.  I marked the primary partition as a Linux Native partition, and the  extended partition as an extended partition.  I made the primary Linux partition bootable with the 'a' option.  Finally, I wrote the partition table to disk.    My fdisk session went like this:   Command (m for help): n Command action    e   extended    p   primary partition (1-4) p Partition number (1-4): 1 First cylinder (1-789): 1 Last cylinder or +size or +sizeM or +sizeK ([1]-789): 741  Command (m for help): n Command action    e   extended    p   primary partition (1-4) e Partition number (1-4): 2 First cylinder (742-789): 742 Last cylinder or +size or +sizeM or +sizeK ([742]-789): 789  Command (m for help): n Command action    l   logical (5 or over)    p   primary partition (1-4) l First cylinder (742-789): 742 Last cylinder or +size or +sizeM or +sizeK ([742]-789): 789  Command (m for help): t Partition number (1-5): 1 Hex code (type L to list codes): 83  Command (m for help): t Partition number (1-5): 5 Hex code (type L to list codes): 82 Changed system type of partition 5 to 82 (Linux swap)  Command (m for help): a Partition number (1-5): 1  Command (m for help): p  Disk /dev/hda: 32 heads, 63 sectors, 789 cylinders Units = cylinders of 2016 * 512 bytes     Device Boot   Begin    Start      End   Blocks   Id  System /dev/hda1   *        1        1      741   746896+  83  Linux native /dev/hda2          742      742      789    48384    5  Extended /dev/hda5          742      742      789    48352+  82  Linux swap  Command (m for help): w    [It wrote the information to the hard disk, then exited.]   When I installed LILO, I placed LILO on the boot sector of the first (bootable) partition (/dev/hda1) instead of the master boot record (/dev/hda).   Fourth Problem:    * After installing X, as per the XF86 configurations on the Linux ThinkPad survey, I was unable to start X.  X would just cause the screen to become blank.   X has to be ""Kicked in"", so to speak, by hand.  After X starts, hit Fn+F7 (the Fn and the F7 keys at te same time) to get the X display to function.   Fifth Problem:    * After starting X, one can not exit X and return to a normal text display.   One can not leave X after entering it on the ThinkPad.  The best workaround this problem is to edit /etc/inittab to make the default runlevel 5.  This enables a mode where you can log in and log out without leaving X, using a program known as xdm.   In order to make the default runlevel 5, look for a line like this in /etc/inittab:   id:3:initdefault:    Change the line to look like this:   id:5:initdefault:    Note the number 5 instead of 3.   You may also wish to disable most of the virtual terminals in runlevel 5, since you won't be using them [1].  There are a series of lines that look like this in /etc/inittab:  1:12345:respawn:/sbin/mingetty tty1 2:2345:respawn:/sbin/mingetty tty2 3:2345:respawn:/sbin/mingetty tty3 4:2345:respawn:/sbin/mingetty tty4 5:2345:respawn:/sbin/mingetty tty5 6:2345:respawn:/sbin/mingetty tty6    Change the lines to look like this:   1:12345:respawn:/sbin/mingetty tty1 2:234:respawn:/sbin/mingetty tty2 3:234:respawn:/sbin/mingetty tty3 4:234:respawn:/sbin/mingetty tty4 5:234:respawn:/sbin/mingetty tty5 6:234:respawn:/sbin/mingetty tty6    Note that most of the above lines no longer have a '5' in them.  For various reasons, it's a good idea to have an emergency virtual terminal. Linux does (or, at least, used to do) funny things without at least one virtual terminal.   Sixth problem:    * I was unable to have the kernel see a parallel port zip drive   The I/O base of the parallel port is at 0x3bc instead of 0x378.  To have Linux see a parallel zip drive on the ThinkPad 365xd:   insmod ppa.o ppa_base=0x3bc       instead of simply:   insmod ppa.o    Note that the I/O base of the parallel port was determined with the MSD program on a MS-DOS boot disk.   Seventh problem:    * After entering 'suspend mode' on the ThinkPad (Fn+F4), the system would   crash when I tired to exit from suspend mode.   The kernel needs to be recompiled with APM support on the ThinkPad 365xd. To do this, make sure the kernel source is installed on your system.   You can install the kernel source from the RedHat CD, as in the following example Linux session:  [root@localhost /]# mount /mnt/cdrom [root@localhost /]# cd /mnt/cdrom/RedHat/RPMS/ [root@localhost RPMS]# rpm --install kernel-source-2.0.30-2.i386.rpm     If you do not have a RedHat CD, do the procedure most appropriate for your RedHat system to install the above RPM package.   I then went to the directory /usr/src/linux, ran 'make menuconfig' and went to 'Character Devices --->', then enabled 'Advanced Power Management BIOS support' without enabling any of the other features ('Ignore USER SUSPEND', etc.).   I then made a kernel image with 'make zImage' (and waited a while, hitting the space bar every 5-10 minutes so the machine would not crash), and copied the kernel image (located in the directory '/usr/src/linux-2.0.30/arch/i386/boot' as the file 'zImage') over to /boot.   I then edited my /etc/lilo.conf so that the boot line which looked like this:   image=/boot/vmlinuz   looked like this:   image=/boot/zImage   and re-ran Lilo thusly:   /sbin/lilo    ** Be very careful with changing Lilo.  Doing things incrrectly can make    it difficult to re-enter Linux**   Once I did all this, I had a functional Linux system on my ThinkPad 365xd, which I am currently using to type this in (on the streets of Santa Cruz, no less)   Speaking of being on the streets, I find the DTSN display almost unreadable in direct sunlight, and only somewhat readable in the shade on a sunny day (fortunatly, the Pacific coast fog is strong tonight).  I hear that TFT displays are a lot better in this regard.    [1] The virtual terminals is something you can use to multitask in     text mode with Linux.  To change virtual terminals, simply hit alt     and a function key between F1 and F6.            Copyright © 1997, Sam Trenholme   Published in Issue 21 of the Linux Gazette, September 1997                              ""Linux Gazette... making Linux just a little more fun! ""                 Adventures with PPP   By Larry Ayers,  layers@marktwain.net        Introduction    When I first began using Linux a couple of years ago, one of my goals was to be able to go on-line.  At that time I was constantly rebooting into OS/2 so I could use the internet and this OS schizophrenia was becoming tiresome.   Eventually, after many chatscript iterations and minicom sessions I had a dependable PPP setup.  I thought my PPP troubles were over; as time passed my command of the various  pppd  and  chat  options began to fade.   This past month my local internet service provider sold its machines and signed up with a large provider in Atlanta.  When the accounts were switched over suddenly I could no longer log in and life became a bit too interesting...    Log-In Fashions Change    A couple of years ago an ISP was happy just to have a set of working log-in scripts which could be distributed to its Windows and Mac customers.  At that time most computer users were either hobbyists or professionals, and could be counted on to know what to do with the script.  As the internet surged in popularity more and more customers appeared without much knowledge of basic computer usage, and the help-desks and support personnel began to be swamped with requests for set-up help.  Naturally, the tendency was to move towards simpler log-in set-ups, if possible without any script at all.  As customer interest in  text-mode shell accounts waned, a log-in could be accomplished with little more than the username and password.  This (I was informed in an e-mail from my provider) was our new log-in sequence: just the username and password.   This sounded simple enough; all I had to do was delete the expect-send sequence  selection:  PPP  from the chat-script and all would be well.  Or so I thought: using this script led to a scrolling list of errors on the console I set up to display all daemon and error messages.  It looked like the router I was attempting to connect to was first trying PAP authentication, failing, then trying CHAP authentification, failing that as well;  the sequence would repeat until the router would hang up in disgust.   Other variations of the chat-script I tried would result in a ""serial line not 8-bit clean"" message.  I talked with the technician who had set up the local router and he claimed that neither PAP nor CHAP were in use; Win95 log-ins were working fine, so I was on my own.   The next step was to try logging in with Minicom, just to see what the actual log-in screen looked like.  I connected and found the expected  Username:  and  Password:  prompts.  I logged in and a command prompt appeared, with no sign of the typical PPP garbage characters.  What now?  I typed  help  and a list of available commands scrolled by.  I was logged in  to the Cisco router, evidently, and before long I found that I could telnet anywhere I liked.  I could run a  systat  command and see which other  users were logged in.  The command  show hosts  provided  a list of hosts which I could connect to, and soon I was logged in at the main WWW server in Atlanta!  I'd never been logged in at an UltraSparc server running Unix SysVR4 before, and it was great fun exploring the directory structure and running real VI for the first time.  I could run pine (and I ended up with yet another e-mail address) and read news with the nn newsreader.   This was all quite diverting, but didn't address the PPP problem.  So soon I was back at the router's prompt.  I tried typing  ppp  and the indicative garbage characters appeared.  This looked encouraging, so I added this exchange to my chatscript and tried again.  The  pppd  daemon was satisfied this time, and I had what looked like a real PPP session. Unfortunately, it turned out to be limited to the router and I could do nothing with the connection.  Another dead-end!   Back to OS/2    At first I couldn't even log in with OS/2 when I revived an old installation and  tried to dial in.  Deleting the entire log-in sequence in the dialer got me online again, but even with debugging turned on I still couldn't determine just when the username and password strings were being sent to the server.   On-line once again, I was off to the newsgroups hoping to find advice.   Eventually I came across a posting in  comp.os.linux.networking  which contained a couple of intriguing statements.  The first intimated that Win95 by default makes use of PAP authentification, but the user isn't necessarily informed of the fact.  Possibly the Netscape dialer which my ISP distributes was using PAP as well, I thought.  The second statement recommended using the  pppd  option  +ua /etc/ppp/pap-secrets .  I had seen this option while reading the  pppd   /etc/ppp/options  file, but the manual listed this option as being obsolete, so I'd never tried it.   The posting's author recommended an unusual format for the  pap-secrets  file, unlike the format recommended in the documentation I'd been reading and unlike the sample included in my PPP installation: just a simple two-line file, the first line containing the username and the second displaying the password.  No server or client names, just the two words.   Success    I was surprised and elated when this configuration worked the first time. I had the chat-script simply dial the number and wait for the  CONNECT  string.  The server asked for PAP authentification and I was online without even dealing with the username and password prompts, which I suppose are only for the maintainers of the router.   I'm writing this piece because I suspect that many other servers will probably be adopting similar streamlined login procedures, and the approach I've outlined here may prove useful in at least some of these cases.  One thing to remember is that directing the  pppd  debugging messages to an unused virtual console is very helpful, most easily accomplished by inserting the line:     *.*     /dev/tty8    in your  /etc/syslog.conf  file.              Copyright © 1997, Larry Ayers   Published in Issue 21 of the Linux Gazette, September 1997                              ""Linux Gazette... making Linux just a little more fun! ""                 SVGATextMode   By Larry Ayers,  layers@marktwain.net       Fit More Text On Your  Console Screen    Introduction    This summer a new version of  SVGATextMode  was released, and thinking that many Linux users might be unfamiliar with the package, I put together this review as an introduction to a versatile and useful console utility.   Typically, Linux distributions use LILO as the boot loader, which refers to the file  /etc/lilo.conf  for instructions.  One of the lines in the file is  vga =  , with either the number of a console video mode following the ""="", or the word  ask .  If ""ask"" is specified, the Linux boot process is interrupted and you are asked which (EGA) video mode you prefer.  An option (thankfully!) is also provided allowing the user to peruse a menu of available console video modes, which varies depending on the video chipset. With my generic S3 Virge card, these modes are offered:        80x25    80x50    80x43    80x28    80x30    80x34    80x60    132x25    132x43     It's nice to have a choice of video modes (which determine the screen font  size) but these boot-time options just scratch the surface of what the newer video cards  and monitors offer.   SVGATextMode is a utility which borrows some of the techniques which the X-Window system uses to exploit the resources of your  video system and applies them to the console screen.   How It Works    SVGATextMode actually reprograms the registers of your video card, allowing  many more modes than the preprogrammed modes available at boot-up.  It borrows  some of the techniques used by XFree86 in order to make available more console  video modes.  The modes provided by your video-card BIOS are EGA modes, and they run at a low refresh-rate and dot-clock compared to those used by X-windows.   The program can be either started at boot-time from one of the init-files, or at any time from the console prompt.  When it starts a configuration file  ( /etc/TextConfig ) is parsed.  The defaults are very conservative. The file needs to be read and edited before any real advantage can be obtained  from the program.  This is due to the vast differences in capability between various video cards and monitors.  As in X configuration, the correct values for your monitor's horizontal and vertical refresh rates need to be entered in the  TextConfig  file.  If you've successfully configured X you shouldn't  have any problems with SVGATextMode.   Configuration and Use    SVGATextMode is what I consider to be a ""mature"" package, in that it has been under development long enough to have received contributions and bugfixes  from a worldwide community of users.  Many video cards are supported, though I  don't think quite as many as XFree86 supports.   In the default  /etc/TextConfig  file many of the lines are high-resolution modes contributed by users.  Once you have entered your video chipset and monitor timings into the file, the command  SVGATextMode -n  [mode]  will let you know if your hardware can support the mode without actually starting the program.  Once you've found some promising modes just eliminate the ""-n"" from the command and with any luck you'll have the new text mode visible on your console screen.  Possibly the screen will be corrupted.   Running the SVGAlib utility  savetextmode  before trying a new mode, then if corruption appears  restoretextmode  afterwards ought to allow recovery of your previous default text mode.  It will take some experimentation, but the package is very well documented and is worth the trouble.   There are some included modes with 160-character wide screens, which can be  very useful while running an editor which allows two 80-character pages to be displayed side-by-side.  Emacs can do this, and there is a LISP package available called follow-mode which allows both pages to scroll relative to each other.   SVGATextMode doesn't just allow more characters to be displayed on the screen.  Even relatively low-resolution modes will look crisper and be easier to read due to the higher refresh rates typically used.  The most dramatic advantages, naturally, are evident with newer, more powerful video-cards and large monitors, but even with my middle-of-the-road equipment the utility is well worth using.   Caveats    If you use Dosemu from the console there can be problems.  I have to reset the text-mode to my old default 80x43 mode before starting Dosemu or I get unrecoverable corruption requiring a reboot.  I haven't had any problems switching from a console session to X and back, but, just as with X-windows, performance varies depending upon the video-card and monitor involved. Read the documentation; it's very complete and a great help while getting started.   Availability    The source package (version 1.6) can be retrieved from the Sunsite archive site or one of  its mirrors, in this  directory . A binary package for Redhat systems is available  here , and a Debian binary can be downloaded from   here .             Copyright © 1997, Larry Ayers   Published in Issue 21 of the Linux Gazette, September 1997                               ""Linux Gazette... making Linux just a little more fun! ""                 Yet Another Window Manager   By Larry Ayers,  layers@marktwain.net        Introduction    Marco Macek, a Slovenian computer-science student, has been developing a quite powerful and configurable editor called FTE for the past couple of years.  FTE is a multi-platform folding editor, available for Linux, OS/2, DOS, and Windows; I wrote a short review of an earlier beta in issue 7 of LG.  Lately Marco has turned his hand to developing a new window-manager.  Unlike some Linux projects, which are released to the FTP sites in the early stages of development, the Ice window-manager seems to have been under development as a non-public project throughout the early beta versions.  It just showed up one day in the Sunsite incoming directory in a remarkably complete and usable form.   Differences and Features    Lately window-managers seem to be proliferating, with offshoots and variants of fvwm predominating.  Icewm is in large part inspired by the OS/2 Workplace Shell interface.  Though OS/2 has been never gained the market acceptance its adherents have hoped for, the Workplace Shell is a remarkably advanced object-oriented GUI, and Macek has attempted to adapt some of its ""look-and-feel"" to the Linux environment.  Another influence is the common Windows 95 interface, which does have some useful features worth emulating.   Win95's bottom-of-the-screen icon bar , with its cascading menus and dynamic window indicators, has been nicely reproduced in Icewm.  The equivalent of the ""Start"" menu (which functions much like Win95's) has a ""Linux"" label with a penguin icon.        The general appearance of the windows (borders, titlebars, et al) is very reminiscent of OS/2.  Various types of ""X"" kill buttons are available, but the  general appearance of the window-borders seems to be hard-coded;  that is, not configurable.  Here's a screenshot of a typical window:         I liked the cascading mouse button menus, with a different menu shown for each mouse button.  The Enlightenment window-manager has a similar feature. These menus are hierarchical and behave like their OS/2 equivalents.         This window-manager really doesn't have such compellingly new features that  many long-time Fvwm2 or AfterStep users would want to adopt it, but for new Linux users more familiar with Win95 or OS/2, the similarities might serve to ease the transition.  It compiled easily on my 2.0.30 system, and it seemed to be stable and dependable.   The source archive is available from  the icewm home-page , as well  as the sunsite FTP site.  Icewm's home page also has Redhat RPM's of the source.            Copyright © 1997, Larry Ayers   Published in Issue 21 of the Linux Gazette, September 1997                               ""Linux Gazette... making Linux just a little more fun! ""                 Remote Compilation Using SSH and Make   By John R. Daily,  jdaily@bbn.com               Problem        Occasionally I use my Linux machine at home to write code that I intend to compile on a remote machine.   While maintaining open  ftp  and  telnet  connections to the remote machine to handle the transfer and compilation steps is a manageable solution, I decided to explore  ssh  and  make  to develop a more automated method.   The benefits of my solution:     No need to remember which files have been modified.   Ability to use Emacs' compilation capabilities to move to errors in    the source.    As mentioned above, no need to use  ftp  and  telnet , and hence no    benefit to keep an open dialup connection when not compiling.   Automate, automate, automate. Laziness is a virtue.      Overview of Solution     My first step was to set up  ssh  and related tools in order to allow secure copying of files to my remote system. While setting up a  .rhosts  file is a (barely) acceptable solution, my IP address and name is different each time I dial in, and it would be rather awkward to change the remote system's  .rhosts  file each time I dialed in.    ssh  allows me to use a much more secure form of authentication to copy files and execute remote commands.   Once I had  ssh  behaving properly, I used Emacs'  info  facility to explore implicit rules in makefiles, and wrote a simple makefile to handle the file transfers and remote compilation.   As an example of the intended effect, assume my remote machine is called ""remote"" (and my local machine ""local""), and I've just modified a source file called  daemon.c . I would like to execute the following commands in an automated fashion (note that  scp  is a secure copy command packaged with  ssh , and that the  -C  option specifies compression, useful for dialup connections):  scp -C daemon.c jdaily@remote:~/source-directory ssh -C remote ""cd source-directory && make""      Implementation     First, I needed  sshd  running on the remote system to handle my secure connections. Fortunately,  sshd  was already running on the remote system in question, but according to the man pages, it can be run as any user, and is restricted to handling connections for that user (which should be quite sufficient for our needs).   Then, I needed to install the  ssh  toolset on my local machine. Again, ideally these would be installed in a public binary directory such as  /usr/local/bin , but any user can install them in his/her home directory.    I also wanted a key which would allow me to authenticate myself between systems, and which would eliminate the need to type my password each time I tried to run one of the  ssh  commands. For this, I just ran  ssh-keygen , and made sure to not give a pass phrase, so that none would be needed to use my private key to establish the connection.   [jdaily@local ~]$ ssh-keygen  Initializing random number generator... Generating p:  ............++ (distance 186) Generating q:  ......................................++ (distance 498) Computing the keys... Testing the keys... Key generation complete. Enter file in which to save the key (/home/jdaily/.ssh/identity): <CR> Enter passphrase: <CR> Enter the same passphrase again: <CR> Your identification has been saved in /home/jdaily/.ssh/identity. Your public key is: 1024 35 718535638573954[...] jdaily@local Your public key has been saved in /home/jdaily/.ssh/identity.pub      Once I had a public key, I used  scp  to copy it to the remote machine.   [jdaily@local ~]$ scp -C ~/.ssh/identity.pub jdaily@remote:~/.ssh/key jdaily's password: <entered my remote password>     Then I logged into the remote host and copied the key file into  ~/.ssh/authorized_hosts . If that file already existed, I would have appended the key file.   Following all this, I could run  ssh  and  scp  without needing either a password or a pass phrase to connect to  remote .   Now I needed a makefile to automate my system. Ideally, the files on the remote machine would be checked to see if they were older than the files on my local machine, and if so, they would be copied over. To simplify matters, I decided to keep a record of the ""last transferred date"" for each file by touching a corresponding file each time I copied a source file over.   As an example, when I transferred a newer copy of  daemon.c  over, I touched  daemon.ct  in the same directory. Any transfer of a  .h  file would be marked by the creation of a file with a  .ht  suffix.   After poking around the  info  file for  make , I came up with the following makefile.  TRANSFER=scp REXEC=ssh SSHFLAGS=-C # Compress data REMOTE=jdaily@remote:~/source-directory FILES=debug.ht messages.ht client.ct daemon.ct queue.ct queue.ht  %.ht : %.h  $(TRANSFER) $(SSHFLAGS) $< $(REMOTE)  touch $@  %.ct : %.c  $(TRANSFER) $(SSHFLAGS) $< $(REMOTE)  touch $@  all-done: $(FILES)  $(REXEC) $(SSHFLAGS) remote ""cd source-directory && make""  touch all-done     This had one limitation in particular; I was unable to specify command-line arguments for  make  on the remote machine without writing them directly into the makefile on my local system.  While this was fine for the current application, I decided to generalize it by creating a  run-make  shell script, which would handle the remote execution of make after calling make on the local system.   Here is my  run-make  shell script:  #!/bin/sh  make echo ssh -C remote \""cd source-directory \&\& make $*\"" ssh -C remote ""cd source-directory && make $*""     I then removed the line from my makefile which remotely ran  make .   Here's the output from a successful compilation sequence.   cd ~/source-directory/ ./run-make scp -C debug.h jdaily@remote:~/source-directory touch debug.ht scp -C messages.h jdaily@remote:~/source-directory touch messages.ht scp -C client.c jdaily@remote:~/source-directory touch client.ct scp -C daemon.c jdaily@remote:~/source-directory touch daemon.ct scp -C queue.c jdaily@remote:~/source-directory touch queue.ct scp -C queue.h jdaily@remote:~/source-directory touch queue.ht touch all-done ssh -C remote ""cd source-directory && make "" gcc -Wall -Wstrict-prototypes -Wmissing-prototypes -g -c queue.c gcc -Wall -Wstrict-prototypes -Wmissing-prototypes -g -DPORT=3000 -o daemon daemon.c queue.o -lsocket -lthread gcc -Wall -Wstrict-prototypes -Wmissing-prototypes -g -DPORT=3000 -o client client.c -lsocket  Compilation finished at Sat Aug  9 01:22:19      Tools      ssh  is a secure replacement for such tools as  rsh ,  rlogin , and  rcp . It can be found at  http://www.ssh.fi .      make  is a standard Unix utility. GNU's  make  comes with most, if not all, Linux distributions.            Copyright © 1997, John R. Daily   Published in Issue 21 of the Linux Gazette, September 1997       Spare Cycles Needed for Promoting Linux   By Bill Duncan,  bduncan@teamlinux.org       Ever wish you could do more to promote Linux and yet you never seem to have enough time?  Now for a few pennies worth of electricity per day you can put your Linux machine to work promoting Linux!    There are a number of distributed computing projects in progress or being organized, and Linux Advocacy teams are one method available to us which can help raise the visibility of Linux. What I'd like to describe in this article is one such effort   called the   RSA Data Security Secret-Key Challenge .                        This article will describe      what the project is ;       why we are doing this and                     how it might benefit Linux  and       how to get started .                     There is also a section on       who is involved ;     other links for further information  and      when to get involved                      at the end.           What?    The     Secret-Key Challenge  is a contest sponsored by    RSA Data Security  which is being used primarily to further research into the strength of encryption standards.  The DES challenge was won back in June.  RSA is offering a $10,000US prize to the winning team which breaks the  RC5-32/12/7  challenge which uses a 56 bit key.  The challenge has been running since January 28th, 1997.    The status of the various challenges can be seen    here . The method being used for  cracking the code  by the various groups is a  brute force  check of the entire  2^56  keyspace.    To give you an idea of the magnitude of the problem, consider that a single fast Pentium Pro based system would take in excess of 4000 years to run through the entire keyspace.  A 200 Mhz Pentium would take about 9000 years.         Why?     Promoting Linux     Promoting Linux  is the main reason we are participating in this effort.  We would like to raise public awareness of Linux, and this seems like one of many good avenues for doing it.  It is a relatively easy and fun way to get a large number of Linux users involved in a publicity effort.    Linux is in one of those "" chicken-and-egg "" situations at the moment.  We need to make more software companies aware that Linux is a market force to be recconned with.  With more software, it will be easier to convince more users, which will convince more companies etc.  A snowball effect is what we need to break off the plateau we're on.    There are many operating system advocacy groups participating in the effort. One of the strongest ones at the moment is Apple.  It seems like they've been putting all their available systems into the effort and are currently ranked number one in the Bovine effort.  This is the one to beat!  The other Linux advocacy group  linux@linuxnet.org  is in second place on Bovine, but they do not seem to have a presence in the Cyberian effort.  The group we are involved with,  rc5@teamlinux.org  is moving up from behind very quickly on Bovine, and are consistantly in the Top 20 teams on Cyberian for the key rates.    Naturally we hope that you'll consider the team which we are involved with, but both Linux teams have similar goals and reasons for being, and either team would be a good choice.     Helping to Change Encryption Restrictions    To prove that 56-bit encryption is insufficient.  It is high time for the U.S. government to rethink the current encryption export policies and standards.    Stronger encryption is readily available and the belief that "" bad-guys "" might restrict themselves to using encryption that could be tapped by the government does not make sense.     Having Fun!    It is fun to watch your system work on the project, see the results and get into mild competitions with other teams.  Your system is probably idle most of the time and it is satisfying to know that all of the "" idle-cycles "" can now be put to productive use!    Most groups and teams have some methods available for looking at the statistics. Check into these sites on a regular basis, and see how well your team is doing!  The competitive aspect can spur growth as it motivates people to get other people involved.  This is good!       How?     There are three overall efforts working on the RSA RC5 Challenge that we know of. Each one has different client programs to run and different procedures to follow. They also each have their own pros and cons.  Each overall effort is also divided up into "" teams "". We believe that only the first two groups have active Linux Advocacy groups, but we may be mistaken.  (The third group had a team called  Linux! , but did not have a web address or a way to contact them which we could see.)       The Bovine RC5 Cracking          Effort Headquarters     The Cyberian          RC5-56 Project CommCentre     Infinite Monkeys RC5          Coordinated Attack     You will need to pick a team.  Either of the Linux teams will make a good choice and both teams have instructions for setting up which you can read on their respective Websites.  See the  section below  for more of a description on both teams.    The team we are involved with,    Team Linux , has members involved with both    Bovine  and    Cyberian , so we will describe both here.    We will also assume that you are using a Linux machine, although we (Team Linux) don't restrict you to using Linux.  Our feeling on the matter is that the other machines on our team are "" Linux Sympathasizers "" or "" Linux Wannabee "" machines!   ;-)     All groups work on the basis of  keyservers  handing out work for the distributed systems, or  client systems  (that's you and me) to work on. There is very little network traffic to do this.  Basically the keyservers hand out a range of keys to work on.  Your system then checks each key by brute force and contacts the keyserver again when it needs more work to do. The programs work at very low priority  (nice-level)  so that you shouldn't notice any change in interactive sessions, effectively only using "" idle cycles "". The client system also tells the server which range it has checked so that the numbers can show up in your team's statistics.   (This is the fun part.)      The following will not be an exhaustive description of either system but will give you a few pointers on setting up.  For more information, see your team's Web pages.  Hopefully, this get you started and show you how easy it is.     Bovine   Clients     The    Bovine  effort has a lot going for it.  They are well organized; have fast client programs for a number of platforms; have checked a larger portion of the key space and will be giving away a larger portion of the winnings (should they win).  They have stated that they will give $8000US of the winnings to    Project Gutenberg  which is a very worthwhile cause.  They are keeping $1000US and will give $1000US to the winning team.    Both Linux teams will be giving all the prize money away. The  linux@linuxnet.org  group will be donating the money to    Linux International , while the  Team Linux  group is leaving it to members to vote on, and may well end up doing the same.   Team Linux  is also in discussions with several other companies about additional sponsorship for a worthy Linux cause.  We will have an announcement about this soon.     Both    linux@linuxnet.org  and the team we are involved with,    Team Linux  (with an email of  crusader@mo.net ) are represented in this group.  You may pick either team if you choose to use the Bovine system.     The first thing to do is to get a copy of the  client program  and unpack the archive into an empty directory.  At the time of this writing, the latest version was  v2 build 4  and the Linux archive contains:     -rwxrwxr-x bovine/rc5   292892 Aug  7 05:06 1997 rc5v2b4/rc5v2 -rw-rw-r-- bovine/rc5     2085 Aug  6 22:11 1997 rc5v2b4/README.TXT       You'll notice that the files are containted in a subdirectory relative to where you unpack them.  So if you unpack in your home directory you will create a subdirectory called  rc5v2b4  containing the files. (I also create a symlink [symbolic link] here, to make typing easier.  Pick a name which is easier to type such as  bovine . You can then use this as an alias.)    ln  -s  rc5v2b4  bovine         The Bovine  system uses one program which both does the key checking and also maintains a  cache  of keys, contacting a keyserver when it needs more work, and checking in the finished blocks.     Configuring the Bovine client involves running the client program with the  -config  option.  You will then be presented with a menu, which should be similar to the one reproduced here:      CLIENT CONFIG MENU ------------------ 1)  Email to report as [default:rc5@distributed.net] ==> rc5@distributed.net 2)  Blocks to Buffer [default:5] ==> 5 3)  Blocks to complete in run [default:0] ==> 0 4)  Hours to complete in a run [default:0] ==> 0 5)  Keys per timeslice - for Macs etc [default:65536] ==> 65536 6)  Level of niceness to run at [default:0] ==> 0 7)  File to log to [default:] ==>  8)  Network communication mode [default:1] ==> 1 14)  Optimize performance for CPU type [default:-1] ==> -1 0)  Quit and Save       The important one to change is "" 1 "".  This email address you add here determines which team your blocks will be counted for.  This is case sensitive, and does not tolerate typos, so be careful when typing this in and double check.    Press the "" 1 "" key, followed by the "" Enter "" key and you will be presented with the following prompt:     Email to report as (64 characters max) [rc5@distributed.net] -->       If you decide to count your blocks for  linux@linuxnet.org  then enter it here.    If you decide to work with  Team Linux  then you need to enter  crusader@mo.net . (The reason we don't use  rc5@teamlinux.org  on Bovine is that we received our  teamlinux.org  domain after actually starting the effort. The Bovine group was unwilling to move our stats to the new email address so we had to keep the old one to maintain our block counts. The  crusader@mo.net  email address actually belongs to Eric P. Anderson, who started Team Linux.)       Fine Tuning       If you are only connected to the net part time, you should consider buffering a larger number of blocks.  Assuming that you connect once per day, you'll need to get at least a day's worth and maybe a bit more, for good measure. (The limit is 200 on the latest clients I think.)  If you are connected to the 'Net full time, then you can leave this at the default setting.    I also suggest that you define a log file, perhaps       /var/tmp/bovine.log    might be a good choice. This is all you really need to define unless you have specific needs, such as getting around a firewall. (These subjects are beyond the scope of this article, and you should consult the  Bovine Client Documentation  for more help if you run into difficulties.  They also maintain several  mailing lists  where you might find additional help.)    At this point, save the setup by pressing the "" 0 "" key, and you should be ready to test it out. The configuration file which is saved is called  rc5v2.ini , and is placed in the current directory.    Test it out!  Type the name of the program and watch it go! (We usually leave it running with a spare xterm or on one of the text consoles. One nice thing about the Bovine client is that it gives you feedback on how far through each block it is.)     Cyberian Clients     Personally, we find the  Cyberian Effort  more satisfying, although it is not without its problems.  They have been going through some difficulties on their server in the last week while one of the key developers was away in China. (This should be cleared up by the time you read this.)  They also only have one server whereas Bovine have many, so Cyberian are currently more prone to having problems. Lastly, they have not been working as long as Bovine, so have not checked as much of the keyspace.    On the positive side, Cyberian have far better stats which make them much more fun to be involved with.  Currently, the Bovine stats are only updated once per day and do not give you access to your individual numbers.  The Cyberian stats are updated every 10 minutes or so and gives you a list of all of the team members as well as your overall team statistics.    This is a great boon for people getting involved as they can see themselves up on the board within minutes!  Cyberian also has many more categories of numbers and graphs to delight the people involved.    Lastly, the Bovine effort is offering $1000US to the winning team, while the Cyberian effort is offering  $5000US .  This would mean more money for a worthwhile Linux effort, should one of the Linux teams win. Note that the Bovine group is giving the bulk of the money to a worthwhile cause, it's just not a Linux cause.)    At the time of this writing, we believe that the only Linux advocacy group here is    Team Linux . The email address they are using here is:    rc5@teamlinux.org .    First, you need to    download   their client program . Pick the appropriate one for your architecture.  We assume that most of us will be using the "" Client v3.04 for Linux [X86] "" although others are available.    This tar archive will unpack in your current directory so you should make a directory for it:  $HOME/cyberian , for example, then change to that directory.    Unpacking with  tar tvzf  Linux-x86.bin304.tgz  will give you the following files:   -rwxrwxr-x tic0/tic0     20315 Jul 25 15:08 1997 rc5client -rwxrwxr-x tic0/tic0     18093 Jul 25 15:08 1997 sa_simple      The Cyberian system uses these two programs: one  (rc5client)  which checks the keys and the other  (sa_simple)  which maintains the cache and contacts the server when necessary. Both programs will list the available options if you run the program with "" -\? "". (The backslash may be necessary to escape the question mark on some shells.)     You will need to contact the server to load the initial cache of blocks at this point.  For now, run   sa_simple  -1      If everything works OK, you should see a message saying that the server has been contacted and that your cache has been loaded. If the program has difficulty contacting the server, you will see repeated messages to that effect.  If this condition lasts more than ten minutes or so, then there may be a problem. See the  Cyberian  or  Team Linux  Websites for more details. It may be a networking issue, or it may be that their server is still having some problems.     The Cyberian system does not use configuration files, nor does it create logfiles; so all options must be supplied on the command line. (We like to use logfiles to maintain a record of what was done and to see what it is doing occasionally.) You can automate this by creating a shell script such as the following:       #!/bin/sh # # Run the Cyberian client programs: # (This version is for part-time connections, full-time connections don't # use the -1 option on sa_simple, or the -q option on rc5client) #  MY_EMAIL=yourname@yourdomain   # Change This!!! TEAM=""rc5@teamlinux.org"" LOW_WATER_MARK=500 HIGH_WATER_MARK=1000  export TEAM HIGH_WATER_MARK LOW_WATER_MARK MY_EMAIL  sa_simple  -1  -l $LOW_WATER_MARK  -h $HIGH_WATER_MARK > /var/tmp/sa_simple.log 2>&1 &  rc5client  -t $TEAM -e $MY_EMAIL -N -q -n19            > /var/tmp/rc5client.log 2>&1 &          With a shell script such as this you can find out what is happening at any time by doing a  "" tail -f  /var/tmp/rc5client.log "" or  "" tail -f  /var/tmp/sa_simple.log "".  (In fact, we just leave a few xterms running with a tiny font, so we can keep an eye on them while doing other things.)    Assuming that everything is running OK, you can start seeing your own email address in your team's statistics in a very short period of time.  After a few hours of processing, make a connection to the net again (if you are dialing in part time), and run   sa_simple -1  by itself.  After the server has acknowledged your blocks, you should be able to do a search and see your email address show up  here  in about 15 minutes!    Another nice feature which we like about Cyberian is the ability to see what is left in the cache.  This is very useful for users with part-time connections. The following is a script we use to summarize what is in the cache.  You can use this as is, or even modify it to give you estimates of the number of hours left. If you have trouble cutting and pasting from here, you can find it on the  Team Linux site .       #!/bin/sh # # @(#) cache.sh - summarize rc5 cache information dump # Author:  Bill Duncan, bduncan@teamlinux.org # # Note:  make sure rc5client is in your PATH.  I assume current directory.  PATH=$PATH:  rc5client -d | awk '   BEGIN {     F = ""%-6s %4d %s\n""   }   FNR == 1 { next }   NF > 0 {   time = $2     $1 = $2 = """"   s = sprintf(""%6s~%s"", time, $0)     a[ s ]++   }   END {     for (i in a) {       split(i, b, ""~"")       printf F, b[1], a[i], b[2]       total += a[i]       if (i ~ /COMPLETED/)         done    += a[i]       else         notdone += a[i]     }   # sort these lines to the end   printf ""~\n""   printf F, ""~"", done,    ""  DONE""   printf F, ""~"", notdone, ""  NOT DONE""   printf F, ""~"", total,   ""  TOTAL IN CACHE""   }'  | sort  | sed 's/^~/ /'           This script will give you a display such as the following:       122:59   27   COMPLETED REPORTING 125:47  101   COMPLETED REPORTING 137:15   93   COMPLETED 137:15  125   COMPLETED REPORTING 150:26    1   RESERVED 150:26    4            5   NOT DONE         346   DONE         351   TOTAL IN CACHE          This display tells us that we need to connect to the server soon as we only have 5 blocks to go before running out!  The numbers down the left column are the number of hours and minutes left before that block expires.  The middle column is the number of blocks with that specific expiry.  The rest of the line is a status, with ""RESERVED"" being the block currently being worked on and no status means that the group has not been started yet.        Stats, Numbers and Graphs     As we have mentioned elsewhere, the Cyberian group pay more attention to the statistics and graphs, which we tend to think are more fun for people.    Both groups tend to pay alot of attention to the blocks already completed.  This is like saying that someone has bought 10,000 losing lottery tickets vs. someone else who has only bought 10. The prize is not given to the group with the most losing tickets! Both teams have an equal chance of buying the next winning lottery ticket!!    More important is  the current rate  at which the  tickets  are being bought, or in our case, the rate at which  key blocks  are being checked.    If you compare teams on that basis, it gives a more realistic relative probability on which team will find the secret key and win the prize money.    Having said all that, watching the numbers and the graphs, and comparing your team's numbers with other teams is all part of the fun.    The    Bovine stats  recently had an overhaul but is still only updated once per day. For example: only team statistics are shown, without mentioning individual efforts.    The    Cyberian stats  and their    search facility  are a joy to use.  They provide almost instant feedback for anyone getting involved as you can usually find your entries within minutes of contacting the server.  You can also see how your contribution has helped the overall team effort.         Who?      So Where do I Sign Up?    Why two teams?  Why don't we just join up with the other team, and combine our numbers?  We've been asked this probably the most since Eric Anderson started Team Linux.    The reason is that we feel that "" friendly "" rivalry will benefit both teams and help get people excited about getting involved.  The benefit to Linux will hopefully be greater participation and better visibility.    Both teams have the same main goals in mind with promoting Linux the highest on the list.  However, we both have different ways of going about this.    The  linux@linuxnet.org  team has plenty going for it.  It's been around a lot longer and has accumulated a much larger total number of blocks checked.  They have openly stated that they will donate the entire $1000 to Linux International if they win.  They seem to have two sets of Web pages and you can access the second set  here .    The  Team Linux  group have stated that they will donate all of any prize money or other revenue directly to a Linux group of the members' choosing.  Any administrative costs will be paid for out of our own pocket.  Since Team Linux is also involved in the Cyberian effort, the prize money may very well be $5000US for Team Linux, or $1000US if the key is found through the Bovine effort.    Team Linux is also in discussion with several companies about up-ing the anti, possibly by having them match the prize money available, or perhaps some other method which does not rely on chance nearly as much. We should have an announcement on this soon.    We would like to encourage you to get involved in either team and compete in the spirit of Linux, for the benefit of Linux. As long as the competition remains friendly, it will be healthy and help out.        The Future of Distributed Computing     Getting tens of thousands of computers working on a common problem is an awesome technical accomplishment.  It is made all the more interesting by the fact that the computers are spread out world-wide, some of them available full-time, some not, with different hardware and operating systems.  Having them all owned by different people and organizations, each with their own agenda and motivations adds yet another dimension to the task.     Some papers and sites on the topic of distributed systems and related subjects which we've found:       Condor  is a project at      University of Wisconsin-Madison      which has been going on for about 10 years.  They have published a number of      interesting papers      on what they call      High Throughput     Computing (HTC) .     They are the movers and shakers for the third group working on     the RSA Challenge called      Infinite Monkeys .    Yahoo      have a whole section devoted to      distributed computing .     There is a good collection of material here, with many universities being     represented.    The GREAT Internet     Mersenne Prime Search  is another way to use those spare cycles.    In Search Of The     Optimal 20 & 21 Mark Golomb Rulers    SETI@home  is     an effort to use spare cycles in the     Search for Extra-Terrestrial Intelligence (SETI).  It looks like this might     ramp up to be a  very big thing  by next Spring.  They are looking to     put hundreds of thousands of machines to work.   Let's make sure they do     a Linux client program!          As we all know, lots of cool research has come from the folks at      Xerox PARC       (Palo Alto Research Center) , including probably the first     windowing environment.  It's not surprising to find that they have      a     number of papers  on the subject.  There is one which looks particularly     interesting in a section called  allocating time on idle computers :    C. A. Waldspurger et al.,     Spawn: A Distributed Computational Economy, 1992 .     Unfortunately, it has been taken off-line.  I seem to recall something like     this published some years ago,     possibly in  Byte ,     although no reference could be found.       While researching the Xerox PARC site, we came across a section called the      Dynamics of     Computation Area .   You have to see this ,     if for no other reason, to see     the graphic depicting many  small distributed efforts  overtaking one      large effort !!             When?         Do it   now!!     It's easy.  You'll have plenty of help.  And once you are set up, you can let your system do the rest!                Copyright © 1997, Bill Duncan   Published in Issue 21 of the Linux Gazette, September 1997                                                          Copyright © 1997 Specialized Systems Consultants, Inc.  For information regarding copying and distribution of this material see the  Copying License .         ""Linux Gazette... making Linux just a little more fun! ""                       Contents:     About This Month's Authors   Not Linux                   About This Month's Authors                  Randy Appleton    Randy Appleton is a new professor in the Math and Computer Science department of Northern Michigan University. He typically teaches the higher lever C.S. classes, especially the operating systems classes. He has two dogs, two cats and speaks a small amount of German. He likes to SCUBA dive and has his very own pilots license.      Larry Ayers  Larry Ayers lives on a small farm in northern Missouri, where he is currently engaged in building a timber-frame house for his family. He operates a portable band-saw mill, does general woodworking, plays the fiddle and searches for rare prairie plants, as well as growing shiitake mushrooms. He is also struggling with configuring a Usenet news server for his local ISP.       Gerd Bavendiek  Gerd has worked as a software engineer with various flavors of Unix since 1988. In  1994 he realized that using Linux could make his every-day work more convenient. Since that time he has used Linux and various GNU-software. He lives in Essen, Germany.  In his spare time he builds model-steam engines using real hardware: lathe, milling-machine and a lot of hand tools.   John Daily   John Daily works for BBN (or is that GTE?) as a systems administrator/software engineer. He spends far too much time in front of computers, but when he's not, he prefers to be outside riding his new bicycle, or otherwise exploring New England.    Jim Dennis  Jim Dennis  is the proprietor of   Starshine Technical Services . His professional experience includes work in the technical  support, quality assurance, and information services (MIS) departments of software companies like    Quarterdeck ,    Symantec/ Peter Norton Group , and    McAfee Associates  -- as well as  positions (field service rep) with smaller VAR's. He's been using Linux since version 0.99p10 and is an active participant on an ever-changing list of mailing lists and  newsgroups.  He's just started collaborating on the 2nd Edition for a book on Unix systems administration. Jim is an avid science fiction fan -- and was married at the World Science Fiction Convention in Anaheim.       Bill Duncan   Bill has worked with Unix systems since the early Version 7 days on PDP-11's. He worked with Xenix hroughout most of the eighties and has also worked with many other flavors of Unix over the years, but his operating system of choice is now Linux.  When not working or fiddling with his four Linux systems at home (which is rare), he might have some time left over for his other hobbies: his dog (Daisy), photography and Amateur Radio. He can be reached at  bduncan@BeachNet.org .       John Fisk  John Fisk is most noteworthy as the former editor of the  Linux Gazette . After three years as a General Surgery resident and Research Fellow at the Vanderbilt University Medical Center, John decided to "":hang up the stethoscope"":, and pursue a career in Medical Information Management. He's currently a full time student at the Middle Tennessee State University and hopes to complete a graduate degree in Computer Science before entering a Medical Informatics Fellowship. In his dwindling free time he and his wife Faith enjoy hiking and camping in Tennessee's beautiful Great Smoky Mountains. He has been an avid Linux fan, since his first Slackware 2.0.0 installation a year and a half ago.      Sam Trenholme   Sam Trenholme has been using Linux since June 19, 1995.  He sees Linux as a very powerful tool for communicating and maintaining connections with people.  His goal is to eventually obtain a Master's degree in Computer Science.                   Not Linux               Thanks to all our authors, not just the ones above, but also those who wrote giving us their tips and tricks and making suggestions. Thanks also to our new mirror sites.       My assistant, Amy Kukuk, did all the work again this month. She's so good to me. Thank you, Amy.   Our beautiful new logo was designed by our very own Graphics Muse, Michael J. Hammel. (He used The Gimp.) Thanks, Michael.   Well, this is the last issue that Amy and I will be working on. We are turning over the editorship to Viki Navrotilova. Here's a bit about Viki:     Viktorie Navratilova has been using Linux for the past 4 years, and has been active in both the Israeli and Chicago Linux Users' Groups. She started using Linux because of its network capabilities, and then stayed for the compilers.      I know Viki will have as much fun as we have and do a wonderful job. Show your support and send her lots of articles.     LG  will remain under the guardianship of  Linux Journal  and neither the web address or e-mail address will change. Articles from  LG  will continue to appear in  LJ .      Have fun! Bye-Bye!           Marjorie L. Richardson  Editor,  Linux Gazette   gazette@ssc.com                     Linux Gazette  Issue 21, September 1997, http://www.ssc.com/lg/   This page written and maintained by the Editor of  Linux Gazette ,   gazette@ssc.com"
GX116-76-13006973	"README for XFree86 4.0.1 on OpenBSD    :   Running X   Previous:   Configuring X for Your Hardware   Next:   Kernel Support for X         6. Running X     6.1. Starting xdm, the display manager   To start the display manager, log in as root on the console and type: `` xdm -nodaemon ''.   You can start xdm automatically on bootup by changing the line     xdm_flags=NO            # for normal use: xdm_flags=""""      to:    xdm_flags=""""            # for normal use: xdm_flags=""""      in  /etc/rc.conf .     Note that the binary distributions of XFree86 for OpenBSD on ftp.xfree86.org and its mirrors don't include support for the XDM-AUTHORIZATION-1 protocol, because of the US export  rules.     6.2. Running X without the display manager   The easiest way for new users to start X windows is to type: `` startx >& startx.log ''.  Error messages are lost unless you redirect them because the server takes over the screen.   To get out of X windows, type: `` exit '' in the console xterm. You can customize your X by creating  .xinitrc ,  .xserverrc , and  .twmrc  files in your home directory as described in the xinit and startx man pages.       README for XFree86 4.0.1 on OpenBSD    :   Running X   Previous:   Configuring X for Your Hardware   Next:   Kernel Support for X"
GX078-49-11410512	Node: Perfect Power Algorithm , Previous: Perfect Square Algorithm , Up: Root Extraction Algorithms      Perfect Power    Detecting perfect powers is required by some factorization algorithms.  Currently  mpz_perfect_power_p  is implemented using repeated Nth root extractions, though naturally only prime roots need to be considered.  (See  Nth Root Algorithm .)   If a prime divisor p with multiplicity e can be found, then only roots which are divisors of e need to be considered, much reducing the work necessary.  To this end divisibility by a set of small primes is checked.
GX010-89-0590832	Red-headed woodpecker                 Melanerpes erythrocepha
GX060-71-2368493	"April 2000, Issue 52       Published by  Linux Journal     Front Page   |   Back Issues   |   FAQ   |   Mirrors   |   Search                         Visit Our Sponsors:                                                                                                 Table of Contents:               The MailBag            Help Wanted & Article Ideas         General Mail           News Bytes            Distro News         News in General         Software Announcements           The Answer Guy  ,  by James T. Dennis       More 2-Cent Tips        Microsoft flip-flop  ,  by Mark Bolzern       HelpDex  ,  by Shane Collinge       A Fantastic Interview with Wine's Man Alexandre Julliard  ,  by Fernando Ribeiro Corrêa and Luis Strano       Linux Site O' The Month: Glade  ,  by Sean Lamb       ""Cannot execute /bin/bash: Permission denied"" - solved!  ,  by Ben Okopnik       Introduction to Shell Scripting--The Basics  ,  by Ben Okopnik       Linux Gazette art  ,  by Mike Orr       Exploring parsing and virtual machines with Python  ,  by Pramode C E       The Back Page            About This Month's Authors         Not Linux                                         TWDT 1 (gzipped text file)   TWDT 2 (HTML file)  are files containing the entire issue: one in text format, one in HTML.  They are provided  strictly as a way to save the contents as one file for later printing in the format of your choice;  there is no guarantee of working links in the HTML version.                   Linux Gazette ,   http://www.linuxgazette.com/   This page maintained by the Editor of  Linux Gazette ,   gazette@ssc.com      Copyright © 1996-2000 Specialized Systems Consultants, Inc.                 ""Linux Gazette... making Linux just a little more fun! ""             The Mailbag!    Write the Gazette at   gazette@ssc.com     Contents:     Help Wanted -- Article Ideas   General Mail                Help Wanted -- Article Ideas     Answers to these questions should be sent directly to the e-mail address of the inquirer with or without a copy to gazette@ssc.com. Answers that are copied to  LG  will be printed in the next issue in the Tips column.     Before asking a question, please check the  Linux Gazette  FAQ  to see if it has been answered there.               Mon, 13 Mar 2000 17:07:37 -0400  From: DoctorX < d0ct0r_x@hven.com.ve >  Subject: Suggestions    I am from Venezuela South America and I think that the next issue of ""Linux Gazette""  will contain something about Latin American Linux Distributions , and others project developed in Latin America    I am a leader of a project named HVLinux HVlinux is a project for make a venezuelan linux distribution based on slackware, it run for now in RAM ( version 0.2.2 ) but  the next version will run from HD.    HVLinux HOME :   http://www.hven.com.ve/hvlinux     this site is in spanish    It is only a suggestion    Wenceslao Hernandez C.                    Wed, 1 Mar 2000 06:47:02 -0800 (PST)  From: Jim Coleman < j_e_coleman@yahoo.com >  Subject: Free ISPs for Linux???    This isn't exactly a burning question but I'd be interested in knowing if anyone in the Gazette readership knows of a free ISP that supports Linux. All of the ones I've checked out so far require Windows and/or Internet Explorer.    Thanks!               Thu, 02 Mar 2000 08:24:30 GMT  From: Brad Ponton < alpha_bp@hotmail.com >  Subject: redhat 6.1 'hdc: lost interrupt' problems    i own a panasonic 24x CDROM, a quatum 2.5GB bigfoot  and recently purchased  a segate 17.2GB.    i am getting 'hdc: lost interrupt' constanly through the install ( which  ploads along for about 2 hours ) then ends in what i think is suppoed to be  text displayed, only the screen then starts displaying out of sync, drawing  lines across the screen which look like very large ( 2 inch, or 4 centimetre  ) and unreadable  letters.  thus the install ends. ( obviously incomplete )    other probs with computer which may have influeenced    a) to install the seagate was extremly hard requiring about an hours worth  on fiddling with ide cables and jumper settings, currently the quatum is  master of the primary ide, with nothing else, the cdrom is secondary master  and the seagate is secondary slave. this is about the ONLY way all devices  are detected properly AND the cd is able to boot.    b) -before the segate was installed- i have ( along with other a queer  'randomly order' file display in windows explorer for only some directories  ) not beenable to play audio cds, with them either not being detected by  windows 'cdplayer' or jumping from track to track when play is pressed,  without playing anything.  although data and video cd's continue to run  fine.    thank you for your time ( and possibly help )                Sat, 4 Mar 2000 01:07:37 +0100  From: Kjell Ø. Skjebnestad < autowern@c2i.net >  Subject: Help Wanted: XF86 3.3.6 vs ATi Rage 128    so. i need some help over here. X is not working properly with my spanking new ATi Rage 128-card (""bar code text""). here's what i have done so far:    downloaded XF86 3.3.6 (binary) (which supports ATi Rage 128) to my Win98 disk. installed a normal installation of Red Hat 6.1 (in text mode) to my linux disk. installed XF86 3.3.6 properly to my linux disk, taking great care not to overwrite the original `xinitrc' provided by Red Hat runned XF86Setup, configured everything there;the XF86Setup-test worked nicely runned `startx', which started Gnome etc. the Gnome Help Browser popped up, but the text... it was all like bar codes (that is, only horizontal lines). but occasionally, perfectly legible text popped up when scrolling. the words `Gnome Help Browser' in the title line was perfectly legible all the time. and yes, i have entered the correct sync rates for my monitor.  i presume this is a font problem, but the means to solve it i cannot begin to comprehend. yea, i have clutched my brain rather avidly trying to get my system working properly. i have even tried deleting the font-folder before installing XF86-3.3.6... and making sure that the font-folder was regenerated when installing XF86-3.3.6.     so. in summary, the main problem seems to be the weird behaviour of text when using X (""bar code text""). any help to solve this problem would be greatly appreciated.                 Sun, 05 Mar 2000 02:15:18 -0800  From: Dianne Witwer < dwitwer@innercite.com >  Subject: PLEASE HELP ME!    All right, I have the boot disk failure on my computer. And I was readding the article and I dont have a boot disk or a back up disk.  But can I just reinstall windows somehow without using a boot disk. Thanx     Josh                Mon, 6 Mar 2000 14:51:05 -0000  From: Anthony W. Youngman < Anthony.Youngman@ECA-International.com >  Subject: RE: Clenning(sic) lost+found    I notice Ed said ""it's often the sign of serious disk corruption"". May I beg to disagree? Note that ALL of the files in lost+found are of type b or c. I don't know why or how this corruption occurs, but I found that (1) I couldn't delete them, and (2) the machine gaily carried on working with no sign of any problems.    The problem only went away when the computer was scrapped - it was a 386 and was replaced with a 686MX.     [It sounds like we agree.  Perhaps I wasn't clear.  Really weird  permissions like  ""c-wx--S-w-""  that no sane person would ever do even in their stupidest moments can be a sign that some hardware fault has zapped the system.  Data corruption is the result, not the cause. The goal is then to find the cause or scrap the computer.  Perhaps the cause was a one-time thing, as apparently happened in your case.     The files that wouldn't delete may have had their immutable or undeletable attribute set.  The command  lsattr  (see manpage) shows which attributes a file has, and  chattr -i -u  will remove those attributes.  Attributes are like permissions but refer to additional characteristics of files in the ext2 filesystem. However,  lsattr /dev  spews out a whole lot of error messages, so it may be that the command won't help with device files (""b"" or ""c"" as the first character of a  ls -l  entry.) -Ed.                Wed, 08 Mar 2000 11:43:04 -0700  From: T.J. Rowe < tjr@ida.net >  Subject: man-db package compilation problems    First of all, I'd just like to thank all those who replied to my previous postings here at LG and got me unstuck. =)  I only like to resort to asking when I've exahsted all my own ideas.  That being said, I've come up across another interesting challenge to which I've yet found no solution.  Here's the deal:    In compiling the man-db package (as at least one reader correctly guessed, yes, I'm following the LFS linux from scratch howto from here at LG), I get the follow compilation error using both pgcc 2.95.2 as well as egcs 2.91.66 on both my new linux partition and the ""main"" partition:   cp include/Defines include/Defines.old sed -e 's/^nls = .*/nls = all/' include/Defines.old > include/Defines make -C lib make[1]: Entering directory `/root/project/man-db-2.3.10.orig/lib' make[1]: Nothing to be done for `all'. make[1]: Leaving directory `/root/project/man-db-2.3.10.orig/lib' make -C libdb make[1]: Entering directory `/root/project/man-db-2.3.10.orig/libdb' gcc -O -DHAVE_CONFIG_H  -DNLS -I../include -I.. -I. -I-  -c db_store.c -o db_store.o In file included from db_store.c:44: ../include/manconfig.h:298: parse error before `__extension__' ../include/manconfig.h:298: parse error before `(' make[1]: *** [db_store.o] Error 1 make[1]: Leaving directory `/root/project/man-db-2.3.10.orig/libdb' make: *** [libdb] Error 2       Has anyone gotten this problem before?  Any ideas? :)                Thu, 9 Mar 2000 01:13:16 -0500  From: Kent Franken < Franken@requestfoods.com >  Subject:     I would really like to see case studies on switching to Linux form other platforms.    Here's our platform and some requirements and questions:    We currently use Windows NT Terminal Server Edition. How hard would it be to go to Linux?    - We have two TSE servers with approximately 30 users each logged in on average. In total, we have about 130 users but it is a manufacturing plant and many people share terminals.    - We use Citrix Metaframe, for Load Balancing and failover. Is there a product for Linux that offers this option?    - We use thin clients (Boundless (www.boundless.com) Windows CE terminals with RDP and ICA protocols) and no X.  I have not been happy with the CE terminals.  I was wondering if an X-term performed better?  You can really see how slow CE is if you just click on the start button and move the mouse up and down the program list.  I had an old PC with not enough RAM and the ICA client worked much better than the CE ICA client.  I just found www.ltsp.org and the x-terms look fantastic (you could do a whole article just on that project).    - Dependability. I have to reboot my TSE servers once a week.  Last week a new HP printer driver caused about 40 blue screens of death before we figured out what was going on.  Will Linux be better?    - Office productivity software.  If we are used to MS Office, what will it be like going to something like star-office?    - Anti-virus programs?  Is there an antivirus program to scan mail stores (sendmail POP server)?    - Security.  How good is Linux at keeping users honest?  With TSE you can delete or overwrite files in the system directories as a user.  Can't delete a system file? Just open it in Word and save it and watch us IS guys jump around.               Thu, 09 Mar 2000 19:27:53 +0100  From: Eva Gloria del Riego Eguiluz < evagre@jazzcyber.com >  Subject: HELP, PLEASE!    I have a problem with one partition of my hard disk. Yesterday I installed Red Hat 6.0 and everything was O.K. until I saw that I could not enter in one of my FAT32 partition.    In Windows '98, when I click on E: (the wrong partition) the message is ""One of the devices vinculated to the system doesn't work"" (or something like that, I read the message in spanish).    I tried to see the hard disk with Partition Magic 3.0 and the error message is:    ""Partition table error #116 found: Partition table Begin and Start inconsistent: the hard disk partition table contains two inconsistent descrptions of the partition's starting sector....""    I want to know if I have lost all the information in this partition or in the other hand a way to get the data again.    The other partition of the hard drive are O.K. and I can start Windows O.K. and Linux also, because the wrong partition isn't primary.    Thank you very much,                Sat, 11 Mar 2000 08:40:07 -0500 (EST)  From: Ahmadullah Asad < arasad@undergrad.math.uwaterloo.ca >  Subject: a question...    Hi,    I would like to download the postscript viewer from  http://www.medasys-digital-systems.fr/mirror/linux/LG/issue16/gv.html but I cannot connect to this German FTP site. Any help will be appreciated. Also I am totally ignorant of how to compile and run the source if I am successful in downloading this file. I would really appreciate if you can give me some info on that as well.    [Which distribution do you use?  It's included in Debian, and it should be included in all the other distributions as well. You can also get the .deb file and convert it to rpm or tgz using the alien program if you have it (in the package ""alien""). -Ed.]                  Mon, 13 Mar 2000 18:39:52 +0500  From: Choudhry Muhammad Ali < orbit@nettlink.net.pk >  Subject: VGA card Problem with Redhat 6.1    hi    I 've been running with  Linux 4 a few years now, using RedHat 6.0 distributions. I'm currently upgrading my computer with  RedHat 6.1. Recently, Redhat 6.1 Running fine, but one small problem with my vga card...6.1 not configure properly....set automatically my VGA Card on perverse version(sis 5 series)...my card is sis 6 +series     Does anyone have any ideas as 2 why this would b happening and how 2 correct it?    CMA                Tue, 14 Mar 2000 19:07:34 +0100  From: Laurent STEFAN < lstefan@europeenne-assurances.com >  Subject: MIME and mail ?    How to join a file (.html, .gif or whatelse) in a e-mail with the mail program ?    I'm using something like : # ./test.pl | mail someone@somewhere -s""something""    but it result only a full text report in the body.    regards.   The Editor wrote  Try the mpack program.  I haven't used it, but its opposite munpack works fine for me. -Ed.   Laurent responded  Thanks for mpack, it seems to be a good stuff but it doesn't works with MIME's type text/html. Maybe I need to add some headers (content-type:) to my file.    Now a good stuff :    I made a bash script that look like this for the mail process:   exec $PROG | mail someone@somewhere.somedom -s ""My subject Mime-Version: 1.0 Content-Type: Text/html  ""      And it works !    So, why not to add a 'boundary=...' with a Multipart/related in Content-Type and while we are at it a 'Content-Transfert-Encoding: BASE64' ?    If you can tell me where there's a BASE64 encoder ... That would be great !                   Thu, 22 Jul 1999 15:28:09 +0200  From: Sandeep     <  fuhrer6mill@yahoo.com >  Subject: Video Card AbigPRoblem    Hello there, i am sandeep from india and i have recently Bought a azza MainBoard with Built in Sound Card (Avance Logic 120) and Video Card (SiS-530(but chip is SiS-5595 (AGP with shared Ram ))) there is a very big problem Linux couldnot recognise the VRAM  on the shared Sdram MOdule originally allocated by Award Bios. The sound card also was not recognised by the new Linux 6.0 version but by 5.2v ver of Red Hat it was recognised as Sound Blaster not as my original card as u guys have bveen doing great work i thought that u would be able to solve my problem or direct me to those who can thankiing u guys u r really doing a great work bye My email address is fuhrer6mill@yahoo.com (i am calling from a cafe so please do not reply to any other e mail address than given above(fuhrer6mill@yahoo.com)                Tue, 22 Feb 2000 21:53:22 +0100  From: Wim van Oosterhout < vanoosterhout@email.com >  Subject: ISND PCI128 Trust    Ban anyone tell me how to install my ISDN adaptor? Kind regards Wim van Oosterhout                Fri, 17 Mar 2000 12:00:59 -0500  From: thesun < thesunray@hotmail.com >  Subject: Mailbag submission:  Help Wanted on Japanese text input    Hi,    I'm new to the Linux Gazette but not new to Linux, and I've had a hell of a time trying to find clear, step-by-step info about how to WRITE Japanese under RedHat Linux 6.1.  Part of the problem is that I don't READ Japanese well enough to sift through the Japanese sites, but I've found a program called ""dp/NOTE"" from OMRONSOFT which almost works--apparently, the program is supported by the Japanese version of RedHat 6.1, but I don't know what RPMs to download to get the thing to run under the English version...or even if it will run at all.  Are there fundamental differences between the Japanese and the English versions?  Should I set up a dual boot system?  Ideally, I'd like to just run English RedHat but have a program I can pull up that will allow easy romaji text input and then convert to hiragana, katakana, or Kanji.  There's a nice program by NJStar that does that, but it's (barf!) Windoze95 only.    Any suggestions or help would be greatly appreciated.    Thanks,    thesunray@hotmail.com                Fri, 17 Mar 2000 19:20:34 -0500  From: Clark Ashton Smith < CAS@FutureRealms.com >  Subject: Help with group rights and Netscape Composer    I've search deja news, Linux HowTos, and books, and I have not seen this error mentioned.  Makes me think it something on my end, but I can't figure out what it is.  I'm hoping someone can help.    I am running RedHat Linux 5.2 and Netscape 4.08.    I created a group called web and made a directory   /usr/local/webauth      I set the group and the SGID bit on that directory  chgrp -v web /usr/local/webauth chmod -v 2775 /usr/local/webauth      Now for the problem:    Anyone in the web group should be able to save into that directory.  With Netscape composer they can only edit files that already are in that directory!?!    If I use the ""Save As"" option in Netscape Composer to save into that directory I get the following error:    ""The file is marked read-only.""    The same error occurs using the ""Save"" option to save a new file to that directory.  BUT, if I open a file from that directory in netscape, edit it, and use the  ""Save"" option, it will write over the old file in that  directory.  I can edit any existing html files created  by anyone in the ""web"" group.    What on earth is going on?  The users belong to the web group and they can all create files in /usr/local/webauth  via the touch command or emacs.  The users all have a  umask of 002. The files they create with touch or emacs  are all are created   -rw-rw-r-- username.web filename      They can use emacs to open end edit each others files in /usr/local/webauth, but they can't create new files with netscape composer!  They can only edit existing files and save them to the same filename.    The only way I can get ""Save As"" and ""Save"" to create new files in /usr/local/webauth is to set the permissions to  chmod -v 2776 /usr/local/webauth    or   chmod -v 2777 /usr/local/webauth   which defeats the whole point of creating special work  groups and protecting the files from being written by  anyone not in the group.     If you can, please shed some light on this.  Thank you.               Mon, 20 Mar 2000 20:05:16 -0000  From: Tony < tony@exocomp.free-online.co.tony@exocomp.free-online.co.uuk >  Subject: connecting win98 and Linux    I am relatively new to Linux so please be patient. Can anyone tell me how to connect my win 98 machine with my Linux server. I used to run win 95 and had no problems but since using win98 overtime I try to browse my network from network neighbourhood I am unable to browse the network, I cannot ping the Linux server either. I am sure that I have TCP/IP installed correctly on both machines.  Any help anyone can give would be most helpful. Regards A newly.                Fri, 24 Mar 2000 16:23:30 +0300  From: Alexandr Redko < redial@tsinet.ru >  Subject: DNS for home mail not working    For some time I was following the guidelines of article by JC Pollman and Bill Mote ""Mail for the Home Network"", Linux Gazette #45 with the aim to build my verySOHO net.      Without DNS and sendmail I succesfully established dialup link with my ISP,    browsed the Net, send and received my mail.   With caching only DNS the dealings were equally succesfull, DNS dump showed    that caching really took place.   I installed sendmail and POP3 on my Linux server. No mail transport between    it (sasha.asup 10.0.0.5) and W95 client (10.0.0.101).   I created DNS config files with MX records and got it going but only within    the local network. No ping except with ISP server and no nslookups.      Here is my setup:  Linux Red Hat Cat 6.0  -------------------------------------------------------------  ""host.conf""  -------------------------------------------------------------  order hosts,bind  multi on  -------------------------------------------------------------  ""nsswitch.conf""  -------------------------------------------------------------  hosts:      files dns  -------------------------------------------------------------  ""resolv.conf""  -------------------------------------------------------------  search asup  nameserver 10.0.0.5  -------------------------------------------------------------  ""named.conf""  -------------------------------------------------------------  options {   directory ""/var/named"";     forward first;   forwarders {       196.34.38.1;       196.34.38.2;   };   /*    * If there is a firewall between you and nameservers you want    * to talk to, you might need to uncomment the query-source    * directive below.  Previous versions of BIND always asked    * questions using port 53, but BIND 8.1 uses an unprivileged    * port by default.    */  // query-source address * port 53;  };      zone ""."" {   type hint;   file ""db.cache"";  };     zone ""asup"" {   notify no;   type master;   file ""db.asup"";  };  zone ""0.0.10.in-addr.arpa"" {   notify no;   type master;   file ""db.0.0.10"";  };  zone ""0.0.127.in-addr.arpa"" {   type master;   file ""db.127.0.0"";  };  -------------------------------------------------------------  ""db.asup""  -------------------------------------------------------------  @       IN      SOA     sasha.asup. redial.asup.  (                                        1  ; Serial                                        10800     ; Refresh                                        3600      ; Retry                                        604800    ; Expire                                        86400 )   ; Minimum    IN      NS      sasha    IN      MX 10   sasha  sasha  IN A 10.0.0.5  sasha  IN MX 10 sasha  mail  IN A 10.0.0.5  www  IN A 10.0.0.5  news  IN A 10.0.0.5  localhost IN A 127.0.0.1  asup1  IN A 10.0.0.101  asup1  IN MX 10 sasha  -------------------------------------------------  ""db.0.0.10""  -------------------------------------------------  @       IN      SOA     sasha.asup. redial.asup.  (                                        1  ; Serial                                        10800     ; Refresh                                        3600      ; Retry                                        604800    ; Expire                                        86400 )   ; Minimum    IN      NS      sasha.asup.  5  IN      PTR     sasha.asup.  5  IN      PTR     www.asup.  5  IN      PTR     mail.asup.  5  IN      PTR     news.asup.  101  IN      PTR     asup1.asup.  ----------------------------------------------------------  ""db.127.0.0""  ----------------------------------------------------------  @       IN      SOA     sasha.asup. redial.asup.  (                                        1  ; Serial                                        10800     ; Refresh                                        3600      ; Retry                                        604800    ; Expire                                        86400 )   ; Minimum    IN      NS      localhost.  1  IN      PTR     localhost.  ----------------------------------------------------------  ----------------------  ""firewall""  ----------------------  :input ACCEPT  :forward REJECT  :output ACCEPT  -A forward -s 10.0.0.0/255.255.255.0 -d 10.0.0.0/255.255.255.0 -j ACCEPT  -A forward -s 10.0.0.0/255.255.255.0 -d 0.0.0.0/0.0.0.0 -j MASQ  ----------------------  # echo 1 > /proc/sys/net/ipv4/ip_forward ----------------------------------- /etc/sysconfig/network ----------------------------------- NETWORKING=yes FORWARD_IPV4=""yes"" HOSTNAME=sasha.asup DOMAINNAMEGATEWAY="""" GATEWAYDEV="""" ----------------------------------- With ppp0 up route ---------------------------------------------------------------------------- 10.0.0.5            *            255.255.255.255    UH    0    0 0    eth0 196.34.38.254   *                       255.255.255.255    UH    0    0 0    ppp0 10.0.0.0            *                   255.255.255.0      U      0 0    0    eth0 127.0.0.0          *                    255.0.0.0          U     0 0    0    lo default              196.34.38.254     0.0.0.0           UG  0     0 0    ppp0 ----------------------------------------------------------------------------    DNS debug when making nslookup for my ISP server: ---------------------------- datagram from [10.0.0.5].1026, fd 22, len 31 req: nlookup(www.tsinet.ru) id 1755 type=1 class=1 req: missed 'www.tsinet.ru' as '' (cname=0) forw: forw -> [196.34.38.1].53 ds=4 nsid`421 id55 3ms retry 8sec retry(0x4011e008): expired @ 953043527 (11 secs before now (953043538)) reforw(addr=0 n=0) -> [196.34.38.1].53 ds=4 nsid""50 id=0 3ms datagram from [10.0.0.5].1026, fd 22, len 31 req: nlookup(www.tsinet.ru) id 1755 type=1 class=1 req: missed 'www.tsinet.ru' as '' (cname=0) reforw(addr=0 n=0) -> [196.34.38.2].53 ds=4 nsid`421 id55 3ms reforw(addr=0 n=0) -> [196.34.38.2].53 ds=4 nsid""50 id=0 3ms datagram from [10.0.0.5].1026, fd 22, len 31 req: nlookup(www.tsinet.ru) id 1755 type=1 class=1 req: missed 'www.tsinet.ru' as '' (cname=0) ----------------------------      I'll be very greatful if someone say me what I done wrong.    Regards to  All   Bill Mote wrote     I appreciated the depth to which you went in talking about your invironment, however, I'm confused about what your problem is.  Can you tell me exactly what isn't working and what you're trying to do please?  I'd love to help!   The Editor asked whether the problem had been solved, and Alexandr wrote      Thank you for attention to my petty problem. Sorry to say that I'm in no way closer to it's solution then in the beginning. I got two letters (thanks very much ) from JC Pollmann:   Pollman's letter #1     A number of things could be causing the problem:    ""db.asup"" ------------------------------------------------------------- @       IN      SOA     sasha.asup. redial.asup.  (                                       1  ; Serial                                       10800     ; Refresh                                       3600      ; Retry                                       604800    ; Expire                                       86400 )   ; Minimum    IN      NS      sasha   IN      MX 10   sasha sasha  IN A 10.0.0.5 sasha  IN MX 10 sasha  mail  IN A 10.0.0.5 www  IN A 10.0.0.5 news  IN A 10.0.0.5       I know they say otherwise, but try using CNAME, eg:  mail IN CNAME 10.0.05     localhost IN A 127.0.0.1  asup1  IN A 10.0.0.101 asup1  IN MX 10 sasha ------------------------------------------------- ""db.0.0.10"" ------------------------------------------------- @       IN      SOA     sasha.asup. redial.asup.  (                                       1  ; Serial                                       10800     ; Refresh                                       3600      ; Retry                                       604800    ; Expire                                       86400 )   ; Minimum    IN      NS      sasha.asup. 5  IN      PTR     sasha.asup.     you can not use CNAMED names for reverse lookup   5  IN      PTR     www.asup. 5  IN      PTR     mail.asup. 5  IN      PTR     news.asup. 101  IN      PTR     asup1.asup.      make those changes and do a named restart and see what happens.    Pollman's letter #2     copy this to your rc.local file and reboot:   echo ""setting up ipchains"" echo ""1"" > /proc/sys/net/ipv4/ip_forward # allow loopback, always /sbin/ipchains -A input -i lo -j ACCEPT # this allows all traffic on your internal nets (you trust it, right?) /sbin/ipchains -A input -s 10.0.0.0/24 -j ACCEPT # this sets up masquerading /sbin/ipchains -A forward -s 10.0.0.0/24 -j MASQ  #you need this for ppp and dynamic ip address echo 1 > /proc/sys/net/ipv4/ip_dynaddr     Alexandr continues     I did my home work:   --------------- named.conf --------------- options {  directory ""/var/named"";  forwarders {      forward.first;      195.34.38.1;      195.34.38.2;      195.34.38.1;  };  /*   * If there is a firewall between you and nameservers you want   * to talk to, you might need to uncomment the query-source   * directive below.  Previous versions of BIND always asked   * questions using port 53, but BIND 8.1 uses an unprivileged   * port by default.   */  query-source address * port 53; };  // // zone ""."" {  type hint;  file ""db.cache""; };  zone ""asup"" {  notify no;  type master;  file ""db.asup""; };  zone ""0.0.10.in-addr.arpa"" {  notify no;  type master;  file ""db.0.0.10""; };  zone ""0.0.127.in-addr.arpa"" {  type master;  file ""db.127.0.0""; }; ------------- db.asup ------------- @       IN      SOA     sasha.asup. redial.asup.  (                                       1  ; Serial                                       10800     ; Refresh                                       3600      ; Retry                                       604800    ; Expire                                       86400 )   ; Minimum    IN      NS      sasha   IN      MX 10   sasha sasha  IN A 10.0.0.5 sasha  IN MX 10 sasha  mail  IN CNAME 10.0.0.5 www  IN CNAME 10.0.0.5 news  IN CNAME 10.0.0.5  localhost IN A 127.0.0.1  asup1  IN A 10.0.0.101 asup1  IN MX 10 sasha ------------------------- db.0.0.10 ------------------------- @       IN      SOA     sasha.asup. redial.asup.  (                                       1  ; Serial                                       10800     ; Refresh                                       3600      ; Retry                                       604800    ; Expire                                       86400 )   ; Minimum    IN      NS      sasha.asup. 5  IN      PTR     sasha.asup. 101  IN      PTR     asup1.asup. ------------------------- firewall ------------------------ :input ACCEPT :forward ACCEPT :output ACCEPT -A input -s 0.0.0.0/0.0.0.0 -d 0.0.0.0/0.0.0.0 -i lo -j ACCEPT -A input -s 10.0.0.0/255.255.255.0 -d 0.0.0.0/0.0.0.0 -j ACCEPT -A forward -s 10.0.0.0/255.255.255.0 -d 0.0.0.0/0.0.0.0 -j MASQ ------------------------ network ------------------------ NETWORKING=yes FORWARD_IPV4=""yes"" HOSTNAME=sasha.asup DOMAINNAME= GATEWAY= GATEWAYDEV= ------------------------      I connect to my ISP by issuing "" ipup ppp0 "" command, and then my luck ends:     ifconfig reports that my remote address is 195.34.38.254 (ISP's primary and secondary DNS being 195.34.38.1 and 195.34.38.2) (by the way: why it is always so, I thought that ISP get dynamic IP for me from some pool and they must differ from connection to connection);   ip forward is set;   route says that 195.34.38.254 is my default route;   ping for addresses 195.34.38.1, 195.34.38.2 and 195.34.38.254 goes throgh;   ping for loop and local network 10.0.0.0/255.255.255.0 goes through;   nslookup for loop and local network goes through;   mail goes both ends between Linux box (10.0.0.5) and PC with Win98 (10.0.0.101);   no ping except given above to external internet and no lookups there.      Here is excerpt from tcpdump output:   12:39:23.442252 ppp0 > sasha.asup > 195.34.38.1: icmp: echo request 12:39:23.644703 ppp0 < 195.34.38.1 > sasha.asup: icmp: echo reply .......... 12:39:27.434735 ppp0 > sasha.asup > 195.34.38.1: icmp: echo request 12:39:27.574701 ppp0 < 195.34.38.1 > sasha.asup: icmp: echo reply 12:39:28.014857   lo > sasha.asup.1052 > sasha.asup.domain: 30612+ PTR? 10.0.41.198.in-addr.arpa. (42) 12:39:28.014857   lo < sasha.asup.1052 > sasha.asup.domain: 30612+ PTR? 10.0.41.198.in-addr.arpa. (42) 12:39:28.015356 ppp0 > sasha.asup.domain > 195.34.38.1.domain: 37592+ PTR? 10.0.41.198.in-addr.arpa. (42) ............ 12:39:29.434740 ppp0 > sasha.asup > 195.34.38.1: icmp: echo request 12:39:29.564708 ppp0 < 195.34.38.1 > sasha.asup: icmp: echo reply   13:26:31.045625   lo > sasha.asup.1075 > sasha.asup.domain: 31874+ PTR? 90.10.8.128.in-addr.arpa. (42) 13:26:31.045625   lo < sasha.asup.1075 > sasha.asup.domain: 31874+ PTR? 90.10.8.128.in-addr.arpa. (42) 13:26:31.046140 if21 > sasha.asup.1071 > 198.41.0.4.domain: 16489+ PTR? 90.10.8.128.in-addr.arpa. (42) 13:26:31.464747 if21 > sasha.asup > 195.34.38.1: icmp: echo request 13:26:31.604706 if21 < 195.34.38.1 > sasha.asup: icmp: echo reply       I got it so that there is some problem with masquerading and my packets just don't go any further than my ISP's server.    Regards to  All               Fri, 24 Mar 2000 19:13:08 +0200  From: Ivanus Radu < ivanusra@cs.ro >  Subject: I need an answer, pls help me    Hello!    I am proud to announce this: ""I'm a 4 day Linux admin, and i'm doing ""fine"" :) ""    OK. Now to the important problems:    1. I've found that in the Net3-4 HOWTO : ""If you are interested in using Linux for ISP purposes the I recommend   you take a look at the Linux ISP homepage for a good list of pointers   to information you might need and use."" in Net3- HOWTO I found this : ""11.  Linux for an ISP ?      If you are interested in using Linux for ISP purposes the I recommend   you take a look at the Linux ISP homepage     for a good list of pointers to   information you might need and use.""   but the link is broken...   Q: What now? (I am interested in making linux for ISP purposes) 2. A Winmodem solution for Linux users.    If U are luky to have an win9x sistem connected to the linuxbox trought an network card, then do this:    -  install a Wingate like SyGate 2.0 for Win on the Win9x box    -  In Linux make Default Gateway to link to the Win9x box IP   That's all for the moment :)    TNX  bye.                 Fri, 24 Mar 2000 17:29:16 -0800 (PST)  From: Michael Dupree < dimebag2go@yahoo.com >  Subject: HELP!!!!!!!!!!    i need some help if u can do so please do.   when i am in a chatroom and stuff on aim people use booters witch create errors i need a patch for aim that will stop these errors if u can please do      [What's ""aim""?  Is it a Linux program?  We publish only questions dealing with Linux-related issues.  Also, are these ""errors"" things which crash the browser or are you simply trying to prevent the roommaster from booting you out when maybe s/he has a legitimate reason for doing so?    If you really have a program with a bug in it, we need to know what the program is, who makes it, whether it's standalone or runs with a web browser, under what circumstances the error occurs, what error messages you get, and what kind of computer and version of Linux you have. -Ed.]                   Fri, 24 Mar 2000 22:37:50 -0500  From: Walter Gomez < lulu@erols.com >  Subject: HP682 C jet ink color printer    My 682C HP printer is not workin properly.  When a print signal is sent, the printer will move a page in and start flashing the yellow light but not print the file.  I have checked everything I could think about with no result.  Could you help me? Regards,                Fri, 24 Mar 2000 22:54:58 -0800  From: Taro Fukunaga < tarozax@earthlink.net >  Subject: Sendmail faster start up!    Hi,    I am having trouble with sendmail. I read an article in the Gazette dated a few? months? ago about setting up sendmail, but I'm still puzzled.    I am running MkLinux R1 (a RedHat 6.0 implementation) and sendmail takes forever to startup. Taking a cue from the article, I stopped the sendmail daemon, started up pppd, and then restarted sendmail. It started up much faster. Also I've noticed that if I don't have the pppd up,sendmail tries to ping my other computer (the two are connected by an ethernet and router). Both machines are at home. The other machine does not have ppp set up yet. Well if I don't want to start pppd immediately on boot, what can I do to make sendmail start up faster?              Sat, 25 Mar 2000 12:39:14 +0200  From: Serafim Karfis < serakar@vero.gr >  Subject: Linux as a  mail server    I am trying to find instuctions on how to use my Linux server as a mail server for my company.  I have a registered domain name, a permanent connecion to the internet and unlimited number of e-mail accounts under my domain name. Please keep in mind that I am a new Linux user, so any instructions have to be detailed for me to understand.  Thank you in advance.                 Sun, 26 Mar 2000 23:16:30 +0530 (IST)  From: nayantara < ndeep_b@yahoo.com >  Subject: insmod device or resource busy    Hi, I'm running 2.2.12.... I wrote a module that goes:  #define MODULE #include    int init_module(void) {  printk(""<1>It worked!\n"");  return 0; } void cleanup_module(void) {  printk(""<1>All done.\n""); }      now, i compile this and when i insmod it, it printk's It worked! but then gives me :could not load module device or resource busy. what am i missing? what resource is busy? (I looked through the FAQ's but didn't find anything.....so if i missed it please bear with me)    Thanks, Deepa               Tue, 28 Mar 2000 15:43:10 +0100  From: Luis Neves < luis.neves@netc.pt >  Subject: Xircom CE3 10/100 and Red Hat 6.1    Hello,    I have a toshiba laptop with Red Hat's 6.1 Linux installed. I also have a Xircom 10/100 Ethernet Adapter. I know that xircom doesn´t provide any drivers for Linux and the compatibility list regarding ethernet adapters from RH 6.1 doesn´t include xircom cards. Is there any workarround ? How can I get it to work ?    Thanks in advance,    Luis Neves.    luis.neves@netc.pt                Tue, 28 Mar 2000 16:16:49 GMT  From: hasan jamal < hasanjamal@hotmail.com >  Subject: Re: source code of fsck    I need the source code of ""fsck"", the file system checker under the  /sbin directory. I have searched most of the ftp archives related to linux and did not find anywhere. I got RedHat & SuSe distribution, in none of them I found. I would be grateful if anybody can give me the source code or the ftp  site.     Md. Hasan Jamal Bangladesh   The Editor wrote     It should be included in your distribution.  I know only Debian, so when I type ""dpkg -S fsck"" it shows me fsck and fsck.ext2 are in the ""e2fsprogs"" package.  (There are other fsck modules for different filesystem types in other packages, including ""util-linux"".)  Rpm (and yast?) do a similar thing but with different command-line options. Find the appropriate command on your system and it will show which package the program comes from.  Probably e2fsprogs*.srpm or util-linux*.srpm or a similar file will have the source you want.    Hasan responded     I got it in SuSE. Thanks a lot for such a quick reply.                 General Mail              Wed, 1 Mar 2000 11:45:34 -0600  From: Scott Morizot < tmorizot@adc.is.irs.gov >  Subject: Pine and Pico not ""open source""?    I just got around to reading the February edition of Linux Gazette.  I was more than a little perplexed by the claim in the article about nano that pico and pine weren't ""open source"".    While it's true that pine and pico aren't under the GPL, neither are many other open source stalwarts like sendmail and apache.  Even a quick read of the license    http://www.washington.edu/pine/overview/legal.html     makes it clear that the source can be used for any use, even commercial, that it can be modified, and that it can be distributed.  I certainly don't see anything that would prevent it from being considered open source.    Oh, and the source is available, of course.  Always has been.    And, although you can't get the pico source separately from the entire source tree, you can build just pico or, if your OS is one of the supported ones, download a pico binary for your systems from the unix-bin directory.    ftp://ftp.cac.washington.edu/pine/unix-bin/      Not that nano isn't a perfectly good editor and effort.  There can't be too many.  But keep the facts about pine and pico straight.    Scott Morizot < tmorizot@adc.is.irs.gov > wrote     Ummm.  GPL'ed software is protected under copyright also.  So is sendmail.  So is apache.  All of those licenses are licenses to use copyrighted software.  UW's is just another license to use copyrighted software.  But all free software protected by a license is copyrighted software and includes some sort of restrictions on its use.  GPL software is no less under copyright than software under any other license. In fact, copyright is what allows the GPL to make the restrictions on use that it does.  Software that is not under copyright is in the public domain and absolutely no restrictions may be made on its use at all.    I didn't see anything in the legal notice that would constrain the  redistribution of binary versions of pico.  And, in fact, binary versions  of pico are redistributed with most distributions of Linux.      While it's not GPL, I still fail to see any terms in the UW pine license that cause it not to meet the open source definition.    [The license does not allow you to distribute modified binaries of pine.  (Hint: all the Packages in your Linux distribution are ""modified binaries"", because they undergo customization to adhere to the distribution's overall standards.)  This is why it's not ""open source"".  Pine is not  included in Debian.  Instead, you install special packages which include the source and diffs and compile it yourself.  -Ed.                     Tue, 29 Feb 2000 11:40:06 +0100  From: Linux Gazette < gazette@ssc.com >  Subject: FAQs     The following questions received this month are answered in the   Linux Gazette FAQ :        Is it possible to receive the Linux Gazette in HTML format by email?                Thu, 2 Mar 2000 17:17:31 -0800  From: Systems Administrator < sysadmin@ssc.com >  Subject: Duplicate announcement on lg-announce    Some time ago you had trouble with your mailinglist (lg-announce). Your latest announcement was received twice, I therefore attach a text file with the headers from the two messages. I hope this will help you to fix the problem.       [The latest round of duplicates was caused by the same problem as  the ones last fall--a certain subscriber or their ISP had a  misconfigured mail program which sent the message back to  the list.  This address was in the middle of the Received: lines  of all the duplicate message samples we saw.      There are some mailers (Windoze?) which do not honor the  envelope-to field of forwarded mail as they should, but instead think  they should send it to everybody in the To: header--even though this  has already been done.  And majordomo's code to detect this sort of loop  appears to be broken.  While we work on a solution at the software  level, we have unsubscribed that address and complained to the user and  his/her postmaster.     The two cases involved different users on different continents.  So we cannot guarantee it won't happen again, but will continue to  unsubscribe addresses as they are detected. -Ed.                     Fri, 3 Mar 2000 01:38:37 -0800 (PST)  From: Matthew Thompson < mattyt@oz.net >  Subject: Microsoft OS's, their pricing and Linux    Greetings,    Perhaps someone has brought this up before, but I have YAMSCT (Yet another Microsoft conspiracy theory :).  Maybe this whole thing about them not being able to combine the NT kernel with the Win9x series of OS's is a ruse.      If they did that, based on the current anti-trust scrutiny, they'd have to lower the price of WinNT/2000/whatever to the price of Win98/ME. They'd never be allowed to force home users to pay the premium price that businesses are now paying for Win2KPro on the desktop.    So as long as they have 2 separate product lines, they can charge basically double for Win2000 that gets sold to businesses.  They would completely lose those higher profit margins if they merged the products.    I know I'm preaching to the proverbial choir, here, but it will take Linux to end this.  But only when you can have it *all* (I'm typing this from a telnet session to my Debian box from Win98SE, since I want to use all the features of RealPlayer 7, java, Diablo and Descent 3).  I'm hopeful that Mozilla will cure the java problems under Netscpape (does anyone know if this will be the case?), more games are coming out for Linux all the time, but what about multimedia apps?  Is there Free project out there to fill this gap?  I haven't heard anything about Real releasing a fully functional RealPlayer for Linux, especially as a plug-in.    As much as it pains me to say it, right now I'm afraid Linux *is* lacking on the desktop. Here I am, a Linux evangelist (practically a zealot, ask my friends) and I spend more time in Win98 than I do Linux because of the games and internet apps available.    What can we do about this?  Is it enough to send emails to companies like Real to get them to release the same software for Linux that they do for Windows?  We certainly can't expect MS to release Media Player 6.4 (which *is* an excellent app, btw) for Linux.               Fri, 3 Mar 2000 16:05:32 -0700  From: Jim Hill < jimhill@meldrick.swcp.com >  Subject: Drop that comic strip pronto    The guy doing your strip can't draw and isn't funny.  One can conceivably get away with a lack of either skill or humor but certainly not both.    Thanks for your 15 seconds.       [Since the  Gazette  is a do-it-yourself enterprise, if you   don't like something, it's up to you to send in something better. :)  -Ed.]                  Mon, 6 Mar 2000 20:33:03 -0800  From:  < fuzzybear@pocketmail.com >  Subject: RE: Who is Jim Dennis?       From SeanieDude on Tue, 21 Sep 1999    Why the f*ck is your name listed so damn much in hotbot?      Dear SeanieDude:    The reason the Godfath... err, Mr. Jim Dennis appears so often in a HotBot search is that, as the current head of the Maf... err, a large syndicate, he is being investigated due to a totally unfounded accusation: namely, that everyone who has ever been rude to him, *particularly* via e-mail, seems to have suffered unfortunate accidents.    Should your precarious health NOT fail shortly, for some inexplicable reason, take this as a guide for your future behavior:    NEVER be rude to people you don't know anything about, in e-mail or otherwise.    Hoping that you're still around to take good advice, Consigliori Ben Okopnik                Thu, 9 Mar 2000 13:49:49 -0700  From: Vrenios Alex-P29131 < Alex.Vrenios@motorola.com >  Subject: RE: Article Submission    Mike Orr,    I have three articles on your web site so far and you might be happy to know that LG is an inspiration to me. This won't happen over night, but I am starting my own web site magazine about early computers and their use, at   http://www.earlycomputing.com/  . You probably have a good deal of experience with the issues surrounding such a venture so any words of wisdom would be greatly appreciated. (Mine will be more a labor of love than a money making enterprise.)    I look forward to contributing to LG again in the future in any event, as the focus of your site and mine are quite different. Thanks in advance.        [I'll help out if I can.  I only began editing the Gazette eight  months ago, and it's been around for five years.   So I can't say much  about starting an ezine; just how to keep it going.     I'm wondering whether you can get enough articles about early  computing to have a regular ""zine"", or if just a ""site"" where you can  post articles as you receive or write them would be just as well?  I am  surprised at how many people are willing to contribute to the Gazette.  Every month I used to wonder whether I'd get only a few articles that  month, but so far I've always gotten plenty to make a full zine.  But  that will be more difficult with a more specialized topic, and  especially at the beginning when you're not as well known.     Feel free to send me any other questions you have.  maybe we can  make an article or section in the Mailbag eventually about starting a  zine.  Maybe you'll feel like writing an article about your experience  setting up an early computer zine, how you're doing it  similar/differently than the Gazette, etc.  Not exactly Linux related,  but I'm the editor so I can put in anything I want.  Plus I know that  there is an interest in early computers among Linux folk: we got an  article about emulators recently and another person is also writing  another article about emulators now. -Ed.]                  Sun, 12 Mar 2000 20:52:18 -0500  From: Doc Simont < mdsimont@snet.net >  Subject: Gandhi quote    To Whom it may Concern --    I would be interested to know the source of the (great) quote that you use at the top of your web page:    ""One cannot unite a community without a newspaper or jounal of some kind.""    I am one of a number of volunteers who manage to produce a surprisingly high-quality monthly ""newspaper"" for our small town in NW Connecticut.  It might be something we could use, but our standards prevent us from taking attributions without verification.  Too often something attributed to Abraham Lincoln turns out to really have come from Dante (or vice-versa) ;-).    Any pointers toward the source would be very much appreciated.       [It's from the movie  Gandhi .  We don't know whether Gandhi  himself said it. -Ed.]                   Mon, 13 Mar 2000 09:49:26 -0700 (MST)  From: Michael J. Hammel < mjhammel@graphics-muse.org >  Subject: correction to your Corel Photo-Paint story    Stephen:    In your C|Net article on Corel's release of Photo-Paint for Linux,  ( http://news.cnet.com/news/0-1003-200-1569948.html ) you mentioned Gimp and Adobe as Corel's most likely competitors.  This isn't  exactly true.  First, Gimp has no marketing or business structure.  Not even a non-profit.  So, although its a terrific program, it lacks the exposure that a commercial application can get.  In the long run, this may hurt it.    (I actually toyed with the idea of trying to form a non-profit or even a for-profit to keep Gimp a strong product, but coming up with a business model for this type of application is difficult.  Its not likely selling the OS, where service and support can bring in significant income.)    Adobe's move into Linux is limited, so far, to its PDF and word processing tools.  Its not, as far as I know, doing anything about porting is graphics or  layout applications (though Frame is probably considered a layout too by many).  Corel's not really competing with Adobe in graphics on Linux yet.      Mediascape  is about ready to launch its vector based ArtStream for Linux next month.  This will be the first entry into the Linux layout tools market.  Not long after that, Deneba (www.denebe.com) is expected to launch their Linux version of Canvas 7, a popular Mac image editing tool with vector, layout, and Web development features.  These would be Corel's main competitors in the vector graphics arena.  Gimp remains a competitor in the raster-based image editing front, but the lack of prepress support and and organizational structure could eventually become a problem.               Fri, 17 Mar 2000 18:36:30 EST  From:  < PoiPuPy@aol.com >  Subject: subscription    Hello, I'm looking to find a postal address to you...? I do volunteer work with an  inmate pen pal site:   http://members.xoom.com/crosllinked/index.htm  Today I received a request from an inmate, wanting any type of subscription  to any site who offers news on Linux Operating Sytems. Thank You for your time. Sandy       [Our address is:   Attn: Linux Gazette Specialized Systems Consultants, Inc. PO Box 55549  Seattle, WA 98155-0549   USA       ...but I'm not sure what that will gain him.  The  Gazette  is not available by mail, unless a reader (you?) would be willing to print it out and send it to him.  Otherwise, he would have to read it online or via the FTP files or a CD.    Of course,  Linux Journal  is available by mail if he wants that. A text order form is at   http://www.linuxjournal.com/subscribe/subtext.txt  which you can print and have him mail in. -Ed.]                 Wed, 22 Mar 2000 08:12:40 +0100  From: Morgan Karlsson < morgan.karlsson@nordiskcarbonblack.se >  Subject: translation of linux gazette articles    Hello, My name i Morgan Karlsson and I'm a new member of the se.linux.org family. I wonder if it's ok to translate articles from you to swedish and publish them  on our website  www.se.linux.org ? Or even if we get enough people working with it translate every number of you  fantastic magazine in swedish. What do you think about this?         [Certainly.  We welcome translations. When your site is ready, please fill out the form at   http://wwwlinuxgazette.com/mirrors.html  so that we can add the site to our mirrors list and people will be able to find you. -Ed.]                     This page written and maintained by the Editor of the  Linux Gazette . Copyright © 2000,  gazette@ssc.com   Published in Issue 52 of  Linux Gazette , April 2000      ""Linux Gazette... making Linux just a little more fun! ""              Contents:     Distro News   News in General   Software Announcements                           April 2000  Linux Journal         The April issue of  Linux Journal  is on newsstands now. This issue focuses on the Internet.     Linux Journal  has articles that appear ""Strictly On-Line"". Check out the Table of Contents at   http://www.linuxjournal.com/issue72/index.html  for articles in  this issue as well as links to the on-line articles.  To subscribe to  Linux Journal , go to   http://www.linuxjournal.com/subscribe/index.html .       For Subcribers Only :  Linux Journal  archives are available  on-line at    http://interactive.linuxjournal.com/            Distro News                SuSE and Mandrake         NUREMBERG, Germany, PASADENA, USA and METZ, France - 2/14/2000 - SuSE Linux AG, MandrakeSoft and Linbox Inc. are joining forces to develop Linux Network Computing and bring it to the broadest audience. SuSE Linux AG, MandrakeSoft and Linbox Inc. are partnering to develop and include in future versions of Linux distributions the key technologies of the Linbox Network Architecture. All SuSE Linux and MandrakeSoft users will soon be able to set up efficient diskless Network Computing solutions based on Linux.     The Linbox Network Architecture is an open approach to Linux Network Computing based on diskless standard computers on the desktop side, such as the Linbox Net Station, and full featured servers, such as the Linbox Net Server. According to Jean Pierre Laisne', CEO of Linbox Inc., ""The Linbox Network Architecture allows users to bring the power of Linux to the desktop at minimal costs while still preserving the user's investments in Windows or MacOS software. Diskless Linbox Net Stations can be set up in a matter of minutes by users with no previous skills in the Linux environment and require no maintenance.""     Under the joint partnership, SuSE Linux AG, MandrakeSoft and Linbox will form an open project which will publish the specifications of the Linbox Network Architecture and the required software under open source licensing. Development will be held by the Linbox R&D center in the Lorraine region, France's pioneering region for Linux and Free Software. All Linux users and businesses are welcome to join the LNA open project.                  Best          Technology Center Hermia, Tampere, Finland - February 21, 2000    SOT will be releasing their Best Linux operating  system to English-speaking users worldwide for the first time. The press conference and publication will take place at  CeBIT 2000, Hannover, Germany at 10am, February 24.    ""The T-1 beta program was a success. We now have a good reason  to expect the same success with the final English release as  that we've had in Finland. I am sure that the release will  finally dispel the myth of Linux as a server-only operating  system, and will show Linux as a real contender for  the dominating OS. I hope to see you at the press-release  conference at CeBIT 2000"" said Santeri Kannisto, CEO, SOT.    The first English version is called Best Linux 2000. SOT  will begin shipping boxes after the release. Boxes will be  available from well-known Linux-resellers and book stores.  Additional information is available at the Best Linux web  site,  http://www.bestlinux.net     The Best Linux 2000 boxed set includes some new features never seen before in Linux. It includes lifetime technical  support and a free update service. Customers are shipped  the latest installation CD to guarantee their Best Linux  is always up-to-date. A boxed set includes also a 400 page  manual, an installation CD, a source code CD, a Linux games CD  and a software library CD providing an easy way even for home  users to start using a complete Linux system.                 Caldera            Caldera IPO Marks First Linux Disappointment                 Mandrake         INDIANAPOLIS - March 27, 2000 - Macmillan USA ( http://www.placeforlinux.com ) announced Secure Server 7.0 for professional server administrators.    Macmillan's new product is a secure Linux web server built within the new Linux-Mandrake(tm) 7.0 operating system.                 MaxOS (Alta Terra)             FREDERICTON, NB, March 17 /CNW/ - Mosaic Technologies Corporation and Alta Terra Ventures Corp. have announced an alliance that will see Mosaic's Linux training programs bundled with Alta Terra's MaxOS(TM) Linux operating system.    Bringing Linux to the everyday PC desktop user is a major priority of both Alta Terra and Mosaic.     To help Windows users make the transition to Linux, Mosaic, working with India's Sona Valliappa Group, will offer a Linux simulator, which runs in a Microsoft Windows(TM) environment. This allows users to go through the steps of installing and setting up Linux, without leaving Windows. Mosaic will follow up with training programs to help users with tasks within Linux itself.          Mosaic Technologies Corporation      Alta Terra Ventures Corp.                 SuSE          CeBIT, Hannover, Germany (February 22, 2000) - SCO  and SuSE Linux AG, today announced an agreement to offer SCO Professional Services to SuSE customers, worldwide. The new offering, along with SCO's global reach, will help extend SuSE's growth into new markets. The agreement marks the first time SuSE Linux AG has partnered for professional services on a global level.     The SCO Professional Services offerings are designed to help SuSE's customers and resellers to get started with planning, installation, configuration, and deployment of their new SuSE Linux systems.                 TurboLinux         Santa Cruz, California, March 13, 2000 - Lutris Technologies Inc., and TurboLinux Inc., today announced a joint effort to certify and distribute the Enhydra Java/XML application server for the TurboLinux operating system. The partnership creates a scalable Open Source foundation for enterprise e-business application development and deployment.      Lutris and TurboLinux will work together to promote the Open Source e-business platform.  Enhydra will be distributed on the TurboLinux companion CD and listed in the TurboLinux Application Directory as a premier development environment. Lutris will provide support, training and professional services for Enhydra applications running on TurboLinux.                News in General                Upcoming conferences & events              Colorado Linux Info Quest    April 1, 2000  Denver, CO    thecliq.org            Corel Linux Roadshow 2000    April 3-7, 2000  Various Locations    www.corel.com/roadshow/index.htm             Montreal Linux Expo    April 10-12, 2000  Montreal, Canada    www.skyevents.com/EN/            Spring COMDEX    April 17-20, 2000  Chicago, IL   www.zdevents.com/comdex            HPC Linux 2000 : Workshop on High-Performance Computing with Linux Platforms    May 14-17, 2000  Beijing, China    www.csis.hku.hk/~clwang/HPCLinux2000.html    (In conjunction with   HPC-ASIA 2000 : The Fourth International Conference/Exhibition on      High Performance Computing in Asia-Pacific Region)          Linux Canada    May 15-18, 2000  Toronto, Canada   www.linuxcanadaexpo.com            Converge 2000    May 17-18, 2000  Alberta, Canada   www.converge2000.com            SANE 2000 : 2nd International SANE (System Administration and Networking) Conference    May 22-25, 2000  MECC, Maastricht, The Netherlands    www.nluug.nl/events/sane2000/index.html            ISPCON    May 23-25, 2000  Orlando, FL   www.ispcon.internet.com            Strictly Business Expo    June 7-9, 2000  Minneapolis, MN   www.strictly-business.com            USENIX    June 19-23, 2000  San Diego, CA   www.usenix.org            LinuxFest    June 20-24, 2000  Kansas City, KS   www.linuxfest.com            PC Expo    June 27-29, 2000  New York, NY   www.pcexpo.com             LinuxConference    June 27-28, 2000  Zürich, Switzerland   www.linux-conference.ch                      Winners of Design Competition to Speak at Open Source  Convention          February 14th -- Software Carpentry is pleased to announce that O'Reilly  & Associates has invited the winners in each category of its design  competition to present their work at the 2nd Annual Open Source Software  Convention in Monterey, CA, July 17-20, 2000.      So far, 27 individuals and groups have indicated that they will be submitting a total of 39 designs. The deadline for first-round entries is March 31, 2000; for more information, see the Software Carpentry web site at:  http://www.software-carpentry.com                   RE: LinkUall.com Intro       My name is Arnold White and I have a free collaboration software called LinkUall. With LinkUall.com - you can use LinkUall to post events in your calendar, chat, create projects, download documents etc... all for free. I think this would be a great enhancement to your site, and invite you to visit  www.linkuall.com ! Please let me know what you think, and remember it's all free!                 Linux Support for Trisignal's Phantom Embedded Modem          HANNOVER, GERMANY, Feb. 28, 2000 -- TRISIGNAL Communications, a Division of Eicon Technology Corporation, today announced the availability of its Phantom (TM) Embedded Modem reference design for the Linux operating system.    This new, off the shelf, pre-ported design will be immediately available for license to OEMs, allowing them to quickly bring to market any product running Linux and requiring V.90 modem connectivity, such as Internet appliances. The embedded Phantom design comes with all the necessary modem code and engineering support required for final integration by the OEM. Manufacturers that license this embedded modem design can benefit from TRISIGNAL?s core software code which has an installed base approaching 20 million units.     http://www.trisignal.com .                Computer I/O announces the Easy I/O Server and partnership with MonteVista Software          Chicago, IL - February 29, 2000 -- Computer I/O Corporation, a provider of software and services that simplify network access to live and real-time data streams, today announced the release of the Easy I/O Server, a Linux-based network I/O server.  The Easy I/O Server is a flexible network I/O appliance that leverages the versatility of Linux and Computer I/O's new middleware technology  to bring cost-effective, real-time networked data streaming capabilities to embedded and enterprise application developers.    The Easy I/O Server delivers an entirely new approach to the creation and remote access of I/O servers, peripherals, and appliances for telecommunica tions, multi-media, or any other application utilizing real-time data streams. It's I/O middleware technology provides unified interfaces for applications, network access, and real-time data collection and transfer.  Computer I/O designed Easy I/O to allow application developers to quickly deploy and access a streaming data server without the need to understand low-level real-time and network programming issues. With its browser-based hardware configuration interface, and universal application programming interfaces, the Easy I/O Server helps reduce software development and maintenance costs, and cuts the time to market for new embedded and enterprise network data applications.     www.computerio.com                A new e-commerce server, and how the company uses Linux        Internet Technologies, Inc. (Inttek (TM)) has developed a highly effective E-Commerce System with the ability to work directly with Hell's Kitchen Systems CCVS.    For more information, visit our site:   www.penguincommerce.com .  Visit  www.megcor.com  for a working commercial example.  The megcor.com site sold almost $1000.00 in golf equipment the first weekend it went live.  More examples will be coming soon.    The System is hosted on a remote Application Server -- The only required on-site hardware/software is a PC and Web Browser.  No knowledge of HTML is needed.     Technical Overview:    Penguin Commerce uses proprietary Software Developed by Internet Technologies, Inc.    Penguin Commerce is based on the following:    Red Hat Linux (currently running on 5.2)    Red Hat Secure Server -- (based on Red Hat Secure Server with modification)    Our secure web servers run a customized version of the Red Hat Secure Server release. We continually upgrade and improve these servers for maximum security.    MySQL Database Engine    PHP Version 4 (including custom Inttek extensions)    Various types of Open Source Image processing software    PGP Encryption Technology    PGP is used throughout our E-Commerce solutions to provide security for sensitive data. For example, before customer credit card numbers are stored in the MySQL database, they are encrypted to ensure privacy in the event that the data transmission to the MySQL server is compromised.    Hell's Kitchen Systems CCVS (including custom network connection program)    HKS CCVS software runs on a separate server, connected to the secure web server via a private Ethernet connection utilizing non-routed IP addresses. This, plus aggressive packet filtering, guarantees that the CCVS server is available for connections from the secure server only. All access to the CCVS server is controlled to prevent unauthorized access to any credit card numbers stored in plain text form.    Connections to the CCVS software are made through the standard Linux inetd service, which calls an intermediary program to translate commands and output between the secure web server and the CCVS software. This intermediate software, written in C with the CCVS C language API, is designed as an extra layer of abstraction, insulating the web programmer from the details of credit card processing, and generalizing the credit card processing interface.  This will allow us to present a consistent interface to web designers and programmers, regardless of the details of our credit card processing implementation. Our intent was to keep the credit card intelligence on the CCVS server, not the web server.    An overview of the physical layout is as follows:   (Internet)           | General Firewall (running RedHat Linux)           | Apache Web Server running PHP4 and MySql (running RedHat Linux)           | Secure Server Running the RedHat Secure Server Distribution           | (Private Ethernet Segment)           | HKS CCVS Server Running CCVS and custom CCVS connection software (running RedHat Linux)           | Modem with phone line to connect to Vendors Merchant Account (For security purposes, the HKS CCVS Server will not accept incoming phone calls via the modem)       Milestone achievements of Inttek or Inttek engineers that involved Linux:      1991    David McGough began tracking progress of Linux as it evolved from Minix.    1993    First Linux installations (used Linux for Internet Gateways, E-mail servers, etc).    1994    Used Linux for application hosting and file serving (using SAMBA) for Lower Cape Fear Hospice, and related agencies.    1995    Installed 2.4GHZ wireless Network for Lower Cape Fear Hospice.    1995    Demonstrated Wireless Networking Capabilities at Chamber of Commerce Business Expo    1995    Development, sales and support of Servers and related ISP support equipment for Wilmington Internet Services Enterprises    1996 Incorporated as Internet Technologies, Inc.    1996    Development, sales and support of Servers and related ISP support equipment for ISAAC Internet    1996    Setup Wireless Test Link from top of Solomon Towers to ISAAC Internet.  Developed modified RedHat 3 system to interface reliably with    data radios.  Server included Firewall, web server, cgi support, etc.  Maintained Server remotely for over 16 months WITH NO CRASHES. The server was locked in a utility room on the 11th floor that we didn't have direct access to.  This is an indication in our confidence in the stability of the Linux server.    1996    Started installing point-to-point wireless LAN systems commercially.    1996    Installed aggressive Redhat Linux based Internet Gateway / Router for Wilmington Shipping company. This system provides an integrated solution for Internet Services, Network printing and file services, etc., to all 13 Frame-Relay-Linked US offices for Wilmington Shipping / Southern Overseas. Also, installed RedHat Linux based WAN systems for several Southern Overseas Offices. These systems used WAN interface adaptors from Sangoma, and all have maintained better than 99.5% uptime. These systems are still in use today.    1997    Designed, and started Installation of a very aggressive Wireless    LAN system for the Wilmington Housing Authority. Wireless links ranging from 115 KBPS to 3.2 MBPS to connect all WHA remote offices to the WHA main office, using a centralized repeating point. Developed Outdoor Enclosure systems to contain Radio / Data Equipment.  Use Redhat Linux based Servers for Routing.    1997    Inttek became an ISP (November). We are 100% RedHat Linux based (all dial-in servers, Internet servers, routers, etc).    1998    Inttek Launched Software development department.  Focus was on developing Web Based Applications.    1998    Developed the WECT Live Weather System and web based admin consoles for content and weather updates.    1998    Leased Rooftop of Solomon Towers and established our first Commercial Wireless Internet Access WMAN Repeating Station.  This Station currently provides 3.2Mbit Wireless Metropolitan Area Networking, T-1 speed wireless Internet Access in the down town Wilmington Area, Up to approx. 8 miles outside of Wilmington down the Hwy 421 Industrial Corridor.    1998    Developed remote controlled wireless Video / and weather monitoring system.  System connected wirelessly over a path of 10.5 miles from our downtown repeating station to an enclosure on the roof of    the Oceanic Restaurant in Wrightsville Beach.  System allowed us to remote control cannon video conferencing camera and receive live weather    information.  This data was posted to a web site.    1998    Designed, installed, and maintain the Wireless Citywide network for the town of North Myrtle Beach, SC.    1998   Became Authorized Wave Access Value Added Reseller    1999    Became Authorized Lucent WaveLan / Wave Access VAR (Lucent Acquired Wave Access)    1999    Became Authorized SCO Unix VAR    1999    Developed the WECT Web Classifieds System    1999    Installed 3.2 MBPS wireless link from downtown Wilmington to Bolivia.  This link provided 3.2 MBPS wireless data communication over a    path length of 18.5 miles.  The installation the main Brunswick County Municipal Complex with T-1 Internet Connectivity. This physical installation is located 450' up a radio communications tower, and uses RedHat Linux based routers!    1999 Installed 3.2 MBPS wireless link from Bolivia to Yaupon Beach, using a water tower as a repeating point. This is over a path of  11.5 miles. This repeater then connects to our Oak Island Office and provides Internet/WAN Access for our employees, dedicated clients,  and dialup clients.  The Yaupon Tower Repeater can provide wireless  Internet / Network connectivity for the majority of the island.  The Bolivia Tower Repeater has the potential to tie in all 19 Brunswick county municipalities to the main complex.    1999    Developed Linux based experimental region-wide weather monitoring system ( ilmwx.inttek.net ). This system was used extensively by the national hurricane center and the national weather service during Hurricane Flyod.    1999/ 2000    Extensive effort in development of web-based software and E-Commerce Applications.  Development of the Penguin Commerce E-Commerce System.     2000    Developed Water billing system (in MS Access) and developed Palm Pilot Application for data entry -- plan to port to Web Based Solution                  Qarbon.com and SuSE Inc. Debuts Linux Viewlet Project         Qarbon.com, the originator of Viewlets, and SuSE Inc, a leading international Linux distribution, announced the launch of Qarbon.com's ""The Linux Viewlet Project."" Viewlets are a Web innovation that changes help files and FAQ's into vivid and dramatic ""How To"" demonstrations that ""show"" rather than ""tell"" a user how to perform a specific computing task. The introduction of Viewlets to the Linux community allows Linux developers and users from around the world to create, use and exchange Viewlets, which answer thousands of questions. Keeping with the Linux spirit, Viewlets are free to everyone on the net. Qarbon.com's business model includes a free Viewlet development tool, advertising-based revenue sharing for Viewlet authors and participating web sites,and a Viewlet syndication process designed to promote the use of Viewlets across the web.    To see some of the first Viewlets built around SuSE's Linux 6.3 go to  www.teach2earn.com/linux/ . Viewlets are expected to be a boon to increasing the use of Linux as users and developers see how Viewlets solve problems, reduces help desk calls and facilitates installation and use.                 MyFreeDesk: coming soon to a Jordanian cybercafe near you          MINNEAPOLIS-March 15, 2000-  MyFreeDesk.com  announced today that Quality Internet of Jordan, Inc., a chain of Internet cafes in the Middle East, will offer ad-free versions of the MyFreeDesk.com web-based office suite on its computers beginning April 1, 2000. Quality Internet customers who traditionally visited the cafes to browse the Internet or play online games will now have the added benefit of a complete office suite of personal computer applications. MyFreeDesk includes a fully featured word processor, spreadsheet, presentation program, database, email manager and Web page editor.    Quality Internet charges its customers an hourly rate to use its computers. MyFreeDesk will receive 50 percent of Quality Internet's proceeds from customers who pay for the ad-free version of MyFreeDesk. Quality Internet expects to open 12 Internet cafes throughout the country of Jordan during the year 2000.                   Linux directories from MyHelpDesk          MyHelpdesk.com  unveiled directories of technical support and productivity information for 20 distributions of the Linux operating system and some of the most popular Linux applications. The free directories will include help for Linux Web browsers, graphical desktop environments and Linux utilities and add-ons.    Each one of the 20 directories contains the Internet's best resources on everything from searchable knowledge bases and FAQs, to upgrade information and bug reports, to training and tutorials. The 20 directories cover the most popular distributions of the Linux operating system, including Caldera Open Linux, Corel Linux, Debian, Linux Mandrake, MK Linux, Red Hat, Slackware, SuSE and WinLinux 2000.               Sair Linux and GNU certification news         Sair's complete Linux and GNU Certified Administrator (LCA)  level  of  exams  are  now available  worldwide  and  our  self-study  guide for Linux & GNU Installation and Configuration has sold close to 40,000 copies.   www.linuxcertification.com                LinuxMall: LPI certification          DENVER -   LinuxMall.com , is urging the adoption of certification standards developed by the Linux Professional Institute. The Linux Professional Institute (LPI) is an international non-profit organization dedicated to establishing professional vendor-neutral certification for the Linux Operating System.     Mark Bolzern, President of LinuxMall.com, is a member of the LPI Advisory Council and a sponsor of the organization. LinuxMall.com joins the company of other industry leaders like IBM, Caldera Systems, and Hewlett-Packard in supporting LPI's mission to certify the talent and hard work of Linux professionals throughout the world.    The first exam for LPI certification was launched in January 2000, offering an incentive program of Linux-related utilities to participants.  LinuxMall.com has donated over a hundred of incentive items-including t-shirts and Tux the penguin mascots-to participants who have completed the initial phase of testing.  In addition, LinuxMall.com provided the fulfillment and distribution of all prizes donated by other LPI sponsors.  ""Because of the neutrality of LPI certification, businesses will gain a higher level of confidence in the abilities of the professionals they hire,"" adds Bolzern. ""It's far more credible than certification standards established by a single company, such as the MSCE standard.""               LinuxMall: Dice.com job searches         DENVER - LinuxMall.com announces an agreement with EarthWeb's  Dice.com that will allow customized Linux job searches directly from the site by simply placing Linux in the job search string. LinuxMall.com will continue to enhance and improve job-related information such as training and education within the LinuxMall.com site.    Under terms of the agreement, LinuxMall.com becomes part of Dice.com's Custom Search Network, which is a targeted group of sites that use the Dice.com job search engine to power their job areas. LinuxMall.com becomes the 16th site to display Dice.com listings on their Web site through Dice.com's Custom Search Network, which includes Red Hat.com, Girl Geeks.com and UserFriendly.org.                LinuxMall: Penguin Power Playing Cards        In case you haven't been playing with a full deck...     Tux demonstrates once again that he's playing with a full deck and holding all the cards.    For those late nights at the office, relaxing at home with family and friends, or the perfect gift for the Joker who has everything (hmmm...), LinuxMall.com proudly presents Penguin Power and LinuxMall.com playing cards!    Tux appears in formal dress on face cards, befitting a Linux King, Queen or Jack. The Joker, however, may be in need of a decent haircut. But they're all waiting to be dealt in to your favorite game and fit neatly up most regular-sized sleeves.    These playing cards are just the latest addition to LinuxMall.com's vast array of Linux goodies. Be sure to check out the entire site; LinuxMall.com has everything from beach towels and buttons to bumper stickers and ""Born to Frag"" T-shirts.       http://www.linuxmall.com/shop/01840                  Linux Links          SiteReview.org  is a place where wensurfers review and rate web sites.  Go post some Linux reviews, and say something nice about  Linux Gazette . :)     http://joydesk.com  is groupware that provides web-based email, calendar, address book and task list services for web sites.  Prominent customers include FreeI.net and www.webmail.ca.freei.net.      IBM Unveils Linux-Based Supercomputer       An interview with MontaVista founder Jim Ready      Why Linux won't fragment like UNIX did     Coming soon, to a car near you: Linux-based Internet radios       Linuxcare Establishes Asian Operations      www.destinationlinux.com  encompasses everything related to Linux, from games, jokes, contests to Linux information (products, news, training, etc.).    On the FirstLinux site:        web.firstlinux.net : metacrawler dedicated to Linux information (A metacrawler is a search engine that searches several other search engines for you.)      A  web e-mail service  to rival Hotmail.  Read your mail from anywhere while supporting the Linux cause.      Linux Reviews : user-submitted reviews of Linux software.      Checklist for Linux newbies : things to consider before installing a  Linux system.       Neosystem  (France) provides turnkey application servers, training and consulting for Linux.      http://www.balista.com/njp/linux.htm  is a personal site by Nicholas Jordan, containing tips, links and advocacy.     LinPeople  is the Linux Internet Support Cooperative, a system of free technical support on IRC.  The channel is  #LinPeople  on  irc.linpeople.org:8001 .                   Software Announcements                KDevelop 1.1final         We are proud to announce the 1.1final version of KDevelop (http://www.kdevelop.org) . This version contains several new features  and many bugfixes. It is intended to be the last release for KDE 1.1.2. We want to concentrate our effort now for KDevelop 2.x (which will work on KDE 2.x).    Summary of changes (between 1.0final and 1.1final):        7 new application templates        KDE1 OpenGL                   KDE2 SDI     KDE2 mini     KDE2 MDI     QT2 SDI     QT2 MDI/QWorkspace     QT2 MDI/QextMDI      complete integrated internal debugger   extended documentation, inclusive a KScribble tutorial and example code   improved editor: visible bookmarks, comment/uncomment code in editor     window,support for multibyte character   improved other components: dlgeditor, classviewer   Htdig search engine support   translations (online help, manual) into many languages   better OS support: KDevelop is now available for Linux, NetBSD, FreeBSD, Solaris and Unixware.      Please see   http://www.kdevelop.org   for further information (requirements and download addresses) and   http://fara.cs.uni-potsdam.de/~smeier/www/pressrelease1.1.txt  for the official press release.                 PROGRESS SonicMQ ADDS SUPPORT FOR LINUX         NEW YORK-iEC 2000-February 29, 2000-Progress Software Corporation today announced the Developer Edition of its award-winning Progress(r) SonicMQ(tm) Internet messaging server will support the Linux operating system.    ""We really wanted to try running SonicMQ on Linux,"" said Michael Quattlebaum, director of R&D at ChanneLinx.com, a provider of complete e-commerce solutions by linking industries into an interoperable digital marketplace.  ""I installed it on my Linux server, had it up and running in no time and it worked like a dream.  Because SonicMQ is 100% Java, it can run with little or no configuration changes on any platform with a supported JVM. SonicMQ has been great to work with -- a clean implementation of the JMS specification with the added tools needed to make it practical.""    SonicMQ is the first-and to date the only-standalone messaging server available from a major software vendor based on Sun's specification for Java-based messaging, Java Message Service (JMS).  By providing a standards-based reliable and scalable messaging infrastructure for Internet application interoperation, together with key standards beyond the JMS specification such as eXtensible Markup Language (XML), SonicMQ ensures business-to-business transactions are successfully completed.     www.progress.com                  Other software          Garlic  is a free molecular visualization program, for viewing proteins and DNA.     Mahogany 5.0  e-mail and news client for X11 (GNOME or KDE).    Opera Software has released a  i  tech preview  (that means  alpha) version of their web browser Opera.    Java products that run on Linux:        ENHYDRA open source Java/xml application server         J/Link, The Java-Mathematica Connection                    This page written and maintained by the Editor of the  Linux Gazette . Copyright © 2000,  gazette@ssc.com   Published in Issue 52 of  Linux Gazette , April 2000      Contents:   Greetings From Jim Dennis        graphic chipset Linux/CA-810 --or--  Linux on an Intel ""Camino"" CA810 Motherboard    March Linux Gazette blurb --or--  When ""Quit Confirm"" Dialogs are NOT Enough...    When you burn an ISO image to a CD... --or--  What to do with .ISO files    Where did it go --or--  Can't Format ""Network"" Drive to do Install    hardware error li_ --or--  Linux Gazette Answer Guy Privacy Statement    libguile --or--  A Be-GUILE-ing Question    co-processes --or--  zsh Co-processes    virtual console login --or--  Console Logins Fail; KDM Okay?   Or: System Integrity Checking  Redhat display --or--  Simple: Change X Resolutions on the Fly    2c Tip: Show TCP/UDP port usage --or--  Cross Comment: 2cent Tips    Communicting between subnets with no router :-? --or--  Routing Mystery    Question --or--  Shutting Down the ""ping Daemon""    LILO Windows boot --or--  Keeping Both Hard Drives Connected   New LILO Overcomes 1024 Cylinder Limit!  Icewm and open xterm with root rights --or--  ICEWM Key Bindings (Macros) and X in ""Toaster"" Mode    LI Problem (Answered) --or--  LILO Stopping at LI  ---  LBA and ""linear"", or NOT    Lost Password --or--  Simpler Way to Recover From a Lost Password    source code of fsck --or--  Getting to the Source(s) of fsck    Linux as a Win NT server --or--  Singing the Song for Samba    Telnet goes X? --or--  Exporting a DISPLAY    fvwm2 and blank screens --or--  That Blankety Blanker!    rsh works but not -display... --or--  Permission Denied on  -display    Cardboard Boxes --or--  Thinking  AROUND  the Box?    Intel's integrated Chipset --or--  Identifying the Integrated Video Chipset    Advice on Linux --or--  InfoRocket, Experts Exchange, Answer Guy and Netnews            Greetings from Jim Dennis     I've been thinking about Linux.  And about those penguins.    Need a better mascot.  Cats.  Cats are cute.  Cats go everywhere.    Except Antarctica.    We're smarter than that.  But penguins - they  live  there. Hsss!  Besides, penguins are birds.  Birds are snacks.  Cats have been on the   internet far longer.  Everyone knows  lynx  was one of   the first hunters here.  We already have three Linux disties anyway ( BlueCat ,   BlackCat , and   BluePoint ).  Cats are the purrrrrfect mascot for the new Linux.     Hmm.  I had a pretty darn good blurb written up about cool new stuff in 2.4 (still in the pre phase right now) but when I came back to my chair after getting coffee, my cat had taken over the chair and was sitting there,  purring  innocently .    As I lack the time to do it over (again!) here you go.  See you next  month.      ""Linux Gazette... making Linux just a little more fun! ""                 More 2¢ Tips!    Send Linux Tips and Tricks to   gazette@ssc.com                   2 Cent Trick: handy dictionary     Fri, 10 Mar 2000 16:52:05 -0800  From: Bryan Henderson < bryanh@giraffe-data.com>     A writer should never forego looking up a word in the dictionary because it's too much effort.  Here's a way to have a dictionary at your fingertips if you're connected to the Internet: Make a shell script 'dict' that does   lynx ""http://www.m-w.com/cgi-bin/dictionary?book=Dictionary&va=$*""      Now the shell command      dict quotidian    Brings up a definition of ""quotidian"".    I use Lynx instead of wget because the dictionary page has links on it I might want to follow (such as alternate spellings and synonyms).  I use Lynx instead of something graphical because it is fast.                  faq_builder.pl script     Sat, 11 Mar 2000 07:08:15 +0100 (CET)  From: Hans Zoebelein < hzo@goldfish.cube.net>     Everybody who is running a software project needs a FAQ to clarify questions about the project and to enlighten newbies how to run the software. Writing FAQs can be a time consuming process without much fun.    Now here comes a little Perl script which transforms simple ASCII input into HTML output which is perfect for FAQs (Frequently Asked Questions). I'm using this script on a daily basis and it is really nice and spares a lot of time. Check out http://leb.net/blinux/blinux-faq.html for results.    Attachment faq_builder.txt is the ASCII input to produce faq_builder.html using faq_builder.pl script.     'faq_builder.pl faq_builder.txt > faq_builder.html'    does the trick. Faq_builder.html is the the description how to use faq_builder.pl.     faq_builder.pl   faq_builder.html   faq_builder.txt                     winmodems     Tue, 14 Mar 2000 20:09:41 -0500  From: Les Urban < lnaa@centurytel.net>     Well I'm a Linux newbie. Been in DP for 25 years and wanted something better. I'm running SuSE 6.3 and having fun. Really close to wiping WINDOZE from my hard disk. I've really enjoyed your site and have found many answers to the many questions that have been starring me in the face. Keep up the good work.    Read another article about winmodems being dead wood as far as Linux is concerned. I got a great deal I thought at Best Buys a 56k modem for 9.95. Of course I should have know it had to be a winmodem. But I stumbled on the site  linmodems.org  There are alot of people working on this issue. In fact LUCENT has provided a binary for their LT MODEMS.  Well I downloaded that guy and I'm running great on my winmodem. There are other drivers available for other modems. Some are workable and some are still in development. I believe it's worth taking a look and spreading the word. You can reach alot more than I can.    Once again great site and thank you for all the helpful hints. I'll continue to be a steady visitor and a Linux advocate.                    Fantastic book on linux - available for free both on/offline!     Sat, 18 Mar 2000 16:15:22 GMT  From: Esben Maaløe (Acebone) < acebone@f2s.com>     Hi!    When I browse through the 2 cent tips, I see a lot of general  Sysadmin/bash questions that could be answered by a book called ""An  Introduction to Linux Systems Administration"" - written by David Jones  and Bruce Jamieson.    You can check it out at    www.infocom.cqu.edu.au/Units/aut99/85321     It's available both on-line and as downloadable PostScript file.  Perhaps it's also available in PDF.     It's a great book, and a great read!                       Tips in the following section are answers to questions printed in the Mail Bag column of previous issues.                     ANSWER:  Re: help in printing numbered pages!     Wed, 01 Mar 2000 07:48:30 GMT  From: Anthony E. Greene < agreene@pobox.com>        I usualy print a lot of documentation. One thing that I would like  to make is that my print jobs gets the pages to be numbered. So at the  bottom of the pages we could see ""page 1/xx"" , etc. I had looked a  while for info in how to set this up, but could not find. The printtool  just dont do it. Maybe i should to create a filter, but what commands  must i use to make this heapppens???      It depends on the software you used to create the file. If it is a plain text file, you can use ""pr"" to print it with page numbers in the header:   pr -f -l 55 somefile.txt | lpr      If the file is HTML, there is a utility html2ps that will do what you need. It's available at    http://www.tdb.uu.se/~jan/html2ps.html . It converts HTML to PostScript with an option for page numbers and other things.    If you are using a word processor, it may have an option to include page numbers. Let us know what you are trying to print and we may be able to give better help.     José A. Gaeta Mendes < gaeta@ecosfera.com.br>  suggests     See emacs *Tools | Print | Postscript Print Buffer* command... It does exactly what you want!    [ ]s - J. A. Gaeta Mendes Greetings from Brazil!   Michal Jaegermann < michal@ellpspace.math.ualberta.ca>  suggests     'man pr'    For fancier output with various bells and whistles    'man nenscript'    (plus maybe a driver script, or two, to get your customizations).      Michal    Bob Ternosky < michal@ellpspace.math.ualberta.ca>  suggests     Try the 'mpage' command.    It wont work for everything but it uses a header and page numbers and can also print multiple pages of stuff per page (saves paper).    Example:  mpage -2 -H document | lpr      (prints 2 pages on one, and puts a header w/ filename, page numbers)    Hope this helps.   From: Clovis Sena < csena@itautec-philco.com.br >     Thanks Bob and everybody who helped me! Now I am using mpage to print. That makes more sense, saving paper and toner.                 ANSWER:  Re: Inexpensive, powerful db's for Linux?     Wed, 01 Mar 2000 08:01:11 GMT  From: Anthony E. Greene < agreene@pobox.com>      To develop a distributed database application that runs on Linux,  what inexpensive, powerful databases might work best?      Check the Application section at   Linux.org   for databases. It lists big names such as DB2, Oracle, Informix, Ingres, and others such as  PostgreSQL  which is free, powerful, and ships with Red Hat Linux. The latest beta adds several desirable features. You may hear a lot about MySQL, but if you're building anythin more complicated than a basic query system, you'll need something more powerful than MySQL.   Marius ANDREIANA < rocky@ss.pub.ro>  wrote    PoestgreSQL, by far. www.postgresql.org Inexpensive ( free, GPL ), powerful ( check the website for a list of features ), great. There's also MySQL, but less powerful than Postgres ( performance, when talking about milions of records, and many more )     Distributed ? PostgreSQL is the database engine, server & client. You start the server and you can connect to it from any other machine using TCP/IP. Connect from what ? From what you want : C, Python, PHP, Perl, etc etc ( see Postgres howto ). A recent great adition is Gnome-DB ( www.gnome.org/gnome-db/ ), which gives you the power to develop cool desktop applications.                 ANSWER:  Re: linuxconf     Wed, 1 Mar 2000 06:36:17 -0700 (MST)  From:  < ghaverla@freenet.edmonton.ab.ca>     I'm just guessing, but are the clocks on all these machines synchronized?  That seems to be one reason why one computer would continually update another.                ANSWER:  Modems     Wed, 1 Mar 2000 12:20:02 -0300  From: Juan M. Fera < jmfera@sion.com>     Hello:   You can solve your problems by reading the section 20 (Modems) on the Linux Hardware Compatibility HOWTO...      http://www.linuxdoc.org/HOWTO/Hardware-HOWTO-20.html     and the section 30 (Appendix E.  Linux incompatible Hardware) too...      http://www.linuxdoc.org/HOWTO/Hardware-HOWTO-30.html                     ANSWER:  IP Masquerade Connection Problems     1 Mar 00 08:47:35 PST  From: Darrell Scott < scottie99@netscape.net>     This is a known bug with the PPP packages distributed with Red Hat 6.1.  See RHEA-1999:051-01 for a full description of the problem, and pointers to updated packages.    Scottie                  ANSWER:  Re: make virtuald     Thu, 2 Mar 2000 22:32:07 +0100 (CET)  From: Roland Smith < rsmith@xs4all.nl>         I am trying to compile virtuald using make virtuald here is the  error I get    Makefile:14: *** missing separator. Stop.       I did a cut and paste of the code from  http://www.linuxdoc.org/HOWTO/Virtual-Services-HOWTO-3.html in the  section 3.4 Source then used ftp to put it on the server in order to  compile it.     This is a small gotcha with make. See the following makefile snippet:   # Remove all generated files. clean:;         rm -f $(OBJS) $(BASENAME) *~ core $(TARFILE) $(BACKUP) $(LOG)      The commands that follow a rule (`rm' in this case) should be preceded by a tab character. Probably, some tabs got converted to spaces when cutting-and-pasting.    Try editing the Makefile with vi or emacs. Both can insert literal tab characters, and emacs has a specail mode for makefiles that takes care of that automagically.   Darrell Scott < scottie99@netscape.net>  suggests     Hi,    I think you're missing a Makefile!    The ""make"" command interprets a set of commands in a specifically written makefile, to compile and link source code into an executable.  ""gcc"" is the actual compiler/linker, and is appears to be what you actually require in this case.  Try ""gcc (source filename goes here) -o virtuald"" (it's probably wise to move your source from virtuald to virtuald.c with the command ""mv virtuald virtuald.c"" first).    Scottie    btw, if you did write a makefile, a common gotcha is that at least one tabspace is required between the label and the commands.  Spaces just won't cut it; you'll end up with the ""Missing Separator"" message again!                   ANSWER:  Linux & win98 internet connection sharing     Wed, 1 Mar 2000 22:41:07 -0500  From: DJ Busch < djbusch@mediaone.net>     Check out a program called WinRoute for Windows 98.  You can download a trial copy from winroute.com.  If it's setup right, you can tell your Linux box that your Win98 box is your ""default gateway"" and winroute will do the rest for you.  I have 2 W98 boxes, 1 linux box and 1 iMac all running on this kind of setup and I've never had a problem.     DJ Busch                  ANSWER:  Re: Gazette crashes Konqueror (from LinuxGazette #51/General Mail)     Thu, 2 Mar 2000 08:41:07 +0000  From: Jan-Hendrik Terstegge < helge@jhterstegge.de>     Hi!    In LinuxGazette #51 Pierre Abbat (phma@oltronics.net) wrote:    I am trying to read the Gazette with kfm 1.167 and several pages crash  it, including the mailbag and 2c Tips. Can you help me figure out  what's wrong?  It's happend before.   In you Subject you wrote the the gazette crashes the konqueror, but in your text you wrote it is the kfm. What thing do you use? Is the Konqueror your kfm replacement. Then I think you use a KDE-beta Version. Please try to use stable releases (I think the last was KDE 1.1.2).                ANSWER:  AS/400 Emulation     Thu, 02 Mar 2000 08:25:59 -0500  From: Vince Du Beau < vdubeau@ploverdev.com>      From: Jeffrey T. Ownby (jownby@ecsis.net)   Subject: 5250 terminal for AS400 connection      I am adding a Linux box to a network consisting of several Win9X  and NT machines that use either IBM Client Access or Rumba to connect  to our AS400. Is there a program similar to either one of these that  can provide terminal emulation on Linux. Any info appreciated!      Later,   Jeffro      I currently use tn5250 to connect from my laptop to an AS/400 (thru an NT Server).  This is a modified version of telnet with better key mappings.  You can find it at:          http://www.blarg.net/~mmadore/5250.html     IBM also has a java based version of client access which reportedly runs under Linux.  I haven't tried it since it requires some of it to run from the HTTP server on the AS/400.  Their link is:         http://www-4.ibm/software/network/hostondemand     Hope this helps.    Vince Du Beau   From: Jimmy O'Regan < jimregan@litsu.ie>  suggests     There's a 5250 terminal emulator available at   http://www.linux-sna.org/software/5250/index.html     We use an AS/400 in the college I attend, and while I haven't been able to get permission to put a linux box on the same network as the 400 (and therefore cannot vouch for the linux version) I have tried the WinNT port of the program, and it works very well.  (Though as far as I remember, there was no way to paste)    But as far as getting the capabilities of client access, you should try Linux SNA (  http://www.linux-sna.org/ ) which adds the AS/400s native protocol stack to the kernel. There are also some tools which should provide some of the other capabilities of client access, such as file transfer.    (If you get it working, please drop me a note, as I'd love some testimonial to use to convince my college to let me hook up a box to our as/400).                      ANSWER:  Quick tip for mounting FDs, CDs, etc...     Fri, 25 Feb 2000 15:49:17 -0800  From:  < fuzzybear@pocketmail.com>     If you can't or don't want to use auto-mounting, and are tired of typing out all those 'mount' and 'umount' commands, here's a script called 'fd' that will do ""the right thing at the right time"" - and is easily modified for other devices:   #!/bin/bash d=""/mnt/fd0"" if [ -n ""$(mount $d 2>&1)"" ]; then umount $d; fi      It's a fine example of ""obfuscated Bash scripting"" , but it works well - I use it and its relatives 'cdr', 'dvd', and 'fdl' (Linux-ext2 floppy) every day.     Ben Okopnik                  ANSWER:  Re: Pentium-II Xeon and calculation speed     Sun, 27 Feb 2000 15:19:44 +0100 (CET)  From: Roland Smith < rsmith@xs4all.nl>         Hi guys, here I'm trying to get a little bit of help with my  computer. I'm doing a very time expensive calculations using FORTRAN  programs, compiled with g77 under Red Hat 6.1. First, on dual  Pentium-II/400MHz and Pentium-III/450MHz computers I noticed, that when  program size (RSS in top) is getting biger that approximately 600K  computation speed dramatically decreasing by factor two. This slowing  down agrees with the bus speed (100MHz) and L2 cache (512K, 200MHz). So,      What have you done about optimizing your program? Some things you could do:      profile the running application to see where it spends it's time, then        rewrite the critical code, using a faster algorithm.     use the most recent compiler (2.95.2, I believe) which knows about more     recent Pentium-class processors.     compile the critical modules for speed, and the others for small size,     to make the image smaller.     if everything else fails, try rewriting critical sections an assembly code.       kill all unnecessary services to give the program as much CPU time as   possible.    enhance the program's nice value (only root can do this, though).    make your program multi-processor-aware. Normal programs only use 1   CPU. You have to run several instances of your program (or make it   multi-threaded) to really take advantage of your two CPU's.       I've decided that the reason lies in the cache sped/size and bought  (pretty cheap) dual Pentium-II/450MHz Xeon computer with 2MB L2 cache  per proccessor that suppose to run at 450MHz and 512M SDRAM on  SuperMicro mainboard. Unfortunately I did not find any difference in  performance of this computer and still much cheaper dual  Pentium-II/400MHz. Why is it?      Total performance depends on a lot of things except CPU speed and cache size. To name a few:       amount of RAM    - type and speed of hard disks    - is the kernel SMP aware?    - number of processes competing for CPU time      The clock speeds between the two systems don't vary much. So if you find that your performance hasn't increased as much as you expected, the only thing that you can conclude is that the cache size probably isn't the limiting factor here.     May be, Red Nat 6.1 somehow must be told explicitely about cache size?  But I did not find any such option...       I don't *think* so. AFAIK, the cache can't be influenced from the OS on x86 CPU's. I've only heard of that trick with Mac's running on 68040's    HTH, Roland                 ANSWER:  Re: Anti Virus programs for linux Red Hat 6     Sun, 27 Feb 2000 15:35:41 +0100 (CET)  From: Roland Smith < rsmith@xs4all.nl>         Is there a ""definative"" anti virul program for Linux? Any info  appreciated!      There are several anti-virus programs available, see Freshmeat.net:   http://freshmeat.net/appindex/daemons/anti-virus.html     I believe that the McAfee also runs on Linux.     But these are mostly used for scanning mail destined for other systems that are more vulnerable to viruses.    Linux and other UNIX-like systems don't suffer much from viruses, because most programs do not run with root privileges. So they don't have access to the system, other than the user's home-directory and processes.    So as long as you're surfing as a normal user, and not as root, any virus that you contract can at most endanger your own files and processes, and not the integrety of the system. Besides, most binary and macro viruses are targeted on DOS/Windows, so they don't even work on Linux.    Of course there are other attacks on your system possible, forms of so-called root-exploits; using known defects in programs to gain access to your machine as root.    That's why you do need to keep track of your distribution's security advisories.                  ANSWER:  Re: neighbour table overflow     Sun, 27 Feb 2000 15:38:13 +0100  From: Baco < baco@baco.net>     Dear,     I was running quite a long time with NFS and transmission stopped. I  get: Sep  6 00:03:20 coyote kernel: eth0: trigger_send() called with  the transmitter busy.  I rebooted the machine I was connected to and I  get the below (part of /var/log/messages >file. Not all error  statements shown):    Sep  6 17:57:04 beartooth kernel: neighbour table overflow Sep  6 17:57:04 beartooth kernel: neighbour table overflow Sep  6 17:57:04 beartooth rpc.statd: Cannot register service: RPC: Unable to send; errno = No buffer space available Sep  6 17:57:04 beartooth nfs: rpc.statd startup succeeded Sep  6 17:57:04 beartooth rpc.statd[407]: unable to register (SM_PROG, SM_VERS, udp).l:         I had the same problem but with all ftp daemons running under inetd    My problem was resolved when I added ""127.0.0.1 localhost"" into /etc/hosts and when I setup the loopback lo interface using route and ifconfig    I hope this was also your problem.                 ANSWER:  Win95-Linux small network with null modem     Sun, 27 Feb 2000 10:36:57 -0500  From: David B Sarraf < david.sarraf@juno.com>     Dear Wagner Perlino    What you are asking is commonly done with Linux.  For example I have a small home network with three and sometimes four W95 machines and sometimes another Linux box.  All are connected to a hub along with a ""server"" linux box.  That machine does the following       dials my ISP on demand using the diald package    network address translation (masquerading) and firewalling (blocks bad guys) using IPFWADM    intranet server using Apache    file (disk volume) and printer sharing (2 printers) using Samba    modem sharing (for Juno, FreeInet, etc)    intranet-enabled control of lamps and other devices using an X10 transmitter on the serial port.    Projects underway:         database server installation, possibly MySQL        cron and perl scripts to update a database of my personal Setiathome statistics             I did not set out to do all of this at once.  The project began as a request to make a dial-on-demand connection.  It just grew as I got better with Linux and realized the power of the O/S and machine.    Dial on demand was quite an experience to set up due to my then inexperience with Linux, ISP hookups, and networking.  Now it would be quite easy.     There were some issues with the current version of diald (0.16 and 0.99) and incompatibilities with newer versions of Linux (particularly Red Hat 6.1 and the Ethertap device).  When I did this project about a year ago the issues were being worked through.  Some comprehensive how-tos were posted and some users were reporting success. By now the package itself has probably been fixed.  My workaround was to stay with diald 0.16 and RedHat 5.1.  Setup was straightforward and the combination has worked flawlessly for about a year.      Contact me if you want more details.  I'd be glad to help.                 ANSWER:  Subject: insmod and newbie to RH6.1     Sun, 27 Feb 2000 11:05:53 -0500  From: David B Sarraf < david.sarraf@juno.com>     Put the insmod command into /etc/rc.d/rc.local      Any commands there are run at boot time.                   ANSWER:  secondary ide and cdrom     Sun, 27 Feb 2000 22:32:44 -0500  From: George W. Bursha < gburs2@hotmail.com>     I noticed a number of times people have problems with secondary ide on a pnp sound card. Don't be alarmed by ide3: unexpected interrupt, status=0xff, count=1. That is to say, if you are successful in getting your isapnp.conf correct and the the card seems proper from dmesg all except for this message and you still can't do a mount /dev/cdrom /cd0.....well fool, then go to /dev and rm cdrom and ln -s to the correct device! /dev/cdrom is probably linked to /dev/hdb for example. When testing your cd use 'mount -t iso 9660 /dev/hdx /mnt/cdrom'. Where x in hdx is the correct device name. You will perhaps surprise yourself after many hours spent shaking your head.                  ANSWER:  Re: Users required to enter root-password? Red Hat 6.1     Tue, 29 Feb 2000 19:40:27 -0500  From: Srinivasa A. Shikaripura < sas@lucent.com>     I have just installed version 6.1 and set up my modem to dial out to my ISP.  However, when I log on as a user and press KDE>Internet>kppp a pop-up box  opens up and wants me to enter the root-password! This does not seem right.  is there a way to avoid having to enter the root pass word when logged on  as a non-root user?       You could possibly change the permissions on /dev/modem and whatever it is pointing to (/dev/ttyS1 etc.) to allow the user to read/write from that device.    You should also be selectively allow some users to use the modem by giving group permissions, but I am really not suer how it is done. (but I know it is possible).    cheers -Sas                  ANSWER:  Re: Modem problem with 5.2     Sat, 04 Mar 2000 11:33:45 -0800  From: Steve Dunbar < sad@efn.org>      ... I can hear the modem clicking like it is trying to dial, but it will     never dial the number....      Try running setserial to set the IRQ used by the modem, e.g. I use  ""setserial /dev/ttyS2 irq 5 uart 16550A"" to get my modem working. This command must be run as root. You may have to mess with the jumpers on your modem card to set the IRQ.    There should be an initialization script that controls serial port configuration at boot time. On Suse 6.3 this is /sbin/init.d/serial. It should be possible to edit this script to set your modem set up automagically, although I haven't yet got it working on my system.    See the Modem HOWTO for more info.     -- Steve                 ANSWER:  Installing Linux on a laptop with a single FD/CD slot     Sun, 5 Mar 2000 17:45:26 -0800  From:  < ben-fuzzybear@yahoo.com>     Saw this question in LG the other day - yep, I'm a few issues behind but catching up fast. Relatively easy answer (I just tried it with both Debian and Red Hat and it works fine):    (Assumptions: you have DOS/Windows installed, and can read from your CD.)    First, create a directory - C:\Linux is fine.     (The two examples below will cover the majority of the installs done these days, and are easily adaptable to other distros.)    Debian   I'm one of those guys who'd never heard of a distro on CD until _after_ d'loading a gig-plus worth of stuff, back when... but somewhere on the CD there should be files called ""loadlin.exe"", ""root.bin"", and ""linux"", ~1.5MB worth of stuff. Copy those to your new directory. Shut down your machine (I'm assuming the CD and the FD are not hot-swappable - otherwise there'd be no point to this), swap in the CDR, and turn it back on. Start DOS - *not* a DOS window under Win9x, but DOS (by pressing the F8 key, if necessary, as soon as you see the ""Starting Windows..."" message), type    cd Linux      at the C: prompt, then type   loadlin linux root=/dev/ram initrd=root.bin     Red Hat     This uses the 5.2 CD but I would think it's much the same for the different versions. From the ""dosutils"" directory, copy ""loadlin.exe""; from ""dosutils\autoboot"" copy ""vmlinuz"" and ""initrd.img"" into your ""Linux"" directory. Shut down, attach CDROM, reboot into DOS, 'cd Linux', and type   loadlin vmlinuz initrd=initrd.img      ...and you're on your way!     Another tip, while we're on the subject - Debian has these files available at their FTP server, and probably on the CD as well -   base2_1.tgz -  10MB drv1440.bin -  1.4MB resc1440.bin - 1.4MB      Stick these in your ""Linux"" directory, too; they'll install a base Linux system on your HD, or let you perform any sort of rescue ops necessary (by mounting your existing Linux partition as /target hanging off a ramdisk, for example - forget your root password lately?  ). No CD required - that's the entire base package. One of _the_ handiest things there is when you're munging through a tricky installation - and a GOOD reference for the initial state of your /etc files (look inside base2_1.tgz). Putting those files on the DOS side is usually my first step during an installation, and it's saved my sanity more than once.     Ben Okopnik Captain S/V ""Ulysses""                  ANSWER:  X screen captures into video animation     Mon, 6 Mar 2000 10:27:37 -0700 (MST)  From: Michael J. Hammel < mjhammel@graphics-muse.org>     Thus spoke Ferenc Tamas Gyurcsan    I just saw your problem on the lg. Did you look for something like  xvidcap? (I can't give you an url, but you will find it.)  ps: If you manage to produce a good mpeg from the captured pictures,  please let me know how.  Ferenc      The original question was from Shawn Medero, who asked:       It captures motion on the computer desktop, basically multiple    screen-captures tied together to form a movie of sorts. Primarly one would    use to create training demostrations on linux applications, etc.       I checked, and yes, XVidCap does appear to fit this description.  A quick check on  Freshmeat  gave this description for XVidCap:    XVidCap is an X11/Xt program, which captures specified rectangular areas of    the X11 desktop. The captured frames can be saved in different formats    (XWD, PNG, JPEG, PPM). Frames per second and other parameters can be    defined at the command line. The saved frames could be used e.g. for an    mpeg encoder or to make an animated GIF. A Step-mode is supported to get a    frame on mouse click.      I tried to access the Homepage for this program, but couldn't get through, though it might be a problem on my end.  I don't have time to recheck today, so I'll just pass along the URLs of interest.    Download:   ftp://ftp.komm.hdk-berlin.de/pub/linux/X11/  Homepage:   http://home.pages.de/~rasca/xvidcap/     Thanks to Ferenc for pointing this out.  Its another application to add to my own catalog of tools on the Graphics Muse site  ( http://graphics-muse.com ).                 ANSWER:  Uninstalling Linux on a Laptop     Tue, 7 Mar 2000 12:55:23 -0500  From:  < Michael.Risser@Summus.com>     First I know this is opposite of what the intentions of Linux are, but sometimes it IS necessary. I recently had to remove Linux from my Dell Inspiron 3500 Laptop so that I could reinstall Windoze, it was necessary due to work, and limited hard-drive space(4GB).    Windows fdisk, Partition Magick, and Drive Wizard would not remove the partitions I had created for Red Hat 6.1(kudos to Linux on that one :-)) Instead you must first begin installing WinNT, and allow it to remove the partition. After WinNT has removed the partition you can either let it format the drive, or install Windoze as normal. So far that is the only way I have found to remove Linux partitions    Note: This tip was actually given me by my brother-in-law who had to do the same thing.                 ANSWER:  2 Cent Tips     Wed, 08 Mar 2000 16:13:59 -0500  From: Bolen Coogler < bcoogler@dscga.com>   How to set vi edit mode in bash for Mandrake 7.0    If, like me, you prefer vi-style command line editing in bash, here's how to get it working in Mandrake 7.0.    When I wiped out Redhat 5.2 on my PC and installed Mandrake 7.0, I found vi command line editing no longer worked, even after issuing the ""set -o vi"" command.  After much hair pulling and gnashing of teeth, I finally found the problem is with the /etc/inputrc file.  I still don't know which line in this file caused the problem.  If you have this same problem in Mandrake or some other distribution, my suggestion for a fix is:    1. su to root. 2. Save a copy of the original /etc/inputrc file (you may want it back).    3. Replace the contents of /etc/inputrc with the following:   set convert-meta off set input-meta on set output-meta on set keymap vi set editing-mode vi      The next time you start a terminal session, vi editing will be functional.    --Bolen Coogler                  ANSWER:  Solution to mysterious dial-in hangup     Wed, 15 Mar 2000 19:19:56 +0100  From: Eric Kafé < kafe@mobilixnet.dk>     This seems to be a very common Red Hat 6.1 bug. The problem is mentioned, without a solution, in the current FAQ for the PPP demon.    After installing Red Hat 6.1, every time I tried to dial-in to my ISP, a mysterious hangup occurred on the first attempt, and the connection always succeeded the second time. I first suspected the ISP, but they have nothing to do with it.    The problem disappeared as soon as I compiled ppp from the most recent source rpm. I use ppp-2.3.11-1 with a 2.2.14 kernel. Compilation was straightforward. Now I connect at once and everything is just fine.     According to the README.linux file in the ppp documentation, there are some subtleties related to compiling ppp for different kernel versions. Perhaps the ppp package included in Red Hat 6.1 was configured for another kernel than it ships with.        Best regards                 ANSWER:  ATI xpert cards     Sat, 18 Mar 2000 21:50:25 -0800  From:  < noah@nack.org>           I'm new user and believer of the Linux OS and I need help badly. I'm looking for a driver for an ATI Xpert@Work 8Mb PCI card. Where can      I get it? I'm using a RedHat 5.2 and my monitor is a Mitsubishi Diamond Scan model FA3415AT4 [...]      Configure your display with the help of 'XF86Setup' (you have to write it as I do, with upper and lower cased letters), or, if it doesn't run the 'xf86config' program. Try to find your ATI Card, and if you don't, use simply SVGA. Most of cards which are not listed are standard SVGA Cards (my Matrox Millenium G200 also), and they run very well with the SVGA driver.    I have (successfully) set up a bunch of ATI cards under RedHat, and lately  (>=5.0) have found that Xconfigurator seems to give better results with ATI cards.                    ANSWER:  Re: Tip & Tricks     Tue, 21 Mar 2000 16:09:45 -0600  From: Jesse Lang < jesse@tcmi.com>     The tip you're looking for looks something like this:     Edit your dns entry that probably looks like this:   www A [Your Machine's IP Address]    TO:   @ A [Your Machine's IP Address] www CNAME  @      What you're saying is that your IP is uniandes.edu.co and that www is a alias to it.  So either way, it will end up at your site.  If Apache is set up with the ServerName directive as ""www.uniandes.edu.co"", then it will fix names as soon as it connects to apache.                     ANSWER:  Re: make virtuald     Tue, 21 Mar 2000 16:50:16 -0600  From: Jesse Lang < jesse@tcmi.com>     Chances are if your are using any other platform than Linux (Windows, dos, mac, etc.), the problem is the mode that ftp was in when you uploaded it. You have to make sure you upload in ascii mode as opposed to binary.  This mode will do the proper conversion of line breaks and such.  Give it another shot.  The best way to tell if it's readable on linux is to type 'cat filename.c'  You should see the line breaks in the right places.  Hope this works for you.  Let me know if you need more help if this doesn't roll out for you.                ANSWER:  Linux not detecting above 64meg     Tue, 21 Mar 2000 16:50:16 -0600  From: Linux Gazette < gazette@ssc.com>     Several readers took your humble Editor to task for telling a user that Linux cannot autodetect memory above 64 MB because of a BIOS limitation; instead, I said that you have to tell Linux explicitly in the LILO config file or at the LILO command line.    The readers said they have had no problems with Linux autodetecting their 128 MB of memory.  So I went home and took the   append = ""mem 128M""   line out of my /etc/lilo.conf file and discovered that, indeed, it was  unnecessary.  But I know it was a necessity last year when I put the system together.  In the meantime I had switched from kernel 2.0.36 to 2.2.14--perhaps autodetection was added to the 2.2 kernels.                ANSWER:  Multiple video cards     Mon, 13 Mar 2000 12:46:32 +0100  From: François Désarménien < desar@club-internet.fr >      I have a question, have you any idea where I could find info about running multiple video cards and monitors under linux. eg. 2 SVGA cards or a SVGA and a VGA card ... and how should one configure these ??       XFree4.0 (which is out now) should solve this issue.                 ANSWER:  Screen ""Camera"" for linux     Thu, 30 Mar 2000 02:28:57 -0500  From: Paul Winkler < desar@club-internet.fr >  Shawn Medero wrote:   It captures motion on the computer desktop . .basically multiple screen-captures tied together to form a movie of sorts. Primarly one would use to create training demostrations on linux applications, etc.      You could do this with import (part of the ImageMagick package) and a simple shell script. Try this, for example.     camera.sh     You could then combine them to an animated GIF with Gimp. Or use ImageMagick's animate command to view the sequence, like this:  animate shot*.gif    But that starts a loop that repeats until you stop it...                  ANSWER:  Extracting a block of text from a file      Thu, 30 Mar 2000 09:29:34 -0800  From: Jim Dennis < djimd@linuxcare.com >     I'm trying to extract a block of text from a file using just bash and  standard shell utilities (no perl, awk, sed, etc). I have a definitive  pattern that can denote the start and end or I can easily get the line  numbers that denote the start and end of the block of text I'm  interested in (which, by the way, I don't know ahead of time. I only  know where it is in the file). I can't find a utility or command that  will extract everything that falls between those points. Does such a  thing exist?      awk and sed are considered to be ""standard shell utilities."" (They are part of the POSIX specification).  The sed expression is simply:   sed -n ""$begin,${end}p""  ...    ... if begin and end are line numbers.    For patterns it's easier to use awk:   awk ""/$begin/,/$end/"" ...    ... Note: begin and end are regexes and should be  chosen carefully!    However, since you don't want to do it the  easy way, here are some alternatives:    ------------------ WARNING: very long -------------------------    If it is a text file and you just want some lines out of  it try something like: ( text version )   #!/bin/sh # shextract.sh  # extract part of a file between a # pair of globbing patterns  [ ""$#"" -eq ""2"" ] || {  echo ""Must supply begin and end patterns"" >&2  exit 1  } begin=$1 end=$2 of="""" ## output flag while read a; do  case ""$a"" in   ""$begin"") of=""true"";;   ""$end"") of="""";;   esac  [ -n ""$of"" ] && echo $a   done exit 0       ... this uses no external utilities except for the test command ('[') and possibly the 'echo' command from VERY old versions of Bourne sh.  It should be supported  under any Bourne shell derivative.  Under bash these are builtin commands.    It takes two parameters.  These are ""globbing"" patterns NOT regular expressions.  They should be quoted, especially if they contain shell wildcards (?, *, and [...] expressions).    Read any good shell programming reference (or even the rather weak 'case...esac' section of the bash man page) for details on the acceptable pattern syntax.  Note because of the way I'm using this you could invoke this program (let's call it shextract, for ""shell extraction"") like so:   shextract ""[bB]egin|[Ss]tart"" ""[Ee]nd|[Ss]top""      ... to extract the lines between the any occurrence of the term ""begin"" or ""Begin"" or ""start"" or ""Start"" and the any subsequent occurence of ""end"" or ""End"" or ""stop"" or ""Stop.""      Notice that I can use the (quoted) pipe symbol in this  context to show ""alternation"" (similar to the egrep use of the same token).    This script could be easily modified to use regex's instead of glob patterns (though we'd either have to  use 'grep' for that or rely on a much newer shell such as ksh '93 or bash v. 2.x to do so).    This particular version will extract *all* regions of the file that lie between our begin and end tokens.    To stop after the first we have to insert a ""break"" statement into our ""$end"") ...;;; case.  To support an ""nth"" occurence of the pattern we'd have to use an additional argument.  To cope with degenerate  input (cases where the begin and end tokens might be out of order, nested or overlapped) we'd have to  do considerably more work.    As written this example requires exactly two arguments. It will only process input from stdin and only write to stdout.  We could easily add code to handle more arguments (first two are patterns, 'shift'ed out rest are input file names) and some options switches (for output file, only one extraction per file,  emit errors if end pattern is found before start  pattern, emit warnings if no begin or subsequent end pattern is found on any input file, stop processing on  any error/warning, etc).    Note: my exit 0 may seem superfluous here.  However, it does prevent the shell from noting that the program ""exited with non-zero return value"" or warnings to that effect.  That's due to my use of  test ('[') on my output flag in my loop.  In the  normal case that will have left a non-zero return value since my of flag will be zero length for the part of  the file AFTER the end pattern was found.    Note: this program is SLOW.  (That's what you get for asking for it in sh).  Running it on my 38,000 line /usr/share/games/hangman-words (this laptop doesn't have /usr/dict/words) it takes about 30 seconds or  roughly only 1000 lines per second on a P166 with 16Mb of RAM.  A binary can do better than that under MS-DOS  on a 4Mhz XT!    BUG:  If any lines begin with - (dashes) then your version of echo *might* try to treat the beginnings of your lines as arguments. This *might* cause the echo command to  parse the rest of the line for escape sequences.  If you have printf(1) evailable (as a built-in to your shell or  as an external command)  then you might want to use that instead of echo.    To do this based on line numbers rather than patterns we could use something more like:  ( text version )    #!/bin/sh # lnextract.sh #       extract part of a file between a #       line numbers $1 and $2  function isnum () {  case ""$1"" in  *[^0-9]*)   return 1;;  esac  }  [ ""$#"" -gt ""2"" ] || {  echo ""Must supply begin and end line numbers"" >&2  exit 1  }  isnum ""$1"" || {  echo ""first argument (first line) must be a whole number"" >&2  exit 1  }  isnum ""$2"" || {  echo ""second argument (last line) must be a whole number"" >&2  exit 1  }  begin=$1 end=$2  [ ""$begin"" -le ""$end"" ] || {  echo ""begin must be less than or equal to end"" >&2  exit 1  }  shift 2 for i; do [ -r ""$i"" -a -f ""$i"" ] || {   echo ""$i should be an existing regular file"" >&2   continue   } ln=0 while read a ; do  let ln+=1  [ ""$ln"" -ge ""$begin"" ] && echo $a  [ ""$ln"" -lt ""$end"" ]   || break  done < ""$i"" done exit 0       This rather ugly little example does do quite a  bit more checking than my previous one.    It checks that its first two arguments are  numbers (your shell must support negated character class globs for this, ksh '88 and later, bash 1.x and 2.x,  and zsh all qualify), and that the first is less than or equal to the latter.  Then it shifts those out of the way so it can iterate over the rest of the arguments, extracting our interval of line from each.  It checks that each file is ""regular""  (not a directory, socket, or device node) and readable before it tries to extract a portion of it.  It will follow symlinks.    It has some of the same limitations we saw before.    In addition it won't accept it's input from stdin (although we could add that by putting the main loop into a shell function and invoking it one way if our arg count was exactly two, and differently  (within our for loop) if $# is greater than two. I don't feel like doing that here --- as this message is already way too long and that example is complicated enough.    It's also possible to use a combination of 'head' and 'tail' to do this.  (That's a common exercise in shell programming classes).  You just use something like:   head -$end $file | tail -$(( $end - $begin ))      ... note that the 'tail' command on many versions  of UNIX can't handle arbitrary offsets.  It can only handle the lines that fit into a fixed block size. GNU tail is somewhat more robust (and correspondingly larger and more complicated).  A classic way to work around limitations on tail was to use tac (cat a file backwards, from last line to first) and  head (and tac again).  This might use prodigous amounts of memory or disk space (might use temporary files).    If you don't want line oriented output --- and your patterns are regular expressions, and you're willing to use grep and dd then here's a different approach:   start=$(grep -b ""$begin"" ... ) stop=$(( $( grep -b ""$end"" ... ) - $begin )) dd if=""$file"" skip=$begin count=$stop bs=1b      This is not a shell script, just an example. Obviously you'd have to initialize $begin, $end, and $file or use $1, $2, and $3 for them to make this into a script.  Also you have to modify those grep -b commands a little bit (note my ellipses).  This is because grep will be giving us too much information.  It will be  giving a byte offset to the beginning of each pattern match, and it will be printing the matching line, too.    We can fix this with a little work.  Let's assume that we want the first occurrence of ""$begin"" and the last occurence of ""$end""  Here's the commands that will just give us the raw numbers:   grep -b ""$begin"" ""$file"" | head -1 {   IFS=:   read b x  echo b    }  grep -b ""$end"" ""$file"" | tail -1 | {   IFS=:  read e x  echo e  }      ... notice I just grep through head or  tail to get the first or last matching line, and I use IFS to change my field separator to a "":"" (which grep uses to separate the offset value from the rest of the line).  I read the line into two variables (separated by the  IFS character(s)), and throw away the extraneous data by simply echoing the part I wanted (the byte offset) back out of my subshell.    Note:  whenever you use or see a pipe operator in a shell command or script --- you should realize that you've created an implicit subshell to handle that.    Incidentally, if your patterns *might* have a leading - (dash) then you'll have problems  passing them to grep.  You can massage the  pattern a little bit by wrapping the first character with square brackets. Thus ""foo""  becomes ""[f]oo"" and ""-bar"" becomes ""[-]bar"". (grep won't consider an argument starting with [ to be a command line switch, but it will try to parse -bar as one).    This is easily done with printf and sed:   printf ""%s"" ""$pattern"" | sed -e 's/./[&]/'      ... note my previous warning about 'echo' --- it's pretty permissive about arguments that  start with dashes that it doesn't recognize, it'll just echo those without error.  But if your pattern starts with ""-e "" or -n it can effect out the rest of the string is represented.    Note that GNU grep and echo DON'T seem to take the -- option that is included with some GNU utilities. This would avoid the whole issue of leading dashes since this conventionally marks the end of all  switch/option parsing for them.    Of course you said you didn't want to use sed, so you've made the job harder.  Not impossible, but harder.  With newer shells like ksh '93 and bash 2.x we can use something like:   [${pattern:0:1}]${pattern:1}      (read any recent good book on shell programming to learn about parameter expansion).  You   can use the old 'cut' utility, or 'dd' to get these substrings.  Of course those are just as external to the shell as perl, awk, sed,  test, expr and printf.  If you   really wanted to do this last sort of thing (getting a specific size substring from  a variable's value, starting from an offset in the string, using only the bash 1.x parameter expansion primitives) it could be done with a whole lot of fussing.  I'd use ${#varname} to get the  size, a loop to build temporary strings of ? (question mark) characters to of the right  length and the ${foo#} and ${foo%} operators (stripping patterns from the left and right of  variable's value respectively) to isolate my substring.      Yuck!  That really is as ugly as it sounds.    Anyway.  I think I've said enough on the subject for now.    I'm sure you can do what you need to. Alot of  it depends on which shell you're using (not just csh vs. Bourne, but ksh '88 vs. '93 and bash  v1.14 vs. 2.x, etc) and just how rigit you are about that constraint about ""standard utilities""    All of the examples here (except for the ${foo:} parameter expansion) are compatible with bash 1.14.    (BTW: now that I'm really learning C --- y'all can either rest easy that I'll be laying off the sh syntax for awhile, or lay awake in fear of what I'll be writing about next month).    Here's a short GNU C program to print a set of  lines between one number and another: ( text version )    /* extract a portion of a file from some beginning line, to  * some ending line * this functions as a filter --- it doesn't take a list * of file name arguments. */  #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;errno.h&gt;  int  main (int argc, char * argv[] ) { char * linestr; long begin, end, current=0; ssize_t * linelen;   linelen = 0;  linestr=NULL;  if ( argc &lt; 3 ) { fprintf(stderr, ""Usage: %s begin end\n"", argv[0]); exit(1); }  begin=atol(argv[1]); if ( begin &lt; 1 ) { fprintf(stderr, ""Argument error: %s should be a number ""   ""greater than zero\n"", argv[1]); exit(1); }  end=atol(argv[2]); if ( end &lt; begin ) { fprintf(stderr, ""Argument error: %s should be a number ""   ""greater than arg[1]\n"", argv[1]); exit(1); }  while ( getline(&linestr, &linelen, stdin ) &gt; -1    && (++current &lt; end ) ) { if (current &gt;= begin) {  printf(""%s"", linestr);  } }  exit(0); return 0; }      This is about the same length as my shell version. It uses atol() rather than strtol() for the argument to number conversion. atol()  (ASCII to long) is simpler, but can't convey errors back to us. However, I require values greater than zero, and GNU glibc atol() returns 0 for strings that can't be  converted to longs.  I also use the GNU getline() function --- which is non-standard, but much more convenient and robust than fussing with scanf(), fgets() and sscanf(), and getc() stuff.                     This page written and maintained by the Editor of the  Linux Gazette . Copyright © 2000,  gazette@ssc.com   Published in Issue 52 of  Linux Gazette , April 2000       ""Linux Gazette... making Linux just a little more fun! ""                 Microsoft flip-flop   By  Mark Bolzern                      Microsoft's flip-flop on Linux has created a lot of confusion in the marketplace. Here's a look at the positions taken during and after the anti-trust trial, and an evaluation by a Linux advocate.     Microsoft has managed to create a quagmire of uncertainty among some potential Linux users by conveniently recognizing Linux as a technological threat to Windows 9x and NT during the Antitrust Trial, then denouncing Linux as ""hype"" on a Microsoft web site. Obviously, Microsoft was willing to portray Linux as competition to the court, but not to the buying public.    One the one hand, in its ""Proposed Findings"" submitted to the anti-trust court, Microsoft all but endorsed Linux. The section on the findings on competitive operating systems glittered with references to Linux's viability and acceptance. While anti-trust prosecutors no doubt anticipated that sort of tactic from Microsoft, such detailed recognition of Linux coming from Microsoft was stunning. Of course, Microsoft's Proposed Findings were not the findings of the court, and shortly after the trial, Microsoft accordingly changed its public position about Linux.   Documenting the Flip-flop     While Microsoft may have previously characterized Linux as ""pie in the sky,"" the company felt sufficiently threatened to show a short film ridiculing Linux at its July meeting with stock market analysts. Most people would consider that good old-fashioned FUD (Fear, Uncertainty and Doubt), a tactic frequently employed by Microsoft. After the meeting, however, Microsoft executives reportedly emphasized the real point: They had ridiculed Linux because they were afraid of it.     In September, in a hefty document submitted to the anti-trust court (Defendant Microsoft Corporation's Revised Proposed Findings of Fact, Microsoft Does Not Possess Monopoly Power in the Alleged Market for ""Operating Systems for Intel-Compatible PCs."" -- September 10, 1999) Microsoft made over 50 references to Linux as a competitive operating system that is gaining significant momentum and market share.     But in October, Microsoft was on the offensive again, publishing a ""Linux Myths""  ( http://www.microsoft.com/ntserver/nts/news/msnw/LinuxMyths.asp ) page on the web. This time Linux was characterized as a lot of hype.     We all know that Microsoft is a fierce competitor, with many challengers and enemies. But in the interest of separating the hype from the realities, we need to sort out what were the main assertions about Linux that Microsoft declared in its court-filed ""Proposed Findings,"" and how do the compare to the ""Linux Myths"" document.    As one who has been heavily involved with the microcomputing world since the mid '70s, and a member of the Linux community from the outset, I would like to review the Microsoft positions and try to make sense of them. To accomplish this, however, we must assess some obvious contradictions.   Issue 1: Competitive Operating Systems  The case brought by ""We The People"" against Microsoft was for its alleged unfair trading practices that, among other things, stifled innovation. Microsoft countered that charge in their Proposed Findings document by saying there is considerable evidence of significant innovation in the marketplace. Indeed, Microsoft cited Linux very prominently among ""competitive operating systems"" and quoted Gordon Eubanks, CEO of Oblix, as saying Linux has already become a ""viable commercial solution."" Microsoft also cited that Linux ""runs on various popular microprocessor architectures, such as Intel's x86, Compaq's Alpha, Silicon Graphics MIPS, Motorola's PowerPC and Sun's SPARC.""     A month later Microsoft flip-flopped in its Linux Myths by saying, ""Linux does not provide support for the broad range of hardware in use today.""     Microsoft was, in fact, right the first time. In reality, Linux supports most exciting PC hardware and much non-PC hardware. Linux is an innovative extension of Unix as noted in my 1994 document ""Why Linux is Significant,"" which predicted correctly many years ago the state of Linux today  ( http://www.LinuxMall.com/news/announce/lxsig ).      With the proven stability of the Linux kernel, Microsoft is correct to anticipate that various Linux systems will compete effectively with Windows NT. Perhaps more important, Linux will compete with Windows 2000, Microsoft's future contender for the business community. In fact, the wild success of the Red Hat and VA Linux IPOs has no doubt stolen a lot of thunder from the long-planned Windows 2000 rollout.   Issue 2: The User Interface  Running Linux successfully on microprocessors is one thing, but what about the user interface? Microsoft's September position, taken in the Proposed Findings, stated that ""KDE distributes a graphical user interface (GUI) for use with Linux on desktop computers that looks remarkably like Windows 98 . . . and Corel is also developing a graphical user interface for Linux.""    Later on, in its Linux Myths, Microsoft maintains that ""The complexity of the Linux operating system and cumbersome nature of the existing GUIs would make retraining end-users a huge undertaking and would add significant cost."" Another flip-flop.    The fact is, the Corel and KDE interfaces are indeed pleasing and user friendly. So are the ones developed by the Gnome project, Xi Graphics' CDE and others. And when you consider the thousands of expert participants in the Linux community who are contributing their expertise to the free software cause, it suggests that if there's a next quantum improvement in GUIs, it will come through the Linux Community.   Issue 3: Software Applications  Okay, Linux qualifies as an operating system with a GUI. But what about applications? In the Proposed Findings Microsoft says numerous software developers are producing Linux applications, and more are on their way. Those which Microsoft identified included Netscape's browsing software, Lotus Notes, Corel's WordPerfect Office and the StarOffice suite of business applications from Sun, as well as productivity suites and many Internet applications.    In the Linux Myth document Microsoft flip-flopped again, saying, ""Linux as a desktop operating system makes no sense. A user would end up with a system that has fewer applications, is more complex to use and manage, and is less intuitive.""     It seems to me that this flip-flop is not only transparent, but flies in the face of potential future litigation. The fact is, freely-distributed Windows emulators will circumvent many interface problems. Even Microsoft's Proposed Findings recognizes that it's possible to run Windows-based applications for Linux by using WINE emulation software developed by the open source movement. In addition, Red Hat, Caldera, SuSE, TurboLinux, Linux-Mandrake and other future versions of Linux will be bundled with popular desktop applications. And products like Tarantella, which connects dissimilar systems to share applications, and VM-Ware, which allows running Linux and Microsoft OS simultaneously on the same machine, among others are starting to have a significant impact. There is also a significant trend toward the porting of Windows applications to Linux by manufacturers themselves.    Microsoft is also guilty of not being completely honest with its own users. Windows 2000 will be incompatible with a number of existing Windows applications, and with the advent of Intel's 64-bit computing platform, both Linux and Windows will find themselves on a level playing field for applications. When vying for application support on the Intel 64-bit platform, Microsoft may quickly fall behind Linux in terms of available applications.    Issue 4: What About Hardware Support?  What about the big hitters in microcomputer hardware, are they likely to support Linux? According to the Proposed Findings, ""Leading OEMs such as Sun, Dell, Gateway, Toshiba, IBM, Silicon Graphics, Hewlett-Packard and Hitachi, (plus Apple) are now shipping Linux . . . preinstalled on one or more of their computer models.""     Later, in the Linux Myths, Microsoft says ""The Linux community likes to talk about Linux as a stable and reliable operating system, yet there are no real world data or metrics and very limited customer evidence to back up these claims."" Microsoft points to it customers, including Boeing, Barnes and Noble, Dell Computer and Nasdaq, as dependent on Windows NT 4.0 for their mission-critical applications.    While Microsoft has, and will continue to have, an impressive list of high-end customers, so too does Linux. Nearly all of the Fortune 2,000 are listed in LinuxMall.com's customer base, and are using Linux for strategic purposes. As stated by Microsoft and noted in the press on a daily basis, many high-profile computer manufacturers and independent support companies are now offering comprehensive lists of hardware supported by Linux. At the time of this writing, in addition to the manufacturers mentioned by Microsoft, my company, LinuxMall.com, is being flooded by requests from companies wanting to offer Linux-based hardware, as well as offering support services for sale.     Actually, the Internet abounds with stories of failed installations based on Microsoft technology being replaced by Linux and other Open Source systems, and the phenomenal return on investment that doing so brings about.    Issue 5: User Support  The Proposed Findings state that ""five to ten million people were using Linux on workstations or personal computers at the beginning of 1999, and that the number is growing rapidly.""     Then, in Linux Myths: ""Serious corporations are spending serious money on Linux, and it is growing rapidly on all relevant fronts . . .The Linux operating system is not suitable for mainstream usage by business or home users,"" and goes on to explain why Linux has a long way to go to be competitive to Windows.    It doesn't actually surprises me that so many millions of people were using Linux as of last year. As CEO of one of the Internet's largest Linux-related sites, I have seen our traffic grow to more than 1/2 million people per month, many of whom are using Linux. IDC has pegged the growth of the Linux market at about 212% per year, and I believe that Microsoft has pegged the annual Linux growth rate closer to 1000%. That's rather breathtaking, and the rate is obviously capable of continuing in the short term as the support for both corporate and home users gets dramatically better.    Witness to a Paradigm Shift? Microsoft's contradictory position on Linux as a viable competitor seems indicative of the difference between the marketplace and the court. It also indicates that Microsoft senses a paradigm shift similar to the shift that allowed Microsoft to replace IBM as the dominant force in the computer industry. Only time will tell if Linux will displace Microsoft entirely, but the shift is important nonetheless. Just as IBM suffered and then adapted, so will Microsoft. The question is ""when.""     If you're aware of the news in general, you know there is a lot of excitement about Linux, and a certain amount of hype. My guess is that all the ink Linux has generated over the past year has created a 60-70% awareness of the operating system. Of that, perhaps 5-10% took action in 1999. Does that mean it's being oversold? I don't believe so.     Microsoft minimizes the importance of Linux's low cost (actually, no cost to download, and cheaper yet when you consider time, $1.89 for any of the most popular Linux distributions on CD from LinuxMall.com.), arguing that ""A free operating system does not mean low total cost ownership."" However, when a Fortune 1000 business considers running Windows 2000 on servers and thousands of workstations, they will be faced with paying millions of dollars for their operating system in licensing fees alone! In addition, it is common knowledge that it is not out of the ordinary to need to reboot Windows NT servers weekly or monthly in order to avoid problems. Linux, on the other hand, has been proven to run for months and sometimes years without requiring a reboot. In 24/7 operations this is a critical issue. This is especially true when the cost of supporting Linux, because of its stability and configurability, may actually be lower than for Windows NT, even while techs for Linux are being quickly spawned by universities and the Internet. These are reasons why many if not most of the ISPs that once used Windows NT now use Linux or its Open Source cousin, FreeBSD, as will more and more corporations.    I believe Linux is en route to becoming the operating system of choice very soon. Its development simply cannot be stopped, simply because of the community dynamic behind it. As people become aware of how rapidly Linux is getting easier to use and support, acceptance at the desktop will grow dramatically. In the next two or three years, Linux will continue to attain significant market penetration. Over the next five years, it has a chance to become the dominant operating system for general use.    I also believe that the findings of fact tend to underestimate what is happening with Linux. In general, the present situation is accurately depicted by the findings, but I believe Judge Jackson has erred on the side of caution in finding that Linux is not a significant long-term competitor to Microsoft. However, Judge Jackson can be excused for his lack of vision concerning Linux since proving that Microsoft would have significant competition in the future will not excuse them for past actions.    In the end, Microsoft's public smoke screen cannot obscure the fact that Linux is a viable operating system for servers and desktops alike. Linux has made good on being the ""better UNIX than UNIX"" that was the stated goal of Windows NT. The question is no longer, ""Is Linux ready for you?"" The question now is, ""Is the public ready for Linux?""                 Copyright © 2000, Mark Bolzern   Published in Issue 52 of  Linux Gazette , April 2000        ""Linux Gazette... making Linux just a little more fun! ""                 HelpDex   By  Shane Collinge                  Database                     Paper Clips                     Cartooning          More  HelpDex  cartoons are on Shane's web site,   http://mrbanana.hypermart.net/Linux.htm .                    Copyright © 2000, Shane Collinge   Published in Issue 51 of  Linux Gazette , March 2000        ""Linux Gazette... making Linux just a little more fun! ""                 A Fantastic Interview with Wine's Man Alexandre Julliard   By  Fernando Ribeiro Corrêa  and Luis Strano   Originally published at   http://www.olinux.com.br/interviews/10/en                     Olinux: Tell us about your background?    Julliard:   I've studied computer science at the Swiss Federal Institute of Technology. I've been working in software development for the last 10 years, mostly in embedded software (routers, payphones, etc.), and I've been working as a hobby on the Wine project since its start in 1993.   Olinux: Explain shortly the Wine's History and Organization? What´s its main purpose?    Julliard:   Wine started in 1993, and I've been the maintainer since 1994. The main purpose is to allow running Windows binaries under Linux (and other Unix systems), as well as to allow people to recompile their existing Windows source code to build native Unix binaries without having to modify the existing code.  The organisation is along the ""benevolent dictatorship"" model; all the changes are submitted to me, and I have the final say on what gets or doesn't get into the source tree.   Olinux: What is your main work in real life? Are you full time worker for  wine?    Julliard:   I'm working for the company CodeWeavers; part of my job is to work on Wine, the other part is to work on custom development jobs for customers. At the moment this includes doing Wine development on  behalf of Corel, so yes I'm mostly working full-time on Wine, at least for now.   Olinux: What you do in Wine?    Julliard:   A little bit of everything... my speciality is mostly in the low-level areas like memory management, threading, etc. Plus of course studying incoming patches and merging them into the source tree.   OLinux: Are there business companies or any other type of organization that  finances Wine development? How did Corel investment and support change  wine´s development?    Julliard:   There is no organisation putting funds directly into Wine, but there are companies having people work on Wine; of course the major contributor in this area is Corel, with a lot of people working full-time on Wine.  Corel's involvment has done a lot for Wine, mainly by addressing areas of the code that had been a bit neglected until then, and also by doing extensive testing of all their office suite under Wine and fixing all the problems they encountered. Wine is definitely much better now than it would have been without Corel's help.   Olinux: Everyone in Wine's staff is a volunteer?    Julliard:   No, since there are people at Corel working on it as part of their job.   Olinux: How people are organized and what are tools are used to control the  results of the work being done in different projects and parts of the  world?    Julliard:  People communicate through mailing lists, and all the code is in a CVS repository accessible read-only by anybody. All the changes are reviewed by me, and then stored in the CVS tree where anybody can test them.   Olinux: How many people are working for wine nowadays? Are you satisfied  with  the  results?    Julliard:  It's hard to say exactly how many people are working at any given moment, but I'd estimate it at 30-40 active developers. I think the results are very impressive, particularly when compared to the amount of resources Microsoft is putting into Windows.   Olinux: Are there anything that can be done to improve productivity?    Julliard:  Having more people of course; better documentation of the Windows API would help a lot but I don't think there is much to hope for from Microsoft in this respect.   Olinux: Describe the active projects and their core activities? How are the tasks divided and co-ordinated in terms of content and staff?    Julliard:  There is no formal organisation in sub-projects. Everybody works on what he wants to, and coordination is done through the mailing list and CVS tree.   Olinux: How would you answer Bill Gates statements that Linux wasn't any danger to  Microsoft monopoly because it was decentralized and  uncoordinated?    Julliard:   Linux is a danger to Microsoft precisely  because it is decentralized. There isn't one company that you can buy or put out of business, so the usual Microsoft tactics do not work against Linux.   Olinux: Do you see any problem regarding quality of software development and maintenance due associated to the volunteer work?    Julliard:  I think the quality is usually better with volunteer work, since people take the time to do things the right way, and also take more pride in their work since it is published for the whole world to see.  The main problem with volunteer work is that the parts of the code that are less fun to write get less attention; this is why it is a good thing to have both volunteer and paid developers on the same project.   Olinux: How do you describe wine achievements in 90's and what are the prospects and goals for 2000? When users will have a perfect version of wine?    Julliard:   Wine has come a very long way, from the initial 16-bit support to now nearly complete support of both 16- and 32-bit APIs, OLE, DirectX, etc. We are getting to the point where the core of Wine is complete, which should lead us to the first general public release, hopefully sometime this year.   The perfect version that runs 100% of the applications with 100% compatibility is probably never going to exist, but a version that is perfect for a certain number of tested applications is certainly possible; and in fact today's Wine is already perfectly good enough for certain applications.     The OLinux site also has more Linux interviews.      English:   http://www.olinux.com.br/interviews/     Portuguese:   http://www.olinux.com.br/entrevistas/                     Copyright © 2000, Fernando Ribeiro Corrêa and Luis Strano   Published in Issue 52 of  Linux Gazette , April 2000        ""Linux Gazette... making Linux just a little more fun! ""                 Linux Site O' The Month: Glade   By  Sean Lamb                    What's This?     This article is the the current installment in an ongoing series of site reviews for the Linux community.  Each month, I will highlight a Linux-related site and tell you all about it.  The intent of these articles is to let you know about sites that you might not have been to before, but they will all have to do with some aspect of Linux. Now, on with the story...    Glade ( http://glade.pn.org/ )    Linux, and UN*X in general, rocks the command line.  However, as more users familiar with that  other  operating system migrate to a real operating system, they expect to see a graphical interface on almost everything.  You may argue that this is a Bad Thing, but as a programmer myself, I see this as a Good Thing.  It means that more and more programs will need to be written, updated and maintained, which translates to job security.   With users migrating from another windowing system, they expect to find programs that have a windowing interface.  Even with the advantage that there is almost always more  than one way to do something in Linux, the choice of windowing libraries to use can very quickly generate a religious war, so I'll try not to spread any of my own preferences in this area, lest I become a target myself.   Until recently, it has been difficult to write a completely windows-driven (note the  lack of capitalization here) user interface from scratch.  Writing an interface with a text editor and compiler can be exceedingly time consuming for a programmer who isn't  intimitely knowledgeable about the windowing library.  That's where Glade comes in.   The program...    Glade is an attempt to create an interface builder that uses the GTK+ library to  create the widgets that the programmer needs for an application.  If you have the  GNOME development libraries installed, Glade can produce native GNOME application  interfaces as well.  Once you get used to creating and placing widgets in Glade, you can create some very complex interfaces in a manner of minutes.   When the interface is the way that you like, Glade can create the source code for you in either C, C++, Ada95, Python and Perl.  Glade will also allow you to create a dynamically loaded interface that uses libGlade to read and build the screen definitions without generating source code (this can be handy for writing quick dialog boxes or informational windows).   Although Glade is currently still in development, now at version 0.5.7, my testing proved this to be a robust application that was able to create the interface that I wanted with a minimum of troubles.   The website...    This wouldn't be a Linux Site O' The Month without a look at the website, so let's take a closer look...   At first glance, the Glade website isn't the most exciting site on the internet.  But, that's not necessarily a Bad Thing.  With a minimum of graphic elements on the main page, it is a very fast-loading site, compared to others that I've seen recently.  The site is  frameless, which I am tending to like more as I see frames so misused on other sites.   The Features section of this site includes screenshots of the three windows that make up the Glade interface as well as some sample images of interfaces that were created with Glade. The Download page includes the usual list of source code tarballs and a few prebuilt packages for some of the more popular distros.  The developer has included both the release history  and todo list for Glade in the History and ToDo sections, respectively.  If your mailbox isn't quite full enough yet, you can get your fill under the Mailing Lists link.  Finally, in the Links section, there are links to information and tools that use or support Glade, while the Applications section highlights apps that were built with Glade.   This isn't a very big website, but what it lacks in size, it makes up in content.  There is enough information on this site to help you get Glade installed on your box, get you started building applications with it, and get you examples of other programs that were created with it.  If you've been thinking of building an application for Linux but don't know where to start in building your interface, try Glade.  You'll be surprised at how easy it can be to get down  to writing the code that controls your program and not worry about how it connects to the user's rodential device pointer.              Copyright © 2000, Sean Lamb   Published in Issue 52 of  Linux Gazette , April 2000        ""Linux Gazette... making Linux just a little more fun! ""                 ""Cannot execute /bin/bash: Permission denied"" - solved!   By  Ben Okopnik                   Just a few minutes before sitting down to write this article, I managed to fix a problem that has been the bane of my existence for the last two weeks. Since it is a problem that I have often seen mentioned in the Linux Gazette, usually phrased in a manner that shows the writer to be standing on a chair with a noose around his neck and typing with his toes, I've decided to share it with other readers, hopefully saving them wear and tear on good rope. This may also serve as a good guide to troubleshooting software problems in general. Be aware, though, that a login problem could involve _any_ of the areas described - what fixed my particular machine may not be the solution for yours.     A couple of weeks ago, I decided to install an MUA (Mail User Agent) on my  machine. A strange thing to do, considering that I live on a sailboat  anchored well away from phone lines or electricity - but I had my reasons.  I'd done this on land-based systems before; there was just a bit of  experimentation that I wanted to do.  Wel  l, as a pride of lemmings goeth before a fall off a cliff, so does an  MTA (Mail Transfer Agent) go before an MUA - you need something that  will deliver the mail, otherwise there's not much point in writing it! So,  an MTA/MUA installation. No problem - I keep the entire Debian  distribution on the Linux partition of my hard drive; this speeds up installations as well as making package searches a trivial task.    If truth be known, I don't like 'su', at least not for major tasks: the fact that it keeps the original user's environment variables, rather than assuming those of the account being ""su""'d to, has caused me a few ""interesting moments"". Yeah, a quick permissions change or an /etc file modification - all right, - but for serious work, like installing and uninstalling several major packages (I wasn't sure which MTA I wanted yet), I log in as `root'.    On to the task. Midnight Commander makes it the work of a few keystrokes to dive into and explore a directory tree, as well as letting you look inside - and install - any Debian or RedHat package. Let's see...  `sendmail'? (Read the `man' page inside the package, look at the docs,  install...) Nope, too big and complex. I need something a bit simpler.  (Uninstall.) `exim'?... `exmh'?... `mh'?... `nmh'? All got the same  ""install/uninstall"" treatment, with the exception of required libraries:  whenever I install a library, it stays installed. After a bit of doing  this on a new system, I don't get any complaints about `Required libraries  missing' - if it wasn't for the fact that a number of libs in any given  distribution are `either/or' choices (they'd conflict with each other), I'd install the entire ""libs"" directory and never worry about it again!    However, I still had an MTA to choose. Ah, `smail'! Easy to install,  painless to configure - done. Easy choice for an MUA - I really like the  configurability of `mutt' - and I'm finished! (Prophetic words...)    EXCEPT. Now, I found that I could not log in as a non-root user anymore.  The message I got was:   Cannot execute /bin/bash: Permission denied      What in the heck was this?     `Was this some occult illusion?   Some maniacal intrusion?   These were choices Solomon   Himself had never faced before...'       I knew that I hadn't done anything in /etc/password - for that matter, anything in /etc - but I wasn't 100% sure of what those packages, safe as they're supposed to be, were doing under my auspices as `root'. So, I quickly did some double-checks - yes, user `ben' still existed in /etc/password; ditto for group `ben' in /etc/group; entering the wrong string as a password provoked the usual `Login incorrect' message instead of the `Cannot execute'. Hmm.    Another double-check: I created a new user (""joe""), new password and all  (""joe"") , and tried to log in as that user. No go, same error. Something in the login sequence had died, for reasons unknown. (Goodbye,  ""joe""...)    At this point, I let out a quiet ""eep!"" of minor panic, very quickly switched to another VT, and tried to log in as `root'. WHEW; no problems there. At least I would still have access to the machine when I next brought it up... I'd have hated to do an immediate `live' backup and reinstallation!     Open up /bin. What do the file permissions look like? Uh-huh... everything is set to 755 (-rwxr-xr-x); in addition, `login', `mount', `umount', `ping' and `su' are all SETUID (-rwsr-xr-x). So far, so good; how about /etc permissions? They all look OK too - mostly 644 (-rw-r--r--), with an occasional 600 (-rw-------) here and there, for files denied to everyone but `root'. All right, let's try something silly; I overwrote `login' and `bash' with fresh copies, straight out of their original packages, to make sure that they weren't corrupted. Nope; still no luck.    Wait, how about /home? If the permissions on that got mis-set and the user  couldn't get in... Rats, it was fine too - 6775 (drwxrwsr-s). Checking the  .bashrc and .bash_profile showed nothing unusual - and their perms were  OK. Just for kicks, I checked all the other subdirectories in '/'; all except /root were world-readable, which was fine.    There are a couple of files in /var that keep track of who's logged in, when they logged out, and so on; if these guys get corrupted, *all* sorts of strange unpredictable stuff happens. So - emergency measure time!  - I typed   cat >/var/log/wtmp cat >var/run/utmp    which blew their contents away and left them as zero-length files.   [He actually typed this without the ""cat"", but I put the ""cat"" in to make it clear that the "">"" was part of the command line and not the  shell prompt. -Ed.]   I  logged out on all VTs (just so `utmp' and `wtmp' would get some data),  and...   the usual result.    Permissions on /dev/ttyX and /dev/vcsX (terminals and virtual consoles)?  They all looked OK too; I was starting to lose hope.     Wait; what about a systematic approach? Let's get an idea of exactly  what's happening before running in every direction. A quick look at the System Administrator's Guide (SAG) to refresh my memory - ah, there's the login process:                 From the ""System Administrator's Guide"", by Lars Wirzenius             First, init makes sure there is a getty program for the terminal      connection (or console). getty listens at the terminal and waits for the     user to notify that he is ready to login in (this usually means that the     user must type something). When it notices a user, getty outputs a welcome      message (stored in /etc/issue), and prompts for the username, and finally     runs the login program. login gets the username as a parameter, and     prompts the user for the password. If these match, login starts the shell     configured for the user; else it just exits and terminates the process     (perhaps after giving the user another chance at entering the username and     password). init notices that the process terminated, and starts a new     getty for the terminal.                                                                ' ' ' ' ' ' ' '                            ------------                    '   GIF2ASCII   '                           |   Start    |                   ' conversion by '                            ------------                    ' ""fastfingers"" '                                 V                          '    program    '                         -------------------                 ' Copyleft 2000 '            ___________| init: fork + exec |_______          ' ' ' ' ' ' ' '           |           | ""/sbin/getty""     |       |           |            -------------------        |           ^                     V                 ^           |          ----------------------       |           |         | getty: wait for user |      |           |          ----------------------       |           ^                     V                 ^           |         ----------------------        |           |        | getty: read username,|       |           |        | exec ""/bin/login""    |       |           |         ----------------------        |           ^                     V                 ^           |         ----------------------        |           |        | login: read password |       |           |         ----------------------        |           ^                     V                 ^        |                    / \                |           |                   /   \               |      -------------           /  Do \              |     | Login: exit |---<-No- /  they \             |      -------------          \ match?/             ^                              \     /              |                               \   /               |                                \ /                |                                 | Yes             ^                                 V                 |                     ------------------------      |                    | login: exec(""/bin/sh"") |     |                     ------------------------      ^                                 V                 |                      ----------------------       |                     | sh: read and execute |      |                     | commands             |      ^                      ----------------------       |                                 V                 |                             ----------            |                            | sh: exit |-----------                             ----------                                      Figure 8.1: Logins via terminals: the interaction of init, getty, login,     and the shell.        Note that the only new process is the one created by init (using the     fork  system call); getty and login only replace the program running in the     process (using the exec system call).                 Following the process, we can see that everything up until the last part - the 'exec(""/bin/sh"")', that is - seems OK. It's during or after that hand-off that things go wild. The problem was now down to system calls, something I wasn't quite sure how to approach... and yet that piece of information contained everything I needed to know; I just didn't know how to apply it. Later on, it would become self-evident.    Over the next ten days or so, every time I logged in I would try something new; some things totally outlandish and unlikely to work; some, bright ideas that produced great disappointment when the Evil Message once again showed its head. Nothing worked. I replaced `getty'; tried a couple of shells other than /bin/bash; tried ""su""ing to `ben'; checked the logs (they showed `ben' as having successfully logged in (!), which told me that `login' was fine; the failure occurred when it handed the process off to `bash' - I knew that!)...    After finding only a few references to this on the Net - mostly in Japanese, Swedish, and German (I managed to puzzle out the last two - one of them suggested checking perms on '/' ! Excellent idea...  which didn't pan out in my case), I shot off a panicked resume of the problem to the The Answer Guy   - Hi! <grin> Unfortunately, he must have been swamped by all those Windows2000 questions that he just loves to answer... anyway, I was cast on my own resources.     Ah - `strace'! Remember `strace'; `strace' is your friend... A really  fantastic piece of software that traces the execution of a program and  reports it, step by step. Let's go!     Since you have to be logged in to run a program, I ran   strace -s 10000 -vfo login.ben login ben      from my current VT; this meant ""Run strace on `login ben'; print all lines up to 10000 characters long (I didn't want to miss any messages, no matter how long they were); make the output verbose; trace any forked processes; output the result to a file called `login.ben'"". Then, as a baseline, I ran   strace -s 10000 -vfo login.root login root     - and now, I had two files to compare. The `root' one was about twice  as long as `ben' - that made sense, since a successful login goes on to execute all the stuff in the ""~/.bash*"" files.    `strace login' makes for very informative reading. If I hadn't already read the System Administrator's Guide, this would have given me the exact information - in far more detail. It shows all the libraries that are read, every file examined by `login', the comparison procedure for `group' and `password'... the only thing it did NOT show was the reason for the failure; just the fact itself, at exactly the point in the procedure where I expected it to be:   (300+ lines elided) execve(""/bin/bash"", [""-bash""], [""TERM=linux"", ""HZ=100"", ""HOME=/home/ben"",      ""SHELL=/bin/bash"", ""PATH=/bin:/usr/bin"", ""USER=ben"", ""LOGNAME=ben"",      ""MAIL=/var/spool/mail/ben"", ""LANG=C"", ""HUSHLOGIN=FALSE""]) = -1 EACCES      (Permission denied)             write(2, ""Cannot execute /bin/bash: Permission denied\n"", 44) = 44      Just great. The last thing poor `login' tried to do, before falling over  on its back with its legs twitching in the air, was to `execve' bash with the defined variables collected from /etc/password, /etc/login.defs, and so on - all of those looked OK - and write those 44 hateful characters to ""stderr"" (output descriptor 2). Basically, the stuff I'd already figured out.    I did notice, however, that `login' was opening a number of libraries in /lib that were needed by the Name Service Switch configuration file (/etc/nsswitch.conf). What if one of the mentioned libraries was corrupted?  That would be right in line with the `system calls' theory - since libraries are where the system calls come from! Let's check the lib that handles local logins for NSS (see `man nsswitch'):   dpkg -S libnss_compat-2.0.7.so     (""Tell me, O Mighty Debian Package Manager, whence cometh said program?""), and the Debian Oracle, in his wisdom, replied -   libc6: /lib/libnss_compat-2.0.7.so      Humm. The very core of the Linux libs. Well... a quick replacement of all  the /lib/libnss* ... and no change. Next idea.    This procedure got me thinking, though. Something was indeed ""rotten in the state of Denmark"" - perhaps I needed to check perms on the files in /libs?    The only problem was, I didn't know what they were supposed to be. You  see, most of the libs are set to ""root.root 644"" - owner root, group root,  user - read/write, group - read-only, others - read-only. There are a few, though, that should be set ""root.root 755"" - as above, but with ""execute"" permissions for everyone added... and without looking at a fresh Linux installation, I had no idea of what was right.    WAIT a minute! As I'd mentioned in a 2-cent tip that I'd sent in to LG, I  like to keep a copy of a Debian ""base installation"" file set (7 files,  about 15MB) on my DOS partition as a 'rescue' utility - it should have  everything I need!                And so it was. Midnight Commander, via its ""Virtual File System"", allows you to explore compressed files as if they were directories; a look inside ""base2_1.tgz#utar/lib"" (the VFS syntax used by MC) showed me that one of the very first libs - ld-2.0.7.so - was supposed to be set to 755. Ten seconds later, I was the owner of a brand-new Virtual Terminal - as user `ben'.    Yes, I did check the perms on all the other libraries; `ld-2.0.7.so' was  the only one that was affected. The only remaining `unknown' was how the  perms changed in the first place... but I suspect that question will never  be answered.         As usual, the lessons that Linux teaches are hard - but fair. There's  *always* a way to solve a problem; admittedly, often the easiest way is to  reinstall the system, but this does not teach you the ""innards"" of an OS  the way tracking down a problem will. In my case, reinstallation would  have been relatively easy: I have a couple of spare drives, easily big  enough to hold my ""up to the minute"" data so that I don't even need to  touch my backups, and a basic Debian install takes me less than 10 minutes. I wasn't interested in that. The thought uppermost in my mind  was: ""What would happen if this occurred at a customer's site?"" I   needed   to know what the right solution was... and through persistence - no, sheer  bloody-mindedness - I succeeded.       I don't suggest that every one of you beat his brains out against some difficult problem once a week just to ""keep in practice"" - but I do suggest that you use a methodical approach, based on knowledge gained from reading the appropriate HOWTOs and other documentation available before grabbing that installation CD yet another time. There will be times when you'd like nothing better than to laugh maniacally as you watch your system shrink to a pinpoint, dropping away from your lofty perch on the Empire State Building... and there will be other times when the satisfaction of having solved a knotty problem of this sort makes you pound your chest and do Tarzan imitations.     Now, if you all will excuse me, I've got a chimpanzee and an elephant I'm  supposed to meet...      Happy Linuxing to all,  Ben Okopnik                 Copyright © 2000, Ben Okopnik   Published in Issue 52 of  Linux Gazette , April 2000        ""Linux Gazette... making Linux just a little more fun! ""                 Introduction to Shell Scripting--The Basics   By  Ben Okopnik                                    Introduction to Shell Scripting - The Basics        ``Here's a hint. When you think your code to exec a shell function is just not working, never, repeat NEVER send it ""/etc/reboot"" just to see what happens.''   -- Elliott Evans    INTRO  Shell scripting is a fascinating combination of art and science that gives you access to the incredible flexibility and power of Linux with very simple tools. Back in the early days of PCs, I was considered quite an expert with DOS's ""batch files"", something I now realize was a weak and gutless imitation of Unix's shell scripts. I'm not usually much given to Microsoft-bashing - I believe that they have done some absolutely awesome stuff in their time - but their BFL (""Batch File Language"") was a joke by comparison. It wasn't even a funny one.  Since shell scripting is an inextricable part of the shell itself, quite a bit of the material in here will deal with shell quirks, methods, and specifics. Be patient; it's all a part of the knowledge that is necessary for writing good scripts.     PHILOSOPHY OF SCRIPTING  Linux - Unix in general - is not a warm and fuzzy, non-knowledgeable-user  oriented system. Rather than specifying exact motions and operations that you  must perform, it provides you with a myriad of small tools which can be connected in a literally infinite number of combinations, to achieve any result that is necessary (I find Perl's motto of ""TMTOWTDI"" - There's More Than One Way To Do It - highly apropos for all of Unix). That sort of power and flexibility, of course, carries a price - increased complexity and a requirement for higher competence in the user. Just as there is an enormous difference between operating, say, a bicycle versus a super-sonic jet fighter, so is there an enormous difference between blindly following the rigid dictates of a standardized GUI and creating your own program, or shell script, that performs exactly the functions you need in exactly the way you need them done.  Shell scripting is programming - but it is programming made easy, with little, if any, formal structure. It is an interpreted language, with its own syntax - but it is only the syntax that you use when invoking programs from your command line; something I refer to as ""recyclable knowledge"". This, in fact, is what makes shell scripts so useful: in the process of writing them, you continually learn more about the specifics of your shell and the operation of your system - and this is knowledge that truly pays for itself in the long run as well as the short.     REQUIREMENTS  Since I have a strong preference for `bash', and it happens to be by far the most commonly used shell, that's what these scripts are written for. Even if you use something else, that's still fine: as long as you have `bash' installed, these scripts will execute correctly. As you will see, scripts invoke the shell that they need; it's part of what a well-written script does.  I'm going to assume that you're in your home directory, since we don't want these files scattered all over the place where you can't find them later. I'm also going to assume that you know enough to hit the ""Enter"" key after each line that you type in, and that, once you have selected a name for your shell script, you will check that you do not have an executable with that same name in your path ( Hint: type ""which bkup"" to check for an executable called ""bkup"" ). For this specific reason, you should  never  name your scripts ""test"". This is one of the FAQs of Unix, a.k.a. ""why doesn't my shell script/program do anything?"" There's an executable in /bin called ""test"" that does nothing (nothing obvious, that is) when invoked...  It goes without saying that you have to know the basics of file operations - copying, moving, etc. - as well as being familiar with the basic assumptions of the file system, i.e., ""."" is the current directory, "".."" is the parent (the one above the current), ""~"" is your home directory, etc. You didn't know that? You do now! <chuckle>  Whatever editor you use, whether `vi', `emacs', `mcedit' (the default editor in  Midnight Commander  and one of my favorite tools), or any other text editor is fine; just don't save this work in some word-processing format.  In order to avoid constant repetition of material, I'm going to number the lines as we go through and discuss different parts of a script file. I'll be putting it all together at the end, anyway.     BUILDING A SCRIPT  Let's go over the very basics of creating a script. Those of you who find this obvious and simplistic are invited to follow along anyway; as we progress, the material will become more complex - and a ""refresher"" never hurts. As it is, the projected audience for this article is a Linux newbie, someone who has never created a shell script before - but wishes to become a Script Guru in 834,657 easy steps. :)     In its simplest form, a shell script is nothing more than a shortcut - a list of commands that you would normally type in, one after another, to be executed at your shell prompt - plus a bit of ""magic"" to notify the shell that it is indeed a script.  The ""magic"" consists of two simple things: a notation at the beginning of the script that specifies the program that is used to execute it, and a change in the permissions of the file containing the script in order to make it executable.  As a practical example, let's create a script that will ""back up"" a specified file to a selected directory; we'll go through the steps and the reasoning that makes it all happen.  First, let's create the file and set the permissions. Type  >bkup chmod +x bkup  The first line creates a file called ""bkup"" in your current directory. The second line makes it executable; note that the ""+x"" option of `chmod' makes this script executable by everyone - if you wish to restrict that, you'll need to run `chmod' with ""u+x"" or ""ug+x"" (see the ""chmod"" man page). In most cases, though, just plain ""+x"" is fine.  Next, we'll need to actually create the script. Start your editor and open up the file you've just made:  mcedit bkup  The first line in all of the script files we create will be this one (again, remember to ignore the number and the colon at the start of the line):  1: #!/bin/bash    I've heard this referred to as the 'hash-bang hack'. The interesting thing about it is that the pound character is actually a comment  marker - everything following a '#' on a line is supposed to be ignored by the shell - but the '#!' construct is unique in that respect, and is interpreted as a prefix to the name of the executable that will actually process the lines that follow.  This is a subtle but important point, by the way: when a script runs, it actually starts an additional bash process that runs under the  current one; that process executes the script and exits, dropping you back in the original shell that spawned it. This is why a script that,  for example, changes directories as it executes will not leave you in that new directory when it exits: the original shell has not been told to change directories, and you're right where you were when you started - even though the change is effective while the script runs.  To continue with our script:  2:  # ""bkup"" - copies specified files to the user's ~/Backup 3:  # directory after checking for name conflicts.    As I've mentioned, the `#' character is a comment marker. It's a good idea, since you'll probably create a number of shell scripts in the  future, to insert some comments at the beginning of each one to indicate what it does - or at some point, you'll be scratching your  head and trying to remember why you wrote it. In later columns, we'll explore ways to make that reminder a bit more automatic... but let's go on.  4: cp -i $1 ~/Backup      The ""-i"" syntax of the `cp' command makes it interactive; that is, if we run ""bkup file.txt"" and a file called ""file.txt"" already exists in  the ~/Backup directory, `cp' will ask you if you want to overwrite it - and will abort the operation if you hit anything but the 'y' key.  The ""$1"" is a ""positional parameter"" - it denotes the first thing that you type after the script name. In fact, there's an entire list of  these variables:  $0 - The name of the script being executed - in this case, ""bkup"". $1 - The first parameter - in this case, ""file.txt""; any parameter may      be referred to by $<number> in this manner. #@ - The entire list of parameters - ""$1 $2 $3..."" $# - The number of parameters.  There are several other ways to address and manipulate positional parameters (see the `bash' man page) - but these will do us for now.     MAKING IT SMARTER  So far, our script doesn't do very much; hardly worth bothering, right? All right; let's make it a bit more useful. What if you wanted  to both keep the file in the ~/Backup directory  and  save the new one - perhaps by adding an extension to show the ""version""? Let's try  that; we'll just add a line, and modify the last line as follows:  4: a=$(date +%T-%d_%m_%Y) 5: cp -i $1 ~/Backup/$1.$a    Here, we are beginning to see a little of the real power of shell scripts: the ability to use the results of other Linux tools, called ""command substitution"". The effect of the $(command) construct is to execute the command inside the parentheses and replace the entire ""$(command)"" string with the result. In this case, we have asked `date' to print the current time and date, down to the seconds, and pass the result to a variable called 'a'; then we appended that variable to the filename to be saved in ~/Backup. Note that when we assign a value to a variable, we use its name ( a=xxx ), but when we want to use that value, we must prepend a '$' to that name (.../$1.$a). The names of variables may be almost anything, with these exceptions:     No reserved words, i.e.       case do done elif else esac fi for function if in select then until while time          May not contain unquoted metacharacters or reserved characters, i.e.       ! { } | & * ; ( ) < > space tab           Should not unintentionally be a standard shell variable, such as       PATH PS1 PWD RANDOM SECONDS (see ""man bash"" for many others)      In my experience, if you confine your variable names to lower-case letters, dashes, and underscores, there won't be any problems.     The effect of the last two lines in the script is to create a unique filename - something like  file.txt.01:00:00-01_01_2000  - that should not conflict with anything else in ~/Backup. Note that I've left in the ""-i"" switch as a ""sanity"" check: if, for some truly strange reason, two file names do conflict, ""cp"" will give you a last-ditch chance to abort. Otherwise, it won't make any difference - like dead yeast in beer, it causes no harm even if it does nothing useful.  By the way, the older version of the $(command) construct - the `command` (note that ""back-ticks"" are being used rather than single quotes) - is deprecated, for a good reason. $()s are easily nested -  $(cat $($2$(basename file1 txt))) , for example; something that cannot be done with back-ticks, as the second back-tick would ""close"" the first one, and the command would fail, or do something unexpected. You can still use them, though - in single, non-nested substitutions (the most common kind), or as the innermost or outermost pair of the nested set - but if you use the new method exclusively, you'll always avoid that error.     So, let's see what we have so far, with whitespace added for readability and the line numbers removed (hey, an actual script!):  #!/bin/bash    # ""bkup"" - copies specified files to the user's ~/Backup # directory after checking for name conflicts.    a=$(date +%T-%d_%m_%Y) cp -i $1 ~/Backup/$1.$a    Yes, it's only a two-line script - but one that's starting to become useful. We'll continue playing with it in the next issue.     Oh, one last thing; another ""Unix FAQ"". Should you try to execute your newly-created script by typing  bkup  at the prompt, you'll get this familiar reproof:  bash: bkup: command not found   -- ""HEY! Didn't we just sweat, and labor, and work hard... What happened?""  Unlike DOS, the execution of commands and scripts in the current directory is disabled by default - as a security feature. Imagine what would happen if someone created a script called ""ls"", containing ""rm -rf *"" (""erase everything"") in your home directory and you typed ""ls""! If the current directory (""."") came before ""/bin"" in your PATH variable, you'd be in a sorry state indeed...  Due to this, and a number of similar ""exploits"" that can be pulled off, you have to specify the path to all executables that you wish to run there - a wise restriction. You can also move your script into a directory that is in your path, once you're done tinkering with it; ""/usr/local/bin"" is a good candidate for this ( Hint: type ""echo $PATH"" to see which directories are listed ).  Meanwhile, in order to execute it, simply type  ./bkup file.txt   - the ""./"" just says that the file to be run is in the current directory. Use ""~/"", instead, if you're calling it from anywhere else;  the point here is that you have to give a complete path to the executable, since it is not in any of the directories listed in your  PATH variable.  This assumes, of course, that you have a file in your current directory called ""file.txt"", and that you have created a subdirectory  called ""Backup"" in your home directory. Otherwise, you'll get an error.     REVIEW  In this article, we've looked at some of the basics involved in creating a shell script, as well as some specifics:      File creation     Permissions     Spawned subshells     Execution in a non-PATHed directory        The `hash-bang hack'     Comments     Positional parameters     Command substitution     Variables       WRAP-UP  Well, that's a good bit of information for a start. Play with it, experiment; shell scripting is a large part of the fun and power of  Linux. Next month, we'll talk about error checking - the things your script should do if the person using it makes an error in syntax, for example - as well as getting into loops and conditional execution, and maybe dealing with a few of the ""power tools"" that are commonly used in shell scripts.  Please feel free to send me suggestions for any corrections or improvements, as well as your own favorite shell-scripting tips or any really neat scripting tricks you've discovered; just like anyone whose ego hasn't swamped their good sense, I consider myself a student, always ready to learn something new. If I use any of your material, you will be credited.  Until then -  Happy Linuxing!         REFERENCES  ""man"" pages for 'bash', 'cp', 'chmod'     ``Not me, guy. I read the Bash man page each day like a Jehovah's Witness reads the Bible. No wait, the Bash man page IS the bible.   Excuse me...''   -- More on confusing aliases, taken from comp.os.linux.misc                  Copyright © 2000, Ben Okopnik   Published in Issue 52 of  Linux Gazette , April 2000        ""Linux Gazette... making Linux just a little more fun! ""                 Linux Gazette art   By  Mike Orr                   In the last issue, your humble Editor asked if anybody wanted to send in any artwork to jazz up the Gazette.  I received two entries.            Linux Total World Domination 2005    John Hinsley < jhinsley@telinco.co.uk >        Penguin created using xpaint    Rick Smith < rsmith13@tampabay.rr.com >                      Copyright © 2000, Mike Orr   Published in Issue 52 of  Linux Gazette , April 2000        ""Linux Gazette... making Linux just a little more fun! ""                 Exploring parsing and virtual machines with Python   By  Pramode C E                   The design of compilers/interpreters is a challenging field - one which offers a lot of scope for theoretical exploration as well as hands on coding. Being a Python fan, I tried to implement some of the ideas which I am learning about compilers/interpreters in this beautiful language. As I am neither a Python Guru nor a compiler expert, the implementation may be imperfect. But it was certainly lots of fun!    A simple language   Don't be disappointed when I tell you that we are not going to discuss the implementation of an Object Oriented, functional language with automatic garbage collection and the works! The language I am talking about here is the one which we learn as kids, the language of arithmetic expressions. For example,   1+2*3-4 1/2+3-4/5 .....   We will start with a program which will read an expression of this form and evaluate it directly. We will then modify this program to generate a data structure called a parse tree which can then be evaluated by recursive algorithms. The next step is to generate instructions for a virtual machine using this parse tree. The last step is to store these virtual machine instructions on disk  and run it with an interpreter when required.    Context-free grammars     Programming languages are often described using a compact and powerful notation called a Context-free Grammar. The grammar describes a set of substitutions. Here is a grammar for arithmetic expressions:   E ::= T { ADDOP T } T ::= F { MULOP F } F ::= 0 | 1 | 2 | 3 | ..... ADDOP ::= + | - MULOP ::= * | /    Assume that E stands for expression, T stands for term and F stands for factor. The curly brace denotes 'zero or more repetitions'. Reading the first production, we would say that ""An expression is a term, followed by zero or more repetitions of the combination of an adding operator and a term."" The third production says that a factor is either 0 or 1 or 2 or 3 or 4 and so on, ie, the whole set of positive integers. It takes some time to get used to esoteric definitions like this, but if we have a basic understanding of recursive structures, it is not very difficult.    A simple expression evaluator     Here is the source for a simple expression evaluator in Python. ( text version )   #--------------------A simple expression evaluator---------------#  import re, string Inputbuf = []   # A token is either a number or an operator symbol.  # The main program reads a line from the input and # stores it in an array called Inputbuf. The function # gettoken() returns individual tokens from this array.  def gettoken():   global Inputbuf  p = re.search('^\W*[\+\-\*/]|^\W*[0-9]+', Inputbuf)  token = p.string[p.regs[0][0]:p.regs[0][1]]  token = string.strip(token)  if token not in ['+', '-', '*', '/']:   token = int(token)  Inputbuf = Inputbuf[p.regs[0][1]:]  return token    # lookahead() peeks into the input stream and tells you what # the next input token is   def lookahead():  global Inputbuf  try:   p = re.search('^\W*[\+\-\*/]|^\W*[0-9]+', Inputbuf)   token = p.string[p.regs[0][0]:p.regs[0][1]]   token = string.strip(token)   if token not in ['+', '-', '*', '/']:    token = int(token)   return token  except:   return None    def factor():  return gettoken()   def term():  e1 = factor()  tmp = lookahead()  while (tmp in ['*', '/']):   gettoken()   if (tmp == '*'):    e1 = e1 * factor()   else:    e1 = e1 / factor()   tmp = lookahead()   return e1    def expression():  e1 = term()  tmp = lookahead()  while (tmp in ['+', '-']):   gettoken()   if (tmp == '+'):    e1 = e1 + term()   else:     e1 = e1 - term()   tmp = lookahead()    return e1    def main():  global Inputbuf  Inputbuf = raw_input()  print expression()    if __name__=='__main__':  main()     It would be good to trace the execution of the above code for some simple expressions.      Producing a parse tree     The above program simply evaluates the given infix arithmetic  expression. We are now going to modify it to produce a parse tree instead. A parse tree for the expression 1+2*3 would look like this:     +          / \         /   \        1     *           / \            /   \                          2   3           Each node of the tree consists of the following fields:     'op' or 'number' depending on whether the node is an       internal node or a leaf node    A link to the 'left child' called 'left'    A link to the 'right child' called 'right'    The tree is built from the bottom up. The function 'factor' simply creates a new tree node with a number in it, initializes the left and right pointers to NULL, and returns the node. The function 'expression()' creates a new node with an operator '+' or '-' as the value of the 'op' field and assigns the left and right pointers to values obtained by calling 'term()'. Function 'term()' works in a similar way.    ( text version )    #--------------------Produce a parse tree---------------------#  # gettoken() and lookahead() are same as in the first listing  NULL = 0 import re, string Inputbuf = []   class Tree:  pass   def factor():  newnode = Tree()  newnode.number = gettoken()  newnode.left = newnode.right = 0  return newnode   def term():  left = factor()  tmp = lookahead()  while (tmp in ['*', '/']):   gettoken()   right = factor()   newnode = Tree()   newnode.op = tmp   newnode.left = left   newnode.right = right   left = newnode   tmp = lookahead()   return left   def expression():  left = term()  tmp = lookahead()  while (tmp in ['+', '-']):   gettoken()   right = term()   newnode = Tree()   newnode.op = tmp   newnode.left = left   newnode.right = right   left = newnode   tmp = lookahead()    return left   def treeprint(ptree):  if (ptree):   try:    print ptree.op   except:    print ptree.number   treeprint(ptree.left)   treeprint(ptree.right)    def main():  global Inputbuf  Inputbuf = raw_input()  ptree = expression()  return ptree   if __name__=='__main__':  ptree = main()  treeprint(ptree)      Building a stack machine     The parse tree which we have created can be easily evaluated by writing a recursive function. But we will adopt a different method. We will generate code for evaluating expressions in the instruction set of a simple hypothetical machine called a  'stack machine'. The instructions which this machine has are very simple - push a number on to the stack, add two numbers, multiply two numbers etc. Thus, evaluation of the expression 1+2*3 yields the following code:  push 1  push 2  push 3 mul  add   These instructions are stored in an array. Push, mul, add etc are functions. The instructions may be directly executed by walking through the array and executing the functions held by each array element or they may stored in a disk file (an easy way is to use the Python pickle module, though it is a waste of space).  Another program may then read this code into an array and execute it. The code which I have written works like this: If you run the program without any filename  argument, it reads an expression from the keyboard, generates code for the virtual machine in an array and executes it by walking through the array. The code is also stored in a file called 'code.out'. Now if you run the program with a file name argument code.out, it loads the instructions from the file and executes it, without reading from the keyboard.    ( text version )    import re, string, sys, pickle # Functions not included herein should be copied from the previous listings.  NULL = 0 Inputbuf = []  NCODE = 100 NSTACK = 100 Code = []  Stack = [0] * NSTACK Pc = 0 Stackp = 0  class Tree:  pass   class CodeItem:  pass   def initcode():  global Code  for i in range(0, NCODE):   t = CodeItem()   Code.append(t)    def pushop():  global Stack, Stackp, Code, Pc    Stack[Stackp] = Code[Pc].number  Stackp = Stackp + 1  Pc = Pc + 1     def addop():  global Stack, Stackp, Code, Pc    Stackp = Stackp - 1  right = Stack[Stackp]  Stackp = Stackp - 1  left = Stack[Stackp]  Stack[Stackp] = left + right  Stackp = Stackp + 1  # define subop, mulop and divop here.     def generate(codep, ptree):  try:   # if the field 'number' is not present, the          # following line generates an exception.    n = ptree.number    Code[codep].op = pushop   codep = codep + 1   Code[codep].number = n   codep = codep + 1   return codep  except:   if (ptree.op == '+'):    codep = generate(codep, ptree.left)    codep = generate(codep, ptree.right)    Code[codep].op = addop    codep = codep + 1    return codep       # elif (ptree.op == '-'): We will write the code                 # generation actions for '-', '*', '/' here.                     def eval(ptree): # Generate the instructions, then execute them  global Pc, Stackp, Code, Stack  Pc = generate(0, ptree)  Code[Pc].op = NULL    Stackp = 0  Pc = 0  while Code[Pc].op != NULL:   tmp = Pc   Pc = Pc + 1   Code[tmp].op()  return Stack[0]     def eval2():    # Directly execute the loaded code         global Pc, Stackp, Code, Stack    Stackp = 0  Pc = 0  while Code[Pc].op != NULL:   tmp = Pc   Pc = Pc + 1   Code[tmp].op()  return Stack[0]     def main():  global Inputbuf, Code    try:   f = open(sys.argv[1])   Code = pickle.load(f)   f.close()   result = eval2()   print 'result is:', result   return result  except:   print 'Not opening code file, reading from k/b'   initcode()   Inputbuf = raw_input()   ptree = expression()   result = eval(ptree)   f = open('code.out', 'w')   pickle.dump(Code, f)   print 'Code dumped in a file called dat'   print 'result is:', result   return result     if __name__=='__main__':  result = main()     'generate()' and 'eval()' are the critical functions. 'generate()' walks through the expression tree creating the virtual machine code and storing it in an array 'Code'. 'eval()' walks through the array 'Code' executing the instructions, using an array 'Stack' for  holding the partial results.    Conclusion     It is possible to extend the above program to handle variables and assignment statements, control flow constructs like gotos, if statements etc. Soon, you would be building a simple Basic-like language.    Coming from a C background, Python's lack of certain C constructs like the ++ operator is a minor irritation. The lack of compile time type declarations also seems to have some detrimental effects upon code readability. Also, you will pay dearly for any typo.  If you have a variable 'f' of type 'struct foo' and 'foo' does not have a field called 'next', an assignment to 'f.next' will generate a compile time error in C whereas the Python interpreter would gladly allow the assignment to go through.      References   The standard book on compiler design is 'Principles of Compiler Design' by  Aho A.V and Ullman J.D. The inspiration for this article came from 'The Practice of Programming', another excellent book by Brian Kernighan and Rob Pike. The 'generate' and 'eval' functions are Python renderings of code from this book. 'A Second course in Computer Science with Pascal' by Daniel D. McCracken presents several algorithms, including an expression evaluator, in a very engaging style.                 Copyright © 2000, Pramode C E   Published in Issue 52 of  Linux Gazette , April 2000              Published by  Linux Journal              The Back Page     About This Month's Authors   Not Linux                  About This Month's Authors                     Mark Bolzern  Mark is President and CEO of   LinuxMall.com , a director at Linux International, on the advisory councils of the Linux Professional Institute and the Linux Business Expo. He has a long history of involvement with the Open Source community, and is considered one of the ""Original Linux People."" He is also one of the organizers of the Linux Business Expo and other Linux community activities. He appears frequently as an op/ed guest of industry publications and is a frequent public speaker on the subject of open systems and Linux.       Shane Collinge  Part computer programmer, part cartoonist, part Mars Bar. At night, he runs around in a pair of colorful tights fighting criminals. During the day... well, he just runs around.  He eats when he's hungry and sleeps when he's sleepy.                                                 Fernando Correa and Luis Strano  Fernando is a computer analyst just about to finish his  graduation at Federal University of Rio de Janeiro. Now, he has built with his staff the best   Linux Portal  in Brazil and have further  plans to improve services and content for their Internet users.    Luis is a 17-year-old student in Sao Paulo and a volunteer in this section at OLinux.      Sean Lamb  I'm currently working on completing my BS degree in Computer Science at Lakeland College (begun earlier at the University of California, Riverside). I've been involved in computer support for the past 6 years, via phone, fax, and email, and I have created documentation for use by end users (some articles in the Microsoft Knowledge Base) and other support staff (published in-house as either individual documents or on the support intranet), and I contributed some chapters to ""Special Edition Using KDE"" from Que publishing (now in print). I have done some application development on MS-DOS platforms and have begun developing a pair of applications for my Linux box. I am currently employed as a software developer working in C++ with Informix on a mix of Linux and AIX servers. When I'm not playing with or writing about Linux, I can usually be found working on my model railroad.        Ben Okopnik  A cyberjack-of-all-trades, Ben wanders the world in his 38' sailboat, building networks and hacking on hardware and software whenever he runs out of cruising money. He's been playing and working with computers since the Elder Days (anybody remember the Elf II?), and isn't about to stop any time soon.       Ben Okopnik  A cyberjack-of-all-trades, Ben wanders the world in his 38' sailboat, building networks and hacking on hardware and software whenever he runs out of cruising money. He's been playing and working with computers since the Elder Days (anybody remember the Elf II?), and isn't about to stop any time soon.      Mike Orr  Mike is the Editor of the  Linux Gazette .  You can read what he has to  say in the Back Page column in this issue.  He has been a Linux enthusiast since 1991 and a Debian user since 1995.  He is SSC's web technical coordinator, which means he gets to write a lot of Python scripts. Non-computer interests include ska/oi! music and the international language Esperanto.       Pramode C.E and Gopakumar C.E  Pramode works as a teacher and  programmer while Gopakumar is an engineering student who likes to play with Linux and electronic circuits.                  Not Linux                    Next month  Linux Gazette  will have a new Editor: Jason Kroll. Jason is the Technical Editor for  Linux Journal , so you may know him from his product reviews and Stupid Programming Tricks column.  He is a strong supporter/activist for free software, and I predict he is going to have a lot of fun running the  Gazette .  Especially considering the enthusiasm of its readers and contributors, as I have always commented.    I will continue to work on technical aspects of SSC's web sites, which means writing more web applications in Python, such as the  LG   Discussion forums unveiled last month.  (What do you guys think of them, by the way?)    Next month, Jason and I will be working together to produce the May issue. The following month, he'll be on his own, because I'll be on VACATION in  England and Scotland, and not turning on a computer at all if I can help it!         The following quote was sent to me by a coworker.    The classically minded among us may have noted a new TV ad for Microsoft's Internet Explorer e-mail program which uses the musical theme of the ""Confutatis Maledictis"" from  Mozart's Requiem.    ""Where do you want to go today?"" is the cheery line on the screen. Meanwhile, the chorus sings ""Confutatis maledictis, flammis acribus addictis.""    This translates to ""The damned  and accursed are convicted to the flames of hell.""    Good to know that Microsoft has done its research.            Thanks for sending in your articles and 2-cent tips.   Remember: don't just use Linux this month, have fun with it!    Michael Orr  Editor,  Linux Gazette ,  gazette@ssc.com                   This page written and maintained by the Editor of the  Linux Gazette .  Copyright © 2000,  gazette@ssc.com   Published in Issue 52 of  Linux Gazette , April 2000"
GX050-80-13577167	Pileated woodpecker                 Dryocopus pileatus
GX046-72-10115075	Red-headed woodpecker                 Melanerpes erythrocepha
GX057-55-15034157	"Usenet News HOWTO Prev Next 1. What is the Usenet? 1.1. Discussion groups The Usenet is a huge worldwide collection of discussion groups. Each discussion group has a name,  e.g.   comp.os.linux.announce , and a collection of messages. These messages, usually called  articles , are posted by readers like you and me who have access to Usenet servers, and are then stored on the Usenet servers. This ability to both read and write into a Usenet newsgroup makes the Usenet very different from the bulk of what people today call ``the Internet.'' The Internet has become a colloquial term to refer to the World Wide Web, and the Web is (largely) read-only. There are online discussion groups with Web interfaces, and there are mailing lists, but Usenet is probably more convenient than either of these for most large discussion communities. This is because the articles get replicated to your local Usenet server, thus allowing you to read and post articles without accessing the global Internet, something which is of great value for those with slow Internet links. Usenet articles also conserve bandwidth because they do not come and sit in each member's mailbox, unlike  email based mailing lists. This way, twenty members of a mailing list in one office will have twenty copies of each message copied to their mailboxes. However, with a Usenet discussion group and a local Usenet server, there's just one copy of each article, and it does not fill up anyone's mailbox. Another nice feature of having your own local Usenet server is that articles stay on the server even after you've read them. You can't accidentally delete a Usenet articles the way you can delete a message from your mailbox. This way, a Usenet server is an  excellent  way to archive articles of a group discussion on a local server without placing the onus of archiving on any group member. This makes local Usenet servers very valuable as archives of internal discussion messages within corporate Intranets, provided the article expiry configuration of the Usenet server software has been set up for sufficiently long expiry periods. 1.2. How it works, loosely speaking  Usenet news works by the reader first firing up a Usenet news program, which in today's GUI world will highly likely be something like Netscape Messenger or Microsoft's Outlook Express. There are a lot of proven, well-designed character-based Usenet news readers, but a proper review of the user agent software is outside the scope of this HOWTO, so we will just assume that you are using whatever software you like. The reader then selects a Usenet newsgroup from the hundreds or thousands of newsgroups which are hosted by her local server, and accesses all unread articles. These articles are displayed to her. She can then decide to respond to some of them. When the reader writes an article, either in response to an existing one or as a start of a brand-new thread of discussion, her software  posts  this article to the Usenet server. The article contains a list of newsgroups into which it is to be posted. Once it is accepted by the server, it becomes available for other users to read and respond to. The article is automatically  expired  or deleted by the server from its internal archives based on expiry policies set in its software; the author of the article usually can do little or nothing to control the expiry of her articles. A Usenet server rarely works on its own. It forms a part of a collection of servers, which automatically exchange articles with each other. The flow of articles from one server to another is called a  newsfeed . In a simplistic case, one can imagine a worldwide network of servers, all configured to replicate articles with each other, busily passing along copies across the network as soon as one of them receives a new articles posted by a human reader. This replication is done by powerful and fault-tolerant processes, and gives the Usenet network its power. Your local Usenet server literally has a copy of all current articles in all relevant newsgroups. 1.3. About sizes, volumes, and so on Any would-be Usenet server administrator or creator  must  read the  ""Periodic Posting about the basic steps involved in configuring a machine to store Usenet news,""  also known as the Site Setup FAQ, available from  ftp://rtfm.mit.edu/pub/usenet/news.answers/usenet/site-setup  or  ftp://ftp.uu.net/usenet/news.answers/news/site-setup.Z . It was last updated in 1997, but trends haven't changed much since then, though absolute volume figures have. If you want your Usenet server to be a repository for all articles in all newsgroups, you will probably not be reading this HOWTO, or even if you do, you will rapidly realise that anyone who needs to read this HOWTO may not be ready to set up such a server. This is because the volumes of articles on the Usenet have reached a point where very specialised networks, very high end servers, and large disk arrays are required for handling such Usenet volumes. Those setups are called ``carrier-class'' Usenet servers, and will be discussed a bit later on in this HOWTO. Administering such an array of hardware may not be the job of the new Usenet administrator, for which this HOWTO (and most Linux HOWTO's) are written. Nevertheless, it may be interesting to understand what volumes we are talking about. Usenet news article volumes have been doubling every fourteen months or so, going by what we hear in comments from carrier class Usenet administrators. In the beginning of 1997, this volume was 1.2 GBytes of articles a day. Thus, the volumes should have roughly done five doublings, or grown 32 times, by the time we reach mid-2002, at the time of this writing. This gives us a volume of 38.4 GBytes per day. Assume that this transfer happens using uncompressed NNTP (the norm), and add 50% extra for the overheads of NNTP, TCP, and IP. This gives you a raw data transfer volume of 57.6 GBytes/day or about 460 Gbits/day. If you have to transfer such volumes of data in 24 hours (86400 seconds), you'll need raw bandwidth of about 5.3 Mbits per second just to  receive all these articles . You'll need more bandwidth to send out feeds to other neighbouring Usenet servers, and then you'll need bandwidth to allow your readers to access your servers and read and post articles in retail quantities. Clearly, these volume figures are outside the network bandwidths of most corporate organisations or educational institutions, and therefore only those who are in the business of offering Usenet news can afford it. At the other end of the scale, it is perfectly feasible for a small office to subscribe to a well-trimmed subset of Usenet newsgroups, and exclude most of the high-volume newsgroups.  Starcom Software, where the authors of this HOWTO work, has worked with a fairly large subset of 600 newsgroups, which is still a tiny fraction of the 15,000+ newsgroups that the carrier class services offer. Your office or college may not even need 600 groups. And our company had excluded specific high-volume but low-usefulness newsgroups like the  talk ,  comp.binaries , and  alt  hierarchies. With the pruned subset, the total volume of articles per day may amount to barely a hundred MBytes a day or so, and can be easily handled by most small offices and educational institutions. And in such situations, a single Intel Linux server can deliver excellent performance as a Usenet server. Then there's the  internal  Usenet service. By internal here, we mean a private set of Usenet newsgroups, not a private computer network. Every company or university which runs a Usenet news service creates its own hierarchy of internal newsgroups, whose articles never leave the campus or office, and which therefore do not consume Internet bandwidth. These newsgroups are often the ones most hotly accessed, and will carry more  internally generated  traffic than all the ``public'' newsgroups you may subscribe to, within your organisation.  After all, how often does a guy have something to say which is relevant to the world at large, unless he's discussing a globally relevant topic like ``Unix rules!''? If such internal newsgroups are the focus of your Usenet servers, then you may find that fairly modest hardware and Internet bandwidth will suffice, depending on the size of your organisation. The new Usenet server administrator has to undertake a sizing exercise to ensure that he does not bite off more than he, or his network resources, can chew. We hope we have provided sufficient information for him to get started with the right questions. Prev Home Next Usenet News HOWTO   Principles of Operation"
GX075-22-14044091	Notes about setting up the environment variables         in your account to run the   MVD   software               in staf98a         on the BNL linux computers           I do not know if all of this stuff is relevant for staf98. I did not try to figure out which of these variables is no longer relevant. If you figure out more about this and tell me, I'll update this page.    This is something you only have to do once. These can be defined in your .login file (for example).      Define the location of the top directory   in your account where you want to install it  .     setenv MYCVS /phenix/workarea/sullivan/cvs     define the location of root:     setenv ROOTSYS /opt/rhic/ROOT2.09     My instructions tell you to set this variable as you create the staf libraries, but you could also define a default value of it:     etenv LD_LIBRARY_PATH $MYCVS/install/i686-pc-linux-gnu/lib:/afs/rhic/phenix/software/new/staf/ana/lib:/afs/rhic/phenix/software/new/staf/sys/lib:/opt/rhic/ROOT2/lib       Also setup some phenix standard environment variables. I have the following lines near the top of my .cshrc file.     #PHENIX-specific set-up   if($?PHNX_ARCH)then      source $HOME/.phnx_alias   else      source $HOME/.phnx_cshell   endif     where $HOME is my home directory -- i.e. these are two files in my home directory.          John Sullivan   comments to: sullivan@lanl.gov   updated 21-July-1998
GX044-61-6032397	"Linux Security HOWTO Prev   15. Acknowledgments Information here is collected from many sources. Thanks to the following who either indirectly or directly have contributed:   Rob Riggs  rob@DevilsThumb.com     S. Coffin  scoffin@netcom.com   Viktor Przebinda  viktor@CRYSTAL.MATH.ou.edu    Roelof Osinga  roelof@eboa.com   Kyle Hasselbacher  kyle@carefree.quux.soltc.net   David S. Jackson  dsj@dsj.net   Todd G. Ruskell  ruskell@boulder.nist.gov    Rogier Wolff  R.E.Wolff@BitWizard.nl   Antonomasia  ant@notatla.demon.co.uk    Nic Bellamy  sky@wibble.net    Eric Hanchrow  offby1@blarg.net    Robert J. Berger rberger@ibd.com    Ulrich Alpers  lurchi@cdrom.uni-stuttgart.de    David Noha  dave@c-c-s.com    Pavel Epifanov.  epv@ibm.net   Joe Germuska.  joe@germuska.com   Franklin S. Werren  fswerren@bagpipes.net    Paul Rusty Russell  <Paul.Russell@rustcorp.com.au>    Christine Gaunt  <cgaunt@umich.edu>    lin  bhewitt@refmntutl01.afsc.noaa.gov    A. Steinmetz  astmail@yahoo.com    Jun Morimoto  morimoto@xantia.citroen.org    Xiaotian Sun  sunx@newton.me.berkeley.edu    Eric Hanchrow  offby1@blarg.net    Camille Begnis  camille@mandrakesoft.com   Neil D  neild@sympatico.ca   Michael Tandy  Michael.Tandy@BTInternet.com   Tony Foiani  tkil@scrye.com   Matt Johnston  mattj@flashmail.com   Geoff Billin  gbillin@turbonet.com   Hal Burgiss  hburgiss@bellsouth.net   Ian Macdonald  ian@linuxcare.com   M.Kiesel  m.kiesel@iname.com   Mario Kratzer  kratzer@mathematik.uni-marburg.de   Othmar Pasteka  pasteka@kabsi.at   Robert M  rom@romab.com   Cinnamon Lowe  clowe@cinci.rr.com   Gunnar Ritter   g-r@bigfoot.de   The following have translated this HOWTO into various other languages!  A special thank you to all of them for help spreading the Linux word...  Polish: Ziemek Borowski  ziembor@FAQ-bot.ZiemBor.Waw.PL    Japanese: FUJIWARA Teruyoshi  fjwr@mtj.biglobe.ne.jp    Indonesian: Tedi Heriyanto  22941219@students.ukdw.ac.id    Korean: Bume Chang  Boxcar0001@aol.com    Spanish: Juan Carlos Fernandez  piwiman@visionnetware.com   Dutch: ""Nine Matthijssen""  nine@matthijssen.nl    Norwegian: ketil@vestby.com  ketil@vestby.com   Turkish: tufan karadere  tufank@metu.edu.tr   Prev Home   Conclusion"
GX092-46-4864023	Next  Previous   Contents     15. Acknowledgements    Information here is collected from many sources. Thanks to the following that either indirectly or directly have contributed: following who either indirectly or directly have contributed:   Rob Riggs  rob@DevilsThumb.com   S. Coffin  scoffin@netcom.com Viktor Przebinda  viktor@CRYSTAL.MATH.ou.edu    Roelof Osinga  roelof@eboa.com Kyle Hasselbacher  kyle@carefree.quux.soltc.net David S. Jackson  dsj@dsj.net Todd G. Ruskell  ruskell@boulder.nist.gov    Rogier Wolff  R.E.Wolff@BitWizard.nl Antonomasia   ant@notatla.demon.co.uk    Nic Bellamy   sky@wibble.net    Eric Hanchrow   offby1@blarg.net    Robert J. Berger  rberger@ibd.com    Ulrich Alpers   lurchi@cdrom.uni-stuttgart.de    David Noha   dave@c-c-s.com    Pavel Epifanov.   epv@ibm.net Joe Germuska.   joe@germuska.com Franklin S. Werren   fswerren@bagpipes.net    Paul Rusty Russell   <Paul.Russell@rustcorp.com.au>    Christine Gaunt   <cgaunt@umich.edu>    lin   bhewitt@refmntutl01.afsc.noaa.gov    A. Steinmetz   astmail@yahoo.com    Jun Morimoto   morimoto@xantia.citroen.org    Xiaotian Sun   sunx@newton.me.berkeley.edu    Eric Hanchrow   offby1@blarg.net    The following have translated this HOWTO into various other languages!  A special thank you to all of them for help spreading the Linux word...  Polish: Ziemek Borowski   ziembor@FAQ-bot.ZiemBor.Waw.PL    Japanese: FUJIWARA Teruyoshi   fjwr@mtj.biglobe.ne.jp    Indonesian: Tedi Heriyanto   22941219@students.ukdw.ac.id    Korean: Bume Chang   Boxcar0001@aol.com    Spanish: Juan Carlos Fernandez   piwiman@visionnetware.com Dutch: R. Ekkebus   reggy@zeelandnet.nl         Next  Previous   Contents
GX195-64-0197717	╝бд╬е┌б╝е╕  ┴░д╬е┌б╝е╕   ╠▄╝бд╪     14. ╝╒╝н    ╦▄е╔енехесеєе╚д╬╛Ё╩єд╧дддэдддэд╩╜ъдлдщ╜╕дсд┐дтд╬д╟д╣. ─╛└▄бж┤╓└▄┼кд╦╣╫ ╕ед╖д╞дпд└д╡д├д┐░╩▓╝д╬╩¤б╣д╦┤╢╝╒д╖д▐д╣:   Rob Riggs д╡дє  rob@DevilsThumb.com   S. Coffin д╡дє  scoffin@netcom.com Viktor Przebinda д╡дє  viktor@CRYSTAL.MATH.ou.edu    Roelof Osinga д╡дє  roelof@eboa.com Kyle Hasselbacher д╡дє  kyle@carefree.quux.soltc.net David S. Jackson д╡дє  dsj@dsj.net Todd G. Ruskell д╡дє  ruskell@boulder.nist.gov    Rogier Wolff д╡дє  R.E.Wolff@BitWizard.nl Antonomasia д╡дє   ant@notatla.demon.co.uk    Nic Bellamy д╡дє   sky@wibble.net    Eric Hanchrow д╡дє   offby1@blarg.net    Robert J. Berger д╡дє  rberger@ibd.com    Ulrich Alpers д╡дє   lurchi@cdrom.uni-stuttgart.de    David Noha д╡дє   dave@c-c-s.com    Pavel Epifanov д╡дє   epv@ibm.net Joe Germuska д╡дє   joe@germuska.com Franklin S. Werren д╡дє   fswerren@bagpipes.net    Paul Rusty Russell д╡дє   <Paul.Russell@rustcorp.com.au>    Christine Gaunt д╡дє   <cgaunt@umich.edu>    lin д╡дє   bhewitt@refmntutl01.afsc.noaa.gov    A. Steinmetz д╡дє   astmail@yahoo.com    ┐╣╦▄ ╜▀д╡дє <morimoto@xantia.citroen.org>  Xiaotian Sun д╡дє   sunx@newton.me.berkeley.edu    Eric Hanchrow д╡дє   offby1@blarg.net    ░╩▓╝д╬╩¤б╣д╧д│д╬ HOWTO дЄ┐зб╣д╩╕└═╒д╦╦▌╠їд╖д╞дпд└д╡ддд▐д╖д┐!  Linux д╬╕└═╒дЄ╣ндсды╝ъ┼┴дддЄд╖д╞дпд└д╡ды┴┤д╞д╬╩¤б╣д╦┐╝дп┤╢╝╒д╖д▐д╣.   е▌б╝ещеєе╔╕ь: Ziemek Borowski д╡дє   ziembor@FAQ-bot.ZiemBor.Waw.PL    ╞№╦▄╕ь: ╞г╕╢╡▒▓┼   fjwr@mtj.biglobe.ne.jp    едеєе╔е═е╖ев╕ь: Tedi Heriyanto д╡дє   22941219@students.ukdw.ac.id    ┤┌╣ё╕ь: Bume Chang д╡дє   Boxcar0001@aol.com    е╣е┌едеє╕ь: Juan Carlos Fernandez д╡дє   piwiman@visionnetware.com екещеєе└╕ь: R. Ekkebus д╡дє   reggy@zeelandnet.nl             ╝бд╬е┌б╝е╕  ┴░д╬е┌б╝е╕   ╠▄╝бд╪
GX035-54-8578144	Web PET         You can get a passive, that is non updating and non control,  image of a pet page by entering the path name of the pet data file  in the form.          PET file path name:
GX040-71-2377165	"Red Hat Linux 7.1: The Official Red Hat Linux Reference Guide Prev Chapter 3. Boot Process, Init, and Shutdown Next Behind the Scenes of the Boot Process Note      This section looks at the x86 boot process, in particular. Depending    on your system's architecture, your boot process may be slightly    different. However, once the kernel is found and loaded by the system,    the default Red Hat Linux boot process is identical across all    architectures. Please see  the section called  Differences in the Boot Process of Other Architectures  for more    information on a non-x86 boot process.      When a computer is booted, the processor looks at the end of the    system memory for the  BIOS  (Basic Input/Output    System) and runs it. The BIOS program is written into read-only    permanent memory and is always available for use. The BIOS provides the    lowest level interface to peripheral devices and controls the first    step of the boot process.      The BIOS tests the system, looks for and checks peripherals, and then    looks for a drive to use to boot the system. Usually, it checks the floppy drive    (or CD-ROM drive on many newer systems) for bootable media, if    present, and then it looks to the hard drive. The order of the drives used for booting is usually    controlled by a particular BIOS setting on the system. Once Red Hat Linux is installed on    a hard drive of a system, the BIOS looks for a     Master Boot Record  (MBR) starting at the first    sector on the first hard drive, loads its contents into memory, and    passes control to it.        This MBR code then looks for the first active partition and reads the partition's    boot record. The boot record contains instructions on how to load the  boot loader,  LILO  ( LI nux     LO ader). The MBR then loads LILO, which takes over    the process (if LILO is installed in the MBR). In the default Red Hat Linux    configuration, LILO uses the settings in the MBR to display boot    options and allow for user input on which operating system to actually    start up.    But this begs the question: How does LILO in the MBR know what to do  when the MBR is read? LILO actually has already written the instructions  there through the use of  lilo  with  the  /etc/lilo.conf  configuration file.        Options in  /etc/lilo.conf    Most of the time, you will have no need to change the Master Boot    Record on your hard drive unless you need to boot a newly installed    operating system or are looking to use a new kernel. If you do need to    create a new MBR using LILO but using a different configuration, you will need edit     /etc/lilo.conf  and run     lilo  again.   Warning        If you are planning to edit  /etc/lilo.conf , be      sure to make a backup copy of the file before making any      changes. Also, be sure that you have a working boot floppy available      so that you will be able to boot the system and make changes to the      MBR if there is a problem. See the man pages for       mkbootdisk  for more information on      creating a boot disk.        The file  /etc/lilo.conf  is used by     lilo  to determine which    operating system(s) to utilize or which kernel to start, as well as to    know where to install itself (for example,   /dev/hda  for the first IDE hard drive). A sample     /etc/lilo.conf  file looks like this:   boot=/dev/hda map=/boot/map install=/boot/boot.b prompt timeout=50 message=/boot/message lba32 default=linux  image=/boot/vmlinuz-2.4.0-0.43.6  label=linux  initrd=/boot/initrd-2.4.0-0.43.6.img  read-only  root=/dev/hda5  other=/dev/hda1  label=dos  This example shows a system configured to boot two operating systems:    Red Hat Linux and DOS. Here is a deeper look at a few of the    lines of this file (your  /etc/lilo.conf  may look    a little different):                             boot=/dev/hda  tells LILO to look on the                     first hard disk on the first IDE controller.                                         map=/boot/map  locates the map file. In                     normal use, this should not be modified.                                         install=/boot/boot.b  tells LILO to                     install the specified file as the new boot sector. In normal        use, this should not be altered. If the                      install  line is missing, LILO will        assume a default of  /boot/boot.b  as the file                     to be used.                                        The existence of  prompt  tells LILO to show you whatever        is referenced in the  message  line. While it        is not recommended that you remove the  prompt         line, if you do remove it, you can still get a prompt by holding        down the  [Shift]  key while your machine starts to boot.                                         timeout=50  sets the amount of time that                     LILO will wait for user input before proceeding with booting        the  default  line entry. This is                     measured in tenths of a second, with 50 as the default.                                         message=/boot/message  refers to the                     screen that LILO displays to let you select the operating                     system or kernel to boot.                                         lba32  describes the hard disk geometry        to LILO. Another common entry here is         linear . You should not change this line        unless you are very aware of what you are doing. Otherwise, you        could put your system in a state where it cannot boot.                                         default=linux  refers to the default                     operating system for LILO to boot from the options listed below this        line. The name  linux  refers to the                      label  line below in each of the boot options.                                         image=/boot/vmlinuz-2.4.0-0.43.6  specifies the linux kernel to                     boot with this particular boot option.                                         label=linux  names the operating system                     option in the LILO screen. In this case, it also is the name that is referred to by the                      default  line.                                         initrd=/boot/initrd-2.4.0-0.43.6.img         refers to the  initial ram disk  image that is used        at boot time to actually initialize and start the devices that makes        booting the kernel possible. The initial ram disk is a collection        of machine-specific drivers necessary to operate the hard drive and        anything needed to load the kernel. You should never try to share        initial ram disks between machines unless they are identical in        their hardware configurations (and even then, it is a bad idea).                            read-only  specifies that the root partition        (see the  root  line below) as one that cannot        be changed, only read.                                         root=/dev/hda5  tells LILO what disk                     partition to use as the root partition.                     LILO then shows the Red Hat Linux initial screen with the different operating  systems or kernels it has been configured to boot. If you only have Red Hat Linux installed and have not  changed anything in  /etc/lilo.conf , you will only  see  linux  as an option. If you have set up  LILO to boot other operating systems as well, this screen is your chance to  select what operating system will boot. Use your arrow keys to highlight the operating  system and press  [Enter]       If you would like to have a command prompt to enter commands to LILO, press     [Cntl] - [X] . LILO displays a     LILO:  prompt on the screen and waits for a preset    period of time for input from the user. (The amount of time LILO waits    is set by the  timeout  line in the     /etc/lilo.conf  file.) If your     /etc/lilo.conf  is set to give LILO a choice of    operating systems, at this time you could    type in the label for whichever operating system you want to boot.      If LILO is booting Linux, it first loads the kernel into memory, which is a     vmlinuz  file (plus a version number, for example,     vmlinuz-2.4.0-xx ) located in the  /boot     directory.  Then the kernel passes control to  init .      At this point, with the kernel loaded into memory and operational,    Linux is already started, although at a very basic level. However,    with no applications utilizing the kernel and with no ability for    the user to provide meaningful input to the system, not much can be done with    it. The  init  program solves this problem by bringing up    the various services that allow the system to perform its particular role.   Init    The kernel finds  init  in     /sbin  and executes it, and     init  which coordinates the rest of the boot    process.      When  init  starts, it becomes the parent or    grandparent of all of the processes that start up automatically on your Red Hat Linux system.    First, it runs the  /etc/rc.d/rc.sysinit  script, which sets    your path, starts swapping, checks the filesystems, and so on.    Basically,  rc.sysinit  takes care of    everything that your system needs to have done at system    initialization.  For example, on a networked system,     rc.sysinit  uses the information in the     /etc/sysconfig/network  file to initialize network    processes. Most systems use a clock, so on them     rc.sysinit  uses the     /etc/sysconfig/clock  file to initialize the    clock. If you have special serial port processes that need to be initialized,     rc.sysinit  may also run     rc.serial .      Then,  init  runs the     /etc/inittab  script, which describes how the system should    be set up in each  runlevel  and sets the default    runlevel. (See  the section called  Init Runlevels  for more    information on init runlevels.) This file states, among other things, that     /sbin/update  should be run whenever a    runlevel starts. The  update  program is    used to flush dirty buffers back to disk.      Whenever the runlevel changes,  init  uses    the scripts in  /etc/rc.d/init.d  to start and stop    various services, such as your web server, DNS server, and so    on. First,  init  sets the source function library for the system (commonly     /etc/rc.d/init.d/functions ), which spells out how    to start or kill a program and how to find out the PID of a program. Then,     init  determines the current and the previous runlevel.      Next,  init  starts all of the background    processes necessary for the system to run by looking in the    appropriate  rc  directory for that runlevel    ( /etc/rc.d/rc <x> .d ,    where the  < x >  is numbered 0-6).     init  runs each of the kill scripts (their    file name starts with a  K ) with a     stop  parameter. Then,     init  runs all of the start scripts (their file names start with an     S ) in the appropriate runlevel directory with a     start  so that all services and applications are    started correctly. In fact, you can execute these same scripts manually    after the system is finished booting with a command like     /etc/rc.d/init.d/httpd stop  or  service httpd           stop  logged in as root. This will stop the  httpd            server.   Note      When starting services manually, you should be root. If you get a           error when executing  service httpd stop , you may not have            /sbin  pathed in       /root/.bashrc  (or the correct  .rc  file for your           preferred shell). You can either type the full command of            /sbin/service httpd stop  or add  export        PATH=""$PATH:/sbin""  to your shell  .rc  file. If you edit your           shell configuration file, log out and back           in as root to make the changed shell configuration file take effect.      None of the scripts that actually start and stop the services are    located in     /etc/rc.d/rc <x> .d .    Rather, all of the files in     /etc/rc.d/rc <x> .d     are  symbolic links  that point to actual scripts located in     /etc/rc.d/init.d . A symbolic link is nothing more than    a file that simply points to another file, and they are used in this    case because they can be created and deleted without affecting the    actual script that kills or starts the service. The symbolic links to the    various scripts are numbered in a particular order so that they start    in that order. You can change the order in which the services start up or are killed by changing the    name of the symbolic link that refers to the script that actually starts or kills the    service. You can give symbolic links the same number as other symbolic    links if you want that service start or stop right before or after    another service.      For example, for runlevel 5,  init  looks into    the  /etc/rc.d/rc5.d  directory and might finds the    following (your system and configuration may vary):   K01pppoe -> ../init.d/pppoe K05innd -> ../init.d/innd K10ntpd -> ../init.d/ntpd K15httpd -> ../init.d/httpd K15mysqld -> ../init.d/mysqld K15pvmd -> ../init.d/pvmd K16rarpd -> ../init.d/rarpd K20bootparamd -> ../init.d/bootparamd K20nfs -> ../init.d/nfs K20rstatd -> ../init.d/rstatd K20rusersd -> ../init.d/rusersd K20rwalld -> ../init.d/rwalld K20rwhod -> ../init.d/rwhod K25squid -> ../init.d/squid K28amd -> ../init.d/amd K30mcserv -> ../init.d/mcserv K34yppasswdd -> ../init.d/yppasswdd K35dhcpd -> ../init.d/dhcpd K35smb -> ../init.d/smb K35vncserver -> ../init.d/vncserver K45arpwatch -> ../init.d/arpwatch K45named -> ../init.d/named K50snmpd -> ../init.d/snmpd K54pxe -> ../init.d/pxe K55routed -> ../init.d/routed K60mars-nwe -> ../init.d/mars-nwe K61ldap -> ../init.d/ldap K65kadmin -> ../init.d/kadmin K65kprop -> ../init.d/kprop K65krb524 -> ../init.d/krb524 K65krb5kdc -> ../init.d/krb5kdc K75gated -> ../init.d/gated K80nscd -> ../init.d/nscd K84ypserv -> ../init.d/ypserv K90ups -> ../init.d/ups K96irda -> ../init.d/irda S05kudzu -> ../init.d/kudzu S06reconfig -> ../init.d/reconfig S08ipchains -> ../init.d/ipchains S10network -> ../init.d/network S12syslog -> ../init.d/syslog S13portmap -> ../init.d/portmap S14nfslock -> ../init.d/nfslock S18autofs -> ../init.d/autofs S20random -> ../init.d/random S25netfs -> ../init.d/netfs S26apmd -> ../init.d/apmd S35identd -> ../init.d/identd S40atd -> ../init.d/atd S45pcmcia -> ../init.d/pcmcia S55sshd -> ../init.d/sshd S56rawdevices -> ../init.d/rawdevices S56xinetd -> ../init.d/xinetd S60lpd -> ../init.d/lpd S75keytable -> ../init.d/keytable S80isdn -> ../init.d/isdn S80sendmail -> ../init.d/sendmail S85gpm -> ../init.d/gpm S90canna -> ../init.d/canna S90crond -> ../init.d/crond S90FreeWnn -> ../init.d/FreeWnn S90xfs -> ../init.d/xfs S95anacron -> ../init.d/anacron S97rhnsd -> ../init.d/rhnsd S99linuxconf -> ../init.d/linuxconf S99local -> ../rc.local    These symbolic links tell  init  that it    needs to kill  pppoe ,     innd ,  ntpd ,     httpd ,  mysqld ,     pvmd ,  rarpd ,     bootparamd ,  nfs ,     rstatd ,  rusersd ,     rwalld ,  rwhod ,     squid ,  amd ,     mcserv ,     yppasswdd ,     dhcpd ,  smb ,     vncserver ,     arpwatch ,  named ,     snmpd ,  pxe ,     routed ,     mars-nwe ,  ldap ,     kadmin ,  kprop ,     krb524 ,  krb5kdc ,     gated ,  nscd ,     ypserv ,  ups , and     irda . After all processes are killed,     init  looks into the same directory and finds    start scripts for  kudzu ,     reconfig ,     ipchains ,     portmap ,     nfslock ,  autofs ,     random ,  netfs ,     apmd ,  identd ,     atd ,  pcmcia ,     sshd ,     rawdevices ,     xinetd ,  lpd ,     keytable ,  isdn ,     sendmail ,  gpm ,     canna ,  crond ,     FreeWnn ,  xfs ,     anacron ,  rhnsd ,    and  linuxconf . The last thing     init  does is run     /etc/rc.d/rc.local  to run any special scripts    configured for that host. At this point, the system is considered to    be operating at runlevel 5.      After  init  has progressed through all of    the runlevels, the  /etc/inittab  script forks a  getty  process for    each virtual console (login prompts) for each runlevel (runlevels 2-5    get all six; runlevel 1, which is single user mode, only gets one    console; runlevels 0 and 6 get no virtual    consoles). Basically,  getty  opens tty lines, sets    their modes, prints the login prompt, gets the user's name, and then    initiates a login process for that user. This allows users to    authenticate themselves to the system and begin to use it.      Also,  /etc/inittab  tells     init  how it    should handle a user hitting     [Ctrl] - [Alt] - [Delete]  at    the console. As Red Hat Linux should be properly shut down and restarted    rather immediately power-cycled,  init  is told to    execute the command  /sbin/shutdown -t3 -r    now  when a user hits those keys.  In addition,  /etc/inittab  states    what  init  should do in case of power    failures, if your system has a UPS unit attached to it.      In runlevel 5,  /etc/inittab  runs a script    called  /etc/X11/prefdm .  The     prefdm  script runs the preferred X display    manager ( gdm  if you're running GNOME,     kdm  if you're running KDE, or     xdm  if you're running AnotherLevel) based on the    contents of the  /etc/sysconfig/desktop  directory.      At this point, you should be looking at a login prompt.  All that, and    it only took a few seconds.   SysV Init           As we have seen, the  init  program is run by the           kernel at boot time. It is in charge of starting all the normal           processes that need to start up with the system.  These include the getty           processes that allow you to log in, NFS daemons, FTP daemons, and           anything else you want to run when your machine boots.                     SysV init  is the standard init process in           the Linux world to control the startup of software at boot time,           because it is easier to use and more powerful and flexible           than the traditional BSD  init .                    SysV init also differs from           BSD init in that the configuration files           are in  /etc/rc.d  instead of residing           directly in  /etc .  In            /etc/rc.d , you will find  rc ,            rc.local ,  rc.sysinit , and           the following directories:          init.d rc0.d rc1.d rc2.d rc3.d rc4.d rc5.d rc6.d    SysV init represents each of the    init runlevels with a separate directory, using     init  and symbolic links in each    of the directories to actually stop and start the services as the    system moves from runlevel to runlevel.             In summary, the chain of events for a SysV           init boot is as follows:               The kernel looks in  /sbin  for       init                              init  runs the                /etc/rc.d/rc.sysinit  script                             rc.sysinit  handles most of the boot loader's               processes and then runs  rc.serial  (if it               exists)                             init  runs all the scripts for the               default runlevel                             init  runs  /etc/rc.d/rc.local                         The default runlevel is decided in  /etc/inittab .           You should have a line close to the top like:          id:3:initdefault:           The default runlevel is 3 in this example, the number after the first           colon.  If you want to change it, you can edit            /etc/inittab  by hand.  Be very careful when you           are editing the  inittab  file. If you do mess up,           you can fix it by rebooting, accessing the  boot:            prompt with  [Cntl] - [X] , and typing:          boot:    linux single           This  should  allow you to boot into single-user           mode so you can re-edit  inittab  to its previous           value.           Next, we'll discuss information in the files within   /etc/sysconfig  that define the parameters used by  different system services when they start up.        Prev Home Next Boot Process, Init, and Shutdown Up Sysconfig Information"
GX062-04-3362144	"Speech Recognition HOWTO Prev Next 5. Speech Recognition Software 5.1. Free Software Much of the free software listed here is available for download at: http://sunsite.uio.no/pub/Linux/sound/apps/speech/      5.1.1. XVoice XVoice is a dictation/continuous speech recognizer that can be used  with a variety of XWindow applications.  It allows user-defined macros. This is a fine program with a definite future.  Once setup, it  performs with adequate accuracy. XVoice requires that you download and install IBM's (free) ViaVoice  for Linux (See Commercial Section).  It also requires the configuration of ViaVoice to work correctly.  Additionally, Lesstif/Motif (libXm) is  required.  It is also important to note that because this program  interacts with X windows, you must leave X resources open on your  machine, so caution should be used if you use this on a networked or multi-user machine. This software is primarily for users.  An RPM is available.  HomePage:  http://www.compapp.dcu.ie/~tdoris/Xvoice/             http://www.zachary.com/creemer/xvoice.html Project:   http://xvoice.sourceforge.net Community: http://www.onelist.com/community/xvoice 5.1.2. CVoiceControl/kVoiceControl CVoiceControl (which stands for Console Voice Control) started its  life as KVoiceControl (KDE Voice Control).  It is a basic speech  recognition system that allows a user to execute Linux commands by  using spoken commands.  CVoiceControl replaces KVoiceControl. The software includes a microphone level configuration utility, a vocabulary ""model editor"" for adding new commands and utterances, and the speech recognition system. CVoiceControl is an excellent starting point for experienced users looking to get started in ASR.  It is not the most user friendly, but once it has been trained correctly, it can be very helpful. Be sure to read the documentation while setting up. This software is primarily for users. Homepage:  http://www.kiecza.de/daniel/linux/index.html Documents: http://www.kiecza.de/daniel/linux/cvoicecontrol/index.html 5.1.3. Open Mind Speech Started in late 1999, Open Mind Speech has changed names several times (was VoiceControl, then SpeechInput, and then FreeSpeech), and is now  part of the ""Open Mind Initiative"".  This is an open source project.   Currently it isn't completely operational and is primarily for developers. This software is primarily for developers. Homepage:  http://freespeech.sourceforge.net 5.1.4. GVoice GVoice is a speech ASR library that uses IBM's ViaVoice (free) SDK to control Gtk/GNOME applications.  It includes libraries for  initialization, recognition engine, vocabulary manipulation, and panel control.  Development on this has been idle for over a year. This software is primarily for developers.  Homepage:  http://www.cse.ogi.edu/~omega/gnome/gvoice/ 5.1.5. ISIP The Institute for Signal and Information Processing at Mississippi State University has made its speech recognition engine available.  The toolkit includes a front-end, a decoder, and a training module.  It's a functional toolkit. This software is primarily for developers. The toolkit (and more information about ISIP) is available at: http://www.isip.msstate.edu/project/speech/ 5.1.6. CMU Sphinx Sphinx originally started at CMU and has recently been released as  open source.  This is a fairly large program that includes a lot of  tools and information.  It is still ""in development"", but includes  trainers, recognizers, acoustic models, language models, and some  limited documentation. This software is primarily for developers. Homepage:  http://www.speech.cs.cmu.edu/sphinx/Sphinx.html Source: http://download.sourceforge.net/cmusphinx/sphinx2-0.1a.tar.gz 5.1.7. Ears Although Ears isn't fully developed, it is a good starting point for programmers wishing to start in ASR. This software is primarily for developers. FTP site: ftp://svr-ftp.eng.cam.ac.uk/comp.speech/recognition/ 5.1.8. NICO ANN Toolkit The NICO Artificial Neural Network toolkit is a flexible back propagation neural network toolkit optimized for speech recognition applications.   This software is primarily for developers. Its homepage: http://www.speech.kth.se/NICO/index.html 5.1.9. Myers' Hidden Markov Model Software This software by Richard Myers is HMM algorithms written in C++ code. It provides an example and learning tool for HMM models described in the L. Rabiner book ""Fundamentals of Speech Recognition"".   This software is primarily for developers. Information is available at:  http://www.itl.atr.co.jp/comp.speech/Section6/Recognition/myers.hmm.html 5.1.10. Jialong He's Speech Recognition Research Tool Although not originally written for Linux, this research tool can be compiled on Linux.  It contains three different types of recognizers: DTW, Dynamic Hidden Markov Model, and a Continuous Density Hidden Markov Model.  This is for research and development uses, as it is not a fully functional ASR system.  The toolkit contains some very useful tools.   This software is primarily for developers. More information is available at: http://www.itl.atr.co.jp/comp.speech/Section6/Recognition/jialong.html 5.1.11. More Free Software? If you know of free software that isn't included in the above list, please send me a note at:  scook@gear21.com .  If you're in the mood, you can also send me where to get a copy of the software, and any impressions you may have about it.  Thanks! 5.2. Commercial Software 5.2.1. IBM ViaVoice IBM has made true on their promise to support Linux with their series of ViaVoice products for Linux, though the future of their SDKs aren't set in stone (their licensing agreement for developers isn't officially released as of this date - more to come).  Their commercial (not-free) product, IBM ViaVoice Dictation for Linux (available at http://www-4.ibm.com/software/speech/linux/dictation.html) performs very well, but has some sizeable system requirements compared  to the more basic ASR systems (64M RAM and 233MHz Pentium).  For the  $59.95US price tag you also get an Andrea NC-8 microphone.  It also  allows multiple users (but I haven't tried it with multiple users, so  if anyone has any experience please give me a shout).  The package  includes: documentation (PDF), Trainer, dictation system, and  installation scripts.  Support for additional Linux Distributions based on 2.2 kernels is also available in the latest release.   The ASR SDK is available for free, and includes IBM's SMAPI, grammar API, documentation, and a variety of sample programs.  The ViaVoice Run Time Kit provides an ASR engine and data files for dictation  functions, and user utilities.  The ViaVoice Command & Control Run Time Kit includes the ASR engine and data files for command and control  functions, and user utilities.  The SDK and Kits require 128M RAM and a Linux 2.2 or better kernel) The SDKs and Kits are available for free at: http://www-4.ibm.com/software/speech/dev/sdk_linux.html 5.2.2. Vocalis Speechware More information on Vocalis and Vocalis Speechware is available at:    http://www.vocalisspeechware.com  and   http://www.vocalis.com . 5.2.3. Babel Technologies Babel Technologies has a Linux SDK available called Babear.  It is a speaker-independent system based on Hybrid Markov Models and Artificial Neural Networks technology.  They also have a variety of products for Text-to-speech, speaker verification, and phoneme analysis.  More information is available at:  http://www.babeltech.com. 5.2.4. SpeechWorks I didn't see anything on their website that specifically mentioned Linux, but their  ""OpenSpeech Recognizer"" uses VoiceXML, which is an open standard. More information is available at:  http://www.speechworks.com. 5.2.5. Nuance Nuance offers a speech recognition/natural language product (currently Nuance 8.0) for a variety of *nix platforms.  It can handle very large vocabularies and uses a unqiue  distributed architecture for scalability and fault tolerance. More information is available at:  http://www.nuance.com. 5.2.6. Abbot/AbbotDemo Abbot is a very large vocabulary, speaker independent ASR system. It was originally developed by the Connectionist Speech Group at  Cambridge University.  It was transferred (commercialized) to  SoftSound.  More information is available at:   http://www.softsound.com. AbbotDemo is a demonstration package of Abbot.  This demo system has a vocabulary of about 5000 words and uses the connectionist/HMM continuous speech algorithm. This is a demonstration program with no source code. 5.2.7. Entropic The fine people over at Entropic have been bought out by Micro$oft... Their products and support services have all but disappeared.  Their support for HTK and ESPS/waves+ is gone, and their future is in the hands of M$.  Their old website as http://www.entropic.com has more information. K.K. Chin advised me that the original developers of the HTK (the  Speech Vision and Robotic Group at Cambridge) are still  providing support for it.  There is also a ""free"" version available at:  http://htk.eng.cam.ac.uk . Also note that Microsoft still owns the copyright to the current HTK code...      5.2.8. More Commercial Products There are rumors of more commercial ASR products becoming available in the near future (including L&H).  I talked with a couple of  L&H representatives at Comdex 2000 (Vegas) and none of them could give me any information on a Linux release, or even if they planned on releasing any products for Linux. If you have any further information, please send  any details to me at  scook@gear21.com . Prev Home Next Hardware   Inside Speech Recognition"
GX075-57-4021320	"Speech Recognition HOWTO Prev Next 5. Speech Recognition Software 5.1. Free Software Much of the free software listed here is available for download at: http://sunsite.uio.no/pub/Linux/sound/apps/speech/      5.1.1. XVoice XVoice is a dictation/continuous speech recognizer that can be used  with a variety of XWindow applications.  It allows user-defined macros. This is a fine program with a definite future.  Once setup, it  performs with adequate accuracy. XVoice requires that you download and install IBM's (free) ViaVoice  for Linux (See Commercial Section).  It also requires the configuration of ViaVoice to work correctly.  Additionally, Lesstif/Motif (libXm) is  required.  It is also important to note that because this program  interacts with X windows, you must leave X resources open on your  machine, so caution should be used if you use this on a networked or multi-user machine. This software is primarily for users.  An RPM is available.  HomePage:  http://www.compapp.dcu.ie/~tdoris/Xvoice/             http://www.zachary.com/creemer/xvoice.html Project:   http://xvoice.sourceforge.net Community: http://www.onelist.com/community/xvoice 5.1.2. CVoiceControl/kVoiceControl CVoiceControl (which stands for Console Voice Control) started its  life as KVoiceControl (KDE Voice Control).  It is a basic speech  recognition system that allows a user to execute Linux commands by  using spoken commands.  CVoiceControl replaces KVoiceControl. The software includes a microphone level configuration utility, a vocabulary ""model editor"" for adding new commands and utterances, and the speech recognition system. CVoiceControl is an excellent starting point for experienced users looking to get started in ASR.  It is not the most user friendly, but once it has been trained correctly, it can be very helpful. Be sure to read the documentation while setting up. This software is primarily for users. Homepage:  http://www.kiecza.de/daniel/linux/index.html Documents: http://www.kiecza.de/daniel/linux/cvoicecontrol/index.html 5.1.3. Open Mind Speech Started in late 1999, Open Mind Speech has changed names several times (was VoiceControl, then SpeechInput, and then FreeSpeech), and is now  part of the ""Open Mind Initiative"".  This is an open source project.   Currently it isn't fully operational and is primarily for developers. This software is primarily for developers. Homepage:  http://freespeech.sourceforge.net 5.1.4. GVoice GVoice is a speech ASR library that uses IBM's ViaVoice (free) SDK to control Gtk/GNOME applications.  It includes libraries for  initialization, recognition engine, vocabulary manipulation, and panel control.  Development on this has been idle for over a year. This software is primarily for developers.  Homepage:  http://www.cse.ogi.edu/~omega/gnome/gvoice/ 5.1.5. ISIP The Institute for Signal and Information Processing at Mississippi State University has made its speech recognition engine available.  The toolkit includes a front-end, a decoder, and a training module.  It's a functional toolkit. This software is primarily for developers. The toolkit (and more information about ISIP) is available at: http://www.isip.msstate.edu/project/speech/ 5.1.6. CMU Sphinx Sphinx originally started at CMU and has recently been released as  open source.  This is a fairly large program that includes a lot of  tools and information.  It is still ""in development"", but includes  trainers, recognizers, acoustic models, language models, and some  limited documentation. This software is primarily for developers. Homepage:  http://www.speech.cs.cmu.edu/sphinx/Sphinx.html Source: http://download.sourceforge.net/cmusphinx/sphinx2-0.1a.tar.gz 5.1.7. Ears Although Ears isn't fully developed, it is a good starting point for programmers wishing to start in ASR. This software is primarily for developers. FTP site: ftp://svr-ftp.eng.cam.ac.uk/comp.speech/recognition/ 5.1.8. NICO ANN Toolkit The NICO Artificial Neural Network toolkit is a flexible back propagation neural network toolkit optimized for speech recognition applications.   This software is primarily for developers. Its homepage: http://www.speech.kth.se/NICO/index.html 5.1.9. Myers' Hidden Markov Model Software This software by Richard Myers is HMM algorithms written in C++ code. It provides an example and learning tool for HMM models described in the L. Rabiner book ""Fundamentals of Speech Recognition"".   This software is primarily for developers. Information is available at:  http://www.itl.atr.co.jp/comp.speech/Section6/Recognition/myers.hmm.html 5.1.10. Jialong He's Speech Recognition Research Tool Although not originally written for Linux, this research tool can be compiled on Linux.  It contains three different types of recognizers: DTW, Dynamic Hidden Markov Model, and a Continuous Density Hidden Markov Model.  This is for research and development uses, as it is not a fully functional ASR system.  The toolkit contains some very useful tools.   This software is primarily for developers. More information is available at: http://www.itl.atr.co.jp/comp.speech/Section6/Recognition/jialong.html 5.1.11. More Free Software? If you know of free software that isn't included in the above list, please send me a note at:  scook@gear21.com .  If you're in the mood, you can also send me where to get a copy of the software, and any impressions you may have about it.  Thanks! 5.2. Commercial Software 5.2.1. IBM ViaVoice IBM has made true on their promise to support Linux with their series of ViaVoice products for Linux, though the future of their SDKs aren't set in stone (their licensing agreement for developers isn't officially released as of this date - more to come).  Their commercial (not-free) product, IBM ViaVoice Dictation for Linux (available at http://www-4.ibm.com/software/speech/linux/dictation.html) performs very well, but has some sizeable system requirements compared  to the more basic ASR systems (64M RAM and 233MHz Pentium).  For the  $59.95US price tag you also get an Andrea NC-8 microphone.  It also  allows multiple users (but I haven't tried it with multiple users, so  if anyone has any experience please give me a shout).  The package  includes: documentation (PDF), Trainer, dictation system, and  installation scripts.  Support for additional Linux Distributions based on 2.2 kernels is also available in the latest release.   The ASR SDK is available for free, and includes IBM's SMAPI, grammar API, documentation, and a variety of sample programs.  The ViaVoice Run Time Kit provides an ASR engine and data files for dictation  functions, and user utilities.  The ViaVoice Command & Control Run Time Kit includes the ASR engine and data files for command and control  functions, and user utilities.  The SDK and Kits require 128M RAM and a Linux 2.2 or better kernel) The SDKs and Kits are available for free at: http://www-4.ibm.com/software/speech/dev/sdk_linux.html 5.2.2. Abbot/AbbotDemo Abbot is a very large vocabulary, speaker independent ASR system. It was originally developed by the Connectionist Speech Group at  Cambridge University.  It was transferred (commercialized) to  SoftSound.  More information is available at:   http://www.softsound.com. AbbotDemo is a demonstration package of Abbot.  This demo system has a vocabulary of about 5000 words and uses the connectionist/HMM continuous speech algorithm. This is a demonstration program with no source code. 5.2.3. Entropic The fine people over at Entropic have been bought out by Micro$oft... Their products and support services have all but disappeared.  Their support for HTK and ESPS/waves+ is gone, and their future is in the hands of M$.  Their old website as http://www.entropic.com has more information. K.K. Chin advised me that the original developers of the HTK (the  Speech Vision and Robotic Group at Cambridge) are still  providing support for it.  There is also a ""free"" version available at:  http://htk.eng.cam.ac.uk . Also note that Microsoft still owns the copyright to the current HTK code...      5.2.4. More Commercial Products There are rumors of more commercial ASR products becoming available in the near future (including L&H).  I talked with a couple of  L&H representatives at Comdex 2000 (Vegas) and none of them could give me any information on a Linux release, or even if they planned on releasing any products for Linux. If you have any further information, please send  any details to me at  scook@gear21.com . Prev Home Next Hardware   Inside Speech Recognition"
GX059-34-7151324	"Next   Previous   Contents       5. Frequently Asked Questions:        5.1 Where can I find more information on using Loadlin?          Loadlin can be found on your favorite distibution's installation CD. Just do a search for 'loadlin'.         The Loadlin-1.6 User's Guide is available for download at:          http://elserv.ffm.fgan.de/~lermen/manual.txt    or    ftp://ftp.eskimo.com/u/p/praxis/manual.txt       You might also try visiting the   Loadlin Home Page         Additional information is available at:         http://metalab.unc.edu/LDP/HOWTO/BootPrompt-HOWTO-2.html#ss2.2     5.2 I am not sure what partition Linux is installed on. How do I find out?          At a Linux shell prompt, run the  df  utility. If you see a line with  /boot , then it will be quite obvious. If you do not see a line with  /boot , then look on the line with a single "" / "".       5.3 Where do I find the kernel image file and how do I copy it to my MS-DOS partition?          The kernel image file is usually called  vmlinuz  and should be located in the '/boot' directory. Often  vmlinuz  is a symbolic link to the actual kernel. If all else fails type:                find / -name vmlinuz*         at a Linux shell prompt. This will search all Linux partitions for the vmlinuz file. If you have multiple vmlinuz files, then make sure you use the correct one. If you are not sure, then the safest bet would be to use the most recent one.  To copy your linux kernel file to your DOS partition, you need to make your DOS partition visible to Linux, then mount the partition if it is not already. Generally, this should have been set up when you installed Linux. All you need to do next is change to the directory the vmlinuz file is in and copy it over to DOS using the cp command.  However, if Linux was not set up to recognize your DOS partition, then copy vmlinuz to a floppy. Take any DOS formatted floppy (with enough disk space to hold your kernel image file) and insert it into your floppy drive. Type:                 mount /dev/fd0 /mnt/floppy        at a Linux shell prompt. Then change to the directory your kernel image file is in and type:                 cp vmlinuz /mnt/floppy        This will copy vmlinuz to your floppy disk and it will be readable by DOS. Shutdown Linux, boot to DOS, then copy vmlinuz to whichever directory you choose. If you recompile your kernel, do not forget to copy the new kernel image file to your DOS partition. This will overwrite your old file, so it might be a good idea to rename the old file first just in case the new one does not work properly.    Alternatively, if you have the  mtools  utilities you could type:                              mcopy vmlinuz a:                5.4 Does it matter if I install Linux or Windows 95/98/ME first?          Technically no. However, it would be  much  simpler to install Windows first. That way it is easier to setup Linux to recognize your DOS partition(s) as you can usually do this during the Linux installation.       5.5 I currently have LILO installed, but I want to use Loadlin instead. How  do I remove LILO?        You will need to restore the Win95 MBR (Master Boot Record) that LILO overwrote when you installed LILO. At a DOS prompt type:                    fdisk /mbr          5.6 What if I already dual boot between Windows 95 and Windows 3.x, and I  want to boot to Linux using this method?        Frankly, if you want to do this I would recommend using LILO. However, if you really do not want to use LILO, you will have to boot to Win 3.x first, then issue the Loadlin command. (Make sure Windows 3.x is NOT    running, but that you are in DOS 5.0 or 6.x).       5.7 Is it possible to initiate Linux from the Windows 95/98/ME desktop?          Yes. First, create a batch file called ""linux.bat"", for example. Edit the file to contain a Loadlin command such as:                    loadlin f:\vmlinuz root=/dev/hdc2 ro        Now save the file on your Windows desktop. Next, right click on the Linux.bat icon, then left click on Properties. Now click on the Program tab, then click on the Advanced button. Click on the box next to ""MS-DOS mode"" and make sure the box next to ""Warn before entering MS-DOS mode is checked"". Click OK, then click on OK again. Now when you double click on the Linux icon, a warning box will appear before going into MS-DOS mode. If you click on ""Yes"" then Windows enters MS-DOS mode and executes the Linux.bat file.  NOTE:  You must be in MS-DOS mode in order to use Loadlin. Please see the manual.txt file mentioned in   Section 4.1  of this   FAQ  for more  information.      5.8 Where can I get a plain text version of this document?          You can get a plain text version of this document at:    ftp://ftp.eskimo.com/u/p/praxis/loadlin.txt         5.9 Is Loadlin the only alternative to LILO?          No. There are other utilities you could use for dual booting:    GRUB : The GNU GRand Unified Bootloader       XOSL : Extended Operating System Loader       Other Bootloaders and Related Links           Next   Previous   Contents"
GX134-32-4574015	Perl FAQ 2.2: Have any books or magazine articles been published about Perl?                                                             Perl FAQ 2.2                                    Have any books or magazine articles been published about Perl?                        There are a number of books either available or planned.  Mostly     chronologically, they are:           Programming Perl  (the ``Camel Book''):               Author:  Larry Wall  and  Randal Schwartz    Publisher: O'Reilly and Associates   ISBN 0-937175-64-1  (English)   ISBN 4-89052-384-7  (Japanese)   ISBN 3-446-17257-2  (German)  ( Programmieren in Perl )      (translator: Hanser Verlag)             This is probably the most well known and most useful book for 4.036 and     earlier.  This part of O'Reilly's hugely successful ``Nutshell Handbook''     series.  Besides serving as a reference guide for Perl, it also contains     tutorial material and is a great source of examples and cookbook     procedures, as well as wit and wisdom, tricks and traps, pranks and     pitfalls.  The code examples contained therein are available from      ftp://ftp.ora.com/pub/examples/nutshell/programming_perl/perl.tar.Z  or      ftp://ftp.cis.ufl.edu/pub/perl/ora/programming_perl.   Corrections and     additions to the book can be found in the Perl4 man page right before     the BUGS section under the heading ERRATA AND ADDENDA.                  Learning Perl  (the ``Llama Book''):               ISBN 1-56592-042-2      (English)       ISBN 4-89502-678-1      (Japanese)       ISBN 2-84177-005-2      (French)       ISBN 3-930673-08-8      (German)           Another of O'Reilly's ``Nutshell Handbooks'', by  Randal Schwartz .  This book is     a smaller, gentler introduction to perl and is based off of Randal's     perl classes.  While in general this is a good book for learning perl     (like its title), early printings did contain many typos and don't     cover some of the more interesting features of perl.  Please check the     errata sheet at ftp.ora.com, as well as the on-line examples.          If you can't find these books in your local technical bookstore, they      may be ordered directly from O'Reilly by calling 1-800-998-9938 if in     North America and 1-707-829-0515 otherwise.             Johan Vromans*  created a beautiful reference guide.  The reference     guide comes with the Camel book in a nice, glossy format.  The LaTeX     (source) and PostScript (ready to print) versions are available for FTP     from ftp.cs.ruu.nl:/pub/DOC/perlref-4.036.1.tar.Z in Europe or from     ftp.cis.ufl.edu:/pub/perl/doc/perlref-4.036.tar.gz in the United     States.  Obsolete versions in TeX or troff may still be available, but     these versions don't print as nicely.  See also:         ftp://ftp.uu.net/languages/perl/perlref-4.036.1.tar.gz   ftp://ftp.cs.ruu.nl/pub/DOC/perlref-4.036.1.tar.gz   ftp://ftp.khoros.unm.edu/pub/perl/perlref-4.036.1.tar.gz             Johan has also updated and released a reference guide based on version     5.000.  This is available from the same places as the 4.036 guide.     This version is also available from prep.gnu.ai.mit.edu in the /pub/gnu     section along with the perl5 source.  It may be added to the standard     perl5 distribution sometime after 5.002.  If you are using version     5.000, you will want to get this version rather than the 4.036 version.         Larry routinely carries around a camel stamp to use when autographing     copies of his book.  If you can catch him at a conference you can     usually get him to sign your book for you.            Prentice Hall also has two perl books.                  The first is  Perl by     Example  by Ellie Quigley. (385 pages, $26.96, ISBN 0-13-122839-0) A     perl tutorial (perl4); every feature is presented via an annotated     example and sample output.  Reviews of this book have varied widely.     Many new perl users have used this book with much success, while many     ``veteran'' programmers have had many complaints about it.           The second book is called  Software Engineering with Perl  by Carl     Dichter and Mark Pease.   Randal     Schwartz  was a technical reviewer for this book and notes this:        SEwP is not meant as instruction in the Perl language, but rather  as an example of how Perl may be used to assist in the semi-formal   software engineering development cycles.  There's a lot of Perl  code that's fairly well commented, but most of the book describes  software engineering methodologies.  For the perl-challenged,  there's a  light  treatment of the language as well, but they refer  to the llama and the camel for the real meat.             SAMS Publishing also has a Perl book available, as part of their ``Teach     Yourself in 21 Days'' series, called  Teach Yourself Perl in 21 Days .     ISBN 0-672-30586-0 Price: $29.95, 841 Pages.  This book is the first     book to have a section devoted to version 5.000, although it was     written during an alpha stage and may not necessarily reflect current     reality.            Please note that none of the above books are perfect, all have some     inaccurances and typos.  The two which Larry is directly associated     with (the O'Reilly books) are probably the most technically correct,     but also the most dated.  Carefully looking over any book you are     considering purchasing will save you much time, money, and frustration.     Starting in the March, 1995 edition of  Unix Review .  Randal Schwartz*  has been authoring a bi-monthly Perl column.  This has so far been an introductory tutorial.          Larry Wall  has published a 3-part article on perl in Unix World     (August through October of 1991), and Rob Kolstad also had a 3-parter     in Unix Review (May through July of 1990).   Tom Christiansen  also has     a brief overview article in the trade newsletter Unix Technology     Advisor from November of 1989.  You might also investigate ``The Wisdom     of Perl'' by Gordon Galligher from SunExpert magazine;  April 1991     Volume 2 Number 4.  The Dec 92 Computer Language magazine also     contains a cover article on Perl, ``Perl: the Programmers Toolbox''.         Many other articles on Perl have been recently published.  If you      have references, especially on-line copies, please mail them to      the FAQ maintainer for inclusion is this notice.         The USENIX LISA (Large Installations Systems Administration) Conference     have for several years now included many papers of tools written in     Perl.  Old proceedings of these conferences are available; look in     your current issue of ``;login:'' or send mail to  office@usenix.org       for further information.         Japan seems to be jumping with Perl books.  If you can read japanese     here are a few you might be interested in.  Thanks to Jeffrey Friedl*     and  Ken Lunde*  for this list (NOTE: my screen cannot handle japanese      characters, so this is all in English for the moment  NOTE2: These     books are written in Japanese, these titles are just translations):      Title: Welcome to Perl Country (Perl-no Kuni-he Youkoso) Authors: Kaoru Maeda, Hiroshi Koyama, Yasushi Saito and Arihito   Fuse Pages: 268+9           Publisher: Science Company  Pub. Date: April 25, 1993    ISBN: 4-7819-0697-4    Price: 2472Y           Author Email:  maeda@src.ricoh.co.jp  Comments: Written during the time the Camel book was being  translated.  A useful introduction, but uses jperl (Japanese Perl) which is not necessarily compatible.     Title: How to Write Perl     (Perl Shohou) Author: Toshiyuki Masui Pages: 352             Publisher: ASCII Corporation  Pub. Date: July 1, 1993      ISBN: 4-7561-0281-6   Price: 3200Y           Author Email:  masui@shocsl.sharp.co.jp  Comments: More advanced than ``Welcome..'' and not meant as an introduction.  Uses the standard perl and has examples for handling Japanese text.     Title: Introduction to Perl  (Nyuumon Perl) Author: Shinji Kono Pages: 203             Publisher: ASCII Corporation  Date: July 11, 1994       ISBN: 4-7561-0292-1   Price: 1800Y           Author Email:  kono@csl.sony.co.jp  Comments: Uses the interactive Perl debugger to explain how things work.     Title: Perl Programming  Authors: L Wall & R Schwartz Translator: Yoshiyuki Kondo Pages: 637+32           Publisher: Softbank Corporation  Pub. Date: February 28, 1993 ISBN: 4-89052-384-7   Price: 4500Y           Author Email:  cond@lsi-j.co.jp  Comments: Official Japanese translation of the Camel book, ``Programming Perl''.  Somewhat laced with translator notes to explain the humour.  The most useful book.  Also includes the Perl Quick Reference -- in Japanese!               Other resources at this site:    Return to  Perl FAQ index .  Return to  MoxPerl Home Page .  Send mail to  Tom Christiansen .
GX038-26-11746176	"November 1999, Issue 47 Published by  Linux Journal                         Visit Our Sponsors:                                            Table of Contents:      The Front Page     Linux Gazette  FAQ         The MailBag        Help Wanted & Article Ideas    General Mail       News Bytes         Distro news    News in General    Software Announcements       The Answer Guy , by James T. Dennis   More 2 Cent Tips    Bob Young Speaks at LXNY , by Stephen Adler   Explorations In Linux Sound , by Larry Ayers   Linux on Token Ring , by Eugene Blanchard   Introduction to Socket Programming , by Pedro Paulo Ferreira Bueno and Antonio Pires de Castro Junior   Multiboot MS-DOS 6.22 - Windows98 - Windows NT Server 4.0 - Linux , by Tom de Blende   rms @ UBC , by Eric Hayashi   Setting Up a Linux Server Network , by Alex Heizer   Securing Linux: The First Steps , by Peter Lukas   Programming on language Dino , by Vladimir N. Makarov   Chez Marcel , by Marty McGowan   Micro Publishing , by Rick Holbert and Mark Nielsen   Emacs Macros and the Power-Macros Package , by Jesper Kjær Pedersen   Backup for the Home Network , by JC Pollman and Bill Mote   Running UNIX At Home , by Rob Reid   Developing Web Applications at Home - Part 1 , by Anderson Silva   LSOTM (Linux Site O' The Month): LinuxNewbie.org , by Slambo   TCP for Transactions , by Mark Stacey, John Nelson and Ivan Griffin   Teaching web site construction with Linux , by Alan Ward   The Back Page         About This Month's Authors     Not Linux                                 TWDT 1 (gzipped text file)   TWDT 2 (HTML file)  are files containing the entire issue: one in text format, one in HTML.  They are provided  strictly as a way to save the contents as one file for later printing in the format of your choice;  there is no guarantee of working links in the HTML version.                   Linux Gazette ,  http://www.linuxgazette.com/   This page maintained by the Editor of  Linux Gazette ,   gazette@ssc.com      Copyright © 1996-1999 Specialized Systems Consultants, Inc.                   ""The Linux Gazette... making Linux just a little more fun! ""                                 The  Linux Gazette  FAQ    Updated 22-Sep-1999         Contents               Questions about the  Linux Gazette                       Why this FAQ?     Where can I find the HTML version of the  Gazette ?     Which formats is the  Gazette  available in?     Which formats is the  Gazette   not  available in?     Is the  Gazette  available in French?  Chinese?  Italian?  Russian?     Why is the most recent issue several months old?     How can I find all the articles about a certain subject?     How can I become an author?  How can I submit my article for publication?     May I copy and distribute the  Gazette  or portions thereof?     You have my competitor's logo on the Front Page; will you put mine up too?                                                Linux tech support questions                      How can I get help on Linux?     Can I run Windows applications under Linux?     Do you answer Windows questions too?     How do I find the help files in my Linux system?     So I'm having trouble with this internal modem...                          This FAQ is updated at the end of every month.  Because it is a new feature, it will be changing significantly over the next few months.              Questions about the  Linux Gazette      1. Why this FAQ?     These are the most Frequently Asked Questions in the  LG  Mailbag. With this FAQ, I hope to save all our fingers from a little bit of typing, or at least allow all that effort to go into something No (Wo)man Has Ever Typed Before.              2. Where can I find the HTML version of the  Gazette ?               The main web site--  www.linuxgazette.com .             Mirror sites in 47 countries , some with translations in other languages.            Indirect mirrors, including   Linux Documentation Project  mirror sites.            In the   Debian/GNU Linux  distribution, as ordinary *.deb packages.            On CD as part of a  Linux Journal  archive CD-ROM .  There may also be other companies that include the  Gazette  on their CDs--we don't keep a central list.  (But we may in the future.)                   3. Which formats is the  Gazette  available in?                As a single HTML file.   Every issue includes a TWDT (The Whole D--- Thing) file containing a copy of all the articles in one file.  This may be useful if you have a slow modem, or if you want to print it all out at once.  Look for ""TWDT"" near the bottom of the issue's Table of Contents.  Hyperlinks in this version are not guaranteed to work.             As a single text file.   This is a text-only version of the above.  Look for ""TWDT"" near the bottom of the issue's Table of Contents.             Via FTP.   Each issue is available as a *.tar.gz file, containing both the ordinary HTML files and the TWDT files.  See  ftp://ftp.ssc.com/pub/lg/README  for details.  Other FTP sites are listed on our  mirrors  page.                  4. Which formats is the  Gazette   not  available in?     Other archive formats.  We need to keep disk space on the FTP site at a minimum for the sake of the mirrors.  Also, the Editor rebels at the thought of the additional hand labor involved in maintaining more formats.  Therefore, we have chosen the formats required by the majority of  Gazette  readers. Anybody is free to maintain the  Gazette  in another format if they wish, and if it is available publicly, I'll consider listing it on the mirrors page.     Zip,  the compression format most common under Windows. If your unzipping program doesn't understand the *.tar.gz format, get Winzip at  www.winzip.com .     Macintosh formats.   (I haven't had a Mac since I sold my Mac Classic because Linux wouldn't run on it.  If anybody has any suggestions for Mac users, I'll put them here.)     Other printable formats.                               PostScript                    You can use Netscape's ""print to file"" routine will create a PostScript file complete with images.                    PDF                    I know Adobe and others consider PDF a ""universal"" format, but to me it's still a one-company format that requires a custom viewer--not something I'm eager to maintain.  If you can view PDF, can't you view HTML?                    Word                    I'll be nice and not say anything about Word....               E-mail.   The  Gazette  is too big to send via e-mail. Issue #44 is 754 KB; the largest issue (#34) was 2.7 MB.  Even the text-only version of #44 is 146 K compressed, 413 K uncompressed.  If anybody wishes to distribute the text version via e-mail, be my guest.  There is an announcement mailing list where I announce each issue; e-mail  lg-announce-request@ssc.com  with ""subscribe"" in the message body to subscribe.  Or read the announcement on  comp.os.linux.announce .     On paper.   I know of no companies offering printed copies of the  Gazette .              5. Is the  Gazette  available in French?  Chinese?  Italian?  Russian?     Yes, yes, yes and yes.  See the  mirrors page . Be sure to check all the countries where your language is spoken; e.g., France and Canada for French, Russia and Ukraine for Russian.             6. Why is the most recent issue several months old?     You're probably looking at an unmaintained mirror.  Check the   home site  to see what the current issue is, then go to the  mirrors  page on the home site  to find a more up-to-date mirror.    If a mirror is seriously out of date, please let   gazette@ssc.com  know.             7. How can I find all the articles about a certain subject?     Use the  Linux Gazette   search engine . A link to it is on  the Front Page , in the middle of the page.  Be aware this engine has some limitations, which are listed on the search page under the search form.    Use the  Index of Articles .  A link to it is  on the Front Page, at the bottom of the issues links, called ""Index of All Issues"".  All the Tables of Contents are concatenated here onto one page.  Use your browser's ""Find in Page"" dialog to find keywords in the title or author's names.    There is a seperate  Answer Guy Index , listing all the questions that have been answered by the Answer Guy.  However,  they are not sorted by subject at this time, so you will also want to use the ""Find in Page"" dialog to search this listing for keywords.               8. How can I become an author?  How can I submit my article for publication?     The  Linux Gazette  is dependent on   R eaders  L ike  Y ou  for its articles.  Although we cannot offer financial compensation (this is a volunteer effort, after all), you will earn the gratitude of Linuxers all over the world, and possibly an enhanced reputation for yourself and your company as well.    New authors are always welcome.  E-mail a short description of your  proposed article to    gazette@ssc.com , and the Editor will confirm whether it's compatible with the  Gazette , and whether we need articles on that topic.  Or, if you've already finished the article, just e-mail the article or its URL.    If you wish to write an ongoing series, please e-mail a note describing the topic and scope of the series, and a list of possible topics for the first few articles.    The following types of articles are always welcome:      technical articles of a HOWTO nature.  (How to set up a program, how to maintain it, my experience running a program even if I'm not an expert, etc.)   For ideas about possible articles,  look in the Mailbag for questions that keep recurring.  Explicit requests for articles appear at the top of the ""Help Wanted -- Article Ideas"" section.    Articles demonstrating the use of Linux in an industry or environment where it might not be commonly expected.    Software reviews, as long as it is a balanced review and not simply an advertisement.  Comparing the pros and cons of this program with similar programs is a plus.    Reports from conferences, etc.    Anecdotes, lighthearted stuff, etc.    Articles requested in the ""Help Wanted and Article Ideas"" section of the Mailbag.    Other areas I haven't thought of.      We have all levels of readers, from newbies to gurus, so articles aiming at any level are fine.  If you see an article that is too technical or not  detailed enough for your taste, feel free to submit another article that fills the gaps.    Articles  not  accepted include one-sided product reviews that are basically advertisements.  Mentioning your company is fine, but please write your article from the viewpoint of a Linux user rather than as a company spokesperson.       If your piece is essentially a press release or an announcement of a  new product or service, submit it as a News Bytes item rather than as  an article.  Better yet, submit a URL and a 1-2 paragraph summary (free  of unnecessary marketoid verbiage, please) rather than a press release,  because you can write a better summary about your product than the  Editor can.      Articles not specifically about Linux are generally not accepted, although an article about free/open-source software in general may occasionally be published on a case-by-case basis.    Articles may be of whatever length necessary.  Generally, our articles are 2-15 screenfulls.  Please use standard, simple HTML that can be viewed on a wide variety of browsers.  Graphics are accepted, but keep them minimal for the sake of readers who pay by the minute for on-line time.  Don't bother with fancy headers and footers; the Editor chops these off and adds the standard  Gazette  header and footer instead.  If your article has long program listings accompanying it, please submit those as separate text files.    Please submit a 3-4 line description of yourself for the Author Info section on the Back Page.   Once you submit this, it will be reused for all your subsequent articles unless you send in an update.    Once a month, the Editor sends an announcement to all regular and recent authors, giving the deadline for the next issue.  Issues are usually published on the last working day of the month; the deadline is seven days before this. If you need a deadline extension into the following week, e-mail the Editor.   But don't stress out about deadlines; we're here to have fun.  If your article misses the deadline, it will be published in the following issue.    Authors retain the copyright on their articles, but distribution of the   Gazette  is essentially unrestricted: it is published on web sites and FTP servers, included in some Linux distributions and commercial CD-ROMs, etc.    Thank you for your interest.  We look forward to hearing from you.              9. May I copy and distribute the  Gazette  or portions thereof?     Certainly.  The  Gazette  is freely redistributable.  You can copy it, give it away, sell it, translate it into another language, whatever you wish.  Just keep the copyright notices attached to the articles, since each article is copyright by its author.  We request that you provide a link back to  www.linuxgazette.com .    If your copy is publicly available, we would like to list it on our  mirrors page , especially if it's a foreign language translation.  Use the submission form at the bottom of the page to tell us about your site.  This is also the most effective way to help  Gazette  readers find you.               10. You have my competitor's logo on the Front Page; will you put mine up too?    All logos on the Front Page and on each issue's Table of Contents are from our sponsors.  Sponsors make a financial contribution to help defray the cost of producing the  Gazette .  This is what keeps the  Gazette  free (both in the senses of ""freely redistributable"" and ""free of ads""  )  To recognize and give thanks to our sponsors, we display their logo.    If you would like more information about sponsoring the  Linux Gazette , e-mail  sponsor@ssc.com .               Linux tech support questions     This section comprises the most frequently-asked questions in The Mailbag and The Answer Guy columns.              1. How can I get help on Linux?     Check the FAQ.  (Oh, you already are.   )         Somewhat more seriously, there is a Linux FAQ located at  http://www.linuxdoc.org/FAQ/Linux-FAQ.html  which you might     find to be helpful.   For people who are very new to Linux, especially if they are also new    to computing in general, it may be handy to pick up one of these basic    Linux books to get started:     Bill Ball's  Learning Linux in 24 Hours   Mark Sobell's  A Practical Guide to the Linux System   Either  Linux Installation and Getting Started  or the  O'Reilly book  Running Linux .  They're extremely similar  so you should only need one of them.     Mailing lists exist for almost every application of any note, as well as for the distributions.  If you get curious about a subject, and don't mind a bit of extra mail, sign onto applicable mailing lists as a ""lurker"" --  that is, just to read, not particularly to post.  At some point it will make  enough sense that their FAQ will seem very readable, and then you'll be well versed enough to ask more specific questions coherently.  Don't forget to keep the slice of mail that advises you how to leave the mailing list when you tire of it or learn what you needed to know.   You may be able to meet with a local Linux User Group, if your area has one.  There seem to be more all the time -- if you think you may not have one nearby, check the local university or community college before giving up.   And of course, there's always good general resources, such as the Linux Gazette      Questions sent to  gazette@ssc.com  will be published in the Mailbag in the next issue.  Make sure your From: or Reply-to: address is correct in your e-mail, so that respondents can send you an answer directly.  Otherwise you will have to wait till the following issue to see whether somebody replied.    Questions sent to  answerguy@ssc.com  will be published in The Answer Guy column.    If your system is hosed and your data is lost and your homework is due tomorrow but your computer ate it, and it's the beginning of the month and the next Mailbag won't be published for four weeks, write to the Answer Guy.  He gets a few hundred slices of mail a day, but when he answers, it's direct to you.  He also copies the Gazette so that it will be published when the month end comes comes along.    You might want to check the new   Answer Guy Index  and see if your question got asked before, or if the Answer Guy's curiosity and ramblings from a related question covered what you need to know.             2. Can I run Windows applications under Linux?     An excellent summary of the current state of WINE, DOSEMU and other Windows/DOS emulators is in issue #44, The Answer Guy,  ""Running Win '95 Apps under Linux"" .    There is also a program called  VMWare  which lets you run several ""virtual computers"" concurrently as applications, each with its own Operating System.  There is a  review  in  Linux Journal  about it.             3. Do you answer Windows questions too?    Answers in either the Tips or Answer Guy columns which relate to troubleshooting hardware, might be equally valuable to Linux and Windows users. This is however the  Linux  Gazette ... so all the examples are likely to describe Linux methods and tools.   The Answer Guy has ranted about this many times before.  He will gladly answer questions involving getting Linux and MS Windows systems to interact properly;  this usually covers filesystems, use of samba (shares) and other networking, and discussion of how to use drivers.   However, he hasn't used Windows in many years, and in fact avoids the graphical user interfaces available to Linux.  So he is not your best bet for asking about something which only involves Windows.  Try one of the Windows magazines' letter-to-the-editor columns, an open forum offered at the online sites for such magazines, or (gasp) the tech support that was offered with your commercial product.  Also, there are newsgroups for an amazing variety of topics, including MS Windows.             4. How do I find the help files in my Linux system?    The usual command to ask for a help page on the command line is the    word  man  followed by the name of the command you need help    with.  You can get started with  man man .  It might help you to    remember this, if you realize it's short for ""manual.""   A lot of plain text documents about packages can be found in     /usr/doc/packages  in modern distributions.  If you installed    them, you can also usually find the FAQs and HOWTOs installed in    respective directories there.   Some applications have their own built-in access to help files (even those    are usually text stored in another file, which can be reached in other    ways).  For example, pressing F1 in  vim , ? in  lynx ,    or ctrl-H followed by a key in Emacs, will get you into their help system.    These may be confusing to novices, though.   Many programs provide minimal help about their command-line interface if    given the command-line option  --help  or  -? .  Even if these    don't work, most give a usage message if they don't understand their command-    line arguments. The GNU project has especially forwarded this idea.  It's    a good one;  every programmer creating a small utility should have it    self-documented at least this much.   Graphical interfaces such as  tkman  and  tkinfo  will    help quite a bit because they know where to find these kinds of help files;    you can use their menus to help you find what you need.  The better ones    may also have more complex search functions.   Some of the bigger distributions link their default web pages to HTML    versions of the help files.  They may also have a link to help directly from    the menus in their default X Windowing setup.  Therefore, it's wise to    install the default window manager, even if you (or the friend helping you)    have a preference for another one, and to explore its menus a bit.             5. So I'm having trouble with this internal modem...    It's probably a winmodem.  Winmodems suck for multiple reasons:     Most of them lack drivers for Linux.  Notice the term ""most"" and not     ""all"" -- see  http://linmodems.org  for      more about those few that do, and some general knowledge on the subject.  Since they aren't a complete modem without software, even if they     were to work under Linux, they'd eat extra CPU that could be better     spent on other things.  So they'll never seem quite as fast as their     speed rating would imply.  Internal modems have their own problems;  they overheat more easily,     and have a greater danger of harming other parts in your system when     they fail, merely because they're attached directly to the bus.  The     tiny portion of speed increase that might lend is not really worthwhile     compared to the risk of losing other parts in the system.     So, yeah, there can be good internal modems, but it's more worthwhile    to get an external one.  It will often contain phone line surge suppression    and that may lead to more stable connections as well.             This page written and maintained by the Editor of  Linux Gazette ,  gazette@ssc.com  Copyright © 1999, Specialized Systems Consultants, Inc.,         ""Linux Gazette... making Linux just a little more fun! ""             The Mailbag!    Write the Gazette at   gazette@ssc.com     Contents:     Help Wanted -- Article Ideas   General Mail                Please, readers, e-mail your questions and comments in    TEXT   format,  not HTML.  And if your mailer splits long lines by putting an  ""="" at the end of the line and moving the last character or two to the  next line, please try to turn that feature off.  Also some mailers turn  punctuation and foreign characters into ""=20"" and ""=E9"" and the like.  I  can't reformat those, since I don't know what the original character  was!  -Ed.      P.S.  This the first time ever I have resorted to blinking text, which I usually despise.  I understand some mailers don't allow you to turn off this obnoxious ""multimedia"" formatting.  But if you can, please do so.         Help Wanted -- Article Ideas     Answers to these questions should be sent directly to the e-mail address of the inquirer with or without a copy to gazette@ssc.com. Answers that are copied to  LG  will be printed in the next issue in the Tips column.     Before asking a question, please check the   Linux Gazette  FAQ  to see if it has been answered there.               Thu, 28 Oct 1999 09:21:39 -0700  From: Linux Gazette < lg@ssc.com>   Subject: Filename extensions for web program listings    Hi, astute readers.  Your  Linux Gazette  editor has a question for you.  With this issue, I've started moving program listings that are  included in articles into their own separate text files, to make it  easier for those who want to run the programs.    My question is, which filename extensions are safe to use so that they'll show up properly as text files in the browsers?  I'm wavering between using a language-specific extension (.c, .sh, .pl, .py, etc.) vs putting .txt at the end of all of them (or .sh.txt, etc.)  What about listings that don't have an extension on the source file?  They display as text on my browser, but do they display properly on yours?    Language-specific extensions would be the most ideal, because they offer the possibility of syntax highlighting if the browser supports it.  (Does any browser support this?)  However, I know I've tried to view files on other sites that I know perfectly well are text-readable, but the browser insists on downloading them rather than viewing them because it doesn't recognize the type.  (Of course, that's better than the corollary, where it tries to view .tar.gz or .mp3 files as text.)      Of course, the ultimate answer is to fix your mailcap entry and MIME types, but that can be tedious.  Also, the person viewing the site may not know how to set the MIME types properly.    So which is better: language-specific extensions, no extensions, or .txt?               Thu, 23 Sep 1999 14:56:32 -0700 (PDT)  From: Angelo Costa < angico@yahoo.com>   Subject: 3-button mouse on X Window System    Can anybody help me with this simple (I guess) problem? My three-button mouse works very fine on the console, but it doesn't when I ""startx"". What's going on? How can I solve this problem and start using the middle mouse button under X? Any suggestion will be appreciated.    Thanx,  Angico.               Fri, 24 Sep 1999 17:50:53 -0500  From: Bret Charlton < bret@bluebonnet.net>   Subject: Monitor    I am new to Linux and I am having problems with my monitor.  Do you know where I might be able to get some help?     [We'll need some more information.  What exactly is the problem?  What  kind of monitor and video card do you have? -Ed.]                  Sun, 26 Sep 1999 05:31:15 -0600 (MDT)  From: Dale M. Snider < dsnider@nmia.com>   Subject: Linux hangs when out of swap    When running memory intensive problems, such as animate from ImageMagic or General Mesh Viewer (GMV) out of Los Alamos Labs, and the swap space limit is reached, Linux hangs. Only option is to power off the computer. This is repeatable (sad to say it has been too often lately).    This does it on the RedHat 6.0 and 5.2 releases. Is there a way to force the application to abort and not the kernel when the swap limit is reached?    I am using the RedHat 6.0 on a PIII, 500 Mhz Intel computer Linux 2.2.5-15 (root@porky) (gcc egcs-2.91.66)   Memory:    Total      Used      Free    Shared   Buffers    Cached Mem:      257876    254496      3380     21292    203096     23624 Swap:     136544         0    136544      Cheers  Dale     [Take a look at the ulimit command (built into bash and other shells).  It tells the kernel not to let this process use more than X amount of  resources.  I use ""ulimit -c 0"" to prevent core files from being  created.  There are several options dealing with memory, although I  haven't used them.  The most promising looks like -v, which sets ""the  maximum amount of virtual memory  available to the shell"".     I have also had problems when the swap limit is reached, but not  exactly like what you describe..  Unfortunately, Linux's otherwise  excellent memory manager is not quite up to par in this situation.  The  kernel is supposed to start killing processes when a critical stage is  reached to free up some memory; however, sometimes that doesn't happen  properly.     I had a situation happen while I was out of town where apache and  squid zombied for no apparent reason, and there were no error messages  in the syslog.  I restarted them (after clearing out the PID lock files  so they would consent to restart) and they ran OK.  Then I realized  syslog wasn't running, which was the reason I had gotten no error  messages for the past day.  Then I noticed there were a whole lot of  zombies, and when I tried to ""kill -9"" them, they remained.  ""Update""  (the daemon that flushes files to disk) was also a zombie.  Tried to  run ""shutdown"", but it wouldn't do anything.  Tried switching runlevels,  still didn't help.  Finally I realized init wasn't running!  How do you  shut down the system when you can't run ""shutdown""?  The old-fashioned  way: close as many files as you can, run sync, press reset, and hope for  the best.  When it came up again, I had lots of fsck errors, two  lost+found files (fortunately non-critical), and all the files I had  created or modified over the past day were unchanged.  Fortunately, the  changes I had made to a text file two days before, which I had worked a  whole day on, were still there.  When I asked people what could have  caused this, the consensus seemed to be the system had probably run out  of memory.  This is with kernel 2.2.10 on Debian.  Fortunately, the   problem has not repeated; and doubly fortunate, it didn't happen during  the time I was away and had to log into the box remotely to check my  e-mail; and triply fortunate, exim (in non-daemon mode) ran fine the  whole time.  -Ed.]                   Sun, 26 Sep 1999 13:59:49 -0400  From: Dyslexic < dyslexic@mindspring.com>   Subject: agp support in linux    Does linux support the AGP port? I have linux setup on a AMD K6-2 450Mhz with 160Megs of ram 13 gig hd, HP  CD-RW, zip drive, SB AWE64 on an EPOX MVP3G motherboard I am using a creative graphics balster banshee AGP card with 16megs of ram.    I have installed linux mandrake 6.0 (from the cd included with the Maximum linux magazine) during the installation the only error i encontered was that the bootloader wouldn't install.    right now I am booting with a floppydisk. When linux boots up the resolution is set at about 640 x 480 and is very difficult to work with is there anyway to increse the resalution? I have checked several FAQS and have found nothing helpful, I don't know anyone who uses linux so i'm pretty much flying blind here                Mon, 27 Sep 1999 11:11:20 +0100  From: Linda Fulstow < linda.fulstow@easynet.co.uk>   Subject: epsom 800 printer driver disk    Linda Fulstow SCOPE 01752 788099    We need to install above and need a driver installer disk, can you help. e:mail us or please call 01752 788099, we are desperate.                 Mon, 27 Sep 1999 10:58:22 -0500  From: EuphoriaDJ < eddthompson@ssi.parlorcity.com>   Subject: iMac and Linux ethernet (& FreeBSD maybe)    I have all the wires hung, the hub powered and the computers on. I would like to share files between my iMac and Linux box and later on when I get it running my 68kFreeBSD Mac. Also I would Like to serve X windows to the Mac from Linux.    Any help would be excellent.  TTFN    An Elephant: A mouse built to government specifications  Never try to out-stubborn a cat  Natural laws have no pity                  Tue, 28 Sep 1999 03:51:36 +0000  From: Ben < benvh@wish.net>   Subject: AT-command error message    Whenever I try to run ""at"" I get an error message, like so:    root@benzz:> at 10:15 command Only UTC Timezone is supported. Last token seen: command Garbled time    This is actual output. My system _is_ on UTC timezone, the at man-page didn't help a bit. Someone suggested that I should write a file:    echo command> file at 10:15 cat < file    but that wouldn't help, as ""at"" is still in there, and it's ""at"" making trouble. Does anybody know what I'm doing wrong? Or just another way to schedule tasks? I'm getting desperate now...      May the Source be with you.               Wed, 29 Sep 1999 22:24:29 -0700  From: Wayde C Gutman < wcgutman@mwpower.net>   Subject: LS120    This is a multi-part message in MIME format.   I would like to know exactly what I need to input into the /etc/fstab concerning having OpenLinux 2.2 to see the LS120 drive. My system has the 1.44 floppy drive at fd0, hard drive at hda and hda1, and the cdrom at hdc. I tried the approach Caldera suggested for the owner of OpenLinux 1.3, it didn't work or I messed up, which is possible since I am still a greenhorn at this.                  Fri, 1 Oct 1999 16:43:35 +0800  From: u < leeway@kali.com.cn>   Subject: program that play Video Compact Disk (VCD) and more    i have RH 5.1. Is there any program that play Video Compact Disk (VCD)? Last month I posted the same question from leeway@tonghua.com.cn. Unfortunately, the free eamail-box does not work now and i get no help. I apologize and thank anyone who replied.    Something very strange happens: My Win97 can't use CD-ROM after a week of installation but Linux has no problem. Now Win97 uses MS-DOS compatible mode to access hard disk and it's slow. Anybody has any idea on this?    i use mixviews of Debian to record a wave file input from a cassette player. I use 3k sample rate/16 bit and it plays fine. But the effect is terrible on recorder of Win97. When i change the sample rate to 8k, it's OK on both. Why? Is there any wave-to-mp3 util? mixer does not remember the setting so i have to adjust it each time. How to solve it?    PS: is there any icons for redhat and debian so I could use to launch Linux from Win97? i already made the shortcuts but can't find good icons and i'm not good artist. I will appreciate if you could email icons to me.                Sat, 02 Oct 1999 21:29:21 +0200  From: 2095910 < albert.prats@campus.uab.es>   Subject: Tryin' to install a Diamond SupraExpress 56i V PRO    I have a problem with my new modem. I tried to install it under Red-Hat 5.2 but it doesn't work. My modem is an internal Diamond Supra Express 56i V PRO and under W98 the  default configuration is irq 12 an I/O port 0x3e8. Under W98 it works perfectly and i don't think this is a ""winmodem""(isn't  it?). Windows ""says"" that under DOS it must be configured with: COM 3, irq 4 and I/O port 0x3e8 (/dev/ttyS2 isn't it?)    I just want to know if this is a winModem or not and how can I install it.                Mon, 4 Oct 1999 18:08:56 -0400  From: The Wizard < wizard@openface.ca>   Subject: My Windows partition hasd full access for root only    I have 2 questions:    I have partitioned my HD in 4 partitions.       1 - Win98 (Filesystem is FAT-Win95)    Linux Swap    Linux OS    Personal Data (Filesystem is FAT-Win95)      Questions 1.  Both the FAT-Win95 Filesystem Partitoins get mounted properly in Linux but the problem is that only root has read/write/execute permission. The other users only have read/execute permissions.How can I have it set up so that everyone had r/w/x permission to the mounted filesystems (and all the subdirectories within them)    Question 2.   If I access any file from the FAT-WIN95 filesystem and make a change to it within Linux, when I boot in windows, that file is marked as ""read only"". Any idea why this is happening and how I can stop this from happening?    Maybe the two are related. Any help will be greatly appreciated.                     Wed, 06 Oct 1999 01:22:19 -0700  From: Zac Howland < howla_j@cs.odu.edu>   Subject: Diamond HomeFree Phonline Home Networking    I recently bought a Daimond HomeFree Phoneline Networking kit.  It works great in windows, but i use linux most of the time on my pc and was wondering if anyone knew how to set it up for a linux machine.  My pc is the ""Administrator"" so I need it to work so others in my home network can still access the net while I am working in Linux.    Thanks                Wed, 06 Oct 1999 13:05:18 +0200  From: Sandra Uredat < a2844745@smail.Uni-Koeln.DE>   Subject: KDE slower than windoze?    Hi all,    I've just installed linux on my Acer Notebook 370 and I thought everthing works fine. But when I'm running KDE it takes e.g. about 5 minutes to open Netscape!!! Is anybody out there who knows what's wrong with my installation???    Thanx in advance  Sandra               Sat, 9 Oct 1999 04:31:52 +0900  From: Ganesan < cs7505@cs.inf.shizuoka.ac.jp>   Subject: CDROM MOUNT FAILURE DURING INSTALL    I am trying to install REDHAT LINUX 6.0 to my Note-PC. but I can't get it done.     I always get the message mount failure.     I searched FAQ,but all the question is about how to mount after installing.     I am getting this message after my PC search for the PCMCIA card. My PC managed to find my PCMCIA-SCSI Card(ADAPTEC 152X) but  after that the message says ""CDROM Mount Failure-Block device required""     Please tell me how to do it.     Thankyou.  Ganesan                    Sun, 10 Oct 1999 09:23:42 -0400  From: Brad Renner < banner99@iapdatacom.net>   Subject: LINUX for a 486    I read about LINUX in a recent issue of a computer magazine.  I really don't use my PC for much of anything but work.(I use it to run a Roland PNC 1410 vinyl cutter) I am, to say the least, Curious about LINUX.  I also have an old Toshiba satellite T1910CS.  It's a 486 with 4 megs of RAM and I believe a 200 meg hard drive.  A friend of mine was going to throw it away so I took it.  I would love to experiment with LINUX if there is a version available that will run on it.  Windows 95 just crawls on the thing, and I've recently been using DOSSHELL.  The only thing I really will be using it for is keeping track of customers,  printing invoices, and E-Mailing my wife.    Thanks  Brad Renner     [I have a Toshiba Satellite 486-75, 16MB RAM, 500MB HD, and it has been  running Linux for four years.     I would not recommend trying to install Linux on a 4MB machine if  you're not familiar with Linux.  It would have to be done the  ""old-fashioned way"", without the automatic installation utilities the  current distributions have.  You would have to use an old kernel  (perhaps from the 1.x series).  For your efforts you would get a server  that could perhaps be used as a one-purpose dedicated server or as a  dialout terminal, but that's it.     I used to work for an ISP where we used 386s (8MB RAM) and then 486s  (16MB RAM) as routers.  The 386s worked fine with the then-current  version of Slackware (this was 1996), although we upgraded the memory to  16MB on the higher-traffic ones.  The worst problem was never knowing  when the ancient hard drives would fail.  The 486s (1998) were much more  reliable.     Linux is very scalable and can be used on a wide variety of  machines, but of course some of its features aren't usable on lower-end  machines.  You didn't say what capacity your desktop PC has.  I would  consider 16MB a minimum amount of memory for a general-purpose machine  that is not running X-windows, and 32 (or more) if you want to run  Netscape or an office suite. -Ed.]                   Mon, 11 Oct 1999 13:26:21 +0200  From: Mr. Tibor Berkes < berkes_t@netlock.net>   Subject: TAAKACS+ and RADIUS    I would like to know whether the TAKACS+ and RADIUS authentication servers for Internet Service Providers can authenticate by x509 certificate which can be found at the customer, so at the Dial-Up Networking there isn't Log-in and Username.    I look forward to hearing from you,                    Tue, 12 Oct 1999 00:31:10 +0200  From: Th. Fischer < frosch@cs.tu-berlin.de>   Subject: Compiling everything myself    Greetings, ladies and gentleusers.    I would like to compile my own Linux system. Not just the kernel. Everything. I've got enough room and partitions on my disk(s) to do it. Do not tell me do buy a distribution. Until now, I've tried a lot of them - I count eleven on my shelf - I do not like one of them the way I would like a self-created one.    I just need a place to start. All of the distributions must have started at some point or another - how did they do it? Please point to a location where info may be obtained. The LDP seem to provide _nothing_ concerned to this task.    Every hint will be highly appreciated. I would also love to contribute documentation of the process to the Free Software community.     Every reader is invited to answer via email.    Thorsten Fischer                Tue, 12 Oct 1999 09:50:02 -0600  From: Tom Miller < tjmiller@DATC.TEC.UT.US>   Subject: Looking for suggestions and ideas for a Linux-based class     By way of introduction, I am a computer and networking instructor at Davis Applied Technology Center (- the ATC's are Utah's equivalent of VoTech schools.)  My original industry background is in *ix-networked mainframes, LAN/WAN architecture, and in mixed-environment networks ( mixed, as in putting *ix and MS in the same coherent network- I even went and got an MCSE to certify in the MS half of it)    Digression aside, this is my predicament:    Having recently come on board as a instructor here at DATC, I had noticed that the UNIX curriculum was way out of date, and had but a single small class (they were still teaching an older version of SCO-Unix as the core OS.)  I proposed to update it, and a deadline of January 2000 was set for the basic course, March 2000 for the advanced/sysadmin level course (though it should be done at about the same time as the basic course.)    Currently, I have a basic course outlines (using Linux as the core OS), and have found the textbooks for the courses (which I have split up into basic *ix and advanced sysadmin-level *ix)    My question to all of you in the industry is this: What parts of Linux, and the networking of same, are most important to you? Should there be more concentration in TCP/IP fundamentals (which I have included), specific Linux/*ix-based programs ( KDE, Gnome, Apache), or which? What is it that you most desire in an entry-level (or not-so-entry-level) employee candidate?    I do have a structure based on my own opinions, yes, but since our mandate at DATC is to match industry needs, I wanted to get the widest base of opinions possible.    (An aside - I know that Red Hat is working to get a cert program together, but until it gets in place fully (and until all the testing centers carry it), I've got a curriculum to build.)    Please feel free to send all of your ideas, suggestions, and a brief description of why they should be implemented to me, here at tjmiller@datc.tec.ut.us  . Especially encouraged are those in the industry who hire entry-level IT professionals. I would also appreciate a brief description of what your company does in the industry, if you would be so kind.    My gratitude in advance,  TJ Miller jr                     Tue, 12 Oct 1999 15:21:53 -0400 (EDT)  From: Roberto Novoa Quiñones < rnovoa@ucfinfo.ucf.edu.cu>   Subject: Desde Cuba          Un saludo ante todo. Tuve la oportunidad de leer en Internet un artéculo de esta revista y por eso quiero mantener correspondencia con ustedes y si les es posible enviarme a esta dirección información sobre el efecto 2000 y las consecuencias que esto traerá para la economéa o para cualquier rama, no especéficamente de la economéa.        Soy estudiante de la Facultad de Ingenieréa Mecánica de la Universidad de Cienfuegos y actualmente estoy cursando el tercer año de la carrera. Su ayuda me será de gran satisfacción ya que por otros medios no puedo obtener esta información. Gracias.     Fraternalmente,    Marco Novoa Quiñones.                    Tue, 12 Oct 1999 23:50:19 -0700  From: Ken Deboy < glockr@alternavision.com>   Subject: Source for ls command?    Hi,  I'm looking for source code for the ls command on my Redhat (4.2) CDROM under the SRPMS directory, but I can't find it anywhere. I also did a 'find / -name ls* -print' of my system, and it found the binary but not the source file. Can you please tell me where it is? Thanks:)      [It's part of a larger package.  I use Debian, so I would type:     dpkg -S ls | grep bin/ls     (The grep is there because of the large numbers of hits  on the bare substring ""ls"".)  This shows which package contains the  file.  fileutils: /bin/ls See the rpm manpage; there should be an option  that does a similar thing.  In any case, the package is probably called  ""fileutils"" on RedHat too, since both distros got it from the same  source. -Ed.]                           Thu, 14 Oct 1999 20:18:03 +1000  From: Hakon Andersson < hakon@netspace.net.au>   Subject: i740 AGP    I wish to run my i740 AGP under Linux. I am a Linux newbie though. I was wondering if you could tell me, or direct me onto some resources on how to setup my i740, or which server to install during installation. I am installing Redhat5                 Thu, 14 Oct 1999 17:13:34 +0530  From: uday rajput < udayrajput@hotmail.com>   Subject: final year engg project on VPN    sir, I am A final Year student in India toiling with the Idea of a VPN as A final year project. Virtual Private Network is A Virtual concept for me till now desperate need for help as time is running out .    resources at hand:      Red HAt Linux 6    a star board lan network    a shell internet account at work place.                   14 Oct 99 18:33:36 MDT  From: Wasim Ahmed < gracewasim@usa.net>   Subject: Creative 3D Exxtreme Driver Needed for Linux       I'm a Newbie in Linux, but i have a Great Background on Computer Field Right now I'm using Win 98, NT. I have used Linux before. Right now, I have 233MMX, 40MB Ram, CD-ROM, 5.1GB HDD, 100 ZIP Drive, Creative AWE64 Sound Card & Creative 3D Exxtreme Graphics Blaster.     Now I have installed Red Hat Linux 5.2. Installation was succesful. But my X Window is not running, cause i don't have driver for 3D Exxtreme.    Can u pleasee help me by providing the Driver or can u tell me where I can find it?    Please, that will be Great Help to me..               Fri, 15 Oct 1999 10:51:15 +0200  From: Stephan Schulz < sschulz@cvbg.stl.sn.schule.de>   Subject: Need some Help installing Vodoo3000 AGP on Linux X    Is there a free X-Server for Vodoo3000 AGP cards? If yes plaese tell me where and how to use it!                  Fri, 15 Oct 1999 08:31:55 -0700  From: Linux Gazette < lg@ssc.com>   Subject: Re: sample    On Fri, Oct 08, 1999 at 02:15:08PM +0800,  wrote:    Suppling some 8-10 sample installation plans will be  of great help to the beginners of my type.      Hi.  What do you mean by sample installation plans?  Do you mean a list of packages to install?  Step-by-step installation instructions?  Or something else?                Fri, 15 Oct 1999 08:50:15 -0700  From: James M. Haviland, RN < jhavilan@oz.net>   Subject: Re: Linux Gazette #46 (October 1999) is available    If I download the ""tar"" file [of the  Linux Gazette ], but how do I read it?  I've have OpenLinux 2.3 installed at the moment.  I do have 2.3, but do seem to be able to install it.  Doesn't like my CD player(?).     TIA     Oh, yes this Eudora Lite.  I like it better than the reader that comes with 2.3. I didn't find Pine in the install.  Yes, I can download the tar file, but how to install it is another question.     [Download lg-base.tar.gz and the lg-issue##.tar.gz files of your choice.  Run  tar xzvf lg-FILENAME.tar.gz  for each file.  They will all expand into a subdirectory ""lg"".  (Run  man  tar  for an explanation why.)  Then in your favorite web  browser go to the URL   file:/FULL-PATH-TO/lg/index.html  (using the real  full path, of course).  index.html is a symbolic link to  index.html.  -Ed.]                 Wed, 23 Oct 1996 11:24:47 -0400  From:  Thomas Russo < webmaster@baybiz.net>   Subject: su not working    Hello.  I am writing because as of 2 weeks ago I have lost the ability to su to root.  I can still log in as root.  I can also su from root to normal users.  I am running Red Hat 6.0 with the kernel 2.2.5-15 on i686.  I am currenly running a live Apache web server version 1.3.6.  I have been told that the loss of the ability to su to root could be a sign of an intruder. I am hoping this is not true.  I am further hoping that this is just some setting that can adjusted to remedy this.  I am at a complete loss as what to do I am hoping that you can help me with this.  If there is anyother information that I have left off I apologize.  Thank you in advance   The Editor wrote:     I don't have answers, but some possible strategies:    1) Check /etc/passwd (and /etc/shadow if it exists) for any users besides root with UID 0.  These should probably be removed, or at least put an  'x' or '*' or something at the beginning of the password so they can't log in.    2) Change your root password (and other passwords).    3) Check for all programs called ""su"" on the system.  Only one should  exist, /bin/su.  The others could be trojan horses.  Do you get the same behavior if you type ""/bin/su"" to run it rather than just ""su""?    4) Reinstall the package containing /bin/su.  (shellutils?)    5) Read the man and/or info pages for su carefully: there may be a configuration file somewhere that determines who can su.    6) What error message did you get?  Login incorrect?  Permission denied? Forbidden to su root as this user or on this terminal?    7) Are you using shadow passwords?  There could be an inconsistency in the password configuration: are all the passwords in /etc/passwd *'d out?  Or is there a password in /etc/passwd that is different than  /etc/shadow?  Shadow passwords are supposed to be an all-or-nothing approach, but sometimes one gets inconsistencies in that some programs (login, passwd, su, getty, adduser) use/modify the shadow file and  others don't.  I would not expect this on a modern Red Hat installation, though.  If you do notice a discrepency, all login/authentication packages should be replaced, and have a boot floppy handy in case you lock yourself out of your system.      8) Are you using NIS?  This would add another layer of complexity which I'm not qualified to comment on.    Thomas wrote back:     [parts of e-mail deleted]   I can't find anything [in the su man page] except a mention of the wheel group    I get incorrect password...when it is the correct password I have now determined that any su involving a password fails for the same reason...incorrect password    I am using shadow passwords.. I have found an inconsistency.  In passwd there is one user named ken (as it should be)  however in shadow there is a ken and a Ken(should not be a Ken).  So according to you I should replace all the packages for login, which I have not done yet, nor am a sure how to do.  Are they RPM's ( I hope)?    No on the NIS    The Editor responded:    If your system uses a wheel group, only people in the wheel group are allowed to su root.  Add your username to the wheel group in /etc/groups. You'll then need to log out and back in again.  Run the command ""groups"" to see which groups you're in.    /etc/passwd and /etc/shadow should not have any lines that aren't either genuine users or the pseudo-users that came with the OS (audio, floppy, dip, nogroup, users, etc) or installed by packages (majordom, news, irc, etc). The pseudo-users normally have a password ""*"" to prevent anybody from  logging in as them (except ""news"" perhaps if you have a news administrator that needs to be user ""news"" to do administrative work).    There should be RPMs for all the login-related programs.  Look through the descriptions of packages on your CD and you should find them. The shadow utilities will be in a separate package.    I would fix any inconsistencies or unauthorized users in the passwd and  shadow files first, and then reinstall the packages if things still aren't working right.    Thomas wrote again:     I really appreciate all your advice.  I have found the problem.  Apparently the rights to /bin/su were set to  rwxr-xr-x  instead of  rsxr-xr-x .  I feel really stupid for overlooking such a thing.  I still don't know how it got changed.  I am guessing that it was not an intruder, I cannot see a motive to do such a thing...but who knows.  I still have that strange user that did not belong.  I just edited him out of shadow.  Once again thanks.    The Editor lamented:    Ach, I didn't even think about that.    Thomas added:     Probably not worth printing anymore huh.  Once again thanks.  If you ever have any thoughts on how that extra user got into shadow feel free to let me know.  Thomas   The Editor concluded:    Regarding the unknown user:  considering it's your own name, it may be that you typed it that way at some prompt during the initial installation.    Regarding the e-mails: they're still worth printing because they may help somebody else.                Sun, 17 Oct 1999 14:25:10 -0400  From: CYBERSTORM < cyberstorm@prodigy.net>   Subject: LINUX!!!!!!!!!!    I can't figure for the life of me.........why is it so hard to get a modem recommendation for LINUX???  This is all I'm asking for!  I've seen the text on what not to use, but no information on what to use. hmmmm.....    1. A modem for Linux on an IBM aptiva.... once more, any recommendations???     Anybody!!      The Editor wrote:    I don't know the IBM aptiva, but assuming it's an ordinary PC...    Any modem that's not a Winmodem is fine.  If it says on the box that it works with DOS and/or Macintosh as well as Windows, it should work.  I use the US Robotics Sportster, but modems have standardized enough now that they should be pretty interchangeable.  External modems are easier to configure than internal ones, because you have the status lights to tell you what the modem is doing, and you don't have to muck about with Plug-n-Delay or whether another device (a serial port?) is using the IRQ.  Some people also suggest external modems are better because the heat they generate belongs outside the computer case.    If you intend to use a 56K modem, verify with your ISP which modems are compatible with their equipment at 56K. -Ed.]      Cyberstorm responded:     Thanks for the extended information....it was all I wanted.  Accept my apologies for the message sent earlier.... it's a bit frustrating when your on a schedule. You've been very helpful to me.               Mon, 18 Oct 1999 10:07:16 -0200  From: Erik Fleischer < ferik@iname.com>   Subject: Installing Red Hat 6.1    Hello, there.    I have successfully downloaded Red Hat 6.1 and burned a CD, but when  I try to install it -- either using AUTOBOOT from DOS or the boot  disk produced with RAWRITE and BOOT.IMG -- I always get the same  error message:   running install... running /sbin/loader exec: No such file or directory install exited abnormally sending kill signals  etc.      I have checked that there are no missing files in the stuff I  downloaded, but I cannot find /sbin/loader, which is obviously a  problem.    Any suggestions?  Erik               Mon, 18 Oct 1999 19:27:54 -0700 (PDT)  From: john saulen < johnsav@yahoo.com>   Subject: install modem and printer    I've recently installed Linux 6.1.I am having a problem installing my Zoom 56k modem as well as my Lexmark 3200 color inkjet printer.I have been to the Lexmark site and there are no drivers for Linux.Any help in this matter would be appreciated.                Tue, 19 Oct 1999 10:49:41 -0700  From: Dr. Nicholas Graham < ngraham@ucsd.edu>   Subject: Dual PIII Xeon performance    I do some intensive (multi-week runs) ocean modeling on my Dell 610 w/ a PIII 500 Mhz Xeon.  I am having a hard time finding out whether a second PIII will improve the speed of a single process, or only for multi-processes. Either way would help, but it would be nice to know before laying out the $.     Thanks - Nick Graham               Tue, 19 Oct 1999 16:45:40 -0500  From: Danny R. < danny@josifa.com>   Subject: How can 3 stand-alone PCs be hooked up with ADSL?    I am considering to subscribing (SWBell) ADSL from South Western Bell  (without subscribing their Internet Service). My current ISP and Web  Hosting service provider is UNICOMP. I have 3 emails and 3 stand alone PCs  (no LAN connection). Each PCs need to access to the internet daily.       How can those 3 stand alone PCs be hooked up with ADSL (from SWBell) without LAN connection ?    What hardware/software are needed to do so?      Thank you for your attention and I am looking forward to hearing from you  soon.                 Wed, 20 Oct 1999 12:27:45 +0200  From: Giovanni Rizzardi < Rizzardi.Etnoteam@italtel.net>   Subject: Modem performance ...    I am not a new comer because it is four years that I am happily using Linux.    Two months ago I bought a modem and I did not have any problem putting it at work but for a strange difference in the performance when I connect using Linux or Win95 (both on the same PC but in different partitions): the connection speed using Linux is around 30,000  while using Win95 is aroud 50,000.    Till now I have not understood why, is there anyone that can explain me where is the bug ?    My modem is a 3Com Sportser Flash V90 and Linux is RedHat 6.0    Many thanks,                          Giovanni.                Thu, 21 Oct 1999 02:15:30 +0200  From: Altair < aitor.sm@teleline.es>   Subject: Free-Mathematica??    Sorry, I don't know if I'm sending this email to the adequate address. Sorry 2: for mistakes with my English.    Question:        Mathematica is becoming one of the more popular programs to deal with symbolic mathematics.        Is anybody in this world trying to create a Free-Mathematica     for Linux?        If the answer is yes, I wouldn't mind to help if possible, I'm a Mathematician.                  21 Oct 1999 08:20:03 -0700  From:  < akudesia@123india.com>   Subject: Compaq Proliant Fast wide SCSI-2    Hi there    Trying to install RedHat Linux 6.0 on Compaq Proliant 2000 and Installer program can not detect on board SCSI controller (Fast Wide SCSI-2). I tried all listed but none of them works.    Where to find?                Thu, 21 Oct 1999 20:46:51 +0100  From: oliver cameron < oliver@hii.co.uk>   Subject: Small Business Server    Can anyone direct me to an article on setting up a linux server for windows/NT clients similar in functionality to Microsofts expensive and unreliable ""Small Business Server""? I need a linux box with a proxy server (Squid), Sendmail , an ISDN connection with automatic dialling configured, a fax server, a file server with samba, automated back-ups and printer support. Has anyone produced a readable article on the subject as I have found the various HOWTO's depressingly complicated. Maybe I have missed something obvious but I have not seen any articles devoted to setting up a simple LAN server under Linux. Any help would be greatly appreciated.    Oliver (oliver@hii.co.uk)                 Thu, 21 Oct 1999 15:56:49 -0400  From: Anthony Mancuso < am5008@cnsvax.albany.edu>   Subject: 810 chipset    I was looking through the questions and responses in the gazette here, and I came across a question about the onboard video card, Intels 810 chipset.  I am also having problems with it.  However, you didnt write a response to the person.  I was wondering if you had any solutions to this problem, or any ideas.  If you could help me out I would greatly appreciate it.    Tony  am5008@cnsvax.albany.edu     [I stay away from answering video card questions because I don't know  much about the different cards.  I am very cautious with hardware, and  buy only models that I have heard other Linux users say good things  about during the previous year.  Thus, I have a Diamond Stealth which  has worked wonderfully for years and a Matrox Millenium II which has  more video memory but apparently a bad RAMDAC (the picture blanks out  for a second at random moments).  It was warranted for a year, but of   course the model got retired before that, so I never did bother sending  it back to the company; I just moved it into a server where it could  run in text mode.  -Ed.]                 Thu, 21 Oct 1999 17:12:00 -0400  From: Max-zen < onqams@muss.cis.mcmaster.ca>   Subject: comparision    Why would I want to use Linux as opposed to Windows??? Could you give me a comparision or give me some sites to look at??                 Sat, 23 Oct 1999 12:42:40 +0800  From: Zon Hisham < zon@mad.scientist.com>   Subject: Norton Kill my LILO    My wife ran Norton antivirus and detected that the MBR was changed. She checked the 'Repair' box.    Now my LILO is gone. How do I install it back into the MBR?    Currently using RedHat 6.0.     rgds.                 Sat, 23 Oct 1999 11:29:34 +0530  From: R . A. PATANKAR < srp@pn3.vsnl.net.in>   Subject: sis 6215c driver needed    i have a sis 6215c graphics card. where can i download a linux driver for the card.                  Sat, 23 Oct 1999 12:26:03 +0100  From: CMFD < rena1@jet.es>   Subject: Diamond SpeedStar A50    Hello, I would like to know if Diamond SpeedStar A50 graphic card  is used and supported to install XWindows in Red Hat Linux, because it has given many problems.Or if there are some drivers to upgrade this card. Thank you for your attention.                  Sun, 24 Oct 1999 19:26:48 -0400  From: E-man < falcon65@mindspring.com>   Subject: fsck    I was running RHL6.0 w/o a UPS, when all of the sudden the power went out. The system rebooted and started to to a forcecheck scan, this is not the first time this happened. There were problems and I was told to run fsck from a boot disk.    LONG STORY SHOT: there are problems with it not seeing files, or someting like that, and now I don't have X, its gone and PROC wont load.    Any clues as to what could have happened?    I'm a newbie, about 2 months old. I already miss my Linux!!!!                 Mon, 25 Oct 1999 11:57:40 +0200  From: Juan Pazos < jpazos@teleline.es>   Subject: Connecting Linux to NT    I want to connect from my Linux home box (over a analogic line and using PPP) to my office Windows NT Server; I try to find some HOWTO about it but I can not get it. Do you know where I can get it?                  25 Oct 99 08:36:39 MDT  From: Syed Adnan < kundalani@usa.net>   Subject: RIVA tnt 2    I own a Riva TNT 2 Value Graphics card. I'm having a serious problem with installing Linux 6. I've never used Linux before and have treid installing Linux several times using differnt servers(I dont even know what those are). I guess my normal shell screen is working properly but the Linux GUI is not loading... do i need a specific driver for Riva tnt and if so then how do I install it  through the shell.    Regards  Adnan    P.S Where exactly are the answers to thees question published?      The Editor wrote:    The question will be published in the Mailbag section of the November issue, to be published this Friday.  People will send responses to you directly with a cc: gazette@ssc.com.  Responses will be published in the 2-Cent Tips section of the next issue.                Mon, 25 Oct 1999 19:02:08 +0200  From: Fred Van der Linden < els11867@skynet.be>   Subject: HP890C    Can anyone send me a driver for HP890c printer.    Many thanks for answering,  Fred Van der Linden                Mon, 25 Oct 1999 20:02:06 +0100  From: Tom Kidd < chewbaca@tomsdig.freeserve.co.uk>   Subject: Dialing Up my ISP    I was wandering if it is at all possible to use my current ISP account (with Freeserve) through REDHAT Linux. If So why does it always Crash, If not, Wat kind of Account(what ISP) do you Recomend?     Sincerly Tom                 Mon, 25 Oct 1999 19:38:13 +0000  From: roselin leong < zczcr14@ucl.ac.uk>   Subject: Research    I am a university student at the University College London. I was wondering if I could get some help here. I am currently working on a dissertation on open source, incorporating case studies on Linux, Netscape and so on. I will also be looking at the changes open source have affected closed source softwares.    One part of my research is where I am analysing the business model of Linux (from Redhat) . However I fear by going to Redhat's website the information about it's product may be biased and I may not be able to get an all rounded opinion. Hence is there any links (apart from the technical ones) that you could recommend?    Thank You.                    Wed, 27 Oct 1999 00:54:44 -0500 (CDT)  From: Eric Agnew < agnew@spfc.org>   Subject: mail bag q: 1-way cable modem woes    6 days of scouring the mini-HOWTO, the web, deja, the linux-net archives, and trying every imaginable route(8) configuration have left me nothing short of frustrated...    I just got a new com21 from Prime Cable in Chicago, which, of course, ""doesn't fully support"" anything but win95/98/nt (which, of course, it works fine under).  Of course, I'd much prefer to have it up on the linux box, so all the machines can use it (currently 3-5 machiens share a 28.8 connection- ugh!).    They give you a username/pw, a number to dial into w/ a regular modem, and have you set up the ethernet as 10.0.0.1/255.255.255.240.    I can dial in ok, ping other machines on the same subnet (which come back over ppp0), etc.  Problem is, the only thing I get on eth1 are arp who-has packets and pings from 10.0.0.14 (which I'm guessing is their router) to other hosts on the subnet.    I'm running debian potato w/ a fresh 2.2.13 kernel & just about every networking option compiled in.  I've disabled ipchains & eth0 (internal lan) until I can get this thing working.  I've tried every set of ifconfig & route commands I could think of, & still nothing.    If anyone out there has a similar cable/ppp setup, the outputs of 'ifconfig' and 'route -n' would be of immense help (all I've been able to find are RH sysconfig examples), as well as anything unusual (special ppp hacks, kernel modules, etc.) that was necessary to get it to work.    Any help greatly appreciated.  Thanks.                    Wed, 27 Oct 1999 10:19:20 -0700  From: Irfan Majeed < irfan@indiagate.com >  Subject: Re: Please Help  We are using POP3 on linux. Can a particular user will bw restricted to send outgoing mail ? For an internal mail auto respondent mail is possible ?       What is it exactly you want to know?         Whether a certain user can only send mail but can't receive it?     Whether the user can be forbidden from sending mail, but   can still receive it?     Is it possible to set up an automatic response message that   will go out if the user receives any mail?        Which mail transport program are you using?  (Sendmail, exim, smail,  qmail, postfix, etc)     People normally use pop to receive mail, but they send mail directly  to the mail transport program.  So it should be possible to restrict one  without the other.  I don't know how you would configure the  restriction, though.  Mail transport programs have a configuration  option to prohibit relaying from certain domains, but I don't know if  that can be used to reject mail from certain local users.     Autoresponders usually work via the ""vacation"" feature in mail  transport programs, normally using a .vacation file in the user's home  directory with the body of the message.     Pop usually works on top of the normal mail-reading mechanism.  That  is, the mail transport program delivers received mail to the user's  spool file, and then the pop program acts like a normal mail reader and  picks it up from there.                  Wed, 27 Oct 1999 23:47:40 -0500  From: Smita Narla < snarla@cse.unl.edu>   Subject: Re: thank you and please send me more.     I'm doing a general research on survey of testing techniques used in open source.For that thing i need a questionnaire.i need to send these questionnaire to 200 developers and from their feedback i 've to analyse.For example one question might be ""When do  you consider testing to be complete?"".My advisor told me that developers will feel comfirtable if they are to answer multiple choice questions so now hope i made my need clear. can you please help me now. i'll be glad if u could send me some questions and some mail addresses of  developers who r using linux to develop their applications.. ineed some 15 of them.    awaiting ur response, smita.     The Editor wrote:    1) Is open source a permanent change in the software industry, or just  a passing fad?    2) What do the controversies regarding the differences between the open source licenses (GPL, BSD, Artistic, Mozilla, etc) imply for the future of open source?  Are they hampering the movement?    3) Some people say that the proliferation of software patents is going to destroy the open source movement.  Is this true?    4) Is it possible to earn a living by writing open source software?    Go to www.opensource.org, www.cosource.com and www.sourcexchange.com and look through their web sites.  That may give you some ideas.      Smita responded:     thanks alot for the help. i t gave me some ideas of where to search for my kind of thing. but i need some information about the TESTING  METHODOLIGIES ------like how people test opensource  ----what kind of testing techniques they use---------.    i'll really very glad  if you can send me some more questions like this. smita       The Editor asked:    To suggest techniques, we'd need to know what the goal is.  Why would people be testing open-source software?  What would they be looking for? Bugs?  How well the program functions compared to a similar closed- source program?    Open-source programs are usually tested by their developers and some of their users --- in other words, by the people who need the programs to function correctly.  There is frequently some kind of informal organization of volunteers which accepts bug reports and ensures they are followed up on.    Organizations such as Linux distributions that don't write a lot of software themselves but instead repackage other people's software, will also do their own testing, to ensure the program conforms to the standard the distribution has set for all their packages.  For instance, the Debian distribution follows the Linux Filesystem Standard, which specifies that configuration and data files and belong in certain directories.  The distribution maintainers may modify the program slightly to make it confirm to this rule, then test it to ensure it does.  The distribution receives bug reports both about its own errors (which it fixes itself) and errors regarding the program's internals (which it forwards to the program's own development team).    Is this the kind of testing you're talking about?  If so, your best bet would be to talk with developers of open-source programs.  They can tell you how their particular programs are tested, which should  give you an idea how open-source programs in general are tested.     Smita responded:    I'm doing a general research on survey of testing techniques used in open source.For that thing i need a questionnaire.i need to send these questionnaire to 200 developers and then analyze their their feedback.For example one question might be ""When do  you consider testing to be complete?"".My advisor told me that developers will feel comfirtable if they are to answer multiple choice questions so now hope i made my need clear. can you please help me now.    i'll be glad if u could send me some questions and some mail addresses of developers who are using linux to develop their applications.  I need some 15 of them.               Thu, 28 Oct 1999 16:00:33 +0530  From: Neelu Gora < ng@aitpl.stpn.soft.net>   Subject: LINUX-Display Driver help    Hello,    I have Linux 5 (SUSE) installed on my PC at home. When I try to start xwindows , it gives error message for the missing XFree86 display driver. I have been trying to find the suitable display driver on the net, but could not find it.    Display chip type is SIS 6215crev21. Could you please tell me from where can I get it ?    Thanks, Neelu.                 Thu, 28 Oct 1999 14:54:48 +0100  From: Network Desktop User < G.F.Wood@shu.ac.uk>   Subject: Linneighbourhood    Hi,     sorry to bother you with inconsequential mail but I think you of all people should know this !! I'm looking for some software called  Linneighbourhood. It's a network neighbourhood browser for Linux.  I have scoured the net for it but to no avail !!  Can you help??     Thanks     G Wood - UK     [I haven't heard of it.  UNIX traditionally has not had ""Network  Neighborhood"" type of software.  The user is expected to know by other  means (e.g. a list) which servers are available and what their domain  names are.  There may be third-party products which do this, but I'm  not familiar with them.  -Ed.]                  Thu, 28 Oct 1999 17:15:32 +0200 (CEST)  From: =?iso-8859-1?q?jonathan=20sainthuile?= < sainthuile@yahoo.fr>   Subject: informaton linux    bonjour,    Je me presente, Mon nom est Jonathan je suis lyceen(17 ans)et je suis fou de l'informatique.     D'apres une information sur internet j'ai cru comprendre que votre site (""linuxgazette"") offrait la possibilite, de recevoir par E-mail les nouveautees du systeme d'exploitation LINUX.      Je suis moi-mme futur ""linuxien"" et je suis avourais-je encore neophite en ce concerne Linux.  J'aurai aime, si cela vous est possible, recevoir des information au sujet du language, de la difference avec Windows, des probleme a eviter...     Je vous remercie d'avance pour votre reponse et vous souhaite une bonne continuation                                      Sainthuile Jonathan              Thu, 28 Oct 1999 17:15:32 +0200 (CEST)  From: thandor < thandor@cin.net>   Subject: Terminal Emulators    I have a linux shell from my Win98 machine via a terminal login.  I am presently using telnet to do this, however this causes profound graphical errors, no color, and other problems.  I am looking for a better terminal.  Any suggestions?    Thanks  Thandor               Thu, 28 Oct 1999 17:15:32 +0200 (CEST)  From:  < Vikrantj@niit.com>   Subject: linux clickability in windows NT Domain    I have a linux red hat 5.2 running machine an windows NT 4 domain. Now the machine is completely on the network and it is visible in the network neighbourhood of other window 95, NT computers but when I click on the linux machine it says ""network path not found"". Now if I search for the machine by using its IP address then it click on the searched IP address the machine icon opens up allowing me to browse the shares. Actually after making the necessary changes to the smb.conf file when I gave the   smbpasswd -j DOM -r DOMPDC     command (DOM stands for my domain and DOMPDC stands for my pdc netbios name), it gave an error and did not allowed me to join the domain.    What could be the reason, if anyone can help?                  General Mail              Fri, 24 Sep 1999 22:38:11 -0600 (MDT)  From: Phil Hughes < phil@ssc.com>   Subject: Microsoft demonstrates Caldera (humorous)    I talked to Jay Green at the Seattle Times about the Microsoft Linux web page.  He felt, as I did, that Microsoft just doesn't know how to ""control"" Linux because they can't just buy it.    He pointed me to a web page on the Microsoft trial.  He was at the particular event I am including below.  He said it was the best commercial he had heard for Linux in general and specifically Caldera Linux.  The guy presenting works for Microsoft.     (From   microsoft.com/presspass/trial/transcripts/jan99/01-25-pm.htm )        ""HELLO.  MY NAME IS VINOD VALLOPPIL, AND I'M A PROGRAM MANAGER IN THE PERSONA AND BUSINESS SYSTEMS GROUP AT MICROSOFT.  THIS IS A DEMONSTRATION OF THE CALDERA OPENLINUX OPERATING SYSTEM, A NON-MICROSOFT OPERATING SYSTEM FOR PERSONAL COMPUTERS.  THE DEMONSTRATION WILL SHOW THAT CALDERA'S OPERATING SYSTEM PROVIDES EFFECTIVE FUNCTIONALITY FOR TYPICAL END USERS.        I HAVE INSTALLED A COPY OF CALDERA'S OPERATING SYSTEM ON THIS STANDARD PERSONAL COMPUTER AND ACCEPTED ALL DEFAULT SETTINGS A WELL AS INSTALLED A SET OF END-USER APPLICATIONS BUNDLED WITH CALDERA'S OPERATING SYSTEM.        I'M CURRENTLY DEMONSTRATING CALDERA'S OPERATING SYSTEMS' GRAPHICAL USER INTERFACE.  THE GRAPHICAL USER INTERFACE, OR GUI FOR SHORT, AS PROVIDED BY CALDERA TO INSURE THAT THE OPERATING SYSTEM IS EASY TO USE AND IS COMPETITIVE WITH MICROSOFT'S WINDOWS OFFERING.        A QUICK TOUR OF THE SCREEN DEMONSTRATES THAT IN MANY RESPECTS, CALDERA'S OPERATING SYSTEM LOOKS JUST LIKE MICROSOFT WINDOWS.  CALDERA'S OPERATING SYSTEM HAD A START MENU AT THE BOTTOM OF THE SCREEN LISTING INSTALLED PROGRAMS AND MAKING IT VERY EASY TO SELECT AND RUN THESE PROGRAMS; A TASK BAR AT THE TOP OF THE SCREEN LISTING PROGRAMS THAT ARE CURRENTLY RUNNING ON THE COMPUTER; AND FINALLY, AN ARRAY OF ICONS ON THE UPPER LEFT PORTION OF THE SCREEN PROVIDING USERS A QUICK WAY TO RUN PROGRAMS OR ACCESS INFORMATION ON THEIR HARD DISK.        LIKE MICROSOFT WINDOWS, CALDERA'S OPERATING SYSTEM PROVIDES A SERIES OF ACCESSORY APPLICATIONS FOR CONSUMERS' DAILY ACTIVITIES SUCH AS EDITING DOCUMENTS AND WRITING E-MAIL.  FOR EXAMPLE, I WILL EDIT A QUICK DOCUMENT, TYPIN `THIS IS A TEST.'        I WILL ALSO CREATE A QUICK SAMPLE E-MAIL MESSAGE.        CALDERA'S OPERATING SYSTEM HAS A GROWING LIST OF THIRD-PARTY APPLICATION SUPPORT AND CORPORATE BACKING, INCLUDING, BUT NOT LIMITED TO, COMPANIES SUCH AS NETSCAPE, INTEL, ORACLE, SUN, AND IBM.        IN ORDER TO CREATE A MORE COMPETITIVE OFFERING TO WINDOWS, CALDERA'S OPENLINUX OPERATING SYSTEM, IN PARTICULAR, BUNDLES A NUMBER OF THESE THIRD-PARTY PROGRAMS.        A CRITICAL CLASS OF APPLICATIONS WHICH ARE VERY POPULAR WITH CUSTOMERS IS THE OFFICE PRODUCTIVITY SUITE.  MICROSOFT'S OFFERING IN THIS CATEGORY IS MICROSOFT OFFICE.  OTHER COMPETITORS TO MICROSOFT OFFICE WHO BUILD ON THE WINDOWS PLATFORM INCLUDE COREL, IBM, AND STAR DIVISION OF GERMANY.        CALDERA'S BUNDLES STAR DIVISION'S PRODUCTIVITY SUITE WITH THEIR OPERATING SYSTEM. IN THIS CASE, I HAVE STAR OFFICE FOR CALDERA'S OPERATING SYSTEM ON SCREEN.  LIKE MICROSOFT'S POPULAR OFFICE SUITE, STAR OFFICE PROVIDES AN INTEGRATED SUITE OF APPLICATIONS INCLUDING WOR PROCESSING LIKE MICROSOFT WORD, A SPREADSHEET PROGRAM LIKE MICROSOFT EXCEL, AND A PRESENTATION GRAPHICS PROGRAM LIKE MICROSOFT'S POWERPOINT.        STAR OFFICES'S APPLICATIONS IN THIS CATEGORY NOT ONLY PROVIDE FULL-FEATURED PRODUCTS, BUT THEY'RE ALSO INTEROPERABLE WITH POPULAR WINDOWS PRODUCTS.  FOR EXAMPLE, I WILL NOW IMPORT A RICHLY FORMATTED DOCUMENT CREATED IN MICROSOFT WORD INTO STAR OFFICE RUNNING ON CALDERA'S OPERATING SYSTEM.  NOTICE THAT NOT ONLY THE TEXT OF THE DOCUMENT WAS ABLE TO BE IMPORTED INTO STAR OFFICE, BUT ALSO FEATURES SUCH AS RICHLY FORMATTED SECTION HEADINGS--IN THIS CASE, THE BLUE BOLD-FACED TEXT WITH THE LINE ABOVE IT--AND EMBEDDED GRAPHICS, THE CIRCLE WITH THE WORD ""PRINTER"" INSIDE OF IT.        LIKE CALDERA'S GRAPHICAL INTERFACE, STAR OFFICE ALSO BENEFITS STRONGLY FROM CUSTOMERS' EXPERIENCE WITH MICROSOFT PRODUCTS.  THE STAR OFFICE PROGRAMS HAVE BEEN DESIGNED TO LOOK LIKE, AND WORK LIKE, MICROSOFT OFFICE.  AS JUST ONE EXAMPLE, DOCUMENT FORMATTING FEATURES SUCH AS BOLD-FACE TYPE, UNDERLINE TYPE, AND ITALICS ARE QUICKLY AND EASILY AVAILABLE TO THE END USER WITH JUST A SINGLE MOUSE CLICK ON BUTTONS THAT LOO VERY MUCH LIKE AND ARE LOCATED ON A TOOLBAR JUST LIKE THE BUTTONS THAT PROVIDE THESE FEATURES IN        IN SUMMARY, I HAVE DEMONSTRATED THAT CALDERA'S OPERATING SYSTEM IS:  FIRST, POWERFUL AND EASY TO USE; SECOND, THAT THERE ARE SIGNIFICANT THIRD-PARTY SUPPORT IN BOTH SOFTWARE AND HARDWARE COMPANIES; AND FINALLY, THAT CALDERA'S PRODUCT BUNDLES A STRONG OFFICE PRODUCTIVITY SUITE FROM STAR DIVISION WHICH IS NOT ONLY INTEROPERABLE WITH MICROSOFT PRODUCTS, BUT IS ALSO DESIGNED TO WORK AND LOOK LIKE MICROSOFT PRODUCTS SO THAT USERS OF THESE PRODUCTS WILL BE COMFORTABLE AND PRODUCTIVE USING THESE PROGRAMS.        THIS CONCLUDES THE DEMONSTRATION OF CALDERA OPENLINUX OPERATING SYSTEM VERSION 1.3.""   --  just fyl               Fri, 24 Sep 1999 22:38:11 -0600 (MDT)  From: s. keeling < keeling@spots.ab.ca>   Subject: http://www.linuxgazette.com/index.html    Yes, I have a comment.    YOU IDIOT!  Sorry, don't take it personally; it's just a figure of speech.    I'm at the url listed in the subject.  I'm supposedly at the cover page of the latest issue.  What do I do now?  Where the @#$%^&* is the ""Next Page"" button.  How do I turn the page on your so-called Gazette?    Oh, maybe you have to hit the ""Back"" button to get to the page where you can select the next page ...  Well that's stupid!!?!?!?    Sorry, it had to be said.  Rant off.  Sorry if I offend.  I'll go look at content now, thanks.      [There is a single Front Page that is shared by all the issues.   That is why it doesn't have an issue-specific ""next page""   button.  It is a bit confusing, but it has been that way since   long before I started editing the Gazette, and we haven't   received any other complaints about it.  -Ed.]                  Sun, 26 Sep 1999 12:14:59 +0000  From: Benjamin Smith < bens@saber.net>   Subject: Letter format extension?    OK, you're over-worked, underpaid, and would probably find yourself split a thousand ways from Sunday if you actually tried to implement 1/100th of the suggestions you get.    That said, I have another one for you.    The letters column would be, IMHO, easier to read if there were talk-backs after each letter, or that could be easily linked to, so that suggestions for solving a problem can be perused before making my own.    More like a newsgroup, or the talk-backs at the end of /. articles.    -Ben                       (""`-''-/"").___..--''""`-._    (Simba)                     `@_ @  )    `-.  (        ).`-.__.`)                     (_Y_.)'  ._    )  `._ `. ``-..-'                 _..`--'_..-_/  /--'_.' ,'               ((().-''  ((().'  (((.-'        Benjamin Smith       [The problem is, Slashdot is read only at one web site, whereas the  Gazette is also read from mirrors, mirrors of mirrors, CDs, etc.  Thus,  the only common denominator is standard HTML.  No CGI scripts, no  databases, no Javascript.  The current Mailbag + 2-Cent Tips system  seems to be the best way to ensure that everybody can read all the  responses.     An indexing system to link letters and responses would be nice.  Heather has already implemented an index for the most frequent Answer  Guy questions.  If somebody has an idea how to do something like that  for the Mailbag letters, we can consider it.  However, sorting the  letters into subjects and putting in direct links to each letter in the  back issues would be a  lot  of work.     We are looking at ways to improve the  Gazette  and make it  easier to navigate, but only in ways that won't leave a portion of  our readership out.     In the meantime, to find help with a problem, use the Answer Guy  index, the Index of All Issues (linked at the bottom of the issues list  on the Front Page), and the search engine linked in the middle of the  Front Page.     P.S. Nice tiger. -Ed.]                    Tue, 28 Sep 1999 11:37:09 -0600  From: Dale Offret Jr. < doffret@silverstar.com>   Subject: Spanish Translations    Dear sir or madam,    In reading the October issue of the Gazette I got side tracked into the mirrors site and the French translation sites.  I looked for Spanish translations and didn't find any.    My question is anyone currently developing a Spanish site? If so, who?  If not, what criteria need to be met for someone to offer a translated issue?    Background:    I am a college graduated with an associates degree in Information Systems. I have avidly read the Gazette for the last 2 to 3 years.  I am not a native Hispanic, but my grandfather was born in Mexico.  From Dec. 1992 to Dec. 1994 I served as a church representative to Costa Rica in Central America where I learned a great deal of Spanish.  I also took 3 years in high school.    I am looking for ways to improve my Spanish and I believe this could help me.    Thank you for your time.  Sincerely,  Dale Offret Jr.     [There are no Spanish translations I know of.     There are no criteria requirements.  If you do a translation, we  will gladly put a link to it on the  mirrors  page .     You may wish to work together with one or more of the Linux Users  groups in the Spanish-speaking countries.  Perhaps you could arrange a  deal with them where you would translate the articles and have a native  proofread them.  There is a directory of users groups at   www.linuxjournal.com/glue ,  ""Users Groups (GLUE)"".  -Ed.]                  Mon, 4 Oct 1999 07:24:21 +0800  From: u < leeway@kali.com.cn>   Subject: redhat in pirated China    Although legitimate software vendors sell Linux in China, the price is much higher than that of pirated CD-ROM vendors. These vendors are major source of software for Chinese. (Yes piracy rate is very high.) They play cat-mouse game with the government agency. No matter it is Win98, NT, VC or freeware, the price is the same: 10 yuan or 1.2 US$ each CD.    Because of the underground nature of these vendors, they dishonestly label the CD-ROMs. Here redhat is dominant in Linux category. In fact the makers are so preoccupied with redhat that they describe FreeBSD as ""in a redhat series"". Although the new redhat version is 6.0, they have 6.5. I don't care because the ""6.5"" CD is an authentic 6.0. And I understand why they label them that way: they have already sold ""6.0"", ""5.5"" redhat CD, which actually are variations of 5.1 or 5.2. One ""5.5"" redhat CD description proudly claims that it is ""completely cracked"". I do notice that 5.2 installer select some Chinese tools by default. But I am very unhappy because Netscape can't run. I realize much later that the file size is incorrect although it could be installed. Recently ""6.51"" has come to the shelf. It has 2 CDs. The 2nd one has StarOffice, Oracle and DB2. I wonder when RedHat could make a official presence here. But would that help? The official redhat CD is 50 US$. It can't beat 1.2 US$.                      Wed, 06 Oct 1999 01:14:22 +0200  From: David Fauthoux < david.fauthoux@free.fr>   Subject: Merci    A little mail to say you that your work is EXCELLENT ! My article has a very very good traduction ! (I thank Jason Kroll) Your gazette is clear, interesting and very well managed.    In french : Bravo !    I hope I will be able to send you another article to join your great work !    Thanks again,  David     [David was the author of the   Bomb ô Bomb  article in issue 46.  -Ed.]                      Wed, 13 Oct 1999 17:27:57 -0400  From: Dan Dippold < dann@mich.com>   Subject: comments, criticisms, suggestions and ideas.    Search... ?    How Mr. Coldiron is going to replace his desktop OS  with Linux as he uses Visual Basic on it and Access (""he has some ideas, more on that in a later issue"" he says) is what I *would* search for.                Thu, 21 Oct 1999 21:40:57 -0700  From: Ron Tarrant < rtarrant@northcom.net>   Subject: A Suggestion    Hi there!  I read your magazine and I think it's great. I've picked up quite a few tips from the Answer Guy and I really like his column. But...    I'd really like to see a separate index page for the Answer Guy with links to all his stuff in all the issues organized by subject. It would make it a lot easier to find articles on specific topics. Heck, it might even make an interesting book when enough information has been gathered.  If you would consider this, I'd be most grateful. Thanks for a great magazine!     [Heather Stern's time machine was busy this month (to borrow a phrase  from the Python newsgroup), and she has already implemented the Subject  Index you seek,  See the Answer Guy column in this issue.  -Ed.]                 Mon, 25 Oct 1999 15:44:04 +0530  From: balaviyer < n1040233@bom7.vsnl.net.in>   Subject: regarding subscription    Dear sir,    I want 2 subscribe this new group. How do I go about it.     [This is not a mailing list, so there's nothing to subscribe to.  What  you see at  www.linuxgazette.com   is what we do.  -Ed.]                 Thu, 30 Sep 1999 12:14:59 -0400  From:  Barry < barry.thoms@ms.rc.gc.ca>   Subject: Gazette    I am brand new to the Linux world so this may be a stupid question.    Why do all of the past issue links for the Linux Gazette goto RedHat and not the issue?    regards  Barry     [The links at    www.linuxgazette.com  don't  do this.  If you find a mirror site that's messed up or way out of date,  please e-mail  gazette@ssc.com  with  the URL of the site, and I'll try to figure out what's wrong.  -Ed.]                 Thu, 23 Sep 1999 17:03:29 +0100  From: Andrew Bryant < andrew@brilyant.demon.co.uk>   Subject: Gazette issue 44 AND Netscape    Hi,    Could you tell me a reason why Netscape 4.06 suffers indigestion when I ask it to browse my downloaded copy of the HTML version of LG 44?    The system is a 486 with 32Mb RAM, running RedHat 5.1 with a 2.0.35 kernel. Netscape reads 34% of the file, then stops.The Netscape process (I should say processes, because there seem to be two) still occupies memory, but no longer consumes clock cycles according to top.  Nothing on the page responds to mouse or keyboard, and the page doesn't re-draw if you drag another window across it.    There is still plenty of swap space available - is it possible that Netscape doesn't ""know"" how to use it?    Issues 43 & 45 behave themselves.  A rational explanation would be welcome, and a cure even more so!   I have studied the offerings of the Netscape site, but nothing I read there seems quite to fit these symptoms.                Sat, 02 Oct 1999 23:58:57 -0600  From: Doug Dahl < dougdahl@incentre.net>   Subject: Magazine cut-off    Dear sir,     I use Redhat 5.1 with Netscape 4.05 (or4.02? whatever the default is) and I have the same problem mentioned in your recent edition of having the full page HTML load only about half on your Linux Gazette home page. In a test of this issue I only got about to the ""Linux and the future"" article by Husain Al-Mohssen about to the middle of the second paragraph with a file size of roughly 299535. Lately I have taken to reading the gzipped text files especially as I can read them offline but thought I would mention this problem since apparently someone else has this problem.     As to the size I was routinely able to read transcripts of the MS-DOJ depositions up to about 400KB with no problems (except those apparently on their end and not related to size at all)    Sincerely,    Doug Dahl     [I don't know why some people's files are getting cut off halfway.  Any idea?  -Ed.]                  Thu, 7 Oct 1999 16:55:51 -0700  From: John Cockerham < jcocker@silverlink.net>   Subject: Linux Is Not For You    Bravo to Mr. Nod for his article   Linux Is Not For You  in issue 46. I too am going through the growing pains of using LINUX for the first time.  My cousin, a big time UNIX systems engineer, wants me to do a little project for him.  He has an accounting program written in DBaseIII that he wants ported to PostgreSQL.  This sounds feasible, and I should have the requisite knowledge since I earn a living as a SQL Server and Oracle DBA and an NT systems administrator.  A database is a database and SQL is mostly SQL.  How hard could it be?    I added a third computer to my home NT network and attempted to install LINUX.  The installation may have been successful, I will never know because when faced with the dot prompt, I didn't know what to do.  None of the DOS commands or even the old RTE commands I could think of would work, so I turned it off.  My cousin took the machine to his house and got it running on his network.  He even put a little 'red hat' sticker on it. He tried to explain why it was necessary to set up a partition for the kernel and a partition for the swap file and a working partition and so on and then handed me a book about the size of a Manhattan phone directory that was supposed to explain everything.  I stuck the computer on my home network and fired it up.    It promptly froze up.  Since I couldn't get it to do anything, I turned it off.  ""Worst thing you could do"" he told me when I called the next day when it wouldn't boot up.    I installed another release of Red Hat 6 I had ordered from an online auction.  It installed immediately and to my great joy even had a desktop-like interface complete with a start button.  This looks great, but I still can't make it do much.  At least the mouse works.  The next weekend he visited my house, and got the computer to see the network.  Even he was not willing to try and get the printer to work over the network, and instead brought a nice HP print sharing device.  I asked about installing PostgreSQL and he assured me it was easy.  ""Just mount the CD and install the RPMs"" he tells me.  RIGHT!    LINUX People, I am really trying hard, but I agree with nod.  LINUX is NOT user friendly.  Now I know all of you true believers are thinking ""What a Wimp, you should have seen how hard it was back at release 2"".  I do know that I could have taken a brand new computer virgin and had them somewhat productive in an NT-SQL Server environment in the time I have spent just trying to learn to copy a file and mount a drive.  I still have not been able to start with my conversion project since I don't have a database I can talk to yet.  I realize that if I had been brought up in a UNIX environment, this stuff would be second nature by now, but I wasn't.  I still haven't had the nerve to shut the damn computer down again, because I hate to have my cousin make the hour drive over to get it started again.    I am going to keep working at it, but right now I think the motto ""You get what you pay for"" is true.      [Thanks for your letter.  It was exceptionally well written.     Those of us who are tekkies need to keep in contact with people who  are new at Linux, in order to get it to the point of being  user-friendly.  But we also tend to believe that the more you puts into  learning how your OS works (any OS), the more you will get out of it.     #BEGIN ""rant"" {   MS and some other OS companies unfortunately does not encourage people  to do this.  In fact, they actively discourage it.  Both at a marketing  level (""You don't need to know anything about this computer; just plug  it in and it will work."" [which is of course a big lie for any OS]; ""You  don't need special training to become an NT administrator, unlike  UNIX.""), and at a technical level (it's hard to tell what Windows is  doing behind the scenes when it boots, or why it crashed, and what to do  if those configuration dialogs don't have the options you need), and  also at the legal level (""Reverse-engineer this and we'll sue you."")  This may be fine for an embedded appliance, but it seriously limits  one's ability to use one's computer at its potential, or to fix it  yourself if it goes bust.     My dad always used to say, ""Why can't a computer be like a car?  All  cars have a steering wheel that works the same, ditto for the clutch and  gearshift.""  The trouble is, we only ask a car to do one thing: go  somewhere.  Running the myriad of applications we expect from a computer  is a whole different ballgame.  Plus, the computer industry isn't nearly  mature enough to come to the level of standardization that cars have.  Macs have a different keyboard and user interface than PCs because  somebody though it would ""work better"".  There is not enough agreement  on what the ideal user interface should be.   } END ""rant"".       Now I know all of you true believers are thinking ""What a Wimp,   you should have seen how hard it was back at release 2"".          There will always be people like that.       I realize that if I had been brought up in a UNIX environment,   this stuff would be second nature by now, but I wasn't.        #BEGIN ""personal opinion"" {   I started using UNIX in 1990, through a shell account at an ISP I got  specifically to learn UNIX on.  I'm very, very glad I did.  It is the  standard, the common denominator linking all other parts of computerdom,  not in the least because it's the only OS available from more than one  company.   } END ""personal opinion"".                  Wed, 27 Oct 1999 16:31:58 -0700  From: Arnaud    alnoken@mail.dotcom.fr  < alnoken@mail.dotcom.fr>   Subject: Linux is not for you        Dear nod,          Ouch ! Harsh blow ...            I have just read that article you wrote in Linux Gazette    (issue 46 - '1999/10) about Linux.            So, let me introduce myself as well.    I am technically a Linux/Unix technical-savvy ; by business need, a    buggy-Windows user. And i very much dislike what you wrote, except for    one single thing : this is just true. You really insulted the Linux    community, but just by speaking common sense.          Linux developpers tend to think that a sane product is enough. But it    is like food. You can spend time preparing a good and sane traditional    european or asian (say french or japanese) meal, and take your time to    savour it. Or you just can go to those unsane, too fat, pre-digested    tasteless (say McDo or 'fish and chips') fastfood. Everybody knows    what is good for one's health. But everyone runs into the place where    you can fill up your belly instantly.  Same is true for using    computer. Microsoft sells shit. But more people can use it nearly    right-out-of-the-box. Linux guys make things that work, while    Microsoft sells stuff that is somewhat usable. You are right when you    tell that Linux guys should study the other camp's strengthes and    weaknesses.             Nevertheless, you are wrong when you say that Windows is    slower than Linux. This may be true in your example, but Linux does    not spend so much time managing an intuitive interface. Stability    always have a performance penalty. Having Windows much stabler would    make it much slower, because that would mean the OS spend some time    monitoring itself, preventing its own crashes by auto-repairing at    run-time, like those big companies' giant mainframe computers (or    phone ompanies switches) do (Alcatel switches' OS can spend up to 65%    of their time preventing a crash, because if this happens, that could    stop thousands of active communications, and guess why MVS is as big    as NT 4.0 with just a tiny subset of its functionnality, no graphical;    interface, ...).             Yet, globally, you expressed what i have been thinking for    some years now : Unix or Linux are bound to disappear if they just    concentrate on their strengthes, and do not try at the same time to    outperform Microsoft's skills. Something that can be done. NeXTStep,    eight years ago was superior to what Windows95 was seven years later.    But NeXT was a small company in a market already overwhelmed with Bill    Gates financial power. A commercial newcomer could not breathe in such    rarefied market. Free software can. If free software does not really    try to compete, then some Japanese commercial corporation are the only    ones that can fight Microsoft. Sega, Nintendo and Sony have begun    development that will turn their play console into consoles that will    actually marginally be used to play. Thoses devices will be build    around the Net, so they will manage documents. Then, what else all    their computing power could be used for, apart for creating, editing,    those, managing your mail, calendar and contacts ? And those    corporation do know how to make consumer products. Even Windows is not    such a product, because you yourself stated that people needed your    help to sort out the mess that sometimes occur.             Their was the huge stable mainframes, then lighter    minicomputers, then microcomputers. All professional-world-rooted    devices. Microsoft pushes the enveloppe against those with Windows2000    (formally NT), a product that explodes in market shares. But next is    everybody's information device. This is the consumer market. The one    that counts. Microsoft is already here with WindowsCE, but prepares    the true attack with its yet- to-come XStation (a Microsoft machine    !). The competitors are rare : three Japanese ... and no one else.           Where is Linux ? Linux claims for World domination. World    domination means dominating both markets : the end-user device and the    remaining of the infrastructure. As history tells, dominating the    end-device helps dominating the rest of the infrastucture, just    because it makes so many more people mastering the technology (even if    it is comparatively less limited in terms of functionality), and then    so much more skilled technicians on the job market. Only exceptions    are surviving old dinosaurus IBM and certainly Microsoft in the    future. Unix mini-systems greatly reduced the mainframes number by    infiltering them credibly through Amdahl mainframes, and relegating    them to niche markets (namely big corporations' strategic central data    centers). Windows has come the same way from all those desktops, and    now making its way into the infrastructure markets (servers,    superservers, routers, datamarts, etc.), restricting Unix to niche    markets itself (scientific calculators, and high-end database servers)    and FreeBSD and Linux to their proof-of-concept market (mainkly    Internet servers and firewalls in corporations that are big enough to    justify the hiring of Linux-knowlegeable people). So now you see why    Microsoft has invested less money in Windows during the last three or    four years than it invested in WindowsCE,  interactive TV, now in play    consoles, and more generally around consumer markets. You also see why    Sega, Nintendo and Sony are to be looked at. Their products are to    this date poor in terms of information features, but they are    extremely powerful in processing power, and designed from the very    first line to be bug-free.          If Linux wants to count in the future, the Linux community must take    this into account : not look at what already exists or is advertised    by Bill Gates, but anticipate what is next.      Remember the car industry. First there was those who designed    their own car from scratch, starting in France,around the end of    XVIIth century (as computer OS pioneers did). Then, end of XIXth    century, those who build their cars from standard pieces, but had to    turn dozens switches on (the fuel valve, the battery, the generator,    the contactor), and then turn vigourously the to start it (as    mainframe/Unix/Linux users do), then those who bought partially    assembled car kits, with pieces bought from several providers (as    Windows users do). Then there were the ones who bought cars you just    had to climb into and turn on the key to use them, because Ford    brought that in the first quarter of the century. The latter category    now accounts for, say, 99.9 % of car-buyers.             I guess one day, you will buy your computer, turn it on, feed    it with your name, e-mail address, ISP number (or transfering them in    a one-keystroke operation from your old machine along with your diary,    address book, documents), and start using it, without having to deal    with LILO, sendmail, PPP account, and others' idiosyncrases. That day    is just around the corner. With or Without Linux.             Is the community at work making Linux ready ? Or will we    satisfy ourselves with Linux remaining in its getting-surrounded    computer techies niche ?                        This page written and maintained by the Editor of the  Linux Gazette ,  gazette@ssc.com   Copyright © 1999, Specialized Systems Consultants, Inc.   Published in Issue 47 of  Linux Gazette , November 1999       ""Linux Gazette... making Linux just a little more fun! ""              Contents:     Distro News   News in General   Software Announcements                   News submissions should be sent to   gazette@ssc.com  in  TEXT  format.  Not HTML, DOC, RTF, etc., please.  Instead of a press release, please send a two-paragraph summary of why Linux users would be interested in your product or service, along with a link to your web site.               November 1999  Linux Journal         The November issue of  Linux Journal  will be hitting the newsstands in mid-October. This issue focuses on databases, and includes an interview with Linus, the ""mild-mannered programmer, defender of free source, and all-around nice guy"", as well as pictures of Linux's creator.     Linux Journal  now has articles that appear ""Strictly On-Line"". Check out the Table of Contents at   http://www.linuxjournal.com/issue67/index.html  for articles in  this issue as well as links to the on-line articles.  To subscribe to  Linux Journal , go to   http://www.linuxjournal.com/subscribe/ljsubsorder.html .       For Subcribers Only :  Linux Journal  archives are now available  on-line at  http://interactive.linuxjournal.com/        Flash!    Can't find that April 1996  Linux Journal ? Someone borrowed the September 1998 copy?    Now you can have it all!  All of  Linux Journal  (issues 1-56; 1994-1998) and all of  Linux Gazette  (issues 1-45; 1995-1998) on one archival CD.    Ordering info in the next Gazette.            Distro News   This is a new section featuring news about Linux distributions.              Red Hat announces Red Hat Linux 6.1         DURHAM, N.C.--October 4, 1999-- Red Hat , Inc. today announced the release of a suite of Official Red Hat Linux 6.1 products. The latest release incorporates easy installation, software update information and access, and improved system management capabilities.  Users can move quickly through installation with graphic-based directions, choosing from GNOME, KDE, server or custom interface settings, with seamless integration of software RAID configurations to safeguard critical data and application availability.  Additionally, the PXE 2.0 technology (part of the Wired for Management Baseline 2.0) enables Red Hat Linux 6.1 installations to be done across the network, with no need for local media.    Red Hat Linux 6.1 also provides customers with fast access to the latest software technology from Red Hat through the Red Hat Update Agent, an online customer service application for retrieval and management of software updates.                   Linux-Mandrake ""Cooker"" (development version)          Linux Mandrake is proud to announce the availability of its new development version code-named ""Cooker"". What sets the distribution apart from previous versions is that Linux Mandrake has now adopted a new open style of development that allows real-time updating of the distribution based on the contribution of both it's dedicated staff and the user base.     Linux Mandrake Cooker is aimed at the following audiences:      Users who want to stay on the cutting edge with a distribution that is updated daily.     Users who want an easier way to upgrade their existing software.     Developers who want to contribute to the development and direction of Linux Mandrake.      Cooker is now available online at:  www.linux-mandrake.com/cooker  or on CD.                  Storm Linux Beta Released         Vancouver, Canada  -- October 25, 1999 --   Stormix Technologies  announces the official beta version of Storm Linux. The final release is scheduled for November 1999.    ""What we learned from the alpha,"" says Bruce Byfield, Product Manager for Stormix Technologies, ""is that users want a Linux install that's easy but not dumbed down.    ""For example, in the alpha, users were forced to install the Linux Loader and could only do so on the master boot record. However, alpha testers told us very clearly that they wanted more flexibility. So, in the beta, we've given it to them. At the same time, new users can simply accept the defaults and quickly get a workable system. We've tried to balance flexibility and ease of use all down the line.""    Another major feature of the Storm Linux is the Storm Hardware System. SHS automatically detects PCI devices, including video and network cards, SCSI devices, and USB bridges.    ""The information collected during alpha testing,"" Lindsay says, ""has greatly extended our hardware compatibility. As a result, we'll be putting our database on the web, so that users worldwide can request and receive support for their cards. Our goal is to make Storm Linux the most complete Linux hardware solution available.""    Other features of the beta include GUI modules for networking, dialup, and adding users. ""These modules,"" Byfield explains, ""are simply the first glimpse of what Stormix is planning. The final release will include other modules that weren't ready for the beta.""    Copies of the beta are being mailed to registered testers. Copies can also be downloaded from the Stormix web site.    Founded in February 1999, Stormix Technologies is a Linux development Canada based in Vancouver, Canada. Its flagship product is Storm Linux, an enhancement of the Debian GNU/Linux distribution.                    Mandrake/Panoramix         Panoramix is a new installation procedure, allowing easy installation of Linux-Mandrake. It has just been integrated in   Cooker , our experimental distribution. Panoramix is entirely written in Perl which is interface independent, offering contributors an easy and flexible way to contribute. This beta version features the integration of Diskdrake, a complete hard-drive partitioning tool, that offers users a simple graphic tool for completing the painful partitioning phase while installing Linux.                   Debian computers available in UK         Space-Time Systems is currently offering three PC models with Debian 2.1 (Slink) pre-installed.  STS actively supports Free Software and the development of GNU/Linux by donating 3% of the retail cost of each system sold, split equally between the Free Software Foundation and Software in the Public Interest, Inc.    All systems are supplied with A Beginner's Guide to Using GNU/Linux help-sheet, GNU/Linux software on CD's, plus a boot floppy. All GNU/Linux systems are ready for use, with the X server and a Graphical User Interface (GUI) already configured.    www.spacetimesystems.dial.pipex.com/ .                  Red Hat Expands Board of Directors, Strengthens Development Group         Durham, N.C.--October 12, 1999--Red Hat, Inc., today announced that Kevin Harvey, General Partner of Benchmark, has joined the Red Hat Board of Directors and Walter McCormack has joined the company as head of Corporate Development.    Harvey brings more than 15 years of emerging technology company experience and vast knowledge of the computer industry to Red Hat. McCormack brings a strong background in investing, advisory and financing services to Red Hat.                  Other distribution news        Caldera         Fujitsu Ltd. to offer OpenLinux in its servers      Debian            Commercial support from VA Linux Systems, O'Reilly Associates and SGI, Inc...   Debian will be sold in major retail stores for $19.95, including a book and a demo CD of Loki's ""Myth II: Soulblighter"" game.  The book will also be freely available online.       Expert Linux        SuperAnt 's Expert Linux CD has a live Linux filesystem that can be used without hard disks.  Includes kernel 2.2.12 and KDE.  It can also be used as a rescue disk.  Boot Linux from the CD if your BIOS supports it, or from the MS-DOS prompt.     Peanut Linux        Reviewed  in  The Linux Bits #20.      Red Hat        Intel will bundle  RH with Intel's server platforms the company markets through its recently created Internet Service Provider program.     Comaq to provide call center support for enterprise users worldwide of the Official Red Hat Linux OS.     Magic Software  Enterprise Server 8.3 (e-commerce and business software) included in Red Hat 6.1.     ORBit Software 's backup solution included in Red Hat 6.1 .       SuSE       SuSE and Siemens AG (Munich) have completed a Linux extension allowing the use of up to four GByte of memory on Intel-based servers.  The patch has been integrated into the Linux 2.3.15 developer's kernel.     TurboLinux          Several key deployment and financial backing deals                   News in General               Linus sees a future full of free operating systems         CNet  article  in which Our Hero discusses what he thinks Open Source will -- and will not -- do for the computer industry.  He discusses the less- successful-than-expected Mozilla project, and disparages Sun Microsystems' use of the term ""open"".    Thanks to    The Linux Bits #20  for bringing this article to our attention.               Upcoming conferences & events        Alternative Linux 1999 November 1-3, 1999 Montreal, Quebec, Canada  www.alternativelinux.com/  (French)  www.alternativelinux.com/en  (English)  USENIX LISA -- The Systems Administration Conference November 7-12, 1999 Seattle, WA  www.usenix.org/events/lisa99   COMDEX Fall / Linux Business Expo November 15-19, 1999 Las Vegas, NV  www.comdex.com/comdex/owa/event_home?v_event_id=289   The Bazaar: ""Where free and open-source software meet the real world"". Presented by EarthWeb. December 14-16, 1999 New York, NY  www.thebazaar.org   SANS 1999 Workshop On Securing Linux. The SANS Institute is a cooperative education and research organization. December 15-16, 1999 San Francisco, CA  www.sans.org                  Magic software has learned a lesson about penguins          Magic Software   announced that it has made a $10,000 donation to the Wildlife Conservation Society for the preservation of penguins.  In addition, the Company stated it will no longer use live penguins to promote its Linux products.  Magic created quite a ""flap"" recently when it usedtwo live penguins at the LinuxWorld Expo in San Jose to introduce its new business-to-business e-commerce solution, Magic eMerchant for Linux, for this rapidly growing operating system whose symbol is a penguin.    The controversy started last August when Magic brought two live trained penguins, named Jeffrey and Lucinda, to the San Jose Convention Center to open the trade show floor, as well as introduce each of the Companys hourly demonstrations of its new eMerchant  product.  For five minutes at the start of every hour, the birds trainers would allow people around the booth to take pictures of one of the birds (the birds alternated times in the booth), as well as pet the bird.  This ""ruffled the feathers"" of some trade show attendees who later called PETA (People for the Ethical Treatment of Animals) to voice their concerns.                   Netwinder news          OTTAWA, ONTARIO - September 13, 1999 - Rebel.com Inc. announced that it has entered into a technology and distribution agreement with KASAN Electronics Corp., a leading manufacturer and distributor of PC peripherals and electronics. The agreement provides KASAN with exclusive rights to market and distribute the NetWinder OfficeServer throughout the Pacific Rim.    Due to the increased number of Internet users, the Linux thin-server market is expected to grow rapidly in Korea. The Korean government supports the development of Linux OS-based servers, resulting in Linux-based servers being a very affordable alternative for both business (SOHO) and personal usage. It is also estimated that there will be over 100,000 Web hosting operations in Korea by year-end.    ""We are very pleased to be able to handle sales and marketing for the NetWinder in regions like China and Japan,"" said Jay Park, director of marketing and development for KASAN Electronics. ""The thin-server market is one of the most rapidly growing in the network market, we are confident that by adding our expertise and services to the NetWinder we will achieve World leader status within three years.""                  Tri-Centrury Dynamic Development Objects for Java          Wideman, Ark. --  Tri-Century Resource Group, Inc. (TCRGI) announced the immediate availability of Dynamic Data Objects for Java (DDO tm ), a set of Java development tools that allow adjustments to any DDO-based enterprise application with minimum intrusion and testing. A free 30-day DDO demo is available  at   www.tri-century.com .   Development and testing took place on a Red Hat 5.2 system using Java 1.1. and Java 1.2 from   www.blackdown.org .                   Cobalt Networks Announces RaQ 3i Server Appliance          Cobalt Networks , a developer of server appliances, has introduced its third-generation server appliance, the RaQ 3i, today at ISPCON.  The RaQ 3i expands Cobalt's RaQ product line by providing the ideal server appliance for high-traffic Web sites, e-commerce, and application hosting.  Designed with ISPs and small to mid-sized businesses in mind, the RaQ 3i further solidifies Cobalt's reputation for providing server appliances that offer powerful performance, great return on investment and a low total cost of ownership.      ""The new Cobalt RaQ 3i delivers a compelling server appliance platform for Intershop commerce products,"" said Ed Callan, Vice President of Marketing at Intershop. ""Cobalt's customers will now have access to powerful e-commerce solutions based on Intershop's industry leading sell-side e-commerce solutions and the cost-effective, easy-to-manage, and scalable RaQ 3i.  The RaQ 3i with Intershop Hosting and Merchant uniquely deliver e-commerce for ISPs and businesses."" Cobalt designed the RaQ 3i with an open source design and extensible architecture making it easy to integrate, deploy, and support Internet and network-based applications. Cobalt server appliances are pre-configured with the  Linux  operating system and provide the core web publishing, email, and file transfer services upon which ISPs and developers can build their solutions.  The Cobalt RaQ 3i significantly extends the range of available applications for the Cobalt RaQ product line.                   Cobalt Qube/RaQ get Knox Arkeia backup         Burlingame, Calif. - September 1, 1999 - Knox Software and Cobalt Networks  announced today the availability of Arkeia software for Cobalt RaQ  and Qube family of products.  Arkeia provides a comprehensive  solution for ISPs and corporations to protect data.  Its unique  transaction engine allows multiple backups and restores to be performed  simultaneously with total reliability.      Arkeia provides incremental and full backups, scheduled or on demand,  and preserves directory structure, registry, symbolic links and special  attributes. Arkeia utilizes an exclusive multi-flow technology to  deliver speeds that are 200 to 300 percent faster than rival software  packages. Its Java interface enables the system administrator to manage  multiple remote backup servers through the Internet as if they were  local backups.    Pricing for Arkeia 4.2 starts at under $600.  A configuration  protecting 2 - type 1 computers (UNIX, NT Server), 5 - type 2 computers  (Linux, Win 95/98), and utilizing a single tape drive costs less than  $1,000.  Cobalt RaQ and Qube customers can download the Arkeia software  and purchase the package online at  www.arkeia.com .                 Cobalt partners with Gateway         SAN DIEGO--Oct. 12, 1999-- Gateway  Inc., and Cobalt Networks Inc., today announced an agreement under which Cobalt will supply server appliance technologies that enable Gateway to expand its capabilities to provide small-to-medium sized organizations with affordable and turnkey technology solutions designed to leverage the Internet.                  Cobalt Unveils Management Tool         Mountain View, Calif., October 18, 1999-Cobalt Networks, Inc., a developer of server appliances, today introduced the Cobalt Management Appliance. This system is specifically designed to allow system administrators to monitor and perform management tasks on large installations of Cobalt RaQ server appliances from a single management console.    By simply using Cobalt's proprietary user interface, system administrators can easily and securely apply software packages to a list of selected RaQs, reboot multiple RaQs remotely, change settings for an entire RaQ server farm, and activate and deactivate FTP, telnet, SNMP, and DNS.                    LinuxCare expands Japanese operation         Seeking to widen its presence in the already-expanding  Japanese Linux market, Linuxcare, Inc. announced  Friday that it has entered into a certification, service  and support-based strategic partnership with  Inter Space Planning Corporation (ISP)...       www.ecommercetimes.com/news/articles/991004-3.shtml                  National Semiconductor to use Linux in set-top boxes         Hong Kong - September 27, 1999 -    National Semiconductor  Corporation has appointed INFOMATEC AG / IGEL Technology Labs to develop Linux-based firmware to port to National Semiconductor's market-leading set-top box and thin-client platforms.                   VA files for IPO         VA Linux Systems has filed for  an initial public offering (IPO) with the Securities and Exchange  Commission (SEC). This is the second major Linux-related public stock move, after Red Hat. The option also mentions Andover.net's and LinuxOne's recent IPO filing.      www.ecommercetimes.com/news/articles/991011-4.shtml                   Ziatech news         Ziatech Corporation is combining its CompactNET(tm) multiprocessing technology with the recently announced LinuxPCI 1000 Development System, speeding the implementation of Linux-based, multiprocessing CompactPCI systems. The CompactNET version of the LinuxPCI 1000 comes with MontaVista Software's Hard Hat(tm) Linux, an embedded version of Linux. For more information, visit:       CompactNET open source web site  This web site allows users of Ziatech's CompactNET multiprocessing technology to download the open source code drivers for the Linux operating system. The CompactNET source code is being released as open source to foster the standard interoperability of CompactPCI multi-computing solutions from different vendors.                    SCO invests in LinuxMall         The Santa Cruz Operation has become the largest external investor in LinuxMall.com, one of the 200 busiest sites on the Internet.  LinuxMall CEO Mark Bolzern is quick to add that the company will continue its vendor- neutral tradition.  The investment will enable LinuxMall to ""take LinuxMall.com to the next level and meet the needs of the growing Linux community.""...      www.ecommercetimes.com/news/articles/991014-7.shtml                  Loki Hack Winners Announced         Atlanta, GA.  --  October 15, 1999 Winners of the first annual Loki Hack were announced in an afternoon press conference at the Atlanta Linux Showcase. During the Hack, enthusiastic and talented hackers from across the country and around the world had 48 hours in a secure setting to make alterations to the Linux source code for Activision's popular strategy game Civilization: Call to Power.  The hackers had full reign to add features, alter logic,  and implement additional library support.     ""This is the closest we could get to Open Source with our commercial products,"" said Scott Draeker, Loki president and founder. ""The world can't see the source, but the contestants did. And all the hacks, mods, and changes will be posted in binary form for free download from our website next week. This was our chance to show the gaming world what the Open Source community can accomplish, and the results have been incredible.""    At the press conference Draeker awarded first prize to Christopher Yeoh, a developer from Denver, Colorado. Yeoh completed several modifications to Civilization: Call to Power, including the addition of extra units such as land carriers and stealth carriers. Yeoh also enhanced the Spy unit by allowing it to infiltrate an enemy city. If successful, the Spy is destroyed, but the player can view the infiltrated city's statistics until payment is received from the enemy.    First prize is a StartX MP Workstation from VA Linux Systems. Runners-up will receive their choice of Gamer-X sound cards from Creative Labs, Inc., 3950U2 Ultra2 Dual Channel SCSI cards from Adaptec, Inc., and  Millennium G400 video cards from Matrox Graphics, Inc. All contestants completed at least one hack and will each receive a prize.                   Linux Getting 'Pervasive'         Pervasive Software, Inc. has moved its  SQL 2000 server for developing e-commerce applications into the open-source arena by making it available to  developers working with the Linux environment...        www.ecommercetimes.com/news/articles/991018-4.shtml                  MacMillan Publishing + SecurityPortal.com = more Linux security         MacMillan Publishing USA has entered into a strategic alliance  with SecurityPortal.com to bring online security technologies to  users of the Linux operating system (OS)...        www.ecommercetimes.com/news/articles/991022-7.shtml                  Intel Advances Linux Support         Intel Corp. enables online professional users to bring  Gigabit Ethernet performance to their Linux-based Internet  operations, and is working with the open-source community to foster  Internet-enabling product development...       http://www.ecommercetimes.com/news/articles/991025-5.shtml                   VMware Prepackaged         WINDOWS NT USERS NOW HAVE QUICK AND EASY WAY TO ACCESS LINUX    Palo Alto, Calif. -- Windows NT users interested in using Linux now have a quick, easy and painless way to do so.   VMware  , the leading provider of virtual machine applications for PCs, announced today that it has partnered with leading Linux operating system vendors Caldera, SuSE and TurboLinux to make available their versions of the Linux operating system to customers of VMware.    VMware is a revolutionary new application that enables personal computer users to run one or more protected sessions concurrently using one or more operating systems on a single machine.  This gives users the flexibility to run alternate operating systems and eliminates the fear of system or netw ork crashes, security breaches or virus attacks while doing so.    Under these initial agreements with Caldera, SuSE and TurboLinux, VMware for Windows NT and Windows 2000 will come with pre-installed evaluation copie s of these companies92 versions of Linux.  VMware is currently in discussions with other Linux suppliers to expand Windows NT users92 options even fur ther.                        Linux Links           www.LinuxFool.com  is a support and  discussion portal for Linux users.  It is an official mirror of the Linux Documentation Project.     Linux in Algeria  (French-language site)     eExams  offers skills testing via the web for companies seeking to screen prospective employees.  A Linux System Administrator exam is included among its many IT and non-IT offerings.    CNet article about    Transmeta taking aim at Intel .  From The Linux Bits #20.    The  Iozone  filesystem benchmark has a new version.                Software Announcements                  CUPS for Linux          The first production release of the Common UNIX Printing System (""CUPS"") is now available for download.  The license is GPL.     http://www.cups.org      The Common UNIX Printing System provides a portable printing layer for UNIX operating systems. It has been developed by Easy Software Products to promote a standard printing solution for all UNIX vendors and users. CUPS provides the System V and Berkeley command-line interfaces.     CUPS uses the Internet Printing Protocol (IETF-IPP) as the basis for managing print jobs and queues. The Line Printer Daemon (LPD, RFC1179), Server Message Block (SMB), and AppSocket protocols are also supported with reduced functionality.     CUPS adds network printer browsing and PostScript Printer Description (""PPD"")-based printing options to support real world applications under UNIX.     CUPS also includes a customized version of GNU GhostScript (currently based off GNU GhostScript 4.03) and an image file RIP that can be used to support non-PostScript printers.   Sample drivers are provided for HP DeskJet and LaserJet printers.  Drivers for over 1600 printers are available in our  ESP Print Pro  software.                    Cygnus Announcements         SUNNYVALE, Calif., October 12, 1999  -- Cygnus Solutions, the leader in open source software, today announced the commercial availability of Cygwin, a UNIX/Linux shell environment and portability layer enabling delivery of open source projects to Windows.  Cygwin provides corporate IT and software developers a solution for integrating a heterogeneous environment of Windows and UNIX-based systems.  In addition, developers can use Cygwin to quickly migrate applications from UNIX to Windows.    SUNNYVALE, Calif., October 12, 1999 Cygnus Solutions, and Integrated Computer Solutions (ICS) today announced a strategic agreement to integrate ICS Builder Xcessory PRO (BX PRO) with Cygnus Code Fusion9 Integrated Development Environment (IDE). This agreement provides Linux software developers with the first commercial IDE with graphical user interface (GUI) builder development capabilities.                     Running Windows NT applications on Linux         San Jose, CA. (October 18, 1999) - In a move to dramatically accelerate the expansion of business-critical applications available on the Linux platform, Mainsoft Corporation, the leader in cross-platform solutions for the enterprise, today announced it is developing a version of MainWin for the Linux environment.  MainWin is Mainsoft's Windows platform for UNIX operating systems.  MainWin allows software developers to re-host Windows NT applications on UNIX leveraging one single source code for both Windows and UNIX systems.     The same MainWin technology that has been available for UNIX platforms will be incorporated into the Linux product; to date, more than one million MainWin licenses have been installed worldwide.  As an extension of Mainsoft's product offering, the MainWin for Linux strategy will initially focus on the Red Hat Linux operating system with others likely to follow.    In the coming weeks, a demo will be available for download on Mainsoft's Web site at  www.mainsoft.com  and the commercial release is scheduled for end of Q1 2000.                 Netscape gets e-commerce security boost         Article about LinuxPPC's 128-bit encryption for Netscape 4.7 on the Power PC, Netscape's own efforts to boost encryption security, and the Clinton administration's proposal to partly relax US crypto-export restrictions.       www.ecommercetimes.com/news/articles/991021-2.shtml                    This page written and maintained by the Editor of the  Linux Gazette ,  gazette@ssc.com   Copyright © 1999, Specialized Systems Consultants, Inc.   Published in Issue 47 of  Linux Gazette , November 1999          ""The Linux Gazette... making Linux just a little more fun! ""                   The Answer Guy           By James T. Dennis,   answerguy@ssc.com   LinuxCare,   http://www.linuxcare.com/             Issue #47 of The Answer Guy   previous titles sorted by topic!    Greetings From Jim Dennis    Contents:       Logging In   X Window Networking --or--  The X Graphical Environment   Routing, Firewalls, and other ""raw"" Networking   Winmodems   Ordinary Modems and other Useful Serial Devices   Hard Disk Drives, Filesystems and Partitioning   CD-ROM, Tapes, and more Removable Media   LILO, SYSLINUX, and more Boot Loaders   Mail Servers and Clients   Other Servers   Scripting and Programming (including Startup Scripts)   Sweet Music?   Non-Linux OS Questions  if they didn't fit elsewhere.  Etiquette and More Social Questions    If that could possibly have missed it... -or-  Everything Else           Greetings from Jim Dennis      It is amazing to me how busy I have been this month.  I answered     almost as many messages as in that storm of them wrapping up last    year's backlog.    I especially want to thank everybody this month who piped in to     help the Answer Guy with IDE CDROMs under SCSI emulation being really    transparent - so transparent, that such CD's have to be referred to    as  /dev/scd0 .    I'll really give thanks when I can get back home with Heather and our    computers.  I have my laptop, but it's just not the same.  Happy    Thanksgiving, everyone!    [ For those of you who were answered by email during this month         - look forward to seeing your messages in print next issue. This list by topic has been requested by several, it's something I've been wanting to do for a while, and I really think you'll find it useful.  Also, Each question is still listed only once, so those which might fit more than one section have been listed in the section that best applies. -- Heather]            Logging In      #39:  Another ""No Login"" Problem: A little tip   #39: login source code --or--   Seeing Stars During Login   #39: security issue, /etc/passwd --or--   Secure Shutdown from the Console   #38: Why can I only login as root? --or--   Another  ""No Login"" Problem   #38  and  #37 :   Unable to Open Console: After ""Custom"" Install   #37: Why can I only login as root? --or--   Another  ""No Login"" Problem   #37: [Fwd: rsh on 2.0.34] --or--   More on: 'rsh' as 'root' Denied   #36: rsh config --or--   Getting 'rsh' to work   #36: rsh on 2.0.34 --or--   'rsh' as 'root' Denied   #36: Hello I need some help --or--   Eight Character login Name Limit   #36: Root password --or--   Can't Login in as Root   #36: password change --or--   CGI Driven Password Changes   #36:  Liam Greenwood: Your XDM question    and  #36 : How can I find this out? --or--   Remote Login as 'root'   #35: Keyboard Problem --or--   No Echo During Password Entry   #35:  FTP Login as 'root' --- Don't!   #34: xdm --or--   Remote X using xdm   #29:  adduser   #29:  Redhat telnet   #29: TACACS+ client for Linux --or--   TACACS and RADIUS Authentication         Models for Linux and/or PAM   #28  and  #26 :                   xdm  Login doesn't!   #26:  Can't Telnet to Red Hat 5.0 Server   #25:  Running as root on Standalone Systems -- DON'T   #15:  root login Bug in Linux           The X Graphical Environment      #46: Another ""respawning"" question --or--   Id ""x"" respawning too fast: Murdered Mysteriously   #46: How to add fonts to Linux --or--  Adding Fonts   #44: video timings needed --or--   Video Timings: Configuration Curse   #44: I am a begining Linux user, PLEASE Help! --or--   SiS 6326 and XFree86   #39: Fvwm95-Wharf --or--   fvwm95-Wharf: xterm comes out black?   #38:  Jim Dennis: Re: Gimp on RH5.1   #37:  eterm quickie + general commment (linux SUPERGRAN)   #37: X terminals via serial links? --or--   X Windows Over a Serial Line (Null Modem)   #37: modem problems under linux --or--   X Prevents/Kills Modem Connection   #37: Better resolution (laptop LCD) --or--   Higher Resolution X on a Laptop   #36: Changing the color depth for your x-server? --or--   Changing the X Server's Default Color Depth   #36: Num Lock and X apps --or--   NumLock and X Problems   #36: Tuning monitors for use with X --or--   Fraser Valley LUG's Monitor DB   #36: Trident 9685 tv --or--   Support for Trident Video/Television Adapter   #34: French loadkeys --or--   More on International Keyboard         Mappings and Monochrome X   #34: ... Redhat 4.2/Motif, problem discovered.  --or--   Conflict: Num-Lock,         X Window Managers, and pppd   #32:  XFree86 Installation in DOSLinux   #32:  Tuning X to work with your Monitor   #31:  XFree86 on Trident Providia 9685   #31:  X Window with two monitors...   #30: PC lockups --or--          Hardware Lockups due to                 Graphics Load   #30:  tv cards and dual monitor   #28:  xdm  in 16bpp Mode   #26:  Cthugha    #23:  Running Multiple Instances of X   #23:  KDE BETA 1   #22:  X-Windows Libraries   #22:  Redhat 4.2/Motif   #21:  X-Windows is Crashing   #21:  XLocks Monitor   #21:  Linux Control Panel   #20:  Video Cards   #20:  X Locks Monitor   #20:  Colormap Question   @19:  MetroX Problems   #18:  Adding Programs to Pull Down Menus   #19:  Adding Programs to the Pull Down Menus   #17:  Using X With 2 Monitors and 2 Video Cards   #17:  StartX   #15:  Copy from Xterm to TkDesk   #14:  X Window Problem           Routing, Firewalls, and other ""raw"" Networking      #46: Two Network Cards --or--   Routing Revisited   #46: http://sunsite.mff.cuni.cz/lg/issue13/answer.html --or--   From the Dim History: EQL Revisited    Bandwidth Load Sharing w/o ISP Support  #45: Internet Access Control --or--   Limiting Internet Access through Cable Modems   #45: Getting on the Internet --or--   Getting Access to the Internet   #45: Telnet trouble --or--   More ""Can't Telnet Around My LAN"" Problems   #44: IP forward --or--   TCP/IP Port Relaying   #44:  IP forwarding and Linux           Turning it off.  #44: Help ! --or--   Accessing Private Net Addresses from the    Public Internet   #42: TCP Sockets --or--   SYN, SYN/ACK, ACK, ACK, ACK: TCP Handshaking   ""Pleased to meet you!""  #42: Advanced ipfwadm question. icmp forwarding. --or--   ICMP Masquerading   #42: Hubs --or--   Ethernet Switches vs. Hubs   #42: ping at a differnt port --or--   Ping a Port: NOT   #42:  New Kernel Loses Ether Driver;                 Dial on Demand and Masquerading           A grabbag of user questions.  #42: Personal LAN setup... --or--   Setting up a Personal/Home LAN   #39: Multilink PPP using Linux --or--   Modem Multi-link PPP: EQL   #38:  A Reader Answers: What is the TCP/IP SACK feature?   #38: proxy & router combination --or--   Proxying over PPP   #38: win95->wingate ; linux->? --or--   Drop-in Replacement for ""WinGate""   #37: TCP patch for SACK? (RFC 2018) --or--   TCP/IP SACK Support:  When?  Now!   #37: ""Routing and Subnetting 101"" Linux Gazzette 1/1/99 --or--   Re: Routing and Subnetting for Classes   #37: ifconfig reports TX errors on v2.1.x kernels --or--   'ifconfig': TX errors   #37: Help --or--   Netscape Communicator: ""Improper DNS Type""?   #37:  Routing and Subnetting 101   #36:  Dynamic IP Address Publishing Hack   #36: eql dual line ppp --or--   EQL Serial Line ""Load Balancing""   #36: A Dual Modem configuration... how do I get it to work? --or--   eql Not Working   #36: how to install two ethernet cards for proxy server   for red hat linux --or--   Linux as Router and Proxy Server: HOWTO?   #36: isp --or--   Linux Friendly ISP's: SF Bay Area   #36  and   #34 :  Ether troubles = NE2000 ""clones"" --- not ""cloney"" enough! --or--         > Expansion on NE-2000 Cards:    Some PCI models ""okay""   #36:  ifconfig reports TX errors on v2.1.x kernels   #36: routing without of any outer routers knowing me   as I am a router.. --or--   Proxyarp   #36:  Linux as a Home Internet Gateway and Server   #35:  relaying still not correct ...   #35: Windows file systems across a linux box --or--   Programmer Fights with Subnets   #35: Finding IP address with a script --or--   Using A Dynamically Assigned Address    from PPP Startup Script   #35: SV: PPP-question. --or--   Where to find Multi-Router Traffic Grabber   #33: chroot, twist, and other rescue-boot fun --or--   ""Virtual Hosting"" inetd based         services using TCP Wrappers   #33: ip masquerading --or--   IP and Sendmail Masquerading over a Cablemodem   #32:  ISP Abandons User in Move to NT   #32:  IP Masquerading/Proxy?   #29:  Network Cards   #28: How do I setup gateway server? --or--      Linux as a General Purpose SOHO to                 Internet Gateway   #27:  IP Masquerading/Proxy?   #26:  'ifconfig' to Troubleshoot Dropped Ethernet Packets?   #23:  Linux and OSPF   #21:  Configuration of Two Ethernet Cards   #20:  PPP Problems   #20:  Renaming Problems   #19:  Linux Skip   #18:  Networking Problems   #17:  Response from Weitse Venema   #16:  Using Linux Box as a Firewall   #15:  IP Fragmentation Attack Description           Winmodems      #46: Modem blues.. --or--   High School Modem   #44: DosLinux --or--   What part of ""Win Modem"" Didn't you Understand?   #38: Diamond Multimedia Modems --or--   Reader Comments:  Diamond WinModems:   #38:  [Q]: Winmodem under Linux   #37: serial port settings --or--   Another Damn WinModem   #36: Offer to make available Winmodem interface spec --or--   Modem HOWTO Author Gets Offer RE: WinModems   #36: I do know i am boring (ma windows fa veramente cagare) --or--   Condolences to Another Victim of the     ""LoseModem"" Conspiracy   #29: Winmodems --or--   More on 'WinModems': How to ""lose"" Gracefully      - Just say No!  #28: Linux.bat -or--       LOADLIN.EXE, Plug & ""Pray""                 and ""Win(Lose)Modems""            Ordinary Modems and other Useful Serial Devices      #44:  ppp & voicemail   #45:  Linux to NT PPP Connection Over Null Modem   #44: PPP disconnect --or--   PPP + minicom Disconnects           WvDial Success  #43: Modem Help --or--   Searching for Days for a Linux Modem:         The Daze Continues   #43: One more thing. --or--   Null Modems: Connecting MS-DOS to Linux as a         Serial Terminal   #39:  What's wrong with internal modems?   #39: a small question --or--   Using a 286 as a Serial Terminal   #4: Digi C/X Host W/ C/Con 16 --or--   Linux Support for the         DigiBoard C/X Intelligent Serial Ports   #44: minicom --or--   Minicom Calling a Procomm Host   #39: diald dials every hour... --or--   Overactive diald   #39: Modem Problem --or--   Another Lost Soul   #38:  True modems   #37:  Sportys   #37: diald modem settings E71 --or--   Using ""odd"" modem settings   #37: Curious modem hangup... --or--   PPP Disconnects   #37:  modem disconnect problem?   #37:  Securing a modem dial-out line.   #36: Modem dial out   #34:  RE how to find out the serial connect         speed of a modem   #33: connect script failed --or--   O.K. It's not a Winmodem   #32: Mulitiple processes sharing one serial port --or--   Multiplexing the Computer         -- ISDN Modem Connection   #32:  phreaking   #32:  Finding BBS Software for Linux   #32:  High Speed Serial (RS422) under Linux   #32:  ANOTHER MODEM PROB  Plus, More on Grammar  #32  and   #30 :  Connecting Linux to Win '95 via Null Modem   --or--  A Convert!   #31:  How to check your modems connect speed?   #31:  115K Baud from a Modem:  In your dreams!   #30:  readdress COM port to 3 or 4   #29: Hello --or--   Connecting a Dumb Terminal to your Linux System   #29: PPP connection and diald --or--   Co-ordinating diald and Manual PPP   #29:  getting ppp-2.3.3 to work   #24:  diald's niche   #22:  Swap partition and Modems   #22:  Faxing and Dialing-Out on the Same Line   #21:  Linux PPP Server   #21:  PPP and Internet MCI   #21:  Attaching a Console to a PC   #18:  pcmcia 28.8 Modems and Linux 1.2.13 Internet Servers   #18:  UUCP/Linux on Caldera   #17:  Navas Modem FAQ   #17:  Setting Up a Modem   #17:  zmodem Reply   #17:  UUCP Questions   #16:  zmodem   #16:  Modem Speed   #14:  Dial-up Problem   #13:  Dialup Problem   #13:  Combining Modems for More Speed          Hard Disk Drives, Filesystems and Partitioning      #46: 2gig max file size? --or--    Large File Support Under Linux/x86   #45: LINUX File System Standard. --or--   /bin  vs  /sbin                  and the FHS Revisited   #44: AHA 2940 SCSI timeout errors --or--   was:  Plug and Pray SCAM   #44: AHA 2940 SCSI timeout errors --or--   More on: SCSI Resets Due to Command Timeouts   #44: AHA 2940 SCSI timeout errors --or--   SCSI Resets Due to Command Timeouts   #44: Hdd track 0 bad. --or--   How to Use a Disk with a Bad Track 0   #43:  Hey answer guy!!!   #43: bad clusters --or--   Try Linux ... and Grammar   #43: Duplicating / --or--   Out of Space....or Inodes?  All Sparsity Lost?   #43: RAID 1 solutions --or--   Arco Duplidisk: Disk Mirroring   #42: Unix Internal --or--   Inodes Numbering: An Academic Question   #42: One Bad Sector thats gettin on my nerves! --or--   One Bad Sector  It Doesn't Ruin the Whole Disk  #42: Resizing partitions --or--   Filesystem Management: What must be ""resident""     at all times?   #42: Question about 2 GB max? --or--   Maximum Filesize vs. Maximum Filesystem Size   #41:  file timestamp off Got it !   #39: How Can I Delete? --or--   Deleting Files and UNIX Permissions   #38: how to fix a bad cluster on hd --or--   More Bad Clusters   #38: help with partitions --or--   Installing on a Big Drive:    More on the 1023 Cylinder Limit   #38: help with partitions --or--   Partitioning Mini-HOWTO   #38  and   #37 :         Bad Sectors in my HDD --or--          Removing Bad Sectors   #37: nr_files and nr_inodes --or--           Max Open Files and Inodes: Use The Entries   under  /proc   #37: Partitioning my new Linux box... --or--   Disk Partitioning: Review   #37: I want my 10 GIGS!!! --or--   Ultra-DMA and the 8.4Gb IDE Disk Limit   #37:  Dos   #37:  Low Level Formatting   #37: I used gzip in bad way... help! --or--   Accidental Deletion   #36: Linux File System recommendations --or--   Where to Put New and Supplemental Packages   #36: where can i find information about LOFS, TFS --or--   Translucent, Overlay, Loop, and Union Filesystems   #36: chattr =u and then what? --or--   ext2fs ""Undeletable"" Attribute   #36:  How to Install Linux on an RS6000?   #36: Journal File Support and Tarantella? --or--   SCOldies Bragging Rights   #35:  Suggestions for Linux Users with Ultra Large Disks   #35: Linux question - ""out of the Blue"" --or--   Listing ""Just the Links"": It's the only way, Luke   #35: FS Security using Linux --or--   Crypto Support for Linux   #34: Booting and partitions --or--   Suggestions for Linux Users         with Ultra Large Disks   #33: SCSI drive installation --or--   Partition your HD before you try to use it.   #32:  Bad Clusters on Hard Drive --or--   Another Non-Linux Question!   #32:  Bad Super-block on Filesystem   #31:  Bad Cluster   #28:  Bad cluster in HDD   #23:  pcmcia ide Drives   #22:  Accessing ext2fs from Windows 95   #22:  chattr +i   #22:  Moving /usr subdirectory to another drive..   #21:  More on Disk Defrag   #21:  Enabling Automounter on a Linux Notebook   #20:  Mounting Disks Under Red Hat 4.0   #20:  New Hard Disc   #20:  Linux Disk Support   #20:  Security Issues   #19:  Mounting Disks Under Red Hat 4.0   #19:  Disk Support   #19:  File Permissions   #18:  Users And Mounted Disks   #17:  Duplicating a Linux Installed HD   #17:  fs's   #16:  Duplicating a Linux Installed Hard Drive   #15:  chown Question   #15:  File System Debugger   #15:  Mounted vfat File Systems          CD-ROM, Tapes, and more Removable Media      #44:  Unsupported Floppy Formats: 'dd' Maybe   #44: cdr's --or--   CDR Media: Silver and Gold and Blue, Oh my!   #44: ide-cd module --or--   Reading CD Discs on an IDE CDR Drive   #44: A Fair price for CD duplication --or--   CD Duplication Services: Spam?   #43: Floppy/mount Problems: Disk Spins,         Lights are on, No one's Home? --or--   Floppy Failure: mdir Works; mount Fails           Found the culprit!  #42: hal91 --or--   HAL91 (Floppy Based Linux Distribution)   #39: No rule to make target ' config ' --or--   Recompiling Kernel to Support CD-ROM   #39:  Plee for help   #36: Mounting CD Drives from SoundCard --or--   Mounting multiple CD's   #36:  Manipulating Clusters on a Floppy ...   #36: Remote tape access, using local CPU --or--   Application Direct Access to Remote Tape Drive   #36: Kai Makisara: Re: audio-DAT on SCSI streamer? --or--   More on: Reading Audio Tapes using HP-DAT Drive   #36  and   #35 :  Setting up Linux to serve CD images through loopback --or--          More than 8 loopfs Mounts?   #34: Problems with backup --or--   Problems with a SCSI Tape Drive   #33: fd0 --or--   Floppy/mount Problems: Disk Spins,         Lights are on, No one's Home?   #32:  [announce] Cdrdao 1.0 -         Disc-at-once writing of audio CD-Rs   #31:  DAO software for linux?   #30: DAO software for linux? --or--          ""DAO""    (Disk at Once) CDR?  Stump Me!  #31: Remote Backups (Yet Again) --or--   Remote Backups: GNU 'tar' through 'rsh'   #28: Problems with SCSI-CDROM and Audio CDs --or--      Sinister 'xmcd' Permanently Disables                 Right Speaker Channel   #20:  Linux and Zip Drives   #29:  Remote Tape Backups   #17:  Using MS-DOS Floppies          LILO, SYSLINUX, and more Boot Loaders      #45: Setting up Windows and Linux --or--   Dual Booting without Re-Partitioning   #44:  Installing Win NT 4.0 Workstation and Dual booting    Win NT 4.0 Workstation and Win 95 B   #44: get to know --or--   Downloading a copy of Linux   #44:  Copying boot partitiion   #44: LILO problem.. again --or--   Persistent LILO: Won't Start! Won't Go Away!   #42:sites for general disk info? --or--   General HD Info and Boot Code   #42:  pcmcia install on debian   #42:  Best Place to ""Download Linux""   #38:  Question from an old friend.   #37: Linux 5.2 Loadlin.exe, where do I get it? --or--   Finding LOADLIN.EXE ...    and Linux Loader for Win '9x   #37: Is it possible to run Debian on 4 MB? --or--   Low Memory Installation   #36: lilo --or--   Persistent Boot Sector   #36: Dual booting NT or Win9x with Linux (Red Hat 5.2) --or--   Dual Boot Configurations   #36:  LILO Default   #36: uninstall help --or--   Uninstalling Linux   #35: A newbie question --or--   How Many Ways Can I Boot Thee: Let Me Count Them   #34: dual /boot partitions --or--   Automated Recovery from System Failures   #33: Download a Catch 22?  --or--   Chicken and Egg (Catch-22) for      Linux Download/Install   #32: Thank you --or--   Articles on LILO Saves Life?   #32  and   #31 :         > 'Win '95 Hesitates After Box Has Run Linux?'   #31:  Lilo not working on SCSI when IDE drives installed   #30: Lilo won't boot --or--          Installed on a Secondary SCSI HD:         Lilo Stops at LI   #29: Removing Lilo from a multi-boot machine   #29:  Kernel crashes   #25:  Removing LILO, Reinstalling MS-DOS   #23:  loadlin   #21:  LILO Concerns   #21:  Linux Command Line Arguments   @20:  LILO   @20:  More on LILO   #20:  Booting Linux   #20:  Kernel Panics on root fs   #20:  95 GUI   #19:  Installing Linux   #19:  Weird LILO Problems   #17:  Trying to Boot a Laptop          Mail Servers and Clients      #46: outgoing email using Netscape --or--   Outgoing Mail Problems   #45: RH6 Virtual Email - POP3 problem --or--   Virtual E-mail Domains   #42: procmail and saved variables. --or--   MATCH and Replaceable Parameters in procmail   #38:  ""Integrating"" Linux/sendmail     with MS Exchange   #37 ,    twice :          > setting up an ISP to serve email    Setting up ISP Mail Services  #37: procmail --or--   'procmail' to Get Mail via POP-3?     No.  'fetchmail'   #37: Communicator and PGP on Linux --or--   NS Communicator (Mail) and PGP   #36:  Why 40-second delay in sending mail to                 SMTP server?   #36:  Locked Out of His Mailserver   #36:  Mail processing   #36:  Sendmail on private net with UUCP link to Internet   #36: preference=20 --or--   Secondary MX Records: How and Why   #35: sendmail problem --or--   'sendmail' on a Private/Disconnected Network   #35: e-mail quotas --or--   Quotas for Outgoing e-mail   #33:  Supressing cc: lines in Emacs' Mail replies   #31:  ' sendmail ' requires DNS    ... won't use  /etc/hosts   #30:  auto response for email ?   #29: Question on sendmail... --or--   ' sendmail '  FEATURE          creatures for virtual domain and generic re-write tables   #29: Mail on a LAN Linux to NT --or--   Basic e-mail Setup for Linux?   #29: Sendmail jam --or--   ' sendmail ' Log Jams and Capacity Problems :         running extra ' sendmail -q ' processes  #29: Mail access --or--   Getting at MS-Mail from within         Linux : The Myriad Ways to Co-exist with MS Windows  #29: Program for Mailer Daemons --or--   Automated Handling for MAILER-DAEMON         Messages : Read The Sources, Luke.  #28:  Email Alpha-Paging software   #28:  ' sendmail ' Masquerading: What and Why   #27:  Answer Guy Issue 18 -- Procmail Spam Filter   #27:  Great Procmail Article   #25:  More on Netscape Mail Crashes   #24:  Netscape Mail Crashing   #24:  Netscape /var/spool/USER    #23:  Security Problems with pop3   #22:  Linux sendmail problem   #22:  E-mail adjustment needed   #22:  POP3 vs. /etc/passwd   #21:  Pop3d That Doesn't Use /etc/passwd   #21:  Sendmail   #18:  Fetchmail   #18:  Procmail   #18:  Procmail Idea and Question   #17:  IMAP and Linux   #17:  IMAP Again   #15:  fetchmail and POP3 Correction   #15:  Mail Server Problem   #15:  Mail and Sendmail   #15:  POP3 E-Mail   #15:  Sendmail-8.8.4 and Linux   #14:  Netscape Mail Block   #14:  Dealing with e-mail on a pop3 server          Other Servers      #46: TCPMUX on Linux --or--   TCPMux Revisited:         You'll need a Daemon for it, or a Better inetd   #46: The Mac, Linux, perl, Apache & server --or--   A Staging Server   #45: unix question --or--   Quotas on a Sublet Web Server?   #45: Mars NWE --or--   MarS NWE: HOWTO and Docs in English?     #44:  ftpacess and the Incoming Conundrum   #44: Proxy server --or--   Proxy Program?   #42: Setting up a Loopback Mount --or--   Loopback (localhost) NFS Mounting for FTP   #42: work-around for gdi printer? --or--   WinPrinter Work-around   #38: xntpd --or--   How 'ntpdate' finds IP addresses?   #39: hmm. --or--   FTP Only Access:  Trickier than it Seems   #38: linux --or--   Mysterious Message:  Subject: Linux   #38: Great Job !!! --or--   Linux as a Loghost (Syslog Server)   #38:  Telnetd and pausing   #37: Simplified Security? --or--   Simple Security Tips   #37:  Getting my new linux box to run the ftp server   #37: System clock is too fast... --or--   Ahh ... The Toils of Time   #36: FTP Site... --or--   'ls' Doesn't work for FTP Site   #36: PAM & chroot (fwd) --or--   'chroot()' Jails or Cardboard Boxes   #36: MySql --or--   Finding info on MySqL?   #36: Real PS Printing --or--   Advanced Printer Support:    800x600 dpi + 11x17"" Paper   #36: Re: leafnode-1.7 -- news server for small sites --or--   More on Multi-Feed Netnews (leafnode)   #36:  Setting up ircd   #36: HELP: fetchmail dies after RH 5.2 upgrade --or--   Upgrade Kills Name Server   #36: LPD forks and hangs/Linux --or--   'lpd' Bug: ""restricted service"" option;    Hangs Printer Daemon   #34: apache server --or--   Executing ""Normal HTML"" Files         with Apache   #32:  MS FrontPage for Linux/Apache   #32: PPP --or--   The ""Difficulty"" is in    Disabling  the Services   #32: Online Status Detector --or--   Failover and High Availability for Web Servers :  Conditional Execution Based on Host Availability  #32:  Web Server Clustering Project   #32: wu-ftpd guest account on a Linux Box --or--   WU-FTP guestgroup problems   #31  and   #30 :  Printing Solaris -> Linux --or--  > Remote lpd Solaris to Linux   #30:  winprinters & MTAs : Pointers and Corrections  #27:  Linux Cluster Configuration   #21:  More on ftpd   #21:  Apache 1.2.1   #21:  DNS Problem   #20:  Cookies   #20:  Printing Problems   #17:  Virtual Hosting   #17:  Installing wu-ftpd on a Linux Box   #17:  inetd Questions   #15:  wu-ftpd Problems   #13:  WWW Server          Scripting and Programming (including Startup Scripts)      #46: redirection of stdin-stdout --or--   Programming Question about Regaining stdin/stdout   #45: java curses library and jxterm? --or--   Old Question Revisited: Java Curses Support   #44: Desqview/Linux --or--   Assembly Language Programming for an old     DESQview User   #44:  Linux gazette article, July 1999   #44: linux memory --or--   Free Memory vs. Buffers   #44: finding Changelogs --or--   Kernel Patches and Change Logs   #43  and   #42 : RedHat 5.2 Kernel 2.0.36 --or--   Upgrade Breaks Several Programs,          /proc  Problems, BogoMIPS Discrepancies    A visit to ""Library Hell""  #42: cvs tree for pam --or--   PAM chroot   Wherein Jim rants about PAM  #42: Server shutdown/restart: 2-key keyboard --or--   Server Shutdown Button   #42: Here's a shell scripting question for you. --or--   How to Make a Shell Script ""Unbreakable""   #42: ""core"" files appearing here and there --or--   Dealing with ""core"" files   #42: Xterm and ""Log to file"" --or--   Flexible Logging of Terminal Output to Files:     Use 'screen'   #39:  Error starting recompiling process?   #38: Win 95 computer/NT server environment --or--   Shell Scripting: Getting Host and User Names   #37, Steven Hancock  and   #36 :   ey answer guy! answer this! --or--          Automated PostScript (ps)    to GIF Conversion   #36: who to report gcc bug to? --or--   Where to Report Bugs and Send Patches   #36: question for answerguy --or--   Letting Those Transfers Run Unattended   #36: Compiling kernel --or--   Making a Kernel Requires 'make'   #36  and   #34 :  Updates: Risks and rewards --or--         > Automated Updates          Keeping my RH5.0 system up to date  #35: X and virtual terms --or--   Some Magic Keys for the Linux Console   #35:  modutils question   #35:  libc5 and libc6   #34:  Re Script   #34: Here's a doozy --or--   Telnet/xterm: Log to file   #34: Is there a testsuite for glibc v2.0.x?  --or--   Test Suites for GNU and other     Open Source (TM) Software   #33: [linuxprog] more shuffling experiments --or--   Shuffling Lines in a File   #33:  Conditional Execution Based on Host Availability   #33:  Thanks  for the pointer to uuencode sources.  #32:  Detaching and Re-attaching to Interactive Background         Processes   #32:  The last Linux C library version 5, 5.4.46, is released.  --or--   The End of libc5:         A Mini-Interview with H.J Lu   #32: Linux System Administration.  --or--   Where to put ' insmod ' and         ' modprobe ' Commands for Start-up   #32:Help with C/C++ Environment Program --or--   Integrated Programming Environments for Linux   #31:  Kernel Overview needed....   #31: Question on Memory Leak --or--   Memory Leaks and the OS that Allows Them   #30: Linux and SCO Keymap --or--          SCO Compatible Console Keymaps?   #30: linux kernel security --or--          Breakin' Out of the          chroot()  Jail  adding ""disabilities"" to Linux  #30: gzip from C program --or--          Compression Libraries to                 Link into a C Program   #30: Memory deallocation problems --or--          Linux Memory Usage vs. Leakage   #29:  Version-a-go-go and the Tragedy of     being ""Left Behind""   #28:  Tools for converting X output to java    #27:  Regarding Compile Errors with Tripwire 1.2   #27:  Applix Spreadsheet ELF Macro Language   #26:  Use the Source, Luke!   #24:  Upgrade to Red Hat 5.0?   #23:  An Interesting De-Referencing Problem   #22:  Problem with make   #22:  Visual Basic for Linux   #22:  C++ Integrated Programming Enviroment for X...   #20:  All Those Little % Thingies   #20:  gcc and Slackware Question   #20:  Using JDK 1.1 for Solaris x86 on Linux   #19:  Running FileRunner   #19:  Bash String Manipulations   #18:  Tcl/tlk Dependencies   #18:  [q] Map Left Arrow to Backspace   #17:  Automatic File Transfer   #17:  User Identification   #16:  Problems with Keyboard Mapping   #15:  Automated File Transfer over Firewall   #13:  File Referencing          Sweet Music?      #38:  souncards   #38 ,   #35, Alan Cox ,   #34, HELP!! :   About a OPL-3 ( Yamaha driver for sound) (sorry for bad english...)   --or--         > OPL-3 Sound Drivers   #31: redhat linux 5.0 and reveal sc400 rev a sound card --or--   Reveal SC400 Sound Card:     OSS/Linux and OSS/Free Supported?   #18:  Configuration Problems of a Soundcard          Non-Linux OS Questions      #46:  dao    (""helpless"" in TAG #44))  #44: Linux Partition conflicting with Win98 --or--   Makes Windows Explorer Choke           More complex than that, really.  #44: Linux and Windows 95 --or--   Running Win '95 Apps under Linux   #44: DESQView 386 --or--   DESQview/386 Die Hards into the Next Millennia   #44: Dao --or--   Helpless   #44: pc-mos --or--   5 1/4"" Floppies: Truly Dead   #42: HELP!!!!!!!!!! --or-   Data ""Losted"" (sic)   #42: ""Network Neighborhood"" --or--   Network Neighborhood: Heterogenous File Sharing   #42:  AOL   #38:  Please upgrade your Internet Explorer --or--   The Presumption!   #36 ,    twice :   RedHat Linux (5.1) and Brand X --or--         > How to ""get into"" an Linux system    from a Microsoft client   #36: Question (what else?) --or--   MS Applications Support For Linux   #36: read please very important --or--   Spying: (AOL Instant Messenger or ICQ): No Joy!   #36: Printing question --or--   Extra Formfeed from Windows '95   #36: Mount linux drives from win9x/nt?   password encryption seems to be a problem... --or--   Sharing/Exporting Linux Directories to       Windows '9x/NT   #36: Linux in general --or--   Complaint Department:   #36:  No STREAMS Error while Installing Netware                 for Linux   #36: update on your answer - netware clients --or--   Linux as a Netware Client   #35: office server --or--   Linux as a File/Print Server for Window and DOS boxes:                 Of course!   #35: Question about networking with NetWare --or--   Needs to Login to Netware   #34: Shell File!!!!!  --or--   All that Vaunted Support for those         Windows Users   #34 ,   #29  (a little note),  and  #28   #34: ""Good Times""-email is it a virus?  --or--   The Infection and the Cure    ""Good Times"" are Spread to the ""Great Unwashed""  #34: nt 4.0 ras dialin problem --or--   Another Non-Linux Question   #34:  Macro Virus?   #33:  Linux/Samba as a Primary Domain Controller   #33: Desqview --or--   Buying DESQview and/or DESQview/X   #32: resume on AS/400 --or--   Resume Spam   #32:  Linux Port of SoftWindows   #32:  Virtual System Emulator for Linux      and Why NOT to Use Them   #32: Netware NDS Client --or--   NDS (Netware Directory Services) for Linux:         Clients and Servers   #31: Linux NDS --or--   Linux as a Netware Directory Srvices     Printer Client?   #30: NT Domain and Linux --or--          Linux as a ""Domain Controller"" for                 a WinNT Domain?  Not Yet!                  Linux use of an NT PDC/BDC for authentication?  #30: help on unix --or--          Running Unix/Linux Under Win '9x   #28:  Complex network and NetBIOS   #24:  Red Hat Linux and WABI and other things   #20:  Follow-Up to NT and Linux Article   #20:  Active X for Linux/Unix   #19:  ActiveX for Linux   #18:  ActiveX For Linux   #18:  Linux and NT   #17:  Linux/Unix Emulator          Etiquette and More Social Questions      #46: your web --or--   Who is Jim Dennis?   #45:  Cash In On ... Spam!   #44: can't help it --or--   Spellcheck Award!   #44: This month's ""paltry"" offerings --or--   Typos   #44:  Benchmarks   #43: need your help --or--   Incompetance in Parenting   #42:  RMA for Video Card   #42: Hey answer guy!!! --or--   Linux as a Job!   Hobbies become fun and profit  #42: Pls spare a minute: --or--   Spare a Minute to Provide ""Some Info""   #37: Further answers to questions? --or--   Sometimes Short of the Question   #37: you are the man --or--   The Complaint Department: Typos and    Grammatical Errors   #36: Your book --or--   Book: Linux Systems Administration   #36: very general process question --or--   An Anthropologist Asks About the Linux ""Process""   #36: Thank You --or--   Kudos   #36:  TAG suggestions   #36: Just a sugestion... --or--   Best of Answer Guy:  A Volunteer?   #33: Important typo in Anti-Windows emulator rant --or--   Will the ""Real"" freshmeat Please Get Bookmarked?   #32:  The Five Flaws of  the  Unix System   #31: Stupid question --or--   AnswerGUY? Who is Heather?   #30:  LOVE THE NEW LOOK!!!!   #29: The Answer Guy --or--   Regarding the Column's New Look   #28: Lets vote for Linus --or--      Some Thoughts on ""The Man of the Century""   #20:  A Letter of Thanks          Everything Else      #44: quick swap Q --or--   And from Radioland....   #44: Question --or--   The Lost Art of Helper Apps   #44: 128M Ram question --or--   Seeing only 13M of RAM   #42: How to Build Own Linux Distribution ? --or--   Building a Personal Distribution: Take II   #39: New Linux Distribution --or--   How to Create a New Linux Distribution: Why?   #39: Good morning!!! --or--   Essay Quiz   #39:  Linux and Y2K   #39: Your approach to Y2K problem --or--   Y2K Cause Arithmetic Failures?   #37:  RAM   #37:  LTT submission   #37: Uh, where'd my ""man"" go? --or--   'fsck' Breaks 'man' Pages?   #36: The Linux Swap File --or--   Swap file on a RAM Disk   #36: Locating AV Research --or--   Looking for a Hardware Vendor:    In all the Wrong Places   #36:  troubleshooting   #36: Question --or--   Linux Support for Intel Pentium II Xeon CPU's      and Chipsets   #36: Looking for info on BIOS setup --or--   Plug and Pray Problems   #32:  The BIOS Clock, Y2K, Linux and Everything   #32:  More on Distribution Preferences   #31:  Yggdrasil: A Breath of Life for the   Root of the Linux Distributions?          ...and what about OpenLinux Base?  #38: Is it possible to run Debian on 4 MB? --or--   Low Memory Installation   #37: Linux Diagnostic Tool --or--   Hardware Info Under Linux: MSD.EXE Clone?   #37: copy of Microsoft Office --or--   Free Copy of MS Office for Linux?    It isn't April Yet!   #36: Alternate root-password recovery option --or--   Alternative Method for Recovering from     Root Password Loss   #36: memory usage --or--   Using only 64Mb out of 128Mb Available   #36: Can you give me a Suggestion?/ --or--   Microtek Scanner Support:  Alejandro's Tale   (Alejandro was the querent on this topic in     #35 .)  #36: more on keybindings --or--   termcap/terminfo Oddities to Remotely Run SCO App   #36: Arabic? --or--   Arabic BiDi Support for Linux   #35:  The state of UNIX in 1998   #35: RedHat 5.1 and rpms --or--   RPM Dependencies: HOW?   #35  and   #29 :         > Linux on Dell Systems   #34:  Query   #33:  AutoCAD for Linux?  Not Yet.  Sorry.   #33: tty help --or--   Psuedo tty Becomes Unusable   #32: Driving Terminals w/Java --or--   Java Telnet/Terminal   #32:  FoxPlus for Linux ?   #32:  How to read DVI files?   #32:  Permission to Set up a Linux Server   #32:  /usr/bin/open  command not found   #32:  SysAdmin: User Administration: Disabling Accounts   #31: Assigning UID/GID --or--   UID/GID Synchronization and Management   #31:  What is an RPM?   #30: Dosemu and virtual terminals? --or--          Clipper/xBase Capacity Problems                 --- DOSemu as a Solution?  ""I don't think so.""  #30:  tn3270 security   #30: FoxPlus for Linux? --or--          Dreaming about xBase tools for Linux   #30: please, advice about Linux and C500 --or--          Linux PPC on the Umax C500 SuperMac:                 Not A Good Idea   #30: Help Wanted --or--          User Shell on Virtual Console 1   #29:  Why Linux?   #24:  Slackware Help   #24:  Getting Rid of Virtual Screens   #24:  Linux as a PDT   #23:  VC Madness   #23:  Cryptographic System   #23:  Reminder!   #23:  Compression Program   #23:  WipeOut   #22:  Linux and the 286   #22:  REALBIOS?   #22:  PC Emulation   #22:  Linux 4.2 software and Hardware compatablity problems   #22:  LYNX-DEV new to LYNX   #21:  More Random Crashes   #21:  Lunx and Frames   #21:  Linux/Unix Emulator   #21:  Crypt   #20:  Z Protocol   #20:  Red Hat CD Problem   #20:  Random Crashes   #20:  STO/1/O2 SCSI Card   #19:  Legibility   #19:  Blinking Underline Cursor   #19  and   #18 :  Adding Linux To a DEC XLT-366  #18:  /var/log/messages   #18:  OS Showdown   #18:  What Packages Do I Need?   #16:  SATAN URL Correction   #16:  EDI on Linux   #16:  Running the Internet with Linux   #16:  Respawning Too Fast   #15:  Pseudo Terminal Device Questions   #14:  Security Problem   #14:  More on Security Problem           ""Linux Gazette... making Linux just a little more fun! ""                 More 2¢ Tips!    Send Linux Tips and Tricks to   gazette@ssc.com       New Tips:       Home Network Domain Name  Spell check script  Linux on playstation 2  Is that open port a backdoor?  Inspecting packets denied by your firewall  A random background selector          Answers to Mail Bag Questions:         Telnet trouble  Why should I care?  Compiling network driver  How to prevent remote logins as root  Shell programming  Internet connection proble  Run-time error on cplusplus programme  Making Linux talk to an NT network  Preventing unwanted telnet access  Maximal mount reached; check forced  Riva TNT 2  Netscape and Java  Installing Linux on large drives  Reading Linux partitions from NT/95  COBOL compiler  Mounting a zip disk  CDROM is not a block device  Compiling IRC  Chat server  Imagemap  Printing lines of black  FAQ and printing...                         Home Network Domain Name     Sat, 2 Oct 1999 01:00:45 -0400  From: Barry < BarryJJ@IBM.Net>     Discussions of private networks typically point the user at the IP address ranges - such as 192.168... - reserved for private networks.    But they often also show those networks named something like ""...MyHome.Net"" Murphy says that any name you pick will eventually be a real domain to which you want access.    For a private network, you do *not* have to use a "".net"", "".com"", "".org"" ending.  I've been happily using an adaption of my street address - i.e., something like "".MainSt123"" - for some time, yielding nodes such as Hub.MainSt123 = 192.168.0.1 for a (Linux) gateway, and things like FamilyRoom.MainSt123 for other machines scattered around the house.    I run things such as DNS (early Bind, now Bind8), Apache, Squid, Samba, etc. on the hub machine and have had no configuration problems from *not* using a standard, 3-character ending.    And I sleep easy knowing that I'm *not* using something that may also be a *real* domain name ... at least not in the foreseeable future :-)    Barry Johnson  -  BarryJJ@IBM.Net                   Spell check script     Wed, 20 Oct 1999 21:38:20 -0700  From: David Anderson < davkat1@home.com>     Here's a little Spell ckeck script, I call it ""wspell"" you can call ""wspell"" alone, and anwser the questions or place up to two portions of the word into the command line as in   wspell re quir reacquired require required requirement requirements requires requiring      the requirement of this script is, get the first few letters correct     wspell  (shell script)                   Linux on playstation 2     Thu, 21 Oct 1999 17:38:57 +0930  From: 50012176 < 50012176@snetad.cpg.com.au>     hello,  I just wanted to say, did you know that Playstation 2 is using a Linux interface, while the Dreamcast is using Windows.    later  (((LeX)))                   Is that open port a backdoor?     Sat, 23 Oct 1999 01:38:10 +0200  From: Pat Bateman < pat99@linustart.com>     That's what I though the first time I used the program wget. If you don't know why some port is listening and you are a little bit paranoid and think that's a backdoor, try first this command:    fuser -vn        This will display the program that opened that port, it's PID and the user who executed it. If you are sure that's a backdoor and want to close it, type this:    fuser -kn        This will close this port till the next reboot (unless the backdoor program is runned by cron). Check your system to eliminate the backdoor. Here's my 2cents_tip                  Inspecting packets denied by your firewall     Wed, 29 Sep 1999 11:04:48 -0500  From: marc < lowkey@innocent.com>     I have a firewall, and the logs show when a packet is deined.  Denied packets from the internet can be a warning sign.  But i became tired of searching through the logs for this info, and the ips were not resolved.  So i wrote some scripts that look through a log file, pull out the DENY lines, resolve the ip addresses and remove any duplicates.    These scripts are perhaps the height of kludgeyness, but they work.  I know i like to learn from examples, so maybe this can help others.    the script to run is   show_denied_packets.sh     This script filters out any lines dealing with my local LAN, because I am only looking for packets from the internet.   You may want to set LOCAL_LAN to the ip address of your local lan, if you have one.    It then calls  strip_log.pl     This perl script takes the info from the log and prints out just the ip addresses and ports involved.  This info is then piped into the logresolve program.    logresolve is a c program that came with my apache, although not compiled.  i found it in /var/lib/httpd/support/ .  To compile it i ran  gcc -o logresolve logresolve.c   and then moved the logresolve binary into my bin directory. Its path needs to be set in the show_denied_packets.sh script.    Finally, I was getting many duplicate entries, so i pipe the info to the unix sort command to sort it all, and the unix uniq command to take out all the duplicate entries.    And viola!  you now have a list of all the computers that tried to send you packets that bounced off your firewall.  To keep an eye on this, i put an entry in my crontab to have this info mailed to me once a week. The line looks like this:   # once a week check for denied packets 0 2 * * mon /home/marc/bin/show_denied_packets.sh      Using different scripts together is a strength of unix.  Still, this is a bit kludgy, and if there is any interest, i could whip all this up into one program.                   A random background selector     Tue, 14 Sep 1999 16:58:55 -0400 (AST)  From: Ben Okopnik < ben-fuzzybear@geocities.com>     Hi -    First thing, I'd like to thank you for putting out the LG; it's  been a mentor/SuperFAQ/""AHA!"" generator ever since I first  installed Linux, over a year ago.   ""What a long, strange trip it's been"". Thanks to LG (as well as a myriad other Linux sources), I'm now very comfortable (not yet a guru, though) with it, and learning more every day.    Second - a contribution, if you will. Here's one of the shell scripts that I've written,  bkgr ; it's been a really nifty gadget for me, selecting random backgrounds for my X-Windows. I hope other folx here will find it of as much use.    Drum roll, please... :)     There is lots of configurable stuff in there - graphics prog, window manager, etc. - but the comments should make it sorta simple to adapt. *Hint*: the backgrounds for E-term (this is  where about half of my pics came from) are rather bright and wonderful...      Keep up the good work!                    Tips in the following section are answers to questions printed in the Mail Bag column of previous issues.                     ANSWER:  Telnet trouble     Sat, 25 Sep 1999 01:28:37 -0700  From: Jim Dennis < jimd@starshine.org>          Dear Jim     Your email did help me to solve the problem with the telnet in  linux. It works fine now. Thanks a million.....     I have a small doubt. Let me explain......  My network has a NT  server, LINUX server and 20 windows 95 clients. I followed your  instructions and added the address of all the clients into the  /etc/hosts file on the LINUX machine and voila the telnet worked  immediately.     But the NT server was the one who was running a DHCP server and  dynamically allocating the addresses to the clients. The clients  were configured to use DHCP and were not statically given and ip  addresses.  I managed to see the current DHCP allocation for each  client and add those address into the /etc/hosts file on the LINUX  server but my doubt is what happens when the DHCP address for the  client changes? Then again we'll have to change the address in  the /etc/hosts file right? This seems silly.  Is there anyway to  make the LINUX hosts file to automatically pick up the DHCP  address from the NT server?      Also another important thing is I am still unable to ping from the  NT server to the LINUX server using the name. It works only with  the IP address. Is there any way to make the NT DHCP to recognize  the LINUX server?       Well, either you shouldn't use dynamic addressing  (DHCP) or you should use dynamic DNS.  You could  also disable TCP Wrappers (edit your /etc/inetd.conf  to change lines like:   telnet stream  tcp     nowait  root    /usr/sbin/tcpd in.telnetd     ... to look more like:   telnet stream  tcp     nowait  root    /usr/sbin/in.telnetd in.telnetd       (and comment out all of the services you don't  need while you're at it).         Thanks Jim for all your help....you've become my LINUX  guru.............       Perhaps you should consider getting a support   contract (or joining a local users group).  I may  not always respond as quickly nor as thoroughly  as you'd like.                   ANSWER:  Why should I care?     Sat, 25 Sep 1999 07:34:24 -0400  From: Rick Smith < rsmith13@tampabay.rr.com>     ""R.Smith"" wrote:      Sir,    Since my previous letter about Dalnet providers trying to connect to my  Linux box via telnet port 23, I have found out that they are also trying  port 1080.  I have instigated a policy of dropping all incoming  connections via a command run by host.deny:      /sbin/ipfwadm -I -i deny -S %a       I hate to do this to my niece, but I don't know of any alternative until  these dalnet jerks stop this intrusive practice.    Anyway, my niece has moved to other irc providers that don't  do this kind of thing.      Why should I care if Dalnet is trying to connect to ports 23 and 1080?  I don't run any services on port 1080 and port 23 is closed via hosts.deny.  I care because WITH JUST ONE dalnet user, I sometimes have dozens of syslog messages per day.  I have to go through them and decide if there is a problem.  I have to run whois, nslookup, traceroute, etc. on them to see if they are bogus.  And many of the dalnet domain and IP's ARE bogus.     I could ignore connect attempts to port 23 and miss that one attempt that really was important.  I could ignore port 1080... I could turn off my firewall and let everyone in...    Imagine what a workload I would have if I was an sysadm with 20-30 people on dalnet.    It is simpler to just drop all connect attempts and let my niece use other irc services that aren't abusive.                  ANSWER:  Compiling network driver     Sun, 26 Sep 1999 14:01:58 +0200 (CEST)  From: Roland < rsmith@xs4all.nl>     Hi Jeff,    after you compile the network card driver, you should place it an a directory where insmod searches for it. I think /lib/modules/x.y.z/net would be appropriate, where x.y.z is your current kernel version, e.g. 2.2.10 or 2.0.38.    Altarnatively you can set the MODPATH environment variable to point to the directory where your module is located. See ""man insmod"".                   ANSWER:  How to prevent remote logins as root     Sun, 26 Sep 1999 14:17:48 +0200 (CEST)  From: Roland < rsmith@xs4all.nl>     Erik,    I read your question in issue 46 of the Linux Gazette.    To deny remote logins as root, add the following to the /etc/login.acess file:   -:root:ALL EXCEPT LOCAL      This means you can only login as root from a local console.    But if I where you I would disable telnet entirely and use ssh (secure shell). You can disable telnet by adding a ""#"" in front of the ""telnet"" line in /etc/inetd.conf.    If you are not running a server, I would disable inetd entirely. To do this, comment out the lines that start inetd in the start-up scripts. For Debian this is /etc/init.d/netbase, for Slackware the /etc/rc?.d scripts (""?"" is your runlevel, look at /etc/inittab for the default runlevel). I don't know about Red Hat, but you can do a  ""grep inetd /etc/init.d/*"" to find it there.    Ian Carr-de Avelon < ian@emit.pl>  says:        From: Erik Fleischer < ferik@iname.com >      For security reasons, I would like to make it impossible for anyone    logging in remotely (via telnet etc.) to log in as root, but so far    haven't been able to figure out how to do that. Any suggestions?      This is an easy one, at least under Slackware; other distributions may differ. The file /etc/securetty has the terminals root can use. It looks something like:  tty1 tty2 tty3 tty4 tty5 tty6 ttyS0 ttyS1 ttyp0 ttyp1      The tty(number) entries are what you use normally with the PC video card and keyboard. ttyS(number) entries are serial lines, so for example if you connect to your Linux box via a modem. ttyp(number) entries are ""pseudo terminals"" which you get if you come in via telnet. Delete all the ttyp entries and you can't telnet in as root.    Yours  Ian     [Jeremy Johnstone  <  wizdem25@hotmail.com>  and  Stephen Crane < scrane@flexicom.com>   also sent in the same suggestion.  -Ed.]       Jonathan Marsden < Jonathan@XC.Org>  adds:    You don't say what sort of login you have in mind: telnet? FTP? SSH? rlogin?  I'll try to deal with all of those!    (1) Set the file /etc/securetty to contain only the local console device(s).  This is actually what is done in most or all well known Linux installations by default.  It will prevent root login on telnet connections (or dialin lines, or any tty except the ones listed!).    (2) Make sure root is included in the file /etc/ftpusers.  Again this is done by default on most or all curent Linux distributions.  This file lists all users who will be denied FTP login (one user per line), even if they use the ""correct"" password for that user.    (3) In /etc/ssh/sshd_config (may be /etc/sshd_config on some distributions), set PermitRootLogin no.  This prevents users l"
GX060-31-12389791	"December 2001, Issue 73       Published by  Linux Journal     Front Page   |   Back Issues   |   FAQ   |   Mirrors   |   Search (www.linuxgazette.com)                                 Visit Our Sponsors:                                 Table of Contents:               The MailBag        More 2-Cent Tips        The Answer Gang        News Bytes        Linux User Caricatures  ,  by Franck Alcidi       The Art of Atari ST Emulation  ,  by Matthias Arndt       Audio Processing Pipelines  ,  by Adrian J. Chung       Microsoft's New Briar Patch  ,  by Jim Dennis       Winning the Battle for the Desktop  ,  by Dennis Field       Visual Debugging with ddd  ,  by Wolfgang Mauerer       Installing Linux on Root Devices Unsupported by Your Distribution  ,  by Zwane Mwaikambo       The Answer Gang's Posting Guidelines  ,  by Ben Okopnik       The Foolish Things We Do With Our Computers  ,  by Mike ""Iron"" Orr       Free-Software Appreciation  ,  by Mike (""Iron"") Orr       Content Management with Procmail  ,  by Pradeep Padala and Prakash Bulusu       Writing Documentation - Part 1: POD  ,  by Christoph Spiel       Managing MP3 Playlists, The One UNIX Way  ,  by zhaoway       The Back Page                              Linux Gazette  Staff and The Answer Gang     Editor:  Michael Orr   Technical Editor:  Heather Stern   Senior Contributing Editor:  Jim Dennis   Contributing Editors:  Ben Okopnik, Dan Wilder, Don Marti                    TWDT 1 (gzipped text file)   TWDT 2 (HTML file)  are files containing the entire issue: one in text format, one in HTML.  They are provided  strictly as a way to save the contents as one file for later printing in the format of your choice;  there is no guarantee of working links in the HTML version.                   Linux Gazette ,   http://www.linuxgazette.com/   This page maintained by the Editor of  Linux Gazette ,   gazette@ssc.com      Copyright © 1996-2001 Specialized Systems Consultants, Inc.                    The Mailbag                  HELP WANTED : Article Ideas      Send tech-support questions, Tips, answers and article ideas to The Answer Gang < linux-questions-only@ssc.com >.  Other mail (including questions or comments about the  Gazette  itself) should go to < gazette@ssc.com >.  All material sent to either of these addresses will be considered for publication in the next issue.   Please send answers to the original querent too, so that s/he can get the answer without waiting for the next issue.     Unanswered questions might appear here.  Questions with answers--or answers only--appear in The Answer Gang, 2-Cent Tips, or here, depending on their content.  There is no guarantee that questions will  ever  be answered, especially if not related to Linux.     Before asking a question, please check the  Linux Gazette  FAQ  to see if it has been answered there.                    radius   HTML/CSS question - useful for dicussion   neighbour table overflow   Ethernet: Slow download, fast upload                 radius  Wed, 7 Nov 2001 00:41:46 +0200  hakan bilginer ( hakanb from vestelnet.com )     Hello,     I wonder if it's possible to make a radius server on linux to  authenticate the users on a remote mssql server 7.0 database.we use ms  radius server and want to try linux.and if it's possible which radius  server would you recommend for this job?     Thank you     Hakan Bilginer                  HTML/CSS question - useful for dicussion  27 Nov 2001 23:31:32 +0000  mike ( mike from redtux.demon.co.uk )    I am currently trying to write html which will insert page breaks for printing, which is is CSS2, and just happens to be part of css2 not implemented in mozilla.     Is any anyone aware of any solutions to this using HTML/CSS1                   neighbour table overflow  Tue, 13 Nov 2001 10:53:35 -0500 (EST)  Ian Berry ( ian from wunh.org )     Hi all,     I just set up a nice little p120 with 2-NICs and RedHat7.0 for my mom and it is working great except for one thing which you have spoken of before, the ""neighbour table overflow"" message being printed out to the console.     In a response to a letter from James Zhuang, Heather spoke of how ifcfg-lo might be missing or that lo might not be up but on my system, ifcfg-lo is there and appears correct and lo is up and running.  Also JimD mentioned that pump might be screwing up the loopback configuration and I am running that as my dhcp client;  how might i remedy this problem?  I'd be happy to provide more system information if it would help or if you have any other ideas on where i might look i would appreciate it.     Thanks,     -- Ian Berry      Old symptom, maybe a new problem.  Anybody out there encountering  this too?   Even better if you've got a Tip sized answer.   -- Heather                Ethernet: Slow download, fast upload  Mon, 12 Nov 2001 17:47:29 +0100  Matthias Posseldt ( matthi from gmx.li )     Hi all there,     I recently bought a OVIS Live FSH8R 10/100 MPS autosensing switch and a Davicom 9102 network card (dmfe.c) (They deliver Linux drivers on disk!!) So I cabled all together and connected to a friends notebook. From my  Apache  server he can download with speeds up to 9 MB/s, that's what I expected. Now when I download files (big files to measure the throughput) from his Apache (on Windows    or via smbmount/Samba,  I'll just get a rate of 2,5 MB/s. With iptraf (an ip traffic analyser, it's very good, IMO) I get a lot of big packets (1400-1500 bytes), which are the data packages. But my network interface also receives/sends alot small (<100 bytes) packages. These are confirmation packages, I assume.     Both network cards run at 100 Mps, changing switch ports did not help. The switch has only two cables connected.     So, nice story   . The question:  Why can't I get a fast downlink, but only a fast uplink.     Thanks, Matthias                        GENERAL MAIL                   Diablo under Wine   Tnx Ben & Breen   re Nov issue - Dennis Field article   Two readers address --   RE:Battle for the Desktop: Why Linux Isn't Winning    Ian Carr-de Avelon    Robin Rowe                 Diablo under Wine  18 Nov 2001 13:42:13 -0600  Charles R. Tersteeg ( aa0na from arrl.net )     I read your article in Published in issue 71 of Linux Gazette October 2001 where Jefferson said Diablo ran fine under Wine at LWE.  Which Diablo?  I or II.  I have II running fine, but I can't find anyone who has Diablo I running.     thanks,  chuck     I really don't recall whether it was I or II - but it was the honest to goodness CD from the Windows software package.     It was in the  TRANSGAMING.com   booth;  Transgaming makes ActiveX extensions for   WINE , and with those extensions,  many games run fine.  -- Heather                 Tnx Ben & Breen  Thu, 1 Nov 2001 19:47:22 -0700  William Laing ( wmlaing from home.com )     Ben & Breen  Thank you people who offered me help on loading modules, into the 6.2 system I havent got it right yet, but learnt something for sure. I dumped the system and will start from scratch again with a different card.  Thanks agn bill                  re Nov issue - Dennis Field article  Thu, 8 Nov 2001 10:21:37 -0500  Harold A. J. Isaacs ( chorales from ioip.com )    Would you kindly pass on to Mr Field that ""Lunux Canada"" seems to have exactly what he is looking for. It is not free, but moderately (compared with MS) priced. Certainly it is worth checking them out.     I found them at www.linuxcanada.com     They didn't have anything that interested me but they seem to have exactly what Mr Field needs.     Thanks for your wonderful magazine.      LG has received announcements from Linux Canada before about their POS products.  I sent the URL to Dennis, but I also noted that I couldn't get into the site when I retested it.  However, I can get into the site now.  I think Dennis is looking for more of a software solution, whereas Linux Canada is more geared toward special hardware.  But maybe Dennis will find what he needs. -- Mike       Thank you for your rapid reply.       So far as I know Linux Canada only sells software. There has (in the last 2 years) never been a suggestion of hardware sales or availability - only accounting and point of sale SOFTWARE.       The only time I have had trouble getting into their website was when the backbone was clogged, you could not even get anywhere in Canada then. You may have had a similar problem.       Harold A. J. Isaacs                    RE:Battle for the Desktop: Why Linux Isn't Winning  Mon, 5 Nov 2001 15:33:25 +0100  Ian Carr-de Avelon ( ian from emit.pl )       There are a whole series of relatively common problems related in this article, like applications software which does not run smoothly on all distributions and hardware which is not suported by a distribution, or sometimes by any Linux driver at all.     The real point is what can be done about this, and who should do it. The author, Dennis Field, seems to put the blame with the Linux distribution he chose. He, or his employer, paid them good money and so Linux should do what he needs it to do. There is nothing wrong with the logic of this, but the prospect of all distributions, or the most comercial distributions, or even one Linux distribution running out of the box on all old and new PCs is pritty well nill. Also even if that did happen, it would not get Mr Field to his goal of using Linux for the whole bookshop in one giant leap.     The problems which would need to be fixed even in this one ""case study"" are spread accrose the developers of: Linux kernel, X windows, StarOffice, and the distribution's firewall. Each of these have nowhere near the resources or assistance from hardware designers which Microsoft has, and yet they produce software which (on other criteria than out of the box installation on all PCs) far outperforms Microsoft's products. They have a right to pride in their work and respect from others, and simply calling for any of these teams to work harder till the problems nolonger exist would really mean accepting that Linux has lost, because even if the developers gave up all their free time, the extra improvement could never have the kind of impact which the author desires.     I have writen  elsewhere  (http://www.suite101.com/article.cfm/15359/84340) how I would generally advise SMEs to move towards Linux, but given the evidence of interest in building fairly complex systems at low cost, maybe we need a business by business (Bookshops, Chemists, Garages) Linux forum to give system integration with Linux the kind of boost which  Linux Documentation Project  (LDP) and sourceforge have done in other ways.     Yours  Ian      [Dennis also has  another article  in this issue. -Iron.]                  Re: Battle for the Desktop: Why Linux Isn't Winning  Fri, 9 Nov 2001 15:22:51 -0800  Robin Rowe ( Robin.Rowe from MovieEditor.com )     Dennis,     It is unfortunate that you had trouble installing Linux on your ThinkPad. You don't say what distros you tried, and each distro works a bit differently. Since installation troubles are really the domain of the distro and not the operating system itself it seems unfair that you name the problem as Linux but avoided naming the distros that actually caused you the trouble.     Have you tried  Debian  Linux? This is a very popular distro, supported entirely by volunteers. You could download the boot/root floppy images from debian.org, copy them on to two floppies, then boot and install a minimal Debian Linux OS. This is usually quite easy. After configuring your Linux network settings and adjusting your sources.list to point to the Debian download site you could then use dselect or apt-get to install the rest of whatever you want automatically over the Internet.     That you would have the troubles you did isn't too surprising. Most Windows users would have trouble in the similar circumstances trying to install Windows on their own for the first time without ever having used it before. A more realistic approach when installing Linux for the first time is to enlist the aid of other Linux users. Most Linux users groups host monthly installfests for this reason, so that new users get the install help they need from experienced hands. Had you done that I expect you would have had an operational Linux laptop within minutes. Another approach is to join the debian mailing list where anybody usually gets answers to install problems within a few minutes.     Your analogy comparing Linux to a Ferrari with no wheels is unjust. The wheels are right there, you just had a problem with your ""Some Assembly Required"" situation. You were not picking up your new Ferrari at the dealer, were you? If you were buying a new Thinkpad purchased from IBM with Linux already pre-installed (look under ""personal systems"" at www.ibm.com/linux) you should have no installation problems whatsoever.     Please let me know if I can be of any help to you installing Debian Linux on your laptop.     Cheers,  Robin                        GAZETTE MATTERS                   Re: new LG article: The Art Of Atari ST Emulation   Issue 13                 The distinction between Tips and Articles  Mon, 5 Nov 2001 12:15:23 -0800  Mike Orr ( LG  editor )  Part of a discussion with Matthias Arndt about his article this month      Articles go to  gazette@ssc.com  in HTML format.  Tips, tech-support questions and tech-support answers go to  linux-questions-only@ssc.com  in text format.     Basically, a tip covers just one simple topic in a screenful or two (or less). An article covers several subtopics under separate headings and/or is more than a couple screenfulls.     ... and Tips rarely involve more than one Answer Gang member's comments. I do like to use this rule of thumb: would the answer (possibly without explanation)  fit in a .sig block?  If not, it's probably not small enough to make a good Tip.     When the discussions get going even a short thread might go into TAG, and  some of the better long answers in TAG still aren't as long as a standard article.  I'd also like to remind people that for article submissions, we  prefer simple HTML to the font-laden stuff automatically generated by most  web browsers when ""mail as HTML"" is turned on. -- Heather                 Issue 13  Mon, 12 Nov 2001 11:26:28 +0100  Russell Coker ( russell from coker.com.au )    The following section isn't displayed correctly because you don't use &lt; and &gt; for the <stdio> part.           #include       main()       {               printf(""test\n"");               fflush(stdout);       }       They will not echo what I print.     Thanks Russell.  We don't generally go through the back issues  to correct things like this;  things have gotten a lot better  since then, and I'm proud to say that things have to be sneakier  that that to put bugs into our HTML code these days     -- Heather              This page edited and maintained by the Editors  of  Linux Gazette    Copyright ©  2001  Published in issue 73 of  Linux Gazette  December 2001   HTML script maintained by   Heather Stern  of  Starshine Technical Services,   http://www.starshine.org/           More 2¢ Tips!       Send Linux Tips and Tricks to  linux-questions-only@ssc.com        Command-line calculator   Apache startup script improvement   Re: De-enhancing text   Fun with chroot jails   Password list   DNS   using m-w online dictionary.   PacHell DSL w/LINUX   How we fixed ""FW-I/LINUX kmalloc"" problem   DSL Drivers for USB   gtkmm-config problem   newbie question --or--  Linux equivalent for Active Directory?   Re: [LG 72] 2c Tips #4 translated oddly                 Command-line calculator  Wed, 31 Oct 2001 22:40:27 -0500  Ben Okopnik ( LG  Contibuting Editor )    One of the things I've always found amusing is watching people working at a PC suddenly stop and go digging through their desk for a calculator. I mean, good grief - all that processing power, and they have to go back to the Stone Age! Well, if you're one of those unfortunates, suffer no more. Just put the following lines in your ""~/.bash_profile"":    calc(){ perl -wlne'print eval'; } export -f calc     The next time you log in (or if you source "" .bash_profile ""),  the function will be available to you.    ben@Baldur:~$ calc 3.141592653*6**2   # What is the area of a circle 6 meters across? 113.097335508 ( 3 - 117 ) % 7    # If today is Tuesday, what day was it 117 days ago? 5 sqrt(115) * 1.34   # Hull speed of a ship with a load waterline of 115' 14.3698990949832 ben@Baldur:~$     Note that I actually typed those comments into ""calc""; it chews and swallows them without a problem.     ""calc"" is actually a 'gateway' into Perl (via the ""eval"" mechanism); that makes it into quite a powerful gadget. It supports all the math/trig/etc. operations that are built into Perl - functions like ""abs"", ""atan2"", ""cos"", ""exp"", ""hex"", ""int"", ""log"", ""oct"", ""sin"", ""sqrt"", and even ""rand"" (rolling dice, anyone?)    ben@Baldur:~$ calc print int rand(6) + 1 for 1..20  # Roll 20 6-sided dice 6 1 6 5 3 5 3 5 1 1 6 4 6 3 3 4 1 1 1 4     ""calc"" can be as simple as you like - or provide you with the kind of power that calculators just can't match. It's all in what you choose to do with it. By the way, be aware: there's nothing in ""calc"" that restricts you to ""math-only"" commands; if you type ""unlink my_important_file"", Perl will happily obey your orders (i.e., delete that file.) So, as with everything in Linux, be careful - and have fun.       [Python's interactive mode can also be used as a calculator.   -Iron.]                     Apache startup script improvement  Mon, 19 Nov 2001 08:54:27 -0500  Allan Peda ( allan.peda from verizon.net )     Every thime I setup  Apache  I add two lines to the startup script to parse the config file for the variable containing the name of the file to store the PID at.     It seems logical to me to automate this, since the script has an entry for the pidfile, but really should also ""knows"" the location of the config file, why not parse any redundant information from it and remove the risk of conflicting parameters.     Here is what  I add to the /etc/init.d/apache start|stop script:     CONFIG_FILE=/etc/apache/httpd.conf PIDFILE=`sed -e '/^PidFile /!d; s/PidFile //' $CONFIG_FILE`     or for you bashers:      PIDFILE=$(sed -e '/^PidFile /!d; s/PidFile //' $CONFIG_FILE)     Also, I usually pass the name of the config file to apache explicitly, so that it's obvious via ""ps ef"" what configuration is currently being  used.     Seems to make sense to me.  In fact, I'd hope this makes it into the scripts included in the distro.      [JimD]  It's a good suggestion.     Personally I think the start-up (rc) scripts from most distributions are a bit lacking.  For example I've always thought that it was remiss of the start up script that mounts the  /proc  filesystems fails to check that the mount point is a properly empty directory.     In the case of your suggestion, you are eliminating what I call a ""moving part"" (an opportunity for different configuration elements from different sources to get out of sync with one another).     Of course there are many other failure opportunities which could be mitigated with additional tests.  For example: what if there are multiple PidFile directives? what if the case doesn't match your sed expression (doesn't  Apache  tread PidFile as equivalent to PIDFile, etc)?     [Ben]     The usual way that  Debian  does it is also fairly sensible. This is from "" /etc/init.d/skeleton "" (the template that you're supposed to use when writing an ""init.d"" script under Debian), by Miquel van Smoorenburg and Ian Murdock:    See attached  apache.init-d-fragment.txt    Any daemon, when started via this mechanism, gets an individual pidfile.     [JimD]     I think you miss his point.  Debian's rc scripts are no better than  Red Hat 's in this respect.  If one changes the PidFile directive in the .conf file, then Apache's notion of its PID file location disagrees with Debian's startup/shutdown scripts.     That could be reported as a bug to the maintainer --- but it's unclear how far we should go in making the rc scripts more dynamic. It would be a bit absurd to do comprehensive failure-mode analysis and mitigation for all of the rc scripts.  At some point we must just give up (maybe calling on logger -s to emit and error message).     The problem with making foolproof systems is that the universe keeps creating more ingenious fools.                 Re: De-enhancing text  Fri, 9 Nov 2001 12:16:23 -0800 (PST)  Thomas Adam (The  LG  Weekend Mechanic)  and Peter Dzimko ( dzimko from yahoo.com )   Richard Bly sent us:     Just in case you were not aware, the utility colcrt will take a man page output and format it without all the weird stuff. The underlining is put on the next line so both the text and the underline are visable.      [Thomas Adam] Why not just use the following......:    man manname | col -b > ./mymanpage.man     where ""manpage"" is the man page (obviously). The "" col "" command in this case (with the  -b  flag) will filter reverse line feeds.     There is also the option of using ""man2html"" for the adventurous......       Guys,     I think that following method is much simpler:    man thttpd | col -bx     Regards  Peter Dzimko                  Fun with chroot jails  Tue, 30 Oct 2001 13:21:58 -0500  Heather Stern ( The Editor Gal )   Ben asked:     There's one you could write up (assuming you ever got the time to do it, that is) - creating those ""chroot"" jails. That's something I'd love to have the specifics of; I understand the concept well enough, but having never implemented one, I'm short on the actual mechanics.     There's a fairly current  Freshmeat  entry called ""cage"".  Initial release. Not my stuff, but it's exactly the right idea - some support for a bash-shell centered chroot jail, so you can jail more complex apps a little more safely, e.g. make chroot a one way trip, nicking off a few linux-privs along the way.     Sounds like cool fun; I'll definitely check it out.     In the ""barely enough to run an app"" category, there's a helpful document for BIND, and a different one for Postfix, iirc, but I don't have their URLs memorized and I'm trying to avoid getting -too- distracted. (too late!)     <grin> I'll search for those some time this coming week...     There are a few patches and at least one kernel module (capsel) around now, that offer to stop the   chroot()  call from happening more than once, preventing the usual script-kiddy method of getting out of one, among their other helpful efforts.     Uh... what's the usual script-kiddy method? I mean, I know I can type 'exit' if I've started a regular 'chroot' without specifying a prog... but... maybe I'm not visualizing it right. I'm seeing a chroot jail as a ""system within a system"" - if you exit, you end up at a login prompt. That's it. Real ""root"" is only available via a different IP; in effect, you're logging into a different system. Correct?     Minimum Mechanics:     blank hard disk   install parent level with syslog, cron, ssh, sudo.   create subdirs for jail areas (e.g.  /home/HTTPD-jail ,  /home/MAIL-jail , etc.)   run installer again, using ""already mounted directory"". Once per jail of course.  Mhm. I wonder how hard it would be to create a stripped-down installer just for the purpose. Might make a nice project, don't you think?   tweak each jail like it was a seperate machine you could boot into normally that was dedicated to the purpose. Each jail's ssh must be on a unique IP address/port number combo.   grafting - setup top level so it runs services out of their jails, already chrooted there.   time to make an IPL backup   stripping - take more stuff out of the jails, that they will NEVER need because they are really not the top level after all.  e.g. fsck, copy of the kernel and modules.  This may require some brutal adjustments to the packaging systems so they won't get put back if you choose to upgrade the jails later.   Possibly make it so there should never be a need to be root inside the jail anyway.  etc.   time to make IPL backup #2, on a different media from #1.  Allows for return to this point, or to decide you went overboard and try shaving that differently by starting again from #1.     Eh... you lost me there on #6; that's the part I'm not seeing. What's the interaction mechanism between the two levels? How does the ""top"" see the ""bottom"" without the ""bottom"" seeing the ""top""?     I usually run a lot of things from  /etc/inittab  so they can be respawned if they die.     For #8 I agree, that's the way I would do it - since root can twiddle anything on the mounted filesystems, there shouldn't even be root access in there.  Although I would set up some sort of an ""admin"" account, with carefully decided powers.     Might be helpful to have more hard disks, or seperate partitions for each jail. I gotta stop procrastinating like this ;>     I'm glad you did.    Thanks - I'll dig  into it some more!                  Password list  Tue, 30 Oct 2001 08:49:40 -0500  Ben Okopnik ( LG  Contibuting Editor )    OK, so this is straight out of any security FAQ: whatever you do, _don't_ keep a list of your passwords on your machine. Right? Right.     Now, since you're going to do it anyway...     Here's a somewhat safer way to do it - note that I did not say ""safe"", just ""safeR"". The way I see it, those of you who don't keep one won't be affected, and those of you that do will notch up the security just a tad.     To make this work, you'll need something to keep your secrets for you:    See attached  pass.bash.txt     Here's what you do: put this script in a directory that's in your path, say "" /usr/local/bin "", then set the ownership and permissions as follows:    chown root:root /usr/local/bin/pass # You must be root to do this chmod 755 /usr/local/bin/pass  # And this, too     You now encrypt the file that contains your list of hosts, usernames, and passwords, one per line:    www.cia.gov  JohnDoe   cRYpTo www.kgb.ru  IvanIvanov  bOLsh0isEkRET www.mossad.il  PloniAlmoni  sHiN8eT kempeitai.jp  NanashiNoGombe  haITTeM0ikEmAsEN www.mybroker.com FulanoMengano  QuIenSaBE www.mybank.bm  MattiMeikalainen sAipPUakAuPPIAs www.centralbank.an JanModaal  fInanCIeeL    ...with a command like:   crypt My1SecretPasswD < mysecrets > ~/pass     Move the original (""mysecrets"") to a floppy and put it somewhere safe (yes, that usually means where nobody - not even you will ever find it again.   . Remember to update it once in a while. As to the encrypted file, all anyone is going to see when they look at it (you did set its permissions to 0600, right?) is a bunch of binary-looking gobbledygook.     Now, let's say you want to see what the combo is for ""mossad"". Easy enough:    spy@Hideout.com:~$ pass mossad Enter password (screen echo disabled): www.mossad.il  PloniAlmoni  sHiN8eT spy@Hideout.com:~$     If you want to edit the file, just type "" pass -e "";  this will invoke your editor ("" $EDITOR "" - ""vi"" by default)  on the decrypted version of the file.     ""grep""-related tip: if you want to just see the entire file, call it as    pass $                   DNS  Sun, 11 Nov 2001 12:21:43 -0900  Heather Stern (The Editor Gal)  and Faber Fedor ( The Answer Gang )   David Menegat asked us the following:     I am trying to set up a name server on my mandrake 8 system and I believe I installed the dns package I just don't know how to configure it do you know where there is a faq or have any advice for me.  I just bought a domain name and this is the last piece in the puzzle before the final configuration and I transfer the name to my machine.     Thank you David Menegat      [Faber] Well, there's always the HOWTOs:  http://www.linuxdocs.org/HOWTOs/DNS-HOWTO.html         [Heather] There's also the absolutely marvelous resaources of ""Ask Mr. DNS"".     Although Acme Byte and Wire was bought by Network Solutions, there still  exists his marvelous archive of detailed answers to how DNS works:        http://www.acmebw.com/askmrdns        If that doesn't answer what you need, you can also ask him questions directly at his current email address... which I won't tell you, you'll have to read his archive first      BTW as far as I can  tell, he only answers questions for DNS sites which he can access, so he can  see what things are resolving like.     We hope it helps!  Let us know if Linux itself has any extra questions for you, or there's a spot in the DNS-HOWTO we can explain a bit better for you.  We want it to make sense           To which David replies:     Thank you very much I'm sure I'll have no problem now  thank you  David Menegat                 using m-w online dictionary.  Mon, 19 Nov 2001 21:30:59 -0500  Matt Giwer ( jull43 from tampabay.rr.com )     looking up words in the m-w dictionary. I thought you carried this about a year ago.     create a file named def containing    # def <word> goes to Mirriam Webster page of it definition lynx "" http://www.m-w.com/cgi-bin/dictionary?book=Dictionary&va=$* ""     used as    def word                  PacHell DSL w/LINUX  Sat, 24 Nov 2001 20:47:32 -0800   ( j_on_e from sbcglobal.net from sbcglobal.net )   (linux-questions-only@ssc.com)   Johny asked us ... in quoted-printable, and in HTML:    Im a newbie to Linux but want to lear really bad. Im tired of the  limitations in Windows. Anyway, I just installed OpenLinux eDesktop2.4   Caldera  Systems and want to know  how to configure it for use with my  PacBell DSL using an Efficient Networks SPEEDSTREAM Modem.   a.. 5260 ADSL (ITU Annex A)   a.. 5260: G.DMT, G.Lite, T1.413 (ADSL)   I cannot find a driver or figure out where to configure or how to  configure all of this to work so that I can get my linux online. Please  help or forward this to anyone and everyone who may be able to help me  out.  Thank you very much for your time and I hope I can get this going  very soon.     First, please send mail in text format rather than text+HTML.     External DSL modems (that connect to an ordinary Ethernet card via an Ethernet cable) work fine on Linux.  Internal DSL modems are iffy, especially if they're USB.  It all depends on whether the manufacturer provides Linux drivers or gives us enough of the card's specs to enable us to write a driver or expand one of our existing drivers. Unfortunately, there are so many different types of DSL modems and none of them are as widely used as the different analog modems, so drivers are less likely.     Also, there are analog modems called ""Winmodems"" that are marketed as real modems but they actually have part of their hardware missing. The missing portion is handled by the Windows driver.  These didn't run under Linux for several years, until some Linuxers reverse-engineered them enough to make drivers for at least some of them.  I don't know whether DSL modems have an equivalent to these ""Winmodems"", but you have to watch out for that possibility.  Especially if the DSL provider ""supports only Windows"".     If your modem is new enough that you can return it and get an external modem instead, that's your best bet.  It may cost $100-200 more, but it will be worth it because the modem will be more standards compliant, meaning fewer headaches in the future when you upgrade, move or switch systems.     I'm not sure if DSL has fallen victim to the ""sahave off chips to save  a few cents a motherboard"" craze.  On the other hand, there's PPP over Ethernet (pppoe) to run away from.  Even though you in theory would get full ethernet bandwidth, in practice that protocol slows you down to PPP speeds deliberately. Some very knowledgeable sysadmins I know go  directly into ""rant mode"" when just hearing the acronym. -- Heather               How we fixed ""FW-I/LINUX kmalloc"" problem  Thu, 1 Nov 2001 17:36:28 +0200  Vitaly Karasik ( vkarasik from ndsisrael.com )    It may be too small for article and too big for letter, but I hope it will useful for LINUX/FW-1 administrators and provide a good example of  OSS advantages.     Regards,     Vitaly Karasik Unix System Administrator Israel     But it's perfect for a 2 Cent Tip.  -- Iron    ---- We've tried to replace our NOKIA FW-I box with LINUX one [FW-I v4.1 SP4 + RedHat 6.2  2.2.19 kernel].     Installation was pretty strainforward, but every time when we tried to install policy from our management station we got few messages in /var/log/messages:     /var/log/messages.4:Oct  5 14:29:42 fw kernel: kmalloc: Size (786540) too large /var/log/messages.4:Oct  5 14:29:42 fw kernel: kmalloc: Size (786636) too large /var/log/messages.4:Oct  5 14:29:42 fw kernel: kmalloc: Size (789660) too large     Our policy contains about 90 rules & 400 objects with few VPN.     Short search with Google  pointed us to a few  letters with the same problems, but didn't help to solve the problem. (for instance, ""[FW1] Strange things in RH62 + Fw1-41-Sp2( kmalloc: Size (275548) too large )"" thread on  http://www.firewall-1.org/2001-01/maillist.html )     According to skl1314 from Check Point SecureKnowledge, ""solution is currently not available. Issue under investigation"".     But this search helped me to understand what is exactly the problem: FW-1 call ""kmalloc"" function in order to get block of memory. But linux's kmalloc [kernels 2.2.x  & 2.4.x]  knows to allocate memory in blocks 2K,4K, ... 128K only. And FW-1 in our case  wants to get ~800 K memory.     The solution:     I fixed slab.c in order to increase kmalloc limit from 128K to 1280K. Diff from orig slab.c  for kernel 2.2.19  is below:     298c298 < #define SLAB_OBJ_MAX_ORDER 8 /* 32 pages */ --- > #define SLAB_OBJ_MAX_ORDER 5 /* 32 pages */ 301c301 < #define SLAB_MAX_GFP_ORDER 8 /* 32 pages */ --- > #define SLAB_MAX_GFP_ORDER 5 /* 32 pages */ 345,347d344 <  {262144, NULL}, <  {524288, NULL}, <  {1048576, NULL}, 370,374c367 <  ""size-131072"", <  ""size-262144"", <  ""size-524288"", <  ""size-1048576"" < --- >  ""size-131072""     After compiling & installing new kernel we're able to install fw policy without any problem.                 DSL Drivers for USB  Mon, 5 Nov 2001 13:18:19 -0500  Andy Fore ( arfore from valdosta.edu )    This is in answer to the question about USB DSL drivers for Linux.     There are drivers out there for the Alcatel SpeedTouch USB. The SpeedStream 4060 is actually made by Alcatel.     I have setup the SpeedTouch in RedHat 7.1 and gotten it to successfully work on my home network.     Andy Fore  Computer Services Specialist III                  gtkmm-config problem  Mon, 26 Nov 2001 07:09:04 -0500  Dann S. Washko ( The Answer Gang )    When testing the gtkmm hello world code on this page I get errors:  http://gtkmm.sourceforge.net/tutorial/sec-gettingstarted.html      bash-2.05$ g++ test.cc -o test `gtkmm-config --cflags --libs` In file included from /opt/gnome/include/gtk--/base.h:34,  from /opt/gnome/include/gtk--/object.h:30, from /opt/gnome/include/gtk--/widget.h:32, from /opt/gnome/include/gtk--/container.h:27, from /opt/gnome/include/gtk--/bin.h:27, from /opt/gnome/include/gtk--/button.h:27, from test.cc:2:  /opt/gnome/include/gtk--/proxy.h:6: sigc++/signal_system.h: No such file or directory /opt/gnome/include/gtk--/proxy.h:7: sigc++/bind.h: No such file or directory /opt/gnome/include/gtk--/proxy.h:8: sigc++/convert.h: No such file or directory test.cc:4: `#include' expects ""FILENAME"" or <FILENAME>     For some reason (I believe) something is not getting passed to look for the  sigc++  headers in  /opt/gnome/include/sigc++-1.0/sigc++ .     I was getting more errors about not being able to find  sigc++  headers before I added  -I/opt/gnome/include/sigc++-1.0/sigc++  to the  gtkmm-config file.  Without this line or taking off the  sigc++   directory, produces more errors about not being able to find the headers  in  sigc++ .     The sigc-config file looks just right.     Furthermore, this all started when I tried to compile quickedit.  During the configure process I received and error that gtk-- was not installed correctly and/or I should edit the gtkmm-config script to correct anything off in there.  Viewing the config.log shows the same error as above.     ... after a bit of fighting with it ...     The problem must have been with gtkmm-config or the gtkmm packages I had originally installed.  I compiled gtkmm from the sources and everything appears fine.  Quickedit compiled without complaint.  I noticed the one line in the new gtkmm-config that was not in the old was -I/opt/gnome/lib/sigc++-1.0/include.  I had mistakenly put this in the libs area instead of the cflags.  I'm not sure whether this was the whole crux of the problem though.     -- Daniel S. Washko Lehigh Valley Linux Users Group www.thelinuxlink.net/lvlinux get slack (www.slackware.com ) and get happy               Linux equivalent for Active Directory?  Tue, 30 Oct 2001 11:39:30 -0800 (PST)  Craig Baker ( ctbaker78 from yahoo.com )     Ok Im just learning Linux so bare with this question...I know in Windows 2000 Server you can create a Active Directory and install a Distributed Files system...what would be the Linux counterpart to this be?  I've poored over alot of FAQs but I must not be looking for the correct terminology.  So far the closest Ive found is NIS/NIS+ with NFS.       Take a look at LDAP (i.e., where Microsoft got the original idea) - OpenLDAP < http://www.openldap.org > has some good info on their site; their ""General LDAP FAQ"" is worth a read. As well, Jeff Hodges ""LDAP Roadmap"" < http://www.kingsmountain.com/ldapRoadmap.shtml > is an excellent resource. Novell with their NDS (Novell Directory Services) had an early jump at the idea of abstracting the directory structure from the FS; chances are pretty high (I'm making a guess here - I don't know  Caldera  that well) that Caldera, being a Novell ""sister"" company, supports it. To confuse the tangled skein a bit more, Novell has released the JLDAP (the LDAP class libraries for Java) to the world - I haven't done Novell stuff in years, but I would guess that LDAPv3 is what they're using these days. There might be other implementations of the idea, but the key words, rather than ""Active Directory"", would be ""LDAP"" (Lightweight Directory Access Protocol) and ""X.500"" (the protocol that defines LDAP.)                  Re: [LG 72] 2c Tips #4 translated oddly  Mon, 19 Nov 2001 11:31:10 -0800  Marcelo E. Magallon ( marcelo.magallon from bigfoot.com )    Hi,     I think the translation of the original message is wrong.  The original poster is asking about a content manager, not an editor.  Here:     información acerca de algun manejador de PHP con el cual pueda modificar los archivos de páginas de internet bajo Linux  Red Hat  7.1     Even if the Spanish translation of several computer terms varies wildly across countries, I can't imagine a place where an 'editor' would be called 'manejador'.  This word means 'manager'.  Even if it's not clear what the original author actually wants or needs, I think he's thinking of something along the lines of Midgard, available at  http://www.midgard-project.org .     If the original author does mean an editor, Heather is right on the spot: vim, in particular vim 6, has some nice features, like improved syntax definitions and folding, that make editing of HTML and PHP files much easier.     HTH,  -- Marcelo      Thanks Marcelo. The original querent never wrote back to tell us what he was looking for, even after we asked him.  So I'm inclined to think he's either already found what he needs, or it's his fault if we misunderstood it. But we've published your tip for other readers. -- Iron                 This page edited and maintained by the Editors  of  Linux Gazette    Copyright ©  2001  Published in issue 73 of  Linux Gazette  December 2001   HTML script maintained by   Heather Stern  of  Starshine Technical Services,   http://www.starshine.org/                         The Answer Gang           By Jim Dennis, Ben Okopnik, Dan Wilder, Breen, Chris, and the Gang,  the Editors of Linux Gazette...   and You!  Send questions (or interesting answers) to   linux-questions-only@ssc.com     There is no guarantee    that your questions here will  ever  be answered.     Readers at confidential sites    must provide permission to publish.  However,    you can be published anonymously   - just let us know!    TAG  Member bios       |  FAQ       |  Knowledge base         Contents:     ¶: Greetings From Heather Stern        clock setting   device drivers   fine-grained delay in shell scripts   Serial Programming on an i486 in Linux   Shut down when turn computer off   slib installation   SuSE 7.1 installation CD not recognized   Installing tulip.o in 6.2   Just wondering           Greetings from Heather Stern      Hi everyone and welcome!  This month I hope you like the threads I've selected for you, nice, juicy, full of meat...    Hmm, I wasn't expecting to make that sound like the turkey dinner I had last week.  Oh well!  I hope you had a good Thanksgiving, and of course we all wish you the best for the winter season too.    Now on to the nitpicking     By a  HUGE  margin the Peeve of the Month is poor use of the subject line.  It so happens that we had really high traffic on our  administrative list -- something to do with the   new FAQ  and knowledge base getting posted, everybody give a big hand to Ben and Chris!  -- but, we actually got more slices of mail with useless subjects, totalling about a fifth of the overall mail for the month.    What do I mean?  Well, I'll put it the same way Ben does.  You have only 40 characters (in most mailers).  Don't waste them on things like ""Help me"" (why else would you be mailing us?  Hoping to frame our most creative flames?) and ""Linux problem"" (good, you have the OS we know best) or even, cheerful though it makes us, ""Hi  Gazette ""  (yep, that's us, you reached the right place).    Even worse is people who have no subject at all.  Now it's true that with so many helpful souls in the Gang a lot more of the questions get answered nowadays.  But, my statistics show that about two-thirds of the messages with no subject were utterly ignored.  Not even a worn out match starting a flame.  Nada, zip, zilch.  So you really hurt your chances of getting  anything more than a lump of coal in your stocking by not having a real  subject on your questions for The Answer Gang.    So, the trick is, make sure your subject contains at least one noun or verb that relates directly to the question.  ""SuSE install""  or ""wheelmouse woes"" or something, so we can guess if that message is something we know about, so we can leap into the fray.    Okay, now what can I say about Linux?   Well, let's see.  It'd be a great x-mas present to see that 2.4 kernel stabilize now that 2.5 is properly set up.  (I'd go for ""peace on earth"" but it seems to be making a nasty hole in the stocking, darn it.) I already lost my bet that it'd be  2.4.14 that would win.  What I really want is one of those 21"" studio LCDs  but, I'm broke this season, so I'll probably have to make ""21 inch diagonal"" my New Year's Resolution.  <brickbats appear from offstage>  hey!   watch it!  You trying to break my old monitor?  That's it for now.  Whatever you do this season don't forget to  Make Linux A Little More Fun .      Jim and I will be at the annual Large Installation System Administrators conference in San Diego, the first week of December.    USENIX  always has a great seminar track, plus a lot of the developers we've gotten to know personally are regulars. If you can afford it, I highly recommend going.  If you are going, perhaps we'll see you there.    Failing that, see you next year...             clock setting     From Bryan Henderson             Answered By  Bryan Henderson     By this odd chance, the Gang get to be the querents, and we have a real guru to answer our clock questions at hand.  Thanks Bryan!  -- Heather       As the maintainer of the main Linux hardware clock managing program, Hwclock, I found the Answer Gang discussion and survey of daylight savings time switches and other hardware clock issues enlightening. I'd like to add some important information.       [John Karns]  Thanx for your contribution!  I for one really appreciate it.       [Ben]  First thing, Bryan - thank you for the info, as well as for the very useful job that you're doing!       [Mike]  Yes, Bryan, thanks for taking the time to write that explanation, and for offering to debug distribution-caused problems.        First, let me state that the _only_ sane reason to keep your hardware clock in local time is if you sometimes run Windows on the machine. Windows isn't capable of using a hardware clock in any other format. Unfortunately, local time is Hwclock's default and the default that  Red Hat  and I believe other major distritbutions ship.       [John K]  How about time zones where daylight savings doesn't apply?        Then it's less insane to keep your hardware clock in local time, but still not sane.       [Ben]  I certainly appreciate it; I'm sure that a number of our readers do as well. One of your tips in here - the persistence of ""UTC"" - has already let me figure out why my localtime was ""backwards"" (i.e., 5 hours earlier instead of later) if I set the hardware clock to UTC. I don't use Windows, but I do travel quite a lot, which means I have to keep changing time zones; do you have any advice or pertinent info for doing this        First of all, of course, keep your hardware clock in UTC format. Whenever you enter a new timezone, do a quick 'ln' command to link  /etc/localtime  to the descriptor for your new timezone.       [Ben]  Ah,  so . Actually, I've often thought of writing up a ""Mobile Linux"" article - a sort of a HOWTO for traveling with Linux - and you've just cleared up one of the last pieces of the puzzle.  Tres  cool. For those folks who need to bounce around as I do, here's something that'll be useful:    See attached  chzone1.bash.txt    This script will present you with a menu of choices for the Eastern, Central, Mountain, and Pacific timezones. Pick one, and you're set.        The  /usr/share/zoneinfo/US  directory may be more appropriate here.       [Ben]  Odd. The entire ""tz*"" suite (tzselect, tzconfig, etc.) uses the ""America"" version. <looking at the contents of 'US'> Ah. OK, that seems to make sense - at least you'd be setting the timezone by name (   I'd spent a few minutes hopscotching through ""tzselect"", back and forth, back and forth, to figure out which cities it used for which zones.) So, here's an updated version of ""chzone"" - this one actually covers a wider range but keeps the choice list down to the actual zones rather than the (possibly confusing) list of cities:    See attached  chzone2.bash.txt       The C library (GNU libc 2) looks at  /etc/localtime  for the description of the local timezone.  That can be a symlink to the relevant timezone descriptor in  /usr/share/zoneinfo.   (I use US Pacific Standard/Daylight time, so I link to  /usr/share/zoneinfo/US/Pacific ). If you don't have descriptors for every timezone known to man in  /usr/share/zoneinfo  (5 MB of them come with glibc -- having them all installed appears to be ""normal""), you'll have to install them per your distribution.  Sometimes they are in  /usr/lib/zoneinfo.      Note that changing timezones doesn't cause any time discontinuity. You aren't changing the clock, only the language your system uses to communicate to humans about what time it is.       [Ben]  ... (hopefully, without screwing up "" /etc/timeadj "") other than setting the TZ to the appropriate value? Are there any non-obvious issues with the clock that I should be aware of when I do this?        You change your hardware clock to UTC by adding the --utc option to any clock-setting 'hwclock' command.  You only have to do it once, because your choice gets saved in  /etc/adjtime  and becomes your default in the future.     The major practical drawback to keeping your hardware clock in local time is that in most locales, local time jumps an hour twice a year. The hardware clock is incapable of implementing that.  So you have to explicitly reset the hardware clock twice a year.  Windows does that automatically.  In Linux, you can do it with a startup script and/or cron job, but I'm not aware of any Linux distribution that does it out of the box.  If you're running both Linux and Windows, though, I think both would make the adjustment!       [John K]  In my case, the time doesn't change, as I'm near to the equator.        Actually, the time doesn't change for anybody; only the local time representation does.           [John K]  OK, but I think you understand what I'm saying - daylight savings time doesn't exist here.       [Mike]  Where do you live?  Indiana?     Why are there not timezone configurations for those locations, and if they're not, how hard is it to copy one and modify it to disable the DST?        He said it's near the equator, and he didn't say he can't do timezones the normal way (in fact, he probably does).  He just pointed out that it isn't as advantageous to him as it is to most the world to keep his hardware clock in UTC format, because one of the advantages of UTC format is that you don't have to reset your hardware clock for DST changes.       [John K]  Also, the Linux based distributed network I'm setting up, at this time is all contained within one time zone.  Thus, I haven't felt compelled to leave my hw clock set for utc.  I did try it once on my personal laptop, (sans the --utc option though - I probably used hwclock to set the time, but can't remember all the details) but didn't like the fact the timestamps on my files (ls) were not in agreement with the time as displayed by the 'date' command        The hardware clock format doesn't affect ls and date displays -- unless there's a bug in the system, of course.  I do often see people configure their machines for the wrong time zone and then keep the hardware clock set to the wrong time to compensate.  This causes some displays to be correct, but always causes something else to be broken.       [John K]  I've never done that or even considered doing it, as I can see where it could really distort parts of the system and create havoc.  What I'm trying to say here is that, well let me give an example:         Local time is 1pm   I create a file   I do an ls, which shows the file with a date-stamp that's skewed e.g., 6 hrs from local time.       Thus I constantly have to do mental arithmetic to figure relate these times to my frame of reference, which is local time.  It's particularly undesirable when those 6 hrs spans midnight, so the date-stamp shows a different day.        And every once in a while you see a program that chooses to display times in UTC (because it's easy).  If you lie to your system about what time it is, you can trick that program into displaying local time!  But that breaks other programs.  If you then lie about what time zone you're in, those other programs start appearing to work, but still other things break.  It usually falls apart as soon as you try to communicate to the rest of the world, for example email timestamps.       [John K]  - it tends to make things a little bit confusing.  So I changed things back to local time.     I do also run Windows but mostly via VMWare on a Linux host.  Do you have any info or input in regards to that scenario?     My main concerns are these:     The distributed net that I'm setting up could eventually span outside of the local time zone.  When and if that happens, it might make sense to use utc.        If we're still talking about the hardware clock internal format (UTC vs local time), I don't think the issues change when you expand into multiple time zones.  Using local time shouldn't be any worse than with one time zone, since Hwclock does all the work of converting between Unix standard format and hardware clock format.       [John K]  I have read about the Unix standard format and more or less know what it is, but don't really understand the big picture here - how all the parts fit together.        But if you mean set the timezone on all the machines to UTC so that displayed times are the same on all systems, that's a separate question.       [John K]  But the LANs are a heterogeneous mixture of W9x and Linux clients with a Linux server providing application sharing and Internet gateway services.  I wish to use samba for W9x file sharing and login  /  user profile control, as well as run a batch file to sync the clocks on the w9x clients to the server clock.  In short, I want to have all clocks more or less synchronized.     I don't quite follow you here - ""displayed times""? .. what about syslogd? My concern is mostly with file date-stamps, and system logs.  Lets say I'm examining a system log of a remote system located in a different time zone.  I would like to avoid confusion about when specific events may have happened in relation to my local time - and this would be my principal motivation for using UTC.  For example, I will have a ""master server"" which will be doing telephone dialup to remote hosts to exchange mail, collect system logs, etc.  I would like to have the master server log timestamps of the dialup session agree with those of the remote system logs, rather than all be skewed one or two hours.  Same with file creation & modification timestamps.  I will likely have a Perl or bash script run via cron on remote systems to collect all files of interest having a date-stamp falling within a certain time period.     My understanding prior to the test I did at least a year ago when I set my hw clock to UTC, was that such date-stamps would be shown (e.g., via ls) as local time, but UTC would allow for a standard that would put all systems using it on an equal level, and would help to eliminate confusion regarding date-stamps on files between different systems.  But that didn't seem to be the case - it simply added more confusion.        The usual way to do that is with an ntp network (run ntpd on all the systems.  Have a master ntp time server that gets time from some higher authority and distributes it down to everyone else).  Don't use Hwclock at all (I mean it -- if you set the hardware clock manually even once, the system won't maintain it automatically after that).       [John K]  That's what I have been thinking - sync the ""master server"" clock via NTP (ADSL has just recently been introduced here, so now a full time Internet connection is possible); then use a system util such as ntpdate or rdate (samba logon batch files for the other OS) to sync all other clocks to the master.  Since my ""WAN"" will be mostly dialup, using the NTP daemon an all servers is not possible or practical.     I still have questions about UTC re: W9x and other flavors under VMWare. I guess a little experimentation is in order.     I hope that I haven't rambled too much, and thanx for your input.     Any thoughts you might care to express about this would be greatly appreciated.        Regardless of in what format you keep your hardware clock, the display of the time by 'date', 'ls', etc. is controlled by the time zone settings as defined by the C library (e.g. the ""localtime"" function). Remember, the time does not change each Spring and Fall -- only what we call the time changes.  Properly configured, the C library routines generate daylight savings time in Summer and standard time in Winter. The underlying clock is oblivious.       [Ben]  Is the above configuration anything that needs to be done by the local admin/user, or does the above mean ""properly configured by the author/maintainer/etc of the C library""?        It's C library installation options, like the  /etc/localtime  setup mentioned above.       [Ben]  Hm. All I can do is hope - now that my hardware clock presumably resembles something normal - that the  Debian  installation options are right. Heck, I'll even go so far as to disable my ""spring forward, fall back"" cron jobs.    I'm a brave soul, I am.        The original querent was having trouble with Ls displaying times in UTC instead of local time in Red Hat 6.1.  I've dealt with those messy time zone problems (There was a totally different way of doing time zones before Red Hat 6.0, by the way, and the conversion wasn't perfect) many times, and I'd be happy to debug this problem for anyone who is having it.       [John K]  I'm a bit fuzzy on this issue too.  What is the expected  /  intended system behavior in this regard?  If I set my clock to UTC, and specify hwclock's --utc parm as you have suggested, then the system should compensate in such a way that the ls command would show timestamps reflected as *local time* - or UTC?     I suppose that the system always stamps the files in accordance with the Unix standard format, and it is up to the various parts of the system (ls, tar, and the like) to do conversions in relation to either UTC or local time.  What I interpret you as saying is that there have been instances where these various progs are not in agreement concerning the method with which these conversions are done.  Am I Correct?  I guess it's time for another try at setting one of my boxes to UTC to find out what.     I think this was what I was experiencing as well ( SuSE  6.4).       [Ben]  A very cool offer indeed - you can't get much better than that if you're having problems with the above. I'm not, but - Bryan, my job takes me to the Bay area on a fairly regular basis; I'd be more than happy to stand you a beer if you're interested, on behalf of all the folks that need and appreciate your help.        I'd love to.       [Ben]  Excellent - I'll be up there, let's see <rummaging> the first week of next month <waving at Jim and Heather>. See you then!     (Hmm, perhaps the ""beerware"" concept is outdated. If all of us bought beers for all the authors and maintainers, there wouldn't  be  any more authors or maintainers - not sober ones, anyway. And where would we be then?        Down at the pub, nursing a few sharp ginger beers, or root beers if you like them better, until the Guiness wears off and we're safe to drive home.     -- Heather            device drivers     From ranjeet k s             Answered By  Dan Wilder, Udo Puetz, Mike Orr     to sir,     thanks for reply i wanted to know information regrading linux device drivers books or manuals pages from net and tcp/ip for professional people.     thanks ranjeet       [Dan]  You've reached a mailing list administrative address.  I'm forwarding your query to the < linux-questions-only@ssc.com > mailing list.     You might try a search for     linux device drivers     on  http://www.google.com      I just tried it and got 304,000 matches, of which most of the matches in the first two pages (as far as I got) looked worthwhile to visit.       [Udo]  Hi!     You could download ""writing linux device drivers"" on the oreilly web-page (www.oreilly.com) some time ago (I think 2-3 months ago). This was not the last release, but hey, it's for free and online          [Mike]  There was an article about writing device drivers recently in LG:      http://www.linuxgazette.com/issue69/mathew.html      This article is about a PC speaker driver, but it serves as a general example.  Republished from Linux.com with theirs and the author's kind permission.  I requested this article for LG because we had a need for articles on device-driver programming.             fine-grained delay in shell scripts     From Ben Okopnik         Answered By  Thomas Adam, Mike Orr, John Karns     So, you're writing a shell script, and you want to add a little pizzazz: you know, a little blinking indicator, or a slow display that prints out ""Please wait"" one letter at a time or something. You look around, and the only choices you've got are a) ""sleep"" (a minimum 1-second delay), or various strange things involving loops and ""cat""ting large files (which makes you CPU usage shoot up into the 90% range.) Blechhh. What's a poor but honest scripter to do?     Farm the job out, of course.    See attached  nap.pl.txt    It doesn't get much simpler. ""nap"" will give you a delay in milliseconds, plus a tiny machine-dependent fudge factor for starting Perl. Here, as an example, is that famous ""rotating dash"" indicator, using ""nap"":     while :; do for x in - \\ \| /; do printf ""%c\b"" $x; nap 100; done; done       [Thomas Adam]  Tut tut Ben. For this kind of use, I  always  tweak the millisecond usage of the command:     ""usleep""     Then I can use a for i in....loop and a usual ""echo"" in Bash.     Works everytime.     But, I prefer your script!!           OK, I'll admit my ignorance - what's a ""usleep""? There's nothing like that on my system, or indeed in the  Debian  ""Contents-i386.gz"" file list. Please enlighten me. (I do seem to _vaguely_ remember something like that in C, but that's less than helpful.)       [Thomas]  But, I prefer your script!!              Well, you got _something_ useful out of it. That's a plus.       [Mike]  ..From ""man 3 usleep"": ""The    usleep()   function  suspends  execution of the calling process for usec microseconds.""     It looks like it's available only as a C function.  Somebody should wrap it up in a command.        <smirk> I did.       [Thomas]  ....and they did just that   . I  believe  that on RedHat systems, it was supplied as part of the ""initscripts"" rpm, thus:      http://www.rpmfind.net//linux/RPM/redhat/7.2/i386/initscripts-6.40-1.i386.html      /sbin/usleep     is where  my  copy resides (despite the fact im running  SuSE  7.1 professional).     Hope that helps       [John K]  No such animal on my SuSE 7.2 install ...     jkarns@jkInsp8000:~ > locate usleep /home/jkarns/Dwnlds/Linux/XScreenSavers/xscreensaver-3.32/utils/usleep.c /home/jkarns/Dwnlds/Linux/XScreenSavers/xscreensaver-3.32/utils/usleep.h /home/jkarns/Dwnlds/Linux/XScreenSavers/xscreensaver-3.32/utils/usleep.o /usr/share/doc/packages/mod_php/doc/function.usleep.html /usr/share/doc/packages/phpdoc/manual/function.usleep.html /usr/share/man/allman/man3/usleep.3.gz /usr/share/man/man3/usleep.3.gz        As I'd mentioned, it's not part of Debian - whereas Perl is in every distro. I'm sticking with portability.    Besides, when would you ever need microsecond precision in a shell script? Even milliseconds is splitting it frog-hair fine.       [Mike]  You don't, but sometimes you want to delay for a quarter second or half a second.        BTW, ""usleep"" isn't described in ""libc.info.gz"", either - although there's an interesting-looking ""nanosleep"".             Serial Programming on an i486 in Linux     From V Sreejith                 Answered By  Chris Gianakopoulos, Ben Okopnik, Heather Stern     hi all,     This is my first posting. Here I have a problem related with linux serial programming in C.Hope u can help me in this.     I have a C program that communicates with a remote terminal unit via serial port.The program uses termios structure to initialise the port. The program works as expected in kernel version 2.4.2-2 on an i686 macine.     This same program when tested on a 586 (Kernel 2.2.14-12 on an i586) machine fails to read the port properly. Writing to the port was working properly. The setserial and stty commands produced the same result on both machines.       [Chris G.]  What does ""failing to read the port properly"" mean?  Do the data look rather odd?  Does it look garbled?        Later i found that minicom(communicating with hyperterminal in windows) also showed the same problem while reading the port on the 486 macine. Writing to the port was working properly. Communication was proper when hyperterminal was used on both sides.     Here is the o/p of the setserial command.     /dev/ttyS0, Line 0, UART: 16550A, Port: 0x03f8, IRQ: 4  Baud_base: 115200, close_delay: 50, divisor: 0 closing_wait: 3000 Flags: spd_normal skip_test     and here is the settings on the port using stty command while my program is running.       [Chris G.]  I am guessing that your baud rate is 115200 baud.           speed 9600 baud; rows 0; columns 0; line = 0; intr = ^C; quit = ^\; erase = ^?; kill = ^U; eof = ^D; eol = <undef>; eol2 = <undef>; start = ^Q; stop = ^S; susp = ^Z; rprnt = ^R; werase = ^W; lnext = ^V; flush = ^O; min = 1; time = 0; -parenb -parodd cs8 hupcl -cstopb cread clocal -crtscts -ignbrk -brkint -ignpar -parmrk -inpck -istrip -inlcr -igncr icrnl ixon -ixoff -iuclc -ixany -imaxbel opost -olcuc -ocrnl onlcr -onocr -onlret -ofill -ofdel nl0 cr0 tab0 bs0 vt0 ff0 isig icanon iexten echo echoe echok -echonl -noflsh -xcase -tostop -echoprt echoctl echoke       [Chris G.]  I am guessing that your baud rate is 9600 baud.        If anybody knows what is creating the problem... please do help..     regards, sree       [Chris G.]  Hey Sree, Are you running both sides of the link at the same data rate?  The parameters that you displayed give me the indication that the data rates are not the same.     When you type on one terminal, do you see anything displayed on the other terminal?  If they are different, one cause could be mismatched baud rate. Your stty parameters seem okay -- if they are not, someone else will probably jump in and correct me.     Get back to me (at you convience of course), and let me know what you see on the displays.     I hope that this helps, Chris Gianakopoulos        hi chris,     I think this isn't the problem of the code as this same code is working as expected in an i686 machine.       [Ben]  I agree with you here, Sree; if ""minicom"", etc.  are having problems, then your programming isn't what's at fault - it's ""lower down"". That could still mean that there are problems with the baud rate, however - the ""lower down"" part means anything from the serial port settings, through hardware initialization, to actual hardware problems (the last of which you've eliminated by trying it in Wind*ws.)        So it couldn't be the problem of baudrate,parity etc. Ofcourse my baudrate is 9600 and the stty command showed that i have initialised the port as expected.stty command showed the same o/p for i686 and i586(not i486 ..sorry for the mistake).       [Chris G.]  That's ok.  If you are at the same baud rate, you might expect things to work.       [Ben]  Why the ""of course""? I almost always set my port speed to 115200. One of the few exceptions is when I'm reading from my Minolta Dimage V camera: it will not work with anything past 38400.     Have you tried your program on another 586, preferably a different make and model? It could be that the serial hardware on that specific machine is wonky, or that it's sufficiently strange that the serial driver is having problems. I would also urge you to study the ""setserial"" man page; if indeed the driver is having problems, ""setserial"" gives you _tons_ of configuration options, and you might be able to ""configure the problem away.""        My problem(in an i586) is that i can't read from the port properly.I could get the no of bytes available on the port with an ioctl call.The program fails to read that bytes..     Sometimes it reads correctly a few bytes.. But most of the time the read function returns with Zero bytes read even if bytes are available on the port. Writing was working properly(verifying..by the return value of write function)     Earlier i thought it could be some problem with my code.Later minicom also showed the same problems.That is, whatever was typed on my keyboard was displayed on hyperteminal on the windows machine on the other side correctly.But when i typed something on the other side(in hyperterminal) it was not reaching here properly.That is, once it displayed some ..2 or 3 characters correctly and failed to show the rest.       [Ben]  Hmmm... that _does_ sound like a speed problem. If the port on the other machine was set to, say, 57600, and this machine was set to 9600, it would ""miss"" most of the characters sent to it (although the classic speed problem shows up as random garbage mixed with a few of the characters being sent.)        When hyperteminal was used on these side also ..everything was ok. So i guess..there is no problem with the serial port.     Could this be some problem with the serial driver in linux.     i think the problem is more clear now...     sree       [Ben]  Wind*ws, depending on  the version, sets the serial port speed to 57600 or 115200, if I remember correctly.       [Chris G.]  Hi sree,     You have got an interesting problem here.  First, let me mention that I read Ben Okopnik's response, therefore, I will attempt to provide information that does not overlap his response.  Take his response into consideration.     Let's pretend that your baud rates are the same on both sides.  When you type on your Linux machine, the characters appear on the Hyperterminal display.  So, you Linux machine can send, and your Hyperterminal machine can receive.     Now, when you type on your Hyperterminal machine, I get the impression, that the first few characters that you type appear on the Linux machine (my assumption may be wrong -- correct me if I am wrong).   After that, when you type any more characters on your Hyperterminal machine, the Linux machine displays nothing.  My first guess would be that flow is enabled on your Hyperterminal machine, and you are using a 3-wire connection.     Flow control being enabled would seem like a logical cause for your problem except for one thing.  I get the impression that if you type ten characters on your Hyperterminal machine (excluding the enter key), that your   ioctl()  returns a value of ten.  The results seem contradictory.  I believe that you are telling me the truth -- therefore I am now confused.     One trick that I use to test a serial port on a computer is to test each serial port one at a time.  Go ahead and remove the cable that connects your two computers.  On your Hyperterminal computer, connect a serial cable to it, but, do not connect the other end of the cable to your Linux machine.  On the cable, connect pins 2 and 3 together.  This will connect your transmit data line to your receive data line.  Bring up Hyperterminal and start to type characters.  If things are working, you should see whatever you type appear on the display.     Do the same thing on your Linux machine.  That is, connect a serial cable to the serial port of your Linux machine, and connect pins 2 and 3, of the connector, together.  Bring up minicom, and go ahead and type characters on your Linux machine.  If things are working, you should see whatever you type appear on the display of your Linux machine.     In both cases, we are performing a loopback test.  If you do not see a proper display, you have isolated the machine for which a problem exists on a serial port.     If you do see proper display, I would expect the following causes: 1. Mismatched baud rates between the two computers (maybe not) 2. Problems with your RS-232 drivers (voltage level problems).     If you don't see proper display on each machine, I would expect the following causes: 1. Problems with your RS-232 drivers. 2. Flow control enabled (you could disable flow control)     Try Ben's suggestions too.  My analysis may be incomplete.     Let me know what happens, and good luck, Chris Gianakopoulos        Hi chris amd ben,     Sorry for the delay in replying as there was some problem with our mailserver.       [Chris G.]  No problem.     Now, when you type on your Hyperterminal machine, I get the impression, that the first few characters that you type appear on the Linux machine     Not always...it appeared  rarely...     [Chris G.] Hmmmmmm.....     (my assumption may be wrong -- correct me if I am wrong).   After that, when you type any more characters on your Hyperterminal machine, the Linux machine displays nothing.  My first guess would be that flow is enabled on your Hyperterminal machine, and you are using a 3-wire connection.     Hardware Flow Control is enabled in hyperterminal(That's the default..) That is set in minicom also.I changed only the baudrate. (I am in doubt about this cable whether it is  using 3 pins only or more)     But the cable I use in my program uses the rts,cts pins and uses them in data transmission since the rtu expects that.Everything is working fine in 686 machine.     Flow control being enabled would seem like a logical cause for your problem except for one thing.  I get the impression that if you type ten characters on your Hyperterminal machine (excluding the enter key), that your   ioctl()  returns a value of ten.  The results seem contradictory. I believe that you are telling me the truth -- therefore I am now confused.     I haven't checked the ioctl call with hyperterminal.I am using minicom with hyperterminal.     [Chris G.] Understood.        The ioctl call is used in my program that communicates with an rtu through serial port. I am sending some data to the port and expecting some data in return. The ioctl call returns the no of bytes available on the port. But the read  function fails to read them and returns zero bytes.     By using hyperterminal on both computers communication is perfect. So that proves there is no problem with port or cable.       [Chris G.]  I agree.        If there is some problem with the settings mismatch in hyperterminal and minicom ...how is the communication working correctly in one direction?       [Chris G.]  The direction that is not working would be the one that is not getting the proper handshake -- if my flow control idea is valid.        I will check with flow disabled in hyperterminal.     I want to know whether this is a problem of linux? I am asking this because ..when hyperterminal was used on both sides communication was working. Have anybody encountered this type of problem in 586.       [Chris G.]  That is what is odd.  A serial port is not really associated with a processor -- Ok, ok, some embedded microprocessors do have lots of serial devices incorporated into their package. I would think that you are using something like a 16450, 16550, 8251, or someother UART or USART.  It is just a device that is addressed by the Intel processor in I/O space.  I understand what you mean, though. When you say 586, you are referring to your particular 586 motherboard with its oddly behaving serial interface (as far as its behavior with Linux is concerned).        I am waiting to check this problem with another 486 machine.     I wan't to know more about the flow control aspect. What is its significance?       [Heather]  That's ""ready to send"" and ""clear to send"".  One system says it wants to .. has data ready to go... and the other system has to give it the thumbs up... clear, you can send now.       [Chris G.]  When you want to send, you assert rts.  Your system will monitor cts, and it will not send the data unless cts is asserted (when I say asserted, I mean set to an active state).  If the computer, at the other end of the link, does not activate the cts line, your system will never send the data byte.  It will be flow controlled.  As a quick test, you could make a cable that jumpers rts to cts.  That would be pins 7 and 8 on your db9 connector.        I am using the rts/cts pins in my program. I do it like this.. I will make the rts pin high before writing and wait for cts to become low. Only when cts becomes low will i write to the port. However i am not using any setting/resetting while reading the port. Everything is working fine in 686.     bye sree       [Chris G.]  Okay.  You seem to be troubleshooting things in a good manner.  Don't forget to look at Ben O's suggestions, too.             Shut down when turn computer off     From pclouds         Answered By  Richard Adams, Frank Rodolf, Mike Orr     What I think he is talking about is that with some computers (dell is the only one I know) that are running windowsNT if you hit the power button on the front of the pc they begin to do a software shutdown.     Thats what he is asking how can he set it up so when he hits the power button that the machine notices this and goes into a software shutdown..       [Richard]  Well look at it this way, by depressing the power button on the computer you start a shutdown, ok yes i now know what wa meant, what Linux has that no windows software has is ""ctrl-alt-del"" invokes the defined call in  /etc/inittab  by default its in short, ""shutdown -r now"" that one can change to use 'poweroff' 'shutdown' or 'reboot'.     So instead of pressing the power button on the machine itself, hit ctrl-alt-delete, advantage of that is no need to streach to reach the machine as the keyboard is right in front of you.       [Mike]  There is also a POWERFAIL signal Linux uses to signal the detection of an imminent power failure.  It's meant for emergencies, but maybe you can somehow latch onto that infrastructure.  But an option like 'ctrlaltdel' in ' /etc/inittab ' would be more ideal.     ATX-style computers have a momentary on/off switch that can (somehow) be made to trigger the ""shutdown"" command -- maybe.  I'm not sure how it's done. Look through ""man inittab"", ""man init"" and the kernel documentation, and maybe you'll get an idea.     This won't work with older AT-stype cases and motherboards because they have a true 2-position switch.  When you turn the switch off, it cuts the power mechanically, and Linux doesn't know about it.  Even if Linux did know about it, there's not enough processor cycles left for Linux to do a clean shutdown before it dies.       [Frank]  I did some quick lookup... It seems acpid can do this - should be available with your distribution, or otherwise you can easily find it online.     If not, there is also something called ""Linux PowerSwitch Driver"", which is meant exactly for what you want... You can find it at:      http://deadlock.et.tudelft.nl/~joris/powerswitch      Hope this helps you!        Thanks for all advices. I have got powerswitch. It work very well!             slib installation     From Dann S. Washko         Answered By  Ben Okopnik     While compiling gnucash I needed to install the slib libraries.  I grabbed the latest files from SLIB site and looked over the install information. I initially put the slib files in  /usr/lib/slib , but this was not working, g-wraper kept puking saying it could not find require.scm.  Looking at the path's listed, I moved slib to  /usr/share/guile/1.4.   I reconfigured g-wraper and ran make with no errors.     Is this where slib belongs?       [Ben]  Just a datapoint: on my ( Debian ) laptop, ""slib.scm"" is in  /usr/share/guile/1.3.4/ice-9/.  It sounds like the right neighborhood.        Yeah, that is where it is on my slack system. The g-wrapper program was looking for it in  /usr/share/guile , so that is where I put it.  I managed to compile gnucash successfully.  It puked on the first run saying I should run it as root.  Again, this was an issue with the slib libraries.     strace gnucash showed some issues with opening slib.cat, but after running it as root once, I was able to run it as a user.       [Ben]  Hm. That makes me wonder if it creates some sort of a config file that it relies on in a place wher you normally don't have write permissions. <Shrug> Just a wild guess.        This makes me wonder if my placement of slib is not 100% correct.       [Ben]  I would think that if it wasn't, it would continue to fail. Either way, it's working now, right?           Thanks for your reply, Ben.       [Ben]  You're welcome, Daniel; little enough that it was, I'm glad that it was of use to you.             SuSE 7.1 installation CD not recognized     From Tom Zabosky             Answered By  Dan Wilder, Karl-Heinz Herrmann, Jim Dennis     Good day     I came across the undermentioned question to yourselves and it is the identical problem I have been having. Could you please send me the answer given to this question. Thanking you in advance for your kind consideration in this matter.     yours     Tom Zabosky       ...............     SuSE  7.1 installation CD not recognized     ram son - Tue, 3 Apr 2001 09:52:50 -0700 (PDT)     My knowledge of Linux systems isn't very extensive but I have been checking out different systems by downloading ISO's from ftp sites.Because SuSE 7.1 live-evaluation is only an image and uninstallable, I downloaded from a mirror the folders and files I thought might be needed by duplicating the layout from version 7.0 --which seems to be the same as the ftp layout. Unfortunately I ended up with an unbootable CD...So I made a boot floppy and get started only to get a message saying "" unable to find SuSE 7.1 Installation CD 1..."" It then switches to manual installation and I am able to install using yast1...But I actually wanted to check all the new stuff included in Yast2 and the partitioning improvements -- aside from the curiosity factor to find out what actaually went wrong. If I use the cd from 7.0 the boot floppy works fine and I get yast2. I also compared the layout and files in the two versions and was not able to solve the problem. I searched many sites and all I get are bits and pieces that did not help me much.     The questions are: What is missing from my cd that it is not recognized as the installation cd? What is it that linuxrc looks for to get Yast2 started? and  more importantly where in the tree is it supposed to be? I would greatly appreciate any help you can offer me ..preferably with a direct answer or at least point me to where the answer could ""actually"" be found and save me the link-chasing.  ...............        [Dan]  I'd suggest you ask SuSE this question.       [K.-H.]  I agree with Dan on this -- SuSE would be the place to ask.     If you didn't fetch a boot disk as well and burned the CD explicitly as bootable CD with that disk-image of course it can't be bootable. See cdrecord man pages and README's for details or move to a search engine of your choice and type ""burn bootable CDR"" or something similar.     The partitioning improvements of yast2/7.1 are that you still cant choose any more complicated layout than a continous part of a HD. (seems to have improved with 7.3).     SuSE/yast requires a list of packages and lots of information for administration of the system. probably you forgot that.     You've  no  problem with filesystem type/extensions on the CD? like  all caps filenames instead of lower case ones?     I guess SuSE put something there so it's not that easy to just bake your Installation CD yourself where lots of needed stuff might be needed. Aren't there CD images which would even be bootable?       [JimD]  Actually it's probably a replay of the old question:     I downloaded a .ISO image and it doesn't work after I burn it to a CD     (i.e. the user/querent is using CD burning software that is not recognizing the target file as a pre-mastered ISO image).     The best answer to this question seems to at the LinuxISO web page:      http://www.linuxiso.org/cdburninginfo.html      ... where one can also find ISO images of over twenty Linux distributions, as well as  FreeBSD ,  NetBSD , and  OpenBSD  (which I usually call *BSD or {Free,Net,Open}BSD for brevity's sake).     What I particularly like about this page is that they used to have a Javascript animation that showed a sequence of dialogs and options in ""Easy CD Creator"" that selected the appopriate ""Options, Track Type"" settings for burning pre-mastered ISO images. (Even though that seems to have disappeared, the information is still there; MS Windows users just have to READ it and find the             Installing tulip.o in 6.2     From William Laing             Answered By  Ben Okopnik, Breen Mullins     hello     Can someone instruct me how to install the module/ driver in Linux 6.2 .for the Linksys networking card.     The following module came with the card on a floppy and I was able to load it in as follows as per the instructions. I have tulip.o loaded in at this location.     # locate tulip.o    /lib/modules/2.2.17-14/net/old_tulip.o    /lib/modules/2.2.17-14/net/tulip.o     Does the old file require to be deleted or may it stay ? I am be having some fun, but not making any headway on insmod.At this point I cant go ant further.     Thanking you. Bill       [Ben]  Did you try loading the module that was already on your system? I would do that before using the new one, by preference - consider that to be your fallback position if the new one fails, or gives you any problems. Presumably, you're using the 2.2.17 kernel; all you have to do is type     insmod tulip     If the module loads without errors, check to see if the system actually ""sees"" the card as it should:     ben@Baldur:~$ ifconfig eth0 eth0      Link encap:Ethernet  HWaddr 00:4C:69:6E:75:79           inet addr:192.168.0.3  Bcast:192.168.0.255  Mask:255.255.255.0           BROADCAST PROMISC MULTICAST  MTU:1500  Metric:1           RX packets:0 errors:0 dropped:0 overruns:0 frame:0           TX packets:0 errors:0 dropped:0 overruns:0 carrier:0           collisions:0 txqueuelen:100           RX bytes:0 (0.0 b)  TX bytes:0 (0.0 b)           Interrupt:11 Base address:0x200     Note that your numbers may not be the same as mine; in fact, the line starting with ""inet addr"" will most likely be absent. This is normal.     Truth to tell, I'm a little surprised at the fact that the manufacter included a module: they're normally compiled for a given kernel, and will error out (although they can be force-loaded) when pushed onto a different one.     The old module (I assume, from the above, that you renamed the original to ""old_tulip.o"") does not need to be deleted. If you want to test the system with it instead of the new one, you should just be able to type     insmod old_tulip     Don't try to load more than one of them at a time; unload the one that you don't want with     rmmod <module_name>     You can always see what's loaded by typing     lsmod        Ben     Thank you for Clear instructions, much apprecated. The following happens while using the commands you suggested.     Presumably, you're using the 2.2.17 kernel; all you have to do is type...     Yes a 2.2.17-14 kernal     insmod tulip     Yeilds as follows:     Using /lib/modules/2.2.17-14/net/tulip.o: init_module: Device or resource busy Hint: insmod errors can be caused by incorrect module parameters including invalid I0 or IRQ parameters.     [Ben] That sounds like it's looking for parameters. This can also be caused by I/O or IRQ conflicts, but ...       [Breen]  The tulip cards are all PCI and you shouldn't attempt to specify either IRQs or IO addresses for them. The system assigns these for a PCI device, not the driver.       [Ben]  Right. Check "" /proc/pci "".     insmod old_tulip     Yields the same as the new one. I believe I am guilty of copying both modules myself to the linux box.     [Ben] It sounds like either one will work, once you have the correct parameters.     lsmod     Yeilds:     # lsmod Module                        Size             Used by #     With nothing listed.     [Ben] This is fine.        Both machines can ping each other while Window applications are installed suggesting the network path is funtional.       [Ben]  Good - knowing that will narrow down any troubleshooting that you may do.        Ben, Breen     Agn thank you people for you kind assistance. The results of your suggestions follow. (It is a bare bones machine text only.)     The kernel is a 2.2.17-14  The card is a Linksys  LNE Ver.4.1 TAIMAG HE-012D     I do have other D-Link Cards I have tried, using RTL8139, but the results were the same.     # /var/log/dmesg     Permission denied #       [Ben]  Erm, you're supposed to read it - not execute it. "" /bin/dmesg "" will print out the contents; for a bit more scrolling control, try     more /var/log/dmesg     Reading ""daemon.log"" and ""messages"" in "" /var/log "" would be of even more use - they would tell you what happened when you tried to load the module. A quick look at the available parameters for ""tulip.o"" tells me that there's a ""debug"" option, enabled by     insmod tulip debug=value     Where ""value"" is 1-6 (I just took a quick look through the code, and the tests for ""tulip_debug"" max out at 'if (tulip_debug > 5)...') This should print much more info to the logs.       [Breen]  As Ben said, you're supposed to read the file. But you won't find the detection message we're looking for in dmesg; I realize that you need to look in  /var/log/messages.      Try this:     # grep tulip /var/log/messages*     You'll be looking for a line similar to this:     messages.3:Oct  8 13:17:41 archy kernel: tulip.c:v0.91g-ppc 7/16/99 becker@cesdis.gsfc.nasa.gov     That tells us the version of the tulip driver you're using. Mine is old but so is the card I'm using.     Instead of Ben's suggestion of     # insmod tulip     you may want to try     # modprobe tulip     (Some versions of the tulip driver need a shim driver to load first. modprobe will pick that up.)     If that doesn't work, try getting the latest drivers from Donald Becker's site:      ftp://ftp.scyld.com/pub/network/netdrivers-3.0-1.src.rpm      Become root and install the rpm:     # rpm -i netdrivers-3.0-1.src.rpm  # cd /usr/src/redhat/SPECS # rpm -bb netdrivers.spec     That will build the latest set of drivers.     # cd ../RPMS/i386 # rpm -Uvh netdrivers-3.0-1.i386.rpm   (you MAY have to use a --force flag with that -- you'll know if you do.)  # depmod -a # modprobe tulip     Which should get you up and running.             Just wondering     From andrew             Answered By  Jim Dennis, Faber Fedor     This is a multi-part message in MIME format.       [Faber]  First off, this is a major no-no around these here parts.  Please send your emails as text only, NOT as HTML.  Most of us will refuse to read HTML (because we don't use Outlook, Netscape, etc.).  We even have one guy here who carries around a riffle for people who send MIME formatted emails!        I'll answer your Q this time, but any more that come in as anything other than text only will be ignored (at least by me).       [JimD]     Note that his message was in text  and  HTML.  This is more of a venial sin; though MIME handling of some text mode MUAs isn't all that good and both sections seemed to be in MIME parts (one text/plain and one text/html).        Hello,       [Faber]  Hi.        I am wondering if you could help.       [Faber]  We try our best.        My question is if i was to buy a Redhat 7.2 CD & choose the Upgrade will i expect my major services to break or will this upgrade be able to make it as painless as possible.       [Faber]  Yes, it will be as painless as possible and yes it  will  break things. It all depends on what you are running.  If you save your configuration files (the Upgrade promises to do that, and I beleive it but I don't trust it), you should have minimal problems.   Red Hat  will save your config files as config_file.rpmsave, so you'll still have to go in and ""fix"" stuff.     Outside of that, the only problem I've had upgrading a system is when the 2.4 kernel didn't have a driver/module for the RIAD controller and we had to drop back to the 2.2 kernel and it broke DNS because the BIND on the CDs is looking for a specific 2.4 kernel feature.  Outside of that, they've all gone well.       [JimD]     Personally I prefer the ""scorched disk"" upgrade method.  That's where we do a fresh installation to a new disk and copy our data and configuration over.     Obviously this works best if you have (at least temporary use of) a whole system on which to perform your staging.      Debian  is the only system that I regularly upgrade from one major release to the next without ""scorching the earth"" beneath it.  In other cases I've just seen too many artifacts and quirks in other operating systems when upgrading core libraries and system components.     An advantage to the ""scorched disk"" approach is that you have an obvious back of the entire system throughout the process.  You can easily switch back to the old system.  So it represents a lower risk than the typical ""boot from the new distribution CD, cross you fingers and pray"" process (herein-after referred to as the ""boot and pray"" technique).     If you don't have a whole system to spare then get a spare hard disk. Most systems have a spare interface/channel to which a third or fourth IDE device can be attached (and PCs with SCSI subsystems almost always have spare IDs  and  spare IDE interfaces).  Care should be taken when connecting a new IDE hard drive to an IDE chain with any other IDE device already on it.  (I once wiped out a system by accidentally configuring two drives as masters --- the pinouts on those used to be harder to figure out; bad documentation.  Luckily the customer's backups were good and recent).     After you get the new drive in place and make it bootable, be sure to mount the old filesystems in read-only mode during the transition.     When your done with all of the data and configuration transfer you can put the drive on a shelf for a few weeks, months, or whatever.  When the filesystems on the old drive are so far out of date that you wouldn't use them in the worst case --- then the drive is ripe for putting into a new system.     Of course its possible to do this using tapes, CDR, DVD-RAM or whatever removable media you normally use for your regular backups.  However, the mismatch between the sizes of most production filesystem and removable filesystem media make this convenient.  Tapes are big enough but they must be accessed using archiving utilities which is also inconvenient.     So it is best to use an extra drive where you can.     The hardest thing about any upgrade is knowing when you're done. How confident can we be that  everything  is working? This is one of the challenges to professional systems administration that remains largely unsolved.     Ideally we should be able to run an automated test suite which would test each service and application on our system(s) (locally and from remote systems, including some from ""out on the Internet"" for public servers).  Recently I've been reading about ""Extreme Programming"" which advocates the continuous creation and maintenance of automated test suites which are integrated into the sources and makefiles of a software system.  I've come to the conclusion that sysadmins need to adopt similar practices.  We need something like an  /etc/systest/Makefile  what launches these checks for a given host.     However, that's work for another time -- an article of its own. For now you'll just have to muddle through and test your newly (upgraded) system using whatever procedures you normally use to               This page edited and maintained by the Editors         of  Linux Gazette   Copyright ©  2001  Published in issue 73 of  Linux Gazette  December 2001   HTML script maintained by          Heather Stern  of         Starshine Technical Services,          http://www.starshine.org/        ""Linux Gazette... making Linux just a little more fun! ""              Contents:     Legislation and More Legislation   Linux Links   Conferences and Events   News in General   Distro News   Software and Product News        Selected and formatted by   Michael Conry  and  Mike (""Iron"") Orr        Submitters, send your News Bytes items in   PLAIN TEXT  format.  Other formats may be rejected without reading.  You have been warned!  A one- or two-paragraph summary plus URL gets you a better announcement than an entire press release.                     Linux Journal 's new web site                Linux Journal  has redesigned their   web site .  The new site is based on PHP-Nuke, and allows users to have login accounts and to comment on every article in the site (both magazine articles and web articles), reply to each other's comments, and participate in discussion forums.  Best of all, the frames are gone!  (Good riddance.)                   December 2001  Linux Journal          The December issue of  Linux Journal  is on newsstands now. This issue focuses on System Administration.  Click   here  to view the table of contents, or   here   to subscribe.     All articles through December 1999 are available for public reading at   http://www.linuxjournal.com/magazine.php .   Recent articles are available on-line for subscribers only at   http://interactive.linuxjournal.com/ .                Legislation and More Legislation                 European Legislation       Bad news from the European Patent office. It appears that they are just itching to get a piece of the software-patents action their American colleagues have been hogging.   Eurolinux  have   reported  that the president of the European Patent Office has, ""in preemption of political decisions to be taken by European governments, decreed a regulation that authorises patent claims to computer programs"". The updated rules are   available online  along with a    related memo .   The outrage at this stems both from strong feeling against software patents per se, and from the undemocratic nature of their introduction. As    reported  by the French daily, Le Monde, European governments had already made a decision to postpone changes to the articles in question until further study had been done into the potential ramifications.    A    study  commissioned by the German Federal Ministery of Economy and Technology (BMWi) found that introduction of software patents would be likely to put many currently successful software companies out of business and slow down innovation in the software field (perversely, that report then went on to  recommend  the introduction of these patents). A European Commission    consultative report  [pdf] found that 91% of respondants where opposed to software patents. However, it appears that the ""economic majority"" was in favour of patents. So much for democracy.   There are several fine online resources available if you want to familiarise yourself about the issues regarding software patents.      Eurolinux  is a leading opponent of these ""advances"". Their   Petition for a Software Patent Free Europe  is supported by 80000 signatures. Why not add your own?   The   Federation for a Free Informational Infrastructure  also have a wide range of news and information on these issues. In particular, there is a   guide  to the Interpretation and Revision of the crucial Article 52.     AFUL  (Association Francophone des Utilisateurs de Linux) have a moderate traffic   mailing list  where a range of opinions are expressed. The archives are available    online , and are worth reading (multilingual).          Slashdot   reported   on the signing of the new   European Cybercrime Treaty . The final version is available    here . It is effectively a template to be used by signatory countries when framing laws concerning crime committed using computers. As   reported  by The Guardian, the treaty: ""...outlines common definitions of computer-related crimes, defines the methods for criminal investigations and prosecution and establishes methods of international communication between law enforcement officials.""   Though some   comment  has been favourable, many civil rights groups have   condemned  the treaty on the grounds that it grants excessive powers to police forces while eroding privacy. One consolation (as noted last month) that Bruce Schneier has    highlighted  is the explicit statement in the treaty of the legitimacy of using ""hacking/cracking"" tools in    security work  (as opposed to using them to rob banks!). Nevertheless, there is still strong cause for concern as the provisions for extradition and cross border action could be subject to tragic abuse.         In a final titbit of European news, The Register   recently reported  that the EU Microsoft probe hearings should take place December,  with a verdict early 2002. It appears Competition Commissioner Mario Monti is not giving much away about how this will pan out or what the ultimate aim is.              UK Developments          The European Cybercrime treaty will not be of much interest to the United Kingdom Government, as they seem to have implemented many of the most draconian measures already.  In the current climate of terrorist fear, things are being locked down even more tightly. New measures being introduced by David Blunket (UK Home Secretary) will give law enforcement bodies access to records of all UK telephone and internet users. This was   reported  in The Guardian. This access will not only be available for terrorism investigations, but also for investigations regarding minor crimes and tax issues. This is basically an extension/clarification of the    much criticised    Regulation of Investigatory Powers Act 2000  which gave the government unprecedented powers to monitor communications with very little outside scrutiny or even the need for a court order. Apparently, it is ""inappropriate"" to involve judges in the process where issues of national security or economic well-being are involved. An article in  Criminal Law Review  described this assertion as    ""wholly spurious"" .   The   Foundation for Information Policy Research  (FIPR) and   Magna Carta Plus  have a lot of information regarding this and  related issues.                  Judge Refuses Adobe Injunction Against Reseller of OEM Software          In a case that impacts the questions of (1) whether software is ""licensed"" or ""sold"" and (2) the validity of End User License Agreements (EULAs), a US district judge has    denied  [pdf] Adobe a preliminary injunction against SoftMan Products Company for reselling Adobe software that was originally bundled with computers in OEM fashion but that the computers' owners did not want.    The judge rejected Adobe's claim that the bundled copy was a ""license"" rather than a ""sale"".  Thus, the First Sale doctrine applies, meaning Adobe cannot control the subsequent transfer of the the software after the initial sale.   The court also found that SoftMan was not bound by the EULA because it had never assented to it.  The validity of EULAs was also questioned as the terms were not fully disclosed prior to the sale. Linux Journal has more    details .    Linux Weekly News also has an informative   editorial   that examines how this ruling might affect other cases. One implication is that it should be possible (if the principle of first sale now applies) to resell e-books or unwanted OS installations. The ruling may also be important to the two DeCSS cases (the famous one and another one). These cases ""depend, partly, on the claim that a commercial DVD package was 'improperly' reverse engineered. It is the software's EULA that prohibits that reverse engineering. If the code is reverse engineered without installing it and agreeing to the EULA (by, say, disassembling it on a Linux system), the EULA may not apply"".              Lawrence Lessig        There is an    article   by Lawrence Lessig at   Foreign Policy  on the evolution of the Internet, transforming communication relations from controlled to free, and the very real threat that much of it may become controlled again.    He makes some interesting comments about who invented various important Internet protocols and services and on the vested interests vying for control. ""Policymakers around the world must recognize that the interests most strongly protected by the Internet counterrevolution are not their own. They should be skeptical of legal mechanisms that enable those most threatened by the innovation commons to resist it.""                Judge Rejects French Jurisdiction Over Yahoo's Auction of Nazi Artefacts             US District Court Judge Jeremy Fogel  has    refused  [cnet.com] to enforce a French court's order barring Yahoo from auctioning Nazi memorabilia on a US site that was accessible to French citizens.      LG wonders what the judge would think if the situation were reversed,  given the current attempts by US companies to get their US patents and DMCA copyright rights recognized overseas.               Good and Bad DeCSS News       Slashdot   reported  that in the California DeCSS case, a court of appeal overturned the injunction imposed by a lower court. Quoting: 'In the case of a prior restraint on pure speech, the hurdle is substantially higher [than for an ordinary preliminary injunction]: publication must threaten an interest more fundamental than the First Amendment itself. Indeed, the Supreme Court has never upheld a prior restraint, even faced with the competing interest of national security or the Sixth Amendment right to a fair trial.' This is obviously a very positive development, though there is a long road still to be travelled.       Less positively, in the New York MPAA v. 2600 case, the court of appeals decision has gone in the favour of the MPAA. There are reports on the judgement available    here  [TheRegister.co.uk] and    here  [EFF.org]. Cryptome.org has a very through    collection  of documents relating to both cases, including the  text of the ruling . The judge accepted that computer code can be protected as a form of speech under the first ammendment. He then decided that the target of the injunction was not the  speech , but the functional component (i.e. the use the code can be put to: decrypting DVD's). In these circumstances, the injunction can be granted as long as it is ""content neutral"", and the impact on the speech component is incidental. The judge writes:   This type of regulation is therefore content-neutral, just as would be a restriction on trafficking in skeleton keys identified because of their capacity to unlock jail cells, even though some of the keys happened to bear a slogan or other legend that qualified as a speech component.   The other part of the rationale is that the Government's interest in the prevention of unauthorised access to copyrighted material ""is unquestionably substantial"". Thus, the injunction is upheld. A similar argument is used relating to the injunction against linking to web pages containing DeCSS.   Claims against the injunction based on the principle of fair use were dismissed on the grounds that although the user is allowed to make fair use (say, by quoting from a copyright work) she is not automatically entitled to make that use with a preferred technology. CSS may prevent you taking a still image from a movie, but it does not stop you from photographing your monitor/television screen. Thus, your fair use rights are not affected.   The issue as to whether or not DeCSS is really a piracy tool was relegated to footnote 5. The footnote correctly states that piracy is entirely possible without DeCSS, but contends that DeCSS is a substantial aid to the process. Many would    contend  that the piracy issue is actually a canard (=bogus), but it is the most respectable argument the MPAA can come up with.   Note: I am not a lawyer (as they always say on Slashdot), and this interpretation is based on a quick reading of the ruling just before this month's deadline. However, I believe that the summary above is a fair representation of the major points. As to the correctness of the ruling/opinions, you must make up your own mind. Personally, some of the distinctions seem a touch specious. The separation of speech and function with regard to computer code is not as clear as in the case of the logo on a key, or a poem written on a gun. Also, the issue of fair use regarding the  playing  of legally purchased DVD's on Linux was summarily dismissed, apparently on the basis that you have the right to watch, not decrypt, DVD's you purchase, thus subsection 1201(a)(3)(A) of the    DMCA  still applies.  -- MC      Slashdot has an  eyewitness  account of the Felten vs RIAA hearing .  As you remember, Professor Felton write a paper describing weaknesses in the CSS encryption used on commercial DVDs.  RIAA threatened to sue him if he presented the paper at a scientific conference.  But they didn't sue him, and after a public outcry they withdrew their objection to him presenting the paper.  Meanwhile, Felten filed a lawsuit of his own, claiming that RIAA's action encourages researchers to censor themselves to avoid legal liability that may or may not be  legitimate.  The judge dismissed the suit, saying that he cannot rule on a potential issue (RIAA threatening to sue Felten), but only on an actual issue (if RIAA sued him, which they didn't). He said he is not allowed to rule on Constitutional issues (whether Felton's free-speech rights were violated) in a non-criminal case without a compelling reason, and there is no compelling reason in this case.  He also said this case is like ""night and day"" compared to Dmitry Sklyarov's case, since Dmitry  was  charged with a criminal violation of infringing for commercial gain.  -- Iron ]        Dmitry's trial date is now expected to be April 15, 2002, assuming the case isn't dismissed in the meantime.    More information about most of these issues is on the  Electronic Frontier Foundation  home page.              Bad News for Napster          In less positive news, The Electronic Frontier Foundation published a   white paper  on the US appeals court decision confirming that Napster was liable for its users sharing copyrighted files. The court agreed that the file-sharing technology in itself is not illegal, but the minute its developers and users receive reasonable knowledge that specific infringing files are servable on the system (e.g., if they receive a ""cease and desist"" letter), they must immediately delete these files or they, and possibly their ISP and so on upline, will be liable.  Knowledge of infringing uses overshadows whatever non-infringing uses the server may also be performing.  In practice, this will have the effect of deletion through intimidation, or deleting files that are alleged to infringe but may not.  It also forces sysadmins to become their own police for the benefit of the content companies, or face liability.  Technologies such as    Freenet  that are unable to police user access may have an advantage under this ruling.          Linux Links         LWN  have the following links which you might enjoy:                    LWN penguin gallery                    Release notes       on the new Netscape 6.2           A           Cartoon       about a truly terrifying experience installing ghostscript           LWN has also            summed up  the main points of the Virtual Memory ex-controversy in     Linux 2.4.       The Register  have reported      Microsoft's    bootloader concession  could boost Linux, BSD. They also report on how   difficult  it is to buy a pre-installed Linux system from any of the major PC builders.   Red Hat    offer  to provide open-source software ""in every school district in the United States free of charge"" (dig aimed at Microsoft?)   Linux fans    'hack'  Windows XP advert. In a similar vein comes this   photo .       CNet wonders whether the Open Source model be    killed  by hard times? Annalee Newitz at AlterNet   doesn't think so .    Alternet look at   Network Admin Blues     ZDNet ran a   story  on the Virtual Memory issue. eWeek.com   covered it too .    LinuxWorld have an    article  on installing Debian over a network.    LinuxSecurity.com have a    report  Hal Burgiss' new Linux security quick-start guides: the   Security Quick-Start HOWTO for Linux  and the    Security Quick-Start HOWTO for Red Hat .    At OReillynet.com Jerry Peek   explains  why Unix and Macintosh users should learn to use the command line.     BSD bug report in comic strip    form . From the   Aspiring to Crudeness  e-newsletter .    There is an informative   Article   at   linux.oreillynet.com  about what a kernel Oops is and how to troubleshoot its cause.      Here  is a large list of links to Python sites  and resources. Lots and lots of information, including a selection of links to French language Python sites.      Deepak, from Bangalore, India, submitted a link to his    webpage    where he has a PowerPoint presentation available for download. The title of the presentation is ""The (R)Evolution of an OS"", and it provides a very thorough broad-based introduction to Linux for people who may be familiar only with Windows. The slideshow is ""95% StarOffice compatible"", but even if you don't have Powerpoint or StarOffice, you can also see thumbnails and full-size jpegs of the individual slides.    Ernesto Hernandez-Novich suggested that we plug the    Venezuelan Linux User's Group  and their    mailing list archive . Linux Gazette is always pleased to be able to alert readers to public linux resources. A great way to promote a new or existing Linux Users' Group (LUG)  is to register the LUG at   GLUE  (Groups of Linux Users Everywhere).       LinuxDevices.com  have a    Review  of Sharp PDA running Linux. This was  also   highlighted  on Slashdot, which linked to an infoSync   story .     Not Linux, but  www.gatt.org  is a satire of the WTO web site from the viewpoint of anti-globalization activists.  The real WTO web site,  www.wto.org , allegedly had a statement deploring this pseudo-site.  In a comical turnaround, the satire site now has an article (at the bottom of the home page) titled ""Fake WTO site misleading public"", with a link to the ""fake"" site that is actually the  real  WTO site!    There's neither pine nor apples in pineapples, no ham in hamburgers, Look    here  for further extracts from the book  Crazy English .          Upcoming conferences and events     Listings courtesy  Linux Journal .  See  LJ 's  Events  page for the latest goings-on.                      15th Systems Administration Conference/LISA 2001           December 2-7, 2001 San Diego, CA                    http://www.usenix.org/events/lisa2001                              Consumer Electronics Show (CEA)            January 1-11, 2002 Las Vegas, NV             http://www.cesweb.org/                    Bioinformatics Technology Conference (O'Reilly)    January 28-31, 2002 Tucson, AZ                     http://conferences.oreilly.com/biocon/                    COMNET Conference & Expo (IDG)    January 28-31, 2002 Washington, DC      http://www.comnetexpo.com/                    LinuxWorld Conference & Expo (IDG)            January 30 - February 1, 2002 New York, NY              http://www.linuxworldexpo.com/                    The Tenth Annual Python Conference (""Python10"")           February 4-7, 2002 Alexandria, Virginia                    http://www.python10.com/                    Australian Linux Conference           February 6-9, 2002 Brisbane, Australia             http://www.linux.org.au/conf/                    Internet Appliance Workshop    February 19-21, 2002 San Jose, CA               http://www.netapplianceconf.com/                    Internet World Wireless East (Penton)    February 20-22, 2002 New York, NY        http://www.internetworld.com/events/weast2002/                    Intel Developer Forum (Key3Media)           February 25-28, 2002 San Francisco, CA      http://www.intel94.com/idf/index2.asp                    COMDEX (Key3Media)    March 5-7, 2002 Chicago, IL             http://www.key3media.com/comdex/chicago2002/                 BioIT World Conference & Expo (IDG)           March 12-14, 2002 Boston, MA             http://www.bioitworld.com/                 Embedded Systems Conference (CMP)           March 12-16, 2002 San Francisco, CA              http://www.esconline.com/sf/                 CeBIT (Hannover Fairs)           March 14-22, 2002 Hannover, Germany                    http://www.cebit.de/                 COMDEX (Key3Media)            March 19-21, 2002 Vancouver, BC               http://www.key3media.com/comdex/vancouver2002/                 FOSE           March 19-21, 2002 Washington, DC                    http://www.fose.com/                  Game Developers Conference (CMP)            March 19-23, 2002 San Jose, CA             http://www.gdconf.com/                 LinuxWorld Conference & Expo Singapore(IDG)            March 20-22, 2002 Singapore                  http://www.idgexpoasia.com/                 Software Solutions / eBusiness World           March 26-27, 2002 Toronto, Canada             http://www.softmatch.com/soln20.htm#ssebw                 SANS 2002 (SANS Institute)            April 7-9, 2002 Orlando, FL             http://www.sans.org/newlook/home.htm                 LinuxWorld Conference & Expo Malaysia (IDG)           April 9-11, 2002 Malaysia             http://www.idgexpoasia.com/                 LinuxWorld Conference & Expo Dublin (IDG)           April 9-11, 2002 Dublin, Ireland                           Internet World Spring (Penton)            April 22-24, 2002 Los Angeles, CA             http://www.internetworld.com/events/spring2002/                 O'Reilly Emerging Technology Conference (O'Reilly)           April 22-25, 2002 Santa Clara, CA             http://conferences.oreillynet.com/etcon2002/                 Software Development Conference & Expo (CMP)            April 22-26, 2002 San Jose, CA             http://www.sdexpo.com/                 Federal Open Source Conference & Expo (IDG)           April 24-26, 2002 Washington, DC             http://www.idgworldexpo.com/                 Networld + Interop (Key3Media)            May 7-9, 2002 Las Vegas, NV             http://www.key3media.com/                 Strictly e-Business Solutions Expo (Cygnus Expositions)            May 8-9, 2002 Minneapolis, MN             http://www.strictlyebusiness.net/strictlyebusiness/index.po?                 Embedded Systems Conference (CMP)            June 3-6, 2002 Chicago, IL             http://www.esconline.com/chicago/                 USENIX Annual (USENIX)            June 9-14, 2002 Monterey, CA             http://www.usenix.org/events/usenix02/                 PC Expo (CMP)            June 25-27, 2002 New York, NY             http://www.techxny.com/                 USENIX Securty Symposium (USENIX)            August 5-9, 2002 San Francisco, CA             http://www.usenix.org/events/sec02/                 LinuxWorld Conference & Expo (IDG)           August 12-15, 2002 San Francisco, CA      http://www.linuxworldexpo.com                 LinuxWorld Conference & Expo Australia (IDG)           August 14 - 16, 2002 Australia             http://www.idgexpoasia.com/                 Communications Design Conference (CMP)           September 23-26, 2002 San Jose, California             http://www.commdesignconference.com/                  News in General                Kernel News      Kernel 2.4.16 has been released, fixing an unmounting bug in 2.4.15 (released just recently) that causes fs corruption. The changelog for the first pre-version of 2.4.17 is available   here  2.4.x maintenance has been passed to Marcelo Tosatti.  But the horrible bug was Linus' fault, not his.  (""I inherited this mess from the previous administration,"" is what a US president would say.)   A new development series has been started, 2.5.x.  However, 2.5.0 is the same as 2.4.15, so it has the same horrible bug.  In other words, don't use it. LWN have  reported  the availability of a 2.5.1-pre3 prepatch that fixes this bug. No major changes (cleanups and fixes mostly).  This ends the over-a-year hiatus in which there was no development kernel.                Amazon Saves $$ With Linux and MS vs Linux            CNet  recently    reported  that ""Amazon.com was able to cut $17 million in technology expenses in the last quarter largely because of a switch to Linux."" This was also   reported  at The Register who have links to Amazon's SEC filing.   Before everyone starts predicting the demise of Windows, its worth pointing out that this gain was   at the expense of  UNIX servers (WinInfo). Still it is certainly encouraging. Especially so in light of The Register's report of a    Microsoft memo  describing Linux as  "" the  long-term threat against our core business.  Never forget that!"". You should really take a look at The Reg's report: the original memo is included at the end of the page, complete with references to butt-tattoos (don't ask!). The contents indicate that MS sees Linux as being an obstacle to their plan of replacing UNIX servers with MS powered (there's an oxymoron) servers. Sales folk are urged to identify UNIX systems in their customer's organisations, and then focus on getting MS into those functions (presumeably before some geek slips Linux in). (Story also   featured  on Slashdot.)   This  brings to mind the    Halloween memo  of 1998. To refresh your memory of the documents, and also on the intervening history, take a look at LWN's   editorial   revisiting the memos.  They ask--and answer--the question ""How many of the predictions came true?""                   Microsoft PR Spin Continues While Browser Lockout Still in Effect      Last month we briefly reported on the issue of   MSN  not working with non-Internet Explorer browsers, and  Opera Software 's comments on the situation. Since then, Opera have issued a    press release  detailing apparent inaccuracies/spin being fed into the media by Microsoft spokespeople. Also, not all site features are made available to non ""MSIE 5"" browsers. Seems the only way to get proper service is to set the browser identity to ""MSIE 5"". These kinds of behaviour (taking the Opera statement at face value) bode ill for the future of the open internet.                 Fermi National Accelerator Laboratory Powers New Particle Discovery With 96-Processor Linux NetworX Cluster Supercomputer         Linux NetworX  have announced that scientists at Fermi National Accelerator Laboratory (Fermilab) are using a Linux NetworX cluster to help identify new particles as part of a worldwide scientific collaboration to find subatomic clues to reveal the building blocks of the universe. Fermilab scientists are studying the collisions of protons and antiprotons in an effort to identify new particles that are produced as a result of the collisions.   Located in Batavia, Ill., Fermilab's 48-node cluster from Linux NetworX includes 96 Pentium III 1.0 GHz processors, 48 GB of memory (RAM) and a Fast Ethernet interconnect.                  Linux Clusters       The Register brought   the story  that Compaq  has followed through on its promise to GPL its NSC, or Non Stop Clusters code (the code that SCO licensed and co-developed as UnixWare Non Stop Clusters).  Compaq announced two projects - The CI Project (for the infrastructure) and SSI. ""...and here with one blow is a pretty comprehensive applications platform: Oracle can failover from node to node"", Peter Braam.    On the commercial front,  IBM  have introduced the world's first pre-packaged Linux cluster, a powerful and scalable system that has been optimized for e-business. The IBM eServer Cluster meets the demand of corporate customers who have neither the time nor inclination to ""roll their own"" Linux clusters from a collection of mismatched piece parts. They want an easy-to-order system delivered  and supported by  a single vendor. IBM gave no link to the press release.              Linux is Number 1 at Lyris          Lyris Technologies, Inc. ,  developer of email messaging and filtering software, have revealed  that downloads of its applications for Linux have surpassed all other Unix-based versions combined. Lyris' core products include    ListManager   for opt-in email newsletters, and MailShield for server-based protection against unsolicited email. Linux versions of Lyris software have grown from 40% to more than 60% of the company's Unix downloads since January 2001.         Distro News                Debian      The lates revision of the Debian 2.2 series of releases,    Debian 2.2r4 , has been unleashed. This release ""mostly includes security updates, along with a few corrections of serious bugs in the stable distribution.""     A vulnerability in the packages ssh-nonfree and ssh-socks has been    reported . Migration to OpenSSH is recommended, but updated non-free packages have been released.     Debian Weekly News    reported  that Javier Fernndez-Sanguino Pea has contributed a   Debian Euro HOWTO  to the Debian Documentation Project. This will be important reading for anyone living in or doing business with the European Union after January 1st.              LynuxWorks / BlueCat        LynuxWorks Inc. , a provider of open source and real-time embedded solutions, have unveiled the latest version of its popular BlueCat Linux distribution.               Mandrake       Mandrake Linux  have announced   Mandrake Linux Gaming Edition . This new edition comes on 4 CD's, and is powered by TransGaming Technologies' portability layer. The distro comes complete with Electronic Arts'  The Sims . Reports on the release are available   here  [Slashdot] and   here  [BluesNews].               SuSE           SuSE Linux   have announced SuSE Linux   Connectivity Server . The company's latest business product is a pre-configured Linux network solution, especially adapted to the requirements of SME and suitable for file and print services in company networks as well as secure connections to the Internet.     SuSE Linux, have  made an agreement with IBM to  distribute IBM's entire line of software for Linux in Europe,  Middle East and Africa as a Value Added Linux Distributor.     FirstLinux.com have   reviewed   SuSE 7.3, which has also recently been released in its   PowerPC Edition .          Software and Product News               OpenSSH         OpenSSH 3.0 has been    released  (as reported by Linux Today). Go to their    homepage  for details and downloads (3.0.1 was later released on Nov. 15th).              XNotesPlus V3.4.0 Debuts        Michael J. Hammel, the Graphics Muse, is pleased to announce the release of version 3.4.0 of XNotesPlus, a Personal Information Manager for the Linux and Unix desktop.  XNotesPlus includes support for all major features on the Palm Pilot, including Memos, Todo Lists, the Address Book and Calendaring.  All data from each feature can be downloaded from the Pilot, edited within XNotesPlus and uploaded back to the Pilot.  Additionally, backups and restores of a Pilot PDA can be managed from within XNotesPlus.    The release of XNotesPlus includes numerous bug fixes, many of which were serious problems in earlier releases.  Users of older versions are highly encouraged to upgrade.    XNotesPlus is available in both   source  and   Red Hat Linux 7.0  dynamically built binary distributions.              Creatures on Linux         Creature Labs Ltd and Linux Game Publishing Ltd have announced that Creatures Internet Edition, the latest in the breakthrough Creatures series, is to be released for Linux. Creatures Internet Edition is a bundle of Creatures 3 and Creatures Docking Station and it also includes 4 different Norn breeds (the creatures within the game).  The game allows interaction with other players over the internet.  For more information about Creatures Internet Edition, please visit    http://ds.creatures.net/expansion/cie.pl .                Rackspace Partners with Red Hat on E-commerce         Rackspace Managed Hosting   a provider of managed hosting services, and    Red Hat Linux  have launched E-Commerce Complete, a comprehensive, hosted e-commerce solution. The offering features the Red Hat E-Commerce Suite installed and pre-configured on a Rackspace hosting platform, and it includes support and services from both companies to ensure complete integration and smooth management of the application.               Sharp Goes for Opera in Embedded Software Solution        Opera Software today announced that Sharp   Opera Software  have announced that Sharp will use its Opera 5 for Linux Web browser in the Zaurus SL-5000D developer unit.  The Zaurus SL-5000D is a robust Linux/Java-based handheld.  The Opera Web browser will be used as part of    Lineo, Inc's  powerful software solution Embedix Plus PDA, launched at JavaOne in June this year. Apart from Opera 5 for Linux, the Embedix Plus PDA solution contains Lineo's Embedix Linux,    Trolltech's  Qt/Embedded and QT Palmtop graphical user interfaces, and    Insignia Solution's  Jeode PDA Edition.               Linux Application Appliance and Application Partner Program from Tricord           Tricord Systems , developer of the IlluminaTM clustering software and Lunar FlareTM NAS appliance-- have    announced  a new application appliance series for independent software developers and systems integrators.  The Lunar Flare AA 1100 and AA 1200 support Linux-based applications, consolidating them on an easy-to-manage, fault tolerant, scalable platform with unique clustering and storage capabilities. Tricord's application appliance series combines a high-performance Linux server with built-in clustered storage, making it an optimal appliance solution for content-hungry applications.   Additionally Tricord Systems, and   Tarantella , have    announced  that Tarantella Enterprise 3 software has been certified on Tricord's Lunar Flare Application Appliance (AA) platform.                GUI Programming with Python        The Python/QT book; GUI Programming with Python: QT Edition is in final edit and will be shipping by the end of the month. For those who are unaware QT is the toolkit behind many powerful applications, including the KDE Desktop for Linux/UNIX.   The new book covers the use of Python and QT extensively, including the Blackadder RAD environment for Windows and Linux. For those interested please visit:   http://stage.linuxports.com/projects/pyqt                  Grey Zone Announces the 3 Minute Extranet with SecureZone 5          Grey Zone , a developer of out-of-the-box Linux-based Web content management software, announces the release of SecureZone 5.  SecureZone 5 enables business users to create a completely functioning extranet, including users and content, in as little as 3 minutes.  SecureZone empowers non-technical professionals to rapidly spawn an unlimited number of distinct Web sites from a single platform.  The product combines security, content management, and audience-based publishing capabilities that simplify the Web publishing process, helping companies rapidly and cost-effectively conduct business over the Web. Although ease of use is a major priority, SecureZone is also very feature rich. For more information consult   Grey Zone's web page . SecureZone pricing begins at $50,000.                 XML/PosgreSQL Application Server LXP 0.8         Command Prompt, Inc.  announced the release of    LXP   version 0.8.0, Command Prompt's PostgreSQL application server. The LXP application server provides easy access to the advanced features of PostgreSQL. LXP offers a suite of services to assist the Linux web developer produce easily managed, dynamic websites, data driven websites. Beyond the LXP markup language you can also utilize the following languages through our direct URI support: Java, PHP, C, C++, Python, and Perl. LXP also offers a fast valid XML parsing engine, useful to support industry standard DTDs such as RDF/RSS. An example of LXP application can be found at  LinuxPorts.Com .                Teamware Office 5.3 for Linux Edition 4            Teamware Group , a Fujitsu subsidiary, have released edition 4 of Teamware Office 5.3 for Linux, a complete set of ready-to-run groupware applications for today's business professionals. In the new edition the main emphasis is on web service enhancements. Edition 4 is the first Teamware Office for Linux version with the main focus on the browser side. The new look & feel for the web service client templates has been developed according to extensive usability research and customer requests. Via the renewed web service Teamware Office modulescan be easily accessed with standard web browsers. The service enables fixed www addressing for any Teamware Office object over standard HTML templates making integration with other web based systems as well as search engines easy.   Teamware Office can be purchased online through the Teamware web site at   www.teamware.com/linux .  Also a free 90-day evaluation version can be downloaded at the site.                Copyright © 2001, Michael Conry and  the Editors of  Linux Gazette .  Copying license  http://www.linuxgazette.com/copying.html  Published in Issue 73 of  Linux Gazette , October 2001        ""Linux Gazette... making Linux just a little more fun! ""                 Linux User Caricatures   By  Franck Alcidi                                     Hint:   ""kernel"" is pronounced ""Colonel"" in English.   Colonel Sanders is the mascot of the Kentucky Fried Chicken (KFC) restaurant chain.                Previous cartoons published in Linux Gazette:      Linux User Charactures , issue 72.      You can view my other artwork and sketches on my  projects page .          Franck Alcidi   Franck is an artist in Australia.  His home page (""Ausmosis"") is  http://www.ozemail.com.au/~geisha/projects.html .                  Copyright © 2001, Franck Alcidi.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 72 of  Linux Gazette , November 2001        ""Linux Gazette... making Linux just a little more fun! ""                 The Art of Atari ST Emulation   By  Matthias Arndt                     Contents          Contents   1 Introduction   2 What is emulation?   3 Machine Facts   4 ST Emulation   5 ST Emulators for Linux     5.1 Things common to all emulators   5.2 STonX   5.3 STEEM on Linux   5.4 Hatari     6 TOS   7 Software for the ST   8 Community   9 Conclusion   About this document ...            1 Introduction       I'm quite an Atari ST fan. It was the computer that introduced me to computing in the first place. It was a thrill that changed my life forever.    All those of you who prefer the Amiga, write your own article instead of claiming the ST was or is crap.    What? You don't know what the ST is? It's a late-80s, early-90s 16/32-bit home and semi-professional computer system manufactured by Atari.  The ST still has many friends all over the world, the Atari ST community is very active on the web due to the fact of emulation. Just visit the Little Green Desktop  ( www.atari.st ) or   www.atari.org  to see what I mean.    This article concentrates on Atari ST emulation on Linux, describing the available emulators and some useful information about ST emulation in general.       2 What is emulation?       Emulation tries to rebuild the behavior and performance of hardware components with software. Practically this means to make your PC think it is another computer with a different hardware architecture and in most cases another OS, enabling you to run a great amount of software written for the emulated system on your real box.    In our case, this means running software for the Atari ST on your Linux box.       3 Machine Facts       Anyone who is interested in emulation should at least know the hardware facts of the emulated system. Here we go:    (all data refers to the standard ST, not the TT, Falcon or clones)        CPU: Motorola 68000 running at 8MHz clock speed with a 32Bit wide bus    RAM: either 512K, 1MB, 2MB or 4MB (depending on model)    ROM containing the OS: 192K or 256K (depending on model and OS version)    Shifter video subsystem capable of the following video modes:         320x200 pixels, 16 colours out of 512 (50 or 60Hz)    640x200 pixels, 4 colours out of 512 (50 or 60Hz)    640x400 monochrome running at 72Hz         Yamaha sound chip playing 3 voices simultaneously    build-in MIDI ports (In and OUT)    ROM port to connect a 128K size cartridge    optionally Hard disc    up to 2 floppy drives, either SD or DD standard    serial and parallel ports    mouse    Atari digital joystick support    TV out (ordinary antenna connector) on the M and STE models    OS: TOS (Tramiel Operating System) with builtin GEM    models released up to 1992 (OS version and amount of RAM varies): 520ST, 520STM, 520STFM, 260ST, 520ST+, 1040ST, 1040STF, 1040STFM, 1040STE, 520STE, Mega ST1, Mega ST2, Mega ST4 and Mega STE     The STE models had advanced sound and graphic capabilities.    Always keep in mind that this machine was introduced in the spring of 1985 and the masses were stunned. More capable than a Macintosh of that period and much cheaper at that time.    Just as a little overview of what an emulator has to emulate.       4 ST Emulation       The first attempt at emulating the ST was the Gemulator in 1994 or 1995.  It was an emulator for DOS that needed a special hardware plug-in card. Nowadays, all ST emulators are software-only solutions.    The ST Emulation boom started in 1997 with the DOS based emulator PacifiST written by Frederic Gidouin.    Since then several other ST emulators have reached a very high niveau such as WinSTon or STEEM. This applies partly to ST Emulation on Linux as well. STEEM is now officially available for Linux, and STonX is getting better and better at each release.       5 ST Emulators for Linux          5.1 Things common to all emulators       All ST emulators have the following things in common:        They cannot use real ST floppy discs due to problems with floppy controller programming.    None of these emulators emulate the MIDI ports (STEEM perhaps, at least in the Windows version).    None of these emulators is able to run software from copy-protected disks, so forget about your old originals.           5.2 STonX       The famed STonX was the first and for a long time the only ST emulator available for Unices. It now reached a really usable state, although still not wonderful to play games and run demos on it.    A few quick facts:        doesn't require much CPU power to run it.  A Pentium-class machine with 16MB RAM is sufficient    either support for 4MB or 14MB of ST RAM    supports all ST graphic modes but no overscan or rasters    support for X and SVGALib output    can run in window or full-screen    support for emulated hard-drive, means; mounting of Linux directory trees possible    support for disk images in standard format (*.ST files found on the net)    support for extended ST graphic modes    sound chip emulation    buggy Joystick support (at least I couldn't make it work on my machine)    supports all TOS versions but still prefers a TOS 2.x for best performance    comes as GPLed source code    easy to port to other Unices - STonX runs also on Solaris and AIX     STonX may not be the emulator of choice for games or demos but it is definitely the emulator of choice for developing system-conformant (meaning GEM) applications. It runs pretty fast and smooth. And I couldn't make it crash in 6 months of operation (The emulated ST may still crash but not the emulator program itself).    Really annoying at the moment are:        Joystick support is buggy    no .MSA disk image files    no overscan    too fast for games      But no program is perfect - STonX is definitely worth a try. It is better than one might expect.    STonX can be found at:  http://stonx.sourceforge.net/ .       5.3 STEEM on Linux       This is a port of the STEEM emulator to Linux. It is not GPLed but freeware.    STEEM is much better suited for games, since it features even STE graphics and sound, overscan and raster effects included. It runs many demos and most games.    STEEM facts are:        STE emulation included    can use both .ST and .MSA disk images    Joystick support via keyboard    sound support which sometimes seems to be out of sync (sound effects playing half a second late)    runs all versions of TOS except 1.62 which shouldn't be used at all    nifty interface (remember, STEEM is also available for Windows)    runs many but not all games (at least Super Cars 2 and Xenon work  )    Freeware but not GPLed: only available as a binary distribution     STEEM is close to be perfect. Some features of the Windows version are still missing but it runs pretty good. And its main advantage over STonX: it runs games and demos!    STEEM can be found at:  http://steem.atari.org/ .       5.4 Hatari       Hatari is a port of the WinSTon source code to Linux. It is still in early alpha phase and unusable at the moment.    Check  http://hatari.sourceforge.net/  for details.       6 TOS       As stated above the TOS is the Atari ST's default operating system. (You can run Minix, Mint and several other systems as well.)    Obviously, all ST emulators need a TOS ROM in order to work. It is not included with the emulators and always keep the copyright in mind. There are several places on the net to get TOS images, and there are programs available that allow you to extract the TOS ROM of your ST to a file.       7 Software for the ST       There is still a large amount of ST software around on the net. FTP sites carry public domain and freeware, and some sites have pirated ST games online. Finally, the ST community on the net is very supportive when looking for ST software.       8 Community       There is a large Atari community on the net, several IRC channels, bulletin boards and a hierarchy of Usenet news is available.    A few useful tips:        http://www.atari.st/  - The Little Green Desktop (primary ST emulation site) has a forum and an incredible games archive - go check it out.     http://www.atari.org/  - The main portal of the Atari community features news, forums and lots of links. 90% of the ST related sites on the net can be found here in the Links archive.    comp.sys.atari.st and other newsgroups are available    #atari on IRC may help as well     At the time of this writing, November 2001, the Little Green Desktop is still in a redesign phase but that may change by the time this article is online.       9 Conclusion       The Atari ST is still alive - and you can support this development on Linux. Join us by running an Atari ST emulator. Even if you never had an ST, it is worth a try.     Take me for example, I never had a C64, VCS2600 or ZX Spectrum, but I run emulators for all of them.    Always remember: Atari will never die!              Matthias Arndt   I'm a Linux enthusiast from northern Germany. I like plain old fifties rock'n'roll music, writing stories and publishing in the Linux Gazette, of course. Currently I'm studying computer science in conjunction with economics.                  Copyright © 2001, Matthias Arndt.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 73 of  Linux Gazette , December 2001         ""Linux Gazette... making Linux just a little more fun! ""               Audio Processing Pipelines   By  Adrian J. Chung                   For decades experienced Unix users have employed many text processing tools to make document editing tasks much easier.  Console utilities such as  sed ,  awk ,  cut ,  paste , and  join , though useful in isolation, only realise their full potential when combined together through the use of pipes.    Recently Linux has been used for more than just processing of ASCII text.  The growing popularity of various multimedia formats, in the form of images and audio data, has spurred on the development of tools to deal with such files.  Many of these tools have graphical user interfaces and cannot operate in absence of user interaction.  There are, however, a growing number of tools which can be operated in  batch mode  with their interfaces disabled.  Some tools are even designed to be used from the command prompt or within shell scripts.    It is this class of tools that this article will explore.  Complex media manipulation functions can often be effected by combining simple tools together using techniques normally applied to text processing filters.  The focus will be on audio stream processing as these formats work particularly well with the Unix filter pipeline paradigm.    Sound Sample Translator     There are a multitude of sound file formats and converting between them is a frequent operation.  The sound exchange utility  sox   fulfills this role and is invoked at the command prompt:   sox sample.wav sample.aiff    The above command will convert a WAV file to AIFF format.  One can also change the sample rate, bits per sample (8 or 16), and number of channels:   sox sample.aiff -r 8000 -b -c 1 low.aiff     low.aiff  will be at 8000 single byte samples per second in a single channel.   sox sample.aiff -r 44100 -w -c 2 high.aiff     high.aiff  will be at 44100 16-bit samples per second in stereo.    When  sox  cannot guess the destination format from the file extension it is necessary to specify this explicitly:   sox sample.wav -t aiff sample.000     The "" -t raw "" option indicates a special headerless format that contains only raw sample data:   sox sample.wav -t raw -r 11025 -sw -c 2 sample.000     As the file has no header specifying the sample rate, bits per sample, channels etc, it is a good idea to set these explicitly at the command line.  This is necessary when converting from the  raw  format:   sox -t raw -r 11025 -sw -c 2 sample.000 sample.aiff       One need not use the "" -t raw "" option if the file extension is  .raw , however this option is essential when the raw samples are coming from standard input or being sent to standard output.  To do this, use the "" - "" in place of the file name:   sox -t raw -r 11025 -sw -c 2 - sample.aiff < sample.raw     sox sample.aiff -t raw -r 11025 -sw -c 2 - > sample.raw    Why would we want to do this?  This usage style allows  sox  to be used as a filter in a command pipeline.   Play It Faster/Slower   Normally  sox  adjusts the sample frequency without altering the pitch or tempo of any sounds through the use of interpolation.  By piping the output of one  sox  to the input of another and using unequal sample rates, we can bypass the interpolation and effectively slow down a sound sample:   sox sample.aiff -t raw -r 44100 -sw -c 2 - | sox -t raw -r 32000 -sw -c 2 - slow.aiff    or speed it up:   sox sample.aiff -t raw -r 32000 -sw -c 2 - | sox -t raw -r 44100 -sw -c 2 - fast.aiff      Simple Editing   Suppose one wants a sample consisting of the first two seconds of some other sound file.  We can do this using  sox  in a command pipeline as shown here:   sox sample.aiff -t raw -r 44100 -sw -c 2 - | head -c 352800 | sox -t raw -r 44100 -sw -c 2 - twosecs.aiff    The input file  sample.aiff  is converted to 44.1kHz samples, each two bytes in two channels. Thus two seconds of sound is represented in 44100x2x2x2 = 352800 bytes of data which are stripped off using "" head -c 352800 "".  This is then converted back to AIFF format and stored in  twosecs.aiff     Likewise to extract the last second of a sample:   sox sample.aiff -t raw -r 44100 -sw -c 2 - | tail -c 176400 | sox -t raw -r 44100 -sw -c 2 - lastsec.aiff    and the third second:   sox sample.aiff -t raw -r 44100 -sw -c 2 - | tail -c +352801 | head -c 176400 | sox -t raw -r 44100 -sw -c 2 - lastsec.aiff    Note that with 16-bit samples the argument to "" tail -c + N "" must be odd, otherwise the raw samples become misaligned.    One can extract parts of different samples and join them together into one file via nested sub-shell commands:   (sox sample-1.aiff -t raw -r 44100 -sw -c 2 - | head -c 176400  sox sample-2.aiff -t raw -r 44100 -sw -c 2 - | head -c 176400 ) |  sox -t raw -r 44100 -sw -c 2 - newsample.aiff    Here we invoke a child shell that outputs raw samples to standard output from two different files.  This is piped to a  sox  process executing in the parent shell which creates the resulting file.   Desktop Sound Output     Sounds can be sent to the OSS (open sound system) device  /dev/dsp  with the "" -t ossdsp "" option:   sox sample.aiff -t ossdsp /dev/dsp    The  sox  package usually includes a platform-independent script  play  that invokes  sox  with the appropriate options.  The previous command could be invoked simply by   play sample.aiff      Audio samples played this way monopolise the output hardware.  Another sound capable application must wait until the audio device is freed before attempting to play more samples.  Desktop environments such as GNOME and KDE provide facilities to play more than one audio sample simultaneously.  Samples may be issued by different applications at any time without having to wait, although not every audio application knows how to do this for each of the various desktops.   sox  is one such program that lacks this capability.  However, with a little investigation of the audio media services provided by GNOME and KDE, one can devise ways to overcome this shortcoming.    There are quite a few packages that allow audio device sharing.  One common strategy is to run a background server to which client applications must send their samples to be played.  The server then grabs control of the sound device and forwards the audio data to it. Should more than one client send samples at the same time the server mixes them together and sends a single combined stream to the output device.    The Enlightened Sound Daemon (ESD) uses this method.  The server,  esd , can often be found running in the background of GNOME desktops.  The ESD package goes by the name,  esound , on most distributions and includes a few simple client applications such as:    esdplay  - plays sound samples stored in one of the more popular file formats (WAV, AU, or AIFF)  esdcat  - submits raw sound samples to the server. This tool is a natural fit for terminating a pipeline of sound filters.    This command will play the first second of a sample via ESD:   sox sample.aiff -t raw -r 44100 -sw -c 2 - | head -c 176400 | esdcat    One can also arrange to play samples stored in formats that ESD does not understand but can be read by  sox :   sox sample.cdr -t raw -r 44100 -sw -c 2 - | esdcat    In some cases samples can sound better when played this way.  Some versions of ESD introduce significant distortion and noise when given sounds recorded at a low sample rate.    The Analog RealTime Synthesizer (ARtS) is similar to ESD but is often used with KDE.  The background server is  artsd  with the corresponding client programs,  artsplay  and  artscat . To play a sample:   sox sample.cdr -t raw -r 44100 -sw -c 2 - | tail -c 352800 |artscat      Both ESD and ARtS are not dependent on any one particular desktop environment.  With some work, one could in theory use ESD with KDE and ARtS with GNOME.  Each can even be used within a console login session.  Thus one can mix samples, encoded in a plethora of formats, with or without the graphical desktop interface.   Music as a Sample Source     Having covered what goes on the end of an audio pipeline, we should consider what can be placed at the start.  Sometimes one would like to manipulate samples extracted from music files in MP3, MIDI, or module (MOD, XM, S3M, etc) format.  Command line tools exist for each of these formats that will output raw samples to standard output.    For MP3 music one can use "" maplay -s ""   maplay -s music.mp3 | artscat    The  music.mp3  must be encoded at 44.1kHz stereo to play properly otherwise  artscat  or  esdcat  will have to be told otherwise:   maplay -s mono22khz.mp3 | esdcat -r 22050 -m  maplay -s mono22khz.mp3 | artscat -r 22050 -c 1    Alternatively one can use "" mpg123 -s "".  Additional arguments ensure that the output is at the required rate and number of channels:   mpg123 -s -r 44100 --stereo lowfi.mp3 | artscat      Users of Ogg Vorbis may use the following:   ogg123 -d raw -f - music.ogg | artscat    Piping is not really necessary here since  ogg123  has built-in ESD and ARtS output drivers.  Nevertheless, it is still useful to have access to a raw stream of sample data which one can feed through a pipeline.     Music files also can be obtained in MIDI format.  If (like me) you have an old sound card with poor sequencer hardware, you may find that  timidity  can work wonders.  Normally this package converts MIDI files into sound samples for direct output to the sound device. Carefully chosen command line options can redirect this output:   timidity -Or1sl -o - -s 44100 music.mid | artscat    The "" -o - "" sends sample data to standard output, "" -Or1sl "" ensures that the samples are 16-bit signed format, and "" -s 44100 "" sets the sample rate appropriately.    If you're a fan of the demo scene you might want to play a few music modules on your desktop.  Fortunately  mikmod  can play most of the common module formats.  The application can also output directly to the sound device or via ESD.  The current stable version of  libmikmod , 3.1.9, does not seem to be ARtS aware yet.  One can remedy this using a command pipeline:   mikmod -d stdout -q -f 44100 music.mod | artscat    The  -q  is needed to turn off the curses interface which also uses standard output.  If you still want access to this interface you should try the following:   mikmod -d pipe,pipe=artscat -f 44100 music.mod    Only the later versions of  mikmod  know how to create their own output pipelines.    Effects Filters   Let us return to the pipeline friendly  sox .  In addition to its format conversion capabilities, there is small library of effects filters.  Here are some examples:     Add echo  play sample.aiff echo 1 0.6 150 0.6     Add vibration  play sample.aiff vibro 20 0.9     Add severe distortion  play sample.aiff flanger 0.7 0.7 4 0.8 2 play sample.aiff phaser 0.6 0.6 4 0.6 2     Band pass filter -- sounds like a bad phone connection:  play sample.aiff band 3000 700   or listening through a thick blanket:  play sample.aiff band 0 700     Make a chorus of sounds from one sample:  play sample.aiff chorus 0.7 0.7 20 1 5 2 -s     Hidden messages? Play it backwards:  play sample.aiff reverse     Warning: Depending on the size of the sample, this can use up a lot of memory and/or disk space         Putting It All Together   The major components of an audio command pipeline have now been covered.  Let us see how they can be combined together to perform a few non-trivial functions:      Play a music module on the KDE desktop with a chorus effect:   mikmod -d stdout -q -f 44100 music.xm |  sox -t raw -r 44100 -sw -c 2 - -t raw - chorus 0.7 0.7 80 0.5 2 1 -s |  artscat      Play a song in Ogg Vorbis format with the first 4 seconds removed:  ogg123 -d raw -f - music.ogg | tail -c +705601 |artscat      Convert a MIDI file to Ogg Vorbis format introducing a little added echo:   timidity -Or1sl -o - -s 44100 music.mid |  sox -t raw -r 44100 -sw -c 2 - -t raw - echo 1 0.6 80 0.6 |  oggenc -o music.ogg --raw -    The pipeline has been terminated with the Ogg Vorbis encoder,  oggenc , configured here to accept raw sample data from standard input.    Convert a 32kHz mono MP3 file to 44.1kHz stereo Ogg Vorbis file, lowering the volume in the process:   maplay -s mono32.mp3 |  sox -v 0.5 -t raw -r 32000 -sw -c 1 - -t raw -r 44100 -c 2 - split |  oggenc -o music.ogg --raw -      Concatenate all AIFF files in the current directory into a single WAV file:  for x in *.aiff  do sox $x -v 0.5 -t raw -r 8000 -bu -c 1 -  done | sox -t raw -r 8000 -bu -c 1 - all.wav         Hopefully these examples hint at what can be accomplished with the pipeline technique.  One cannot argue against using interactive applications with elaborate graphical user interfaces.  They often can perform much more complicated tasks while saving the user from having to memorise pages of argument flags.  There will always be instances where command pipelines are more suitable however.  Converting a large number of sound samples will require some form of scripting. Interactive programs cannot be invoked as part of an  at  or  cron  job.    Audio pipelines can also be used to save disk space.  One need not store a dozen copies of what is essentially the same sample with different modifications applied. Instead, create a dozen scripts each with a different pipeline of filters.  These can be invoked when the modified version of the sound sample is called for.  The altered sound is generated on demand.    I encourage you to experiment with the tools described in this article.  Try combining them together in increasingly elaborate sequences.  Most importantly, remember to have fun while doing so.                  Adrian J Chung   When not teaching undergraduate computing at the University of the West Indies, Trinidad, Adrian is writing system level scripts to manage a network of Linux boxes, and conducts experiments with interfacing various scripting environments with home-brew computer graphics renderers and data visualization libraries.             Copyright  2001, Adrian J. Chung.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 73 of  Linux Gazette , December 2001      ""Linux Gazette... making Linux just a little more fun! ""                 Microsoft's New Briar Patch   By  Jim Dennis                   By now most of use with an interest in the software industry and/or in the free software movement have probably heard of Microsoft's latest legal maneuvers, an offer to settle the remaining local antitrust cases (brought by many state's attorneys general) by  providing computers and software  to U.S. public schools.      ""Please don't put me in de  bre'r patch !  Anything but that!"" -- Uncle Remus       I can't believe that I'm alone in seeing this as playing into Microsoft's hands.  If practically all of our children are raised running nothing but Microsoft software, then that's what they'll expect in college and throughout their careers.      Microsoft should be paying dearly to gain such a lucrative franchise.   This is a far cry from punishment or remediation.  Indeed, it is  antithetical to restoring competition to the software industry.    As a Linux user and enthusiast, I don't care about Microsoft.  I never believed that the Federal antitrust case would be effective; and I see the various state and private suits as being mere echos to that. The Europeans might see more effective measures taken by their EC,  but that is unlikely.  However, as an observer of the software industry,  and a veteran in various segments of that market I have to re-iterate my  views on the matter.     The only effective and fair remedies in this case must relate to the software.  Specifically Microsoft must be required to publish source  code to complete and working reference implementations of each protocol, API, and file format that they use in any of their applications and  operating systems.  They must be forbidden from distributing new software until the reference implementations are published.  The reference  implementations must be in the public domain (freely usable by all for free and commercial works).    In other words, given that Microsoft has become the standard in the industry (at least in part through illegal and anti-competitive means) then they bear the burden of providing enough information to everyone else to  ensure  interoperability.    We could argue endlessly about the adequacy of documentation, and the need to publish ""internal"" programming interfaces or ""administrative"" protocols.  This would be a miscarriage of justice.  Requiring a reference implementation for a set of command line primitive utilities, in  ANSI standard C and/or C++ (no MSC or MFC entanglements) provides an unambiguous standard for their compliance.  Either the requisite reference tools can perform the designated (minimal) functions over their protocols, on their target files, or calling their OS/library components, or MS is fined and enjoined from further distribution.    Note that this approach does not force MS to publish the sources to their OS or their applications.  They are free to create an independent reference  implementation.  Of course that would be a expense to them; the cheapest path to compliance would be for them to engineer their software with a  core (that would separately constitute the reference suite) and then add their UI elements on top of that.    However, it is vital that they be prohibited from releases new software until the reference suite is shown to provide the requisite interoperability. It's also critical that the remedy encompass protocols, APIs, and file formats.    Any less is just another example of government and big business posturing to the public while cutting their own backroom deals to line the pockets of the politicians and lockout the ""little guy"" businesses.                 Jim Dennis   Jim Dennis  is the proprietor of   Starshine Technical Services . His professional experience includes work in the technical  support, quality assurance, and information services (MIS) departments of software companies like    Quarterdeck ,    Symantec/ Peter Norton Group , and    McAfee Associates  -- as well as  positions (field service rep) with smaller VAR's. He's been using Linux since version 0.99p10 and is an active participant on an ever-changing list of mailing lists and  newsgroups.  He's just started collaborating on the 2nd Edition for a book on Unix systems administration. Jim is an avid science fiction fan -- and recently got married at the World Science Fiction Convention in Anaheim.                   Copyright © 2001, Jim Dennis.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 73 of  Linux Gazette , December 2001        ""Linux Gazette... making Linux just a little more fun! ""                 Winning the Battle for the Desktop   By  Dennis Field                    Last month  ( Battle for the Desktop: Why Linux Isn't Winning , issue 72), I recounted my misadventures in trying to install Linux onto an IBM ThinkPad, and called several unnamed venders to task for failing to provide adequate documentation and/or customer support. Or testing their software before releasing it, but that's a different story . . .     Well, I actually sold that laptop to a fellow writer (who is perfectly happy with it running WordPerfect under W*ndows 98 Second Edition). I am currently looking for a slightly newer ThinkPad that will support booting directly from a CD. I haven't found one yet, because I'm on a tight budget and, given my previous experience, I want to get something that is at least marginally capable of running Windows XP. Yes, I know I just used the ""W"" word again (for those wishing to stone me, there's a pile of rocks to your left. Anyone wishing to lynch me, however, must supply their own rope).     As far as distributions go, I'm waiting for the latest version of Libranet Linux (due at the end of the month, although they've already delayed the release once - apparently wishing to make sure it works before they ship it. What a novel idea!). They are the one vender from last month's article that actually bothered to answer my email, or to publish their hardware requirements. Meanwhile, I downloaded their old version so I can try it out on my desktop before purchasing the new release. Libranet is based on Debian, and I have heard that Debian actually provides some of the documentation I keep ranking about. If any other venders are already providing the documentation and support I'm referring to, then please understand that this article is directed at those venders who aren't - which is the majority of them, in my experience.     Windows XP is now out, and I continue to be amazed at the opportunity that Linux venders have squandered. After I couldn't find a functional version of Linux (remember, that pile of rocks is to your left), I was forced to upgrade my home PC to XP. XP doesn't really do anything 98 wasn't supposed to be able to do, although I've been running it for almost three weeks now and only had it crash twice (a record for a Microsoft product!). Both times it even rebooted itself without locking up. But Microsoft's infamous Product Activation and obnoxious attempts to hijack everything in the world even vaguely related to computers have continued to sour people on the idea of even trying XP. If any Linux vender had a functional OS, packaged with a good suite of business applications, they could be eating Microsoft's lunch right now.     The first and foremost step in winning the battle against Microsoft will be to introduce a concept which is apparently entirely unknown in the Linux community. This revolutionary new strategy is called Customer Service. No, by this I do not mean the customer is always right (I work in a retail store, remember?). Nor do I mean that Linux should be made into an idiot-proof, one-size-fits-all Windows clone that does all your thinking for you - whether you want it to or not. What I mean is that the objective, goal and overall attitude of those wishing to advance Linux should be  to meet their customer's needs.  Listen closely here, because there's something that a lot of Linux people are currently not understanding: The objective is  not  to get the software on the CD.  The objective is for the customer, i.e.; the end user, to be able to successfully use that software in his business, life, Conquest of the Galaxy. Whatever.     In the late Douglas Adam's science-fiction satire  Life, the Universe and Everything , he introduces a whimsical invention called the ""SEP Field"" (chapter 3). He begins by explaining that to make something (say, a mountain) truly invisible is both infinitely complex and requires fantastic amounts of energy. But if you erect a cheap and simple SEP Field around the mountain, ""then people will walk past the mountain, around it, even over it and simply never notice the thing is there.  An SEP is something that we can't see, or don't see, or our brain won't let us see, because we think that it's somebody else's problem. That's what SEP means.  Somebody Else's Problem.  The brain just edits it out; it's like a blind spot.  If you look at it directly you won't see it unless you know precisely what it is.""     Well, apparently there are a lot of Douglas Adams fans in the world of Linux. Because the single most common response I got from those who objected to last month's article was that I was blaming vender's for things beyond their control. This is a view that is certainly shared by the venders themselves: Your software doesn't install? That's not our problem! There are no instructions telling you how to configure our firewall? Too bad! The software works, but you can't get it to do what you want? Well, figure it out yourself! What? You want us to tell you if Linux will work with your hardware before you buy it? Well, that's certainly not very reasonable of you to expect that level of service!     Now, for the record, I will concede that if it's an obscure printer that only 3 people in the world are using, then it's probably never going to get supported. In which case, you should at least be able to tell your customers that it's not supported, so they won't waste their time trying to get it to work. But the real bottom line is that this doesn't solve the user's problem. And if you're honest you will have to admit that the attitude of dismissing users valid problems as being Somebody Else's Problem covers a whole lot more than just print drivers in the world of Linux.     Am I being unreasonable in expecting venders to actually solve their customers problems? Many of you have said that the Linux venders are not responsible for third-party problems. Well, let me tell you a little story: Last year, everyone in our office chipped in and got our boss a Handspring Visor for Christmas. The first week he had it, he installed some third party software that wiped out the USB connection in his Windows box. We called the third party vender and they denied all knowledge of the problem and had no idea how to fix it. We then called Handspring and explained that the Visor connected just fine until we installed Somebody Else's software, and now it wouldn't connect at all. We'd already tried uninstalling the third party software, we'd tried reinstalling the Windows USB drivers, we even deleted all references to the bad software from the Windows registry. Still no USB connection. Did Handspring have any ideas? Their response was: ""No problem, we've done this before"".  Their phone tech then preceded to lead my boss, step by step, thru opening the Windows registry, finding an obscure entry and editing it. The tech then cheerfully waited while the computer was rebooted to make sure that the problem was fixed. Now, Handspring is  not  responsible for Windows, and they are certainly not responsible for the third party software that caused the problem.  But Handspring knows that the value of their product depends upon being able to connect it to a PC.  So they make it a point to know how to fix connection problems instead of just blaming them on someone else. The last that I heard, Handspring was selling Visors as fast as they could build them, largely to business people.  These same business people won't take a copy of Linux for free. So which approach do you think is more effective? Let me give you a hint: We now have a total of six Visors in our office, and zero Linux boxes.     Wait! Stop. I can already hear your screams of protest. Every Linux vender on the planet is now getting ready to email me to explain that they don't have the resources to do that! Maybe IBM can afford to have world-class Customer Service, but the poor little Linux venders and software companies can't even afford to have anyone answer the phone now. How are they supposed to provide support for their customers? Well, I have a solution for them. You see, there's this newfangled invention called the ""Internet"". People can build something called a ""website"" and post information on it. What? You've already got a website? Well, let's give  it a little test: Go to ibm.com, look up a model of computer and see how much information IBM provides to help their customers use it. Now go to a couple of Linux sites and see how much information they provide. Oops. I hear more screams of protest. You are now yelling ""Do I have any idea what it costs to build and maintain a professional quality website like IBM's?"" Well, perhaps not (although if IBM has more money to spend on website development than you make, then they must be doing  something  right <g>). But I do know a way the smallest Linux vender can compete with IBM in terms of information available, if not polish and web graphics.     Again, the key to IBM's website is not that they manufacture their own servers. The key is that IBM is concerned with making sure that their customers have  whatever it takes to use the products . IBM doesn't just say ""Well, we built a perfectly good laptop, it's not our problem if you can't get it to work"". IBM makes sure that you  can  get it to work. In like manner, I propose that Linux venders build support websites with two key features:     1) The vender should post current information on their distribution's file structure, boot options, port assignments, common command line switches, etc. This should also include professional HOWTO's on installing a new X server, recompiling the kernel, trouble shooting network problems and any other common difficulties. Isn't this all available on the net? Yes, and every HOWTO on the net includes the disclaimer ""This works with SUSE, but I don't know about Red Hat"" or ""I tried this with version 5.1, but 5.2 does it differently"". The vender is the one who knows both the file structure and correct procedures for that  specific  version. And that is the information people  need  to have. One of the great strengths of Linux is that you can work on it yourself. But if you were trying to fix the engine in a '96 model Mercedes, how would you feel if the Mercedes factory sent you a repair manual for an '84 model Ford along with a note that said ""Well, this is pretty close, maybe you can just figure out the differences""?     2) But the venders can't possibly test every piece of hardware, or know every different network configuration! So they shouldn't even try to offer user support, right? WRONG! The second feature that needs to be on the vender's website is an area where users can post HOWTO's of their own. Again, this information needs to be version specific. Not just how to install  some  printer under  some  version of Linux, but detailed, step by step instructions for how to install a Canon BJC250 with distribution 6.5. That way the first person with a BJC250 can pass the correct settings on to everyone else (otherwise everybody is forced to reinvent the wheel). But the Internet is already loaded with Linux HOWTOs. Why add more? Several reasons. Aside from version specific information, having the HOWTO's submitted to the vender for posting means the vender can, if not test each one, at least visually inspect all HOWTO's for apparent errors before posting them. Which at least prevents some joker from telling newbies that the first step in installing a printer is to reformat the hard drive <g>. This would also represent a tremendous research tool for the venders. By adding a couple of radio buttons for user feedback, each HOWTO could be rated (on a scale of 1 to 5) on both whether the HOWTO addressed the user's problem and also how well it solved the problem. That way if a vender gets only 5 hits a month on how to handle MP3 files, but 200 hits on how to burn CD's, then the vender can tell what to improve or add in the next version. And if only half of the people trying to burn CD's actually succeeded, then maybe that problem needs to be fixed. This feedback would also make the HOWTO's self-correcting. HOWTO's that consistently solve people's problems could be made a permanent part of the vender's documentation, possibly even be put into the man pages. Any HOWTO reported as unhelpful or counter productive could be dropped.     If I were a vender, I would carry this idea one step further. Whenever anyone submitted  a HOWTO that got positive user feedback, I would send the person who submitted it token of appreciation (a toy penguin, or a pen with the company logo, or a baseball cap with ""Linux Software Team"" embroidered on it). Does anyone doubt that in less than a month there would contests among your more technically inclined customers (notice I didn't say Computer Geeks ) to see who could collect the most pens, caps, whatever. As a vender, I would encourage this by giving a special prize (T-shirt, jacket, Handspring Visor) to whoever submitted the best written and/or useful HOWTO each month. Wouldn't that cost a lot of money? Well, let's see. If someone spends 10 hours researching and solving a problem for your customers, and you give them a $5 baseball cap, then you've gotten expert technical support for 50 cents an hour.      Many of you are now saying that I'm just being silly. After all, there are all kinds of Linux users groups, mailing lists and clubs already out there. Why should a vender waste his precious time hosting one more? The answer is: Because of your customer, that's why. Imagine for a moment that you are the CEO of amazon.com and you've just learned that your server has crashed. You call the head of your IT Dept. and ask ""What happened? How soon can we be back up?"" The head of your IT Dept. tells you ""Beats me. I have no idea what happened. But I'll start asking around with some friends of mine, and maybe one of them can think of something in a few days?"" How long do you think the head of that IT Dept would have a job? Allow me to let you in on a secret: If some little one man operation with a single printer is using your software to make a living, then keeping that lone printer running is just as important to him as amazon.com's web server is to them. Users groups are wonderful resources for learning, sharing solutions to problems, etc. But the bottom line is that it's the venders who are responsible for keeping their product working. And if the customers can't trust the venders to take that responsibility seriously, then they're not going to buy the software.     And unless I'm mistaken, the people who are now yelling that they don't have time to build a useful website were the same ones who were yelling a few minutes ago that they can't keep up with the Customer Service demands they've already got. Well, everybody that can find the information they need on your website is one less person phoning your understaffed Customer Service Dept.. And if the customer does phone anyway, then which takes less time: Explaining something to him on the phone (and hoping he takes good enough notes to actually do it), or looking it up on your own site and emailing him printed directions to solve his problem? And as for not being able to afford to provide Customer Service? Well, several of the larger commercial venders are now charging for Customer Support. Unfortunately, what none of them have figured out yet, is that you have to actually  provide  the support in order for customers to be willing to pay for it!           In closing I would like to say, for the record, that I am NOT attacking Linux. I like Linux (and will probably enjoy it even more once I find a distribution that actually works <g>). And I think everyone would be better off if Microsoft had some serious competition. But so far, the best explanation that I can come up with for the behavior of most Linux venders is that they are secretly owned by Bill Gates. Because Microsoft couldn't come up with a better strategy to protect it's market share than what many Linux venders are already doing!                Dennis Field   My first encounter with a computer was when my high school got an old IBM 1130 (which had a whopping 8k of main memory!), and I've been playing with computers off and on since then. My first home computer was as Amstrad, which ran C/PM and came complete with a revolutionary 3"" floppy disk drive (yes, you read that right ). Although I've had one college course each in both C and Linux, I still consider myself a Linux newbie.   The author is currently in hiding at a secret location, after having narrowly escaped an angry mob of torch-waving penguins.                  Copyright © 2001, Dennis Field.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 73 of  Linux Gazette , December 2001        ""Linux Gazette... making Linux just a little more fun! ""                 Visual Debugging with ddd   By  Wolfgang Mauerer                     Overview   To err is human. Programmers are humans. Therefore programmers err. The overwhelming complexity and unsurpassable logic inherent in those little words may well be the cause for several years of discussion in the  philosophers' department, but holds without further doubt one timeless truth, when it's brought down to earth again:  All programs written by   human programmers are full of errors.  Although the belief  is still alive in some places that programming is just a more or less mechanical and stupid exercise that can be fulfilled without making any mistakes if only enough care is taken and planning is applied, a more sensible way of thinking seems to be devastating for programmers at first: Nothing works, all  programs are full or error, the specs are wrong, and the implementation does the opposite as expected. But this is noting against programmers,  in fact the fully opposite is the case: Programming is a very complicated and challenging task, and errors are therefore unavoidable, even for the best programmers - only easy things can be done without fault. The importance of errors or better: the way how to  find  and  fix   those errors in the lifecycle of a software product is a task whose importance cannot be  stressed enough over and over. Finding errors is not  just an unavoidable part in the development cycle, but a vital part of every  software system's lifespan.     It seems clear that bugs in software systems must be found, and that good tools are needed to assist the programmer in this complicated task. As most of you might know, there is a very capable debugger available as free software from (who else?)  the GNU project. Since the GNU people are responsible for the  most important compiler under linux, the gnu c compiler, both programs form a bodacious and capital team when it comes to kill  nasty bugs in your programs. Those of you who have already used the debugger know its spartan interface: It's not bad, but not  too good either. Even if one is a friend of the command line and text-based utilities (as the author certainly is),  using this form of debugger interaction is not always hilarious and can be a quite poignant exercise, especially when larger systems with complex data structures are debugged. The text interface may be well suited for single-stepping through  programs, checking simple values or testing certain conditions, but it is certainly not the optimal choice for modern, effective and  easy-to-do debugging of structures deeply connected with each other. Other interfaces (like the emacs gud-mode or the new tui interface for gdb) offer slightly more comfort, but are not ideal as well.    We need a graphical interface therefore, and again the GNU project offers a very good possibility: DDD, the data display debugger.  DDD is a graphical interface written by Andreas Zeller and Dorothea Luetkenhaus (and the help of many other programmers from the free software community) and made into a GNU program some time ago (although it was GPLed already before that). If debugging weren't such a sometimes very hard job, we would nearly be tempted to say that debugging with ddd is mere fun.    What does ddd offer compared to the pure gdb interface or to other debugger front ends like the emacs gud-mode? The main point is not just DDD's normal debugging functions (e.g., stepping through your source file line by line, setting breakpoints and watchpoints, changing the values of program variables), which are supported by ddd (in a very convenient and much simpler way compared to the traditional  gdb interface), but that DDD can also display data structures graphically. What does this mean? Consider a linked list in C, as we will use it in one of our later examples. The data structure basically consists of several data fields together with one or more pointer fields to other structures of the same type, that together form an interconnected network. The network is made up of the values of the pointer variables.  It could in principal by reconstructed by their hexadecimal contents, giving the memory location of the previous or following elements, but this is neither a very convenient nor comfortable task. It is very difficult to produce a concise overview about the situation this way, and even if the programmer succeeds in that laborious task, there is a major drawback: Since memory locations change in the next program run (or when a different input dataset etc. is used), the work is quickly rendered useless. DDD overcomes this limitation by automatically creating diagrams from the memory contents, allowing a simple and appealing visual  view to complex structures.    But the ability to draw program structures graphically is not the only enhancement offered by ddd compared to classical dialog-based debugging methods:        The ability to switch between multiple source files automatically.    A convenient view of the whole program text (and not just some few     lines surrounding the actual statement).    Different back-end debuggers are supported. This means that      ddd can not only     run with gdb as back-end debugger process, but can use debuggers     for the Python and Perl scripting languages, sun's java debugger     or dbx and ladebug (on systems other than GNU/Linux) as well.    Multiple languages are supported. This is not just a result of      the multi-debugger ability, but also a benefit of the gdb support     for different source languages (C, C++, Objective C, Fortran, Java, ...)    The same interface is used for all languages supported by the      underlying debuggers.        Let's see how all these things look in practice by debugging a simple example program.    Generating debugging information   Binary programs normally don't contain any information about the source file; they solely perform the codes intended task in terms  of machine instructions. It is therefore necessary to include so-called  debugging symbols  in the object code before advanced features of a debugger can be used (without this, it would be possible to step through the program in single machine instruction steps, but since there is no direct connection with the source code any more, this is not very helpful). There are several different debugging formats  floating around in the Unix world, but we do not want to dive deeper into this subject, since it is mostly important for compiler programmers. Instead, we will concentrate on the GNU/Linux platform using the GNU C compiler using standard settings.    The standard option to include debugging information in a program is to use the switch  -g  when calling  gcc :          [wolfgang @ jupiter wolfgang]$ gcc -g fac.c -o fac        This will create a binary file  fac  which is bigger in size than the normal executable. Obviously, this is not a big surprise: Since additional data (like assignments between blocks of machine instructions and line numbers in the source code etc.) are stored in the code now, the size must increase.    It is important to note that gcc offers a feature quite rare among competing compilers: Debugging information can be generated even if optimizations are turned on, e.g.  gcc -g -O2 fac.c fac  will work, producing a binary file that is optimized  and  contains debugging information. Although this can be quite handy in some cases, there are some well hidden trap doors behind this approach (like optimizing away several lines of code), so we won't cover these combinations here.    The source file for  fac.c  has the following contents:     #include<stdio.h>  int main() {   int count;   int fac;    for (count = 1; count < 10; count++) {     fac = faculty(count);     printf(""count: %u, fac: %u\n"", count, fac);   }    return 0; }  int faculty(int num) {   if (num = 0) {     return 1;   }   else {     return num * faculty(num - 1);   } }      As you can see, the program just performs some really simple calculations: We loop over a range of integer values from 1 to 9 and call a function to calculate the number's faculty in every loop step. It's perfectly clear that this could b"
GX226-02-2248389	If you are seeing this page then you are hitting the \nwdocs document root.  It also means that somebody hasn't replaced this page with the one that should be here.   Please Replace This Page!!
GX051-48-7904248	"December 2002, Issue 85       Published by  Linux Journal     Front Page   |   Back Issues   |   FAQ   |   Mirrors     The Answer Gang knowledge base  (your Linux questions here!)    Search (www.linuxgazette.com)                               The MailBag     More 2-Cent Tips     The Answer Gang     News Bytes ,  by Michael Conry     HelpDex ,  by Shane Collinge     Ecol ,  by Javier Malonda     Modern Linux Distributions and Hardware-Challenged PCs ,  by Richard Johnson     Handicapped People of the World, Unite! ,  by Janine M Lodato     So You Wanna Create Your Own x86 Operating System? ,  by Patrick Mahoney     Viewing Faxes on the Web ,  by Mark Nielsen     Perl One-Liner of the Month: The Case of the Duplicate UIDs ,  by Ben Okopnik     The Foolish Things We Do With Out Computers ,  by Mike (""Iron"") Orr     Programming Bits: C# Data Types ,  by Ariel Ortiz Ramirez     Qubism ,  by Jon ""Sir Flakey"" Harsem     Process Tracing Using Ptrace - Part III ,  by Sandeep S     Making a Multiple-Boot CD ,  by Juraj Sipos     Getting started with TUX ,  by Vinayak Hegde     The Back Page                 Linux Gazette  Staff and The Answer Gang     Editor:  Michael Orr   Technical Editor:  Heather Stern   Senior Contributing Editor:  Jim Dennis   Contributing Editors:  Ben Okopnik, Dan Wilder, Don Marti          TWDT 1 (gzipped text file)   TWDT 2 (HTML file)  are files containing the entire issue: one in text format, one in HTML.  They are provided  strictly as a way to save the contents as one file for later printing in the format of your choice;  there is no guarantee of working links in the HTML version.         Linux Gazette ,   http://www.linuxgazette.com/   This page maintained by the Editor of  Linux Gazette ,   gazette@ssc.com      Copyright © 1996-2002 Specialized Systems Consultants, Inc.                              ... making Linux just a little more fun!         The Mailbag      From  The Readers of  Linux Gazette                HELP WANTED : Article Ideas     Submit comments about articles, or articles themselves (after reading  our guidelines ) to  The Editors of  Linux Gazette , and technical answers and tips about Linux to  The Answer Gang .           What do I do to make evolution sync with a Visor PDA?   Redhat 7.1 freezes often   How can i determine IP address of client?   Question   glibc versioning   Alan Turing                 What do I do to make evolution sync with a Visor PDA?  Tue, 29 Oct 2002 08:18:05 -0700  Michael Havens ( bmike1 from vei.net )             Is it possible? Another forums told me that it was! They told me it was yet it will not. Whenever a sync is attempted the PDA tells me that a connection ""could not be established"".  What could I download in it's stead that I don't have to fiddle-faddle with? Perhaps it isn't reading the USB correctly. If I open the hardware browserand click 'USB Devices' it gives me a manufacturer and a driver (usb-uhci) but no device.  Any help you can give me would be very much appreciated. Once I learn more how would I go about joining your team? I want to help others later who are in the same predicament that I am now       Cool.  Anybody who wants to be helpful is welcome to join;  see  http://www.linuxgazette.com/tag/members-faq.html .  I'll add that a cheery sense of humor is a plus.  -- Heather    One last thing, do I have to uninstall anything like in Windows? If I remember correctly the answer is 'no' but I best make sure before I erase any programs.     I'm running RedHat 7.3 with a  KDE  desktop (did I phrase that correctly?).       ~Mike~ (-:     Yes, you did.  It might be handy to know a kernel version, but we can guess you have the stock one that came with Red Hat 7.3.  -- Heather    Oops, one more question. When do you release the monthly editions of your web magazine? If you already covered these issues in previous editions just refering me to the edition's URL would work.     Linux Gazette is published on the first of the month at midnight (UTC-0800). Sometimes it's a few hours late (as one smart alec in Australia noticed at 12:15am on the millenium New Year in 2000   ), but that's the goal.  -- Mike                Redhat 7.1 freezes often  09 Nov 2002 13:59:46 +0000  Rajaraman ( rajachemist from yahoo.com )         Hi,     My computer version is redhat 7.1.I had two xeon processors inside.  (8*512GHz)  I am using gnome as my window manager.     It frezees randomly (like once a week or twice or thrice) and I can not do anything other than use the power swtich to reboot it though mouse is moving but it is not doing anything on the screen.  Hardaware diganstic test, I did with a CD sayhing that there is no error.     I though it would be a temperature problem,but in UK the temperature is not so hot and there are six fan inside the cpu.I put an extra fan as well, it does not help.     I have used the cpu memory and tempertaute controller in linux to monitor the temp. chnages but it reveale normal temperture. I have not got any clue and why. I consult some body but most of the people are unware about the OS and the problems.     SO it would be helpful If you could tell me sugesstions and ideas.     regards  rajaraman                 How can i determine IP address of client?  Thu, 07 Nov 2002 13:53:06 -0600  Dave Nissman ( daven from web-wise.com )             I have a linux server and for various reasons I have processes telneting in. I need to identify the ip address of the client fron within a c program running in the telnet session       so i can tell the client his ip address from application   so ican limit what that node can do.     Any thoughts  Thanks in advance                 Question  Wed, 6 Nov 2002 16:22:13 -0500  Antony Gordon ( agordon from bkbacademy.org )             Hi,     My manager wants me to setup the network so that based on userid and IP address (more so userid) you can print anywhere in the building, or just to the printer in the room. I am doing this at a school. Any ideas as to how that can be accomplished?     TIA, -Tony     [David Mandala]  Really need more information in order to answer your question. What types of computers are on the network, what types of print servers, etc.     Cheers     The network consists of a server (RH 7.3) with about 50 ThinkNICs (diskless workstations) booting via PXE into Linux. The printers consist of HP DeskJets in the classroom hooked to JetDirect boxes, a LJ 4100 DTN with JD built in, and a Xerox Document Centre 425.                 glibc versioning  31 Oct 2002 15:27:11 +0000  mike ( mike from redtux.demon.co.uk )         Does anyone know if it is possible to compile against a specific glibc version     To be clearer, I have glibc-2.2.93 installed which contains versions up to and including 2.3     What I am trying to do is set up a build system for producing RPM's that will work on RH 7.3 setups (which is 2.2.5)                 Alan Turing  Wed, 27 Nov 2002 11:10:52 -0000  Shane ( shane from hairyfred.freewire.co.uk )             Hi Linux gang, I am a fairly recent convert to Linux, I am currently running a Win98 (boo hiss) and Redhat 7.2 dual boot system.     I wonder if you could help me? After delving through your back issues I came to number 75 and part one of a very interesting article about Alan Turing. What happened to part 2? Regards and thankyou for the magazine. Shane Doveton. (Scarborough, England).     The author, G James Jones, has health problems and was unable to complete the series.  However, the good news is his health is now better and he's started working again on the second part.  I for one really appreciate his articles because they are so readable and make the history come alive, and readers have also sent in a significant amount of  positive feedback too.    If anybody else would like to write some articles about the giants in computer science history, we'd be interested in publishing them.  -- Mike          GENERAL MAIL           Great info   etymology of ""daemon""   virtual beer and feature request   Hoping... Recovered, THANKS!                 Great info  Sun, 24 Nov 2002 09:29:42 -0700  lucifersam ( lucifersam from shaw.ca )             I realy enjoy finding new ways to code something with examples that actualy work!     This notion came to me after I found the artical on ""Adding Plugin Capabilities To Your Code"" By Tom Bradley.  Except for a implicit cast and some missing header file includes, the code worked like a charm.     I usualy find it difficult to find code that does what it says it does and is in a simple an understandable fasion.  I have been impressed.  I expect (read hope) to see more of this in the rest of your issues!     Thanks.                     etymology of ""daemon""  Mon, 18 Nov 2002 09:40:52 -0800  Bob Krovatz ( krovetz from nec-labs.com )             Hi Heather,     The use of daemon/demon in Operating Systems goes back to the early 1960's.   I did some further checking on the web and found that it was used by the team at Project MAC around 1963 (see  http://ei.cs.vt.edu/~history/Daemon.html ).  On that web page Fenando Corbato attributes the inspiration to Maxwell's daemons. He says ""Maxwell's daemon was an imaginary agent which helped sort molecules of different speeds and worked tirelessly in the background. We fancifully began to use the word daemon to describe background processes which worked tirelessly to perform system chores."".  There is also a notion of ""demon"" in Artificial Intelligence; that was where I heard about the etymology from Selfridge's paper from 1958.  I thought that Selfridge's work inspired their use in operating systems (since his paper was so early), but I should have done some more checking.  In any case the concept of ""daemon"" in operating systems predates BSD by some time.     Bob     Thanks for the extra effort to chase that down. It's cool to learn about these things!  Forwarding to the Answer Gang so they get to see it, and so I can get it added into The Mailbag for this month.     Have a great day                         virtual beer and feature request  Wed, 6 Nov 2002 07:04:17 -0800 (PST)  Raj Shekhar ( lunatech3007 from yahoo.com )             Hi folks! This letter has some feature requests, some tips and lots of virtual beer.     Heather & Mike     LG# 84 was great, awesome, cool!Keep up the good work   .     Heather     Your list of Do's and Dont's was really in the spirit of Linux. Enjoyed it and have copied it        Ashwin     Thanks for the tip on using Konqueror for  reading info pages.     Ben     Thanks for the tips on whatis,whereis. It seems you have something against info. I find it(info) good.     Michael Conry     Your News Byte ""Venezuela and Other Government News"" in LG#83 helped me a lot in writing a paper on using Free Software in egovernance in India. Your selection of sites for News Byte is always wonderful.     And now a ""Feature Request"" I use a cyber cafe to download TWDT(HTML) for LG. Earlier you included author bio with the article itself.     Can it be possible to append the author bio to the TWDT file. Or maybe make a TWDT for the author bio itself for each issue. I really enjoyed reading the bios   .     I have sent my tip to TAG     May the great gnu have mercy on your soul!       Raj Shekhar     We've shared the kudos around to everybody, and I restocked the TAG fridge with your v-beer.  Glad you're enjoying the 'zine.  -- Heather    (regarding bios in TWDT) We'll think about this.  One of the purposes of the Author pages is to have the latest contact information and bio; the articles and TWDT would not be changed after publication.    Pehaps I can put the entire bio page (minus the links to previous articles, and minus the large type in the header) at the bottom of the TWDT article, with a note that this information may be old and another link to the Author page.  -- Mike                Hoping... Recovered, THANKS!  Tue, 29 Oct 2002 10:02:48 -0500  Lon Diffenderfer ( profitrocket from nmax.net )         An email thread occurred which was not linux, but about rescuing documents in some oddball word processing format.  A few of the Gang gave it a shot.  -- Heather    To all who replied, ""THANK YOU!""     With the information you provided, I was able to find a local professional who had administered Xenix systems in years past and was able to use ""strings"" to recover the data. I still do not understand exactly what he did, but I am elated and very grateful to your group for your assistance. If this is the kind of help I can get for Linux, maybe it's time to learn it and switch.     [Jay R. Ashworth]  Probably.         Outstanding; glad to ehar you got your data back.  Now you understand why Unix people (and especially Linux people) are fond of textual configuration and data files whenever possible...     What he  did  was to use the Unix strings(1) program, which sifts through a [random] file looking for strings of characters that appear to be ASCII text, extracting them from the surrounding (binary) data, and printing them on it's output.  Once you do that, it's usually just a cleanup pass.     [Thomas Adam]  You're welcome!!!     I'm glad that people such as Jay, and myself, were of some use. Makes a change actually!!     He he....           GAZETTE MATTERS           Hey answer guy.   Z for South, A for Africa                 Hey answer guy.  Wed, 13 Nov 2002 21:28:19 -0800  Rick Moen ( the  LG  Answer Gang )     Once upon an email, a good question came in.  Too bad it had one of those automatic confidentiality notes attached.  Darn.  The Answer Gang (I don't recall who at the moment) sent the fellow a little note, suggesting that we can help him if he attaches counter-disclaimers, or gives us permission.  We could make him anonymous, of course.    He replied with a short, brusque note saying he found the answer elsewhere. Whose exact text, of course, we can't repeat     -- Heather    [Rick Moen]  Don't worry, we know what you  really  meant by that rather graceless, if not arrogant, comment:  You meant ""Er, sorry about failing to compensate for a dumb disclaimer that defeats the purpose of your group entirely, and if deliberate would have suggested that I don't value what you do.  I'll make sure I don't do it in the future.""     We understand that sometimes you just don't say what you mean, and we hear the intended message, anyway.     [Robos]  Hi Rick. I normally don't post on  /.  but I read this there quite often and somehow this also applies in your case:     PLEASE MOD PARENT UP!       How about in school, teaching the kids to have some manners and we all might get along more nicely...             Z for South, A for Africa  Fri, 8 Nov 2002 10:07:51 -0800  Richard Meyer ( meyerri from au1.ibm.com )  and Chris Duncombe Rae ( duncombe from ring.wcape.gov.za )            [Richard Meyer]  Hi Heather,     Just a minor correction on the advice you gave the laddie asking about Net2Phone.  The .za is South Africa's TLD. In case you're interested (and I admit that you may not be), in the 19th century the Afrikaners used to call South Africa, Zuid Afrika in the Dutch-descended Afrikaans. So that's where SA becomes ZA, leaving SA for Saudi Arabia? (I think).     Funny, I though we did publish a correction about that in the same Mailbag item.  It must have been a letter that came in after publication.  -- Mike    Keep up the good work with the Gazette.     Thanks   .   Mike's right, of course:  -- Heather    [Chris Duncombe Rae]  First off, ZA is South Africa's country code; Zambia is ZM.     ...but the corrector had more important news than that I forgot to look up the ISO codes before going to press.  -- Heather    [Chris]  The  http://www.linux.org.za/LDP  URL leads nowhere. Hunting and pecking around from  http://www.linux.org.za  leads to some HOWTOs and more dead links. Speaking as one who also suffers bandwidth limitations I'd prefer to be pointed directly at the Linux Documentation Project than have to scratch around a supposedly closer site fruitlessly.     Second, I've had a look at your mirror sites in South Africa and a lot of them are very stale.     Of the ones he tried two lead to mirrors that are more than 2 years stale, one may be alive but having connection problems, and others were dead.  -- Heather    [Chris]  Time to update your mirror site list? Or maybe everyone turned off their sites as well as their mirrors while you were upgrading yours?     I wrote to www.linux.org.za to see if they plan to reinstate their mirror. For the others, I'll check again in a couple weeks and if they're still down I'll delete the listings.    We don't get feedback when mirrors go down unless somebody tells us, and we don't have the time to check 210 mirrors manually.  I have looked into writing an automatic mirror checker or finding one off the shelf, but haven't found anything satisfactory yet, anything that can deal with timeout errors on 200 sites, do retries, and report problems back to a program in a way it can take action.  -- Mike    Folks, if you are running one of our listed mirrors and decide you can't handle the bandwidth anymore, take it private, or otherwise aren't going to mirror visibly...  Please, take a spare moment, and let us know that you're leaving the mirror system;  we'll be glad to take all the extra visitors back off your shoulders.  Our blessings to you for what you  could  provide aren't any less when you can't any longer.    Also, new mirrors are always welcome     -- Heather                  This page edited and maintained by the Editors of  Linux Gazette HTML script maintained by  Heather Stern  of Starshine Technical Services,  http://www.starshine.org/   Copyright © 2002  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                              ... making Linux just a little more fun!         More 2¢ Tips!      By  The Readers of  Linux Gazette            See also: The Answer Gang's   Knowledge Base  and the  LG    Search Engine         Linux now serving: Outlook Global Address List   no more duplicate email   Changeing IP address   linux consoles --or--  The ""Other"" [Alt] Key    how to create Imakefiles   Booting stops at devfs --or--  Even journalled filesystems need fsck sometimes    Foxpro   unable to open an initial console   question on redhat ip forwarding --or--  IP Masquerading: Red Hat 8.x Redoux    Learning Red Hat 8.0   Q: man pages for poll_wait(), wait_event()   and others   is the md5 check always right?   Follow ups on mgp and mplayer   Net2Phone ipchains config   Lost win95 data (and system) when loading linux   Good locations for sendmail howtos?   internet connection --or--  Will this modem even work?  Let's ask the internet    Linux Journal's  Weekly News Notes    Tech Tips       subscribe  to LJWNN                   Linux now serving: Outlook Global Address List  Tue, 19 Nov 2002 11:59:58 -0800  Rick Moen ( the  LG  Answer Gang )  Question by Luis Sanchez (LUIS from casiano.com)     Is there a way to share the users in a Linux Mail Server for Outlook clients?  We will connect out Outlook clients via pop3/smtp to the linux email server but wonder how to share the global address list (like Exchange) ..     What you need to do is set up a shared address book using the OpenLDAP server, an open-source facility for serving up Lightweight Directory Access Protocol information to networks, that is routinely included in Linux distributions.  This needs to be done with some care on the OpenLDAP end of things, because Micros*ft Outlook is unusually picky about the LDAP schema.  One hands-on guide to configuring the schema is here:        http://www.dclug.org.uk/archive-Nov00-May01/msg00253.html      You can find one general guide to setting up LDAP (server end)  software , in the form of a set of lecture notes I wrote about LDAP, a year or so ago:      http://linuxmafia.com/~rick/lecture-notes/ldap      An example of how to set up the  client  (MS-Outlook) end of the problem (at a university site) is here:      http://www.cae.wisc.edu/fsg/info/mail/ldap_outlook.html      Note that appending to the address book from MS-Outlook is not supported (or desirable, actually).     Good luck with the project.  Expect it to take a while, to work out all the details.                 no more duplicate email  Tue, 29 Oct 2002 10:20:31 -0800  Dan Wilder ( SSC.COM sysadmin )     We now keep an MD5 sum the body of every message submitted to the Answer Gang.  If another identical message body shows up, it gets sidelined.     As usual, this is run over procmail, with two stanzas in the list's procmailrc that look like:    See attached  dupekiller.procmail.txt    The first stanza says ""filter this message through a program"".     The second says ""sideline if you see an X-Duplicate header in the result"".     The duplicate elimination script being used on this list has been upgraded to use Python's library md5 routines rather than an external pipeline, and to employ locking on the db.     By popular request, we're now filtering other lists here with this, and one local user who often receives duplicate emails that are not always spams has asked for the script, too.     The upgraded script, which the procmail recipe calls upon:    See attached  dup.py.txt                Changeing IP address  Fri, 22 Nov 2002 07:22:58 +0530  Kapil Hari Paranjape ( kapil from imsc.res.in )  Question by eyal (eyal_kornblut from mod.gov.il)     I have a Linux server that functions as a Mail Relay in my system. All I want to do is to change its IP address. How shuld I do it ? witch files shuld I change, and how ??     I would be very thanksfull for some help     eyal     This depends quite a bit on the precise distribution of Linux you have installed. Is it RedHat,  Debian ,  SuSE , Mandrake,...     It also depends on how your network is configured. By static addresses entered in some file under  /etc  or via DHCP.     At the very least you should do:     grep -ril ""your_current_ip_address_here"" /etc     to find out which files refer to your IP address.     In addition if you use SSL and/or SSH you must go through the configuration of these services and check that the new IP address is reflected.     Having gone through this procedure more than once, I must warn you that  if  you a free machine that can take the place of your mail server then the easiest solution is to setup  that  machine as the new mail server and switch off the old machine.     Regards,  Kapil.     You might also want to check that reverse-resolution of DNS is updated to reflect that your new host is attached to this IP address;  it's normally handled by the ISP who owns the IP block, so it's not stored locally unless you have made special arrangements, and even if you have, best to make sure they went through safely for both the old and new address.  -- Heather                The ""Other"" [Alt] Key  Mon, 18 Nov 2002 09:46:18 -0800  Jim Dennis ( the  LG  Answer Guy )  Question by The Gavitron (gavitron from shaw.ca)        http://www.linuxgazette.com/issue35/tag/magickeys.html      James,     Further to your technical article quoted above;     You explain that I can use the  /other/  alt key for ttys 13-24, but in my case, I only want to use both alt keys to switch between the same 12 ttys.  Is it possible to configure this?  Would making tty24 a symbolic link to tty12 accomplish it?  I realise it's been over 4 years since you wrote the original article, but if you can still help, I would greatly appreciate it.     Yours, Gavin McDonald.     You DON'T want to try symlinking those device files around.     Just use the 'loadkeys' utility to change your Linux console's keymaps around to suit you tastes.  You can start by reading the following man pages:  loadkeys(1), keymaps(5), dumpkeys(1), and possibly showkey(1)     Then use 'dumpkeys' to dump a set of all the current key bindings. Edit that (delete all the stuff you don't want to change) and look for the section that looks something like this:    See attached  jimd.console-keymap-fragment-1.txt    ... and another section like:    See attached  jimd.console-keymap-fragment-2.txt    Now simply change those to read:    See attached  jimd.console-keymap-fragment-otheralt.txt    Notice that all I'm doing is changing the Console_13 to Console_1 etc. (at the end of each line that begins with the word keycode).     Then simply pass that through the loadkeys command.  In fact you could take that last excerpt (as show between the "" and "" quotes above) save it to a file ---  /usr/local/etc/mykeymap.def  --- for example and add a line to your rc.local file to perform a simple:     loadkeys < /usr/local/etc/mykeymap.def     ... command.                 how to create Imakefiles  Fri, 08 Nov 2002 16:10:27 +0530 (IST)  Karl-Heinz Herrman ( the  LG  Answer Gang )  Question by Kirankumar Po (Kirankumar.Pv from geind.ge.com)    plz excuse me for asking questions without your permission ,     now my question is ...........     This group (answergang) is willing to answer questions related to the operating system linux, so if you ask a question according to this little help what to ask and how to ask it:      http://www.linuxgazette.com/tag/ask-the-gang.html      you won't have to appologise for asking.     ""can we delete a file of a particular version ?"" if so how , if not what is the alternate for that     Now this question is somewhat... broad. Yes, certainly linux has a version management system, My preferred one is CVS. But unless you tell us what  you  use if you use one we will have trouble guessing what might be appropriate in your case.     file name is test     test 1.1---1.2--1.3----1.4---1.5     i want to delete version 1.3 what is the command for that and tell me the condition of 1.4     For cvs this would be the command ""admin"" with flag ""-o"" for outdate.     khh > cvs -H admin Usage: cvs admin [options] files...       [.......]         -o range   Delete (outdate) specified range of revisions:            rev1::rev2  Between rev1 and rev2, excluding rev1 and rev2.            rev::       After rev on the same branch.            ::rev       Before rev on the same branch.            rev         Just rev.            rev1:rev2   Between rev1 and rev2, including rev1 and rev2.            rev:        rev and following revisions on the same branch.            :rev        rev and previous revisions on the same branch.     Information on a particular version would be told by cvs status or cvs log on the file with an additional ""-r revnumber"" if you really are interested only in that particular version.                 Even journalled filesystems need fsck sometimes  Mon, 18 Nov 2002 13:08:46 +0000 (GMT)  Thomas Adam ( The  LG  Weekend Mechanic )  Question by Trev (tedlinux from inet.net.nz)      Hi, love your Mag, and your doing a great job here.     [Thomas]  I know    I love the magazine too        My MDK 8.1, kernel 2.4.8.26-mdk system stops at     running DevFs deamon invald operand:0000 CPU:0 EIP:   ......... EFLAGS ......... eax    ......... asi    ......... ds     ......... Process devfs pid 123 Stack: ......... CallTrace: ..... Code: (Lots of letters and numbers)     Is this a hardware problem ?     [Thomas]  Oh, it most certainly would suggest a hardware problem. As I am sure you are aware the ""dev fs"" sets up those hardware devices contained within "" /dev "" such as soundcard, etc.     i have no problems in  SuSE  or Win (SuSE and Win on hda, MDK and some vfat partitions on hdb) and i can mount MDKs partitions (in rescue) ok.     I've had problems when booting with devfs twice, the first time (some weeks ago) it put it back to the old dev system, 10 to 15 boots back, it put it back to the devfs system.     [Thomas]  I'm not certain but is the new way (""devfs"") actually a kernel module rather than it being ""built-in"" to the kernel???     I tried rescue to rebuild devfs but not knowing/finding any commands (no man pages) i got nowhere, reiserfsck and e2fsck found no problems, i commented out pts from fstab but it made no difference. I tried booting with devfs=nomount but lilo would not recognize it, not in lilo i guess.     [Thomas]  hmmm...the script "" /dev/MAKEDEV "" does some things, but not what you're trying to do.     I had no luck with your DB or google.     Neither did I        Sorry for being slow getting back to you, only got it going late last night and read your email (and 450 others).     [Thomas]  Oh, that's ok. You actually read 450 consecutive e-mails? Gosh -- hope you haven't got eye-strain        I changed the ""devfs=mount"" to ""devfs=nomount"" in lilo.conf but it made no difference,     [Thomas]  Hmm, that would suggest that your filesystem type for the particular partition is abnormal in someway.     then out of desperation i tried reiserfsck again on  /  but this time i did reiserfsck --rebuild-tree and it fixed it   , dmesg says ""Mounted devfs on  /dev "".     [Thomas]  Ah.... that's interesting and something that Mandrake should have tested and/or implemented in both the kernel and their documentation. I'm sure there are other like you running MDK8.1 with the same problem/.     I'll see if devfs and reiserfs has an update for MDK 8.1.     [Thomas]  Unlikely -- you'll probably have to re-compile your kernel as a result. But it's not as hard as you might think....honest. Last I heard Eric Raymond was working on a graphical ""maze"" frontend for compilation!!! So much for the tcl/tk interface        [ashwin]  Linus rejected that for kernel 2.5. Instead, a Qt interface was chosen, so that's what will be in 2.6 (or it may even be called 3.0).     Thanks Thomas for your reply.     [Thomas]  As I said -- it's what we're here for       Anytime. If you have any other problems, let us know!     Gentle readers, it's also worth mentioning that journaled fs' will still be fsck'd when the volumes reach their maximum mount count.  Journals make them robust, so a crash (which marks notmal filesystems ""dirty"", forcing fsck) simply results in a journal replay.  So now we know one thing that can happen if the journal itself gets an ouchie.  -- Heather                Foxpro  Sun, 17 Nov 2002 20:43:29 -0800  Rick Moen ( the  LG  Answer Gang )  Question by Deviyanti Setionegoro (devi_ys from yahoo.com)    My name is Deviyanti, I want to ask a question, I have a foxpro 2.6 under dos that runs on windows NT. Now I want to migrate from windows NT to linux Redhat 7.2. The question is will my application in foxpro 2.6 can run in Linux? If can, what are the additional software that I should install first, before I move my aplication in foxpro 2.6 to linux.     Something called ""Recital Linux Developer"" runs FoxPro 2.6 applications unchanged on Linux:      http://www.recital.com/solutions_foxpro.htm      Additionally, this question did sort of come up once before, a few years back, when Answer Gang founder Jim Dennis was The Answer Guy, all by his lonesome:      http://www.linuxgazette.com/issue30/tag_database.html      Some of that will no doubt still be relevant.                 unable to open an initial console  Fri, 08 Nov 2002 12:24:07 +0530 (IST)  Karl-Heinz Herrman ( the  LG  Answer Gang )  Question by Lawrence O'Sullivan (lawrence.osullivan from 141.com)    Hi, I could sure use some help with this problem. I've followed the ""Linux from Scratch"" guides to building a Linux system. Their instructions and guides were very good, and everything seems to have compile correctly. Also, I have posted this question on their support mail, and received several suggestion but none helped. When I boot into the new Linux system, the process hangs and the last three lines displayed are:     Freeing unused kernel memory: 140k freed Warning: unable to open an initial console Kernel Panic: Attempted to kill init     Entering this  lfs root=/dev/hda9 init=/bin/sh  in lilo still hangs.     I'm pretty sure (since I had the same when I was first time switching from 2.2.x kernel to 2.4.x style) that the console driver is not in the kernel. my config seems to have that as ""y"" not as module.    See attached  k-h.kernel-dot-config-fragment.txt    I'm not using devfs.     The inittab file appears correct, and was reviewed by the LFS folks.     The fstab file appears correct, and was reviewed by the LFS folks.     The configuration (.config) for the Kernel build appears to be correct. It was reviewed by the LFS folks and I compared it to the distribution that loads.     Maybe or maybe not -- make sure the above mentioned character devices are there.     The new Linux system is on its own partition and the root and boot are on the same partition.     My original Linux distribution, which is on its own partition, still boots and can mount the partition with the new Linux system.     Any suggestion as to what else I can check or change would really help.     Thanks  Lawrence                 IP Masquerading: Red Hat 8.x Redoux  Mon, 18 Nov 2002 20:55:34 -0800  Jim Dennis ( the  LG  Answer Guy )  Question by chhong (chhong from cisco.com)      I have a RedHat Linux 8.0 machine with kernal 2.4.18-14. One of the network card (Eth0 eg. 192.168.10.1) is connected to my private network (consisting of a FTP server and 2 pc). Another network card (Eth1 eg. 201.1.1.*) is connected to the internet. How do I make my FTP server accessible from other pcs in the internet and make pcs in my private network access the internet?     Thanks  Chris Hong     Well, I haven't played with Red Hat 8.0 yet.  However, the key to your question lies in two steps.  First you have to enable the kernel's packet forwarding feature.  Manually this can be done via a command like:     echo 1 > /proc/sys/net/ipv4/ip_forward     However, that would not persist beyond a reboot.  Under Red Hat there is an  /etc/sysctl.conf  file which needs to have an entry like:     net.ipv4.ip_forward = 1     This allows the kernel to route packets (from your internal network to the outside world).     However, that obviously won't do much good by itself.  Packets from your network that ""leaked"" out to the Internet would be useless since no responses could get back to your RFC1918 non-routable addresses (192.168.*.*, 10.*.*.*, and 172.16.*.* through 172.31.*.*).     So, the other requisite step is to enable IP masquerading.  Over the years the Linux IP packet filtering features haved changed radically with each major kernel release.  So old versions of Linux used the 'ipfw', then the 'ipfwadm', and then the 'ipchains' commands to manage the kernel's packet filtering tables and configure its behavior.  Red Hat version 8.0 uses a 2.4 kernel with the netfilter subsystem and the 'iptables' command to manage it.     modprobe iptable_nat # In the NAT table (-t nat), Append a rule (-A) after routing # (POSTROUTING) for all packets going out eth1 (-o eth1) which says to # MASQUERADE the connection (-j MASQUERADE). iptables -t nat -A POSTROUTING -o eth1 -j MASQUERADE       Example slightly modified from    http://www.netfilter.org/documentation/HOWTO//NAT-HOWTO-4.html#ss4.1      You may have to hunt around in the Red Hat  /etc/  directory tree to figure out the best place to put his command.  I think they have an  /etc/rc.d/init.d/iptables  script which you can enable with their 'chkconfig' command.  If you read that I think you'll find some file like  /etc/sysconfig/network-scripts/iptables.dat  or something like that.  If I recall correctly from Red Hat 7.x, you could put just the arguments for this iptables command (from the -t to the end of the line) into that file.     The reason I'm tossing in so many qualifiers in this last paragraph is because I mostly use  Debian  and haven't actually installed or managed a Red Hat 8.0 system, yet.  In addition some of the details change with every major release.  The differences are minor --- easy to adapt to if you can read simple shell scripts.     There is probably also a way to do all of this using some GUI tool. However, I still avoid graphical system administration tools.  I'm firmly of the opinion that the most important systems administration tool is your favorite text editor!                 Learning Red Hat 8.0  Tue, 26 Nov 2002 13:40:35 -0800  Heather Stern ( Linux Gazette  Technical Editor )  Question by James M. Haviland (jhavilan from attbi.com)    What is the best book to learn RH's 8.0?  Or will the books I have on learning 5 or 6 and maybe 7 be good enough to learn the basics or anything except the fine points.     Stuff about the bash shell will be pretty much the same.     Learning how to use a text editor will be pretty much the same.     Chances are that in a modern one the screen may look a little different but it will likely be a little easier to read.     Anything showing screen shots walking you through the install will show pictures only good for that exact version.  You can read the chapter anyway, as the basic steps of partitioning and answering network questions will still be asked, but the screens will look different.     Pretty much, you can follow along in an older book, and look at man pages or --help output from a program to catch up on some things that may be new.  If you also connect to the internet and surf to the home pages of some software you are trying to learn, there may be discussion forums and more things to read there.     And of course there's the Linux Documentation Project     (www.tldp.org)     Many of these things will be equally valid for red hat, or for other linux distributions.     I tried to use the e-mail program that came with it and I set it up wrong some how so that I couldn't send e-mails.  I was able to use Mozzarella or Netscape's e-mail program.     You have to connect to an internet provider before you can read emails. Your system usually has to have an SMTP program (sendmail, or one of its competitors) in order to send emails.     Mozarella, yum.  You probably meant ""mozilla"" - the browser's firebreathing dinosaur-like mascot.     Mozilla and netscape use the same code under the hood;  they compose SMTP messages and transmissions directly, rather than needing a local server.  Think of this as driving the mail up to the post office yourself all the time instead of leaving it at your door for the postman to pick up when he comes by every day for the mail.     Thank you for your time.     Jim     You're welcome.                 Q: man pages for poll_wait(), wait_event()   and others  Mon, 4 Nov 2002 16:21:32 -0500 (EST)  Pradeep Padala ( the  LG  Answer Gang )  Question by Vitaly Karasik (vkarasik from ndsisrael.com)    Are there any  additional sources for manpages [we've checked kernel-doc package,  http://kernelnewbies.org/documents , Kernel* HOWTO's and so on, but without success].     Linux source is the authoritative documentation for kernel functions. I guess you already know about  http://lxr.linux.no . That's the right place to look for documentation        Apart from that Alessandro Rubini's book on device drivers has some information on this. Information regarding poll is here in that book:      http://www.xml.com/ldd/chapter/book/ch05.html#t3      This should give a fair idea of what needs to be done when poll on a device is done.     You can read the whole book online at:  http://www.xml.com/ldd/chapter/book      Also try to follow any driver's code which implements 'select' or 'poll' for the device.                 is the md5 check always right?  Sun, 3 Nov 2002 18:23:17 +0000  Steve Kemp ( skx from tardis.ed.ac.uk )  Question by Simon Pople (paupople from online.no)    I just downloaded 3 Mandrake CDs via FTP and read after doing that that I should have set the download mode to binary not ASCII.  I didn't do that, but when I run MD5 on all the .iso files they are all fine....is it possible that even though the MD5 checksums are all matching, the files still aren't correct, or is MD5 an infallible test of the downloaded ISOs?     MD5 should be a good enough test of validity.  It has got some weaknesses which have recently come to light, but it's extremely unlikely that you've come across three seperate examples.     It's probably the case that your FTP/download software switched to binary by itself, without you having to explicitly do it.                 Follow ups on mgp and mplayer  Sun, 17 Nov 2002 03:40:22 +0100  Robos ( the  LG  Answer Gang )     Hi Folks     I did look into the mgp with embedded mplayer issue today again and got a little further: after looking into the man-page of xwininfo I found -name. If I call:     xwininfo -name MagicPoint     (always the same I hope    I get the win-id like this:     xwininfo -name MagicPoint |grep Window |awk '{print $4}' >/tmp/wid     and then:     mplayer /home/robos/movies/play* -vo x11 -wid cat /tmp/wid=1BOB     OK, I actually put the whole calls into a bash script since mgp makes some strange things if I call it from within mgp with %system. So, in the mgp text I do a     %system ""/home/robos/mplayer.sh""     and call the whole thing like this:     mgp mplayer.mgp -x vflib -U     The -U is the important one: -U since forking is prohibited otherwise... This sorta works, but the display stays a little garbled afterwards (I put a %system ""killall mplayer"" on the next page)  and in the page that displays the vid nothing else is shown (no text). But, I would say something to improve upon. If you use -o with mgp it doesn't go fullscreen and then the vid is also centered in my case (I use enlightenment btw).     OK  I'll toy a little more  Robos                 Net2Phone ipchains config  Mon, 18 Nov 2002 11:46:27 -0600  John Larmour ( jlarmour from eds.com )    In last issue (  LG  84) help wanted #3:   http://www.linuxgazette.com/issue84/lg_mail.html#wanted/3  it was asked if Linux has net2phone support.  -- Heather    I see that this request is a month or more old.  Has this problem been solved?     Many times, people do get their solutions, but don't pass them back along to us.  So I cannot really say.  -- Heather    I have a linux firewall (ipchains) at home, and run Net2Phone on a window98 box that goes through the firewall.  If you are still having problems, I may be able to help with some of the settings.     Okay, I'm at home now and can check the settings.  On the Net2Phone client, choose menu->preferences->network. Make note of the ""doorman"" URLs and port numbers (mine are call1.net2phone.com and call2.net2phone.com, both on port 6801).  In the client box, choose a number for your ports (I use the same for both TCP and UDP).  Valid numbers are greater than 1024 and less than 65000.     My firewall uses masquerading, and is not a proxy.  I don't know what your setup is, so this may or may not work for you.  In my previous message I said I use ipchains.  Sorry, that shoud have been iptables.  I got it set up a while ago, and really haven't touched it since.     Here are the variables I use in my script:     ${ISP} is the network card connected to my ISP, ${LAN} is the network card connected to my home network. ${PHINIT}is the port used by the doorman (6801) ${PHCTL} and ${PHVCE} are the TCP and UDP port numbers I picked     Here are the iptables commands I added to my script to start my firewall:     iptables -A INPUT -p udp -i ${ISP}-s call1.net2phone.com -m state --state != INVALID --source-port ${PHINIT} -j ACCEPT iptables -A INPUT -p udp -i ${ISP}-s call2.net2phone.com -m state --state != INVALID --source-port ${PHINIT} -j ACCEPT iptables -A INPUT -p udp -i ${ISP}--source-port ${PHVCE} -j ACCEPT iptables -A INPUT -p tcp -i ${ISP}--source-port ${PHCTL} -j ACCEPT     Hope this isn't too late to be helpful....                 Lost win95 data (and system) when loading linux  Sun, 17 Nov 2002 13:00:20 EST  mike, Heather Stern ( the  LG  Answer Gang )  Question by JTHodgson (JTHodgson from aol.com)    Dear Answer gang  -   my problem is an inaccessible C: drive holding my win95 system and all my data - much of it not backed up, naturally     .     Here is how I think it happened.     I started with a standard Win95 set up, with a 5G C: drive, a bootable 48x cd drive  and a standard floppy a: drive.     I then added a 20G Western Digital secondary drive. This came with the Phoenix bios overlay ez-bios, which took control of both internal drives (despite the fact that c: was within the old bios limit).     With both drives running a single dos partition, the system ran without problems, until I tried to partition the d:  drive to load linux (6.3 suse). Neither partition magic, nor fip would repartition the disk.     I then downloaded the latest data life guard (DLG) (=ez-bios) installation utility from the web, and used it to partition the d: drive.  I also made a floppy win95 boot disk.     At this point the win95 system was operating correctly, but with a reduced disk size visible on d:.     I then started to load linux by booting from the cd.  It ran through the initial screens without problem, but when it came to assigning the partition to mount the system, the second partition on d: was not visible.  There was no escape route, so I powered off.     Now the system would not boot from c:.     Nor would it boot from the system disc in a:, or ,rather, when I did the c: drive was not accessible (nor the d: drive!).     I tried fdisk  /mbr , and restoring the mbr ""before installing ez bios"" and "" after installing ez-bios"" (options in the downloaded DLG utility).  The DLG utility also told me that the c: drive had a ""non dos partition"".     I assume that I have inadvertently created a linux partition on the c: drive.     How can I recover from this?  Or is there some other explanation?  Is this a     diy job, or should I consider a data recovery service (my marriage may be at stake here!).     Very grateful for any help you could give.  I'm keen to join the penguins, but this is off-putting!     John Hodgson     [mike]  First off, can you boot into linux? If so check the data as follows     mount the c: partition     type ls  /mnt  to see if a mount point has been setup by your distro     if you see something like  /mnt/dos_c  do ls <this dir> to see if there are any files     if there is no  /mnt/dos  etc directory do the following     mkdir /mnt/c mount /dev/hda1 /mnt/c     then type df to see what partitions are mounted     then type ls  /mnt/c  to see if your files are still there     Thanks, Mike...     To avoid the possibility of further over-writing on the old C: drive, I used DemoLinux running from the CD drive.  By default this loads the  KDE  desk top.     This showed two internal drive icons, but clicking on hda1 gave an error:     ""Unable to run the command specified.  The file or directory file:/mnt/hda1 does not exist""     Moving to console mode:     ls /mnt  gave the response     cdrom  floppy  hdb1     Apparently the old C: drive is not being recognised     Mkdir  /mnt/c   gave error message     Mkdir cannot create directory  '/mnt/c' : permission denied     While DemoLinux was loading I spotted a line that I think related to the old C: drive, giving it the following properties: win98 FAT-32 LBA-matched partition     [Heather]  Sorry to come a bit late to the game.  Anyways it looks to me as if your initial diagnosis is correct - the partition table has gotten somehow mismatched with what is really on the drive.     The Linux utility to deal with this problem is gpart - it will physically look at the bits on the drive, and guess a partition table for you.  If your drive electronics do not agree with what your BIOS reads for cylinder/head/sector values, it might actually be wrong, but if you see something that looks like the layout you remember, it's probably right, and you can write the result into the MBR-tail with a commandline switch.     (I say ""tail"" because strictly speaking the first 446 bytes are the boot loader and the 64 bits at the end are the partition table, and some techies refer to only the loader as the MBR, while others call the whole 512byte cluster this.  But we digress.)     The DOS analogue to solve this problem - bearing in mind that I've not had to use it for years, so I cannot vouch for the current edition one way or another... is Symantec's Norton Disk Doctor... NDD  /REBUILD.  As a few repartitioning utlities are on the market they might also have some sort of ""reset to whatever the disk has on it"" feature - possibly as a last-ditch rescue against their own failure modes.  The same caveat against the BIOS mismatch problem applies.  Also, if it isn't new enough a DOS tool may not recognize any linux bits you've managed to get on there.     Anyways, I  have  used gpart recently myself and can assure you that it works.  The real fun is getting a cd-boot or floppy-boot distro that has it in there.  I don't recall if I used Knoppix, or if I host-mounted one of my laptop drives temporarily (so  /dev/hda  was a known good system).  DemoLinux, if it has a copy of gpart on it, can help you solve that quite quickly, and if it doesn't have it, you may be able to fetch a binary of the program into your ramdisk.     Pretty much, all the live-CD discs use a ramdisk or two.                 Good locations for sendmail howtos?  Tue, 26 Nov 2002 13:07:33 -0800  Heather Stern, John Karns ( the  LG  Answer Gang )  Question by David (supersimian from hotmail.com)     Hey there Answer Gang,     You've helped me in the past, I'm hoping you can help me again.     I'm having diffuculties setting up sendmail and friends on a small home network. I can't seem to get mail to work between hosts. I feel fairly competent in linux in general, but this continues to baffle me.     I'm using RedHat 8.0 on two systems, my main desktop, and our firewall/dns/nat/etc box. My roommate is using WinXP. But basically, I'm looking for a good howto doc on setting up email between the gateway box and my desktop, so I can forward the root mail form the gateway to an arbitrary account on my desktop. Y'know, for getting alerts, logwatch info, etc.     And just to learn a bit more about the workings of email in general.     At present, I can't get ANY kind of email to move between the two boxes.     Mostly, I'm looking for a really good writeup on how to configure things to my liking. I mean, I don't want to have to buy a book on it, it's just for home use, but I want a good understanding.     If you people can point me towards a good resource, I'd really appreciate it.     [John Karns]  Well I suppose the best resource is the O'Reilly book on sendmail - but since you mentioned that you don't want to buy a book, I do recall stumbling across a helpful sendmail web site about 3 yrs ago.  So a web search would probably turn up a few sources of info.  There are also some fairly comprehensive FAQ's etc available...     [Heather]       try the faq's and other helpful notes at sendmail.org, then the    community forums at sendmail.net.    each of sendmail's major competitors also have websites;  since some    of their FAQs are in the form of ""under sendmail I would... how do I    do that in this mail transport?""  then reading the documentation of    all the major mailers should help considerably toward learning about    email in general.    for your NT box to get mail from your linux server, either your linux    server needs to run POP or IMAP daemons... or your NT system has to    run an SMTP daemon and be listed as a MX for itself. The first one    is  much  easier.     Thanks Heather, I'll have a look at these resources. Luckily, I've managed to muddle through a bit of it on my own, the mail is moving, just need to fine-tune things a bit. I now understand why the sendmail.cf file is so infamous        rewrite rules, UGH...     [John Karns]  Finally, I can provide a quick hint about (one method of) setting up mail between hosts.  For my purposes I just added the host names in  /etc/mail/mailertable  in form of     machine1.my.psuedo.dom         smtp:machine1.my.psuedo.dom machine2.my.psuedo.dom         smtp:machine2.my.psuedo.dom     In the comments in that file:       ...............    # sendmail will look for all non-local email into this file to determine  # the transport way to the next host. the destination hostname is used  # to find an entry in this file.  ...............      And from  /etc/mail/README:        ...............    sendmail.cf supports some more external database files. The default configuration uses  /etc/aliases ,  /etc/mail/mailertable ,  /etc/mail/genericstable  and  /etc/mail/virtusertable.  These files are normal text files that are converted with ""makemap"" to the real database files (ending in .db).     For all outgoing email, sendmail will use the destination hostname and look into  /etc/mail/mailertable  to see how this email should be transported to the next destination. Please read that file for some examples on email-routing.  ...............      Note 1: There is a Makefile in that dir to enable running 'make' after adding the host names to the text file.  That will create the .db file which sendmail actually uses.     Note 2: I'm not sure how much of this structure is from the generic sendmail and how much may be contributed by  SuSE , but my gueess is that it is mostly generic.  This seems to be born out by the above reference to sendmail.cf pointing to those files.     Note 3: This setup works for me.  I don't have a name server set up, just use a hosts file.  YMMV.             Will this modem even work?  Let's ask the internet  Sun, 10 Nov 2002 14:15:06 -0800  Rick Moen ( the  LG  Answer Gang )  Question by Helen & Ralph (ralphk from hauns.com)       can I use a zoom/modem usb model 3090 with redhat 7.2 ?     The best place to research USB-hardware support problems in Linux is  http://www.linux-usb.org .  You might want to make a   note of that, for the future.  Selecting ""Working devices list"" on the front page takes you the Overview page.  From there, we select Devices, since we're looking up support for a particular hardware device, rather than any of the other information categories.  We're now shown the dozen or so USB device categories, and pick ""Comm:  Communications devices (Modems)"". This brings us to a long multipage list of modems by manufacturer. Moving through that to the Zs, eventually finding the line item for ""Zoom Telephonics, Inc. 3090"".  Finally, selecting that item brings us to  http://www.qbik.ch/usb/devices/showdev.php?id=660 .     And it's bad news:     Zoom sales claims this is ""a winmodem and will not work with Linux"". Shame.     There's more, but that about sums it up: This is undoubtedly a unit designed to achieve the lowest possible retail price by omitting key circuitry normally integral to all modems (the ROM or ""controller"" chip implementing required communications protocols, and/or the UART chip to control and buffer serial communications).  The omitted functionality is then emulated in software by MS-Windows-only proprietary ""engine' software.     If/when you go shopping for a better modem, you might want to consult Rob Clark's modem database, at  http://www.idir.net/~gromitkc/winmodem.html .     The real tip here, for newbies and old hands alike;  we can no longer assume that being external or internal, or which interface a modem is plugged into, indicates whether it has an incomplete chipset and needs a booster shot from specialized driver software.  Some manufacturers offer fully-capable internal modems, and some external ones are duds like this one.  Use the net resources at  http://www.linmodems.org , and if you  decide  to use a supported or partially supported winmodem, don't expect too much out of it when you have your system under a heavy CPU load.  -- Heather                  This page edited and maintained by the Editors of  Linux Gazette HTML script maintained by  Heather Stern  of Starshine Technical Services,  http://www.starshine.org/   Copyright © 2002  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                    ... making Linux just a little more fun!                   The Answer Gang      By Jim Dennis, Ben Okopnik, Dan Wilder, Breen, Chris, and...         ( meet the Gang ) ...          the Editors of  Linux Gazette ...           and You!                 We have guidelines for  asking  and  answering  questions.  Linux questions only, please.   We make  no guarantees  about answers, but you can be  anonymous  on request.   See also: The Answer Gang's   Knowledge Base  and the  LG    Search Engine           Contents:     ¶: Greetings From Heather Stern        Triple booting   code safety   PC-MOS   restoring broken X connections           Greetings from Heather Stern      Welcome once more folks, to the world of The Answer Gang.  We haven't decided where to hang the stockings;  Tux goes out on Geek Cruises all the time, so he's rarely found at the South Pole anymore.  Perhaps I should create a  /hearth  in my home directory, and give it a  /chimney , some  /stockings , and what the heck,  /menorah ,  /presents , and  /peace.on.earth.   Top things off with a  /var/log/yule  we can burn in January, and...     Oh, you didn't want to hear all this silliness.  You wanted to get to the presents.  Well, I can tell you this little nerdette is still looking for LCD monitor prices to come down.  I guess my New Year's Resolution will have to be running past a nice scanner.     If you can't think of anything for the geek in your life, I recommend a good uninterruptible power supply (UPS).  We can always use more...     For those who are wondering, the top reason for anyone not getting answered this month is:  insufficient detail!  Folks, we're pretty smart, and might even be accused of telepathy, but we are not there in the room with you, so we can't see that machine.  We really need those error messages, any bleeps it's making, how it worked before and what you were expecting of it.  With these things, we can provide answers you probably had no idea were available ... beyond just how to do the thing you think will work.   WIthout these hints, we're as blind and as stumped as you are to what's going on.     To all the tiny elves, Kris Kringles and Gnomes in our computers, enjoy your extra trons and blinkylights this season.            Triple booting     From Raj Shekhar      Comments By Mike Orr, Heather Stern, Rick Moen     In response to LG 84, Tips 25:  http://www.linuxgazette.com/issue84/lg_tips.html#25   -- Heather       Muthukumar Kalimani wanted to install three operating systems on his box. I had helped my friend do the same and here are some hard found lessons.       Use ""fdisk"" from your Linux   distro CD to create partitions. Use the   expert mode to partition the hard disk and   use cylinder numbers for specifying partition   sizes.   Using fdisk create a 25Mb - 30 Mb partition   which is below cylinder number 1024. This will   be the partition in which you will install the   /boot of Linux OS.       [Mike]  The Large Disk HOWTO  http://www.tldp.org/HOWTO/Large-Disk-HOWTO.html  claims this is mostly not a problem any more.     (Paranoid people like myself continue to place  /boot  partitions and C: partitions below 1024.)       [Rick]  In theory, it went away in 1994.     That was the year that motherboard manufacturers rolled out Yet Another BIOS Extension, providing a new method by which boot-time software could get extended BIOS routine 13h information to directly address logical cylinders numbered 1024 and above.  A new version of LILO immediately came out, that requested and could process that BIOS information.     So, in theory, the only people who need put  /boot  below the 1024th logical cylinder are       using really antique booting software (a very bad idea) or   contending with very old motherboard BIOSes, usually on 486es.  I'm    unclear on whether any early Pentium motherboards used the older-version    int 13h call, or whether it's a 486-only issue.     A lot of us old-timers retain the  /boot-filesystem-first  habit just from long usage, but also because people sometimes come in the door with antique BIOSes and fail to mention that fact.  Better to put  /boot  near the outer tracks than risk spending considerable effort building a system and then find it unbootable.       [Heather]  Rick and I both do installfests;  I especially help people with laptops, which have all sorts of oddball things in their BIOS.  It's far easier to obey this rule of thumb than have to do things over on the limited time available at such install parties (usually only about 4 or 5 hours, but people arrive late, and would rather spend time learning the diffs between K and Gnome, set up their mailer, etc).     I think it's important to note that  /boot  doesn't care about being first, only about early on the disk (if it cares at all).  I usually give it partition 2;  that satisfies some MSwin setups that want the first entry, and avoids the 4th entry, which some hibernation setups like to take.  Make the third an extend partition, put a D: in there if you were planning a more even split on a large disk, a swap, and at least one more volume for  /  (though I refer you to past articles for The Gang's recommendations about partition layout beyond that).     If you are really trying for maximum space ""under the bar"" assigned elsewhere instead ... it can be as small as 7 or 8 MB. I wouldn't go smaller for fear that monolithic kernels might get pretty big at some point.  You always want room for three things: the bootloader parts themselves, a known good kernel, and whichever one you are recently trying out.   If you're triple-or-more booting and more than one are Linux, you might want to lean the other direction and make room for lots of modules to go with them (symlink  /lib/modules  to  /boot/modules  in all distros and share the goodies).        If you want to know more about Partitioning using ""fdisk"" refer to:     Linux Partition HOWTO  by Tony Harris and Kristian Koehntopp  (it is a mini HOWTO)  in particular see section [5] [Partitioning with fdisk]   http://www.tldp.org/HOWTO/mini/Partition/index.html       install Win98 first and give it the first   partition i.e. allow it to place itself in c:.   If you do not do this Win98 usually corrupts   whatever OS (even if it is from Win family)   is placed on C:.       [Heather]  If you create the FAT filesystem for it ahead of time, MSwin's  SETUP.EXE  usually won't gratuitously fill the entire disk for you, which saves digging up a resizer later.             When you install Linux remember to place the   /boot on the partition you created for it.   If you have trouble booting into your Linux   after you have installed all three OSs, you need   a Operating System loader.   Use Google Search to find any of the following   loaders   XOSL -> Nice GUI   Boot Part -> Light weight and CLI (non-GUI)     Hope you find this relevant.       [Mike]  Are you specifically excluding LILO and GRUB?  Why?        I had written that the querent needs to install a loader   _if  he has  trouble_  booting into GNU/Linux (using either GRUB/LILO). I had installed RH 7.1 with Win2k and I had trouble booting into GNU/Linux. RH 7.1 came with LILO version 21.4-4     Thankfully this problem was well documented in Linux+NT-Loader mini-HOWTO It had adviced to use Boot Part for solving this problem. I am still using Boot Part to boot into my GNU/Linux(RH 7.1) OS. I think newer versions of RH do not show this problem but I am not sure as I have only RH 7.1. (thinking of shifting to  Debian ).LILO does not need any special hacking to detect and boot up Win98.     One of my friends had discovered XOSL and even though he was a newbie, he had three OSs up and running in no time. (Win 98,WinXP,Linux and maybe Win2k too!)       [Mike]  GRUB is more user-friendly than LILO.  I wish I could use it on my computer but the ""linear"" option doesn't work.  I had to switch back to LILO because my computer won't work with the ""lba32"" setting.        Talking about loaders, three years back I experimented with Be OS.It was really cool and really sparing of machine resources. I had Win98 installed on my box. It installed quite easily on FAT filesystem and it placed an icon on my Win98 desktop. On clicking it, Be would boot up. And I think it did not take much time to startup. I removed it beacuse it did not come bundled with much apps. What I wanted to know do we have this sort of funky loader in GNU/Linux?       [Heather]  Yes.  The canonical way to launch Linux froma running DOS or MSwin system is a program called  LOADLIN.EXE.   I understand there is a mildly different version of it for NT, and you should prepare a PIF for it that tells MSwin it's okay to give it all the resources it needs - go ahead and take over the CPU - then you'll have a happy one way trip to whatever kernel you told it to load.   Oh yeah, and the linux kernel you use has to be visible in your DOS filesystem.  I usually suggest to keep such parts in C:\LINUX so it's obvious.        I have not experimented with GRUB but LILO can be tough for a newbie (IMVVHO). Again I am talking about the older versions and I have no experience with newer versions.       [Rick]  A lot of people never learned the Zen of LILO:       /sbin/lilo (the ""map installer"") is best thought of as a compiler,     and /etc/lilo.conf as its source code.   Therefore, if you change /etc/lilo.conf or any of the files it     points to, you must run /sbin/lilo before rebooting, to ""recompile"".   You should always have a ""safeboot"" stanza in /etc/lilo, pointing     to a known-good kernel image that you never fool with, as a     fallback.  This ensures that if, e.g., you compile a new kernel but     accidentally omit console support, you can easily recover.     GRUB is a capable and flexible bootloader, but practically all of the reasons commonly cited for it being preferable to LILO boil down to ""I once messed with my boot files before reading LILO documentation, shot myself in the foot, and therefore blame LILO.""             code safety     From Jose Nazario       Comments By  Mike Orr, Ben Okopnik, Steve Kemp, Tom Bradley     i was looking through the november issue of linux gazette and something caught my eye. overall the issue had a few things i was pretty happy to see: a piece on mono, elf kernel execution, and adding loadable plugins to code. it's this last piece i have a problem with.     Adding Plugin Capabilities To Your Code:  http://www.linuxgazette.com/issue84/bradley.html      tom bradley's code, while demonstration code, is a perfect example of unreliable code and illustrates why this kind of thing should be avoided. in main.c (truncated to save space):     #define PATH_LENGTH 256 ...         char path[PATH_LENGTH], * msg = NULL; ...         /* build the pathname for the module */         getcwd(path, PATH_LENGTH);         strcat(path, ""/"");         strcat(path, argv[1]);     it's quite trivial to overflow path[PATH_LENGTH], even inadvertantly. before you say ""look, this isn't setuid root, this isn't anything but demonstration code, don't rush off to bugtraq"" i want to say this: for precisely the reason that it is demonstration code it should do bounds checking.       [Ben Okopnik]  Agreed, 100%. One of the many security-related sites I read on a regular basis had a ""ha-ha-only-serious"" quote that's worth paying attention to:     <ironic> Security hint of the day:             find . -name '*.[ch]' | xargs egrep -l 'sprintf|strcat|strcpy' | xargs rm     </ironic> -- Pavel Kankovsky aka Peak     Funny, but...       [Steve Kemp]  There are a few decent scanning tools available, like 'flawfinder', 'rats', and 'its' which are worth using if you want to be scared!     Steve  ---  #  Debian  Security Audit Project  http://www.steve.org.uk/Debian         lots of people are going to code their apps with this as a start and not think twice about the reliability of the foundation of this code.  the fact is someone can easily hit this upper limit inadvertantly (think of a well organized person who has a deep directory structure ... suddenly path[] has a lot less overhead).     secondly, bounded string manipulation should just be a habit, and habits develop after repeated application of the effort. crappy, unchecked runtime errors are the bane of software quality, there's no reason you shouldn't always do sanity checks, even in demo code. one reason alone to do it is that you'll get so annoyed you may want to improve the interface to error checked code, benefitting us all.     anyhow, thanks for the november issue.     Forwarding to the author, Tom Bradley < tojabr@tojabr.com >.  This message will be in December's  LG  .  Feel free to write a response or a follow-up article if you wish.  -- Mike       thanks mike. tom, in all seriousness that article was really cool and timely, and i will definitely be referring to it to make use of it. i just take issue with unchecked errors in code ...     thanks for an otherwise well written piece.       [Tom Bradley]  I agree that was setting a bad example on my part, below is a corrected version.     (truncated to only changed partion) ...     char * path, * msg = NULL; int (*entry)(); void * module;     if(argc < 2) {     printf(""No module given.\n""); return; }     path = (char*)get_current_dir_name(); path = (char*)realloc(path, strlen(path) + strlen(argv[1]) + 2); strcat(path, "" / ""); strcat(path, argv[1]); ...     the #define has been removed.     Tom             PC-MOS     From Reilly Burke      Comments By  Thomas Adams, Mike ""Iron"" Orr, Heather Stern      [Heather] Reilly Burke is Technical Advisor for a company called Aero Training Products, Inc. ( http://www.aerotraining.com )     To Derek Holliday     We have copies of PC-MOS and LanLink available.  We also produce LanLink drivers for PC-MOS.     PC-MOS is required to run POS systems with DOS applications.   DOSEMU  is not good enough to run many (most) of the apps.  PC-MOS is file-compatible with DOS systems, but only the November 93 kernel (of PC-MOS) can access 3.5"" floppies.     I'd love to replace our PC-MOS applications, but nothing quite measures up yet.  Linux is nowhere near being able to do the job (it's way too big, complex, & geeky)!  Possibly DR-DOS 8 (coming out in spring 2003 with FAT32) might do the job.       [Thomas]  How would you know until you tried? Just because Linux is too big and ""geeky"" in your eyes; does not mean to say that it couldn't do the job! It's not really logical to say that.       [Iron]  DOS  programs , however, often access the hardware directly, so it's not surprising DOSEMU can't emulate the environment quite well enough.       [Heather]  Thanks for this tip on an old thread;  it's not Linux, but since we seem to be the only place that talks about it...     I'm curious about what the problems under DOSEMU + (say) MS-DOS 5.0 are, but unless this is a problem you're trying to solve for yourself, you may not want to bother delving any further.     The buzzword ""point of sale"" typed into the  Freshmeat  search index ( http://freshmeat.net ) yields 7 direct hits, and a category for point of sale containing 42 projects.  Well over a year ago I saw one written up in a magazine article (I think it was  Linux Journal  actually) about a POS system optimized for a pizza place.  That's geeky;  but the pizzas he was selling are real.     Some of these projects will really be ""e-business"" (aimed at web based stores, not one where a high school student has to run the register, nor where the machine has a real register to pop the change out of) and a few of them are optimized for a specific kind of shop.  But they may do for some people.        Of course we're still trying to move our PC-MOS apps to Linux, but so far, after years of experimenting and coding, we're still running the PC-MOS systems because there's still nothing like them for Point-Of-Sale utility.  It's fast and small and entirely bug-free.   The last PC-MOS kernel released was November 93 (9 years ago).  But it's designed for old hardware (ISA slots, NE2000 ethernet cards, Wyse terminals, and serial printers), and the systems are becoming increasingly difficult to maintain.  There's probably still 100,000 PC-MOS users looking for an answer, but the closest thing is probably DR-DOS.  Linux is not being maintained by POS geeks, so there's a real shortage of Linux POS tools and solutions.     We've tried disassembling the drivers (we succeeded in cloning the Lan client drivers with new serial numbers!) , but disassembling the entire OS is far too complicated.  We've also tried rewriting the DOS apps (in particular, the Shark database). We have its horribly complicated monolithic Microsoft C source code, with chunks of assembler mixed in, but it's still a giant task.  The only feasible direction looks like rewriting the Shark compiler in Kylix, but even that is a horrendous prospect.  So far, PC-MOS still works (and it's paid for   , and the Shark database is still fast and flexible.     We'd really like to hear from any other POS types who are trying to move to Linux.     Reilly Burke             restoring broken X connections     From Mustafa C. Kuscu       Answered By  Jay R. Ashworth, Rick Moen, Robos, Heather Stern, Kapil Hari Paranjape     Hi, James. When a remote X-forwarding ssh connection is broken, all the windows at my local server get lost. Is there a way to prevent the remote processes from shutting down, so as to resume the processes and have the windows re-sent to the local X-server when I relogin?     Thanks Mustafa       [jra]  Not per se, but investigate VNC.  I'm in the midst of writing an article on it as it happens, but it can be used to do what you need.       [Rick]  Jay, just to help:  I know of these VNC implementations (also known as ""RFB"" = Remote Frame Buffer):       RealVNC, formerly AT&T Cambridge's reference implementation,     http://www.realvnc.com    TridiaVNC,  http://www.tridiavnc.com    TightVNC,  http://www.tightvnc.com    x0rfbserver (great name, eh?),  http://www.hexonet.de/software/x0rfbserver ,    optionally with kfrb,  http://www.tjansen.de/krfb  or x0rfb from the    rfb package,  http://hexonet.de/software/rfb      You'll find a number of resources about VNC over SSH in my ssh-clients file,  http://linuxmafia.com/pub/linux/security/ssh-clients      Also worth looking into:       MLView DXPC,  http://www.medialogic.it/projects/mlview  :  Compressed    and proxied X11 -- sort of an update of the LBX idea.  Much faster    than VNC.   rdesktop,  http://www.rdesktop.org , an RDP client for Windows    Terminal Services.  Likewise much faster than VNC; also, fully    multiuser, unlike VNC.       [Robos]  Well, not entirely true IIRC since I had some thoughts about this lately too and shortly after that a friend of mine told me that there exists something like screen for xserver connections. And now guess what, he and me forgot it again. Great. So, it exists, but somewhere and I can't tell where...       [Rick]  Possibly, you're trying to think of xnest?      [Heather] I suspect not;  xnest handles issues about color depth, not being able to set processes to sleep and waken them up from another console.       [Kapil]  Actually you may mean ""ratpoison"" but that is only a window manager which has a ""screen""-ish look and feel.     The following setup works well for me from home and work.     At work:     start ratpoison  get ratpoison to start rfb (or to give its full name x0rfbserver).  get ratpoison to start a screen session.     Do some real work via screen.     (All programs that invoke graphics work via ratpoison).     At Home:     run ssh -L 5900:localhost:5900 to the work machine.  on the remote machine run ""screen -D -R""  start xvncviewer on the local machine.     Do some real work via screen!     Thus text based applications work via ssh and screen so are reasonably fast. Meanwhile any remote program that invokes graphics creates  a window within the xvncviewer.     Needless to say ratpoison runs at home too!     I was quite pleased when I cooked up this config as you can see!     As long as the machine at work continues to run none of the sessions is ever exited or lost. VNC and screen passwrods provide some security as well.     Hope this helps,     Kapil.       [Robos]  Nope, I found it!  I actually mean  - xmove! Look here:      ftp://ftp.cs.columbia.edu/pub/xmove      Thats also the thing the original querent might wanna have.       [Kapil]  I tried out ""xmove"". Er, ... just one problem. It uses TCP connections to connect with the xserver which means that X with ""-nolisten tcp"" does not work.     In the modern security conscious world this is essentially all X servers!       [Robos]  Well, thats true. But, you can either remove the call in  /etc/X11/xinit/xserverrc  and maybe  /etc/gdm/gdm.conf  (dunno for kdm or xdm) or ssh -X   _should  be permitted if I gather some comment I read correctly. The say the others?       [Heather]  As far as X is concerned ssh -X merely yields a valid server running at a higher screen number - 10 rather than 1 is typical, so localhost:10 would send all processes down the ssh pipe back to where you are sitting.     If you're sure it works at the TCP level it may not work.  If it works with normal TCP/IP packets, then it can surely be tunneled.  But you can try playing games with ssh at the transport layer first.  There are stacks of examples for POP over SSH out there;  that's how they work, so it's worth a look too.                     Copyright © 2002  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002        HTML script maintained by          Heather Stern  of         Starshine Technical Services,         http://www.starshine.org/                  ... making Linux just a little more fun!         News Bytes     By  Michael Conry                             Contents:     Legislation and More Legislation   Linux Links   Conferences and Events   News in General   Distro News   Software and Product News        Selected and formatted by   Michael Conry        Submitters, send your News Bytes items in   PLAIN TEXT  format.  Other formats may be rejected without reading.  You have been warned!  A one- or two-paragraph summary plus URL gets you a better announcement than an entire press release. Submit items to  gazette@ssc.com                December 2002  Linux Journal          The December issue of  Linux Journal  is on newsstands now. This issue focuses on System Administration.  Click   here  to view the table of contents, or   here   to subscribe.     All articles older than three months are available for public reading at   http://www.linuxjournal.com/magazine.php .   Recent articles are available on-line for subscribers only at   http://interactive.linuxjournal.com/ .                       Legislation and More Legislation               DMCA        Finding bizarre implications of the DMCA with which to ridicule it is as easy as shooting fish in a barrel.  The Register recently reported that four major retailers (WalMart, Target, Best Buy and Staples) had    invoked the DMCA  to prevent   FatWallet.com  from disseminating information about sales and price comparisons.  The argument runs that sale prices are copyrightable information (and not just simple facts). FatWallet has had to   comply  to avoid the risk of a very costly legal battle.   In other DMCA related matters, Security Focus reported that hardware manufacturers producing games console mod chips   have found themselves under pressure , applied through the device of the DMCA, to cease such production.  The argument hinges on whether the non-infringing uses legitimise the chips, and its a criterion which can vary substantially from country to country.   Finally, there is a very interesting    DMCA article  by Adam C. Engst at  TidBITS .  It provides a good overview of the issues arising from the law, and the stakes the ""content industry"" is playing for in its long-term strategy.  Related to this is another article at TidBITS (by Cory Doctorow) entitled    Can the Digital Hub Survive Hollywood? . It does a fine job of highlighting the tensions between the content/media industries versus the interests of the technology industry at large (as opposed to the welfare of sectoral interests within the tech industry who might do very well if their technology is used for protecting ""content"").  Particular attention is paid to the BPDG (Broadcast Protection Discussion Group).              Mobilix        In a reversal of an lower court's decision, a   German court has ruled  that the name Mobilix is sufficiently close in sound and appearance to Obelix to cause confusion.  Mobilix is a website dealing with the area of Unix on mobile devices.  Obelix is a character from a French comic book. The final implications of this decision are not clear. You can follow the entire story   on the Mobilix website .               DRM         Slashdot recently   reported  on the   ACM Digital Rights Management Workshop .  Among those present was Ed Felten whose    brief commentary can be read here .  It was reported that there was some scepticism that DRM was truly a panacea for the copy-protection worries of Hollywood info-hoarders. In a not unrelated story, The Register    reported on the future of Microsoft's Palladium  and the Trusted Computing Platform Alliance (TCPA).  Even proponents of the system admit it is not totally secure and potentially vulnerable to intelligent hardware attacks.         Linux Links    Some links from  Linux Weekly News :               Summary of a US Department of Defence report  on its level of use of     free software.  The initial brief for the report was to evaluate the     possibility of banning such software, but the final document is quite     positive on the role and importance of free software to the     department's operations.               Linux in emergency-response switchboards .               LinDVD, a Linux DVD player .  Available only to OEMs for embedded     systems, not to individuals.          Some links from the O'Reilly websites:               An article on the future of threads in Linux .               Python for Bioinformatics .               The SSH Cryptosystem .               TriSentry, a Unix Intrusion Detection System .       DesktopLinux.com have   an article  about   Film Gimp .  Film Gimp is a motion picture frame-editing tool.  The article has some technical details and reports on its use in the film industry.    Linux Journal  have   an article  explaining how to train mutt to catch spam using ESR's bogofilter.   News.com have    reported  on IBM's plans to build two new machines which would be the fastest supercomputers to date.  The Blue Gene/L, the faster of the two, will be Linux powered, and 10 times faster than the current title-holder, NEC's Earth Simulator.   A    survey of some open source multimedia projects  which might be of interest.   Some links from  Linux Today          Linux and Main article on           The Linux kernel as a periodical publication , and Linus as editor     in chief.         NewsForge           talk to Jay Beale  of Bastille on improving Linux security               OSDir.com interview  with Bram Moolenaar (most famous for      VIM ) on the subject of his new project,       A-A-P .  A-A-P aims to be a kind of     ""super make"".         The Inquirer  has run a series of articles describing the Linux install process in a way designed to help beginners.  Parts   1 ,   2 ,   3 ,   4 ,   5 .   IBM Developerworks have   an article on open source scientific software , being used increasingly by those involved in scientific research.     A report  at Linux and Main on the path to the next major kernel release.     From Debian Weekly News , a link to    an interview  with Klaus Knopper of   Knoppix .  Particular comments on hardware detection implementation.   Some links of interest from  The Register :         IBM's S/390 Linux guru interviewed on the           Open Source patent question                A guide for relatively experienced users  on securing your data     under Linux.         Brussels to spend €250k on            Linux migration study                Namibia rejects MS in favour of Linux        Some links from   Slashdot  which may interest you:                           Community wireless network          in Bristol, England.                     Humorix reports that Red Hat is hoping to                    make a universal shell and a mutant vi/emacs hybrid editor          to complement their synergised KDE and Gnome (tongue firmly in cheek).               ESR presents a recently leaked Halloween document from Microsoft                   describing their strategy to combat Linux .  This is the latest in a                   tradition of such leaks .                               Tablet PCs with Lindows, notebooks for $800 .                     LinuxBIOS,                   is a non-proprietary system BIOS          that can boot Linux, Windows 2000 and OpenBSD.  It works only with         certain motherboards.                       Mozilla 1.2  is out                      Linus  tells  eWeek about the upcoming Linux 2.6                  Upcoming conferences and events     Listings courtesy  Linux Journal .  See  LJ 's  Events  page for the latest goings-on.                      Linux-Bangalore/2002                    December 3-5, 2002 Bangalore, Inda                    http://linux-bangalore.org/2002/                  USENIX 5th Symposium on Operating Systems Design         and Implementation (OSDI)           December 9-11, 2002 Boston, MA                    http://www.usenix.org/                 Consumer Electronics Show           January 9-12, 2003 Las Vegas, NV                    http://www.cesweb.org/                 LinuxWorld Conference & Expo           January 21-24, 2003 New York, NY                    http://www.linuxworldexpo.com/                 O'Reilly Bioinformatics Technology Conference           February 3-6, 2003 San Diego, CA                    http://conferences.oreilly.com/                 Game Developers Conference           March 4-8, 2003 San Jose, CA                    http://www.gdconf.com/                 SXSW           March 7-11, 2003 Austin, TX                    http://www.sxsw.com/interactive                 COMDEX Canada           March 11-13, 2003 Vancouver, BC                    http://www.comdex.com/vancouver/                 CeBIT           March 12-19, 2003 Hannover, Germany                    http://www.cebit.de/                 4th USENIX Symposium on Internet Technologies and Systems           March 26-28, 2003 Seattle, WA                    http://www.usenix.org/events/                 4th USENIX Symposium on Internet Technologies and Systems           March 26-28, 2003 Seattle, WA                    http://www.usenix.org/events/                 PyCon  (the first ""low budget"" Python conference)       Note:  This is the first  low budget  Python conference, so if you've been avoiding Python conferences due to the cost, this one is for you!  Another conference, the main International Python Conference, will be held in July as part of O'Reilly's OSCON (Open Source Convention).                    March 26-28, 2003 Washington, DC                    http://www.python.org/pycon/                 AIIM           April 7-9, 2003 New York, NY                    http://www.advanstar.com/                 SD West           April 8-10, 2003 Santa Clara, CA                    http://www.sdexpo.com/                 COMDEX Chicago           April 15-17, 2003 Chicago, IL                    http://www.comdex.com/chicago/                 Real World Linux Conference and Expo           April 29-30, 2003 Toronto, Ontario                    http://www.realworldlinux.com                  USENIX First International Conference on Mobile Systems,   Applications, and Services (MobiSys)           May 5-8, 2003 San Francisco, CA                    http://www.usenix.org/events/                 USENIX Annual Technical Conference           June 9-14, 2003 San Antonio, TX                    http://www.usenix.org/events/                 CeBIT America           June 18-20, 2003 New York, NY                    http://www.cebit-america.com/                 O'Reilly Open Source Convention           July 7-11, 2003 Location: TBD                    http://conferences.oreilly.com/                 12th USENIX Security Symposium           August 4-8, 2003 Washington, DC                    http://www.usenix.org/events/                 LinuxWorld Conference & Expo           August 5-7, 2003 San Francisco, CA                    http://www.linuxworldexpo.com                   News in General              MySQL, NuSphere and the GPL        MySQL AB has    settled its dispute  with NuSphere corporation.  MySQL AB had claimed that NuSphere violated the GPL and misused the MySQL trademark. (NuSphere includes MySQL with NuSphere's enhancements in its product.) NuSphere has assigned to MySQL AB the copyrights for its contributions to MySQL.  Not so coincidentally, MySQL AB has just   donated $25,000 to the Free Software Foundation's GPL Compliance Lab , which helps companies offering GPL'd software follow up on GPL violations. According to the FSF's Executive Directory Bradley Kuhn, almost all GPL violations are mistakes rather than wilful infringement.         Distro News               Debian        Debian Weekly News   highlighted  a LinuxOrbit   HOWTO on installing and configuring ALSA .  The piece describes the correct ""Debian way"" to perform the task.              Knoppix          Debian Weekly News Reported  that people from the   Debian-Med subproject  have    started  a Knoppix-Med project.  The aim is to include particular pieces of medical software into the Debian Based   Knoppix distribution . Details of the procedure   are available online .              SuSE          SuSE Linux  has announced a multi-stage product campaign for the corporate desktop deployment of SuSE Linux. Starting January 2003, small and medium-scale enterprises will be able to migrate to Linux on desktops using the ""SuSE Linux Office Desktop"". ""SuSE Linux Enterprise Desktop"", a Linux version optimised for desktop deployment in large-scale enterprises, is expected to be released in the first quarter of 2003.       SuSE Linux has also announced that the   SuSE Linux Enterprise Server (SLES)  has proved itself as a powerful Linux platform for IBM`s DB2 Version 8 database software with SLES latest certification for DB2. SuSE Linux Enterprise Server is the first distribution to be  validated on all hardware platforms supported by DB2 for Linux  (including IBM zSeries mainframes) and validated to run DB2  Enterprise Server Edition. More information on IBM's DB2 for Linux Validation Program   is available online .              UnitedLinux          The UnitedLinux group  have announced the release of Version 1.0 of its UnitedLinux product, a standards-based Linux operating system targeted at the business user. UnitedLinux is the result of an industry initiative to streamline Linux development and certification around a global, uniform distribution of Linux.  Founding companies of UnitedLinux are Linux industry leaders Conectiva S.A., The SCO Group, SuSE Linux AG, and Turbolinux, Inc.         Software and Product News               New kernels        A new stable kernel 2.4.20 has been released.  A new ancient kernel 2.2.23 has also been released if you're still living in the medieval ages. Get your update at a  kernel mirror  near you.              Mathematica Ported to NEC's Itanium Linux Platform          Wolfram Research  and   NEC  have collaborated to port   Mathematica  to NEC's Itanium Linux platform for the upcoming release of Mathematica 4.2.              Appligent Alliance Program          Appligent  has unveiled a new Alliance Program designed to help integrators and consultants develop more powerful electronic document management applications for their clients.  Appligent's main product is a range of PDF-related software which supports, among other operating systems, Red Hat Linux.              Updated Opera 6.1 for Linux on Intel and PowerPC          Opera Software  have released Opera 6.1 for Linux for Intel and PowerPC users. The PowerPC version is the first released on this platform since the tentative Opera 5 for Linux Beta in May 2001. In addition to several bugfixes, this release features better support for fonts in the new version, with font anti-aliasing enabled by default and improved support for Chinese, Japanese and Korean characters.   The changelog  documents all the new developments in this release.               Pygame              Pygame  is a cross-platfrom library designed to make it easy to write multimedia software, such as games, in Python. Pygame requires the Python language and SDL multimedia library. A major advantage is portability, games based on Pygame can run on Windows, NT4, MacOS, OSX, BeOS, FreeBSD and IRIX, as well as Linux.              Cylant Secure          Cylant  has ported the management console for its  Linux Intrusion Prevention system to Windows.  The Windows console allows administrators  to managed CylantSecure server agents from their Windows workstations.                          Copyright © 2002, Michael Conry. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                   ... making Linux just a little more fun!         HelpDex     By  Shane Collinge                      These cartoons are scaled down to minimize horizontal scrolling.  To see a panel in all its clarity, click on it.                                     More adventures of VI-Agra, the vi paperclip assistant, are in the  Qubism  column this issue, and in the back issues under both HelpDex and Qubism.    Recent HelpDex cartoons are at Shane's new web site,  www.shanecollinge.com , on the  Linux  page. Cartoons during his Asia trip this year are at the  CORE  CORE web site.    What's this? Shane found it in the  Los Amigos  hostel in Madrid. I kid you not, it's  true .               Copyright © 2002, Shane Collinge. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                   ... making Linux just a little more fun!         Ecol     By  Javier Malonda                These cartoons were made for es.comp.os.linux (ECOL), the Spanish USENET newsgroup for Linux.  The strips are drawn in Spanish and then translated to English by the author.  Text commentary on this page is by LG Editor Iron. Your browser has shrunk the images to conform to the horizontal size limit for LG articles.  For better picture quality, click on each cartoon to see it full size.              One creative translation here.  ""Ecol brand"" is really whiskey and Fanta. The Spanish phrase ""con naranjita"" means ""with a little orange"", but in practice it means ""mixed with Fanta"".  Fanta is a carbonated orange drink.  ""A favorite in Europe since the 1940s, Fanta was acquired by the Coca-Cola Company in 1960,"" says the Coca-Cola web site.  (I would link to it but it's a brower-crashing site.)  Whiskey and Fanta is popular in Spain, so I'm told. Since neither the words nor the concept translate to English very well, the author changed it to ""Ecol brand"", haha.                                That last browser is Opera.  He's being a Valkyrie from Wagner's   The Ring .  Webster's defines  valkyrie  as ""any of the maidens of Odin who choose the heroes to be slain in battle and conduct them to Valhalla"".       All Ecol cartoons are at  tira.escomposlinux.org  (Spanish) and  comic.escomposlinux.org  (English).    Regarding the two main characters, Bilo and Nano, Javier writes, ""Bilo and  Nano are two students who share a flat.  Although their personalities are  completely different, they get along good enough.  Bilo tries to keep a calm perspective on life, but Nano is pure concentrated bad milk.  I don't know much more about them.""  (Spanish version:   http://bilo.homeip.net/ceferino/bilo-nano/bn_index.html ).    Javier says the Ecol (the comic strip) started as a joke, ""but people liked it and now we have 1000 visits daily and 10 mirrors"".  Ecol (the organization) -- or  escomposlinux.org  as it is officially known -- is an all-volunteer organization run on Linux boxen.  The staff pay its DSL fee out of their own pocket.  Javier is preparing an article for next month about Ecol the organization.     These cartoons are copyright Javier Malonda.  They may be copied, linked or distributed by any means.  However, you may not distribute modifications.  If  you link to a cartoon, please  notify  Javier.                     Copyright © 2002, Javier Malonda. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                   ... making Linux just a little more fun!         Modern Linux Distributions and Hardware-Challenged PCs     By  Richard Johnson                  Introduction    Linux possesses a much-vaunted ability to run on just about any machine you care to throw at it. Well, I've not tried running my washing machine on it yet but I suspect that one day that time will come. In an effort to open up the joys of Linux to a wider audience, the trend in recent Linux distributions has been to wrap up the installation process with a nice user-friendly GUI. SuSE Linux is a case in point. Their installation is run through the YaST installer which sports an attractive interface and makes installing a complex operating system like Linux an almost pleasant experience. There is one drawback however - these graphical installers tend to need a certain amount of, for want of a better word, oomph in your computer. SuSE suggest, for example, that the YaST installer requires a  minimum  of 64MB RAM on your machine.    Once the operating system is actually installed, however, Linux is capable of running on machines that do not meet this more demanding spec. You can tailor and tweak an installation such that you will be able to get some use out of that old 486 you might have stuck in the attic, gathering dust. It could be used as a spare machine, a router, even a small web server.     Nonetheless, if you try and install a recent distribution of Linux on such a machine you may well find that the attractive and user-friendly installer simply refuses to run.    Recently I myself had occasion to install a modern Linux distro on a reasonably old machine. I had to surmount a few problems in the course of this so I've written up my experiences - in this document - in the hope that it may prove of use to others out there who also wish to put older, otherwise redundant, machines to good use.    A need for an Intranet    For a variety of reasons it had become clear to me that the small company for whom I work needed an intranet site available on our local area network. Nothing too complex was required, just a simple site on which to host various company documents and other information; making them readily available to everyone on the network.    I also realised that this would provide me with a perfect excuse to bring Linux into our otherwise Microsoft-only network.    In the retail business margins are always tight and we simply could not justify the cost of a new powerful machine such as would be required to run, for example, Microsoft's IIS. We did, however, have a spare PC that was currently unused. This PC was an older model which was unable to run our relatively new accounting system and so had found itself replaced and relegated to a corner of my office. I duly designated this PC as our future intranet server.    The spec of this box was relatively low by modern standards - in fact the operating system installed on it was MS-DOS 6.22 with Windows for Workgroups 3.11! The PC had a 200MHz Pentium MMX processor, 16MB of RAM and a relatively generous 2GB of hard disk space. I felt this was ample for the somewhat limited demands that our intranet would place on the box - at least to begin with. I knew that I would probably need to increase the amount of RAM in the box; but RAM is cheap and it would be easy to upgrade once I'd installed Linux, if need be. I decided to crack on with my installation.    The distribution    I needed only a relatively minimal Linux installation as the box would operate purely as a web server on the local network - installation of an X server was not required. The distribution that I decided to install was SuSE Linux 8. This was because it is the Linux distro that I use on my own PC at home and I'm familiar and comfortable with SuSE's way of doing things. I've tried a few different distros in my time and have pretty much settled on SuSE as my favourite. It was with a certain amount of relish that I set about installing a new operating system from my own set of CD's without having to worry about any visits from the licensing gestapo.    The installation    I booted up the PC and hit the F2 key to get into the BIOS. A quick check revealed that I could instruct the PC to boot from the cd-rom drive first so I duly set it to behave like this. I inserted disk 1 from my set of SuSE Linux disks and rebooted the PC with the new bios settings. After successfully booting from the CD I chose to do a 'standard installation' from the SuSE menu that appeared.    The SuSE Linux installation process begins by loading a copy of Linux into your system memory, making use of a ramdisk to provide an initial filesystem rather than using the hard disk. Or at least - it tries to. The system appeared to lock up when it tried to uncompress the ram disk into memory. After waiting a while, mindful of the low spec of the system, just to check that I wasn't simply being impatient, I hit ctrl-alt-del and the system shut itself down gracefully.    I tried again - booting the computer once more from the cd-rom, however this time I tried SuSE's 'safe installation'. Unfortunately the same problem manifested itself just as before.     I suspected that the problem was being caused by the limited physical memory on my box. A quick root around on SuSE's website revealed that the minimum memory suggested for running their setup program, as I mentioned earlier, is 64MB; which is rather more than the 16MB my poor box was blessed with.    Not being one to give up without a fight I booted once more from the cd-rom and hit the F2 key at the initial SuSE screen to start up the text based installation - on the hope that this would require less memory than the fancy framebuffer GUI-based installation that SuSE normally provides. It worked! The initial copy of Linux, ramdisk and all, successfully loaded into the system memory and the text-based YaST installation began. I was asked couple of questions regarding such matters as my preferred language and then...a message popped up telling me that I did not have sufficient memory to run YaST. The installation had halted once more.    At this stage YaST actually gave me the option of activating a swap partition to provide some virtual memory in lieu of physical memory. Unfortunately I didn't have a swap partition on this box - just one huge 2GB FAT16 DOS partition. It did, however, point up a possible solution to my problem. I realised that if I manually repartitioned my disk before actually running the YaST - providing myself with a genuine Linux swap partition - then I might actually be able to get somewhere.    The Partitioning    Not having access to any sophisticated partioning software, I decided to obtain a Linux boot disk with the Linux version of FDISK - so that I could roll my own partitions.    To this end I downloaded the truly wonderful Tom's Root Boot Disk. This provides a DOS executable that will format an ordinary 1.44MB floppy disk with a complete bootable Linux system; including a small filesystem and all the handy utilities you could need. It even includes FDISK. Tom's Root Boot Disk can be downloaded from  http://www.toms.net/rb/  and I cannot recommend it highly enough.    The DOS executable provided by Tom will not run in a command prompt on Windows 2000 - the OS on my usual desktop PC at work. Instead it requires an actual DOS operating system, so I copied the downloaded zip file onto the box that I was trying to install Linux onto - if you recall, it had MS-DOS 6.22 installed on it - and unzipped it. Rebooting a Win95/98 PC in MS-DOS mode would also provide you with a suitable environment. I stuck a floppy in the appropriate drive and let Tom's program create my boot disk for me. A painless procedure. Finally I re-booted the computer using my newly created Linux boot disk.     After pausing to marvel for a moment at how darned clever Tom's Root Boot Disk is, I got to work. I should mention at this point that FDISK misbehaved the first time I tried it. I thought I'd zapped the original DOS partition and created for myself a sparkling new Linux swap partition but it turned out that FDISK had misreported the number of heads, cylinders and sectors on my disk. Thus, when it wrote the new partition table it made a right pig's ear of it. I didn't realise this until YaST started throwing up bizarre errors about my disk. I rebooted with Tom's root boot and tried again. The second time around FDISK behaved itself and all was well. Though - left somewhat paranoid by FDISK's behaviour - to make sure that it was now correctly detecting the details of my hard disk I actually took the PC apart so that I could check the label on the disk itself!    FDISK is often cited as being a scary bit of software to use, but I've always found it to be quite straightforward myself. To launch FDISK you type:   #> fdisk /dev/hda    Assuming, of course, that the hard disk to be partitioned is the first IDE disk. You have to tell FDISK which device you want to partition, in this case /dev/hda. If you have any doubts about FDISK's syntax you can check out the man page - yes, Tom's root boot disk even provides man pages for your edification and delight!    Once you've started up FDISK you control its behaviour with single letter commands. Type 'm' (without the quotes) for a list of the available commands. 'p' prints out the current partition details on screen for reference.     First you need to delete the existing partition by typing 'd' and specifying, when prompted, which partition number you wish to delete. The partition numbers are revealed when you  p rint the partition details on screen. Bear in mind that FDISK doesn't actually make any changes to your disk until you use the 'w' command to  w rite your changes. If you screw up you can just type 'q' to  q uit without saving your changes.  Once you have written them, however, there is no going back so be careful. New partitions are added to the disk with the 'n' command. New partitions will be normal Linux partitions by default so you'll need to use the 't' command to change the new partition's  t ype to Linux swap. You need to know the hex code for swap partitions when you change the partition type and you can get this by using the 'l' command to  l ist all the different partition types supported by FDSIK. Linux swap is type 82.    In my case I created two separate primary partitions on the disk. The first was a Linux swap partition; 128MB in size. The second partition was a standard Linux partition taking up the rest of the disk. I then formatted my partitions. For the swap partition I used the following command:   #> mkswap -c /dev/hda1    This sets up a Linux swap area on partition 1 of device hda. The -c flag tells mkswap to check the partition for bad blocks. The second Linux partition I formatted as a Linux Second Extended Filesystem with the command:    #> mke2fs -c /dev/hda2    The syntax, as you can see, is rather similar to the mkswap command.    The installation - slight return    Once I'd created my partitions I booted once more from the SuSE Linux CD - again pressing F2 to opt for the text based installation. This time, when asked if I wanted to activate a swap partition, I could specify the partition that I had just created which was located at /dev/hda1. YaST then proceeded without a hitch - if a little slowly.    From this point onwards the installation was relatively straightforward. SuSE's YaST is a very good setup tool striking just the right balance between sophistication and user-friendlyness, IMHO. The only problem that I needed to watch out for was with YaST's own disk partitioner. This recognised my existing partitions and suggested reformatting the second partition with the ReiserFS journalling filesystem - which I was more than happy to do - however, it also suggested reformatting the swap partition as well. I thought it best not to let it do this as I suspected it might cause problems if I tried to format a swap partition that was in active use...    Conclusion    YaST is good but memory hungry and it certainly made extensive use of the swap partition that I'd created. Once Linux was installed and running I was able to tune my installation to ensure that only the necessary services were running and it ran tolerably well with just the 16MB of RAM. Notwithstanding a lot of activity on the swap partition of course.     In the end I did install more memory in my box. This made the system more responsive and better able to cope with the demands placed upon it by multiple users over the network. Yet I was nonetheless impressed by how well Linux - which is a powerful modern operating system after all - ran on a system with such limited resources.                Copyright © 2002, Richard Johnson. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                   ... making Linux just a little more fun!         Handicapped People of the World, Unite!     By  Janine M Lodato                   This article explores Linux's potential role in assistive technology (AT).  AT allows those living with multiple schlerosis, other handicaps or the affects of aging to take greater control in maintaining their health and living independently.     Introduction     Some of the most criminal and immoral aspects of the monopolistic practices of Microsoft, which for all practical purposes eliminated or curtailed competition, is the fact that PCs today are     much too expensive.   insanely unreliable.   maddeningly complex.      These negative attributes of the Windows world makes the PCs of today useless for the truly needy:     the aging population.   the physically disabled.   the learning disabled.   and the professionals working with all the above.   The sum of these people account for more than half  the population of the world. They are in need of a  collaborative assistive technology (AT) system which  operates with telephone-style simplicity. An end-to-end  AT-based collaborative system connected via the Web will allow the professionals to provide support group-style assistance in the form of a simple virtual community.    Now that Linux is available, it is feasible to approach  this very large market using a low-cost, rugged and simple client system. Linux-based client systems connected to Linux servers are perfect for such end-to-end AT systems offering. The reliable and simple features of Linux coupled with low cost Linux based hardware and platforms and applications are the only solution for these  end users who need AT capabilities.   The work to be done     A very significant upgrade of self-supported health  improvement can be achieved using assistive  technologies (AT) connected via the Web. Recent scientific studies by major universities  in the field of behavioral medicine including  psychoneuroimmunology (PNI) indicate that getting  involved with collaborative group activities  has significant rehabilitation potential. In fact behavioral medicine can prevent disease, and improve quality of life and rehabilitate.  Of course it does not replace the pharmaceuticals,  but it does improve their effectiveness.    It is suggested that the collaborative virtual community systems, based on Web-connected AT clients and servers,  supporting the disabled and the aging can also be used for the able-bodied eyes-busy, hands-busy professionals to  improve their productivity. Also learning-disabled children can make very good use of AT. This low cost set of AT platforms and associated Web connectivity could be  very useful in many government and commercial employment  arenas. This dual-use type approach will significantly lower  the cost of the needed technologies for all groups.     Of course there is still work to be done. Applications for AT technologies  must be developed or perfected to allow collaboration between the health  service professionals  or social worker professionals and the many people in need.  Web connected AT oriented software components running on Linux client  machines connected to Linux servers have to be created such as     simple and application specific user interface.   voice based interaction via computer/telephone.   always-on and always-available systems.   a collaborative virtual community systems.      Through such systems the professionals can monitor,  mentor and moderate and even medicate the members  of the collaborative community. For a good example:  when dealing with students with learning disabilities, it is  important to get their attention, to bolster their behavior  and finally to improve their cognitive productivity.  With  assistive technology people can prevent further destruction  of their faculties, improve their quality of life and can even be  rehabilitated somewhat.  Just the idea of being productive  adds to a person's self-esteem enormously.     A personal example     I have many years of personal experience using AT and found  it very helpful in SPMS (secondary progressive multiple sclerosis) conditions as described below in a brief review of my personal experiences.      In addition to my extensive experience with AT I also have related graduate credentials from both California State  Univ at Northridge  (the center for AT corporate interactions)  as well as CSU in Sacramento and UOP in Stockton.               In spite of my handicap, I find it gratifying and fulfilling to  concentrate my efforts on projects worthwhile to a very deserving community.   Involvement such as this has proved to have healing powers for me.  I am  living proof of the powers of PNI based on personal involvement.            Having relied on AT in order to survive my wheelchair imprisonment,  specifically voice recognition for writing, I see dual value: one for the  hands-busy, eyes-busy professionals increasing their productivity through  ease of use, and the other, of course, for use by the physically disabled.     Being disabled with MS, I use IBM ViaVoice on a MAC to write. It allows  me to verbally communicate by email with my friends as well as giving me the  opportunity to express myself and get involved with worthwhile projects in  the AT arena.     Typically voice recognition systems spell very well but now and then  some of them do make typos which really take the cake:        emerge -> eat March   inevitable -> in edit a bowl   Nazi -> not see   multiple schlerosis -> multiple skull roses   idiosyncracies -> HBO sink receives   A loud sneeze from my husband nearby inspires the computer to type  ""aha"".               I receive enduring fulfillment from developing my intellectual strengths  and putting them to positive use. I learn from my negative experiences which  have been many in my 54 years of existence and I savor my positive  experiences  to learn optimism.     The best way to use these intellectual strengths is to get involved with  collaborative teamwork and personal communications within the disabled  community and with companies who provide assistive technologies for this  community.              It is important for me to maintain what little health I have and  to become involved in something I hold great faith in.  So I have decided to  become involved in the latest AT systems available to people with  disabilities.  I am especially interested in technologies that help the  disabled express themselves, such as voice recognition for writing and  voice-activated telephone service for talking.     There are many AT type technologies that focus on, and make good use of  the physical abilities a disabled person may still have such as voice, lip  movement, eye motion and brain waves. These capabilities can be used with  brain-actuated computer systems and voice recognition software, to name a  few.  Integrating these already-existing technologies into something usable  by disabled clients so they can express themselves will offer them freedom in  spite of their handicap.         Understanding that there are companies already seeking to address this  market makes my involvement in the area that much easier and completely  natural.  Finding companies geared toward brain-actuated computer control  systems is my next assignment.       As a handicapped woman who still has control of her mental faculties and  voice, I have something to offer by connecting the right people so that I can  integrate systems through the Internet to develop a mutually beneficial  virtual community.          Conclusion      Personal communications and collaborative teamwork need assistive  technologies to further the self-esteem of the disabled.  Linux, due to its low cost, open architecture and international development, provides an ideal platform for building these technologies.  Those living with handicaps (and their relatives and friends) can make a unique contribution to this effort because they know firsthand what benefits AT can provide.     Involvement in AT projects can help disabled people in another way too. Not only does it provide a distraction from their problems, but it's also a constructive way to spend their time while furthering a cause they believe in.       The positive rehabilitative effects of Behavioral Medicine is my method  of surviving and thriving until a final cure for MS is developed.     [LG would like to see additional articles and Mailbag letters  about Linux's applicability in assistive technology.  If you have any  ideas, let us know.  -Ed.]             Copyright © 2002, Janine M Lodato. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                   ... making Linux just a little more fun!         So You Wanna Create Your Own x86 Operating System?     By  Patrick Mahoney                  1. Introduction   One of the great difficulties a hobbyist programmer faces when trying to start the development of his own OS is finding out where to start. Many books describe in-depth theoretical OS concepts, yet noone seems to take a hobyist programmer by the hand and bring him face to face with these concepts. This is precisely what this article aims at doing.   Several articles related to this topic appeared in the last few issues of the Linux Gazette. I plan to approach it in a much less programming oriented manner, only presenting to the reader the tools and tips he will need to begin the development of his own OS. Once done with this article, the interested reader should be all set to start browsing the resources available to him and start designing and coding.   You might not be aware of it, but operating system development doesn't start at the beginning. (!!)  Writing a solid bootloader is a whole project in itself, and I would not advise one to begin an OS development project by writing a bootloader. Many reliable ones are available for free (Grub, lilo, ppcboot, etc...). If you plan on writing your own, I suggest you delay this task to a later stage of the project. In this article, I will be using GNU Grub, the Grand Unified Bootloader.   2. Description of the development environment   To ease the pain that OS development will bring to you, you will need to set up an adapted development environment which meets a certain number of requirements:      You should get to rapidly test your newly compiled kernel  You should never have to reboot your development machine  You should not need to use floppies as a storage medium for your OS     This article will present one of many possible environments which meets these requirements. It will consist of a development machine and a testbed machine that both lie on a common network.   2.1 The development machine   Obviously, this machine will need to be equipped with a good set of programming tools: assembly and C compilers, a linker and a 'make' utility are musts.   A tool I found more useful than I initially thought it would be is an emulator. Such a tool will help debug your kernel and will allow you to rapidly test your newly added line of code. Don't be fooled, though. An emulator never replaces a good ol' testbed machine.    Next, you need a TFTP server. This tool will allow your testbed machine's tftp enabled bootloader to acquire  a kernel from the development machine via the network connection.   2.2 The testbed machine   All this machine needs is a network card and a TFTP enabled bootloader that supports it.   3. Setup of the development environment    3.1 The development machine   The chosen programming tools are:    gcc 2.95.4  ld 2.13.90.0.10     Bochs version 1.4.1 is the chosen x86 emulator. Special care should be taken to compile it with debugger mode enabled. These commands should do the job:   $ ./configure --enable-x86-debugger  $ make   In order to properly use Bochs, you need to create a disk image. This image needs to have both a bootloader and a filesystem. This can be done using the  mkbimage  script. If you're too lazy to do it yourself, grab  this  gzipped 10MB disk image and add   diskc: file=c.img, cyl=24, heads=16, spt=63   to your .bochrc file.   As for the TFTP server, I chose to use atftpd. It's an easy to use linux-based TFTP server implementation.   3.2 The testbed machine   The chosen bootloader is GNU Grub version 0.92. Special care should be taken to enable Grub's tftp client to talk to your network card. My testbed machine has a cheap NE2000 ISA clone. Following carefully the netboot/README.netboot instructions, I used these commands:   $ ./configure --enable-ne --enable-ne-scan=0x220  $ make   Note that a PnP PCI card would be easier to configure. Now, you can either install the Grub images on the testbed machine's MBR or on a floppy which your testbed machine will boot from. I prefer the latter, since my testbed machine is also used for other purposes, and therefore, I'd rather not play with its HD.   $ cat ./stage1/stage1 ./stage2/stage2 > /dev/fd0   Now just insert your floppy in your testbed machine to see if your network card gets recognized. You can either configure it by hand or use a dhcp server, if any.   grub> dhcp  Probing... [NE*000]  NE2000 base 0x220, addr 00:C0:A8:4E:5A:76  Address: 192.168.22.14  Netmask: 255.255.255.0  Server: 192.168.22.1  Gateway: 192.168.22.1   Note that you won't have to configure these parameters by hand each time you boot. See the GNU Grub documentation and the 'grub-install' script for details.   That's it! You're all set to test your setup!    4. Testing your development environment setup...   As I mentioned earlier, I will leave the core OS programming stuff to the experts out there. So in order to test your setup, we will use the example kernel from the GNU Grub sources located in the /docs directory.    The kernel is built from three source files: boot.S, kernel.c and multiboot.h. You can build the kernel by doing:   $ gcc -I. -c ./boot.S  $ gcc -I. -c ./kernel.c  $ ld ./kernel.o ./boot.o -o kernel -Ttext 100000   Here's a quick and incomplete explanation. Multiboot is a standard that defines a way for the bootloader to pass information to the kernel it tries to load. boot.S accepts this information, sets up a stack, and calls 'cmain'. This function sets up the vga display, reads the information passed to him, prints some stuff and leaves. Then, boot.S gets the control back, prints the string 'Halted.', and enters an infinite loop. Pretty simple stuff, right? The reader is invited to dig into the code to get more details.   4.1 ...with Bochs   The plan is to mount your disk image via a loopback device, copy your kernel on the filsystem of the image, unmount it, and fire off Bochs. Of course, you have to add an offset to the start of the filesystem. But you knew that, right?   # /sbin/losetup -o 32256 /dev/loop1 ./c.img  # /bin/mount -t ext2 /dev/loop1 /mnt/osdev/  # cp  /docs/kernel /mnt/osdev  # umount /mnt/osdev/  # /sbin/losetup /dev/loop1 -d  $ bochs   Of course, that can be automated by your Makefile. Once in Grub, simply do:    grub> kernel (hd0,0)/kernel  grub> boot        (Click the image for the full size.)     4.2 ...with your testbed machine   First, setup your TFTP server so that the client can retrieve your kernel:    # /usr/sbin/atftpd --daemon /home/bono/src/grub-0.92/docs   Fire off your testbed machine. Configure your network connection as shown above. Next, specify your devel machine's ip address as the TFTP server address and the location of the kernel image. Note that this option can be set by the dhcp server. Finally, start the boot process.    (...)   grub> tftpserver 192.168.22.36  Address: 192.168.22.14  Netmask: 255.255.255.0  Server: 192.168.22.36  Gateway: 192.168.22.1   grub> kernel (nd)/kernel  [Multiboot-elf, <0x100000:0x807:0x0>, <0x101808:0x0:0x4018>,  shtab=0x106190, entry=0x100568]   grub> boot    A screen similar to that of Bochs should appear on your testbed machine's display.   5. Where to go from here   Well you're pretty much set to start the development of your OS. Lots of good documentation resides on the web. Browse, post, ask, think. Monolithic or micro kernel? Segmentation or paging?   If your debugging needs come to outgrow both the emulator and your kernel's printk's, one setup you could add to your OS is a serial debugger. This can range from some bytes thrown on the serial port, to a gdb-compatible remote-debugging extension. This information could be retrieved and processed by your development machine through a null-modem serial cable. It's a handy common practice in OS development.     6. Resources      Tanenbaum' os dev book   The bible of operating system development   alt.os.development   There, you'll find the solution to many of your problems!   Freenode IRC's #osdev (irc.debian.org)    Friendly folks who never go to bed!   A few osdev tutorials  including Tim Robinson's.   Tim's been there!   The Operating System Resource Center    BosoKernel    Nicely done x86 beginner's tutorial. (French)      Intel Architecture Software Developer's Manual Volume 3: System Programming   Don't leave home without it.      7. Thanks   Many thanks to all those who have accepted to patiently answer my never-ending questions on #osdev: pavloskii, geist, oink, byrdkernel, air.             Copyright © 2002, Patrick Mahoney. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                   ... making Linux just a little more fun!         Viewing Faxes on the Web     By  Mark Nielsen                      Introduction   Setting up Apache 2.0   Suggestions for you   Conclusion   References        Introduction  The purpose of this article is to describe a simple Perl script I use to manage faxes on my fax server over the web. The method I use is very crude and is only used by myself and one other person in the company  I work for,  but it works for me. With very little effort, it would be very easy to  setup professional scripts to handle faxes from small to very large corporations. I also believe it would be very easy to setup a web interface for other fax systems (if they don't already have it). Personally, I would much rather send and receive faxes over a webpage because then I can access the system (and the faxes) from anywhere in the world.    For my setup, I was using efax, which is not that easy to get along with. For any sane person, I recommend  HylaFax  or some other alternative (mgetty has some hope).    Please read my other efax article at  Linux Focus .      Configuring Apache 2.0  First, look at how I   compiled  and then    configured  Apache 2.0. This is just one installation I did, out of many.  No, Php is not running on my webserver even though the config file says I am.   I have a directory, /usr/local/apache2/htdocs/fax, where I put in my Perl script and .htaccess files.    Underneath this directory, I have these directories:    home -- my faxes go here   ab -- where other Audioboomerang faxes go.   source -- where we have the original faxes at.   display -- the list of faxes yet to be viewed/archived.   archives -- where the ps and pdf files are archived.     I put a .htaccess in these directories to limit access by people. An example .htaccess is  AuthName Test AuthType Basic AuthUserFile /usr/local/apache2/passwords/Passwords  order deny,allow require user mark ted     You can change/add passwords with htpasswd.    Next, the last thing is to create a perl script.  Here is my very crude Perl script. If I ever do anything else with it,  I will convert it to a Python script first as Python is the next wave for programming (I hope). Python, Zope, Apache, Linux, and PostgreSQL  are the top choices for my programming environment. Save it as ""fax.pl"" and perform a ""chmod 755 fax.pl"" after saving it.    You can  download  it or just view it below.  #!/usr/bin/perl  use CGI;  print ""Content-type: text/html\n\n\n"";  my $Home = ""/usr/local/apache2/htdocs/fax""; my $Source = ""$Home/source""; my $Archives = ""$Home/archives""; my $AB_Archives = ""$Home/ab""; my $Display = ""$Home/display""; my $Home_Archives = ""$Home/home"";  `mkdir -p $Source`; `mkdir -p $Archives`; `mkdir -p $Display`; `rsync -av /var/spool/fax/incoming/fax* $Source`; `mkdir -p $AB_Archives`;  #------------------------------------ my @Files = <$Source/fax*>; foreach my $File (@Files)    { #  print ""$File\n"";   my (@Temp) = split(/\//, $File);   my $File_Name = pop @Temp;   if (!(-e ""$Archives/$File_Name\.pdf""))     {     print ""<br>Processing new fax: $File\n"";     my $Command = ""tiff2ps $File > $Archives/$File_Name\.ps""; #    print ""$Command\n"";      `$Command`;     my $Command = ""/usr/bin/ps2pdf $Archives/$File_Name\.ps $Archives/$File_Name\.pdf""; #    print ""$Command\n"";     `$Command`;     `cp $Archives/$File_Name\.pdf $Display/$File_Name\.pdf`;      }   }  #--------------------------------------- my $query = new CGI; my $Action = $query->param('action'); my $File = $query->param('file'); $File =~ s/[^a-zA-Z0-9\_\.]//g;  if (!(-e ""$Display/$File"")) {} elsif ($Action eq ""archive"")    {   print ""<br>Archiving $File\n"";   `rm -f $Display/$File`;   } elsif ($Action eq ""archive2"")   {   print ""<br>Archiving $File\n"";   `cp $Display/$File $AB_Archives/`;   `rm -f $Display/$File`;   } elsif ($Action eq ""archive_home"")   {   print ""<br>Archiving $File\n"";   `cp $Display/$File $Home_Archives/`;   `rm -f $Display/$File`;   }   print qq(<hr><a href=""archives/"">Archives</a> -- might be password protected. <br><a href=""home/"">Home Archives</a> -- might be password protected. <br><a href=""ab/"">Audioboomerang Archives</a>\n);  my $Table_Entries = """"; my @Files = <$Display/fax*>; foreach my $File (sort @Files)   {   my (@Temp) = split(/\//, $File);   my $File_Name = pop @Temp;   my $Link = ""<a href='display/$File_Name'>$File_Name</a>"";   my $Delete = ""<a href='fax.pl?action=archive&file=$File_Name'>archive file</a>"";   my $AB =""<a href='fax.pl?action=archive2&file=$File_Name'>archive to AB</a>"";   my $Home =""<a href='fax.pl?action=archive_home&file=$File_Name'>archive for Home</a>"";    $Table_Entries .= qq(<tr><td>$Link</td><td>$Delete</td><td>$Home</td><td>$AB</td></tr>\n);   }  print ""<table border=1><tr><th>View Fax</th><th>Archive the Fax</th> <th>Archive to AudioBoomerang</th></tr>\n""; print $Table_Entries; print ""</table>\n"";  if (@Files < 1) {print ""<h1> No faxes or they are all archived.</h1>\n"";}             Suggestions for you.      I normally write in Python 2.2 these days, as this should be rewritten in. I just happened to use Perl because I was testing mod_perl and  Apache 2.0.    Write a Python script to let people upload PostScript, images, or other file formats that Linux can convert to tiff to send out as faxes. In addition, the Python script should receive the telephone number, cover letter, etc. to make the system flexible.    Create a Python/TK or  wxPython  script which acts as a client program to send and recieve faxes from your  Apache 2.0 server. The trick here is that people might have to create a postscript file first to upload faxes or better yet, figure out some way to directly print to the Python Script.    When you have a multiple page fax, have the Perl/Python  script on the webserver detect and order the pages and merge them into one ps file with psmerge or other tool.    Faxes can be pretty sensitive so use the secure service in Apache 2.0 for viewing or sending your faxes.        Conclusion  I think it is pretty cool, and my boss thinks it is pretty cool.  I am going to switch to a different fax service because efax is hard to deal  with when sending faxes. My next goal is to make it so I can send faxes through a webpage. I will have to set it up so that you first print your document to a postscript file and then upload it (or upload a graphic image or something else that Linux can convert usign a standard tool).    I am not sure what other fax setups utilize the web, but from my perspective, I always want to have access to my faxes over the web or to send a fax over the web.      References       If this article changes, it will be available here   http://www.tcu-inc.com/Articles/31/nielsen.html                Copyright © 2002, Mark Nielsen. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                   ... making Linux just a little more fun!         Perl One-Liner of the Month: The Case of the Duplicate UIDs     By  Ben Okopnik                Chapter 1    The e-mail was short, succinct, and got right to the point.  Woomert - I'll be short, succinct, and get right to the point. Three-company merger. Nervous sysadmin. 3000+ users. /etc/passwd. UIDs. Regards, Frink Ooblick    Woomert Foonly, the Hard-Nosed Computer Detective, chuckled to himself. The client had been rather loud and incoherent on the phone, with ""It doesn't work!"" and ""I need help!"" being the chief features of his conversation. Woomert had sent Frink to the site to reconnoiter, and the above was the highly satisfactory result. All that remained was to come up with the solution; given that only a few short hours remained before the client shut down for the day, Woomert decided to use his time productively. Let's see - where was his favorite pillow?...   Chapter 2    Refreshed and ready, Woomert appeared at the site, and immediately encountered a rather excited Frink.   - ""Woomert, it's terrible! The file is far too long to search manually, and the UIDs are all over the map. The sysadmin is contrite, frantic, and panicked by turns, and his hair is almost all gone. What can we do?""   - ""No worries, mate... oh, sorry. I was just in Canberra a few hours ago, and some of the influence is still with me. I can tell you from horrible experience that tomorrow will be even worse: I've got to be in Dallas in the morning, New York in the afternoon, and Tel Aviv in the evening. I would advise you to wear earplugs, or absent yourself from my environs until the accents fade. Ah, the perils of travel...""  Frink was becoming visibly upset.   - ""Woomert - you're not taking this seriously. Can't you see that this is a major problem?""   - ""Oh, this? Relax, take it easy. It's not nearly as bad as it looks, Frink; in fact...""  Woomert deftly extracted his favorite typing gloves from his pocket and slipped them on.   - ""...Perl makes it rather trivial. What we'll do is give the sysadmin a couple of command-line tools that he can use to resolve this problem, and - since he's using 'bash' - he'll be able to pull them up with the 'up-arrow' key as he needs them. Here we go!""  perl -F: -walne'$h{$F[2]}.=""$F[0] "";END{$h{$_}=~/ ./&&print""$_: $h{$_}""for keys%h}' /etc/passwd   A list of duplicate UIDs, along with their related usernames scrolled down the screen after Woomert pressed the ""Enter"" key. Both Woomert and Frink noted with interest that there was a  triple  entry for UID0 -  0: root sashroot kill3r    - ""Well, well. Looks like somebody managed to break in and give themselves a UID0 (root) account. 'sashroot' is OK - that's the 'standalone shell' for those rough repair jobs - but 'kill3r'? Well, we'll let the client know; meanwhile, on with the current problem. The sysadmin will now have a list of all the duplicates - there don't seem to be all that many - but searching for the next available UID could be a pain. So, here's a second tool -""  perl -wle'{getpwuid++$n&&redo;print$n}'    - ""That should give him a good start on getting it all straightened out. As for us - we're homeward bound!""   Chapter 3    When they had returned to Woomert's house and were seated in front of the fireplace - the night had been a cold one, and the wind whistled outside the window - Frink looked expectantly at Woomert. Noting the look, Woomert laughed.   - ""I know, I know. I should explain, shouldn't I? The air of mystery is a sharp, pleasant thing, but it is as nothing compared to the pleasure of learning. Here, let's start with the first one:  perl -F: -walne'$h{$F[2]}.=""$F[0] "";END{$h{$_}=~/ ./&&print""$_: $h{$_}""for keys%h}' /etc/passwd   ""First, take a look at the command-line switches I used:""   -w Enable warnings -a Autosplit (see ""-F"") -l Enable line-end processing -n Implicit non-printing loop -e Execute the following commands -F:    Use ':' as the separator for the '-a' autosplit   ""If you remember our  last adventure , all of the above except '-a' and '-F' are already familiar to you. Autosplitting splits the lines read in by '-n' or '-p', using whitespace as a default separator and saving the result in the '@F' array. '-F' optionally redefines the separator by which to split.""  ""Since we're reading in '/etc/passwd', let's look at the format of the individual lines in it:""  borg:x:1026:127:All your base are belong to us!:/home/borg:/bin/bash  ""There are seven standard fields, laid out as 'name - passwd - UID - GID - GECOS - dir - shell'. The only things we're interested in for the moment are name and UID; what I'm going to do is build a hash - a very important data structure in Perl, one of the three basic ones - that contains the UID (3rd field) as the  key , and the name (1st field), followed by a space, as the  value , for all the entries in '/etc/passwd':  $h{$F[2]}.=""$F[0] ""  Since usernames can't have spaces in them, it makes a convenient separator. Once that's done, I'll loop over the hash and print out any value which contains a space followed by any character:""     $h{$_}=~/ ./&&print""$_: $h{$_}""for keys%h}  ""I see you still look puzzled. Here, let me write out the above in a more readable form:""  for ( keys %h ){                # Loop over the ""%h"" hash       if ( $h{$_} =~ / ./ ){      # Does the value contain a space followed by anything?           print ""$_: $h{$_}\n"";   # If so, print the UID, a colon, a space, and the value       }   }   ""If you think about it, you'll see that the only thing that will match the above regex is a value with more than one name in it - meaning a duplicate UID.""   - ""All right - now I can see how you got the results. What about the second expression, the 'next available UID' tool?""   - ""Ah, you mean this one:""    perl -wle'{getpwuid++$n&&redo;print$n}'       ""It's nothing but a short loop in which I check if the UID specified by '$n' exists. If that test succeeds - meaning that there  is  a UID equal to '$n' in use - 'redo' gets invoked, '$n' is incremented, and the test happens again. If it fails, however, '$n' is printed to STDOUT and the program exits. Useful, and not too complicated. Just a bit of work, and they should have it all done. The security breach is something else, but at least now they know about it...""            Copyright © 2002, Ben Okopnik. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                   ... making Linux just a little more fun!         The Foolish Things We Do With Our Computers     By  Mike (""Iron"") Orr                           Washing flooded chips   By  Philippe Rousselot     Here's what happened to me a few years ago when computers were not so cheap  and a group of 5 very old machines were worth saving from a flood.    I was working in a Laboratory at the time. We had a room with 2 big  microscopes and 5 old Macs used for image analysis. The room ended up flooded during the night after an autoclave (kind of  big pressure cooker that biologically-inclined geeks use to sterilize  things) broke down. Although the microscopes were safe, the table with the Macs got hit. All the machine ended up covered with a muddy rusty water.    The next morning, I decided to bring the Macs to the lab to dismantle  them. By chance the drives and power supply were dry but the motherboards  were in really bad shape.    I washed all the cards in distilled water and then in alcohol. I then put them in an oven at 40 degrees Celsius for a day.    Everyone was smiling at me until I rebuilt the Mac and got them running again.  At the time, I did not know that it was the way electronic boards were washed in fact, and I was not really sure of the result before it came.    In the meantime, the machines got reimbursed by the insurance that did  not consider worth getting the old one back, so we doubled our investment  in the computers.         A foolish HDD fail   By  Onur Yalazý     Once upon a time (maybe 4-5 years ago), I had a 80286 case for  old timess sake. But its floppy drive wasn't working. So I decided  to use my Pentium II' s floppy with it. I was trying to install a DOS  6.22 system on it think. But i wasn't able to take the floppy out of its original case. A bit  acrobaticly I put the cases in parallel and with a long cable connected  the floppy to 286.  Everything was OK.     But there was something wrong.  (Did I metioned the pentium was where my  father did his civil-engineering tasks?)  The floppy's LED was on  continuoussly. I was in a hurry and didn't think  the cable was wrongly plugged. The PC didn't boot. The system was down. It should be the doom. I got angry and started to hit the floppy drive  with a hammer. After that I got the idea of the cable. HIT! Everything  seemed to be ok then. But i got a damaged HDD. The HDD was below the  floppy.. The real doom :) But the good thing was that I had that drive backed up.    So never work without backups and hammers when working inside the case.         Computer Abuse   By  Donovan Colbert     Probably the most expensive learning experience in my history was hooking up a second drive, a used 20mb Miniscribe SCSI 3.5"" as the second in a chain to my Amiga 2000 years ago. I didn't know about SCSI termination, and back then, it was real important. I watched in dazed amazement as a single wire on the cable smoked and burnt down toward the first drive, like the black powder burning toward the weapons room in a Looney Toons featuring Bugs Bunny and Yosemite Sam as the pirate. At probably the last possible second, I broke the trance and lunged forward, groping around the back of the machine for the power switch. I got it just in time. I only lost the 20mb SCSI.    About a year later, I got a job at a used retail computer store, and found a dead miniscribe 20mb among the waste products. I removed the controller card, swapped it out with the controller on my drive, and brought life back to my drive. That evening, it was resting on the corner of a desk, and a co-worker bumped it and it fell onto the concrete floor. That was the end of that drive.     I think I paid $200 for the drive, used. Needless to say, I shortly became an expert in proper termination of SCSI chains. :)         The Monster Hard Drive   By  Josef Moffett      Years ago now (about 1989 or so) I was the grateful recipient of an old XT  that no one wanted. I hadn't had much to do with computers up until then on  the hardware side - but this one came in pieces, so it was a matter of  getting my sleeves rolled up an' putting it all together.    It was great - a complete change to the ol' Commodore 64 and plus 4 that I'd played with before. But I kept getting this wierd problem. The hard drive ( a monster and a half) -- all of twenty megabytes, and in a double-height casing (so it weighed a ton) -- was connected to the IDE controller card, which in turn was seated into the motherboard). When switching on the computer everything was fine. The old XT booted up with its old (DOS 3 I think) OS and worked fine. But whenever I tried to format or delete any of the old stuff on it it seemed fine until next reboot, when everything was still there. Wierd.    So I took it along to a computer shop with a workshop and admitted to being  completely baffled by the phenomenon. The techie took one look at the ribbon  cable connecting the hard drive to the IDE controller and unplugged it and  plugged it so that it was seated over BOTH rows of pins. I had plugged the  cable in so that one whole row of pins had been missed.    Needless to say, I was one really embarrassed teenager! Needless to say as  well that it has never happened again - some mistakes are just too stupid to  repeat!             [If you have a story about something foolish or ingenious you         did to your computer, send it to          gazette@ssc.com .  -Iron.]                                       Copyright © 2002, Mike (""Iron"") Orr. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                   ... making Linux just a little more fun!         Programming Bits: C# Data Types     By  Ariel Ortiz Ramirez                 In my   previous article , I introduced the C# programming language and explained how it works in the context of the Mono environment, an open-source implementation of Microsoft's .NET framework. I will now go on to some details on the data types supported by the C# programming language.    In the subsequent discussion I will use the following diagrammatic notation to represent variables and objects:       The variable diagram is a cubic figure that depicts three traits (name, value and type) relevant during the compilation and execution of a program. In the von Neumann architecture tradition, we will consider a variable as a chunk of memory in which we hold a value that can be read or overwritten. The object diagram is a rounded edge rectangle that denotes an object created at runtime and allocated in a garbage collectable heap. For any object in a certain point in time, we know what type (class) it is, and the current values of its instance variables.     Type Categories    In the C# programming language, types are divided in three categories:         value types     reference types      pointer types     In a variable that holds a  value type , the data itself is directly contained within the memory allotted to the variable. For example, the following code       int x = 5;      declares an 32-bit signed integer variable, called  x , initialized with a value of 5. The following figure represents the corresponding variable diagram:       Note how the value 5 is contained within the variable itself.    On the other hand, a variable that holds a  reference type  contains the address of an object stored in the heap. The following code declares a variable called  y  of type  object  which gets initialized, thanks to the  new  operator, so that it refers to a new heap allocated  object  instance ( object  is the base class of all C# types, but more of this latter).        object y = new object();      The corresponding variable/object diagram would be:       In this case, we can observe that the ""value"" part of the variable diagram contains the start of an arrow that points to the referred object. This arrow represents the address of the object inside the memory heap.     Now, let us analyze what happens when we introduce two new variables and do some copying from the original variables. Assume we have the following code:        int a = x; object b = y;       The result is displayed below:        As can be observed,  a  has a copy of the value of  x . If we modify the value of one of these variables, the other variable would remain unchanged. In the case of  y  and  b , both variables refer to the same object. If we alter the state of the object using variable  y , then the resulting changes will be observable using variable  b , and vice versa.    Aside from references into the heap, a reference type variable may also contain the special value  null , which denotes a nonexistent object. Continuing with the last example, if we have the statements        y = null; b = null;      then variables  y  and  b  no longer refer to any specific object, as shown below:       As can be seen, all references to the object instance have been lost. This object has now turned into ""garbage"" because no other live reference to it exists. As noted before, in C# the heap is garbage collected, which means that the memory occupied by these ""dead"" objects is at sometime automatically disposed and recycled by the runtime system. Other languages, such as C++ and Pascal, do not have this kind of automatic memory management scheme. Programmers for these languages must explicitly free any heap allocated memory chunks that the program no longer requires. Failing to do so gives place to memory leaks, in which certain portions of memory in a program are wasted because they haven't been signaled for reuse. Experience has shown that explicit memory de-allocation is cumbersome and error prone. This is why many modern programming languages (such as Java, Python, Scheme and Smalltalk, just to name a few) also incorporate garbage collection as part of their runtime environment.    Finally, a  pointer type  gives you similar capabilities as those found with pointers in languages like C and C++. It is important to understand that both pointers and references actually represent memory addresses, but that's where their similarities end. References are tracked by the garbage collector, pointers are not. You can perform pointer arithmetic on pointers, but not on references. Because of the unwieldy nature associated to pointers, they can only be used in C# within code marked as  unsafe . This is an advanced topic and I won't go deeper into this matter at this time.    Predefined Types    C# has a rich set of predefined data types which you can use in your programs. The following figure illustrates the hierarchy of the predefined data types found in C#:       Here is a brief summary of each of these types:              Type       Size in         Bytes       Description               bool       1       Boolean value. The only valid literals are  true        and  false .               sbyte       1       Signed byte integer.               byte       1       Unsigned byte integer.               short       2       Signed short integer.               ushort       2       Unsigned short integer.               int       4       Signed integer. Literals may be in decimal (default)       or hexadecimal notation (with an  0x  prefix).  Examples:  26 ,        0x1A               uint       4       Unsigned integer. Examples:  26U ,  0x1AU        (mandatory  U  suffix)               long       8       Signed long integer. Examples:  26L ,  0x1AL        (mandatory  L  suffix)               ulong       8       Unsigned long integer. Examples:  26UL ,  0x1AUL        (mandatory  UL  suffix)               char       2       Unicode character. Example: 'A' (contained within       single quotes)               float       4       IEEE 754 single precision floating point number.       Examples:  1.2F ,  1E10F  (mandatory  F  suffix)               double       8       IEEE 754 double precision floating point number.       Examples:  1.2 ,  1E10 ,  1D  (optional  D        suffix)               decimal       16       Numeric data type suitable for financial and monetary       calculations, exact to the 28th decimal place. Example:  123.45M        (mandatory  M  suffix)               object       8+       Ultimate base type for both value and reference types.       Has no literal representation.               string       20+       Immutable sequence of Unicode characters. Example:  ""hello       world!\n""  (contained within double quotes)          C#'s has a unified type system such that a value of any type can be treated as an object. Every type in C# derives, directly or indirectly, from the  object  class. Reference types are treated as objects simply by viewing them as  object  types. Value types are treated as objects by performing  boxing  and  unboxing  operations. I will go deeper into these concepts in my next article.    Classes and Structures    C# allows you to define new reference and value types. Reference types are defined using the  class  construct, while value types are defined using  struct . Lets see them both in action in the following program:        struct ValType {     public int i;     public double d;     public ValType(int i, double d) {         this.i = i;         this.d = d;     }     public override string ToString() {         return ""("" + i + "", "" + d + "")"";     } }  class RefType {     public int i;     public double d;     public RefType(int i, double d) {         this.i = i;         this.d = d;     }     public override string ToString() {         return ""("" + i + "", "" + d + "")"";     } }  public class Test {     public static void Main (string[] args) {          // PART 1         ValType v1;         RefType r1;         v1 = new ValType(3, 4.2);         r1 = new RefType(4, 5.1);         System.Console.WriteLine(""PART 1"");         System.Console.WriteLine(""v1 = "" + v1);         System.Console.WriteLine(""r1 = "" + r1);          // PART 2         ValType v2;         RefType r2;         v2 = v1;         r2 = r1;         v2.i++; v2.d++;         r2.i++; r2.d++;         System.Console.WriteLine(""PART 2"");         System.Console.WriteLine(""v1 = "" + v1);         System.Console.WriteLine(""r1 = "" + r1);     } }      First we have the structure  ValType . It defines two instance variables,  i  and  d  of type  int  and  double , respectively. They are declared as  public , which means they can be accessed from any part of the program where this structure is visible. The structure defines a constructor, which has the same name as the structure itself and, contrary to method definitions, has no return type. Our constructor is in charge of the initialization of the two instance variables. The keyword  this  is used here to obtain a reference to the instance being created and has to be used explicitly in order to avoid the ambiguity generated when a parameter name clashes with the an instance variable name. The structure also defines a method called  ToString , that returns the external representation of a structure instance as a string of characters. This method overrides the  ToString  method (thus the use of the  override  modifier) defined in this structure's base type (the  object  class). The body of this method uses the string concatenation operator (+) to generate a string of the form ""( i ,  d )"", where  i  and  d  represent the current value of those instance variables, and finally returns the expected result.    As can be observed, the  RefType  class has basically the same code as  ValType . Let us examine the runtime behavior of variables declared using both types so we can further understand their differences. The  Test  class has a  Main  method that establishes the program entry point. In the first part of the program (marked with the ""PART 1"" comment) we have one value type variable and one reference type variable. This is how they look after the assignments:       The value type variable,  v1 , has its instance variables contained within the variable itself. The  new  operator used in the assignment        v1 = new ValType(3, 4.2);      does not allocate any memory in the heap as we've learned from other languages. Because  ValType  is a value type, the new operator is only used in this context to call its constructor and this way initialize the instance variables. Because  v1  is a local variable, it's actually stored as part of the method's activation record (stack frame), and it exists just because it's declared.     Objects referred by reference type variables have to be created explicitly at some point in the program. In the assignment        r1 = new RefType(4, 5.1);    the  new  operator does the expected dynamic memory allocation because in this case  RefType  is a reference type. The corresponding constructor gets called immediately afterwards. Variable  v2  is also stored in the method's activation record (because it's also a local variable) but it's just big enough to hold the reference (address) of the newly created instance. All the instance's data is in fact stored in the heap.    Now lets check what happens when the second part of the program (marked after the ""PART 2"" comment) is executed. Two new variable are introduced and they are assigned the values of the two original ones. Then, each of the instance variables of the new variables are incremented by one (using the  ++  operator).       When  v1  is copied into  v2 , each individual instance variable of the source is copied individually into the destination, thus producing totally independent values. So any modification done over  v2  doesn't affect  v1  at all. This is not so with  r1  and  r2  in which only the reference (address) is copied. Any change to the object referred by  r2  is immediately seen by  r1 , because they both refer in fact to the same object.    If you check the type hierarchy diagram above, you will notice that simple data types such as  int ,  bool  and  char  are actually  struct  value types, while  object  and  string  are  class  reference types.    If you want to compile and run the  source code  of the above example, type at the Linux shell prompt:        mcs varsexample.cs      mono varsexample.exe       The output should be:       PART 1 v1 = (3, 4.2) r1 = (4, 5.1) PART 2 v1 = (3, 4.2) r1 = (5, 6.1)       Resources             http://www.go-mono.com/     The official Mono home page. You can find here the download and install instructions     for the Mono platform. It includes a C# compiler, a runtime environment, and     a class library.     http://msdn.microsoft.com/library/default.asp?url=/library/en-us/cscon/html/vcoriCStartPage.asp     General information on the C# programming language.                Copyright © 2002, Ariel Ortiz Ramirez. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                   ... making Linux just a little more fun!         Qubism     By  Jon ""Sir Flakey"" Harsem                         These cartoons are scaled down to minimize horizontal scrolling.  To see a panel in all its clarity, click on it.                       More adventures of VI-Agra are in the  HelpDex  column this issue, and in the back issues under both HelpDex and Qubism.     All Qubism cartoons are   here  at the CORE web site.                      Copyright © 2002, Jon ""Sir Flakey"" Harsem. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                   ... making Linux just a little more fun!         Process Tracing Using Ptrace - Part III     By  Sandeep S                  The basic features of ptrace were explained in  Part I . In   Part II  we saw a small program which accessed the registers of a process and modified them so as to change the output of that process, by injecting some extra code. This time we are going to access the memory of a process. The purpose of this article is to introduce a methods for infecting binaries on runtime. There are many possible areas of use for this technique.      1. Introduction.    We are familiar with ptrace and know the techniques of attaching a process,  how to trace it and finally to free it. We also have an idea about the  structure of the Linux binary format - ELF.    Our plan is to fetch/modify a running binary. So we have to locate the  symbols inside the binary. There we need  link_map . link_map is  the dynamic  linker's internal structure with which it keeps track of loaded libraries  and symbols within libraries.     The foramt of link_map is (from /usr/include/link.h)      struct link_map   {     ElfW(Addr) l_addr;      /* Base address shared object is loaded at.  */     char *l_name;           /* Absolute file name object was found in.  */     ElfW(Dyn) *l_ld;        /* Dynamic section of the shared object.  */     struct link_map *l_next, *l_prev; /* Chain of loaded objects.  */   };        A small explanation for the fields.    l_addr: Base address where shared object is loaded.  This value can also be found from /proc/<pid>/maps   l_name: pointer to library name in string table   l_ld  : pointer to dynamic (DT_*) sections of shared lib   l_next: pointer to next link_map node   l_prev: pointer to previous link_map node       Link-map is a linked list, each item on list having a pointer to loaded  library. What we have to do is, to follow this chain, go through every  library and find our symbol. Now we have a question. Where we can find this link_map?    For every object file, there is a global offset table (GOT) which contains  many details of the binary. In GOT, the second entry is dedicated for the  link_map. So we get the address of link_map from  GOT[1]  and we go on  searching our symbol.    2. Straight to code.    Now we have collected the basic information needed to access the memory. Let's  start now. First of all we attach the process 'pid' for tracing. Now we go for  finding out the link_map we require. You will find functions  read_data ,   read_str  etc. These are helper functions to make working with ptrace easier. Helper functions are self explaining.    The function for locating the link_map is:    struct link_map *locate_linkmap(int pid) {     Elf32_Ehdr *ehdr = malloc(sizeof(Elf32_Ehdr));     Elf32_Phdr *phdr = malloc(sizeof(Elf32_Phdr));     Elf32_Dyn *dyn = malloc(sizeof(Elf32_Dyn));     Elf32_Word got;     struct link_map *l = malloc(sizeof(struct link_map));     unsigned long phdr_addr, dyn_addr, map_addr;           read_data(pid, 0x08048000, ehdr, sizeof(Elf32_Ehdr));     phdr_addr = 0x08048000 + ehdr->e_phoff;     printf(""program header at %p\n"", phdr_addr);     read_data(pid, phdr_addr, phdr, sizeof(Elf32_Phdr));      while (phdr->p_type != PT_DYNAMIC) {         read_data(pid, phdr_addr += sizeof(Elf32_Phdr), phdr,                              sizeof(Elf32_Phdr));     }          read_data(pid, phdr->p_vaddr, dyn, sizeof(Elf32_Dyn));     dyn_addr = phdr->p_vaddr;      while (dyn->d_tag != DT_PLTGOT) {         read_data(pid, dyn_addr += sizeof(Elf32_Dyn), dyn, sizeof(Elf32_Dyn));     }      got = (Elf32_Word) dyn->d_un.d_ptr;     got += 4;           /* second GOT entry, remember? */      read_data(pid, (unsigned long) got, &map_addr, 4);     read_data(pid, map_addr, l, sizeof(struct link_map));     free(phdr);     free(ehdr);     free(dyn);     return l; }        We start from the location 0x08048000 to get elf header of the process we are  tracing. We get the elf header and from its fields we can get the program header. (The fields of headers were discussed in   Part II .)      Once we get the program header, we go on checking for the header with dynamic  linking information. From the header/struct with dynamic linking information, we  fetch the location of the information. Go on searching until we get the base  address of global offset table.    Now we have the address of GOT with us and take the second entry of GOT  (there we have link_map). From there get the address of the link_map which  we require and return.    We have the struct link_map and we have to get symtab and strtab. For this, we move to  l_ld  field of link_map and traverse through dynamic sections until  DT_SYMTAB and DT_STRTAB have been found, and finally we can seek our symbol  from DT_SYMTAB. DT_SYMTAB and DT_STRTAB are the addresses of symbol table and  string table respectively.    The function resolv_tables is:    void resolv_tables(int pid, struct link_map *map) {     Elf32_Dyn *dyn = malloc(sizeof(Elf32_Dyn));     unsigned long addr;     addr = (unsigned long) map->l_ld;     read_data(pid, addr, dyn, sizeof(Elf32_Dyn));     while (dyn->d_tag) {         switch (dyn->d_tag) {         case DT_HASH:             read_data(pid, dyn->d_un.d_ptr + map->l_addr + 4,                         &nchains, sizeof(nchains));             break;         case DT_STRTAB:             strtab = dyn->d_un.d_ptr;             break;         case DT_SYMTAB:             symtab = dyn->d_un.d_ptr;             break;         default:             break;         }         addr += sizeof(Elf32_Dyn);         read_data(pid, addr, dyn, sizeof(Elf32_Dyn));     }     free(dyn); }        What we actually do here is just reading dynamic sections one by one and checks  whether the tag is DT_STRTAB or DT_SYMTAB. If yes, we can get their respective  pointers and assign to  strtab  and  symtab . Once the dynamic sectoins are  over, we can stop.    Our next step is getting the value of symbol from the symbol table. For this we  take every symbol table entry one by one and check it whether it's a function name. (We are interested in finding the value of a library function). If it is then  it's compared with the function name given by us. If here also they match now the  value of the symbol is returned.     Now we have got the value of the symbol what we actually required. What help will the value do for us? The answer depends upon the reader. As I have already stated we may use this for both good and evil purposes.    You might be thinking that everything is over. We forgot a step that we shouldn't  forget - detaching the traced process. This may leave the process in a stopped  state for ever and the consequences are already discussed in   Part I . So our last and final step is to detach the traced process.    The program may be obtained from.   Ptrace.c  Almost the whole code is self explaining.    Compile it by typing    #cc Ptrace.c -o symtrace        Now we want to test the program. Run some process in some other console, come  back and type.  (Here my test program is  emacs  and the symbol I give is  strcpy ). You may trace any program that is traceable instead of emacs and any symbol you want to inspect.      #./symtrace `ps ax | grep 'emacs' | cut -f 2 -d "" ""` strcpy      and watch what is going on.    3. Conclusion.    So, we come to the end of a series of three articles which has gone through  the basic programming with  ptrace . Once you have understood the basic  concept it is not difficult to make steps by your own. More details on ptrace and elf are available at   www.phrack.org . One more thing  I have to write is that, we reached here without even mentioning a major topic. One major feature of ptrace is its play with system calls. In User Mode Linux, this feature is used in a large scale. I am busy with my classes and final year project, and I promise, if time permits we will continue this series and then we will have a look at those features of ptrace.    All Suggestions, Criticisms, Contributions etc. are welcome. You can contact  me at   busybox@sancharnet.in             Copyright © 2002, Sandeep S. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                   ... making Linux just a little more fun!         Making a Multiple-Boot CD     By  Juraj Sipos                  I noticed that the issue of making a multiboot CD is not very much covered on the Internet, and if so, only sparsely. Commercial Windows vendors include some possibility to create bootable CD's in their software, but I haven't yet seen an option to create a multiboot CD in their packages. For me creating a bootable CD in Linux is much easier than in Windows. There are also many free utilities that help you create a Linux bootable CD, but having a multiple boot CD is a delicacy. You can have several versions of Linux boot images on the CD - versions with support for journaling file systems, repair utilities, various breeds of Linux or BSD, or even QNX, Plan9 and more.       Why do I thing this may be good for you? Imagine you use Linux and FreeBSD simultaneously, you have more Linux distributions installed on your hard disk, but something happened to your system - there is no way to access the data anymore. Either you use a bootable diskette (but there may be many obstacles if you work with a specific system like XFS journaling file system, for example, or encrypted files system, and you find that you must have at least 5 Linux bootable diskettes to suit you), or you create a multiboot CD on which you put various breeds of Linux kernels and utilities. A little CD with 10 operating systems on it is redemption from the illusion of this world that makes you believe that something is always wrong.      I want this article to be easy, practical and intelligible for beginners, too, and I'd like to avoid too technical language that is not understood by many of us. This will help attract readers of various sort.      A bootable CD is based upon the so-called El Torrito standard - but there are other sites that explain this. Visit, for example,  http://www.cdpage.com/Compact_Disc_Variations/danaboot.html     An important information for us will be that we may have up to 10 bootable operating systems on a CD that we may boot anywhere where the boot ability is supported by BIOS. The bootable ISO image file may be created with 1.44MB diskette emulation, 2.88MB diskette emulation, or hard disk emulation.       Now follows the practical guide on how to prepare a multiboot CD       First, you must have a bootable DOS or Linux diskette image file. An image is a file that contains the contents of a disk or diskette. There may be many types of image files - if you dd (disk dump) your Linux partition with a command (let's suppose that your Linux partition is on the /dev/hda1 partition):   dd if=/dev/hda1 of=/my_image.file         a file  my_image.file  will appear in your file system. Not every image file is bootable - it depends on its contents, so a good idea would be to prepare some Linux or BSD diskette image files. The simplest way would be to download such image files from the Internet. Here is the link:      http://www.ibiblio.org/pub/Linux/system/recovery/      The Ibiblio archive is very good. The image files you may download from the above URL are prepared in such a way that they are bootable, so you don't need to care much about building your own image. However, if you want to make your own image, at the above URL you may also find some utilities like Bootkit, CatRescue, SAR, disc-recovery-utils, etc., which will help you create your own bootable diskettes (or bootable image files).       The files we will need for our work, in order to make a multiboot CD, are fbsd-flp-1.0.3.bin (a bootable FreeBSD 2.8 MB diskette image), tomsrtbt, or you may create your own images from the diskettes you already have. Put your DOS or Linux diskette in the diskette drive and type the following command:      dd if=/dev/fd0 of=boot.img bs=512 count=2880          A good idea would also be to visit  http://freshmeat.net  and search for a keyword ""mini"", so you will find even some esoteric mini Linux distributions you normally don't hear about.       The site  http://www.ibiblio.org/pub/Linux/system/recovery/  contains (I deleted some stuff):        Bootkit-1.01.tar.gz    CatRescue101E.tgz    SAR-2.25.tar.gz    banshee-linux.0.61.tar.bz2    brd-2.0.tar.gz    disc-recovery-utils-1.0.tgz    fbsd-iso-1.0.3.bin.gz    fspace.tgz    genromfs-0.5.1.tar.gz    mulinux-5r0.lsm    mulinux-5r0.tgz    picoboot-0.95.tar.gz    rescue02.zip    resque_disk-2.3.99-pre9-A.tgz    rip-10.exe    rip-51.iso.bin    sash.tar.z    tomsrtbt-2.0.103.ElTorito.288.img.bz2    tomsrtbt-2.0.103.dos.zip    trccs-0.8.1r2.iso.bz2    trccs-0.8.1r2.tar.bz2    trccs-0.8.1r2_boot_disk.img.bz2    yard-2.1.tar.gz    yard-prefabs-2.tgz    zdisk-2.14.tar.gz      Some other good sites where you can download bootable diskette images:      LIAP ( http://www.liap.eu.org/ ): LIAP is a Linux in a Pill  - the site contains many 1.44MB diskette images with various utilities and kernel breeds suitable for recovery of various types of disasters.           LEKA RESCUE FLOPPY ( http://leka.muumilaakso.org/ ): Leka Rescue Floppy is a small 1.44Mb distribution.       TOMSRTBT ( http://www.toms.net/rb/ ): Tomsrtbt (Tom's Root Boot) is a rescue utility, a very good one. You may also download the 2.88MB image file from the above site.      You can also download bootable DOS images. Visit, for example,  http://www.bootdisk.com   and download DOS images if you do not have them available. The site contains DOS 5.00 to 6.22, Win 95/98/Me Bootdisks, DOS/Windows 9X/2000/XP bootdisks, Win 95/98/ME - NT4/NT5 bootdisks, DrDOS 7.X disk for Bios Flashing Basic, etc. You may also create a FreeDOS boot diskette.      First, some terms. Let's see a difference between a bootable image file of a diskette or disk and an ISO image file to be burned on a CD. What we must have are bootable diskette image files from which we will create one ISO image file.       1) You may prepare your bootable diskette images from diskettes you already have with the command:   dd if=/dev/fd0 of=/my_image.img  or you may download some bootable diskette image files from the Internet (see the links). Make a directory in your Linux box, for example - /CD, and copy the images to this directory (remember, you may have not more than ten bootable images). Make sure you keep the 8.3 format for file names - 8 characters for the file name and 3 characters for its suffix - this maximum is only for the compatibility issue with the DOS makebt.exe program we will later use).      2) If you want to make use of the space on the CD (ten images of bootable diskettes would only require about 14MB), place some other utilities in a subdirectory, for example, /CD/Soft. An information how to access the CD is included at the bottom of this article.      3) Run the following command from the /CD directory:          mkisofs -b image.img -c boot.cat -J -l -R -r -o /cd.iso /CD         The ""boot.cat"" or ""boot.catalog"" file will be automatically created, so you don't have to have it in your /CD directory - just type the command as you see it - you can type the name of any image file, as long as its name corresponds with the names of image files placed in the /CD directory. The image file included in the above command will be the one you will boot your CD from. The image files must have the size of 1.44MB or 2.8MB.       4) A cd.iso file will be created in your / directory (/cd.iso). When you check this file and mount it (mount /cd.iso /mnt -o loop), the contents of the ISO file should be seen in the directory where you mounted it. This ISO image, if we burn the CD with it, will be bootable but only one image to boot from will be available.       5) So we must edit the ISO image to make a multiple boot CD, thus we will get other images to be included in the menu (0, 1, 2, 3, etc.) we will see when we boot the CD (we will be welcomed by a multiple boot menu with options for 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10. By pressing the chosen number we will boot the desirable operating system.      6) After editing it, we may now burn the CD.      Since I don't have the time and effort to create a Perl script that would edit the ISO image for me and because the editing of the ISO image file may appear complicated for some (I want this article to be as simple as possible), it would be a good idea to use some free programs available on the Internet. One of such free programs is makebt.exe. Some time ago, I found this free program on some sites, but now I was unlucky to find it on the net, so I put it on my website   http://www.tankred.sk/~juro/freebsd/makebt.zip   where you can download it from.       You may run makebt.exe in DOSEMU, BOCHS emulator ( http://bochs.sourceforge.net ), or you can download DOS system diskette images available at  http://www.bootdisk.com , or make a FreeDOS bootable diskette and boot your PC with it in order to run the makebt.exe utility. If you don't have a DOS partition, the best idea would be to use DOSEMU emulator - DOSEMU can also access Linux partitions, where you may have your CD.ISO file waiting to be ""grasped in your clever hands"".      When you run MAKEBT.EXE at the DOS prompt, it will ask for the full path and filename of the ISO file to be modified: you will type the name of the ISO file with multiple boot diskette images in it, for example, CD.ISO, and you will see the following screen:      -------------------------------------------------------------------------------------------------------     Make Multiple Boot CD-ISO Image Modifier ver 1.02     ISO File path and name: cd.iso           Bootable Disk Image   Boot media type     Default   LBA           -------------------    ---------------     -------   --------     BC )  BOOT.CAT      1 )  FBSD.IMG               1.44M Floppy           Y      2 )  LINUX.IMG                     2.88M Floppy             -      3 )  PLAN9.IMG                      1.44M Floppy            -      4 )  QNX.IMG                          1.44M Floppy             -      5 )  OPENBSD.IMG              2.88M Floppy            -      6 )      7 )      8 )      9 )      10 )      <TAB> = move between fields, up/down arrows = move between rows, F1 = Confirm     Press 'y' key to make this image as default boot      ------------------------------------------------------------------------------------------------------     BC stands for Boot Catalog. You just write boot.cat and don't worry about it anymore, as you already used this string in the above mkisofs command (it is, however, important that the ISO image file contains the string ""boot.cat"" in it). Now you carefully type the names of the images. You have to type the name of images in the DOS 8.3 format (this is a DOS restriction for file names - the file may have only 8 characters and suffix 3 characters maximum).       In the middle of the screen you will choose from 1.44MB floppy emulation, 2.88MB floppy emulation, hard disk emulation, or no emulation. We will only use 1.44MB and 2.88MB emulation (if you want to make a hard disk emulation, make a 650MB Linux partition and copy there the filesystem of your Linux system you booted your hard disk from - experiment...) Use the right keyboard arrow to select between the types of emulation. On the right of the screen you have to choose one bootable image as the default one by pressing ""Y"".       When you are finished, press F1 (you may try this several times, as the program may not respond everytime). The program is intelligent - if you typed the image file name incorrectly, you will receive a warning message (after pressing F1). Do not include any descriptions for boot images in the menu that follows after pressing F1, as this feature is mostly exploitable in SCSI CD-ROMs and I haven't studied it very much.       That's it. Now you may burn your CD.       cdrecord -v speed=8 dev=0,0,0 /cd.iso        When you boot the CD, you will not see descriptions for operating systems, only numbers. The first and the second number will (0,1) usually stand for the same operating system. I had not much time to experiment with this issue, but a good idea would be to write down the number, so that you know which operating system you are going to boot from.       We deal here with diskette images and emulation, so if you boot your images with the multiple boot CD you just created, you may access your CD-ROM by typing ""mount /dev/hdc /mnt"", for example, and have also access to your /Soft directory, where you may have other utilities you plan to work with later. In case of a DOS system disk, you should include drivers to access the CD-ROM.      If you want to study or make a Linux program to patch the ISO file, you can compare an ordinary ISO image file with one boot possibility only with the ISO file patched by the makebt.exe utility. A good binary patcher is a diff utility by Giuliano Pochini. Bdiff is a simple and small program for making what the very common utilities ""diff"" and ""patch"" do with text files, but also works with binary files. It may be downloaded from:  http://space.virgilio.it/g_pochini@virgilio.it/   - however, both ISO files must be identical. The diff utility (for comparing files) will show you the place (offsets) where the information with a multiboot flag was written. It is sector 17 (Boot Volume Descriptor) and the Boot Catalog Sector.       I created many multiboot CD's with the above information and I have never experienced a problem. But first, in order to avoid writing unusable CD-Rs - I had some problems making my own OS/2 images - burn the ISO image on rewritable CD-RW disks. Enjoy!             Copyright © 2002, Juraj Sipos. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 85 of  Linux Gazette , December 2002                   ... making Linux just a little more fun!         Getting started with TUX     By  Vinayak Hegde                   Meet TUX - ""The Webserver""      If you did come to the site to read an article about Tux the Penguin -- the lucky mascot of Linux -- you might be disappointed. But don't go away just yet: read on to find what TUX the webserver can do do for you in terms of performance and you will be  delighted. You might just discover something to hack on and tweak. This is an article about TUX - the webserver embedded within the Linux kernel.     The name TUX comes from 'Threaded linUX webserver'. TUX was written by Red Hat and is based on the 2.4 kernel series. It is a kernel-space  HTTP subsystem. As you may have guessed by now TUX is released under the GNU GPL. So in the free software tradition, you are free to tweak it and modify it to meet your own specific needs. One of the ways of adapting TUX for our needs ,is by writing TUX modules, which can be user-space or kernel-space modules. The main goal behind writing TUX was to enable  high-performance webserving on Linux. This was especially important as Linux is extremely popular in the webserver market.     TUX is not as feature-filled as Apache and has some limitations.  But nevertheless, TUX is a complete HTTP/1.1 compliant webserver  supporting HTTP/1.1 persistent (keep-alive) connections, pipelining,  CGI execution, logging, virtual hosting, various forms of modules,  and many other webserver features. TUX is now officially known as  the Red Hat Content Accelerator (RHCA).      What can TUX do for me ?      Though quite some amount of today's webcontent is dynamic generated, most of the webcontent is static. Take for example static webpages and images. This leads to quite a overhead as user-space webservers such as apache have to be use some system calls for actually serving the content. The frequent context switches between kernel-space and user-space programs is quite a performance  hit. TUX is a saviour here. TUX can be built into the monolithic kernel or  dynamically loaded as a module. The first approach is preferable for servers which are dedicated to webserving. When built as a loadable module, it can be dynamically inserted and removed, as when the service is started or stopped  respectively. This approach affords some amount of flexibility.     TUX is used primarily for serving static content, leaving generation and serving of dynamic content to backend webservers such as Apache. Now, newer versions of TUX have the capability to cache dynamic content as well. TUX modules can create ""objects"" which are stored using the page cache. To respond to a request for dynamic data, a TUX module can send a mix of dynamically-generated data and cached pre-generated objects. Thus, most of the requests which are just ""network-copy"" operations can  be handled efficiently by TUX. The new version of TUX uses zero copy block IO  instead of a temporary buffer as in TUX 1.0. Also virtual hosting support has been enhanced for TUX and the number of virtual hosts that can be supported is only  limited by disk space and RAM.      Getting started with TUX     Now that we know what TUX is capable of, we can move to installing and configuring TUX. All the information that follows has been tested on Red Hat 7.2 with TUX-2.1.0-2. Due to ease of use and familiarity Apache has been used as the user-space webserving daemon.        Step 1. Installing TUX     Check whether you have tux installed using the command :-    # rpm -q tux     You may get messages similar to the ones below :      tux-2.1.0-2 (TUX is installed and the version number is printed)    package tux is not installed (obvious!!)   If TUX is not installed, download the rpm (or source package) you can install it  using the following command:     for RPM packages    # rpm -ivh tux-2.1.0-2.i386.rpm        for Source packages   patch the kernel  # patch -p0 < tu"
GX203-07-10129839	"The linux-kernel mailing list FAQ      Before you consider posting to the linux-kernel mailing list, please read at least the start of  section 3  of this FAQ list.     These frequently asked questions are divided in various categories. Please  contribute  any category and Q/A that you may find relevant. You can also add your answer to any question that has already been answered, if you have additional  information  to contribute.   The official site is:  http://www.tux.org/lkml/  (this is in the east coast of the U.S.A). Many thanks to Sam Chessman and David Niemi for hosting the FAQ on a high-bandwidth, professionally managed Linux server. The following mirrors are available (and are updated at the same time as the official site):       http://www.atnf.csiro.au/~rgooch/linux/docs/lkml/  in Sydney, Australia       http://www.ras.ucalgary.ca/~rgooch/linux/docs/lkml/  in Calgary, Canada       http://www.kernel.org/pub/linux/docs/lkml/  in the west coast of the U.S.A.          Hot off the Presses    vger.kernel.org has enabled ECN. You may need to switch ISP in order to receive linux-kernel email. See the section on  ECN  for more details.    Two digest forms of linux-kernel (a normal digest every 100KB and a once-daily digest) are available at  http://lists.us.dell.com/ .      Go to   http://www.atnf.csiro.au/~rgooch/linux/docs/kernel-newsflash.html  for newflashes about official kernel releases.     Read this before complaining to linux-kernel about compile problems. Chances are a thousand other people have noticed and the fix is already published.     Index        Basic Linux kernel documentation        Contributors and some special expressions        Related mailing lists        Question Index        General questions        Driver specific questions        Mailing list questions        ""How do I"" questions        ""Who's who"" questions        CPU questions        OS questions        Compiler/binutils questions        Feature specific questions        ""What's changed between kernels 2.0.x and 2.2.x"" questions        Primer documents        Kernel Programming Questions        Mysterious kernel messages        Odd kernel behaviour        Programming Religion        User-space Programming Questions             Answers        Contributing             Basic Linux kernel documentation  The following are  Linux   kernel  related documents, which you should take a look at  before  you post to the linux-kernel mailing list:        The Linux Kernel Hackers' Guide , compiled by Michael K. Johnson of  Red Hat  fame. Includes among other documents selected Q/As from the linux-kernel mailing list.        The Linux Kernel  book, by David A. Rusling, available in various formats from the  Linux Documentation Project  and  mirrors . Still being worked on, but explains clearly the main structure of the Linux kernel.       The Linux FAQ  by Robert Kiesling has many high quality Q/As.       The Linux Kernel HOWTO  by Brian Ward.  Fundamental reading for anybody wanting to post to the linux-kernel mailing list.      A completely new  Kernelhacking-HOWTO  at  http://www.kernelhacking.org/ . Currently work in progress, but already contains some useful information.      Various Linux    HOWTOs  on specific questions, such as the     BogoMips mini-HOWTO  by Wim van Dorst. These are all by definition LDP documents.      The Linux  kernel source code  for any particular kernel version that you may be using. Note that there is a /Documentation directory which holds some very useful text files about drivers, etc. Also check the MAINTAINERS file in the kernel source root directory.      Some drivers even have  Web pages , with additional up to date information e.g.  the network drivers by Donald Becker , etc. Check the  Hardware section in the LDP site .      Similarly, Linux implementations for some CPU architectures have dedicated  Web pages, mailing lists , and sometimes even a HOWTO e.g. the  Linux Alpha HOWTO  by Neal Crook. Check the LDP site and its mirrors for Web links to the various architecture specific sites.       Linux device drivers , a book written by Alessandro Rubini. C. Scott Ananian  reviewed it for Amazon.com .       Linux kernel internals , a book by Michael Beck (Editor) et al. Also  reviewed for Amazon.com .      Another useful site is:  http://www.kernelnewbies.org/       Here is a general guide on how to ask questions in a way that greatly improves your chances of getting a reply:   http://www.catb.org/~esr/faqs/smart-questions.html . If you have a bug to report, you should also read   http://www.chiark.greenend.org.uk/~sgtatham/bugs.html .   Extra instructions, specific to the Linux kernel are available  here .            Contributors and some special expressions  This is the list of contributors to this FAQ. They are listed in alphabetic order of their abbreviations, used in the  Answers  sections below to identify the author(s) of each answer.     AC :   Alan Cox      AV :   Alexander Viro      ADB:   Andrew D. Balsa      CP :   Colin Plumb      DBE:   Daniel Bergstrom      DSM:   David S. Miller  (co-postmaster)     DW :   David Woodhouse      KGB:   Krzysztof G. Baranowski      KO :   Keith Owens      MEA:   Matti E. Aarnio  (co-postmaster)     MRW:   Matthew Wilcox      PG :   Paul Gortmaker      REG:   Richard E. Gooch <rgooch@atnf.csiro.au>  (FAQ maintainer)     REW:   Roger E. Wolff      RML:   Robert M. Love      RRR:   Rafael R. Reilova      TAC:   Thomas A. Cort      TJ :   Trevor Johnson      TYT:   Theodore Y. Ts'o      VKh:   Vassilii Khachaturov        Some English expressions for non-native English readers. Many of these (and far more) may be obtained from the  Jargon File :      AFAIK = As Far As I Know      AKA = Also Known As      ASAP = As Soon As Possible      BTW = By The Way (used to introduce some piece of information or question that is on a different topic but may be of interest)      COLA = comp.os.linux.announce (newsgroup)      ETA = Estimated Time of Arrival      FAQ = Frequently Asked Question      FUD = Fear, Uncertainty and Doubt      FWIW = For What It's Worth      FYI = For Your Information      IANAL = I Am Not A Lawyer      IIRC = If I Recall Correctly      IMHO = In My Humble Opinion      IMNSHO = In My Not-So-Humble Opinion      IOW = In Other Words      LART = Luser Attitude Readjustment Tool (quoting Al Viro: ""Anything you use to forcibly implant the clue into the place where luser's head is"")      LUSER = pronounced ""loser"", a user who is considered a to indeed be a loser (idiot, drongo, wanker, dim-wit, fool, etc.)      OTOH = On The Other Hand        PEBKAC = Problem Exists Between Keyboard And Chair       ROTFL = Rolling On The Floor Laughing     RSN = Real Soon Now      RTFM = Read The Fucking Manual (original definition) or Read The Fine Manual (if you want to pretend to be polite)      TANSTAAFL = There Ain't No Such Thing As A Free Lunch (contributed by David Niemi, quoting Robert Heinlein in his science fiction novel 'The Moon is a Harsh Mistress')      THX = Thanks (thank you)      TIA = Thanks In Advance      WIP = Work In Progress      WRT = With Respect To            Related mailing lists  Some questions are better posted to related mailing lists on specific subjects. Posting to these mailing lists helps reduce the volume on the linux-kernel mailing list and also increases your chances of having your message read by an expert on the subject. Some people do not have the time to subscribe to the linux-kernel mailing list, as it is too general for them. Some related lists are:      The   linux-net@vger.kernel.org  mailing list is for networking user questions. Subscribe by sending    subscribe linux-net  in the message body to  majordomo@vger.kernel.org      The  netdev@oss.sgi.com  mailing list is for network development (not user questions). Subscribe by sending    subscribe netdev  in the message body to  majordomo@oss.sgi.com             Question Index      Section 1 - General questions           Why do you use ""GNU/Linux"" sometimes and just ""Linux"" in other parts of the FAQ?        What is an experimental kernel version?        What is a production kernel?        What is a feature freeze?      What is a code freeze?        What is a f.g.hh pre i kernel?        Where do I get the latest kernel source?        Where do I get extra kernel patches?        What is a patch?      How do I make a patch suitable for the linux kernel list?        How do I apply a patch?        What's vger?        What is a CVS tree? Where can I find more information about CVS?        Is there a CVS tutorial?        How do I get my patch into the kernel?        Why does the kernel tarball contain a directory called linux/ instead of linux-x.y.z/ ?        What's the difference between the official kernels and Alan Cox's -ac series of patches?        What does it mean for a module to be tainted?        What is this about GPLONLY symbols?        Do I have to use BitKeeper to send patches?        Why do some developers use the non-free BitKeeper? Isn't this against the spirit of Free Software?        Who maintains the kernel?        The kernel doesn't compile cleanly. What shall I do ?           Section 2 - Driver specific questions         Driver such and such is broken!        Here is a new driver for hardware XYZ.        Is there support for my card TW-345 model C in kernel version f.g.hh?        Who maintains driver such and such?        I want to write a driver for card TW-345 model C, how do I get started?        I want to get the docs, but they want me to sign an NDA (Non-Disclosure Agreement).        I want/need/must have a driver for card TW-345 model C! Won't anybody write one for me?        What's this major/minor device number thing?        Why aren't WinModems supported?        Modern CPUs are very fast, so why can't I write a user mode interrupt handler?        Do I need to test my driver against all distributions?           Section 3 - Mailing list questions         How do I subscribe to the linux-kernel mailing list?        How do I unsubscribe from the linux-kernel mailing list?        Do I have to be subscribed to post to the list?        Is there an archive for the list?        How can I search the archive for a specific question?        Are there other ways to search the Web for information on a particular Linux kernel issue?        How heavy is the traffic on the list?        What kind of question can I ask on the list?        What posting style should I use for the list?        Is the list moderated?        Can I be ejected from the list?        Are there any implicit rules on this list that I should be aware of?        How do I post to the list?        Does the list get spammed?        I am not getting any mail anymore from the list! Is it down or what?        Is there an NNTP gateway somewhere for the mailing list?        I want to post a Great Idea (tm) to the list. What should I do?        There is a long thread going on about something completely offtopic, unrelated to the kernel, and even some people who are in the ""Who's who"" section of this FAQ are mingling in it. What should I do to fight this ""noise""?        Can we have the  Subject:  line modified to help mail filters?        Can we have a  Reply-To:  header automatically added to the list traffic?        Can I post job offers/requests to the list?        Why do I get bounces when I send private email to some people?        Why don't you split the list, such as having one each for the development and stable series?           Section 4 - ""How do I"" questions         How do I post a patch?        How do I capture an Oops?        How do I post an Oops?        I think I found a bug, how do I report it?        What information should go into a bug report?        I found a bug in an ""old"" version of the kernel, should I report it?        How do I compile the kernel?           Section 5 - ""Who's who"" questions    Names are in alphabetical order (last name) to avoid stepping on toes.   If someone doesn't appear here, check /usr/src/linux/CREDITS.          Who is in charge here?        Why don't we have a Linux Kernel Team page, same as there are for other projects?        Why doesn't <any of the below> answer my mails? Isn't that rude?        Why do I get bounces when I send private to email to some of these people?        Who is Matti Aarnio?       Who is H. Peter Anvin?      Who is Donald Becker?       Who is Alan Cox?        Who is Richard E. Gooch?        Who is Paul Gortmaker?       Who is Bill Hawes?      Who is Mark Lord?      Who is Larry McVoy?       Who is David S. Miller?       Who is Linus Torvalds?       Who is Theodore Y. T'so?       Who is Stephen Tweedie?       Who is Roger Wolff?         Some people haven't contributed yet with a few lines about themselves, and the policy of this FAQ dictates that nobody is going to write about anybody else without authorization. Hence the missing links e.g. if you are not Linus, don't insist, we are not going to add your information about Linus.      Other OS developers:        Who is Prof. Douglas Comer (Xinu)?        Who is Richard M. Stallman aka RMS (GNU)?        Who is Prof. Andrew Tanenbaum (MINIX)?           Section 6 - CPU questions  Is this a matter of taste or what?        What is the ""best"" CPU for GNU/Linux?        What is the fastest CPU for GNU/Linux?        I want to implement the Linux kernel for CPU Hyper123, how do I get started?        Why is my Cyrix 6x86/L/MX detected by the kernel as a Cx486?        What about those x86 CPU bugs I read about?        I grabbed the standard kernel tarball from ftp.kernel.org or some mirror of it, and it doesn't compile on the Sparc, what gives?        Does the Linux kernel execute the Halt instruction to power down the CPU?        I have a non-Intel x86 CPU. What is the [best|correct] kernel config option for my CPU?        What CPU types does Linux run on?           Section 7 - OS questions  OS theory and practical issues mix.        OS $toomuch has this Nice feature, so it must be better than GNU/Linux.        Why doesn't the Linux kernel have a graphical boot screen like $toomuch OS?        The kernel in OS CTE-variant has this Nice-very-nice feature, can I port it to the Linux kernel?        How about adding feature Nice-also-very-nice to the Linux kernel?        Are there more bugs in later versions of the Linux kernel, compared to earlier versions?        Why does the Linux kernel source code keep getting larger and larger?        The kernel source is HUUUUGE and takes too long to download. Couldn't it be split in various tarballs?        What are the licensing/copying terms on the Linux kernel?        What are those references to ""bazaar"" and ""cathedral""?        What is this ""World Domination"" thing?        What are the plans for future versions of the Linux kernel?        Why does it show BogoMips instead of MHz in the kernel boot message?        I installed kernel x.y.z and package foo doesn't work anymore, what should I do?        People talk about user space vs. kernel space. What's the advantage of each?        What are threads?        Can I use threads with GNU/Linux?        You mean threads are implemented in user space? Why not in kernel space? Wouldn't that be more efficient?        Can GNU/Linux machines be clustered?        How well does Linux scale for SMP?        Can I lock a process/thread to a CPU?        How efficient are threads under Linux?        How does the Linux networking/TCP stack work?        Can we put the networking/TCP stack into user-space?           Section 8 - Compiler/binutils questions  Kernel compilation problems.        I downloaded the newest kernel and it doesn't even compile!  What's wrong?        What are the recommended compiler/binutils for building kernels?        Why the recommended compiler? I like xyz-compiler better.        Can I compile the kernel with gcc 2.8.x, egcs, (add your xyz compiler here)? What about optimizations? How do I get to use -O99, etc.?        I compiled the kernel with xyz compiler and get the following warnings/errors/strange behavior, should I post a bug report to the list?  Should I post a patch?        Why does my kernel compilation stops at random locations with: ""Internal compiler error: program cc1 caught fatal signal 11.""?        What compiler flags should I use to compile modules?        Why do I get unresolved symbols like foo__ver_foo in modules?        Why do I get unresolved symbols with __bad_ in the name?           Section 9 - Feature specific questions  Miscellaneous kernel features questions.        GNU/Linux Y2K compliance?        What is the maximum file size supported under ext2fs? 2 GB?        GGI/KGI or the Graphics Interface in Kernel Space debate?        How do I get more than 16 SCSI disks?        What's devfs and why is it a Good Idea (tm)?        Linux memory management? Zone allocation?        How many open files can I have?        When will the Linux accept(2) bug be fixed?        What about STREAMS? I noticed Caldera has a STREAMS package, when will that go in the kernel source proper?        I need encryption and steganography. Why isn't it in the kernel?        How about an undelete facility in the kernel?        How about tmpfs for Linux?        What is the maximum file size/filesystem size?        Linux uses lots of swap while I still have stuff in cache. Isn't this wrong?        Why don't we add resource forks/streams to Linux filesystems like NT has?        Why don't we internationalise kernel messages?           Section 10- ""What's changed between kernels 2.0.x and 2.2.x"" questions         Size (source and executable)?        Can I use a 2.2.x kernel with a distribution based on a 2.0.x kernel?        New filesystems supported?        Performance?        New drivers not available under 2.0.x?        What are those __initxxx macros?        I have seen many posts on a ""Memory Rusting Effect"". Under what circumstances/why does it occur?        Why does ifconfig show incorrect statistics with 2.2.x kernels?        My pseudo-tty devices don't work any more. What happened?        Can I use Unix 98 ptys?        Capabilities?        Kernel API changes           Section 11- Primer documents  Please, if you wish to contribute a Q/A in this section, provide a very short answer defining the topic and  then a URL  to a longer text/Web page. Like that we can have various URL's for a single Q, each with a different point of view. Another advantage of this approach is that each contributor has to sit down and write a coherent HTML page or text file. Having to structure a written answer gives ample time to think about the issues and the topic as a whole. It also allows frequent independent revisions, which would be impossible on the FAQ itself.   Note that writing the longer text/Web page on some relevant Linux kernel topic and providing a Q/A in this section confers you instant  Guru status . Some people would *kill* for this. Now go and write your stuff. ;)        What's a primer document and why should I read it first?        How about having I/O completion ports?        What is the VFS and how does it work?        What's the Linux kernel's notion of time?        Is there any magic in /proc/scsi that I can use to rescan the SCSI bus?           Section 12- Kernel Programming Questions  Answers to common questions about kernel programming details. See also Tigran Aivazian's page on  kernel programming .        When is cli() needed?        Why do I see sometimes a cli()-sti() pair, and sometimes a save_flags-cli()-restore_flags sequence?        Can I call printk() when interrupts are disabled?        What is the exact purpose of start_bh_atomic() and end_bh_atomic()?        Is it safe to grab the global kernel lock multiple times?        When do I need to initialise variables?           Section 13- Mysterious kernel messages  We sometimes get these messages in our system logs and wonder what they mean...        What exactly does a ""Socket destroy delayed"" mean?        What do I do about ""inconsistent MTRRs""?        Why does my kernel report lots of ""DriveStatusError BadCRC"" messages?        Why does my kernel report lots of ""APIC error"" messages?           Section 14- Odd kernel behaviour  The kernel behaves in ways that seem odd...        Why is kapmd using so much CPU time?        Why does the 2.4 kernel report  Connection refused  when connecting to sites which work fine with earlier kernels?        Why does the kernel now report zero shared memory?        Why does  lsmod  report a use count of -1 for some modules? Is this a bug?        Why doesn't the kernel see all of my RAM?        I've mounted a filesystem in two different places and it worked. Why?           Section 15- Programming Religion  Responses to suggestions about programming techniques and languages.        Why is the Linux kernel written in C/assembly?        Why don't we rewrite it all in assembly language for processor Mega666?        Why don't we rewrite the Linux kernel in C++?        Why is the Linux kernel monolithic? Why don't we rewrite it as a microkernel?        Why don't we replace all the goto's with C exceptions?        Why are the kernel developers so dismissive of new techniques?           Section 16- User-space Programming Questions  Answers to common questions about user-space programming details, as it relates to the kernel/user-space interface (i.e. system calls). This does not cover questions on the C library nor any other library, as those questions are not related to the kernel.        Why does setsockopt() double SO_RCVBUF?             Answers      Section 1 - General questions         Why do you use  "" GNU/Linux ""  sometimes and just  "" Linux ""  in other parts of the FAQ?        (ADB)  In this FAQ, we have tried to use the word ""Linux"" or the expression ""Linux kernel"" to designate the kernel, and GNU/Linux to designate the entire body of GNU/GPL'ed OS software, as found in the various distributions. We prefer to call a cat, a cat, and a GNU, a GNU. ;-)   The purpose of the FAQ is to provide information on the Linux kernel and avoid debates on e.g. semantics issues. Further discussion of the relationship between GNU software and Linux can be found at   http://www.gnu.org/gnu/linux-and-gnu.html .   BTW, it seems many people forget that the linux kernel mailing list is a forum for discussion of  kernel -related matters, not GNU/Linux in general; please do  not  bring up this subject on the list.            What is an experimental kernel version?        (ADB) ) Linux kernel versions are divided in two series: experimental (odd series e.g. 1.3.xx or 2.1.x) and production (even series e.g. 1.2.xx, 2.0.xx, 2.2.x, 2.4.x and so on). The experimental series are fast moving versions which are used to test new features, algorithms, device drivers, etc. By their own nature the experimental kernels may behave in unpredictable ways, so one may experience data losses, random machine lockups, etc.            What is a production kernel?        (ADB)  Production or stable kernels have a well defined feature set, a low number of known bugs, and tried and proven drivers. They are released less frequently than the experimental kernels, but even so some ""vintages"" are considered better than others. GNU/Linux distributions are usually based on chosen stable kernel versions, not necessarily the latest production version.            What is a feature freeze?        (ADB)  A feature freeze is when Linus announces on the linux-kernel list that he will not consider any more features until the release of a new stable kernel version. Usually the net effect of such an announcement is that on the following days people on the list propose a flurry of new features before Linus really enforces the feature freeze. ;-)            What is a code freeze?        (ADB)  A code freeze is more restrictive than a feature freeze; it means only severe bug fixes are accepted. This is a short phase that usually precedes the creation of a new stable kernel tree.            What is a  f.g.hh pre i  kernel?        (ADB)  These are intermediate pre-release versions of version  f.g.hh . Note that usually  i  < 5, but e.g.  2.0.34 pre i  was available with  i  = 1 to 16. Sometimes "" pre "" is replaced by the initials of the developer putting together the kernel revision, e.g. 2.1.105 ac 4 means the 4th intermediate release of kernel version 2.1.105 by Alan Cox.            Where do I get the latest kernel source?        (ADB)  The primary site for the Linux kernel (experimental and production) sources is hosted by Transmeta (the company Linus Torvalds used to work for) on a dedicated Web server at  http://www.kernel.org/ . This site is mirrored across the world, and has pointers to mirrors for each country. You can go directly to a mirror for your country by going to  http://www.CODE.kernel.org/  where ""CODE"" is the appropriate country code. For example, ""au"" is the country code for Australia, so the principle mirror site for Australia is  http://www.au.kernel.org/        (REG)  You may also access tarballs and patches directly via ftp from  ftp://ftp.CODE.kernel.org/pub/linux/kernel/  which is where Linus distributes his kernels from. Other notable kernel hackers have directories under the  people  directory, which is where they keep their kernel patches. The  testing  directory is where Linus puts pre-release patches. The pre-release patches are mainly intended for other developers, so they can stay in sync with changes in Linus' source tree. These are often highly experimental and may crash or cause filesystem corruption. Use at your own risk.   Note that Linus and Marcelo are using  BitKeeper  to manage their kernel source trees, and it is more convenient for them to make snapshots of their latest trees available via BitKeeper, rather than make patches. If you want access to these snapshots (which are merely a work in progress, and may be buggy), there are several access methods available:  BitKeeper: bk://linux.bkbits.net/linux-2.[45] CVS:  :pserver:anonymous@cvs.kernel.org:/home/cvs/linux-2.[45] RSYNC:  rsync.kernel.org::pub/scm/linux/kernel/bkcvs/linux-2.[45]/ Subversion: svn://svn.kernel.org/linux-2.[46]/trunk   These access methods are provided as a service to the community by  BitKeeper , as is the free licence to use the BitKeeper software for Open Source projects. These services cost BitKeeper real money to provide (bandwidth, computing power and support costs for helping the Open Source community). Please do not abuse these services.            Where do I get extra kernel patches?        (REG)  There are many places which provide various extra patches to the kernel for new features. One fairly good archive is available at:  http://www.linuxhq.com/ .            What is a patch?        (RRR)  A patch file (as it refers to the Linux kernel) is an ASCII text file that contains the  differences  between the original code and the new code, plus some additional information such as filenames and line numbers. The patch program (man patch) can then apply the patch to an existing kernel source tree.            How do I make a patch suitable for the linux kernel list?        (REG)  Here are some basic guidelines for posting patches. For information on how to generate patches, see the entry by RRR below.     Ensure the patch does not have trailing control-M characters on each line. A number of broken tools used to encode patches add control-M for ""DOS compatibility"". This breaks many versions of  patch , so be sure to configure your tools properly, or use unbroken tools, otherwise your patch will be silently deleted.     Include the patch inline in your email, in plain text. Do not post it as a base64 MIME attachment. Many people will  not  be able to read your patch, and thus your patch will be deleted without comment.     If you have a large patch, post a URL instead, otherwise you'll fill the mailboxes of thousands of people, and you will get complaints. Posting a new, large patch once might be OK, but updates should not be posted in full (post a URL).     If you want Linus or one of the primary maintainers (i.e. Marcelo, David) to apply your patch, you must  Cc:  them explicitly, otherwise your patch will be ignored.     When sending patches to Linus or one of the primary maintainers, you must include the patch inline, in plain text, no matter how large the patch.      If you want to send a patch to the list for comment, and also send it to Linus/primary maintainer for inclusion, and the patch is large, you may wonder how to reconcile the conflicting requirements. The solution is obvious: post the URL to the mailing list, wait for comments, and later send the patch, inline, to Linus/primary maintainer. Yes, this is more work for you. No, we don't care.     If you have a mailer that eats whitespace or causes similar corruption, then  FIX YOUR MAILER , don't expect to be able to take the easy solution and MIME encode your patch.     Finally, I've seen one person question the veracity of these guidelines, stating that the rules are rather more relaxed, and this FAQ is being over zealous. Fortunately, the King Penguin himself responded to this, so I include his words on this, so that there can be no doubt:  If I get a patch in an attachment (other than a ""Text/PLAIN"" type attachment with no mangling and that pretty much all mail readers and all tools will see as a normal body), I simply WILL NOT apply it unless I have strong reason to. I usually wont even bother looking at it, unless I expected something special from the sender.  Really. Don't send patches as attachments.     Linus         (RRR)  To make a patch you use the diff program (read the info file for diff). The easiest way to do this is to set up two source trees under /usr/src, set a symlink ""/usr/src/linux"" to point to the modified tree, and diff one tree against the other. The file /usr/src/Documentation/CodingStyle has more specific information,  read it . Things to remember:      Always specify unified (-u) diff format.      Avoid making formatting changes to the source that make the diff needlessly larger. Watch out for editors that convert tabs to spaces or vice versa.      Unless you have specific reasons, diff against the latest official source tree. Otherwise, your patch is likely to be ignored. Either way, specify in your post against what you've diff'ed.      Make sure your diff includes only the intended changes in your patch, not every other patch you have made to your source tree. Usually patches are limited to a few files, or directories. It is best to only diff the relevant files i.e. if I only made changes to the file driver_xyz.c under drivers/net, then I would use the following commands (assuming you have the original source tree named ""linux-2.1.105"", and the modified tree pointed at by the symlink ""linux""):    cd /usr/src diff -u linux-2.1.105/drivers/net/driver_xyz.c            \                 linux/drivers/net/driver_xyz.c  > my_patch        The following two should go without saying: the arguments to diff are first  source (the original, unmodified file(s)) , and then  destination (your modified version of the file(s)) , otherwise you get a reversed patch (and lots of people wondering what you're smoking). Also, make sure your patch applies and compiles cleanly.      Of course you need to set up two identical source directories to be able to diff the tree later. A nice trick -- requiring a little bit of consideration, though -- is to create the modified source tree from hard links to the original source tree:   tar xzvf linux-2.1.anything.tar.gz mv linux linux-2.1.anything.orig cp -al linux-2.1.anything.orig linux-2.1.anything       This will hardlink every source file from the original tree to a new location; it is very fast, since it does not need to create some 80+ megabytes of files.  You can now apply patches to the linux-2.1.anything source tree, since patch does not change the original files but move them to  filename .orig , so the contents of the hard-linked file will not be changed.    Assuming that your editor does the same thing, too (moving original files to backup files before writing out changed ones) you can also freely edit within the hardlinked tree.  If your editor does not handle files this way, you need to make a copy of each file before editing it, like this:   cp driver_xyz.c temporary; mv temporary driver_xyz.c      You can use file permissions to remind you to do this.  Just remove write permissions from all the files in the directory you are working in:   chmod -w *.c      The changed tree can be diffed at high speed, since most files don't just have indentical contents, they are identical files in both trees. Naturally removing that tree is quite fast, too.  Thanks to Janos Farkas < chexum@shadow.banki.hu > for this trick.      Finally, review the patch file (the format is not that complicated) before posting, and include all relevant information as to the nature of the patch. In particular, specify: why is this patch needed/useful, and what exactly does it fix/improve.                 How do I apply a patch?        (TAC)  (From  /usr/src/linux/README ) You can upgrade between releases by patching. Patches are distributed in the traditional gzip and the new bzip2 format. To install by patching, get all the newer patch files, enter the top-level directory of the unpacked kernel source tree and execute:   gzip -cd patchXX.gz | patch -p1  or:   bzip2 -dc patchXX.bz2 | patch -p1  (repeat xx for all versions bigger than the version of your current source tree,  in order ) and you should be ok. You may want to remove the backup files (xxx~ or xxx.orig), and make sure that there are no failed patches (xxx# or xxx.rej). If there are, either you or me has made a mistake.  Alternatively, the script patch-kernel can be used to automate this process. It determines the current kernel version and applies any patches found. Use it thus:  scripts/patch-kernel .  The first argument in the command is the location of the kernel source. Patches are applied from the current directory, but an alternative directory can be specified as the second argument.       (RRR)  To apply kernel patches please take a look at the kernel README file (/usr/src/linux/README) under ""Installing the kernel"". There is also a  good explanation  on the Linux HQ Project site.            What's vger?        (REG)  ""vger"" is the name of the machine which hosts the LKML server. This server also hosts a number of other linux-related mailing lists. More information about the server is available at  http://vger.kernel.org/             What is a CVS tree? Where can I find more information about CVS?        (REG)  ""CVS"" is short for Concurrent Versions System, a Source Code Management system. Check out the   CVS Bubbles page .            Is there a CVS tutorial somewhere?        (ADB)  Here is a CVS tutorial which you can find online:       An interactive CVS tutorial.       Getting a general idea of how CVS works takes about 15 minutes (highly recommended). Note that there are various graphical front ends to CVS, so you don't have to learn the usual assortment of cryptic commands.          How do I get my patch into the kernel?        (RRR)  Depending on your patch there are several ways to get it into the kernel.  The first thing is to determine under which maintainer does your code fall into (look in the MAINTAINERS file).  If your patch is only a small bugfix and you're sure that it is 'obviously correct', then by all means send it to the appropriate maintainer and post it to the list.  If there is urgency to the bugfix (i.e. a major security hole) you can also send it to Linus directly, but remember he's likely to ignore random patches unless they are ""obviously correct"" to him, have the maintainer's approval, or have been well tested and meet the first condition.  In case you're wondering what constitutes well tested, here's another important bit: one purpose of the list is to get patches peer-reviewed and well-tested. Now, if your patch is relatively big, i.e.  a rewrite of a large code section or a new device driver, then to conserve bandwidth and disk-space just post an announcement to the list with a link to the patch.  Lastly, if you're not too sure about your patch yet, want some feedback from the maintainer, or wish to avoid open-season flaming on work-in-progress, then use private email.       (REG)  If there is no specific maintainer for the part of the kernel you want to patch, then you have three main options:    send it to  linux-kernel@vger.kernel.org  and hope someone picks it up and feeds it to Linus, or maybe Linus himself will pick it up (don't count on it)    send it to linux-kernel and Cc:  Linus Torvalds <torvalds@osdl.org>  and hope Linus will apply it. Note that Linus operates like a black box. Do not expect a response from him. You will need to check patches he releases to see if he applied your patch. If he doesn't apply your patch, you will need to resend it (often many times). If after weeks or months and many patch releases he still hasn't applied it, maybe you should give up. He probably doesn't like it    send it to linux-kernel and Cc:  Alan Cox <alan@redhat.com> . Alan is better at responding to email, and will queue your patch and resend it to Linus periodically, so you can forget about it. He also serves as a good taste tester. If Alan accepts your patch, it's more likely that Linus will too. If he doesn't like your patch, you will probably get an email saying so. Expect it to be terse.                Why does the kernel tarball contain a directory called linux/ instead of linux-x.y.z/ ?        (DW)  Because that's the way Linus wants it. It makes applying many consecutive patches simpler, because the directory doesn't need to be renamed each time, and it also makes life easier for Linus.            What's the difference between the official kernels and Alan Cox's -ac series of patches?        (REG, contributed by Erik Mouw)  Alan's kernel can be seen as a test bed for Linus' kernels. While Linus is very conservative and only applies obvious and well tested patches to the 2.4 kernel, Alan maintains a set of kernel patches that contains new concepts, more and/or newer drivers, and more intrusive patches. If the patches prove themselves stable, Alan submits them to Linus to include them into the official kernel.              What does it mean for a module to be tainted?        (REG, contributed by John Levon)  Some vendors distribute binary modules (i.e. modules without available source code under a free software license). As the source is not freely available, any bugs uncovered whilst such modules are loaded cannot be investigated by the kernel hackers. All problems discovered whilst such a module is loaded must be reported to the vendor of that module,  not  the Linux kernel hackers and the linux-kernel mailing list. The tainting scheme is used to identify bug reports from kernels with binary modules loaded: such kernels are marked as ""tainted"" by means of the  MODULE_LICENSE  tag. If a module is loaded that does not specify an approved license, the kernel is marked as tainted. The canonical list of approved license strings is in  linux/include/linux/module.h .   ""oops"" reports marked as tainted are of no use to the kernel developers and will be ignored. A warning is output when such a module is loaded.  Note that you may come across module source that is under a compatible license, but does not have a suitable  MODULE_LICENSE  tag. If you see a warning from  modprobe  or  insmod  for a module under a compatible license, please report this bug to the maintainers of the module, so that they can add the necessary tag.       (KO)  If a symbol has been exported with EXPORT_SYMBOL_GPL then it appears as unresolved for modules that do not have a GPL compatible MODULE_LICENSE string, and prints a warning. A module can also taint the kernel if you do a forced load.  This bypasses the kernel/module verification checks and the result is undefined, when it breaks you get to keep the pieces.       (KO)  According to Alan Cox, a license of  ""BSD without advertisement clause""  is not a suitable free software license.  This license type allows binary only modules without source code.  Any modules in the kernel tarball with this license should really be  ""Dual BSD/GPL"" .            What is this about GPLONLY symbols?        (REG)  By default, symbols are exported using  EXPORT_SYMBOL , so they can be used by loadable modules. During the 2.4 series, a new export directive  EXPORT_SYMBOL_GPL  was added. This is almost the same thing, except that the symbol can only be accessed by modules which have a GPL compatible licence (note that this includes dual-licenced BSD/GPL code). This new directive was added for these reasons:    To clarify the ambiguous legal ground on which non-GPL (particularly proprietary) modules lie. A strict reading of the GPL prohibits loading proprietary modules into the kernel. While Linus has consistently stated that proprietary modules are allowed (i.e. he has granted an explicit exemption), it is not clear that he is able to speak for all developers who have contributed to the Linux kernel. While many think Linus' edict means that all contributed code falls under this exemption granted by Linus, not everyone agrees that this is a legally sound argument. The new  EXPORT_SYMBOL_GPL  directive makes the licence conditions explicit, and thus removes the legal ambiguity.    To allow choice for developers who wish, for their own reasons, to contribute code which cannot be used by proprietary modules. Just as a developer has the right to distribute code under a proprietary licence, so too may a developer distribute code under an anti-proprietary licence (i.e. strict GPL).     Note that Linus has stated that existing symbols  will not  be switched to GPL-only. Developers of proprietary modules for Linux need not fear. Furthermore, it is quite unlikely that Linus will look favourably upon the introduction of new core driver APIs which are restricted to GPL-only modules. This would not be in the best interests of Linux. Linus has forwarded me a   message  he sent to someone else to clarify his views.            Do I have to use BitKeeper to send patches?        (REG)  Absolutely not. Some kernel developers, including Linus and Marcelo, have chosen to use  BitKeeper  to manage their kernel source trees, but this does not mean you need to use BitKeeper yourself to maintain your trees or submit patches. Many notable kernel developers continue to maintain their source trees using other tools and techniques, and continue to send conventional patches.   If you want to use BitKeeper to manage and submit your code, the  Documentation/BK-usage  directory has some information and sample scripts which contain some useful suggestions. This documentation and code is not an endorsement of BitKeeper.            Why do some developers use the non-free BitKeeper? Isn't this against the spirit of Free Software?        (REG)  This depends on whose definition of ""freedom"" you are using, and what you think ""Free Software"" means. Some definitions are available at   http://www.gnu.org/philosophy/free-sw.html ,   http://www.debian.org/social_contract.html  and   http://www.opensource.org/docs/definition_plain.html .   If you subscribe to the view that all software wants to be free (and hence all non-free/proprietary software is evil), then yes, using  BitKeeper  is against the spirit of Free Software.   However, if you care more about freedom for software developers to develop software and use whatever tools they wish, then using BitKeeper  is  in the spirit of Free Software, since some developers feel that BitKeeper saves them a lot of time and effort. That is good for the development of Free Software.   This is an idealogical debate that some people will never agree on, and generates considerable flaming on both sides of the argument. Talking about it on the kernel development mailing list will not resolve the issue, no matter how loud or how many times you scream, so it's better that those who feel strongly about it debate the finer points of freedom elsewhere, and leave the development list for matters of actual  code development , which is what it is intended for.   Note that BitKeeper is not free software, but it may be used for Free Software projects at no charge, subject to the licensing rules ( bk help bkl  will show the licence, or you can go to   http://www.bitkeeper.com/Sales.Licensing.Free.html ).   If you are seriously concerned about the use of a non-free managment tool for a Free Software project, the most productive approach to changing the situation is to write a free replacement. This is most likely to take several years of work, particularly because Linus is very demanding. It is worth remembering that it took years from when BitKeeper was ""nearly good enough"" to Linus being satisfied with the feature set. A free replacement will face the same technical hurdles. Larry McVoy (founder of BitKeeper) stated on April 2002 what the development effort was:   it took 4 years of at least 6 day/week efforts by a team that varied in size from 3-8 engineers to get BitKeeper where it is today.              Who maintains the kernel?        (REG)  Originally, Linus Torvalds maintained the kernel. As the kernel has matured, he has delegated maintenance for older stable versions to others, while he continues development of the latest ""bleeding edge"" release. As of 27-MAY-2002, the following kernel versions are maintained by these people:    2.0    David Weinehall <tao@acc.umu.se>   2.2    Alan Cox <alan@lxorguk.ukuu.org.uk>   2.4    Marcelo Tosatti <marcelo@conectiva.com.br>   2.5    Linus Torvalds <torvalds@transmeta.com>               The kernel doesn't compile cleanly. What shall I do?        (REG)  First make sure you have the latest version of that kernel series. Perhaps a pre-patch already has a fix. If not, search the list archives for a fix. Don't contribute to noise on the list by asking a question that may already have been answered.   If the problem has not yet been fixed, try digging into the code yourself and post a fix to the mailing list. You'll be famous! Beware that making broken code compile just for the sake of a clean 'make bzImage modules' doesn't count as a fix, and your fix will be discarded, ignored or flamed.                Section 2 - Driver specific questions         Driver such and such is broken!        (RRR)  Try to be more specific. Please, provide information on your particular setup (see Qs How do I make a bug report?) Also see the Q: ""kernel x.y.z broken!"" below.       (ADB)  That's the worst possible way to start a thread. Please try to reach the author of the driver first and report the ""broken"" driver to him. Constructive criticism is welcome, usually.            Here is a new driver for hardware XYZ.        (REW)  Good work! Please try to find a few people that also have the XYZ hardware and have them test it on their configuration (e.g. by posting a message on a newsgroup). No it won't go in the standard kernel before some people have tested it.  Testing will take a while. In the mean time, kernel development will continue, and you will have to rewrite your patch for the most recent version before Linus might consider it.  As a whole new driver is most likely more than a few pages long, we'd prefer it if you would put the actual driver up for ftp instead of posting it to the list. Post the URL and the description that tells us what your driver does for which hardware.            Is there support for my card TW-345 model C in kernel version f.g.hh?        (REW)  First check if your card is detected at boot time. It usually is. Second see if you might need to configure something like modules.conf for your card. Third see if there is a file with the card name in the kernel sources. (e.g. you have a Buslogic card, and there is a buslogic.c file in the kernel sources, you're in luck.). Next, grep for the manufacturer name through ALL the kernel sources. And try the model number of your card. Also try to find the largest chip on your card and grep for the chip number on that thing. Realize that 53C80 chips might be named 5380 in the kernel. Other chips don't have their middle name removed.  Nothing yet? Now check DejaNews, using the same arguments you used to grep the kernel source. There are 99.99% chances that somebody has exactly the same card TW-345 model C.  Ok. That's what you can do without bothering anyone. If all this doesn't lead somewhere, you should really ask this question on a newsgroup like comp.os.linux.hardware.            Who maintains driver such and such?        (RRR)  Have a look at the /usr/src/linux/MAINTAINERS file, this is the most authoritative source. Also check the source code for the driver itself; in both cases, check the latest version of the kernel that you have available. Some drivers have specific Web pages and sometimes even a dedicated mailing list. Check those first. If you cannot contact the maintainer then  as a last resort  post a short message to the list. In any case, keep in mind that  maintainers are usually very busy people  and most of them work on Linux for free and in their spare time, so  don't expect an immediate response . Some maintainers get just too many mails in too small periods of time to be able to answer them all, so please be kind to them.            I want to write a driver for card TW-345 model C, how do I get started?        (REW)  Good initiative! First a piece of advise: are you up to this? Ten times as many projects like this get started as get finished. Also, make sure that you're not doing double work. Make sure that such a driver is not already available: read  Q/A 2.3  above...  First prepare yourself. Get the docs, read them (OK, you're allowed to start skipping stuff if you've gotten to the part ""detailed register descriptions""). Next, get the Linux kernel source, find a driver that drives similar hardware to the one you're going to work on, and read THAT. (I usually use the smallest one I can find: wc -l *.c | sort -n | head -4).  Ok. You've thought about it. Now the question is, do you have technical documentation for your card? You can reverse engineer the driver for MS operating systems, but having the documentation is MUCH easier.  In the dark old ages (70s to middle of the 80s), you got a complete technical description with every card you could get. This is no longer the case. Anyway, contact your vendor and politely ask them for the ""device driver kit"" or the ""technical manual"" for the card.  Try the head office and your local office at the same time. Local offices occasionally have bad photo copies that they give out before you get an official rejection from the head office. In that case whom you got the documentation from becomes confidential information. Don't put the guy's name in the source.  If you can't get the technical documentation, consider giving up and investing in a competitors product (and tell the manufacturer about this). Not given up yet? Ok. Next step is to find out what the DOS driver does. Try to get the card to work while you run it in a microsoft emulator (dosemu or WINE). This will allow you to program these tools to log the I/O accesses of the driver. This will give you a large list of I/O accesses that the driver did. If you're good, you might be able to see patterns, and deduce how the driver works. From there you might be able to write a working driver. Good luck! You'll need it.            I want to get the docs, but they want me to sign an NDA (Non-Disclosure Agreement).        (REW)  Some people find this a tremendous problem. Some companies just want to know who has the docs to their hardware, and don't mind if you write a GPL-ed driver. In that case, there is really no problem: just tell them what you intend to do and ask them to acknowledge in writing that they've understood what you're saying. In that case, you can get your driver into the standard kernel, but you cannot send out the docs to anybody who wants to work on the driver. They will have to rely on the comments in the source.  Other companies (just like Netscape) themselves signed NDAs that forbids them to disclose information to you.  Some really think that they have trade secrets in the interface towards the software, and intend to keep them secret. Those won't allow you to write a driver and then put the source on the net. Be careful with these.       (ADB)  The first and only NDA I ever received instantly found its way to the wastebasket. I would advise anybody who gets an NDA to refuse to sign it, if it refers to anything that may/will be put under GNU/GPL. Of course, for contract work this doesn't apply.            I want/need/must have a driver for card TW-345 model C! Won't anybody write one for me?        (REW)  Some Linux developers will settle for a beer, and develop the driver for you. Others want a ""free sample"" of the hardware and will then go ahead and write the driver.  If you need more than a few of the cards or you manufacture the cards yourself, you can consider paying one of the commercial Linux device driver companies to get a commercially backed, officially maintained device driver.            What's this major/minor device number thing?        (REG)  Device numbers are the traditional Unix way to provide a mapping between the filesystem and device drivers. A device number is a combination of a major number and a minor number. Currently Linux has 8 bit majors and minors. When you open a device file (character or block device) the kernel takes the major number from the inode and indexes into a table of driver structure pointers. The specific driver structure is then used to call the driver open() method, which in turn may interpret the minor number. There are two tables: one for character devices and one for block devices, each are 256 entries maximum. Obviously, there must be agreement between device numbers used in a driver and files in /dev. The kernel source has the file Documentation/devices.tex which lists all the official major and minor numbers. H. Peter Anvin (HPA) maintains this list. If you write a new driver (for public consumption), you will need to get a major number allocated by HPA. See the  Q/A on devfs  for an improved (IMHO) mechanism for handling device drivers.            Why aren't WinModems supported?        (REG, quoting Edward S. Marshall)  The problem is the lack of specifications for this hardware. Most companies producing so-called ""WinModems"" refuse to provide specifications which would allow non-Microsoft operating systems to use them.   The basic issue is that they don't work like a traditional modem; they don't have a DSP, instead making the CPU do all the work. Hence, you can't talk to them like a traditional modem, and you  need  to run the modem driver as a realtime task, or you'll have serious data loss issues under any kind of load. They're simply a poor design.       (REG)  Note that some people have been putting effort into reverse engineering some WinModems, so you may be lucky and find that yours is now supported. If not, it's time to get a refund and buy a real modem.   Note that modems have to be approved by the appropriate statutory or regulatory body for standards compliance (to make sure they don't send crap down the line and blow up the exchange). With WinModems, the driver software needs to be certified as well as the hardware. It's harder to get approval for Open Source drivers, since it usually costs money to obtain approval. Also, in theory, it's easier to modify an Open Source driver, so it would no longer be compliant. In reality, 99.999% of users don't even know there is source code for the driver, so ""Standards Compliance"" may well be a smoke-screen for manfacturers who don't want to bother with non-WinTel systems. If certification was the only problem, manufacturers could release binary-only drivers.       (DW) The good news is that a certain amount of WinModem hardware is now supported. The bad news is that that is just the tip of the iceberg. Although the WinModems can now be used, they have functionality similar to that of a sound card - all the modulation and demodulation has to be performed by the host CPU. Work is progressing on this front too - see  http://www.linmodems.org/  for more up-to-date information.              Modern CPUs are very fast, so why can't I write a user mode interrupt handler?        (REG, quoting Pete Zaitcev)  This is not a question of having enough CPU cycles to waste them on mode switches. Rather, the current Linux architecture does not allow it. User processes run with interrupts enabled. Thus, any interrupt handler must deactivate the particular interrupt source before a process is scheduled to run, or an interrupt storm results. The deactivation is done in a device specific manner, so at least a small device driver must be present in kernel mode.              Do I need to test my driver against all distributions?        (REG, MEA)  There are minor detail changes in between each kernel version (even in stable series), and depending on what configuration options are used (basically SMP or not), certain things like spinlocks may or may not reserve space in structures, and may or may not need to be called (are even optimized away in non-SMP systems), meaning that a binary driver compiled for SMP  might not  work with a non-SMP kernel. And vice versa.   Also different vendors tend to inject different things into their kernel patch-sets, which again may subtly change data layouts, etc. In stable kernel series great pains are suffered at maintenance so that data layouts of in-kernel APIs (and API calls themselves) are not changed. Nevertheless something may change making binary drivers to fail in mysterious ways.   Subtle memory changes may appear with i386-PAE mode (large memory machines which can't map all of RAM into the kernel at the same time).   Because of these differences, a driver compiled for one version of the kernel, or one vendor's kernel, is not likely to work with another kernel. Thus, if you are distributing a binary-only driver, you will have a significant support load compiling drivers for different kernels. If you are distributing a driver in source form, then, provided the driver is well-written (i.e. does not make assumptions about byte ordering or word sizes and uses standard kernel interfaces), the driver should be portable across kernel versions and architecture types. It will of course have to be compiled by end-users for their particular kernel. Distribution maintainers are likely to provide pre-compiled drivers, thus most end-users won't need to compile the driver themselves.               Section 3 - Mailing list questions   The linux-kernel mailing list is for discussion of the development of the Linux kernel itself. Questions about administration of a Linux based system, programming on a Linux system or questions about a Linux distribution are  not appropriate .     ""Test""  messages are  very, very  inappropriate on the lkml or any other list, for that matter. If you want to know whether the subscribe succeeded, wait for a couple of hours after you get a reply from the mailing list software saying it did. You'll undoubtedly get a number of list messages. If you want to know whether you can post, you must have something important to say, right? After you have read the following paragraphs, compose a real letter, not a test message, in an editor, saving the body of the letter in the off chance your post doesn't succeed. Then post your letter to lkml. Please remember that there are quite a number of subscribers, and it will take a while for your letter to be reflected back to you. An hour is not too long to wait.       (REG)  The essential point to remember when posting to the linux-kernel mailing list is that there are a lot of very busy people reading the list. No matter how important you think you are, it is most likely that there are many people on the list who are more important than you. ""Important"" is not measured by the amount of money you have, how much your question is worth to your company or how desperate you are for an answer, rather, it is measured by how much you contribute to the linux kernel.   With that in mind, you should make sure that you are not wasting the time of other people on the list.  Write for maximum efficiency of reading.  It doesn't matter if it takes twice as long for you to compose a more readable message, if it halves the time a hundred key kernel developers spend trying to decode your message. Ignoring good taste and consideration is most likely to result in you being ignored.       How do I subscribe to the linux-kernel mailing list?         (ADB)  Think again before you subscribe. Do you really want to get that much traffic in your mailbox? Are you so concerned about Linux kernel development that you will patch your kernel once a week, suffer through the oopses, bugs and the resulting time and energy losses?  Are you ready to join the Order of the Great Penguin, and be called a ""Linux geek"" for the rest of your life? Maybe you're better off reading the weekly ""Kernel Traffic"" summary at  http://kt.zork.net/ .  OK, if you still want to read linux-kernel in its full glory, send the line ""subscribe linux-kernel your_email@your_ISP"" in the body of the message to majordomo@vger.kernel.org (don't include the "" characters, and of course replace the fake email address with your true address).  You have been warned!        (MEA)  Quite often I see things like what this summary report tells:  FAILED:   <smtp cedar-republic.com edmond@cedar-republic.com 60000>: ...\         <<- RCPT To:<edmond@cedar-republic.com>         ->> 550 <edmond@cedar-republic.com>... we do not relay   Feeding this address to a page at URL:  http://vger.kernel.org/mxverify.html   yields information that ONE of their backup MX servers refuses to send email thru to them.  Thus whenever all other servers fail to be reachable, that one ruins their email connectivity.   Do make sure YOU don't have this very problem!  See   http://vger.kernel.org/majordomo-info.html  for information on Majordomo.            How do I unsubscribe from the linux-kernel mailing list?        (ADB)  At the bottom of each and every message sent by the linux-kernel mailing list server one can read:  -   To unsubscribe from this list: send the line ""unsubscribe linux-kernel"" in   the body of a message to majordomo@vger.kernel.org   See   http://vger.kernel.org/majordomo-info.html  for information on Majordomo.            Do I have to be subscribed to post to the list?        (ADB)  No, you don't have to be subscribed to the list to post to it. The address of the list is linux-kernel@vger.kernel.org.  And you should indicate on your message that you wish to be personally CC'ed the answers/comments posted to the list in response to your posting.       (REG)  It is, however, generally considered good netiquette to be subscribed to a list (or a newsgroup for that matter) and lurk for a while before posting. That way you can learn what's considered an appropriate post and what isn't.  Don't treat the list as your personal helpdesk. Remember that the list is a community.            Is there an archive for the list?        (REG)  There are many. Here are some:       http://www.uwsg.indiana.edu/hypermail/linux/kernel/  has a search by word/subject capability.       http://marc.theaimsgroup.com/?l=linux-kernel  keeps a collection of Linux related list archives.       http://groups.google.com/groups?hl=en&q=fa.linux.kernel&meta=  is a Google interface to the  fa.linux.kernel  newsgroup, which is in turn fed from the mailing list     Here are some more resources:     ""Kernel Traffic"" at  http://kt.zork.net/  provides a weekly summary of the discussions on the list, and archives previous summaries.              How can I search the archive for a specific question?        (ADB)  Use simple keywords which refer to the issue that matters to you. For example, if you are investigating an oops that happens whenever you plug in a network adapter NIC-007, use ""NIC-007"" or ""oops NIC-007"". As soon as you have found a link to a message that interests you, try to follow the thread. Remember that you will almost always get more information by carefully searching the archive than by posting a question to the list itself.            Are there other ways to search the Web for information on a particular Linux kernel issue?        (ADB)  Sure. Before you check the list archives, you can search DejaNews and AltaVista (simultaneously, if your browser allows you to open various windows). You can also follow some links on the  Linux Documentation Project  site.            How heavy is the traffic on the list?        (TAC)  List traffic is very heavy; the average number of messages per day is 290 [10/2002 - 04/2003]. That's over 8,700 message a month!!!       (ADB)  You really don't want to read each and every posting to the list. If you are concerned with list traffic, I suggest you temporarily try the  digest lists , which will be much easier on your mailbox (thanks to A. Wik for this suggestion).       (REG)  There is a weekly summary called ""Kernel Traffic"" at  http://kt.zork.net/ , which can save you a lot of time.            What kind of question can I ask on the list?        (ADB)  The basic rule is to avoid asking questions that have been asked before, or that are irrelevant to other list users, or that are off topic. Please use your good sense.       (REG)  Remember that this is a list for the discussion of  kernel development . If you have some ideas or bug reports to contribute, this is the place. User space issues are not appropriate for this forum. If you find a bug in the C library or some application, it doesn't belong on linux-kernel.            What posting style should I use for the list?        (REG, contributed by thunder7@xs4all.nl)  When following up a post on the kernel mailing list, please think before you quote. Since everybody else on the list also got the original post, don't quote it entirely. Highlight only the points that you really need to understand your arguments. Make sure the quoted part is recognizable as such, by ensuring each quoted line starts with a > (or more >>, in case of multi-level quoting).  Don't quote signatures, entire patches, entire config files or entire posts. Don't quote the standard signature.  The kernel-list is crowded enough already, let's take care!       (REG)  Be aware that your message is far more likely to be deleted without being read if you have too much quoted material before your reply.       (REG)  And  please  reply  after  the quoted text, not before it (as per  RFC 1855 ). It's very confusing to see a reply before the quoted context. And it's embarrassing: it makes you look like a newbie. Change your mailer if necessary, if the one you have makes it hard to do reply-after-quoting.   I know some people like to quote the entire message they are replying to, so they put their reply right at the top so people won't give up after the first page of quoted material.  Don't do it . It's annoying. Just learn to stop quoting everything. No-one wants to see it all anyway (list archives allow people to see everything if they missed it). You're not helping yourself anyway, as you're more likely to be ignored if you reply-before-quoting.       (REG)  Please don't use tabs or multiple spaces to quote text. Use the "" >  "" sequence instead. Using whitespace to quote text makes it difficult to differentiate between what's quoted and the reply. And don't try to be cute or ""different"" and use some other character like "" } "" or whatever. Again, it's confusing. It wastes people's time.  Write for maximum efficiency of reading .       (REG)  Please try to have halfway reasonable spelling and grammar. When reading text with really bad spelling or grammar, people stall while trying to parse your post. Don't think you're being ""artistic"" by stripping out all punctuation characters. Linux-kernel is not an online gallery, it's a communications medium.  Write for maximum efficiency of reading .       (REG)  Please don't have long, inflammatory, controversial or offensive signatures (see  RFC 1855 ). The rule of thumb is no more than 4 lines of 80 characters each.       (PG)  Don't attach huge files to your post. One major culprit is people attaching their kernel  .config  file to their post. These can be in excess of 1000 lines, and will grow more as kernel options are continuously added.  If the contents of your .config file are relevant to your post then attach the output of  grep ^C .config  or  grep ""=[y|m]"" .config .       (MEA)  Some structures are forbidden as they appear to be used way too much in SPAM mail. Specifically, messages with  Content-Type: text/html  either as the only (primary) message, or as ANY of component sub-messages are considered spam, and rejected outright without any info to the sender.   Also, any message with header matching the regular expression:  X-Mailing-List:.*@vger.kernel.org  is considered to be LOOPING somewhere, and is thus diverted to list-owner.            Is the list moderated?        (ADB)  No, the linux-kernel list is not moderated.            Can I be ejected from the list?        (ADB)  It is technically possible, but I have never heard of anybody being ejected from the linux-kernel list.       (REW)   But   you will if you post questions or answers that are asked and answered on this FAQ. ;-)       (MEA)  Oh definitely, all you need to have is malfunctioning email system which does not accept email to you -- e.g. check your domain backup MX servers by using the tool at:    http://vger.kernel.org/mxverify.html    It is known that over the years the keepers of vger's lists have removed some people after getting sufficiently annoyed with them, but there you really must try to exceed yourself, and will likely get lots of peer pressure before getting kicked off.   Another way to quickly get yourself removed is to use the program called ""fetchmail"" -- which in itself is not all that bad, but apparently it is far too easy to accidentally re-post email to addresses which the visible RFC 822 headers contain -- that is, what the original sender used, like:  To: linux-kernel@vger.kernel.org  The result is duplicate messages on the mailing list. If you let that happen, you can be quite sure that your subscription will be removed as soon as possible.            Are there any implicit rules on this list that I should be aware of?        (ADB)  Here are a few implicit rules which you should be aware of:      Stick to the subject. This is a Linux kernel list, mainly for developers.      Use English only!      Don't post in HTML format! If you are using IE or Netscape, please turn off HTML formatting for your posts to the kernel list.      If you use that other OS, make sure your mailer doesn't use Charset=""Windows*"" as those posts will be blocked.      If you will be asking a question, before you post to the list, try to find the answer in the available documentation or in the list archives. Just remember that 99% of the questions on this list have already been answered at least once. Usually the first answer is the most detailed, so  the archives contain far better information  than you will get from somebody who has answered the same question a dozen times or more.      Be precise, clear and concise, whether asking a question or making a comment or announcing a bug, posting a patch or whatever. Post facts, avoid opinions.      Be nice, there is no need to be rude. Avoid expressions that may be interpreted as aggressive towards other list participants, even if the subject being treated is particularly relevant to you and/or controversial.      Don't drag on with controversies. Don't try to have the last word. You will eventually have the last word, but meanwhile you'll have lost all your sympathy credit.      A line of code is worth a thousand words. If you think of a new feature, implement it first, then post to the list for comments.      It's very easy to criticize someone else's code, but when you write something for the first time, it's not that simple. If you find a bug, a mistake, or something that could be perfected, don't immediately post a comment such as ""This piece of code is crap, how did it get into the kernel?"".  Contact the author of the code, explain the issue, and try to get the point across in a simple, humble way. Do that a few times and you will get a lot of credit as a good code debugger. Then when  you  write a piece of code people will pay attention to you.      Don't flame beginners that ask the wrong questions. This adds noise to the list. Send them a private mail pointing them to a source of information e.g. this FAQ.            (MEA)  If you post HTML, your email won't make it to the lists (see  section 3.9 ).       (REG)  Don't post post  any  religious or political material, including in your signature. Doing it in the body of a message will anger people, as it's always off-topic and is a waste of bandwidth (remember that even in the 21st century, many people are still being gouged by the second for bandwidth by their ISP or telco or both).   Including this unwanted material in your signature is less obnoxious, but is pointless at best (preaching to the converted). Most people will ignore it, and many will be prone to ignore the content of your message, recognising you are a wanker. If you want to be taken seriously, leave the soap-box at home. Limit your posts to technical issues.            How do I post to the list?        (REG)  You send a message to the address  linux-kernel@vger.kernel.org             Does the list get spammed?        (ADB)  The linux-kernel list is no longer spammed, you will rarely if ever find a commercial posting to the list itself. OTOH once you post to the list, expect to get a few undesirable mails in the following days. Unfortunately some people watch the list and think it's a good idea to pick names from it. There are many ways to avoid spam, check the dedicated anti spam sites on the list. I learned many things this way.       (REW)  Although the list maintainers do their best to keep the list spam free, it is not possible to do this 100%. Some of the good kernel development people cannot keep up with the volume on linux-kernel. But they do occasionally post. Therefore we need to keep the submissions open for ""everybody"". Some of the other important people have two or three Email addresses. They too need to post from different addresses. Consequently something that looks like a submission from a valid return address tends to go on the list. There is nothing an automated filtering system can do about it.   The end result is about one spam a month. It happens. The maintainer will get a flood of mail about it and he will block the domain it came from. Please don't bother the list about it, don't add noise.  Don't post  ""This guy is a jerk if he spams this list"".  Don't post  ""I traced him, you can mail bomb him at this address"".  Don't post  ""I traced him, bother his postmaster at such and such"".            I am not getting any mail anymore from the list! Is it down or what?        (ADB)  Majordomo is an intelligent mail list server. If for any reason your email address is unavailable, after some retries you will be automatically unsubscribed.       (REW)  On the other hand, accidents with the mailing list server have happened. These have wiped out the whole subscription list once or twice. Just resubscribe. Majordomo will get you a nice note saying you're still subscribed if suddenly everybody went dumb.  Don't post  ""Just testing: Is the list working? I didn't get any mail for a few days now"".       (MEA)  You may get unsubscribed because MTAs relaying traffic to you get bounces for some reason. One thing to verify is that your email routing data in the DNS is valid, e.g. feed your address to the input box at:   http://vger.kernel.org/mxverify.html        (MEA)  VGER and/or one of its fanout boxes may be in overload. Usually system keepers notice the situation, and it becomes fixed within 1-2 days without messages being lost, but we don't track the entire world. Asking help from   postmaster@vger.kernel.org  could expedite the issue. Asking help on lists WILL NOT help, doing so just puts more load on the system!            Is there an NNTP gateway somewhere for the mailing list?        (RRR)  Yes there is the newsgroup  fa.linux.kernel , but you can only read the mailing list there, not post directly. Posting to the list must go by email to  linux-kernel@vger.kernel.org .   Here's the dejanews URL, if your NNTP host don't have the group   http://www.dejanews.com/bg.xp?level=fa.linux.kernel        (REG)  Unfortunately not all news servers have the fa heirarchy. You can access the  fa.linux.kernel  by going to   http://groups.google.com/groups?hl=en&q=fa.linux.kernel&meta=             I want to post a Great Idea (tm) to the list. What should I do?        (REG)  OK, that's great. Now:      First make sure that your idea is relevant to kernel development. Perhaps your idea is better implemented in the C library, or perhaps in a new library? Before posting to linux-kernel, be sure it really  is  a kernel issue.      OK, so you have this great idea for the kernel. Are you sure someone hasn't thought of it before? Reading all of this document is a good starting point. Also  search the mailing list archives  to see if that topic has been raised before.      Now you have verified that you have an idea none has suggested before. For the best response,  code up an implementation/kernel patch  and post that to the kernel list when you announce your idea. If you provide code, you can be sure someone will try it out and give you comments. If you don't know anything about kernel hacking, this is a good time to start learning:-) By the time you've implemented your idea, you'll be able to call yourself a Linux Guru.      If you really can't code something up, but still would like your idea implemented, post a message to the kernel list. Be as clear and precise as possible, so that people can understand your idea quickly. If you are lucky, someone who likes your idea may find the time to implement it. If nobody steps forward to implement it, you're out of luck: remember, we're all volunteers and we all have too many things to do as it is.      If you get a negative response to your idea, don't get offended, after all, we all have different notions on what is a Good Idea (tm) and a Bad Idea (tm). If someone is rude to you, please resist the temptation to carry on a war on the list. Instead, email them privately saying that you don't like their rudeness. If everybody is polite, but just strongly disagrees with your idea, be careful not to push it too hard. If people haven't understood the point you are making, try explaining it a different way. But if people understand your idea but maintain it is flawed, it's time to stop pushing it. Pushing harder will just get you ignored.      If you're convinced you're right, despite what everybody else says, stop talking about it and implement it! If you're right, you'll have the last laugh.         (ADB)  Good code (i.e. documented, elegant, efficient) and some benchmarking data showing your Great Idea performs well will go a long way to show you're right.            There is a long thread going on about something completely offtopic, unrelated to the kernel, and even some people who are in the ""Who's who"" section of this FAQ are mingling in it. What should I do to fight this ""noise""?        (REW, ADB)  Ignore it.       (REG)  Don't send a response to the kernel list under any circumstances. If you feel compelled to respond, do so privately informing the person that the message was offtopic. Or set up a procmail recipe to drop all messages for that thread: that way you'll never see the thread again.            Can we have the  Subject:  line modified to help mail filters?        (REG)  The usual proposition is that a string like  [LINUX-KERNEL]  is prepended to the subject line.   This question has been raised many times before, and the answer has always been ""no"" or ""there are better ways to filter email"". The majority of the developers, and all (?) of the list maintainers take this position. Some of the reasons are:    It would increase the size of the Subject: line. This is a problem, as it limits the amount of useful information that can be seen in the Subject: line, making it harder to scan through a list of subject lines looking for interesting subjects.    It doesn't work for cross-posted messages, as the subject line for a single email will change depending on which list it was sent via. Not only can this confuse simple-minded filtering recipes, it can also break threaded mail readers (people may end up reading the same message twice).     The correct way to filter is to base your recipe on the  X-Mailing-List:  line, which should always have ""linux-kernel@vger.kernel.org"".      An example procmail recipe would look like this:  # Linux-kernel list :0: /var/lib/emacs/lock/!home!fred!mfilter!linux!kernel * ^X-Mailing-List:.*linux-kernel@vger\.kernel\.org /home/fred/mfilter/linux/kernel    People subscribed to linux-kernel-digest@lists.us.dell.com, which uses GNU Mailman, may want to use something like this:  # linux-kernel-digest :0 * ^X-BeenThere: linux-kernel-digest@lists\.us\.dell\.com /home/fred/mfilter/linux/kernel-digest    People using mailagent might try this in their .rules file (thanks to Martin Smith <martin@sharrow.demon.co.uk>):  To CC: /linux-kernel@vger.kernel.org/ { SPLIT -adi ~/Kernel }   Similarly to procmail you can omit the mail folder from the split command. This causes the split messages to go back into the mailagent queue for further processing.   Most mailers with filtering capabilities can be similarly configured. If not, then you can simply install procmail. If perchance you're running a damaged OS that can't filter properly, and there is no procmail port for it, then you should either upgrade, or accept that you won't be able to filter linux-kernel. Don't bother asking for a subject line modification.            Can we have a Reply-To: header automatically added to the list traffic?        (DW)  Some mailing lists automatically add a  Reply-To:  header to the mails which go through them, forcing people to reply to the list, rather than replying personally to the original poster. This is a bad idea for many reasons which won't be listed here. See Chip Rosenthal's excellent summary    Reply-To:  Munging Considered Harmful  for more explanation.            Can I post job offers/requests to the list?        (REG)  Of course not! This is a technical development list, not a job exchange. If you want to join a job exchange list, send  subscribe linuxjobs  in the  body  of the message to  majordomo@eax.com  by executing the following command:    echo ""subscribe linuxjobs"" | mail majordomo@eax.com    To send messages, email to  linuxjobs@eax.com             Why do I get bounces when I send private email to some people?        (REG)  This could be for a variety of reasons, such as temporary problems with mail delivery. Your email may also be blocked (permanently rejected) by that individual or their ISP. This often happens if you send email from a machine or domain which is listed in the MAPS RBL, DUL and ORBS lists. These lists have been set up to protect people against spam. See  http://www.mail-abuse.org/  and  http://www.orbs.org/  for more information on these lists.    NOTE  that these lists aren't trying to block you personally, they are trying to block known spammers or spammer-friendly sites (RBL and ORBS), or uncontrolled dial-up users (DUL). If you are being blocked, it probably means you have the misfortune to be using an ISP that is not a good net citizen and thus has been added to the RBL or ORBS lists. In some cases, you may be blocked because your ISP has volunteered their dial-up IP address ranges to the DUL, in which case you should be using their approved mail relay rather than sending email out directly from your host.   You must  NOT  post a message to the kernel list about this, as the people there cannot and will not help you. Nor should you use the list as a means of getting a message through to the individual you are trying to contact. This is not what the list is for.   If you are intent on making a fool of yourself in public, follow the same path as too many others before you, and complain on the kernel list about how unfair it is that you are being blocked because your ISP is bad.  Expect sympathy from some, flames from others and silence from most. The net gain will be that your mail will still be blocked by the anti-spam lists, many people will ignore you in future emails (because you've made a fool of yourself), and you may find yourself in the killfiles of some people (i.e.  you personally  are being blocked because some people are fed up with you and don't want to hear anything more from you).   If you actually want your mails to no longer be blocked, get your ISP to clean up their act, or switch to a decent ISP. If you are required to use your ISP's mail relay, but it is crippled somehow, complain to your ISP or switch to one with competent staff.   If your ISP is unresponsive and you don't have an alternative ISP you could switch to, you'll just have to accept that an increasing fraction of people will block your email (as more and more people subscribe to the anti-spam lists). There's no point in shouting at the people who are defending themselves against spam (no-one is obliged to receive any and all email), go pester the spammers instead.            Why don't you split the list, such as having one each for the development and stable series?        (REG, by ""hacksaw"")  It's true that the lkml is a high traffic list and can be a lot to handle. However, splitting the list wouldn't help, since most developers would just subscribe to both lists. In fact, there would then be extra traffic, because of the number of issues that hit both the development and stable kernels, or even farther back!                Section 4 - ""How do I"" questions         How do I post a patch?        (ADB)  I assume you made the patch following the general instructions found  above . Now write a short post describing your patch, the version of the kernel it applies to, your tests, the feedback you would like to get, etc. This should fit in 10 lines. Attach your patch and a one line README file describing it very succinctly, and mentioning your name and email (either as two ASCII files or as a MIME encoded tarball). In the subject of your post, put: [PATCH] <the driver name or piece of code patched>, kernel <kernel version>. Send. Wait.   The small README file insures that your patch will not start circulating around the net without people noticing your name. If you don't care about copyright and/or your patch is trivial, you can skip tarring the files, just gzip the patch file and attach it to your post.       (PG)  If your patch is on the large size (say larger than 500 lines) consider posting a URL pointing to the patch along with the patch description, instead of the whole patch. If you don't have a WWW site handy to put the patch on, then at least gzip it prior to attaching it to your post/patch description.       (REG)  Note that Linus does not read linux-kernel very much. So if you want him to see a patch, you will need to send it to him directly (say by Cc:ing him if you post to the list). Note that Linus likes to be able to read patches in plain ASCII, so anything that is uuencoded or MIMEd is likely to go straight to the bit-bucket. If because your patch is large you only send a URL, send a plain-text copy to Linus privately.   Also note that Linus drops patches silently when he is too busy (which is always:-), so if you don't see it in the next kernel patch, send it again. Oh, and don't expect him to tell you he's applied the patch, either.            How do I capture an Oops?        (REG, quoting Keith Owens)  If an Oops is recoverable then the text appears first in the kernel message buffer (/proc/kmsg).  You can use the dmesg command to print the contents but most of the time klogd and syslogd will automatically capture the Oops and write it to your log files.   Sometimes an Oops is so bad that the kernel is completely hung.  When this occurs, almost anything that requires kernel support is also dead.  In particular most interrupt driven subsystems are unusable, especially after the dreaded "" Aiee, killing interrupt handler "" message.  Since most disk controllers use interrupts, no disk I/O is possible so the Oops does not get written to the log files.  The same problem applies to logging over the network, most network cards require interrupt handlers.   In a complete hang, you have three options.     Write the Oops down by hand from the screen and type it in after you have rebooted.  This is the only option if you have not planned for a kernel hang.     If you plan ahead and install a serial console linked to another machine (read  linux/Documentation/serial-console.txt ) then you can capture the Oops report on the other machine. By far the easiest and most reliable option.     Since kernel 2.3.10 it has also been possible to use a parallel port line printer as a console. You can either attach a real printer, or another computer with EPP (Enhanced Parallel Port) support, which pretends to be a printer.     There have been patches on linux-kernel to save the log somewhere in hardware.  Unfortunately these patches are very hardware specific. Search the l-k archives for ""Oops assist"", ""OOPS output over reboot"" and ""KMSGDUMP"".  Most of these patches require that the keyboard still works and even that can be useless when the kernel hangs.      Other operating systems can save the log even when the machine hangs, why doesn't Linux?  Any OS that can save the log after a catastrophic kernel failure must do so without kernel support, that typically means using the underlying hardware.  Alas the ix86 hardware does not provide enough support for this, in particular most BIOS will clear memory on reset, destroying any data in storage.          How do I post an Oops?        (ADB)  Assuming you have found a genuine Oops (those are rare nowadays, but they happen), you should post the  relevant  portions of your system log, kernel configuration file and kernel symbol map, plus a description of your hardware and the circumstances under which the Oops occurred. Can the Oops be triggered by any particular method? Did it happen after you changed any part of your hardware configuration?  Don't post your oops report before you have checked linux/Documentation/oops-tracing.txt, the relevant paragraphs in linux/README, the ksymoops C program in linux/scripts/ksymoops which has another README, and the gdb man and info pages (thanks to Paul Kimoto for this tip). These documents describe the basic procedure for kernel oops tracing. Good trace info makes it much easier to understand and solve apparently weird oopses.       (REG)   Don't  even bother posting an Oops if you haven't run it through  ksymoops  to decode the symbol addresses. The report will be ignored because it contains too little useful information.   Make sure you copy the correct  System.map  file into  /boot  or into the modules directory, otherwise you will get incorrect results.       (REG, quoting ""The Doctor What"")  There are some situations that make a kernel oops useless.  The two most obvious are if your are overclocking your CPU or running VMWARE's vmmon.  The reason is that overclocking can introduce random bit errors, while VMWARE's vmmon has the ability to (and does) change parts of the kernel.  In both cases, data in the kernel, as reported by the oops, won't be useful.            I think I found a bug, how do I report it?        (ADB)  A bug differs very slightly from an oops, actually. An oops is when the kernel detects that something has gone wrong. A bug is when something (in the kernel, presumably) doesn't behave the way it should, either with a driver or in some kernel algorithm. If you can detect this misbehaviour, you may or may not be getting an oops.  Perhaps the most important step is to determine under which conditions this misbehaviour can be triggered, and whether it is reproducible.            What information should go in a bug report?        (ADB)  Does it affect system security? Is it related to a specific driver/hardware configuration? Did you manage to identify the piece(s) of kernel code concerned? It really depends on the kind of bug you found.       (TYT)  Please follow general good bug reporting guidelines: remember, the developers don't have access to your system, and they're not mind readers.  Tell us which kernel version, and what your hardware is (if you're not sure, more detail is better than less).  At the very least, tell us what processor and motherboard you have, how much memory, how many and what kind of disks (IDE, SCSI, etc.), what kind of disk controllers you have, what other expansion boards (specify whether they're PCI or ISA or some other bus).  Also useful: what version of gcc and binutils were used to compile the kernel.   Try to find a simple, reliable way to trigger the problem.  Telling the developer that they have to set up some complicated application environment (especially if it involves some ghastly expensive proprietary software like SAP or Oracle :-) may cause the developer to hit the 'd' key and move on.   In general, raw data is better than jumping to conclusions.  If you want to give your guesses in your bug reports, they're of course welcome, but this is  not  a substitute for raw data.  Many problems are not what they first seem.  A hardware problem can masquerade as a VM problem.  A device driver or VM problem can cause the filesystem code to notice a discrepancy, and flag a warning.  Even if you're  sure  that the problem isn't a hardware problem, or some other theory that the developer advances, the scientific method demands that you do a test to rule these sorts of things out. Sometimes, you will get surprised.....   If you get a kernel oops message, it's useless unless you give us the proper symbolic information.  This used to mean sending relevant pieces out of System.map.  Fortunately, with the latest syslogd/klogd, this is much simpler (check the man page of klogd to see if your version has this feature; if it doesn't, you should upgrade to the latest version, and probably to a modern distribution).  Make sure that you have the System.map file installed the appropriate place so that klogd can find it (the standard search path is in the /boot, /, and /usr/src/linux directories).   If the system oops and then dies without a chance for klogd to record the information into a syslog file, copy down the oops message exactly, and then use the ksymoops (see the man page) to get the symbolic information out. Remember, the raw numbers by themselves will generally not be useful.   If you can, try to isolate the problem to a specific kernel version. Knowledge that it worked in version 2.2.17, as well as 2.3.0-test6, but it stopped working in 2.3.0-test7-pre1, is extremely helpful, and will save developers a lot of time.  (If you're comfortable disecting patches, fell free, taking apart the individual file changes and try to isolate to a particular change.)       (REG)  You did of course read  REPORTING-BUGS  from the kernel source tree first, didn't you?            I found a bug in an ""old"" version of the kernel, should I report it?        (CP)  Only if it hasn't been fixed yet. The best thing to do is to try to repeat it with a new version of the kernel. If not, you have to figure out if it's been fixed yet. The kernel release announcements and patch descriptions from  Jitterbug  are also useful. Failing that, look for discussion of the bug in linux-kernel and check the patches between your kernel and the latest ones for relevant changes.  If you can't find your bug mentioned, and you're not running a truly ancient kernel, posting a bug report is worthwhile. You can probably expect a request of the form ""try it with the latest kernel"" or ""try it with this patch"" in response. If there's a reason why you can't run the latest kernel (like it's your main dialin server and you don't want to mess with it), saying it in your original report will save some explaining later.            How do I compile the kernel?        (REG)  See the  Kernel HOWTO  for some information. Also, there are people at  http://www.kernelnewbies.org/  who are usually willing to help.       (William Stearns)  The  Buildkernel  script walks you through an entire kernel build, including downloading the necessary files, patching the source, building the kernel and modules, installing the lot into lilo, and optionally building pcmcia-cs, cipe, and freeswan code for that kernel.  Download and install either the tar or rpm version of the script, and run one of the following commands:   buildkernel NEWESTSTABLE #To build the most recent stable kernel. buildkernel NEWESTBETA   #To build the most recent beta kernel. buildkernel 2.4.7        #If you know the version you wish to build.                 Section 5 - ""Who's who"" questions         Who is in charge here?        (ADB)  Do you mean ""Who takes decisions relative to the mailing list?"" or do you mean ""Who takes decisions relative to the Linux kernel""? If the former: there is relatively little to decide when it comes to the mailing list. Majordomo, once correctly setup, will manage the list in an autonomous fashion. In any case, you can always reach the Majordomo-owner for the list, if you have a very specific question about the list mechanism itself. When it comes to kernel development management and decision making, see  the answer to Question 7.8  below.            Why don't we have a Linux Kernel Team page, same as there are for other projects?        (ADB)  Perhaps because there is no Linux Kernel Team, per se. Also because so many people contributed to the Linux kernel that it would be a tough task to setup and maintain such a page. Finally, although this is not a rule, most Linux kernel contributors prefer to keep a low profile, for various reasons.            Why doesn't <any of the below> answer my mails? Isn't that rude?        (ADB)  Probably because of sheer lack of time to answer each email that gets sent to them. What would you do if you got 1000 mails in your mailbox, from one day to the next? They don't mean to be rude, however.  One hint:  if you attach to your mail a genuinely useful piece of good quality code that you wrote, there are good chances that it will be answered (choose a good subject line, too). If you ask a dozen beginner's questions, the truth is, there are zero chances that you will get even the simplest reply pointing to some source of information.  Aside from that, you may get ""mail rejected"" error messages if you try to contact some major contributors of the list. It is due to the spam filtering systems used by them. Please complain about it to your ISP and  don't post to the list about spam !!  .       (REG)  Some people also have very aggressive mail filtering which rejects (non-list) messages from people they don't know, asking for a re-send with a password (this stops SPAM dead). If you mail to someone and receive such an automatic response, don't get upset. Remember, a person's mailbox is their personal property.   Also, some people maintain ""guru lists"" and only read posts on linux-kernel by someone on their guru list, other people's posts go to  /dev/null . This is done because there are too many questions asked on linux-kernel which shouldn't be (which is why people should read this FAQ first!), and people can't cope with the load. If you post to the list and want make sure a specific individual will see the message,  Cc:  that person.            Why do I get bounces when I send private email to some of these people?        (REG)  Some people, like Alan Cox, bounce messages. Read  this  to find out why and what you can do about it.            Who is Matti Aarnio?         (MEA)  He is principally a  ZMailer  hacker, and a co-postmaster of vger.kernel.org.   Sometimes he finds also cycles to hack on the kernel, and you see some patches from him.  (e.g. initial work on Large File Summit; files over 2G in size, was his)           Who is H. Peter Anvin?      Who is Donald Becker?       Who is Alan Cox?         (AC)  Alan Cox supervises the 2.0.34/35/36 kernel releases, works on the Mac68K port, the SGI port, 2.0 networking, modular sound, video capture and helps collect up and sort patches to the kernel. He gets to do all this and sleep because the nice guys at  Red Hat  pay him to hack Linux.            Who is Richard E. Gooch?        (REG himself)  ""I've written various utilities and kernel patches which you can find  here  including the MTRR, devfs and fastpoll patches. My PhD in Computer Science was on the topic of  Astronomical Visualization  , which is my current research interest. This is what I work on when I don't get distracted by kernel hacking. See my  home page  to find out more about me.""            Who is Paul Gortmaker?        (ADB, OK'ed by Paul)  Paul has contributed various pieces of kernel code over the last few years, among other things the Real Time Clock driver. He is also the maintainer of the 8390 based network drivers (NE-2000, etc.), and wrote the Linux Ethernet HOWTO and the Boot-Prompt HOWTO.           Who is Mark Lord?      Who is Larry McVoy?       Who is David S. Miller?        (DSM)  David Miller is mainly known for the porting work he has done, primarily for the 32-bit and 64-bit Sparc platforms although he has made significant contributions to the MIPS effort as well. He is also the current maintainer of the IP networking layer in the kernel and likes to address general performance and scalability problems all over as his time permits.           Who is Linus Torvalds?       Who is Theodore Y. T'so?       ( TYTSO )  Theodore Ts'o  has over the years written, rewritten, or supported Posix Job Control, the high level tty driver, the serial driver, the ramdisk support, e2fsck/e2fsprogs, and other bits and pieces of code in and near the kernel. He is currently a member of the Technical Board of Linux International. His day job at MIT is concerned with  Kerberos  and other network security and I/T architecture issues. He is also a member of the  Internet Engineering Task Force , where he serves as a member of the  Security Area Directorate .            Who is Roger Wolff?        (REW himself)  ""I wrote the kmalloc that still drives linux-2.0.x. I wrote the Specialix and Olicom device drivers. I currently write Linux device drivers for a living.  Contact me  if you need one.""              Other OS developers  Rogier Wolff  (REW)  suggested we add a section on OS developers who influenced/preceded the design of Linux.        Who is Prof. Douglas Comer?        (Prof. Comer)  Dr. Douglas Comer is a full professor of Computer Science at Purdue University, where he teaches courses on operating systems and computer networks. He has written numerous research papers and textbooks, and currently heads several networking research projects.   He has been involved in TCP/IP and internetworking since the late 1970s, and is an internationally recognized authority. He designed and implemented X25NET and Cypress networks, and the Xinu operating system. He is director of the Internetworking Research Group at Purdue, editor of Software - Practice and Experience, and a former member of the Internet Architecture Board.  Dr. Comer completed the original version of Xinu (and wrote ""The Xinu approach"" book) in 1979. Since then, Xinu has been expanded and ported to a wide variety of platforms, including: IBM PC, Macintosh, Digital Equipment Corporation VAX and DECStation 3100, Sun Microsystems Sun 2, Sun 3 and Sparcstations, and Intel Pentium. It has been used as the basis for many research projects. Furthermore, Xinu has been used as an embedded system in products by companies such as Motorola, Mitsubishi, Hewlett-Packard, and Lexmark. There is a full TCP/IP stack, and even the original version of Xinu (for the PDP-11) supported arbitrary processes and network I/O.            Who is Richard M. Stallman?        (RMS)   Richard Stallman  is the founder of the  GNU project , launched in 1984 to develop the free operating system GNU (an acronym for ""GNU's Not Unix""), and thereby give computer users the freedom that most of them have lost. GNU is free software: everyone is free to copy it and redistribute it, as well as to make changes either large or small.  Today, Linux-based variants of the GNU system, based on the kernel Linux developed by Linus Torvalds, are in widespread use. There are estimated to be over 10 million users of GNU/Linux systems today.  Richard Stallman is the principal author of the GNU C Compiler, a portable optimizing compiler which was designed to support diverse architectures and multiple languages. The compiler now supports over 30 different architectures and 7 programming languages.  Stallman also wrote the GNU symbolic debugger (GDB), GNU Emacs, and various other GNU programs.  Stallman received the Grace Hopper Award from the Association for Computing Machinery for 1991 for his development of the first Emacs editor in the 1970s. In 1990 he was awarded a MacArthur Foundation fellowship, and in 1996 an honorary doctorate from the Royal Institute of Technology in Sweden. In 1998 he received the Electronic Frontier Foundation's Pioneer award along with Linus Torvalds.            Who is Prof. Andrew Tanenbaum?        (Prof. Tanenbaum)  Andrew S. Tanenbaum has an S.B. degree from MIT and a Ph.D. from the University of California at Berkeley. He is currently a Professor of Computer Science at the Vrije Universiteit in Amsterdam, The Netherlands, where he heads the Computer Systems Group.  His current research focuses primarily on the design of wide-area distributed systems that scale to millions of users. These research projects have led to over 70 refereed papers in journals and conference proceedings. He is also the author of five books.  Prof. Tanenbaum has also produced a considerable volume of software. He was the principal architect of the Amsterdam Compiler Kit, a widely-used toolkit for writing portable compilers, and MINIX, a small UNIX-like operating system for operating systems courses.  Prof. Tanenbaum is a Fellow of the ACM, a Senior Member of the IEEE, a member of the Royal Netherlands Academy of Arts and Sciences, and winner of the ACM Karl V. Karlstrom Outstanding Educator Award.               Section 6 - CPU questions         What is the ""best"" CPU for GNU/Linux?        (REW)  There is no ""best"" CPU. The choice of CPU always depends on your price/performance/technical requirements. On the x86 side, we have Intel, AMD, Cyrix and IDT/Centaur, with various models available. All of these work.  Besides the x86 processors, the Linux kernel runs on 68k processors, MIPS R3000 and R4000, Power PC, ARM, Alpha and Sparc processors. There are lots of different ways to build a computer around a processor. If you have an x86, they built a PC around it. Don't go around buying second hand R4000 computers because the Linux kernel runs on the R4000 processor. Check the latest Linux kernel revision to see if the specific computer you're buying is supported.       (ADB)  OK, the Linux kernel is a good start. Now, there is a huge difference between kernel support and a ready-to-install distribution. Only four architectures have widely available, reasonably homogeneous distributions: x86 (or i386), Alpha, Sparc and Power-PC. And the Alpha and Sparc distributions that exist still have some rough edges. IOW, if you don't want to spend a lot of time installing and fine-tuning GNU/Linux, and you have a limited budget, your ""best"" choice is an x86 machine. If you have very specific needs (e.g. a hand-held computer running Linux, where the low power ARM architecture would be the ideal choice, or a workstation dedicated to scientific applications, where an Alpha or a Sparc would provide superior performance), check the various architectures, list your specific requirements, and make a choice. Nowadays Alpha 21164 machines are much more affordable than one or two years ago, but it's certainly harder to put one together than your average PC clone.            What is the fastest CPU for GNU/Linux?        (REW, ADB)  The CPU field is very active in terms of technological developments. New CPU models, new architectures, new manufacturing technologies keep pushing the state of the art. WRT GNU/Linux, it is a general consensus that Alpha machines usually provide the best floating point performance, when the actually shipping hardware available at any given point in time is compared (June 1998: the 21164/600).  However for non floating point applications the issue is not as clear-cut. Very high clock rate x86 machines (e.g. Pentium-II/400) provide impressive integer performance, for use in e.g. databases or Web server applications.  For 3D rendering applications you may want to consider the GNU/GPL Mesa OpenGL compatible library, which has support for some graphics accelerator chips.  Also note that some applications are not CPU bound. Check the exact bottleneck in your case.            I want to implement the Linux kernel for CPU Hyper123, how do I get started?        (ADB)  Is Hyper123 supported by gcc, or at least is the Hyper architecture supported by gcc? Do you have a target machine with a well defined architecture? If you have answered yes to both questions proceed to REW's answer. If you have answered no to either or both, don't even bother getting started. This is a major project, not exactly the kind of thing you do over the weekend. Quoting from a  SparcLinux paper  by Miguel de Icaza:   "" Thanks to having an international team of developers and support people, when the first Linux/SPARC distribution on CD went out we had a very strong port: a port that had taken only 22 months to engineer and complete (starting from scratch up to releasing the operating system on a bootable CD-ROM). ""       (REW)  Auch. Difficult task. Besides having to write support for the processor, you will also have to write the boot sequence to get things going. And a few device drivers.   You're not running away screaming yet? Good. Make sure you get the programmers manual for Hyper123, and data sheets for all the peripheral IC's. Make sure you have the docs for the computer that you're working on (addresses, registers for the stuff on the motherboard).  After that, start on learning the processor, by writing the boot program. Try booting a simple program that says ""hello world"". That will also allow you to write a console device driver.   Next, there is the hard part: get Linux to compile and run on the processor.  Make a new arch directory and start putting things in there that implement whatever needs implementing on your processor.            Why is my Cyrix 6x86/L/MX/MII detected by the kernel as a Cx486?        (RRR, ADB)  Cyrix 6x86 CPUs are different in many ways from Pentium (tm) and AMD K5/K6 (tm) CPUs, so special code must be included for adequate CPU detection, setup and reporting. Cyrix 6x86 support isn't perfect in kernels 2.0.x up to 2.0.34. From 2.0.35 on things should get much better ('cause we're working on it ;) ). Similarly, late 2.1.1xx kernels should fully support the Cyrix CPUs. Please check the  Linux Cyrix 6x86 HOWTO  site for details and patches.            What about those x86 CPU bugs I read about?        (ADB)  There are basically three known bugs that affect x86 processors, and each CPU design got its fair share it seems:       The Intel Pentium F00F ""Death"" bug , affects ALL Pentium and Pentium MMX CPUs. Linus implemented the Intel recommended workaround for this bug a few days after the bug was first reported in the newsgroups. All recent kernels will report and workaround the bug.      The AMD K6 ""sig11"" bug , affects only a few K6 revisions.  Was diagnosed by Benoit Poulot-Cazajous. There is no workaround, but you can get your processor exchanged by contacting AMD. 2.2.x kernels will detect buggy K6 processors and report the problem in the kernel boot message. Recently, a new K6 bug has been reported on the linux-kernel list.  Benoit is checking into it.      The Cyrix 6x86(Classic, L, MX) ""Coma"" bug , affects ALL Cyrix 6x86 CPUs. I proposed a simple workaround which is implemented as a user space boot option, a few hours after the bug was reported on the linux-kernel mailing list. See the  Linux Cyrix 6x86 HOWTO  site for details. Cyrix was notified of the bug, and their new MII CPUs are not affected by this problem anymore.                I grabbed the standard kernel tarball from ftp.kernel.org or some mirror of it, and it doesn't compile on the Sparc, what gives?        (DSM)  Often the Sparc port diverges due to the sheer high rate of changes which occur to that port. Also changes can happen to major interfaces in the kernel and the Sparc port is not updated at the same time. Eventually the Sparc port maintainers do try to merge all of their work into the standard tree, and at which time it will compile.  In any event, trees which will compile just fine are available via two mechanisms, the vger CVS tree (accessible via read-only anonymous CVS) and pre made tarballs of known working stable or test kernel trees. Check:      ftp://vger.kernel.org/pub/linux/README.CVS and     ftp://vger.kernel.org/pub/linux/Sparc/kernel/v2.{0,1}/                Does the Linux kernel execute the Halt instruction to power down the CPU?        (REG, ADB)  Yes. The Linux kernel will execute the Halt instruction when the machine is idle (check the code for the idle_task in sched.c). It has done so since the earliest i386 implementation, even though on the i386 we didn't care about power saving; it's just that halting the CPU is the Right Thing (tm) to do when there is no other task that must be run.  On the Pentium, K6 and C6 CPUs, power consumption gets automatically reduced from an average 12-24 Watts operating power down to 2-3 Watts when the processor is Halted. On the Cyrix 6x86 CPUs, Halt state power consumption can be further reduced down to 150 mw by enabling the Suspend-on-Halt feature.  Reduced power consumption means cooler, more reliable machine operation and longer component life. And it saves trees too.            I have a non-Intel x86 CPU. What is the [best|correct] kernel config option for my CPU?        (ADB)  For 386 class machines, compile as a 386. For 486-class machines, compile as a 486.  For the Cyrix 6x86 family CPUs and the AMD K5 and K6, you should probably compile the kernel as a Pentium or PPro. The only difference between the Pentium (-M586) and PPro (-M686) compile options is in the string operations (AFAIK). The Pentium option uses a header file that breaks down the complex string opcodes into simpler operations (which are faster on the Intel Pentium and Pentium MMX).  The PPro option uses the complex opcodes, but should be slightly faster than a Pentium because of the PPro has deeper, smarter pipelines.  The same rules apply to the 6x86 family and the K5/K6, but the difference in speed is minimal between the Pentium and PPro kernel config options on these CPUs (PPro should be slightly better).  The 486 kernel config option (-M486) should  not  be used for anything above a 486-class CPU. This option sets code alignment options that work well on the 486, but that cause excessive NOP padding on 586 and above class machines. Usually, the 6x86 speculative execution capabilities will just optimize this padding at run time, but the NOP opcodes still take precious L1/L2 cache space (same applies to the K6; I am not 100% sure of what the K5 does).  The 386 config option (-M386) does not suffer from excessive padding, but does not produce code optimized for recent x86 CPUs either, so it is also deprecated, except for kernels included in GNU/Linux distributions which must run on the widest possible range of machines.            What CPU types does Linux run on?        (REG)  Quite a few. Below is the list for kernel 2.4.18. Note that for some CPUs advanced development is kept outside the mainline kernel, and changes are merged into the mainline periodically. The WWW pages for these projects are listed as well.    alpha, by DEC (now Compaq).  http://www.linuxalpha.org/     ARM  http://www.arm.linux.org.uk/     Cris (AXIS)  http://developer.axis.com/software/linux/     x86 (32 bit, aka IA32, aka i386)   x86-64 (64 bit extension to x86 by AMD)  http://www.x86-64.org/     IA64 (aka Itanium aka Itanic, by Intel and HP)  http://www.linuxia64.org/     M68K (Motorola M68000 family)  http://www.linux-m68k.org/     MIPS (32 bit and 64 bit)  http://www.linux.sgi.com/     PA-RISC (by HP)  http://www.parisc-linux.org/     Power PC 32 bit  http://www.penguinppc.org/  and 64 bit  http://penguinppc64.org/     S390/S390x (IBM mainframe)  http://linux.s390.org/     SuperH (by Hitachi)  http://www.m17n.org/linux-sh/     Sparc (32 and 64 bits)  http://sunsite.tut.fi/SPARCLinux/  and  http://www.ultralinux.org/     OpenRISC (unfinished)  http://www.opencores.com/cores/or1k-new/linux/     Emotion Engine (SONY Playstation 2)   http://playstation2-linux.com/     ColdFire by Motorola (incompatible derivative of MC68000)   http://www.uclinux.org/ports/coldfire/     VAX (DEC)   http://linux-vax.sourceforge.net/     TMS320 Digital Signal Processor (Texas Instrument)  http://www.dsplinux.net/     8088 / 8086 / 80286 (INTEL)  http://elks.sourceforge.net/     ITRON (Japanese CPU used by DoCoMo in 3G mobile phones)   http://www.emblix.org/english/etop.html     General CPU   http://www.cyut.edu.tw/~ckhung/resource/linux_ports.html                    Section 7 - OS questions         OS $toomuch has this Nice feature, so it must be better than GNU/Linux.        (ADB)  Sorry, but this simply means that OS $toomuch was designed with a given set of objectives and priorities, and GNU/Linux was designed with a different one. Neither is better than the other and also note that I am not referring to the respective implementations. But please, no OS comparisons on the linux-kernel list. Check the newsgroups instead, particularly comp.os.linux.advocacy which is dedicated to that kind of debate.            Why doesn't the Linux kernel have a graphical boot screen like $toomuch OS?        (ADB)  Because it doesn't need one. You can add that feature to the boot loader code, if you want to. The Linux kernel has no graphics primitives, just like any UNIX kernel.            The kernel in OS CTE-variant has this Nice-very-nice feature, can I port it to the Linux kernel?        (ADB)  Sure, you can do (almost) anything you want with Free Software. Oh, OS CTE-variant is not Free Software?            How about adding feature Nice-also-very-nice to the Linux kernel?        (ADB)  You should probably read the   definition of creeping featurism  first. Related concepts, in increasing order of obfuscation: the KISS rule-of-thumb, the ""Small is Beautiful"" concept,  Occam's Razor  and Complexity Theory. A good book to read on these concepts as they apply to OS design is "" The Mythical Man-Month "" by Frederick P. Brooks, Jr.            Are there more bugs in later versions of the Linux kernel, compared to earlier versions?        (ADB)  There are no more  known  bugs in later kernel versions than in earlier kernel versions. However, the Linux kernel source code has been growing at a constant rate. As a general rule, large pieces of code tend to have undetected bugs. OTOH, the core code for the Linux kernel seems to have stabilized at around 16 thousand lines of C code, according to Larry McVoy.       (REW)  I'd say more than 23 thousand lines in 2.1.x. Add together the totals from kernel, mm, arch/<somearch>/, subtract fpu-emulation.            Why does the Linux kernel source code keep getting larger and larger?        (ADB)  There are four causes for this unbounded growth:       New architectures are implemented.  This is usually OK, because the code that is specific to each architecture is (in theory, at least) separate from the others. Common code doesn't grow.      New drivers are implemented.  Again, this is OK, because each driver has different source files, and those are selectively compiled in the kernel executable or built as modules according to the specified kernel configuration.      Old code gets adequately documented.  Adding comments and documentation increases the size of the source, but it's still a Good Idea (tm).      Creeping featurism . It's generally considered a Bad Idea (tm) to keep adding more features to an already working piece of code.                The kernel source is HUUUUGE and takes too long to download. Couldn't it be split in various tarballs?        (REG)  The kernel (as of 2.1.110) has about 1.5 million lines of code in *.c, *.h and *.S files. Of those, about 253 k lines (17%) are in the architecture-specific subdirectories, and about 815 k lines (54%) are in platform-independent drivers. If, like most people, you are only interested in i386, you could save about 230 k lines by removing the other architecture-specific trees. That is a 15% saving, which is not that much, really. The ""core"" kernel and filesystems take up about 433 k lines, or around 29%.  If you want to start pruning drivers away, the problem becomes much harder, since most of that code is architecture independent. Or at least, is supposed to be/will be. There is some driver code which probably should be moved to an i386-specific subdirectory, and perhaps over time it will be (it will take a lot of work!), but you need to be careful. PCI cards for example should be architecture independent. Throwing out the non i386-specific drivers will save around 97 k lines, a saving of about 6%.  But the most important argument for/against splitting the kernel sources is not about how much space/download time you could save. It's about the work involved for Linus or whoever will be putting together the kernel releases. Building tarballs (compressed tarfiles) of the whole kernel already represents a considerable amount of work; splitting it into various architecture-dependent tarballs would dramatically increase this effort and would probably pose serious maintainability problems too.  If you are really desperate for a reduced kernel, set up some automated procedure yourself, which takes the patches which are made available, applies them to a base tree and then tars up the tree into multiple components.  Once you've done all this, make it available to the world as a public service.  There will be others who will appreciate your efforts.  Under no circumstances  should you complain to the kernel list. I promise you that Linus and the core developers will completely ignore such messages, so whinging about it is a complete waste of bandwidth. The only message on this subject that should be posted is an announcement of a new service providing split kernel sources.            What are the licensing/copying terms on the Linux kernel?        (RRR)  In the root directory of the Linux kernel source tree (e.g. /usr/src/linux/), you will find a file COPYING. The file states that the Linux kernel is placed under the GNU General Public License (version 2), a copy of which is provided. If still in doubt, post to the appropriate forums (such as gnu.misc.discuss) or ask a lawyer, but  don't  ask about it on the linux-kernel list.            What are those references to ""bazaar"" and ""cathedral""?        (ADB)  These terms are used to describe two different development models adopted by the Free Software community, and were first coined by Eric S. Raymond. You should check  his original article .  Note that Eric's article describes two among an infinite range of possible different development models. You could for example create new ""Versailles"", ""Great Wall of China"" or ""Pyramid of Kheops"" software development models.  As long as the end result is under a GNU/GPL license, it will still be Free Software.            What is this ""World Domination"" thing?        (ADB)  Geek humor? Please don't take this seriously! This is just a way of saying that there are more and more people using GNU/Linux all over the world i.e. that the  Free Software  movement is gaining momentum. Note that the ""Free"" in Free Software refers to  freedom , just about the opposite of what's implied by ""World Domination"".       (REW)  This is a reference to an interview of Linus some years ago. After being pretty modest about the success that Linux was enjoying he concluded the interview with the remark: "" Of course, what I really want is total world domination. ""  I've been browsing the net for the reference for this.  http://www.ukuug.org/newsletter/63/news@uk63-5.shtml  and  http://www.linuxgazette.com/issue15/lg_toc15.html  are close but not quite close enough.  Linus has referred back to this remark often enough.            What are the plans for future versions of the Linux kernel?        (ADB)  Linus would be the best person to ask, but I don't know if he would have the time and patience to answer this question. There are some development issues that can be mentioned, though:      PnP support in the kernel. Right now one can get PnP support using the isapnptools user space package and manually tuning the I/O, IRQ and DMA channel allocation, but future Linux kernels will do that for you.     Improved SMP support.     Improved 64 bit code support.     Improved POSIX support.     Improved APM support.                Why does it show BogoMips instead of MHz in the kernel boot message?        (ADB)  On some processor architectures it is very difficult to find out the clock speed of the processor, and since the kernel does not depend on determining the MHz rating of a processor to operate correctly, MHz simply do not get calculated at boot time. OTOH, BogoMips get calculated because the kernel bases itself on BogoMips data to implement small time delays (busy loops) needed by various drivers in different circumstances. Note that neither BogoMips nor MHz measure processor performance in any way. See the BogoMips HOWTO by Wim van Dorst for an accurate description of BogoMips. Also take a look at the Linux Benchmarking HOWTO (shameless plug) if you want some basic information on Linux performance measurements.  Sometimes your BogoMips reading will vary by as much as 30%, from one kernel to another. This is due to changes in the alignment of the BogoMips calibration loop, which interacts with cache behavior.  Richard B. Johnson  has recently proposed a small patch that takes care of this problem.            I installed kernel x.y.z and package foo doesn't work anymore, what should I do?        (RRR)  Check out the /usr/src/linux/Documentation/Changes and make sure you have the recommended versions (or newer) of the relevant software.  This is very important.  A lot of things are evolving on Linux and newer versions of the kernel may break older packages (especially on the development kernels). If you are using development kernels keep an eye for reports on the kernel list. If all else fails post a bug report (see Q/A on bug reports) to the list.            People talk about user space vs. kernel space. What's the advantage of each?        (REG)  User space is what all user (including root) programs run in. It is fully virtual memory (i.e. normally swappable). The X server is in user space, for example. So is your shell. Kernel space is the domain of the kernel (wow!), device drivers and hardware interrupt handlers. Kernel memory is non-swapable (i.e. it's REAL RAM), and hence should be used sparingly. Also, operations performed in kernel space are not pre-emptive: this means other processes are prevented from running until the operation completes.  Some people think that it's better to implement stuff in kernel space (""so that everyone has it""). In general this is a Bad Idea (tm) (see  ""creeping featurism""  above), since kernel space resources are more ""heavy"" than user space resources. For example, coding a Mandelbrot fractal generator in kernel space is a *really stupid* idea.  The job of the kernel is to provide a safe and simple interface to hardware and give different processes a fair share of the resources, and to arbitrate access to resources/hardware.  Many ideas are best implemented in user space, with perhaps the absolute minimum of kernel support. The only exceptions to this principle are where it is particularly complicated or inefficient to implement the solution in user space only. This is why filesystems are in the kernel (you *could* put them in user space implemented as daemons), because a kernel implementation is *much* faster.  Note that you can make user space memory non-swappable by using the  mlock(2)  system call. This is a privileged operation and should not be used trivially.            What are threads?        (ADB)  Very shortly, threads are ""lightweight"" processes (see the definition of a process in the Linux Kernel book) that can run in parallel. This is a lot different from standard UNIX processes that are scheduled and run in sequential fashion. More threads information can be found  here  or in the excellent Linux Parallel Processing HOWTO by Professor Hank Dietz.       (REG)  When people talk about threads, they usually mean  kernel threads  i.e. threads that can be scheduled by the kernel. On SMP hardware, threads allow you to do things truly concurrently (this is particularly useful for large computations). However, even without SMP hardware, using threads can be good. It can allow you to divide your problems into more logical units, and have each of those run separately. For example, you could have one thread read blocking on a socket while another reads something from disk. Neither operation has to delay the other. Read ""Threads Primer"" by Bill Lewis and Daniel J. Berg (Prentice Hall, ISBN 0-13-443698-9).            Can I use threads with GNU/Linux?        (REG)  Yes! The Linux kernel has the clone(2) system call, which provides the underlying mechanism for implementing a threads library. And Xavier Leroy has provided us with LinuxThreads, a POSIX 1003b implementation of threads for the Linux kernel.  If you have a libc 5 system, you'll need to install LinuxThreads if it is not already installed. You can get the LinuxThreads library  here .  If you have a libc 6 (aka glibc 2) system, you shouldn't need to do anything. Glibc has LinuxThreads merged in.            You mean threads are implemented in kernel space in GNU/Linux? Why not a hybrid kernel/user space implementation? Wouldn't that be more efficient?        (REG)  It is not clear that there is any significant benefit for Linux to have a hybrid threading library. If we look at Solaris Threads, they have a hybrid scheme, and claim that is an advantage. Well, yes, I suppose so, given their environment (the Solaris 2 kernel). They have a very heavy kernel, so a pure kernel space implementation would be too slow (remember the time it takes to enter/exit the kernel). Linux, on the other hand, has a very efficient kernel, so the difference between a kernel context switch under Linux and a user space context switch under Solaris 2 is pretty small. Also note that Solaris Threads took a long time to get right, because of problems such as signal delivery to threads. With a pure kernel threads implementation, signal delivery is much simpler. Fixing the signal delivery problems with Solaris Threads increased the complexity of their library, leading to bloat and performance loss. We don't want to make the same mistakes.  Now, you may argue that a hybrid scheme under Linux would be  even better . Maybe. Prove it. Code it and benchmark it. In any case, this is a discussion that is not relevant to the kernel, since a hybrid scheme is built on top of kernel threads (Solaris 2 builds their threads on top of LWPs (Light Weight Processes) too). It's a user space issue, so please, keep it off the kernel list.  BTW: if you do manage to code something up and it is much faster than pure kernel space threads, you may need some kind of extra kernel support (depending on how you implement things). If that happens,  then  come and talk about it on the kernel list.  The Linux philosophy is to optimize the kernel first, so that all possible implementations can share the benefits.            Can GNU/Linux machines be clustered?        (REG)  Different people mean different things when they talk about clustering. Some people want transparent fault tolerance and load balancing of general applications, others want parallel processing of a single job. Most people who talk about fault tolerance expect hardware and OS support of this (if a node goes down, the OS will automatically migrate the application to another node). This is not (yet) available for Linux.   You can write a fault tolerant application for a network of computers without direct OS support: you just need to structure your application appropriately. Note that a fault tolerant distributed application may also be a parallel, multithreaded application.   The  Beowulf  project provides an API and system management software to write parallel distributed applications on a network of Linux machines. The main emphasis here is on parallelism to get maximum processing power, although fault tolerance is possible too.  An example of a Beowulf clustered Linux system is  Avalon , which has just been listed among the world's 500 most powerful supercomputers.   Beowulf clusters deliver GFLOPS using arrays of commodity computers. It is an incredibly cheap and elegant way to get significant computing power for e.g. scientific applications.       (ADB)  Also check the Parallel Processing HOWTO by Professor Hank Dietz.       (REG)  In June 2000,  Mission Critical Linux  released   Kimberlite  which they describe as an ""open source linux clustering cabability"". Tim Burke, their Cluster Architect describes it thus:   A Kimberlite Cluster provides support for two server nodes connected to a shared SCSI or Fibre Channel storage subsystem, in an active-active failover environment. The software provides the ability to detect when either node leaves the cluster, and will automatically trigger recovery scripts which perform the procedures necessary to restart applications on the remaining node. When the node rejoins the cluster, applications can be moved back to it, manually or automatically, if required. Sample recovery scripts are provided. Kimberlite is designed to deliver the highest levels of data integrity and be extremely robust. It is suitable for deployment in any environment that requires high availability for un-modified Linux applications.              How well does Linux scale for SMP?        (REG)  Reasonably well. Kernel version 2.2 has much better scalability than version 2.0. People are running 4 processor Intel Xeon machines and 14 processor UltraSparc machines. Version 2.2 still has a global kernel lock, but this is often released quite quickly (for example, when the process blocks waiting for a resource and/or data), so the net result is that it is quite unlikely for two processors to compete for the global lock. Experiments with 14 processor UltraSparc machines shows that Linux scales well, indicating that the current locking strategy is not hurting us for these machines.   Also consider that for parallel processing jobs, the kernel is not involved, so even Kernel v2.0 scaled well for these applications. When we talk about SMP scalability, we are referring to how many IO operations the kernel can perform at the same time.   Unfortunately some hysterical NT supporters continue to spread FUD that Linux does not scale well on SMP. Efforts to insert a bit of truth have generally fallen on deaf ears. If someone tells you that NT scales better than Linux, ignore them. They're operating in a fact-free zone. Tests indicate that NT has trouble scaling to 4 processors. There really is no competition.   Note that kernel version 2.3 has replaced the remaining global kernel lock with finer grained locking. This allows Linux to scale well to 64 processor machines and beyond.            Can I lock a process/thread to a CPU?        (RML)  Yes, as of 2.5.8 the Linux kernel supports binding a process to a particular CPU.  Patches exist for the 2.4 kernel series but are not yet merged (as of 28-APR-2002). This is called ""task CPU affinity"" and the interface was implemented via the following syscalls:     int sched_setaffinity(pid_t pid, unsinged long len, unsigned long *mask)  int sched_getaffinity(pid_t pid, unsinged long len, unsigned long *mask)     which set and get a given task's CPU affinity, respectively. Utilities for manipulating affinity and the patches for 2.4 are available at   kernel.org . The interface allows any task's affinity to be retrieved, although only the task's uid (or root) can change the affinity.  The calls assure the task has been successfully scheduled to a valid CPU before returning.            How efficient are threads under Linux?        (REG)  Incredibly. Compared with all the other kernel-based thread implementations, Linux is probably the fastest. Each thread takes only 8 kiB of kernel memory for the stack and thread creation and context switching is very fast. I have measured less than 1 microsecond context switch times on an old Pentium/MMX 200 (see   http://www.atnf.csiro.au/~rgooch/benchmarks/linux-scheduler.html  for more details). However, the Linux scheduler is designed to work well with a small number of  running  threads. Best results are obtained when the number of running theads equals the number of processors.   Avoid the temptation to create large numbers of threads in your application. Threads should only be used to take advantage of multiple processors or for specialised applications (i.e. low-latency real-time), not as a way of avoiding programmer effort (writing a state machine or an event callback system is quite easy). A good rule of thumb is to have up to 1.5 threads per processor and/or one thread per RT input stream. On a single processor system, a normal application would have at most two threads, over 10 threads is seriously flawed and hundreds or thousands of threads is progressively more insane.   A common request is to modify the Linux scheduler to better handle large numbers of running processes/threads. This is always rejected by the kernel developer community because it is, frankly, stupid to have large numbers of threads. Many noted and respected people will extol the virtues of large numbers of threads. They are wrong. Some languages and toolkits create a thread for each object, because it fits into a particular ideology. A thread per object may be appealing in the abstract, but is in fact inefficient in the real world. Linux is not a good computer science project. It is, however, good engineering. Understand the distinction, and you will understand why many widely acclaimed ideas in computer science are held with contempt in the Linux kernel developer community.            How does the Linux networking/TCP stack work?        (REG)  The best guide may be found in the Linux kernel sources. A popular reference is ""TCP/IP Illustrated"" (volumes 1 to 3) by W. Richard Stevens, which explains much of the theory and practice behind TCP/IP. This material is based on the BSD implementation, which differs from Linux in fundamental ways. Nevertheless, it is an excellent reference.            Can we put the networking/TCP stack into user-space?        (REG)  The short answer is no, because this would slow it down (see the  monolithic versus microkernel debate  for reasons why). The longer answer involves the motivations behind the question. Some people want to inspect every packet, and think it's easier to do in user-space. In fact, the kernel has a network packet filtering API (Linux Socket Filter (LSF), which is an easier-to-use implementation of the Berkeley Packet Filter (BPF)). The LSF allows you to capture some or all packets and pass them to user-space. This yields the advantages of a kernel-based networking stack, but still allows you to inspect packets in user-space if needed.   One reason people want to inspect packets is to perform firewalling. In this case, a far superior solution is available, using the  Netfilter  infrastructure. This is a kernel-level firewalling/NAT solution which is fast and reliable. You may create both stateful and stateless firewalling configurations. This infrastructure was introduced during the 2.3.x development cycle.               Section 8 - Compiler/binutils questions         I downloaded the newest kernel and it doesn't even compile! What's wrong?        (REG)  First check the kernel newsflash page at   http://www.atnf.csiro.au/~rgooch/linux/docs/kernel-newsflash.html  where late-breaking patches may be posted.       (DW)  Do  not  post any details of the compile failure to the mailing list unless you have first checked the  archives  to ensure that the question hasn't been asked already.   Normally, if Linus allows a simple typo into a release kernel which prevents it from compiling, a patch is posted to the list within hours, yet  still  there are clueless idiots who continue to ask about it for weeks thereafter.   Do not do this. We  will  find out where you live, and we  will  come to your house and knock on your door at three o'clock in the morning to ask you stupid questions. Repeatedly, if needs be.   REW's note below also says this; but evidently not explicitly enough. Some people are just too stupid, I guess.       (RRR)  Make sure you are compiling with the recommended version of gcc with default optimizations flags (IOW, leave the Makefiles alone) and a recent binutils. The binutils package is the one that contains the assembler (gas) and linker (ld). See Documentation/Changes for more info. If that works then, experiment with different compiler/optimizations.       (REW)  Linus cannot test every permutation of drivers and options. He's a selfish little guy. He just compiles the version that runs on his computers, and then releases it. Actually, he sometimes even doesn't compile it before releasing. He's a busy man. Give him a break. Wait for half a day. Someone will post a patch that will fix it within that time. If that doesn't happen for more than a day, fix it yourself, and post the patch to linux-kernel. If you don't have the expertise to do this yourself, please  wait for another day , before reporting the problem.  Please check if it hasn't been reported before. Most companies have a help desk that keeps the end users from bothering the developers. Linux is different: You get to talk to the developers. But don't waste everybody's time by posting stuff that has been reported already.       (DBE)  Not all ports of the Linux kernel to different hardware platforms are fully merged into the official tree at kernel.org. If you have problems compiling a kernel for a non-i386 architecture please check the related Web pages and mailing-lists for that specific port.            What are the recommended compiler/binutils for building kernels?        (REG)  This depends on the kernel version. Until 26-OCT-2000, gcc 2.7.2.3 was the recommended compiler for all kernels. On this date, Linus announced that gcc 2.91.66 (aka egcs 1.1.2) is the recommended compiler for 2.4.x kernels up to version 2.4.9. Gcc 2.95.3 is the recommended compiler for kernel 2.4.10 and later.   The recommended binutils is 2.9.1.0.25. Avoid binutils versions from 2.8.1.0.25 to 2.9.1.0.2, these were beta releases and known to be buggy.   Always see the  Documentation/Changes  file for details.            Why the recommended compiler? I like xyz-compiler better.        (RRR)  Quick Answer: it's what Linus uses. Real Answer: the recommended compiler has been extensively tested and proven to be a very stable compiler. What is at issue is not whether other compilers can optimize better, but whether they will compile the kernel correctly.  Current kernels and compilers are very complex pieces of software. There are just too many ways that the two can interact and cause trouble (a recent example: gcc 2.8.x and kernel 2.0.x). By keeping constant one of the variables - the compiler - kernel developers can concentrate on the kernel. If both the compiler and kernel are changing then it's anyone's guess what went wrong.            Can I compile the kernel with gcc 2.8.x, egcs, (add your xyz compiler here)? What about optimizations? How do I get to use -O99, etc.?        (RRR)  Sure, it's your kernel. But if it doesn't work, you get to fix it. Seriously now, there is really no point in compiling a production kernel with an experimental compiler. Production kernels should only be compiled with the recommended compiler. Newer compilers are known to break the 2.0 series kernels, known symptoms of this breakage are hwclock and the X server seg.faulting.   Compiling a 2.0 kernel with egcs or gcc 2.8, even after applying the workaround of copying the ioport.c file from a late 2.1 kernel to 2.0, is not recommended and will inevitably lead to unpredictable kernel behaviour.   Regarding 2.1 kernels, they usually compile fine with other compiler versions, but do NOT complain to the list if your are not using the recommended compiler. Linux developers have enough work tracking kernel bugs, to also be swamped with compiler related bugs.   If you want to play with the optimization options, you need to hack the Makefile in arch/i386/Makefile (assuming you have an x86 processor), but if it breaks... well, you should know the answer by now. Also keep in mind that some demented optimizations (such as -O99) may even produce slower and bigger kernels, due to gratuitous loop unrolling and function inlining.       (ADB)  I think the standard  Paul Gortmaker  disclaimer (?) is: ""If it breaks, you get to keep the pieces."" ;-)            I compiled the kernel with xyz compiler and get the following warnings/errors/strange-behavior, should I post a bug report to the list? Should I post a patch?        (RRR)  In general, no, unless you get these with the recommended compiler. Few exceptions:   Everyone welcomes code cleanup patches, for instance, newer compilers may complain a lot more. Some of these warnings may even be warranted (i.e. ambiguous use of else statements), fixing these is a good thing.   There could be some aging code around that makes too many assumptions about the compiler (especially true about inline assembly), some of the newer compilers break these statements. Fixing these is also a good thing, but be very sure you're are really fixing a bug in the kernel. Workarounds for other compilers will be ignored (if the compiler is buggy, fix the compiler!).            Why does my kernel compilation stops at random locations with: ""Internal compiler error: program cc1 caught fatal signal 11.""?        (REW)  Sometimes bad hardware causes this. Read the Web page at  http://www.BitWizard.nl/sig11/  about this. The important word here is  random .  If it stops at the same place every time, the kernel source might have a glitch or your compiler might be bad. The Web page is mostly about the  random  error source: hardware. There is a bunch of different error messages that you can get if you have bad or marginal hardware.       (ADB)  Overclocked processors very often fail long compilations with a sig11, because a long gcc compilation puts more strain on the processor. As the processor heats up, it may attain a point where internal timings get out of spec. At this point, something gives and you get a sig11.   Also, some old K6 revisions would sig11 when compiling large programs if > 32 Mb of RAM were installed on the Linux box. AMD will exchange these faulty processors for free. Benoit Poulot-Cazajous correctly diagnosed the problem and devised an ingenious test for this bug that is run at boot time in 2.2.x kernels.            What compiler flags should I use to compile modules?        (REG)  At the very least, you need these:  -O2 -DMODULE -D__KERNEL__ -DLINUX -Dlinux        (KO)  I don't advise compiling modules by hand if the directory is in the kernel source tree.  The rest of the Makefile system will not know about the extra modules so it will not recompile them if the config changes nor will it install the modules. The best method (until the 2.5 Makefile rewrite) is to add the directory into the kernel Makefile system.   Create a kernel Makefile in your new directory.  Example:  # # Example Makefile for your own modules #  SUB_DIRS        := MOD_SUB_DIRS    := $(SUB_DIRS) ALL_SUB_DIRS    := $(SUB_DIRS)  M_OBJS          := example-module1.o example-module2.o  include $(TOPDIR)/Rules.make   Edit the Makefile in the parent directory to add your subdirectory to the  SUB_DIRS  list.  make dep ,  make modules  and  make modules_install  will automatically handle your modules.       (VKh)  If you have a local makefile with which you wish to build your module  not linked under the kernel tree in the proper way, you still can ""ride"" on the master Makefile.  This way one can eliminate the dependency on your particular  machine kernel compilation options to be hardwired in the local Makefile. I.e., once you reconfigure the kernel, your driver will compile itself when you do a local ""make"" with the correct set of the new flags.  This is what you can do on 2.2 (Makefile excerpt follows):  EXTRA_CFLAGS := -DDEBUG -DLINUX -I/usr/src/foo/include MI_OBJS  := your-module.o O_TARGET := your-module.o O_OBJS   := your1.o your2.o  # Reuse Linux kernel master makefile on this directory ifdef MAKING_MODULES include $(TOPDIR)/Rules.make else all::         cd '/usr/src/linux' && make modules SUBDIRS=$(PWD) endif    In 2.4 the syntax is different. Rename  MI_OBJS  to   obj-m  and  O_OBJS  to  obj-y   to achieve the same goal there:  obj-m  := your-module.o O_TARGET := your-module.o obj-y   := your1.o your2.o              Why do I get unresolved symbols like foo__ver_foo in modules?        (KO)  If  /proc/ksyms  or the output from  depmod -ae  contains symbols like ""foo__ver_foo"" then you have been bitten by the broken Makefile code for symbol versioning. The only safe way to recover is save your config, delete everything, restore the config and recompile. Do this:  mv .config .. make mrproper mv ../.config . make oldconfig make dep clean bzImage modules # install, boot              Why do I get unresolved symbols with __bad_ in the name?        (REG)  This is an indication that a function has been called with an invalid parameter. In some cases, these invalid parameters can be detected at compile time (through clever use of preprocessor tricks), so the preprocessor will modify the called function name into an invalid one. This will prevent the final link stage from completing (or will prevent the module from loading).   OK, so now that you know why, go forth and pester the maintainer of the section of code that is making the invalid function call. You should check the  CREDITS  and  MAINTAINERS  files to determine the maintainer.               Section 9 - Feature specific questions         GNU/Linux Y2K compliance?        (ADB)  Y2K compliance under GNU/Linux is a multi-level problem.       Applications . Check your application sources for routines that only operate on/test the last two digits of the year field/variable(s). Obviously the problem here is that 2000 > 1999, but 00 < 99. Unfortunately, poor programming practices are just as common and unavoidable as death and taxes...      Libraries . Libc5 and glibc are known to be Y2K compliant. Alan Cox mentioned that libc4 had some problems.      Kernel . The Linux kernel is y2k compliant. BTW the code snippet in the /arch/i386/kernel/time.c will force those non-y2k compliant RTC implementations to the correct date on 00:00:00 Jan 1, 2000. It's been there for quite some time, now, nice and quiet; added by Alan Modra circa 1994!      BIOS . On x86 PC machines, upon boot some BIOS's will wrap back to 1900, later versions will correctly wrap the RTC clock to 2000. This is a rather critical problem in embedded systems if they are not running Linux; if they are running Linux this is solved by Alan Modra's code snippet mentioned above. :-)      Hardware . The standard PC RTC chip will not wrap the century. Wrapping must be done in software/BIOS. The chip will store the century data, but it just won't increment it on 00:00:00 Jan 1, 2000. Same issue as BIOS WRT embedded systems.     Testing the kernel, the BIOS and the RTC hardware is relatively easy if you are allowed to reboot the machine; just enter the CMOS setup routine and set the time to Dec 31 1999, 23:58:00. Boot and check what happens.  Checking applications and libraries takes a lot more work... Specially checking applications when you don't have access to the source code :( The only way is simulation. But this is getting off topic: if you don't have access to the source code, then it's not relevant to GNU/Linux. ;)            What is the maximum file size supported under ext2fs? 2 GB?      (REW, AC)  In the 2.0.x kernels, maximum  file  size (not to be confused with partition sizes, which can be much larger) under ext2fs is 2GB. Larger files are only supported on 64-bit architectures (Alpha and UltraSPARC) in late 2.1.1xx kernels.  Files larger than 2GB are difficult to support on 32-bit architectures. This will probably be implemented in the 2.3 kernel series.            GGI/KGI or the Graphics Interface in Kernel Space debate?        (REG, ADB)  GGI/KDI information can be found  here . The GGI/KGI developers warn against useless debates on the kernel list.            How do I get more than 16 SCSI disks?        (REG)  Get kernel version 2.2.0 or later.            What's devfs and why is it a Good Idea (tm)?        (REG)  OK, pushing my own barrow here. Devfs allows device drivers to have a direct link with device special files (what you see in /dev). The current dependence on major/minor numbers to provide this link poses scalability and performance problems. Devfs also only has device nodes for devices that you have available. Read the  devfs FAQ  for more details. Note that devfs went into the official 2.3.46 kernel.            Linux memory management? Zone allocation?        (ADB)  Rik van Riel has setup a  nice page  on Linux memory management. It has a link to an excellent tutorial on virtual memory.            How many open files can I have?        (REG)  With kernels 2.0.x you can have 256 open FDs (file descriptors). With 2.2.x you can have 1024. Various patches exist which allow you to increase these limits. Note that this can break select(2).            When will the Linux accept(2) bug be fixed?        (REG)  Firstly, this is not a bug in the Linux kernel, despite the fact that the ""Sendmail 8.9.0 Known Bugs List"" states there is a bug with Linux accept(2). The Linux accept(2) call can return the ETIMEDOUT error when there are system resource problems. This is not wrong, just different from what Sendmail expects. Since accept(2) is not part of the POSIX standard, it cannot be claimed that Linux is violating it. I'm told that the Single UNIX Specification, Version 2 (SUSv2), which is much newer, implicitly prohibits ETIMEDOUT. Nevertheless, the networking hackers are not inclined to change this behaviour. They seem to prefer to follow POSIX in this, perhaps following the maxim  the great thing about standards is that there are so many to choose from . Note also that BSD documents slightly different behaviour from SUSv2. It is prudent for an application to deal gracefully with unexpected error codes.            What about STREAMS? I noticed  Caldera  has a STREAMS package, when will that go in the kernel source proper?        (REG)  STREAMS allow you to ""push"" filters onto a network stack. The idea is that you can have a very primitive network stream of data, and then ""push"" a filter (""module"") that implements TCP/IP or whatever on top of that. Conceptually, this is very nice, as it allows clean separation of your protocol layers. Unfortunately, implementing STREAMS poses many performance problems.  Some Unix STREAMS based server telnet implementations even ran the data up to user space and back down again to a pseudo-tty driver, which is very inefficient.  STREAMS will  never  be available in the standard Linux kernel, it will remain a separate implementation with some add-on kernel support (that comes with the STREAMS package). Linus and his networking gurus are unanimous in their decision to keep STREAMS out of the kernel. They have stated several times on the kernel list when this topic comes up that even optional support will not be included.       (REW, quoting Larry McVoy)  ""It's too bad, I can see why some people think they are cool, but the performance cost - both on uniprocessors and even more so on SMP boxes - is way too high for STREAMS to ever get added to the Linux kernel.""  Please stop asking for them, we have agreement amongst the head guy, the networking guys, and the fringe folks like myself that they aren't going in.       (REG, quoting Dave Grothe, the STREAMS guy)  STREAMS is a good framework for implementing complex and/or deep protocol stacks having nothing to do with TCP/IP, such as SNA.  It trades some efficiency for flexibility.  You may find the Linux STREAMS package (LiS) to be quite useful if you need to port protocol drivers from Solaris or UnixWare, as Caldera did.   The Linux STREAMS ( LiS ) package is available for download if you want to use STREAMS for Linux. The following site also contains a   dissenting view , which supports STREAMS.            I need encryption and steganography*. Why isn't it in the kernel?        (TJ)  Note that this section was written in 2000/2001, and the laws in various countries have changed since then. Updates would be appreciated.   In France and Russia, strong encryption is essentially illegal, using it there requires a license which is seldom granted. The United States has cumbersome restrictions on exporting such software (it's considered a ""munition""--see   http://www.epic.org/crypto/export_controls/  ). Having these features in the standard kernel would therefore cause great inconvenience to people in those countries. However, separate programs and patches to the kernel are available at:       ftp://ftp.csua.berkeley.edu/pub/cypherpunks/filesystems/linux/       http://www.freeswan.org/        http://www.inka.de/~bigred/devel/cipe.html        http://www.quick.com.au/ftp/pub/sjg/       http://www.ssh.org/        http://web.mit.edu/kerberos/www/       http://tcfs.dia.unisa.it/        ftp://ftp.tik.ee.ethz.ch/pub/packages/skip/      (*) Steganography is disguising sensitive data as noise in a digitized image, sound file, or the like.            How about an undelete facility in the kernel?        (REG)  This idea keeps being raised again and again. There is no need for kernel support to do this. You can easily do it in user space. There are replacement versions of the  rm  utility which will move/copy files to a wastebasket area instead of actually deleting. If you're really keen, you could implement a wrapper for the  unlink  system call, and use LD_PRELOAD to override the function for all applications. This has been done by Manuel Arriaga and is called ""libtrash"". It is available at:   http://m-arriaga.net/software/libtrash/             How about tmpfs for Linux?        (REG)  The 2.4 series kernels have introduced a tmpfs. The old SysV shared memory code has been replaced with a new shm file-system, which is much simpler and cleaner, thanks to the improved VFS. Since the shm code can be shared to create a tmpfs, this was done. You may find tmpfs useful if you have an embedded system which has the root file-system on a read-only media but needs a writable file-system.       (REG)  Prior to the introduction of tmpfs, many people asked for its development, on the grounds that it would be faster than /tmp in a conventional file-system. This was never considered a valid reason for tmpfs development, because the Linux ext2 filesystem is so good that it outperforms tmpfs (memory-based filesystems) in other operating systems. Jim Nance (jlnance@avanticorp.com) has posted a comparison to linux-kernel. Here is an extract of his message:  The original question is enough of an FAQ that I thought it would be good to have real numbers rather than just my assurances that Linux has a fast FS layer.  Therefore I wrote a benchmarking program that creates/writes/destroys files and ran it under several operating systems and on several types of file systems.  I have included that program as an attachment to this mail.  Here are the results:  OS                      Hardware        FS Type         Loops/Second -------------------------------------------------------------------- Linux 2.2.5-ac6         1               nfs             16.33 Linux 2.2.5-ac6         1               arla            73.67 Linux 2.2.5-ac6         1               ext2            15383.32 Solaris 2.6             2               afs             71.33 Solaris 2.6             2               nfs             10.00 Solaris 2.6             2               ufs             23.67 Solaris 2.6             2               tmpfs           9162.32 Digital Unix 4.0D       3               afs             49.33 Digital Unix 4.0D       3               nfs             14.67 Digital Unix 4.0D       3               ufs             28.67 Digital Unix 4.0D       3               memfs           3062.66 Linux 2.0.33            4               afs             69.33 Linux 2.0.33            4               nfs             15.00 Linux 2.0.33            4               ext2            2218.33  Hardware: 1 -> 333 MHz PII, 512M ram, Compaq WDE4360W disk 2 -> Ultra450 class Sun server (300MHz?) 3 -> Personal Workstation 600 AU. 600 MHz alpha.  1.5G ram 4 -> 75 MHz Pentium, 32M ram, Segate ST31200N disk  Notice how Linux writting to an ext2 file system is significantly faster than any other OS/FS combination.  The next closest is Solaris writting to tmpfs, and its still far behind ext2.  It's also good to notice how slow both Solaris and Digital Unix are on their local file systems. This is probably why both have a ram base file system.  Please note that this benchmark is intended to measure the time it takes to create and delete files, which is expensive on most non-linux systems.  It does not indicate anything about the data I/O rate to an existing file.   It would be interesting to see a comparison between Linux ext2fs and tmpfs.       (REG, by Adam Sulmicki)  If after reading all the above you still feel you need tmpfs, and you're stuck in the stone age with a 2.2 kernel, read on. However, keep in mind it is more of a hack than true tmpfs.   The magic way to do it is:     compile ramdisk support into kernel, the option is:  CONFIG_BLK_DEV_RAM=y      Run the following command to create 2mb ext2 ram disk:  /sbin/mke2fs -vm0 /dev/ram 2048      mount it:  mount /dev/ram /tmp      And you are done.            What is the maximum file size/filesystem size?        (REG)  Maximum file size depends on the block size on your filesystem. For ext2 (and UFS, SysVFS and similar filesystems), the limits are:  Block size      Maximum file size (GiBytes) 512 B           2 1   kiB         16 2   kiB         128 4   kiB         1024 8   kiB         8192   (PAGE_SIZE must be >= 8 kiB)   plus a small amount. The limitation is due to the classic triply-indirect addressing scheme. In the future, ext2 will have extent-based addressing, which will overcome this problem.   The limit for a single filesystem (partition) on a 32 bit CPU is 4 Gi blocks. Each block is 512 Bytes, so that works out to 2 TiB. For 64 bit CPUs, the limits are bigger than you can imagine.            Linux uses lots of swap while I still have stuff in cache. Isn't this wrong?        (MRW)  Not really. Linux will swap out binaries which haven't been used for a long time (e.g. lprd on many systems) in favour of retaining data from files which have been used recently (e.g. header files while compiling a big program). This is more efficient. Trust us, we're engineers.            Why don't we add resource forks/streams to Linux filesystems like NT has?        (REG)  Resource forks (aka ""named streams"") are a way of storing multiple ""streams"" of data in a file. Each stream may be read, written and seeked in just like in files with only one stream of data. Resource forks are used to store ancillary data with files (such as which icon to display for the file when using a graphical filemanager). These extra streams of data may be manipulated by any user who has write access to the file, just as the ""primary"" stream can be manipulated.   Unix only supports one ""stream"" of data per file. Adding support for multiple streams to the Linux kernel is not considered to be especially difficult. However, files with multiple data streams would break a large number of user-space programmes (which currently only manipulate the ""primary"" stream) and  protocols  (such as ftp, http, email, NFS and many more). A number of new utilities would need to be written, and a large number of shell scripts would have to be audited for correctness in a multiple-stream world. Because of this massive breakage, many kernel developers consider resource forks to be a bad idea.   Rather than add kernel support, a user-space library could be written which provided easy management of multiple steams of data for applications, while still storing the data in a single Unix file. If someone wants to write such a library, please do so. Once it's completed, send an email to the FAQ maintainer.   Note that the GNUstep/Foundation library has the  NSBundle  class, which provides this functionality. A number of APIs to this class for different languages are available:      Objective-C  has GNUstep at:  http://www.gnustep.org/       Java  has JIGS at:  http://www.gnustep.it/jigs/       Smalltalk  has StepTalk at:   http://decef.elf.stuba.sk/~urbane/StepTalk/       Scheme  has gstep-guile at:   http://www.tiptree.demon.co.uk/gstep/guile/gstep_guile_toc.html      Note that a separate problem is the storage of ""extended attributes"". These are attributes like file permissions (such as ACLs and POSIX capability sets), which have limited size, and tend to be read and written atomically (i.e. you can't read or write part of the attribute nor seek in it). These usually require special privileges to modify. Also, you normally don't want to copy these attributes when copying files around, thus these extended attributes don't present the problems of massive breakage that resource forks would.            Why don't we internationalise kernel messages?        (REG)  There are several reasons why this should not be done:    It would bloat the kernel sources    It would drastically increase the cost of maintaining the kernel message database    Kernel message output would slow down    English is the language in which the kernel sources are written, and thus is the language in which kernel messages are written. Developers cannot be expected to provide translations    Bug reports should be submitted in English, and that includes kernel messages. If kernel messages were to be output in some other language, most developers could not help in fixing bugs    Translation can be performed in user-space, there is no need to change the kernel    It would bloat the kernel sources     Finally, it  will not  be done. No core developer supports this. Neither does Linus. Don't even ask.               Section 10 - ""What's changed between kernels 2.0.x and 2.2.x"" questions         Size (source and executable)?        (REW)  I use the following to quickly estimate the size of a project:  cat `find . -name \*.c -o -name \*.h -o -name \*.S `| wc -l   I get 811985 (lines of code, including comments and blank lines) when I run this on the 2.0.33 kernel source, and 1460508 when I run this on a 1.0.106 kernel.  This means that the Linux kernel qualifies as an ""extremely large"" software product, requiring the effort of 200 to 500 programmers for 5 to 10 years. [Richard Farley: Software engineering concepts, Mc Graw-Hill, 1985, page 11].  Actually, the Linux kernel is now 7 years old, and has seriously involved 100 to 1000 programmers. (i.e. not counting those that have contributed a ""one line fix""). This is my personal guess, so feel free to disagree or tell me otherwise.       (ADB)  I can't compare actual kernel footprints of 2.0.x vs. 2.1.x, but I think it's worth mentionning that 2.1.x kernels have the ability to ""jettison"" kernel initialization code, freeing the corresponding physical memory. So, even though the  executable  is certainly larger for 2.1.x kernels, you may actually get a smaller memory  footprint .            Can I use a 2.2.x kernel with a distribution based on a 2.0.x kernel?        (REW)  Yes. However some applications may need upgrading. Read /usr/src/linux/Documentation/Changes before you complain about something not working. Also note that the 2.1.(x+1) kernel may need a different set of upgrades than 2.1.x, so you should check the Changes file  every single time  you upgrade your Linux kernel.            New filesystems supported?        NTFS  (read-only). Allows read-only access to Windows NT (tm) partitions.       Coda . Coda is an advanced experimental distributed file system with features such as server replication and disconnected operation for laptops. Note that Coda is also available for 2.0.x kernels as an add-on package. Check the  Coda Web site  for more information.            Performance?        (REG)  Here are some performance optimizations which are only available on 2.2.x kernels:       MTRRs . MTRRs are registers in PPro and Pentium II CPUs which define memory regions with distinct properties. The default mode for PCI memory accesses is ""uncacheable"" which means memory and I/O addresses on a PCI peripheral are not cached. For linear frame buffers, a better mode is ""write-combining"" which allows the CPU to re-order and slightly delay writes to memory so that they can be done in blocks. If you are writing to the PCI bus, you then use PCI burst mode transfers, which are a few times faster.      Finer grained locking . Most instances of the global SMP spinlock have been replaced with finer grained locking. This gives much better concurrency.      User buffer checks . Replaced the old, painful way of checking if user buffers passed to syscalls were legal by a kernel exception handler.  The kernel now assumes a buffer is OK. If not, an exception handler catches the fault and returns -EFAULT to user space. The advantage is that legal buffers no longer need to be carefully checked, which is much faster. The old scheme was also suffering from race conditions under SMP.      New directory entry cache (dcache) . This makes file lookups much faster.  Example:  time find /usr -name gcc -print   2.1.104: cold cache:  0.180u 0.460s 0:15.02 4.2% 0+0k 0+0io 85pf+0w   2.1.104: warm cache:  0.100u 0.150s 0:00.25 100.0% 0+0k 0+0io 72pf+0w   2.0.33: cold cache:  0.100u 0.660s 0:14.87 5.1% 0+0k 0+0io 85pf+0w   2.0.33: warm cache:  0.090u 0.600s 0:00.69 100.0% 0+0k 0+0io 72pf+0w   Note /usr had 17750 files/directories. We see how with a cold cache (no disc blocks cached) there is very little difference. However, once the cache is warm, we see  a fourfold reduction in system time . This is because inode lookups are not needed when a dcache entry is available. Tests performed on a Pentium/MMX 200.                New drivers not available under 2.0.x?        (XXX)  Please add your answer here...            What are those __initxxx macros?        (KGB)  __initfunc() for example is a macro used to put its first argument (a function) into a special ELF section that is dropped from memory once drivers's initialization is over.  So if you write an initialization function, whose code will never be used again after your driver is initialized, you can use __initfunc() around its declaration in order to reduce your kernel memory footprint by a few KB of memory. Similarly, __initdata() is used for variables, arrays, strings, etc. For implementation details and examples please consult the file include/linux/init.h from a 2.2.x source tree.  The main idea here is that the kernel memory is not swappable. Jettisoning useless code represents a nice way to save RAM.            I have seen many posts on a ""Memory Rusting Effect"". Under what circumstances/why does it occur?        (ADB)  AFAIK the expression was coined by Bill Metzenthen, who also provided many data points measuring this phenomenon. It describes the not-so-sane behaviour of the MM layer in kernels 2.1.x (where x is approx. > 50) in small memory systems (e.g. 8 MB machines). Alan Cox recommends the following procedure to detect the Memory Rusting Effect:  (if you have > 8 MB of RAM installed, reboot with  mem=8M  as a kernel boot parameter before)  time make zImage find / -print time make zImage   Comparing the results of the  time  measurements will show whether the memory has been rusted or not by the  find .  Note that just comparing the time it takes to compile a sample kernel under 2.0.x versus 2.1.x is the  wrong  way to measure the Memory Rusting Effect. So don't post this kind of data to the list (we already know it takes longer under 2.1.x in small memory machines).  The Memory Rusting Effect is being investigated by a number of kernel hackers, and it seems practically solved as of kernel 2.1.111.            Why does ifconfig show incorrect statistics with 2.2.x kernels?        (TJ)  This is in  linux/Documentation/Changes  that comes with the kernel sources:  ""For support for new features like IPv6, upgrade to the latest net-tools. This will also fix other problems. For example, the format of /proc/net/dev changed; as a result, an older ifconfig will incorrectly report errors.""              My pseudo-tty devices don't work any more. What happened?        (TJ)  Support for ptys using a major number of 4 was dropped in Linux 2.1.115. Replace your device files with ones using the new major numbers, 2 and 3. They will work with later 1.3 versions of Linux, and any 2.x version.       (REG)  If you use devfs, then this problem magically goes away.            Can I use Unix 98 ptys?        (TJ, with much information provided by H. Peter Anvin)  Yes, but only if you have a kernel and libc which support them, and if your applications are written and compiled to use them. They will be supported by Linux 2.2 and glibc 2.1. This is in  Documentation/Changes  that comes with the kernel sources.  There is also the new standalone libpt by Duncan Simpson which implements the Unix98 PTY API independently of libc (check the Incoming directory on metalab.unc.edu/Linux and mirrors). You still need to have your apps compiled to use this API, of course.            Capabilities?        (TJ)  There's a FAQ on capabilities under Linux at   ftp://ftp.guardian.no/pub/free/linux/capabilities/capfaq.txt .            Kernel API changes        (REG)  Some parts of the kernel API (programming interface) have changed from v2.0 to v2.2. This is relevant to the authors of 3rd party device drivers, filesystems and other code. So called ""3rd party"" code is any kernel code which is not distributed with the official kernel tarball that Linus distributes. A quick reference for programmers wishing to port their code to v2.2 is available   here . Note that this document is not relevant for programmes running in user space.   If you want to port your drivers to the 2.4 series kernel, then read   this , which tells you how to port code from 2.2 to 2.4.               Section 11 - Primer documents         What's a primer document and why should I read it first?        (REG)  From time to time various technical debates start on the linux kernel list. Some of these are about quite important topics, however often these debates are repeated every few months or so and much of the same ground is covered each time around. Other times, questions about how some part of the Linux kernel works are posted. Often we see the same old questions time and time again. Don't get me wrong: these are often reasonable questions, it's just that seeing them over and over is something we'd rather avoid.  This section has some primer document links on various topics that should be read before starting a debate or posing a question (which itself can lead to a debate). This is not an attempt to censor debate, rather, it's an attempt to get you familiar with the current arguments so that you can contribute something new without going over old ground. If it's just a question you have, hopefully we can explain it clearly once, in a single document, and then point everybody to it.            How about having I/O completion ports?        (REG)  The existing UNIX semantics - select(2) and poll(2) - for polling for activity on FDs do not scale very well: the overhead is too high with large numbers of FDs. Here is a  primer document  which explains some of the problems and explores some solutions.            What is the VFS and how does it work?        (REG)  The VFS (Virtual FileSystem or Virtual Filesystem Switch, depending on who you talk to) is basically the Linux filesystem layer. It incorporates the dentry cache and standard UNIX file semantics. It also contains a ""switch"" to specific filesystem types (ext2, vfat, iso9660 and so on), which is why Linux supports so many different filesystems. Read this  VFS primer  document if you want to know more.            What's the Linux kernel's notion of time?        (ADB)  I have tried to put together some information on this topic, which you can find  here . Colin Plumb  is working on new code for the Linux kernel software clock.            Is there any magic in /proc/scsi that I can use to rescan the SCSI bus?        (TJ)  The text below is from drivers/scsi/scsi.c.  /*    * Usage: echo ""scsi add-single-device 0 1 2 3"" >/proc/scsi/scsi    * with  ""0 1 2 3"" replaced by your ""Host Channel Id Lun"".    * Consider this feature BETA.    *     CAUTION: This is not for hotplugging your peripherals. As    *     SCSI was not designed for this you could damage your    *     hardware !    * However perhaps it is legal to switch on an    * already connected device. It is perhaps not    * guaranteed this device doesn't corrupt an ongoing data transfer.    */   For a typical discussion of this topic, see  http://jpj.net/~trevor/linux/rescan_scsi.txt.gz .               Section 12 - Kernel Programming Questions         When is cli() needed?        (ADB)  cli() is a kernel wide function that disables maskable interrupts, whereas sti() is the equivalent function that enables maskable interrupts. Some routines must be run with interrupts disabled, because some peripherals need a guaranteed access sequence, or because the routine is not reentrant and could be reentered from an interrupt, etc. You should never use cli() in a user space program/daemon.       (REW)  The use of cli() is no longer encouraged.  On a single processor, this simply clears an internal CPU flag, which is ANDed with the Maskable Interrupt Request pin. On SMP systems it is quite troublesome to keep ALL processors from servicing interrupts if one processor wants to do something uninterrupted. Currently we try to do locking on a much finer scale. For example, you should put a spinlock on the record that describes THIS INSTANCE of the device that needs the handling without accesses to other registers (e.g. from the interrupt routine). Besides preventing the overhead of trying to keep the other CPUs from handling interrupts, this allows the other CPUs to service interrupts from a second card of the same type in the same machine.            Why do I see sometimes a cli()-sti() pair, and sometimes a save_flags-cli()-restore_flags sequence?        (RRR)  The cli()-sti() pair assumes that interrupts were enabled when execution of the code began, and thus proceeds to reenable them at the end. The save_flags-cli-restore_flags sequence doesn't make this assumption. Since the interrupt flag is one of the flags saved by save_flags(), it will be correctly restored to its previous state by restore_flags().  This is  critical  for code that may be called with interrupts either on or off.   Using save_flags-cli-restore_flags does incur in a very slight overhead as compared to the cli()-sti) pair, which may be significant for speed critical code (apart from being superfluous if it's known a priori that the code will never be called with interrupts off).       (REG)  Note that on UP systems cli(), sti() and restore_flags() operate immediately. However, on SMP systems, these functions may have to wait for the global IRQ lock (when another CPU has disabled interrupts). Other than this difference, these functions are SMP safe. It is also safe to call cli() multiple times on one CPU: the global IRQ lock is only grabbed the first time.            Can I call printk() when interrupts are disabled?        (REG)  Yes, you can, a lthough you should be careful. Older kernels had the infamous  cli()-sti() pair  in printk(), so you would get enabled interrupts when returning from printk(), whether printk() was called with interrupts disabled or enabled; whereas recent kernels (e.g. 2.1.107) restore the flags when printk() is finished. You have to know which version of the kernel you are coding for. Read the Source, Luke. Also note that in 2.2.x kernels, printk() grabs a spinlock for SMP machines to avoid any possible deadlocks.            What is the exact purpose of start_bh_atomic() and end_bh_atomic()?        (REG, quoting Krzysztof G. Baranowski)   To protect your code from being interrupted by a bottom half handler. It is mostly used in syscalls and functions called from userspace and is better than cli/sti pair, because most of the time there is no need to mask interrupts on hardware level..            Is it safe to grab the global kernel lock multiple times?        (REG)  Yes. The global kernel lock is recursive per process. That means a process can grab the lock multiple times and not deadlock. The lock is released when  unlock_kernel()  is called as many times as  lock_kernel()  was called.            When do I need to initialise variables?        (REG)  All variables should be initialised (implicitly or explicitly) before they are read from. Automatic variables are placed on the stack, and thus will have a random initial value. This means that you need to manually initialise them.   Static variables are placed in the .bss section, which is initialised to zero by the kernel (at the start of the boot sequence). If the initial value of a static variable should be zero, you don't need to do anything. If it should be a non-zero value, you will need to initialise it. Note that you should not explicitly initialise a static variable to zero, as this will increase the size of the kernel image, which causes problems for embedded systems.               Section 13 - Mysterious kernel messages         What exactly does a ""Socket destroy delayed"" mean?        (TJ, from a post by Henner Eisen)  Sometimes you may get:    Jul 25 22:14:02 zero kernel: Socket destroy delayed (r=212 w=0)    in /var/log/messages.   It means that the kernel cannot free the internal data structures associated with a released socket because there are still socket data buffers (in the above case 212 bytes read memory) accounted to the socket. For this reason, destroying is delayed and tried again later. At some point, after the remaining sk_buffs accounted to the socket are freed, destroying should succeed. Also:     It keeps spitting that out about every 5 seconds or so. the only way to fix it is to reboot. It doesn't happen very often, but I'd like to find out what's causing it.    This might indicate a problem that some kernel entity (i.e protocol module or network device driver), which is responsible for freeing an sk_buff, fails to do so. To help tracking down the problem, try to find out under which circumstances the messages start to appear (in particular, which program closed a socket right before the messages appears, which network protocol does it use, which network device drivers are involved).              What do I do about ""inconsistent MTRRs""?        (REG)  Sometimes you may get:   mtrr: your CPUs  had  inconsistent ... MTRR settings   mtrr: probably your BIOS does not setup all CPUs  In English, using ""had"" as past or past perfect tense commonly implies that the condition no longer exists. While it isn't absolutely proper, it is very common. The MTRRs  were  inconsistent, but they aren't anymore. The kernel fixed them up. Everything is fine now.             Why does my kernel report lots of ""DriveStatusError BadCRC"" messages?        (REG, contributed by Mark Hahn)  You may see messages like:  kernel: hda: dma_intr: status=0x51 { DriveReady SeekComplete Error } kernel: hda: dma_intr: error=0x84 { DriveStatusError BadCRC }   In UDMA modes, each transfer is checksum'ed for integrity (like Ultra2 SCSI, and more robust than normal SCSI's parity checking). When a transfer fails this test, it is retried, and this warning is reported. Seeing these warnings occasionally is not unusual or even a bad thing - they just inflate your logs a little. If this really bothers you, you can comment out the warning in the driver.   Seeing lots of these warnings (multiple per second) is almost certainly a sign that your IDE hardware is broken.  For reference, all IDE must:    have a cable length of 18"" or less    have both ends  plugged in (no stub)    be 80-conductor cable if you're using a mode > udma33.     IDE modes are generally also generated from the system clock, so if you're overclocking (for instance, running AGP at 75 MHz), you're violating IDE specs, and should not expect correct behavior. Similarly, it's possible for your controller's driver to get timing parameters wrong, but this is certainly not the first explanation to adopt.            Why does my kernel report lots of ""APIC error"" messages?        (REG, contributed by Mark Hahn)  You may get messages like:  APIC error on CPU1: 00(08) .   APIC is the hardware that ia32 systems use to communicate between CPUs to handle low-level events like interrupts and TLB flushes. APIC messages are checksummed, and automatically retried when they fail. This message indicates that a transaction failed; it's only a problem when there are many of them. The APIC checksum is quite weak, so even a few failures is a cause for concern, since it implies that some corruption has likely gone undetected.   Assuming you're not forcing your motherboard to use an invalid system clock (i.e. AGP other than 66 MHz), this is strictly a physical design flaw in your motherboard. The Abit BP6 is notorious for this flaw, but it's not unheard of on other boards (such as the Gigabyte BXD), and it's possible on any board that uses APICs.   You can force the kernel not to use APIC like this with the ""noapic"" kernel option. This also forces CPU0 to handle all interrupts.               Section 14 - Odd kernel behaviour         Why is kapmd using so much CPU time?        (REG)  Don't worry, it's not stealing valuable CPU time from other processes. It's just consuming idle cycles (normally charged to the idle task, which is displayed differently in  top ).   Normally, when your system is idle, the system idle task is run, and this is shown as idle time (i.e. the ""unused"" CPU time is not charged to a specific process). With APM (Advanced Power Management), a special idle task (kapmd) is required so that greater power saving techniques can be enabled. So now, the ""unused"" CPU time is charged to the kapmd task instead.            Why does the 2.4 kernel report  Connection refused  when connecting to sites which work fine with earlier kernels?        (DW)  The 2.4 kernel is designed to make your Internet Experience more pleasurable. One of the ways in which it does so is by implementing Explicit Congestion Notification - a new method defined in  RFC 3168  for improving TCP performance in the presence of congestion by allowing routers to provide an early warning of traffic flow problems.   Unfortunately, there are bugs in some firewall products which cause them to reject incoming packets with ECN enabled. If your own firewall is broken in this respect, you should check with your vendor for a fix.   If the site to which you cannot connect is not under your control, then after you have contacted the administrator of the offending site to let them know about their problem, you can disable ECN in the 2.4 kernel either by disabling the  CONFIG_INET_ECN  option and recompiling the kernel, or by executing the following command as root:    # echo 0 > /proc/sys/net/ipv4/tcp_ecn        (REG)  Fixes are available from some router vendors, and have been since at least mid-2000. These are not ""feature patches"" (which may add new features and have new bugs), but purely bug fixes, and thus should be safe to use, even for the most paranoid. If you have problems connecting to a site, please contact their support. Note that some major sites are known to have lied about fixes from their router/firewall vendor, so if you hear the excuse ""we are waiting on a fix from our vendor"", be skeptical. While there is a workaround available (see above), it is important to encourage sites and ISPs to be ECN tolerant. This doesn't mean that these sites need to support ECN (although it's in their interests), but they need to fix buggy routers so that ECN-enabled systems can fall back to non-ECN mode, rather than having refused or timed out connections. The specific RFC that these buggy routers are violating is:  RFC 793 .    vger.kernel.org is running an ECN-enabled kernel. This means if your email account is with an ISP which has a buggy router, you will not be able to receive linux-kernel mail (as well as other mailing lists hosted on vger). You should check if your ISP is ECN tolerant, and get them to fix their routers or switch to another ISP.    Patches for the following products are available:    CISCO PIX. Patch available for download   here . Patch information:  Bug ID:        CSCds23698 Headline:      PIX sends RSET in response to tcp connections with ECN bits set Product:       PIX Component:     fw Severity:      2            Status:           R [Resolved] Version Found: 5.1(1)       Fixed-in Version: 5.1(2.206) 5.1(2.207) 5.2(1.200)      CISCO Local Director. Patch available for download   here . Patch information:  Bug Id : CSCds40921   Headline:  LD rejects syn with reserved bits set in flags field of TCP hdr   Product:  ld   Component: rotor  Severity: 3                     Status:        R [Resolved]   Version Found: 3.3(3)           Fixed-in Version: 3.3.3.107        Further information may obtained from  http://gtf.org/garzik/ecn/             Why does the kernel now report zero shared memory?        (REG, contributed by Erik Mouw)  Yes, the processes still share memory, but due to changes to the VM in 2.4 it became too CPU intensive to calculate the total amount of shared memory. In order not to break the userland tools, the ""MemShared"" field in /proc/meminfo was set to 0.            Why does  lsmod  report a use count of -1 for some modules? Is this a bug?        (REW)  There are several possibilities. First:       (DW)  No, this is not necessarily a bug. A module may report a use count of -1 if it has a  can_unload  function, which is called when necessary by the system to determine if it is safe to unload the module.       (REW)  But then again, it could be a bug anyway. In that case, you'd normally see the usage count at 0 (or more when it's actually used), and when ""something"" happens, the usage may drop below zero. If you can repeat this, please drop the driver maintainer an Email. Some modules lack the code to unload. They will deliberately set their usage count to -1 to prevent unloading.            Why doesn't the kernel see all of my RAM?        (REG, based on contribution from Mark Hahn)  Some older distributions like (RedHat 6.1) are quite old, and use a 2.2 kernel which has not fundamentally changed since mid-to-late 1998. Way back then, the safe thing for the kernel to do was trust the standard bios memory detection mechanism. That bios call returns memory size as a 16 bit count of 1 KiB chunks, leading to a 64 MiB limit. Modern kernels (2.4 is the current stable kernel) use more modern bios calls that can detect all your memory, and even keep track of which memory is used by the bios itself. So your best option is to install a modern kernel.  You can workaround the 64 MiB limit with obsolete kernels by telling the kernel how much memory you have, by using the  mem=  boot argument. For example, if you have 128 MiB of RAM, you would type  mem=128M  at the lilo prompt, or can have lilo use the argument automatically (add  append=""mem=128M""  to your  /etc/lilo.conf  file).            I've mounted a filesystem in two different places and it worked. Why?        (AV, paraphrased by William Stearns) Because you've asked the kernel to do that. Yes, it works. No, it's not a bug. To unmount it from either mountpoint, simply run  umount <mountpoint> . Repeat for each mountpoint on which you do not wish the filesystem mounted.               Section 15 - Programming Religion         Why is the Linux kernel written in C/assembly?        (ADB)  For many reasons, some practical, others theoretical. The practical reasons first: when Linus began writing Linux, what he had available was a 386, Minix (a minimal OS designed by Andrew Tanenbaum for OS design teaching purposes) and gcc. The theoretical reasons: some small parts of any OS kernel will always be written in assembly language, because they are too dependent on the hardware to be coded in C; for example, CPU and virtual memory setup. Or because we are dealing with very short routines that must be implemented in the fastest possible code e.g. the stubs for the ""top half"" interrupt handlers. WRT C, OS designers (since Thompson and Ritchie first wrote UNIX) have traditionally used C to implement as many OS kernel routines as possible. In this sense C can be considered the ""canonical"" language for OS kernel implementation, and particularly for UNIX variants.            Why don't we rewrite it all in assembly language for processor Mega666?        (ADB)  Basically because we wouldn't gain much in terms of efficiency, but would lose a lot in terms of ease of maintenance and readability of the source code. Gcc is actually quite efficient, when we look at the assembler code generated. You are referred to Andrew Tanenbaum's book ""Structured Computer Organization"", 3rd ed., pages 401-404, for a more detailed comparison of the use of high level languages vs. assembly language in the implementation of OS's. There are a number of references on the subject at the end of the book, too.            Why don't we rewrite the Linux kernel in C++?        (ADB)  Again, this has to do with practical and theoretical reasons. On the practical side, when Linux got started gcc didn't have an efficient C++ implementation, and some people would argue that even today it doesn't. Also there are many more C programmers than C++ programmers around. On theoretical grounds, examples of OS's implemented in Object Oriented languages are rare (Java-OS and Oberon System 3 come to mind), and the advantages of this approach are not quite clear cut (for OS design, that is; for GUI implementation  KDE  is a good example that C++ beats plain C any day).       (REW)  In the dark old days, in the time that most of you hadn't even heard of the word ""Linux"", the kernel was once modified to be compiled under g++. That lasted for a few revisions. People complained about the performance drop. It turned out that compiling a piece of C code with g++ would give you worse code. It shouldn't have made a difference, but it did. Been there, done that.       (REG)  Today (Nov-2000), people claim that compiler technology has improved so that g++ is not longer a worse compiler than gcc, and so feel this issue should be revisited. In fact, there are five issues. These are:      Should the kernel use object-oriented programming techniques?  Actually, it already does. The VFS (Virtual Filesystem Switch) is a prime example of object-oriented programming techniques. There are objects with public and private data, methods and inheritance. This just happens to be written in C. Another example of object-oriented programming is Xt (the X Intrinsics Toolkit), also written in C. What's important about object-oriented programming is the techniques, not the languages used.    Should the kernel be rewritten in C++?  This is likely to be a very bad idea. It would require a very large amount of work to rewrite the kernel (it's a  large  piece of code). There is no point in just compiling the kernel with g++ and writing the odd function in C++, this would just result in a confusing mix of C and C++ code. Either the kernel is left in C, or it's all moved to C++.   To justify the enormous effort in rewriting the kernel in C++, significant gains would need to be demonstrated. The onus is clearly on whoever wants to push the rewrite to C++ to show such gains.      Is it a good idea to write a new driver in C++?  The short answer is no, because there isn't any support for C++ drivers in the kernel.      Why not add a C++ interface layer to the kernel to support C++ drivers?  The short answer is why bother, since there aren't any C++ drivers for Linux. However, if you are bold enough to consider writing a driver in C++ and a support layer, be aware that this is unlikely to be well received in the community. Most of the kernel developers are unconvinced of the merits of C++ in general, and consider C++ to generate bloated code. Also, it would result in a confusing mix of C and C++ code in the kernel. Any C++ code in the kernel would be a second-class citizen, as it would be ignored by most kernel developers when changes to internal interfaces are made. A C++ support layer would be frequently be broken by such changes (as whoever is making the changes would probably not bother fixing the C++ code to match), and thus would require a strong commitment from someone to regularly maintain it.      Can we make the kernel headers C++-friendly?  This is the first step required for supporting C++ drivers, and on the face seems quite reasonable (it is not a C++ support layer). This has the problem that C++ reserves keywords which are valid variable or field names in C (such as  private  and  new ). Thus, C++ is not 100% backwards compatible with C. In effect, the C++ standards bodies would be dictating what variable names we're allowed to have. From past behaviour, the C++ standards people have not shown a commitment to 100% backwards compatibility. The fear is that C++ will continue to expand its claim on the namespace. This would generate an ongoing maintenance burden on the kernel developers.   Note that someone once submitted a patch which performed this ""cleaning up"". It was ~250 kB in size, and was quite invasive. The patch did not generate much enthusiasm.   Apparently, someone has had the temerity to label the above paragraph as ""a bit fuddy"". So Erik Mouw did a short back-of-the-envelope calculation to show that searching the kernel sources for possible C++ keywords is a nightmare. Here is his calculation and comments (dates April, 2002):  % find /usr/src/linux-2.4.19-pre3-rmap12h -name ""*.[chS]"" |\     xargs cat | wc -l   4078662  So there's over 4 million lines of kernel source. Let's assume 10% is comments, so there's about 3.6 million lines left. Each of those lines has to be checked for C++ keywords. Assume that you can do about 5 seconds per line (very optimistic), work 24 hours per day, and 7 days a week:                   5 s   1 hour     1 day   1 week 3600000 lines * ------ * -------- * ---------- * -------- = 29.8 weeks                  line     3600 s     24 hours     7 days  Sounds like a nightmare to me. You can automate large parts of this, but you'll need to write a *very* intelligent search-and-replace tool for that. Better use that time in a more efficient way by learning C.    Note that this is the time required to do a proper manual audit of the code. You could cheat and forgo the auditing process, and instead just compile with C++ and fix all compiler errors, figuring that the compiler can do most of the work. This would still be a major effort, and has the problem that there may be uses of some C++ keyword which don't generate a compiler error, but do generate unintended code. In other words, introduced bugs. That is not a risk the kernel development community is prepared to take.        My personal view is that C++ has its merits, and makes object-oriented programming easier. However, it is a more complex language and is less mature than C. The greatest danger with C++ is in fact its power. It seduces the programmer, making it much easier to write bloatware. The kernel is a critical piece of code, and must be lean and fast. We cannot afford bloat. I think it is fair to say that it takes more skill to write efficient C++ code than C code. Not every contributer to the linux kernel is an uber-guru, and thus will not know the various tricks and traps for producing efficient C++ code.            Why is the Linux kernel monolithic? Why don't we rewrite it as a microkernel?        (REG)  The short answer is why should we? The longer answer is that experience has shown that microkernels have poor performance compared to monolithic kernels. Microkernels have a fundamental design problem, where different components of the kernel cannot interact without passing a privilege barrier (which is expensive). Microkernel advocates claim this is a feature, as it increases modularity and protects one part of the kernel from another. Whether this is a feature or a mis-feature is in the eye of the beholder, but it is clear that there is a performance cost inherent in the microkernel design. This is a cost the Linux kernel developers (and apparently, the users) are unwilling to bear.   There are projects which have ported the Linux kernel to generic microkernels (such as  Mach3 ), usually making Linux a ""personality"". There are also other projects to create microkernel-based Unix-like implementations. Here is a short list:    MkLinux was funded by Apple, and runs Linux on PowerPC Macs. It is available at:  http://www.mklinux.org/ . An x86 version is also available. Note that there is now a native Linux kernel for the PowerPC which is much faster, and is actively maintained. MkLinux has become a historical footnote.    The Hurd is a microkernel-based Unix, and is supposed to be the promised  GNU  kernel. It sits on top of Mach3. The  Debian Project  provides a full  distribution  for the Hurd.    FIASCO is another project for creating MicroKernel LINUX. See   http://os.inf.tu-dresden.de/fiasco/  for details.     There is a   historical Usenet thread  related to this subject, dating back from 1992, with posts from Linus,  Andrew Tanenbaum ,  Roger Wolff ,  Theodore Y T'so ,  David Miller  and others. Nice reading on a rainy afternoon. It's fascinating to see how some predictions (which seemed rather reasonable at the time) have proved wrong over the years (for example, that we would all be using RISC chips by 1998).            Why don't we replace all the goto's with C exceptions?        (REG)  Admittedly, all those goto's do look a bit ugly. However, they are usually limited to error paths, and are used to reduce the amount of code required to perform cleanup operations. Replacing these with Politically Correct if-then-else blocks would required duplication of cleanup code. So switching to if-then-else blocks might be good Computer Science theory, but using goto's is good Engineering. Since the Linux kernel is one designed to be used, rather than to demonstrate theory, sound engineering principles take priority.   So now we come to the suggestion for replacing the goto's with C exception handlers. There are two main problems with this. The first is that C exceptions, like any other powerful abstraction, hide the costs of what is being done. They may save lines of source code, but can easily generate much more object code. Object code size is the true measure of bloat. A second problem is the difficulty in implementing C exceptions in kernel-space. This is convered in more detail below.       (REG, quoting Keith Owens)  The exceptions patch has to use assembler to walk the stack frames.  Exceptions are being touted as a replacement for goto in new driver code but the sample patch only works for i386.  No arch independent code can use exceptions until you have arch specific code that does the equivalent of longjmp for _all_ architectures.   Doing longjmp in the kernel is _hard_, I know because I had to do it for kdb on i386 and ia64.  The kernel does things differently from user space and sometimes the arch maintainers decide to change the internal register usage.  They are allowed to do this because it only affects the kernel, but any change to kernel register usage will probably require a corresponding change to setjmp/longjmp.   So you have arch dependent code which has to be done for all architectures before any driver can use it and the code has to be kept up to date by each arch maintainer.  Tell me again why the existing mechanisms are not working and why we need exceptions?  IOW, what existing problem justifies all the extra arch work and maintenance?            Why are the kernel developers so dismissive of new techniques?        (REG)  This is a complaint that is raised periodically, usually shortly after some debate or flamewar following on from a suggestion to use a ""new"" technique. Often one or more noted kernel developers will shoot down the idea with a dismissive ""that's a dumb idea"" or ""all pain, no gain"", without a detailed explanation of why it's a bad idea. This does indeed look arrogant and dismissive, and gives the impression that the kernel developers are a pack of old dogs unwilling to learn new tricks. This perception is compounded by proclamations made by various computer science teachers about the positive value of the proposed new technique.   It should be noted, however, that kernels developers are exceptionally busy people, and generally prefer to write code than engage in lengthy discussions about why some idea is not good (at least for the kernel). Further, it's fairly likely that the ""new"" technique that is being proposed has already been evaluated, and found to be inadequate/inappropriate for the kernel. Or perhaps the developer has had prior experience with this technique and found it lacking.   If you are convinced that your favourite technique has value, you have to prove it. You can't demand that other people spend the time explaining to you why they think it's a bad idea. You have to do the hard work yourself to show you're right. Code up a patch and benchmark it compared to the standard kernel. Be prepared to defend your patch in a broader context, and demonstrate that it doesn't have costly side-effects. Remember that many micro-optimisations result in macro slowdowns.   Finally, some personal advice. Coding up a controversial patch and proving you're right is a time-consuming task. Because of this, avoid pushing ideas which you read in a book or heard from some CS notable. Stick to pushing ideas which you have either had prior experience, or have spent a lot of time thinking about. This will increase your chances of picking a winner, and decrease your frustration levels.               Section 16 - User-space programming questions         Why does setsockopt() double SO_RCVBUF?        (REG)  This yields similar behaviour as *BSD versions of Unix. Andi Kleen has stated:  Linux counts internal headers in the buffer. BSD does not. This is a heuristic for compatibility (half of the buffer reserved for headers). To compensate the TCP window offering is halved.                    Contributing  Contributions are welcome on this FAQ. These can be submitted, preferably in  diff -u  format, (against this HTML document source) by Email to Richard (see the  Contributors  section above).   Sometimes, we may feel your contribution is controversial and/or incomplete and/or could be improved somehow. Also, the turnaround time has a wide range, from hours to months, depending on how busy Richard is. Please do not email him to chase changes as it slows him down. Suggestions and patches are queued, and  will  be processed eventually. Acknowledgements are usually sent when the change is made. Please be patient, FAQ updates are rarely urgent. Note that small, ""obviously correct"" patches are more likely to be processed faster, and often jump the queue ahead of larger patches.       Last updated on 26 Dec 2003 by Richard Gooch. This document is GPL'ed by its  various contributors ."
GX127-90-8519058	"Next   Previous   Contents       5. Vendor/Manufacturer/Model Specific Information      The following lists many cards in alphabetical order by vendor name and then product identifier. Beside each product ID, you will see either `Supported', `Semi-Supported' or `Not Supported'.  Supported means that a driver for that card exists, and many people are happily using it and it seems quite reliable.  Semi-Supported means that a driver exists, but at least one of the following descriptions is true: (1) The driver and/or hardware are buggy, which may cause poor performance, failing connections or even crashes. (2) The driver is new or the card is fairly uncommon, and hence the driver has seen very little use/testing and the driver author has had very little feedback. Obviously (2) is preferable to (1), and the individual description of the card/driver should make it clear which one holds true. In either case, you will probably have to answer `Y' when asked ``Prompt for development and/or incomplete code/drivers?'' when running  make config .  Not Supported means there is not a driver currently available for that card. This could be due to a lack of interest in hardware that is rare/uncommon, or because the vendors won't release the hardware documentation required to write a driver.  Note that the difference between `Supported' and `Semi-Supported' is rather subjective, and is based on user feedback observed in newsgroup postings and mailing list messages. (After all, it is impossible for one person to test all drivers with all cards for each kernel version!!!) So be warned that you may find a card listed as semi-supported works perfectly for you (which is great), or that a card listed as supported gives you no end of troubles and problems (which is not so great).  After the status, the name of the driver given in the linux kernel is listed. This will also be the name of the driver module that would be used in the  alias eth0 driver_name  line that is found in the  /etc/conf.modules  module configuration file.        5.1 3Com        If you are not sure what your card is, but you think it is a 3Com card, you can probably figure it out from the assembly number. 3Com has a document `Identifying 3Com Adapters By Assembly Number' (ref 24500002) that would most likely clear things up. See  Technical Information from 3Com  for info on how to get documents from 3Com.  Also note that 3Com has a FTP site with various goodies:  ftp.3Com.com  that you may want to check out.  For those of you browsing this document by a WWW browser, you can try 3Com's WWW site as well.     3c501    Status: Semi-Supported, Driver Name: 3c501  This obsolete stone-age 8 bit card is really too brain-damaged to use. Avoid it like the plague. Do not purchase this card, even as a joke. It's performance is horrible, and it breaks in many ways.  For those not yet convinced, the 3c501 can only do one thing at a time -- while you are removing one packet from the single-packet buffer it cannot receive another packet, nor can it receive a packet while loading a transmit packet. This was fine for a network between two 8088-based computers where processing each packet and replying took 10's of msecs, but modern networks send back-to-back packets for almost every transaction.  AutoIRQ works, DMA isn't used, the autoprobe only looks at  0x280  and  0x300 , and the debug level is set with the third boot-time argument.  Once again, the use of a 3c501 is  strongly discouraged ! Even more so with a IP multicast kernel, as you will grind to a halt while listening to  all  multicast packets. See the comments at the top of the source code for more details.     EtherLink II, 3c503, 3c503/16    Status: Supported, Driver Name: 3c503 (+8390)  The 3c503 does not have ``EEPROM setup'', so a diagnostic/setup program isn't needed before running the card with Linux. The shared memory address of the 3c503 is set using jumpers that are shared with the boot PROM address. This is confusing to people familiar with other ISA cards, where you always leave the jumper set to ``disable'' unless you have a boot PROM.  These cards should be about the same speed as the same bus width WD80x3, but turn out to be actually a bit slower. These shared-memory ethercards also have a programmed I/O mode that doesn't use the 8390 facilities (their engineers found too many bugs!) The Linux 3c503 driver can also work with the 3c503 in programmed-I/O mode, but this is slower and less reliable than shared memory mode. Also, programmed-I/O mode is not as well tested when updating the drivers. You shouldn't use the programmed-I/O mode unless you need it for MS-DOS compatibility.  The 3c503's IRQ line is set in software, with no hints from an EEPROM. Unlike the MS-DOS drivers, the Linux driver has capability to autoIRQ: it uses the first available IRQ line in {5,2/9,3,4}, selected each time the card is ifconfig'ed. (Older driver versions selected the IRQ at boot time.) The ioctl() call in `ifconfig' will return EAGAIN if no IRQ line is available at that time.  Some common problems that people have with the 503 are discussed in   Problems with... .  If you intend on using this driver as a loadable module you should probably see  Using the Ethernet Drivers as Modules  for module specific information.  Note that some old diskless 386 workstations have an on board 3c503 (made by 3Com and sold under different names, like `Bull') but the vendor ID is not a 3Com ID and so it won't be detected. More details can be found in the Etherboot package, which you will need anyways to boot these diskless boxes.     Etherlink Plus 3c505    Status: Semi-Supported, Driver Name: 3c505  This is a driver that was written by Craig Southeren  geoffw@extro.ucc.su.oz.au . These cards also use the i82586 chip. There are not that many of these cards about. It is included in the standard kernel, but it is classed as an alpha driver. See   Alpha Drivers  for important information on using alpha-test ethernet drivers with Linux.  There is also the file  /usr/src/linux/drivers/net/README.3c505  that you should read if you are going to use one of these cards. It contains various options that you can enable/disable.     Etherlink-16 3c507    Status: Semi-Supported, Driver Name: 3c507  This card uses one of the Intel chips, and the development of the driver is closely related to the development of the Intel Ether Express driver. The driver is included in the standard kernel release, but as an alpha driver. See   Alpha Drivers  for important information on using alpha-test ethernet drivers with Linux.      Etherlink III, 3c509 / 3c509B    Status: Supported, Driver Name: 3c509  This card is fairly inexpensive and has good performance for an ISA non-bus-master design. The drawbacks are that the original 3c509 requires very low interrupt latency. The 3c509B shouldn't suffer from the same problem, due to having a larger buffer. (See below.) These cards use PIO transfers, similar to a ne2000 card, and so a shared memory card such as a wd8013 will be more efficient in comparison.  The original 3c509 has a small packet buffer (4kB total, 2kB Rx, 2kB Tx), causing the driver to occasionally drop a packet if interrupts are masked for too long. To minimize this problem, you can try unmasking interrupts during IDE disk transfers (see  man hdparm ) and/or increasing your ISA bus speed so IDE transfers finish sooner.  The newer model 3c509B has 8kB on board, and the buffer can be split 4/4, 5/3 or 6/2 for Rx/Tx. This setting is changed with the DOS configuration utility, and is stored on the EEPROM. This should alleviate the above problem with the original 3c509.  3c509B users should use either the supplied DOS utility to disable the  plug and play  support,  and  to set the output media to what they require. The linux driver currently does  not  support the Autodetect media setting, so you  have  to select 10Base-T or 10Base-2 or AUI. Note that to turn off PnP entirely, you should do a  3C5X9CFG /PNP:DISABLE  and then follow that with a hard reset to ensure that it takes effect.  Some people ask about the ``Server or Workstation'' and ``Highest Modem Speed'' settings presented in the DOS configuration utility. Donald writes ``These are only hints to the drivers, and the Linux driver does not use these parameters: it always optimizes for high throughput rather than low latency (`Server'). Low latency was critically important for old, non-windowed, IPX throughput. To reduce the latency the MS-DOS driver for the 3c509 disables interrupts for some operations, blocking serial port interrupts. Thus the need for the `modem speed' setting.  The Linux driver avoids the need to disable interrupts for long periods by operating only on whole packets e.g. by not starting to transmit a packet until it is completely transferred to the card.''  Note that the ISA card detection uses a different method than most cards. Basically, you ask the cards to respond by sending data to an ID_PORT (port  0x100  to  0x1ff  on intervals of  0x10 ). This detection method means that a particular card will  always  get detected first in a multiple ISA 3c509 configuration. The card with the lowest hardware ethernet address will  always  end up being  eth0 . This shouldn't matter to anyone, except for those people who want to assign a 6 byte hardware address to a particular interface. If you have multiple 3c509 cards, it is best to append  ether=0,0,ethN  commands without the I/O port specified (i.e. use I/O=zero) and allow the probe to sort out which card is first. Using a non-zero I/O value will ensure that it does not detect all your cards, so don't do it.  If this really bothers you, have a look at Donald's latest driver, as you may be able to use a  0x3c509  value in the unused mem address fields to order the detection to suit your needs.     3c515    Status: Supported, Driver Name: 3c515  This is 3Com's ISA 100Mbps offering, codenamed ``CorkScrew''. A relatively new driver from Donald for these cards is included in the v2.2 kernels. For the most up to date information, you should probably look on the Vortex page:    Vortex      3c523    Status: Semi-Supported, Driver Name: 3c523  This MCA bus card uses the i82586, and  Chris Beauregard has modified the ni52 driver to work with these cards. The driver for it can be found in the v2.2 kernel source tree.  More details can be found on the MCA-Linux page at  http://glycerine.cetmm.uni.edu/mca/      3c527    Status: Not Supported.  Yes, another MCA card. No, not too much interest in it. Better chances with the 3c529 if you are stuck with MCA.     3c529    Status: Supported, Driver Name: 3c509  This card actually uses the same chipset as the 3c509. Donald actually put hooks into the 3c509 driver to check for MCA cards after probing for EISA cards, and before probing for ISA cards, long before MCA support was added to the kernel.  The required MCA probe code is included in the driver shipped with v2.2 kernels.  More details can be found on the MCA-Linux page at:  http://glycerine.cetmm.uni.edu/mca/     3c562    Status: Supported, Driver Name: 3c589 (distributed separately)  This PCMCIA card is the combination of a 3c589B ethernet card with a modem. The modem appears as a standard modem to the end user. The only difficulty is getting the two separate linux drivers to share one interrupt. There are a couple of new registers and some hardware interrupt sharing support. You need to use a v2.0 or newer kernel that has the support for interrupt sharing.    Thanks again to Cameron for getting a sample unit and documentation sent off to David Hinds. Look for support in David's PCMCIA package release.  See   PCMCIA Support  for more info on PCMCIA chipsets, socket enablers, etc.    3c575    Status: Unknown.  A driver for this PCMCIA card is under development and hopefully will be included in David's PCMCIA package in the future. Best to check the PCMCIA package to get the current status.       3c579    Status: Supported, Driver Name: 3c509  The EISA version of the 509. The current EISA version uses the same 16 bit wide chip rather than a 32 bit interface, so the performance increase isn't stunning. Make sure the card is configured for EISA addressing mode. Read the above 3c509 section for info on the driver.       3c589 / 3c589B    Status: Semi-Supported, Driver Name: 3c589  Many people have been using this PCMCIA card for quite some time      now. Note that support for it is not (at present) included in the default kernel source tree. The ""B"" in the name means the same here as it does for the 3c509 case.  There are drivers available on Donald's ftp site and in David Hinds PCMCIA package.  You will also need a supported PCMCIA controller chipset. See   PCMCIA Support  for more info on PCMCIA drivers, chipsets, socket enablers, etc.     3c590 / 3c595    Status: Supported, Driver Name: 3c59x  These ``Vortex'' cards are for PCI bus machines, with the '590 being 10Mbps and the '595 being 3Com's 100Mbs offering. Also note that you can run the '595 as a '590 (i.e. in a 10Mbps mode). The driver is included in the v2.0 kernel source, but is also continually being updated. If you have problems with the driver in the v2.0 kernel, you can get an updated driver from the following URL:    Vortex Note that there are two different 3c590 cards out there, early models that had 32kB of on-board memory, and later models that only have 8kB of memory. Chances are you won't be able to buy a new 3c59x for much longer, as it is being replaced with the 3c90x card. If you are buying a used one off somebody, try and get the 32kB version. The 3c595 cards have 64kB, as you can't get away with only 8kB RAM at 100Mbps!  A thanks to Cameron Spitzer and Terry Murphy of 3Com for sending cards and documentation to Donald so he could write the driver.  Donald has set up a mailing list for Vortex driver support. To join the list, just do:  echo subscribe | /bin/mail linux-vortex-request@cesdis.gsfc.nasa.gov       3c592 / 3c597    Status: Supported, Driver Name: 3c59x  These are  the EISA versions of the 3c59x series of cards. The 3c592/3c597 (aka Demon) should work with the vortex driver discussed above.    3c900 / 3c905 / 3c905B    Status: Supported, Driver Name: 3c59x  These cards (aka `Boomerang', aka EtherLink III XL) have been released to take over the place of the 3c590/3c595 cards.  The support for the Cyclone `B' revision was only recently added. To use this card with older v2.0 kernels, you must obtain the updated  3c59x.c  driver from Donald's site at:    Vortex-Page If in doubt about anything then check out the above WWW page. Donald has set up a mailing list for Vortex driver support announcements and etc.  To join the list, just do:  echo subscribe | /bin/mail linux-vortex-request@cesdis.gsfc.nasa.gov     3c985    Status: Supported, Driver Name: acenic  This driver, by Jes Sorensen, is available in v2.2 kernels It supports several other Gigabit cards in addition to the 3Com model.      5.2 Accton          Accton MPX    Status: Supported, Driver Name: ne (+8390)  Don't let the name fool you. This is still supposed to be a NE2000 compatible card, and should work with the ne2000 driver.    Accton EN1203, EN1207, EtherDuo-PCI    Status: Supported, Driver Name: de4x5, tulip  This is another implementation of the DEC 21040 PCI chip. The EN1207 card has the 21140, and also has a 10Base-2 connector, which has proved troublesome for some people in terms of selecting that media. Using the card with 10Base-T and 100Base-T media have worked for others though. So as with all purchases, you should try and make sure you can return it if it doesn't work for you.  See   DEC 21040  for more information on these cards, and the present driver situation.    Accton EN2209 Parallel Port Adaptor (EtherPocket)    Status: Semi-Supported, Driver Name: ?  A driver for these parallel port adapters is available but not yet part of the 2.0 or 2.1 kernel source. You have to get the driver from:  http://www.unix-ag.uni-siegen.de/~nils/accton_linux.html       Accton EN2212 PCMCIA Card    Status: Semi-Supported, Driver Name: ?  David Hinds has been working on a driver for this card, and you are best to check the latest release of his PCMCIA package to see what the present status is.        5.3 Allied Telesyn/Telesis           AT1500    Status: Supported, Driver Name: lance  These are a series of low-cost ethercards using the 79C960 version of the AMD LANCE. These are bus-master cards, and hence one of the faster ISA bus ethercards available.  DMA selection and chip numbering information can be found in  AMD LANCE .  More technical information on AMD LANCE based Ethernet cards can be found in   Notes on AMD... .     AT1700    Status: Supported, Driver Name: at1700  Note that to access this driver during  make config  you still have to answer `Y' when asked ``Prompt for development and/or incomplete code/drivers?'' at the first. This is simply due to lack of feedback on the driver stability due to it being a relatively rare card. If you have problems with the driver that ships with the kernel then you may be interested in the alternative  driver available at:  http://www.cc.hit-u.ac.jp/nagoya/at1700/   The Allied Telesis AT1700 series ethercards are based on the Fujitsu MB86965. This chip uses a programmed I/O interface, and a pair of fixed-size transmit buffers. This allows small groups of packets to be sent back-to-back, with a short pause while switching buffers.  A unique feature is the ability to drive 150ohm STP (Shielded Twisted Pair) cable commonly installed for Token Ring, in addition to 10baseT 100ohm UTP (unshielded twisted pair). A fibre optic version of the card (AT1700FT) exists as well.  The Fujitsu chip used on the AT1700 has a design flaw: it can only be fully reset by doing a power cycle of the machine. Pressing the reset button doesn't reset the bus interface. This wouldn't be so bad, except that it can only be reliably detected when it has been freshly reset. The solution/work-around is to power-cycle the machine if the kernel has a problem detecting the AT1700.     AT2450    Status: Supported, Driver Name: pcnet32  This is the PCI version of the AT1500, and it doesn't suffer from the problems that the Boca 79c970 PCI card does. DMA selection and chip numbering information can be found in  AMD LANCE .  More technical information on AMD LANCE based Ethernet cards can be found in   Notes on AMD... .    AT2500    Status: Semi-Supported, Driver Name: rtl8139  This card uses the RealTek 8139 chip - see the section   RealTek 8139 .     AT2540FX    Status: Semi-Supported, Driver Name: eepro100  This card uses the i82557 chip, and hence may/should work with the eepro100 driver. If you try this please send in a report so this information can be updated.      5.4 AMD / Advanced Micro Devices        Carl Ching of AMD was kind enough to provide a very detailed description of all the relevant AMD ethernet products which helped clear up this section.     AMD LANCE (7990, 79C960/961/961A, PCnet-ISA)    Status: Supported, Driver Name: lance  There really is no AMD ethernet card. You are probably reading this because the only markings you could find on your card said AMD and the above number. The 7990 is the original `LANCE' chip, but most stuff (including this document) refer to all these similar chips as `LANCE' chips. (...incorrectly, I might add.)  These above numbers refer to chips from AMD that are the heart of many ethernet cards. For example, the Allied Telesis AT1500 (see  AT1500 ) and the NE1500/2100 (see  NE1500 )  use these chips.  The 7990/79c90 have long been replaced by newer versions. The 79C960 (a.k.a. PCnet-ISA) essentially contains the 79c90 core, along with all the other hardware support required, which allows a single-chip ethernet solution. The 79c961 (PCnet-ISA+) is a jumperless Plug and Play version of the '960. The final chip in the ISA series is the 79c961A (PCnet-ISA II), which adds full duplex capabilities. All cards with one of these chips should work with the lance.c driver, with the exception of very old cards that used the original 7990 in a shared memory configuration. These old cards can be spotted by the lack of jumpers for a DMA channel.  One common problem people have is the `busmaster arbitration failure' message. This is printed out when the LANCE driver can't get access to the bus after a reasonable amount of time has elapsed (50us). This usually indicates that the motherboard implementation of bus-mastering DMA is broken, or some other device is hogging the bus, or there is a DMA channel conflict. If your BIOS setup has the `GAT option' (for Guaranteed Access Time) then try toggling/altering that setting to see if it helps.  Also note that the driver only looks at the addresses:  0x300, 0x320, 0x340, 0x360  for a valid card, and any address supplied by an  ether=  boot argument is silently ignored (this will be fixed) so make sure your card is configured for one of the above I/O addresses for now.  The driver will still work fine, even if more than 16MB of memory is installed, since low-memory `bounce-buffers' are used when needed (i.e. any data from above 16MB is copied into a buffer below 16MB before being given to the card to transmit.)  The DMA channel can be set with the low bits of the otherwise-unused dev->mem_start value (a.k.a. PARAM_1). (see   PARAM_1 ) If unset it is probed for by enabling each free DMA channel in turn and checking if initialization succeeds.  The HP-J2405A board is an exception: with this board it's easy to read the EEPROM-set values for the IRQ, and DMA.  See   Notes on AMD...  for more info on these chips.     AMD 79C965 (PCnet-32)    Status: Supported, Driver Name: pcnet32  This is the PCnet-32 -- a 32 bit bus-master version of the original LANCE chip for VL-bus and local bus systems. chip.  While these chips can be operated with the standard  lance.c  driver, a 32 bit version ( pcnet32.c ) is also available that does not have to concern itself with any 16MB limitations associated with the ISA bus.     AMD 79C970/970A (PCnet-PCI)    Status: Supported, Driver Name: pcnet32  This is the PCnet-PCI -- similar to the PCnet-32, but designed for PCI bus based systems. Please see the above PCnet-32 information. This means that you need to build a kernel with PCI BIOS support enabled. The '970A adds full duplex support along with some other features to the original '970 design.  Note that the Boca implementation of the 79C970 fails on fast Pentium machines. This is a hardware problem, as it affects DOS users as well. See the Boca section for more details.    AMD 79C971 (PCnet-FAST)    Status: Supported, Driver Name: pcnet32  This is AMD's 100Mbit chip for PCI systems, which also supports full duplex operation. It was introduced in June 1996.    AMD 79C972 (PCnet-FAST+)    Status: Unknown, Driver Name: pcnet32  This should also work just like the '971 but this has yet to be confirmed.    AMD 79C974 (PCnet-SCSI)    Status: Supported, Driver Name: pcnet32  This is the PCnet-SCSI --  which is basically treated like a '970 from an Ethernet point of view. Also see the above information. Don't ask if the SCSI half of the chip is supported -- this is the  Ethernet-HowTo , not the SCSI-HowTo.      5.5 Ansel Communications          AC3200 EISA    Status: Semi-Supported, Driver Name: ac3200  Note that to access this driver during  make config  you still have to answer `Y' when asked ``Prompt for development and/or incomplete code/drivers?'' at the first. This is simply due to lack of feedback on the driver stability due to it being a relatively rare card.  This driver is included in the present kernel as an alpha test driver. It is based on the common NS8390 chip used in the ne2000 and wd80x3 cards. Please see   Alpha Drivers  in this document for important information regarding alpha drivers.  If you use it, let one of us know how things work out, as feedback has been low, even though the driver has been in the kernel since v1.1.25.  If you intend on using this driver as a loadable module you should probably see  Using the Ethernet Drivers as Modules  for module specific information.    5.6 Apricot          Apricot Xen-II On Board Ethernet    Status: Semi-Supported, Driver Name: apricot  This on board ethernet uses an i82596 bus-master chip. It can only be at I/O address  0x300 . By looking at the driver source, it appears that the IRQ is also hardwired to 10.  Earlier versions of the driver had a tendency to think that anything living at  0x300  was an apricot NIC. Since then the hardware address is checked to avoid these false detections.      5.7 Arcnet      Status: Supported, Driver Name: arcnet (arc-rimi, com90xx, com20020)  With the very low cost and better performance of ethernet, chances are that most places will be giving away their Arcnet hardware for free, resulting in a lot of home systems with Arcnet.  An advantage of Arcnet is that all of the cards have identical interfaces, so one driver will work for everyone. It also has built in error handling so that it supposedly never loses a packet. (Great for UDP traffic!)  Avery Pennarun's arcnet driver has been in the default kernel sources since 1.1.80. The arcnet driver uses `arc0' as its name instead of the usual `eth0' for ethernet devices. Bug reports and success stories can be mailed to:  apenwarr@foxnet.net   There are information files contained in the standard kernel for setting jumpers and general hints.  Supposedly the driver also works with the 100Mbs ARCnet cards as well!    5.8 AT&T        Note that AT&T's StarLAN is an orphaned technology, like SynOptics LattisNet, and can't be used in a standard 10Base-T environment, without a hub that `speaks' both.    AT&T T7231 (LanPACER+)    Status: Not Supported.  These StarLAN cards use an interface similar to the i82586 chip. At one point, Matthijs Melchior ( matthijs.n.melchior@att.com ) was playing with the 3c507 driver, and almost had something useable working. Haven't heard much since that.      5.9 Boca Research        Yes, they make more than just multi-port serial cards.  :-)     Boca BEN (ISA, VLB, PCI)    Status: Supported, Driver Name: lance, pcnet32  These cards are based on AMD's PCnet chips. Perspective buyers should be warned that many users have had endless problems with these VLB/PCI cards. Owners of fast Pentium systems have been especially hit. Note that this is not a driver problem, as it hits DOS/Win/NT users as well. Boca's technical support number is (407) 241-8088, and you can also reach them at  75300.2672@compuserve.com . The older ISA cards don't appear to suffer the same problems.  Donald did a comparitive test with a Boca PCI card and a similar Allied Telsyn PCnet/PCI implementation, which showed that the problem lies in Boca's implementation of the PCnet/PCI chip. These test results can be accessed on Don's www server.    Linux at CESDIS Boca is offering a `warranty repair' for affected owners, which involves adding one of the missing capacitors, but it appears that this fix doesn't work 100 percent for most people, although it helps some.  If you are  still  thinking of buying one of these cards, then at least try and get a 7 day unconditional return policy, so that if it doesn't work properly in your system, you can return it.  More general information on the AMD chips can be found in  AMD LANCE .  More technical information on AMD LANCE based Ethernet cards can be found in   Notes on AMD... .      5.10 Cabletron        Donald writes: `Yes, another one of these companies that won't release its programming information. They waited for months before actually confirming that all their information was proprietary, deliberately wasting my time. Avoid their cards like the plague if you can. Also note that some people have phoned Cabletron, and have been told things like `a D. Becker is working on a driver for linux' -- making it sound like I work for them. This is NOT the case.'    Apparently Cabletron has changed their policy with respect to programming information (like Xircom) since Donald made the above comment several years ago -- send e-mail to  support@ctron.com  if you want to verify this or ask for programming information. However, at this point in time, there is little demand for modified/updated drivers for the older E20xx and E21xx cards.       E10**, E10**-x, E20**, E20**-x    Status: Semi-Supported, Driver Name: ne (+8390)  These are NEx000 almost-clones that are reported to work with the standard NEx000 drivers, thanks to a ctron-specific check during the probe. If there are any problems, they are unlikely to be fixed, as the programming information is unavailable.     E2100    Status: Semi-Supported, Driver Name: e2100 (+8390)  Again, there is not much one can do when the programming information is proprietary. The E2100 is a poor design. Whenever it maps its shared memory in during a packet transfer, it maps it into the  whole 128K region!  That means you  can't  safely use another interrupt-driven shared memory device in that region, including another E2100. It will work most of the time, but every once in a while it will bite you. (Yes, this problem can be avoided by turning off interrupts while transferring packets, but that will almost certainly lose clock ticks.) Also, if you mis-program the board, or halt the machine at just the wrong moment, even the reset button won't bring it back. You will  have  to turn it off and  leave  it off for about 30 seconds.  Media selection is automatic, but you can override this with the low bits of the dev->mem_end parameter. See   PARAM_2 . Module users can specify an  xcvr=N  value as an  option  in the  /etc/conf.modules  file.  Also, don't confuse the E2100 for a NE2100 clone. The E2100 is a shared memory NatSemi DP8390 design, roughly similar to a brain-damaged WD8013, whereas the NE2100 (and NE1500) use a bus-mastering AMD LANCE design.  There is an E2100 driver included in the standard kernel. However, seeing as programming info isn't available, don't expect bug-fixes. Don't use one unless you are already stuck with the card.  If you intend on using this driver as a loadable module you should probably see  Using the Ethernet Drivers as Modules  for module specific information.     E22**    Status: Semi-Supported, Driver Name: lance  According to information in a Cabletron Tech Bulletin, these cards use the standard AMD PC-Net chipset (see   AMD PC-Net ) and should work with the generic lance driver.      5.11 Cogent        Here is where and how to reach them:              Cogent Data Technologies, Inc.         175 West Street, P.O. Box 926         Friday Harbour, WA 98250, USA.          Cogent Sales         15375 S.E. 30th Place, Suite 310         Bellevue, WA 98007, USA.          Technical Support:         Phone (360) 378-2929 between 8am and 5pm PST         Fax (360) 378-2882         Compuserve GO COGENT         Bulletin Board Service (360) 378-5405         Internet: support@cogentdata.com      EM100-ISA/EISA    Status: Semi-Supported, Driver Name: smc9194  These cards use the SMC 91c100 chip and may work with the SMC 91c92 driver, but this has yet to be verified.    Cogent eMASTER+, EM100-PCI, EM400, EM960, EM964    Status: Supported, Driver Name: de4x5, tulip  These are yet another DEC 21040 implementation that should hopefully work fine with the standard 21040 driver.  The EM400 and the EM964 are four port cards using a DEC 21050 bridge and 4 21040 chips.  See   DEC 21040  for more information on these cards, and the present driver situation.    5.12 Compaq        Compaq aren't really in the business of making ethernet cards, but a lot of their systems have embedded ethernet controllers on the  motherboard.    Compaq Deskpro / Compaq XL (Embedded AMD Chip)    Status: Supported, Driver Name: pcnet32  Machines such as the XL series have an AMD 79c97x PCI chip on the mainboard that can be used with the standard LANCE driver. But before you can use it, you have to do some trickery to get the PCI BIOS to a place where Linux can see it. Frank Maas was kind enough to provide the details:  `` The problem with this Compaq machine however is that the PCI directory is loaded in high memory, at a spot where the Linux kernel can't (won't) reach. Result: the card is never detected nor is it usable (sideline: the mouse won't work either) The workaround (as described thoroughly in http://www-c724.uibk.ac.at/XL/) is to load MS-DOS, launch a little driver Compaq wrote and then load the Linux kernel using LOADLIN. Ok, I'll give you time to say `yuck, yuck', but for now this is the only working solution I know of. The little driver simply moves the PCI directory to a place where it is normally stored (and where Linux can find it).''  More general information on the AMD chips can be found in  AMD LANCE .    Compaq Nettelligent/NetFlex (Embedded ThunderLAN Chip)    Status: Supported, Driver Name: tlan  These systems use a Texas Instruments ThunderLAN chip Information on the ThunderLAN driver can be found in  ThunderLAN .        5.13 Danpex          Danpex EN9400    Status: Supported, Driver Name: de4x5, tulip  Yet another card based on the DEC 21040 chip, reported to work fine, and at a relatively cheap price.  See   DEC 21040  for more information on these cards, and the present driver situation.      5.14 D-Link           DE-100, DE-200, DE-220-T, DE-250    Status: Supported, Driver Name: ne (+8390)  Some of the early D-Link cards didn't have the  0x57  PROM signature, but the ne2000 driver knows about them. For the software configurable cards, you can get the config program from  www.dlink.com . The DE2** cards were the most widely reported as having the spurious transfer address mismatch errors with early versions of linux. Note that there are also cards from Digital (DEC) that are also named DE100 and DE200, but the similarity stops there.     DE-520    Status: Supported, Driver Name: pcnet32  This is a PCI card using the PCI version of AMD's LANCE chip. DMA selection and chip numbering information can be found in  AMD LANCE .  More technical information on AMD LANCE based Ethernet cards can be found in   Notes on AMD... .    DE-528    Status: Supported, Driver Name: ne, ne2k-pci (+8390)  Apparently D-Link have also started making PCI NE2000 clones.       DE-530    Status: Supported, Driver Name: de4x5, tulip  This is a generic DEC 21040 PCI chip implementation, and is reported to work with the generic 21040 tulip driver.  See   DEC 21040  for more information on these cards, and the present driver situation.     DE-600    Status: Supported, Driver Name: de600  Laptop users and other folk who might want a quick way to put their computer onto the ethernet may want to use this. The driver is included with the default kernel source tree. Bjorn Ekwall  bj0rn@blox.se  wrote the driver. Expect about 180kb/s transfer speed from this via the parallel port. You should read the README.DLINK file in the kernel source tree.  Note that the device name that you pass to  ifconfig  is  now   eth0  and not the previously used  dl0 .  If your parallel port is  not  at the standard  0x378  then you will have to recompile. Bjorn writes: ``Since the DE-620 driver tries to sqeeze the last microsecond from the loops, I made the irq and port address constants instead of variables. This makes for a usable speed, but it also means that you can't change these assignements from e.g. lilo; you _have_ to recompile...'' Also note that some laptops implement the on-board parallel port at  0x3bc  which is where the parallel ports on monochrome cards were/are.     DE-620    Status: Supported, Driver Name: de620  Same as the DE-600, only with two output formats. Bjorn has written a driver for this model, for kernel versions 1.1 and above. See the above information on the DE-600.     DE-650    Status: Semi-Supported, Driver Name: de650 (?)  Some people have been using this PCMCIA card for some time now with their notebooks. It is a basic 8390 design, much like a NE2000. The LinkSys PCMCIA card and the IC-Card Ethernet are supposedly DE-650 clones as well.  Note that at present, this driver is  not  part of the standard kernel, and so you will have to do some patching.  See   PCMCIA Support  in this document, and if you can, have a look at:    Don's PCMCIA Stuff     5.15 DFI           DFINET-300 and DFINET-400    Status: Supported, Driver Name: ne (+8390)  These cards are now detected (as of 0.99pl15) thanks to Eberhard Moenkeberg  emoenke@gwdg.de  who noted that they use `DFI' in the first 3 bytes of the prom, instead of using  0x57  in bytes 14 and 15, which is what all the NE1000 and NE2000 cards use. (The 300 is an 8 bit pseudo NE1000 clone, and the 400 is a pseudo NE2000 clone.)        5.16 Digital / DEC           DEPCA, DE100/1, DE200/1/2, DE210, DE422    Status: Supported, Driver Name: depca  There is documentation included in the source file `depca.c', which includes info on how to use more than one of these cards in a machine. Note that the DE422 is an EISA card. These cards are all based on the AMD LANCE chip. See   AMD LANCE  for more info. A maximum of two of the ISA cards can be used, because they can only be set for  0x300  and  0x200  base I/O address. If you are intending to do this, please read the notes in the driver source file  depca.c  in the standard kernel source tree.  This driver will also work on Alpha CPU based machines, and there are various ioctl()s that the user can play with.     Digital EtherWorks 3 (DE203, DE204, DE205)    Status: Supported, Driver Name: ewrk3  These cards use a proprietary chip from DEC, as opposed to the LANCE chip used in the earlier cards like the DE200. These cards support both shared memory or programmed I/O, although you take about a 50%performance hit if you use PIO mode. The shared memory size can be set to 2kB, 32kB or 64kB, but only 2 and 32 have been tested with this driver. David says that the performance is virtually identical between the 2kB and 32kB mode. There is more information (including using the driver as a loadable module) at the top of the driver file  ewrk3.c  and also in  README.ewrk3 . Both of these files come with the standard kernel distribution. This driver has Alpha CPU support like depca.c does.  The standard driver has a number of interesting ioctl() calls that can be used to get or clear packet statistics, read/write the EEPROM, change the hardware address, and the like. Hackers can see the source code for more info on that one.  David has also written a configuration utility for this card (along the lines of the DOS program  NICSETUP.EXE ) along with other tools. These can be found on most Linux FTP sites in the directory  /pub/Linux/system/Network/management  -- look for the file  ewrk3tools-X.XX.tar.gz .       DE425 EISA, DE434, DE435, DE500      Status: Supported, Driver Name: de4x5, tulip  These cards are based on the 21040 chip mentioned below. The DE500 uses the 21140 chip to provide 10/100Mbs ethernet connections. Have a read of the 21040 section below for extra info. There are also some compile-time options available for non-DEC cards using this driver. Have a look at  README.de4x5  for details.  All the Digital cards will autoprobe for their media (except, temporarily, the DE500 due to a patent issue).  This driver is also Alpha CPU ready and supports being loaded as a module.  Users can access the driver internals through ioctl() calls - see the 'ewrk3' tools and the de4x5.c sources for information about how to do this.     DEC 21040, 21041, 2114x, Tulip     Status: Supported, Driver Name: de4x5, tulip  The DEC 21040 is a bus-mastering single chip ethernet solution from Digital, similar to AMD's PCnet chip. The 21040 is specifically designed for the PCI bus architecture. SMC's new EtherPower PCI card uses this chip.  You have a choice of  two  drivers for cards based on this chip. There is the DE425 driver discussed above, and the generic 21040  `tulip' driver.  Warning:  Even though your card may be based upon this chip,  the drivers may not work for you . David C. Davies writes:  ``There are no guarantees that either `tulip.c' OR `de4x5.c' will run any DC2114x based card other than those they've been written to support.  WHY?? You ask.  Because there is a register, the General Purpose Register (CSR12) that (1) in the DC21140A is programmable by each vendor and they all do it differently (2) in the DC21142/3 this is now an SIA control register (a la DC21041). The only small ray of hope is that we can decode the SROM to help set up the driver. However, this is not a guaranteed solution since some vendors (e.g. SMC 9332 card) don't follow the Digital Semiconductor recommended SROM programming format.""  In non-technical terms, this means that if you aren't sure that an unknown card with a DC2114x chip will work with the linux driver(s), then make sure you can return the card to the place of purchase  before  you pay for it.  The updated 21041 chip is also found in place of the 21040 on most of the later SMC EtherPower cards. The 21140 is for supporting 100Base-? and works with the Linux drivers for the 21040 chip. To use David's  de4x5  driver with non-DEC cards, have a look at  README.de4x5  for details.  Donald has used SMC EtherPower-10/100 cards to develop the `tulip' driver. Note that the driver that is in the standard kernel tree at the moment is not the most up to date version. If you are having trouble with this driver, you should get the newest version from Donald's ftp/WWW site.    Tulip Driver The above URL also contains a (non-exhaustive) list of various cards/vendors that use the 21040 chip.  Also note that the tulip driver is still considered an  alpha  driver (see   Alpha Drivers ) at the moment, and should be treated as such. To use it, you will have to edit  arch/i386/config.in  and uncomment the line for  CONFIG_DEC_ELCP  support.  Donald has even set up a mailing list for tulip driver support announcements, etc.  To join it just type:  echo subscribe | /bin/mail linux-tulip-request@cesdis.gsfc.nasa.gov     5.17 Farallon      Farallon sells EtherWave adaptors and transceivers. This device allows multiple 10baseT devices to be daisy-chained.    Farallon Etherwave    Status: Supported, Driver Name: 3c509  This is reported to be a 3c509 clone that includes the EtherWave transceiver. People have used these successfully with Linux and the present 3c509 driver. They are too expensive for general use, but are a great option for special cases.  Hublet prices start at $125, and Etherwave adds $75-$100 to the price of the board -- worth it if you have pulled one wire too few, but not if you are two network drops short.    5.18 Fujitsu        Unlike many network chip manufacturers, Fujitsu have also made and sold some network cards based upon their chip.    Fujitsu FMV-181/182/183/184    Status: Supported, Driver Name: fmv18x  According to the driver, these cards are a straight forward Fujitsu MB86965 implementation, which would make them very similar to the Allied Telesis AT1700 cards.      5.19 Hewlett Packard        The 272** cards use programmed I/O, similar to the NE*000 boards, but the data transfer port can be `turned off' when you aren't accessing it, avoiding problems with autoprobing drivers.  Thanks to Glenn Talbott for helping clean up the confusion in this section regarding the version numbers of the HP hardware.     27245A    Status: Supported, Driver Name: hp (+8390)  8 Bit 8390 based 10BaseT, not recommended for all the 8 bit reasons. It was re-designed a couple years ago to be highly integrated which caused some changes in initialization timing which only affected testing programs, not LAN drivers. (The new card is not `ready' as soon after switching into and out of loopback mode.)  If you intend on using this driver as a loadable module you should probably see  Using the Ethernet Drivers as Modules  for module specific information.    HP EtherTwist, PC Lan+ (27247, 27252A)    Status: Supported, Driver Name: hp+ (+8390)  The HP PC Lan+ is different to the standard HP PC Lan card. This driver was added to the list of drivers in the standard kernel during the v1.1.x development cycle. It can be operated in either a PIO mode like a ne2000, or a shared memory mode like a wd8013.  The 47B is a 16 Bit 8390 based 10BaseT w/AUI, and the 52A is a 16 Bit 8390 based ThinLAN w/AUI. These cards have 32K onboard RAM for Tx/Rx packet buffering instead of the usual 16KB, and they both offer LAN connector autosense.  If you intend on using this driver as a loadable module you should probably see  Using the Ethernet Drivers as Modules  for module specific information.    HP-J2405A    Status: Supported, Driver Name: lance  These are lower priced, and slightly faster than the 27247/27252A, but are missing some features, such as AUI, ThinLAN connectivity, and boot PROM socket. This is a fairly generic LANCE design, but a minor design decision makes it incompatible with a generic `NE2100' driver. Special support for it (including reading the DMA channel from the board) is included thanks to information provided by HP's Glenn Talbott.  More technical information on LANCE based cards can be found in  Notes on AMD...   HP-Vectra On Board Ethernet    Status: Supported, Driver Name: lance  The HP-Vectra has an AMD PCnet chip on the motherboard. DMA selection and chip numbering information can be found in  AMD LANCE .  More technical information on LANCE based cards can be found in  Notes on AMD...   HP 10/100 VG Any Lan Cards (27248B, J2573, J2577, J2585, J970, J973)    Status: Supported, Driver Name: hp100    This driver also supports some of the Compex VG products. Since the driver supports ISA, EISA and PCI cards, it is found under ISA cards when running  make config  on a kernel source.    HP NetServer 10/100TX PCI (D5013A)    Status: Supported, Driver Name: eepro100  Apparently these are just a rebadged Intel EtherExpress Pro 10/100B card. See the Intel section for more information.        5.20 IBM / International Business Machines           IBM Thinkpad 300    Status: Supported, Driver Name: znet  This is compatible with the Intel based Zenith Z-note. See   Z-note  for more info.  Supposedly this site has a comprehensive database of useful stuff for newer versions of the Thinkpad. I haven't checked it out myself yet.    Thinkpad-info For those without a WWW browser handy, try  peipa.essex.ac.uk:/pub/tp750/     IBM Credit Card Adaptor for Ethernet    Status: Semi-Supported, Driver Name: ? (distributed separately)  People have been using this PCMCIA card with Linux as well. Similar points apply, those being that you need a supported PCMCIA chipset on your notebook, and that you will have to patch the PCMCIA support into the standard kernel.  See   PCMCIA Support  in this document, and if you can, have a look at:    Don's PCMCIA Stuff     IBM Token Ring    Status: Semi-Supported, Driver Name: ibmtr  To support token ring requires more than only writing a device driver, it also requires writing the source routing routines for token ring. It is the source routing that would be the most time comsuming to write.  Peter De Schrijver has been spending some time on Token Ring lately. and has worked with IBM ISA and MCA token ring cards.  The present token ring code has been included into the first of the 1.3.x series kernels.  Peter says that it was originally tested on an MCA 16/4 Megabit Token Ring board, but it should work with other Tropic based boards.    5.21 ICL Ethernet Cards          ICL EtherTeam 16i/32    Status: Supported, Driver Name: eth16i  Mika Kuoppala (miku@pupu.elt.icl.fi) wrote this driver, and it was included into early 1.3.4x kernels. It uses the Fujitsu MB86965 chip that is also used on the at1700 cards.      5.22 Intel Ethernet Cards        Note that the naming of the various Intel cards is ambiguous and confusing at best.  If in doubt, then check the  i8xxxx  number on the main chip on the card or for PCI cards, use the PCI information in the  /proc  directory and then compare that to the numbers listed here.    Ether Express    Status: Supported, Driver Name: eexpress  This card uses the intel i82586. Earlier versions of this driver (in v1.2 kernels) were classed as alpha-test, as it didn't work well for most people. The driver in the v2.0 kernel seems to work much better for those who have tried it, although the driver source still lists it as experimental and more problematic on faster machines.  The comments at the top of the driver source list some of the problems (and fixes!) associated with these cards. The slowdown hack of replacing all the  outb  with  outb_p  in the driver has been reported to avoid lockups for at least one user.    Ether Express PRO/10    Status: Supported, Driver Name: eepro  Bao Chau Ha has written a driver for these cards that has been included into early 1.3.x kernels. It may also work with some of the Compaq built-in ethernet systems that are based on the i82595 chip.    Ether Express PRO/10 PCI (EISA)    Status: Semi-Supported, Driver Name: ? (distributed separately)  John Stalba (stalba@ultranet.com) has written a driver for the PCI version. These cards use the PLX9036 PCI interface chip with the Intel i82596 LAN controller chip. If your card has the i82557 chip, then you  don't  have this card, but rather the version discussed next, and hence want the EEPro100 driver instead.  You can get the alpha driver for the PRO/10 PCI card, along with instructions on how to use it at:    EEPro10 Driver If you have the EISA card, you will probably have to hack the driver a bit to account for the different (PCI vs. EISA) detection mechanisms that are used in each case.       Ether Express PRO 10/100B    Status: Supported, Driver Name: eepro100  Note that this driver will  not  work with the older 100A cards. The chip numbers listed in the driver are i82557/i82558. For driver updates and/or driver support, have a look at:    EEPro-100B Page To subscribe to the mailing list relating to this driver, do:  echo subscribe | /bin/mail linux-eepro100-request@cesdis.gsfc.nasa.gov   Apparently Donald had to sign a non-disclosure agreement that stated he could actually disclose the driver source code! How is that for sillyness on intel's part?      5.23 Kingston        Kingston make various cards, including NE2000+, AMD PCnet based cards, and DEC tulip based cards. Most of these cards should work fine with their respective driver. See  Kingston Web Page The KNE40 DEC 21041 tulip based card is reported to work fine with the generic tulip driver.      5.24 LinkSys        LinkSys make a handful of different NE2000 clones, some straight ISA cards, some ISA plug and play and some even ne2000-PCI clones based on one of the supported ne2000-PCI chipsets. There are just too many models to list here.  LinkSys are linux-friendly, with a linux specific WWW support page, and even have Linux printed on the boxes of some of their products.  Have a look at:  http://www.linksys.com/support/solution/nos/linux.htm       LinkSys Etherfast 10/100 Cards.    Status: Supported, Driver Name: tulip  Note that with these cards there have been several `revisions' (i.e. different chipset used) all with the same card name. The 1st used the DEC chipset. The 2nd revision used the Lite-On PNIC 82c168 PCI Network Interface Controller, and support for this was merged into the standard tulip driver (as of version 0.83 and newer). More PNIC information is available at:  http://cesdis.gsfc.nasa.gov/linux/drivers/pnic.html   More information on the various versions of these cards can be found at the LinkSys WWW site mentioned above.      LinkSys Pocket Ethernet Adapter Plus (PEAEPP)    Status: Supported, Driver Name: de620  This is supposedly a DE-620 clone, and is reported to work well with that driver. See  DE-620  for more information.    LinkSys PCMCIA Adaptor    Status: Supported, Driver Name: de650 (?)  This is supposed to be a re-badged DE-650. See  DE-650  for more information.    5.25 Microdyne          Microdyne Exos 205T    Status: Semi-Supported, Driver Name: ?  Another i82586 based card. Dirk Niggemann  dirk-n@dircon.co.uk  has written a driver that he classes as ``pre-alpha'' that he would like people to test. Mail him for more details.    5.26 Mylex        Mylex can be reached at the following numbers, in case anyone wants to ask them anything.            MYLEX CORPORATION, Fremont         Sales:  800-77-MYLEX, (510) 796-6100         FAX:    (510) 745-8016.    They also have a web site:  Mylex WWW Site   Mylex LNE390A, LNE390B    Status: Supported, Driver Name: lne390 (+8390)  These are fairly old EISA cards that make use of a shared memory implementation similar to the wd80x3. A driver for these cards is available in the current 2.1.x series of kernels.  Ensure you set the shared memory address below 1MB or above the highest address of the physical RAM installed in the machine.    Mylex LNP101    Status: Supported, Driver Name: de4x5, tulip  This is a PCI card that is based on DEC's 21040 chip. It is selectable between 10BaseT, 10Base2 and 10Base5 output. The LNP101 card has been verified to work with the generic 21040 driver.  See the section on the 21040 chip (  DEC 21040 ) for more information.    Mylex LNP104    Status: Semi-Supported, Driver Name: de4x5, tulip  The LNP104 uses the DEC 21050 chip to deliver  four  independent 10BaseT ports. It should work with recent 21040 drivers that know how to share IRQs, but nobody has reported trying it yet (that I am aware of).      5.27 Novell Ethernet, NExxxx and associated clones.        The prefix `NE' came from Novell Ethernet. Novell followed the cheapest NatSemi databook design and sold the manufacturing rights (spun off?) Eagle, just to get reasonably-priced ethercards into the market. (The now ubiquitous NE2000 card.)     NE1000, NE2000    Status: Supported, Driver Name: ne (+8390)  The ne2000 is now a generic name for a bare-bones design around the NatSemi 8390 chip. They use programmed I/O rather than shared memory, leading to easier installation but slightly lower performance and a few problems.  Some of the more common problems that arise with NE2000 cards are listed in   Problems with... Some NE2000 clones use the National Semiconductor `AT/LANTic' 83905 chip, which offers a shared memory mode similar to the wd8013 and EEPROM software configuration. The shared memory mode will offer less CPU usage (i.e. more efficient) than the programmed I/O mode.  In general it is not a good idea to put a NE2000 clone at I/O address  0x300  because nearly  every  device driver probes there at boot. Some poor NE2000 clones don't take kindly to being prodded in the wrong areas, and will respond by locking your machine. Also  0x320  is bad because SCSI drivers probe into  0x330 .  Donald has written a NE2000 diagnostic program (ne2k.c) for all ne2000 cards. See   Diagnostic Programs  for more information.  If you intend on using this driver as a loadable module you should probably see  Using the Ethernet Drivers as Modules  for module specific information.     NE2000-PCI (RealTek/Winbond/Compex)    Status: Supported, Driver Name: ne, ne2k-pci (+8390)  Yes, believe it or not, people are making PCI cards based on the more than ten year old interface  design of the ne2000. At the moment nearly all of these cards are based on the RealTek 8029 chip, or the Winbond 89c940 chip. The Compex, KTI, VIA and Netvin cards apparently also use these chips, but have a different PCI ID.  The latest v2.0 kernel has support to automatically detect all these cards and use them. (If you are using a kernel v2.0.34 or older, you should upgrade to ensure your card will be detected.) There are now two drivers to choose from; the original ISA/PCI  ne.c  driver, and a relatively new PCI-only  ne2k-pci.c  driver.  To use the original ISA/PCI driver you have to say `Y'  to the `Other ISA cards' option when running  make config  as you are actually using the same NE2000 driver as the ISA cards use. (That should also give you a hint that these cards aren't anywhere as intelligent as say a PCNet-PCI or DEC 21040 card...)  The newer PCI-only driver differs from the ISA/PCI driver in that all the support for old NE1000 8 bit cards has been removed and that data is moved to/from the card in bigger blocks, without any intervening pauses that the older ISA-NE2000's required for reliable operation.  The result is a driver that is slightly smaller and slightly more efficient, but don't get too excited as the difference will not be obvious under normal use.  (If you really wanted maximum efficiency/low CPU use, then a PCI-NE2000 is simply a very poor choice.) Driver updates and more information can be found at:  http://cesdis.gsfc.nasa.gov/linux/drivers/ne2k-pci.html   If you have a NE2000 PCI card that is  not   detected by the most current version of the driver, please contact the maintainer of the NE2000 driver as listed in  /usr/src/linux/MAINTAINERS  along with the output from a  cat /proc/pci  and  dmesg  so that support for your card can also be added to the driver.  Also note that various card makers have been known to put `NE2000 Compatible' stickers on their product boxes even when it is completely different (e.g. PCNet-PCI or RealTek 8139). If in doubt check the main chip number against this document.    NE-10/100    Status: Not Supported.  These are ISA 100Mbps cards based on the National Semiconductor DP83800 and DP83840 chips. There is currently no driver support, nor has anyone reported that they are working on a driver. Apparently documentation on the chip is unavailable with the exception of a single PDF file that doesn't give enough details for a driver.     NE1500, NE2100    Status: Supported, Driver Name: lance  These cards use the original 7990 LANCE chip from AMD and are supported using the Linux lance driver. Newer NE2100 clones use the updated PCnet/ISA chip from AMD.  Some earlier versions of the lance driver had problems with getting the IRQ line via autoIRQ from the original Novell/Eagle 7990 cards. Hopefully this is now fixed. If not, then specify the IRQ via LILO, and let us know that it still has problems.  DMA selection and chip numbering information can be found in  AMD LANCE .  More technical information on LANCE based cards can be found in  Notes on AMD...   NE/2 MCA    Status: Semi-Supported, Driver Name: ne2  There were a few NE2000 microchannel cards made by various companies.  This driver, available in v2.2 kernels, will detect the following MCA cards: Novell Ethernet Adapter NE/2, Compex ENET-16 MC/P, and the Arco Ethernet Adapter AE/2.     NE3200    Status: Not Supported.  This old EISA card uses a 8MHz 80186 in conjunction with an i82586. Nobody is working on a driver for it, as there is no information available on the card, and no real demand for a driver either.     NE3210    Status: Supported, Driver Name: ne3210 (+8390)  This EISA card is completely different from the NE3200, as it uses a Nat Semi 8390 chip.  The driver can be found in the v2.2 kernel source tree.  Ensure you set the shared memory address below 1MB or above the highest address of the physical RAM installed in the machine.    NE5500    Status: Supported, Driver Name: pcnet32  These are just AMD PCnet-PCI cards ('970A) chips. More information on LANCE/PCnet based cards can be found in  AMD LANCE .      5.28 Proteon          Proteon P1370-EA    Status: Supported, Driver Name: ne (+8390)  Apparently this is a NE2000 clone, and works fine with Linux.    Proteon P1670-EA    Status: Supported, Driver Name: de4x5, tulip  This is yet another PCI card that is based on DEC's Tulip chip. It has been reported to work fine with Linux.  See the section on the 21040 chip (  DEC 21040 ) for more driver information.      5.29 Pure Data          PDUC8028, PDI8023    Status: Supported, Driver Name: wd (+8390)  The PureData PDUC8028 and PDI8023 series of cards are reported to work, thanks to special probe code contributed by Mike Jagdis  jaggy@purplet.demon.co.uk . The support is integrated with the WD driver.    5.30 Racal-Interlan        Racal Interlan can be reached via WWW at  www.interlan.com . I believe they were also known as MiCom-Interlan at one point in the past.    ES3210    Status: Semi-Supported, Driver Name: es3210  This is an EISA 8390 based shared memory card. An experimetal driver is shipped with v2.2 kernels and it is reported to work fine, but the EISA IRQ and shared memory address detection appears not to work with (at least) the early revision cards. (This problem is not unique to the Linux world either...) In that case, you have to supply them to the driver. For example, card at IRQ 5 and shared memory  0xd0000 , with a modular driver, add  options es3210 irq=5 mem=0xd0000  to  /etc/conf.modules . Or with the driver compiled into the kernel, supply at boot  ether=5,0,0xd0000,eth0  The I/O base is automatically detected and hence a value of zero should be used.    NI5010    Status: Semi-Supported, Driver Name: ni5010   You used to have to go get the driver for these old 8 bit  MiCom-Interlan cards separately, but now it is shipped with the v2.2 kernels as an experimental driver.    NI5210    Status: Semi-Supported, Driver Name: ni52  This card also uses one of the Intel chips.  Michael Hipp has written a driver for this card. It is included in the standard kernel as an `alpha' driver. Michael would like to hear feedback from users that have this card. See  Alpha Drivers  for important information on using alpha-test ethernet drivers with Linux.     NI6510 (not EB)    Status: Semi-Supported, Driver Name: ni65  There is also a driver for the LANCE based NI6510, and it is also written by Michael Hipp. Again, it is also an `alpha' driver. For some reason, this card is not compatible with the generic LANCE driver. See  Alpha Drivers  for important information on using alpha-test ethernet drivers with Linux.    EtherBlaster (aka NI6510EB)    Status: Supported, Driver Name: lance  As of kernel 1.3.23, the generic LANCE driver had a check added to it for the  0x52, 0x44  NI6510EB specific signature. Others have reported that this signature is not the same for all NI6510EB cards however, which will cause the lance driver to not detect your card. If this happens to you, you can change the probe (at about line 322 in lance.c) to printk() out what the values are for your card and then use them instead of the  0x52, 0x44  defaults.  The cards should probably be run in `high-performance' mode and not in the NI6510 compatible mode when using the lance driver.      5.31 RealTek           RealTek RTL8002/8012 (AT-Lan-Tec) Pocket adaptor    Status: Supported, Driver Name: atp  This is a generic, low-cost OEM pocket adaptor being sold by AT-Lan-Tec, and (likely) a number of other suppliers. A driver for it is included in the standard kernel. Note that there is substantial information contained in the driver source file `atp.c'.  Note that the device name that you pass to  ifconfig  was  not   eth0  but  atp0  for earlier versions of this driver.    RealTek 8009    Status: Supported, Driver Name: ne (+8390)  This is an ISA NE2000 clone, and is reported to work fine with the linux NE2000 driver. The  rset8009.exe  program can be obtained from RealTek's WWW site at  http://www.realtek.com.tw  - or via ftp from the same site.    RealTek 8019    Status: Supported, Driver Name: ne (+8390)  This is a Plug and Pray version of the above.  Use the DOS software to disable PnP and enable jumperless configuration; set the card to a sensible I/O address and IRQ and you should be ready to go.  (If using the driver as a module, don't forget to add an  io=0xNNN  option to  /etc/conf.modules ). The  rset8019.exe  program can be obtained from RealTek's WWW site at  http://www.realtek.com.tw  - or via ftp from the same site.    RealTek 8029    Status: Supported, Driver Name: ne, ne2k-pci (+8390)  This is a PCI single chip implementation of a NE2000 clone. Various vendors are now selling cards with this chip. See  NE2000-PCI  for information on using any of these cards.  Note that this is still a 10+ year old design just glued onto a PCI bus. Performance won't be staggeringly better than the equivalent ISA model.       RealTek 8129/8139    Status: Semi-Supported, Driver Name: rtl8139  Another PCI single chip ethernet solution from RealTek. A driver for cards based upon this chip was included in the v2.0.34 release of linux.  You currently have to answer `Y' when asked if you want experimental drivers for v2.2 kernels to get access to this driver.  For more information, see:  http://cesdis.gsfc.nasa.gov/linux/drivers/rtl8139.html       5.32 Sager          Sager NP943    Status: Semi-Supported, Driver Name: 3c501  This is just a 3c501 clone, with a different S.A. PROM prefix. I assume it is equally as brain dead as the original 3c501 as well. The driver checks for the NP943 I.D. and then just treats it as a 3c501 after that. See   3Com 3c501  for all the reasons as to why you really don't want to use one of these cards.    5.33 Schneider & Koch          SK G16    Status: Supported, Driver Name: sk_g16  This driver was included into the v1.1 kernels, and it was written by PJD Weichmann and SWS Bern. It appears that the SK G16 is similar to the NI6510, in that it is based on the first edition LANCE chip (the 7990). Once again, it appears as though this card won't work with the generic LANCE driver.    5.34 SEEQ          SEEQ 8005    Status: Supported, Driver Name: seeq8005  This driver was included into early 1.3.x kernels, and was written by Hamish Coleman.  There is little information about the card included in the driver, and hence little information to be put here. If you have a question, you are probably best off e-mailing hamish@zot.apana.org.au      5.35 SMC (Standard Microsystems Corp.)           The ethernet part of Western Digital was bought out by SMC many years ago when the wd8003 and wd8013 were the main product. Since then SMC has continued making 8390 based ISA cards (Elite16, Ultra, EtherEZ) and also added several PCI products to their range.  Contact information for SMC:  SMC / Standard Microsystems Corp., 80 Arkay Drive, Hauppage, New York, 11788, USA.  Technical Support via phone: 800-992-4762 (USA) or 800-433-5345 (Canada) or 516-435-6250 (Other Countries). Literature requests: 800-SMC-4-YOU (USA) or 800-833-4-SMC (Canada) or 516-435-6255  (Other Countries).  Technical Support via E-mail:  techsupt@ccmail.west.smc.com . FTP Site:  ftp.smc.com . WWW Site:   SMC .    WD8003, SMC Elite    Status: Supported, Driver Name: wd (+8390)  These are the 8-bit versions of the card. The 8 bit 8003 is slightly less expensive, but only worth the savings for light use. Note that some of the non-EEPROM cards (clones with jumpers, or old  old  old wd8003 cards) have no way of reporting the IRQ line used. In this case, auto-irq is used, and if that fails, the driver silently assings IRQ 5. You can get the SMC setup/driver disks from SMC's ftp site. Note that some of the newer SMC `SuperDisk' programs will fail to detect the real old EEPROM-less cards. The file  SMCDSK46.EXE  seems to be a good all-round choice. Also the jumper settings for all their cards are in an ASCII text file in the aforementioned archive. The latest (greatest?) version can be obtained from  ftp.smc.com .  As these are basically the same as their 16 bit counterparts (WD8013 / SMC Elite16), you should see the next section for more information.       WD8013, SMC Elite16    Status: Supported, Driver Name: wd (+8390)  Over the years the design has added more registers and an EEPROM. (The first wd8003 cards appeared about ten years ago!) Clones usually go by the `8013' name, and usually use a non-EEPROM (jumpered) design. Late model SMC cards will have the SMC 83c690 chip instead of the original Nat Semi DP8390 found on earlier cards. The shared memory design makes the cards a bit faster than PIO cards, especially with larger packets. More importantly, from the driver's point of view, it avoids a few bugs in the programmed-I/O mode of the 8390, allows safe multi-threaded access to the packet buffer, and it doesn't have a programmed-I/O data register that hangs your machine during warm-boot probes.  Non-EEPROM cards that can't just read the selected IRQ will attempt auto-irq, and if that fails, they will silently assign IRQ 10. (8 bit versions will assign IRQ 5)  Cards with a non standard amount of memory on board can have the memory size specified at boot (or as an option in  /etc/conf.modules  if using modules). The standard memory size is 8kB for an 8bit card and 16kB for a 16bit card. For example, the older WD8003EBT cards could be jumpered for 32kB memory. To make full use of that RAM, you would use something like (for I/O=0x280 and IRQ 9):            LILO: linux ether=9,0x280,0xd0000,0xd8000,eth0      Also see   8013 problems  for some of the more common problems and frequently asked questions that pop up often.  If you intend on using this driver as a loadable module you should probably see  Using the Ethernet Drivers as Modules  for module specific information.     SMC Elite Ultra    Status: Supported, Driver Name: smc-ultra (+8390)  This ethercard is based on the 83c790 chip from SMC, which has a few new features over the 83c690. While it has a mode that is similar to the older SMC ethercards, it's not entirely compatible with the old WD80*3 drivers. However, in this mode it shares most of its code with the other 8390 drivers, while operating slightly faster than a WD8013 clone.  Since part of the Ultra  looks like  an 8013, the Ultra probe is supposed to find an Ultra before the wd8013 probe has a chance to mistakenly identify it.  Donald mentioned that it is possible to write a separate driver for the Ultra's `Altego' mode which allows chaining transmits at the cost of inefficient use of receive buffers, but that will probably not happen.  Bus-Master SCSI host adaptor users take note: In the manual that ships with Interactive UNIX, it mentions that a bug in the SMC Ultra will cause data corruption with SCSI disks being run from an aha-154X host adaptor. This will probably bite aha-154X compatible cards, such as the BusLogic boards, and the AMI-FastDisk SCSI host adaptors as well.  SMC has acknowledged the problem occurs with Interactive, and older Windows NT drivers. It is a hardware conflict with early revisions of the card that can be worked around in the driver design. The current Ultra driver protects against this by only enabling the shared memory during data transfers with the card. Make sure your kernel version is at least 1.1.84, or that the driver version reported at boot is at least  smc-ultra.c:v1.12  otherwise you are vulnerable.  If you intend on using this driver as a loadable module you should probably see  Using the Ethernet Drivers as Modules  for module specific information.     SMC Elite Ultra32 EISA    Status: Supported, Driver Name: smc-ultra32 (+8390)  This EISA card shares a lot in common with its ISA counterpart. A working (and stable) driver is included in both v2.0  and v2.2 kernels.  Thanks go to Leonard Zubkoff for purchasing some of these cards so that linux support could be added for them.    SMC EtherEZ (8416)    Status: Supported, Driver Name: smc-ultra (+8390)  This card uses SMC's 83c795 chip and supports the Plug 'n Play specification. It also has an  SMC Ultra  compatible mode, which allows it to be used with the Linux Ultra driver. For best results, use the SMC supplied program (avail. from their www/ftp site) to disable PnP and configure it for shared memory mode.  See the above information for notes on the Ultra driver.  For v1.2 kernels, the card had to be configured for shared memory operation. However v2.0 kernels can use the card in shared memory or programmed I/O mode. Shared memory mode will be slightly faster, and use less CPU resources as well.     SMC EtherPower PCI (8432)    Status: Supported, Driver Name: de4x5, tulip  NB: The EtherPower II is an entirely different card. See below! These cards are a basic DEC 21040 implementation, i.e. one big chip and a couple of transceivers. Donald has used one of these cards for his development of the generic 21040 driver (aka  tulip.c ). Thanks to Duke Kamstra, once again, for supplying a card to do development on.  Some of the later revisons of this card use the newer DEC 21041 chip, which may cause problems with older versions of the tulip driver. If you have problems, make sure you are using the latest driver release, which may not yet be included in the current kernel source tree.  See   DEC 21040  for more details on using one of these cards, and the current status of the driver.  Apparently, the latest revision of the card, the EtherPower-II uses the 9432 chip. It is unclear at the moment if this one will work with the present driver. As always, if unsure, check that you can return the card if it doesn't work with the linux driver  before  paying for the card.     SMC EtherPower II PCI (9432)    Status: Semi-Supported, Driver Name: epic100  These cards, based upon the SMC 83c170 chip, are entirely different than the Tulip based cards. A new driver has been included in kernels v2.0 and v2.2 to support these cards. For more details, see:  http://cesdis.gsfc.nasa.gov/linux/drivers/epic100.html       SMC 3008    Status: Not Supported.  These 8 bit cards are based on the Fujitsu MB86950, which is an ancient version of the MB86965 used in the Linux at1700 driver. Russ says that you could probably hack up a driver by looking at the at1700.c code and his DOS packet driver for the Tiara card (tiara.asm). They are not very common.    SMC 3016    Status: Not Supported.  These are 16bit I/O mapped 8390 cards, much similar to a generic NE2000 card. If you can get the specifications from SMC, then porting the NE2000 driver would probably be quite easy. They are not very common.    SMC-9000 / SMC 91c92/4    Status: Supported, Driver Name: smc9194  The SMC9000 is a VLB card based on the 91c92 chip. The 91c92 appears on a few other brand cards as well, but is fairly uncommon. Erik Stahlman (erik@vt.edu) has written this driver which is in v2.0 kernels, but not in the older v1.2 kernels. You may be able to drop the driver into a v1.2 kernel source tree with minimal difficulty.    SMC 91c100    Status: Semi-Supported, Driver Name: smc9194  The SMC 91c92 driver is supposed to work for cards based on this 100Base-T chip, but at the moment this is unverified.    5.36 Texas Instruments           ThunderLAN    Status: Supported, Driver Name: tlan  This driver covers many Compaq built-in ethernet devices, including the NetFlex and Netelligent groups. It also supports the Olicom 2183, 2185, 2325 and 2326 products.    5.37 Thomas Conrad          Thomas Conrad TC-5048      This is yet another PCI card that is based on DEC's 21040 chip.  See the section on the 21040 chip (  DEC 21040 ) for more information.    5.38 VIA        You probably won't see a VIA networking card, as VIA make several networking chips that are then used by others in the construction of an ethernet card.  They have a WWW site at:  http://www.via.com.tw/     VIA 86C926 Amazon    Status: Supported, Driver Name: ne, ne2k-pci (+8390)  This controller chip is VIA's PCI-NE2000 offering. You can choose between the ISA/PCI  ne.c  driver or the PCI-only  ne2k-pci.c  driver. See the PCI-NE2000 section for more details.    VIA 86C100A Rhine II (and 3043 Rhine I)    Status Supported, Driver Name: via-rhine  This relatively new driver can be found in current 2.0 and 2.1 kernels.  It is an improvement over the 86C926 NE2000 chip in that it supports bus master transfers, but strict 32 bit buffer alignment requirements limit the benefit gained from this. For more details and driver updates, see:  http://cesdis.gsfc.nasa.gov/linux/drivers/via-rhine.html       5.39 Western Digital        Please see   SMC  for information on SMC cards. (SMC bought out Western Digital's network card section many years ago.)    5.40 Winbond        Winbond don't really make and sell complete cards to the general public -- instead they make single chip ethernet solutions that other companies buy, stick onto a PCI board with their own name and then sell through retail stores.    Winbond 89c840    Status: Semi-Supported, Driver Name: winbond-840  This driver isn't currently shipped with the kernel, as it is in the testing phase.  It is available at:  http://cesdis.gsfc.nasa.gov/linux/drivers/test/winbond-840.c     Winbond 89c940    Status: Supported, Driver Name: ne, ne2k-pci (+8390)  This chip is one of the two commonly found on the low price PCI ne2000 cards sold by lots of manufacturers. Note that this is still a 10+ year old design just glued onto a PCI bus. Performance won't be staggeringly better than the equivalent ISA model.      5.41 Xircom        For the longest time, Xircom wouldn't release the programming information required to write a driver, unless you signed your life away. Apparently enough linux users have pestered them for driver support (they claim to support all popular networking operating systems...) so that they have changed their policy to allow documentation to be released without having to sign a non-disclosure agreement. Some people have said they they will release the source code to the SCO driver, while others have been told that they are no longer providing information on `obsolete' products like the earlier PE models. If you are interested and want to check into this yourself, you can reach Xircom at 1-800-874-7875, 1-800-438-4526 or +1-818-878-7600.    Xircom PE1, PE2, PE3-10B*    Status: Not Supported.  Not to get your hopes up, but if you have one of these parallel port adaptors, you may be able to use it in the DOS emulator with the Xircom-supplied DOS drivers. You will have to allow DOSEMU access to your parallel port, and will probably have to play with SIG (DOSEMU's Silly Interrupt Generator).    Xircom PCMCIA Cards    Status: Semi-Supported, Driver Name: ????  Some of the Xircom PCMCIA card(s) have drivers that are available with David Hinds PCMCIA package. Check there for the most up to date indformation      5.42 Zenith           Z-Note    Status: Supported, Driver Name: znet  The built-in Z-Note network adaptor is based on the Intel i82593 using  two  DMA channels. There is an (alpha?) driver available in the present kernel version. As with all notebook and pocket adaptors, it is under the `Pocket and portable adaptors' section when running  make config . Also note that the IBM ThinkPad 300 is compatible with the Z-Note.      5.43 Znyx          Znyx ZX342 (DEC 21040 based)    Status: Supported, Driver Name: de4x5, tulip  You have a choice of  two  drivers for cards based on this chip. There is the DE425 driver written by David, and the generic 21040 driver that Donald has written.  Note that as of 1.1.91, David has added a compile time option that may allow non-DEC cards (such as the Znyx cards) to work with this driver. Have a look at  README.de4x5  for details.  See   DEC 21040  for more information on these cards, and the present driver situation.      5.44 Identifying an Unknown Card        Okay, so your uncle's cousin's neighbour's friend had a brother who found an old ISA ethernet card in the AT case he was using as a cage for his son's pet hampster. Somehow you ended up with the card and want to try and use it with linux, but nobody has a clue what the card is and there isn't any documentation.  First of all, look for any obvious model numbers that might give a clue. Any model number that contains 2000 will most likely be a NE2000 clone. Any cards with 8003 or 8013 on them somewhere will be Western/Digital WD80x3 cards or SMC Elite cards or clones of them.    Identifying the Network Interface Controller    Look for the biggest chip on the card. This will be the network controller (NIC) itself, and most can be identified by the part number. If you know which NIC is on the card, the following might be able to help you figure out what card it is.  Probably still the most common NIC is the National Semiconductor DP8390 aka NS32490 aka DP83901 aka DP83902 aka DP83905 aka DP83907. And those are just the ones made by National! Other companies such as Winbond and UMC make DP8390 and DP83905 clone parts, such as the Winbond 89c904 (DP83905 clone) and the UMC 9090. If the card has some form of 8390 on it, then chances are it is a ne1000 or ne2000 clone card. The second most common 8390 based card are wd80x3 cards and clones. Cards with a DP83905 can be configured to be an ne2000  or  a wd8013. Never versions of the genuine wd80x3 and SMC Elite cards have an 83c690 in place of the original DP8390. The SMC Ultra cards have an 83c790, and use a slightly different driver than the wd80x3 cards. The SMC EtherEZ cards have an 83c795, and use the same driver as the SMC Ultra. All BNC cards based on some sort of 8390 or 8390 clone will usually have an 8392 (or 83c692, or ???392) 16 pin DIP chip very close to the BNC connector.  Another common NIC found on older cards is the Intel i82586. Cards having this NIC include the 3c505, 3c507, 3c523, Intel EtherExpress-ISA, Microdyne Exos-205T, and the Racal-Interlan NI5210.  The original AMD LANCE NIC was numbered AM7990, and newer revisions include the 79c960, 79c961, 79c965, 79c970, and 79c974. Most cards with one of the above will work with the Linux LANCE driver, with the exception of the old Racal-Interlan NI6510 cards that have their own driver.  Newer PCI cards having a DEC 21040, 21041, 21140, or similar number on the NIC should be able to use the linux tulip or de4x5 driver.  Other PCI cards having a big chip marked RTL8029 or 89C940 or 86C926 are ne2000 clone cards, and the ne driver in linux version v2.0 and up should automatically detect these cards at boot.    Identifying the Ethernet Address      Each ethernet card has its own six byte address that is unique to that card. The first three bytes of that address are the same for each card made by that particular manufacturer. For example all SMC cards start with  00:00:c0 . The last three are assigned by the manufacturer uniquely to each individual card as they are produced.  If your card has a sticker on it giving all six bits of its address, you can look up the vendor from the first three. However it is more common to see only the last three bytes printed onto a sticker attached to a socketed PROM, which tells you nothing.  You can determine which vendors have which assigned addresses from RFC-1340. Apparently there is a more up to date listing available in various places as well. Try a WWW or FTP search for  EtherNet-codes  or  Ethernet-codes  and you will find something.    Tips on Trying to Use an Unknown Card      If you are still not sure what the card is, but have at least narrowed it down some, then you can build a kernel with a whole bunch of drivers included, and see if any of them autodetect the card at boot.  If the kernel doesn't detect the card, it may be that the card is not configured to one of the addresses that the driver probes when looking for a card. In this case, you might want to try getting  scanport.tar.gz  from your local linux ftp site, and see if that can locate where your card is jumpered for. It scans ISA I/O space from  0x100  to  0x3ff  looking for devices that aren't registered in  /proc/ioports . If it finds an unknown device starting at some particular address, you can then explicity point the ethernet probes at that address with an  ether=  boot argument.  If you manage to get the card detected, you can then usually figure out the unknown jumpers by changing them one at a time and seeing at what I/O base and IRQ that the card is detected at. The IRQ settings can also usually be determined by following the traces on the back of the card to where the jumpers are soldered through. Counting the `gold fingers' on the backside, from the end of the card with the metal bracket, you have IRQ 9, 7, 6, 5, 4, 3, 10, 11, 12, 15, 14 at fingers 4, 21, 22, 23, 24, 25, 34, 35, 36, 37, 38 respectively. Eight bit cards only have up to finger 31.  Jumpers that appear to do nothing usually are for selecting the memory address of an optional boot ROM. Other jumpers that are located near the BNC or RJ-45 or AUI connectors are usually to select the output media. These are also typically near the `black box' voltage converters marked YCL, Valor, or Fil-Mag.  A nice collection of jumper settings for various cards can be found at the following URL:    Ethercard Settings     5.45 Drivers for Non-Ethernet Devices        There are a few other drivers that are in the linux source that present an  ethernet-like  device to network programs, while not really being ethernet. These are briefly listed here for completeness.  dummy.c  - The purpose of this driver is to provide a device to point a route through, but not to actually transmit packets.  eql.c  - Load Equalizer, enslaves multiple devices (usually modems) and balances the Tx load across them while presenting a single device to the network programs.  ibmtr.c  - IBM Token Ring, which is not really ethernet. Broken-Ring requires source routing and other uglies.  loopback.c  - Loopback device, for which all packets from your machine and destined for your own machine go. It essentially just moves the packet off the Tx queue and onto the Rx queue.  pi2.c  - Ottawa Amateur Radio Club PI and PI2 interface.  plip.c  - Parallel Line Internet Protocol, allows two computers to send packets to each other over two joined parallel ports in a point-to-point fashion.  ppp.c  - Point-to-Point Protocol (RFC1331), for the Transmission of Multi-protocol Datagrams over a Point-to-Point Link (again usually modems).  slip.c  - Serial Line Internet Protocol, allows two computers to send packets to each other over two joined serial ports (usually via modems) in a point-to-point fashion.  tunnel.c  - Provides an IP tunnel through which you can tunnel network traffic transparently across subnets  wavelan.c  - An Ethernet-like radio transceiver controlled by the Intel 82586 coprocessor which is used on other ethercards such as the Intel EtherExpress.      Next   Previous   Contents"
GX201-37-3866984	"Menu for /mirrors/linux/people/marcelo/linux-2.4/drivers/acorn/char/defkeymap-acorn.map                  0-2,4-5,8,12                         0              keycode              keycode              1              keycode              keycode              alt              2              keycode              keycode              alt              3              keycode              keycode              alt              4              keycode              keycode              alt              5              keycode              keycode              alt              6              keycode              keycode              alt              7              keycode              keycode              alt              8              keycode              keycode              alt              9              keycode              keycode              alt              10              keycode              keycode              alt              11              keycode              keycode              alt              12              keycode              keycode              alt              13              14              keycode              keycode              keycode              keycode              15              16              keycode              17              keycode              18              keycode              keycode              19              keycode              keycode              20              keycode              keycode              21              keycode              keycode              22              keycode              keycode              23              keycode              keycode              24              keycode              keycode              25              keycode              26              keycode              27              keycode              control              keycode              28              keycode              29              keycode              30              keycode              keycode              31              32              33              keycode              34              35              36              37              38              keycode              39              40              41              keycode              42              43              44              45              46              47              48              49              keycode              keycode              50              keycode              keycode              51              keycode              keycode              52               alt              53              54              keycode              55              keycode              keycode              56              keycode              keycode              57              keycode              keycode              58              59              60              keycode              61              62              keycode              63              keycode              64              65              66              67              68              69              keycode              70              keycode              keycode              71              keycode              72              keycode              keycode              73              keycode              keycode              74              keycode              keycode              75              76              77              78              79              80              keycode              81              82              keycode              83              84              85              keycode              86              keycode              keycode              87              keycode              keycode              88              89              90              keycode              keycode              91              keycode              keycode              92              keycode              keycode              93              94              95              keycode              keycode              96              97              98              keycode              99              100              keycode              101              keycode              keycode              102               alt              103              104              105              106              107              108              109              110              111              112              113              114              115              116              117              118              119              120              121              122              123              124              125              126              127              F1              F2              F3              F4              F5              F6              F7              F8              F9              F10              F11              F12              F13              F14              F15              F16              F17              F18              F19              F20              Find              Insert              Remove              Select              Prior              Next              Macro              Pause              '`'              '`'              '\''              '\''              '^'              '^'              '~'              '~'              '""'              '""'              'O'              'o'              '0'              '0'              'A'              'a'              'A'              'a'              ','              ','              '`'              '`'              '\''              '\''              '^'              '^'              '""'              '""'              '`'              '`'              '\''              '\''              '^'              '^'              '""'              '""'              '-'              '-'              '~'              '~'              '`'              '`'              '\''              '\''              '^'              '^'              '~'              '~'              '""'              '""'              '/'              '/'              '`'              '`'              '\''              '\''              '^'              '^'              '""'              '""'              '\''              '\''              'T'              't'              's'              '""'              's'              'i'"
GX058-36-6827587	"May 2001, Issue 66       Published by  Linux Journal     Front Page   |   Back Issues   |   FAQ   |   Mirrors   |   Search                         Visit Our Sponsors:                                                 Table of Contents:               The MailBag        News Bytes            Distro News         News in General         Software Announcements           The Answer Gang        More 2-Cent Tips        The Weekend Mechanic  ,  by Thomas Adam       HelpDex  ,  by Shane Collinge       Interview with Ben Collins, the new Debian Project Leader  ,  by Fernando Ribeiro Corrêa & Marcos Martins Manhães       Converting Linux HOWTOs into Book Format  ,  by Mark Nielsen       Configuring GDM 2.2  ,  by Mark Nielsen       CVS: Client-Server Version Control  ,  by Kapil Sharma       Stopping Spam on Your Linux Box  ,  by Suresh Ramasubramanian       The Back Page            About This Month's Authors         Not Linux                                 Linux Gazette  Staff and The Answer Gang     Editor:  Michael Orr   Technical Editor:  Heather Stern   Senior Contributing Editor:  Jim Dennis   Contributing Editors:  Ben Okopnik, Dan Wilder, Don Marti                    TWDT 1 (gzipped text file)   TWDT 2 (HTML file)  are files containing the entire issue: one in text format, one in HTML.  They are provided  strictly as a way to save the contents as one file for later printing in the format of your choice;  there is no guarantee of working links in the HTML version.                   Linux Gazette ,   http://www.linuxgazette.com/   This page maintained by the Editor of  Linux Gazette ,   gazette@ssc.com      Copyright © 1996-2001 Specialized Systems Consultants, Inc.                    The Mailbag                  HELP WANTED -- Article Ideas      Send tech-support questions, answers and article ideas to The Answer Gang < linux-questions-only@ssc.com >.  Other mail (including questions or comments about the  Gazette  itself) should go to < gazette@ssc.com >.  All material sent to either of these addresses will be considered for publication in the next issue.   Please send answers to the original querent too, so that s/he can get the answer without waiting for the next issue.     Unanswered questions might appear here.  Questions with answers--or answers only--appear in The Answer Gang, 2-Cent Tips, or here, depending on their content.  There is no guarantee that questions will  ever  be answered, especially if not related to Linux.     Before asking a question, please check the  Linux Gazette  FAQ  to see if it has been answered there.                    Device Drivers for Linux Gazette                 Device Drivers for Linux Gazette  Wed, 18 Apr 2001 22:39:40 -0700  Ryan Thibodeau ( rthibode from onlineathens.com )      Hi. Just dicovered Linuxgazette today. This is a really great site.     If you are looking for article ideas, I'd like to see an article, or even series, on writing device drivers for Linux. This is a topic I have found very little information about on the net.     Just my two cents.     Writing the Linux kernel's device driver interfaces are enough of a subject to fill a whole book.  Maybe the O'Reilly  Writing Linux Device Drivers  (by Allessandro Rubini) and their  Understanding the Linux Kernel  by Daniel Pierre Bovet (among others) would be a good choice for you.     As for documention online:  You could always read the sources, copy and paste parts of the Makefiles, copy an existing (similar) device driver and edit.  I realize that this is a horrible oversimplification; but that's how must of the Linux kernel hackers started.  -- JimD             Mon, 16 Apr 2001 22:04:56 -0700  Vivek Kumar ( ascon_system from netkracker.com )    how to write a parallel port device driver,ie, interrupt driven. Not, for printer, but,for general device connected to EPP port..?     If you need something to be interrupt driven than you need a kernel module.  You might be able to have a very simple kernel module that simply relays the interrupt as a character through a device node.  Then you could have a user space process listening...     [ Some guesses about the nature of  poll()  and  select() ,  trimmed. ] Please post a message to a good linux programming newsgroup for better details.  Actually I've posted an abstracted version of this question to the   comp.os.linux.development.system  newsgroup on your behalf.  So, perhaps there's already an answer waiting...  -- JimD    Well, the Answer Guy is just barely getting into this subject,  so for this topic, he's a newbie like the rest of us.  It          looks like some of our weekend mechanics really want to get          down into the spark plugs, there.  So, if anyone feels inclined to write a down and dirty device  driver article that explains a bit of deep wizardry in plain         english, especially if it covers something that's new in the          2.4 series kernels, we'd love to publish it. -- Heather    Or if anybody would like to dissect and explain a small driver  they've written, that would also make a good article. -- Mike                GENERAL MAIL                   Great   Subscribing to LG   Your writing of: ""Integrating"" Linux/sendmail with MS Exchange   Thank you   incensative, and down right rude,                 Great  Sat, 31 Mar 2001 23:07:10 -0600  James E. Touma ( toumaj from home.com )    Great April edition. Thanks a lot. Keep up the good work (and the interesting topics).     Thanks for reading us, Jim!  -- Heather                 Subscribing to LG  Sun, 1 Apr 2001 20:36:36 -0700  Mike Orr ( iron from mso.oz.net )    Finally, a way to subscribe to Linux Gazette!      Debian  has long had the lg-issue## packages.  Now it has a couple new packages:       lg-subscription : install new issues as they arrive.   lg-ltest-two : install the latest two issues and remove older ones.   lg-all : install all of the currently-available issue.     Of course, it adds/removes packages only when you do a general package update. Note that these programs are supported by Debian, not by  LG .    -- Mike (your friendly  Linux Gazette  Editor)     Looks like you have to get it from testing (aka woody) or unstable (aka sid) but at least it shouldn't require a libc update, if you temporarily  add one of these to your sources list to get them.  If one of these   does  ask for a libc change, it's a packaging bug and you should  report it immediately.     But be especially careful to change things back, or you may find yourself in for a big surprise when you run "" apt-get upgrade "" to catch the latest security patches.  -- Heather                 Your writing of: ""Integrating"" Linux/sendmail with MS Exchange  Tue, 10 Apr 2001 10:39:15 -0400  Dave Tabor ( dtabor from mageeop.com )    Hi,     Just a note of constructive criticism.     I just read a copy of your writing of ""Integrating"" Linux/sendmail with MS Exchange, on this site.      http://lhd.datapower.com/LDP/LDP/LG/issue38/tag/5.html      It's something you wrote in 1999, so you may be writing differently now.  If so, please disregard this letter.     What you are about to say is still valuable as a reminder to new members    of the Answer Gang, potential article authors, and in fact just about     anybody who hopes to be a very vocal Linux advocate.  So I hope you    don't mind that we've published it anyway.  -- Heather     Although I found this information helpful, you appear to have trouble staying on track with the useful information, and like to get off subject with the Microsoft bashing.     I do use Microsoft products, as well as Linux and AIX products, and understand your point of view (even agree with most, if not all, of it).     My constructive criticism is that you should refrain from the Microsoft bashing or at least keep it to one line, and keep more to the point of trying to relay useful information.  (I'm assuming that is what you are really trying to do.)     If someone is having trouble with something like integrating sendmail and exchange, they may not have a choice about what systems or software to use, and just need some well written, detailed information, not an anti-Microsoft commercial.     - Dave     Thanks, Dave.  Issue 38 was a long time ago now.     The Answer Gang now includes a number of more cheerful sorts in addition to the curmudgeonly Answer Guy himself.  One or two even still use Windows for some of their work.  (Note: we avoid answering Windows questions at all, unless they're really about working with Linux environments.)  Having more of us frees the ones who really don't want to touch anything about MS, from even having to answer.  Also, a heavier editorial hand is being applied now.     As for myself, I look forward to the day when systems will be sufficiently easy to use that it will not be clear... nor terribly necessary to know... which OS is chugging along ""under the hood"".  I don't think that day is at all  close  but I look forward to it anyway.        -- Heather                 Thank you  Wed, 28 Mar 2001 22:10:12 EST  Spartaco Cicerchia ( MI1SA from aol.com )    Dear Mike     I want to take the opportunity to thank you very much for the feed back and for taking the time to give me the information.                 incensative, and down right rude,  Wed, 4 Apr 2001 00:04:53 -0400  Joe Agate ( joetagate from home.com )    sorry pal, but after reading your reponse to a post for help, i couldnt help but send you this note about what an  [ rude word deleted ] you must be...and would be  very much surprised if anyone would want you on the payroll....     respectfully,  joe agate      http://rpmfind.net/linux/mdw/LDP/LG/issue50/tag/33.html      [ HTML version of same text, also deleted ]     Curiously, he chose to ""rag"" on the Answer Guy for one of his clearer answers to an unclear question.  He calls him a bad name, then signs off ""respectfully"".  Right.     Is it really ""insensitive"" to mention that LG has a search engine ( http://www.linuxgazette.com/search.html )?   Nope, I think not.     Is it ""insensitive"" to ask that querents mention what they've tried already?   Maybe - but it's a fact of life in tech support, most people say ""it's broken"" not ""I tried this, and that, and the other thing, and... yada yada ... anyways so you can see I tried everything, and it hates me"".  In plain verbal conversation it's rude to maunder on like that, so people tend not to do it.  In tech support, the more info you can send us (that is related to the question) the better we can help.  If this were a phone call, we could have this merry back and forth, and it still probably wouldn't take an hour.  At typical Answer Gang speeds though... more info will help you as much as it helps us.     Is it ""insensitive"" to suggest that the poor bloke may have to buy a new card or new server?  Probably.  Oh well.  Life's tough that way sometimes.   Turns out that he's probably okay, according to another reader who assured us that the Jotan is indeed a Trident relative.     Is it insensitive to send us the same text as both plaintext and HTML? No, usually it just means someone didn't know how to turn off this ""feature"" (cough cough.  cough.  no, I'm okay.  cough cough.  water.  Ahem) in MS Outlook.  Try this great answer from Chris G. in last month's Answer Gang:      http://www.linuxgazette.com/issue65/tag/8.html      Lastly, I'm pretty sure it's insensitive to publish this, but Joe, you mailed us, and this is what we normally do with letters to the editors. Let us know when you have a linux question, and we'll try to answer it -- if you give us enough information!                     Linux jobs  Wed, Apr 11, 2001 12:17:14PM -0500  Stuart ( stuart-5757 from hushmail.com )      Would it be possible for someone at your publication to provide me with a resource as to where I could locate an experienced Linux programmer for the Tampa Florida area. Is there a website for Linux job postings or a publication that I might be able to contact. I would appreciate any help that you could give me.     The Answer Gang published a list of sites for job searchers in the last issue.  I'm sure you can post openings at these sites as well.      http://www.linuxgazette.com/issue65/lg_answer65.html#tag/greeting      LG does not publish job listings because they are so temporary in nature: the job may be filled by the time the issue is published!  -- Mike     To repeat from last time:     You can check out  Linux Journal 's Career Center ( http://www.linuxjournal.com/employ ), Geekfinder ( http://www.geekfinder.com ), the Sysadmin's Guild (SAGE) Job Center ( http://www.usenix.org/sage/jobs/sage-jobs.html ), or pay attention to your local area papers for when major high tech Job Fairs are in your area, so you can go to them. There are also some really generic job sites like Dice.Com ( http://www.dice.com ) or MonsterBoard ( http://www.monsterboard.com ). If you hate the corporate mold, check out some of the project offers at Cosource ( http://www.cosource.com ) or Collab.Net ( http://www.collab.net ). Or put up your consulting shingle by listing yourself at Linuxports ( http://www.linuxports.com ) and getting listed into a few search engines.     ... and expand a little:     When I went to Google! and typed in the keywords:    linux jobs      -- it claimed it has about 400 entries.     As Mike noted, many of these allow employers to post job offers, as well as having jobseekers post resumés.  -- Heather         ""Linux Gazette... making Linux just a little more fun! ""              Contents:     Distro News   News in General   Software Announcements        Selected and formatted by   Michael Conry  and Mike Orr        Submitters, send your News Bytes items in   PLAIN TEXT  format.  Other formats may be rejected without reading.  You have been warned!  A one- or two-paragraph summary plus URL gets you a better announcement than an entire press release.         Distro News              Debian      Debian  Potato users out there itching to get their hands on the new 2.4 kernels may be interested in these links.  Linux Weekly News  have posted the Debian-News   message  of Apr 16, which has advice on getting kernel 2.4 working on you 2.2 potato install. The  instructions  should be read carefully before upgrading.     In other Debian news, The third revision of Debian GNU/Linux 2.2 (nickname `potato') has been released.  This point release, version 2.2r3, mostly includes security updates, along with a few corrections to important bugs in the stable distribution. The details are   online .               Mandrake            Linux-Mandrake  8.0 has been released. New features can be studied in detail on their   website . Highlights include KDE 2.1.1, GNOME 1.4, Kernel 2.4.3, Xfree86 4.0.3, and Anti-aliasing. If you would like to donate to the project, go to   http://www.linux-mandrake.com/donations/               Progeny          Progeny  Debian is    out  now. The download edition is already  available , and the box set will be on sale from April 23. Ian Murdock, Progeny CEO and President, has said that Progeny Debian is not trying to be another distribution of Linux. ""In fact, we don't see Progeny Debian as a separate distribution. It is an enhanced version of Debian for the commercial market. All of our development efforts are being contributed back to the Debian community, and we hope that our work can help make Debian better for all users"", he comments.               Red Hat           Red Hat   have announced Red Hat Linux 7.1    with 2.4 kernel . The Red Hat website has a complete list of the    new features .                Slackware       Linux Weekly News  have a  story   on   Slackware 's difficulties.  Apparently, Wind River have laid off the  Slackware development staff. Patrick Volkerding, who is also laid off, says that he has sufficient funds to publish the next edition of Slackware, but not enough to pay developers for their input. This was a big    topic  of conversation on the Slackware forum (might break Netscape).   If you want to see Slackware continue, you can donate to the project via their  PayPal  account. Donate to paypal@slackware.com               SuSE        SuSE Linux   have announced the release of SuSE Linux 7.1 for the Sparc  architecture of Sun Microsystems.  SuSE Linux 7.1 for Sparc comes with the proven Linux Kernel 2.2.18  as well as the latest Kernel 2.4.2 as a special bonus for  technophile users. SuSE Linux 7.1 is based on the program library  glibc 2.2. The popular SBUS graphics cards are supported by  XFree86 4.0.2.  Application support for LFS (Large File Support) and IPv6 (Internet Protocol  Version 6) has grown.    SuSE Linux 7.1 for Sparc (Item No. 99985-21SPC) is supplied on  five CD-ROMs with online documentation. It can be obtained  exclusively directly from SuSE at the price of EUR 159 plus VAT.  SuSE Linux 7.1 for Sparc is also available for download from    ftp://ftp.suse.com/pub/suse/sparc/suse-sparc/           News in General               Upcoming conferences and events          Listings courtesy  Linux Journal .  See  LJ 's  Events  page for the latest goings-on.                      Linux for Industrial Applications 3rd Braunschweiger  Linux-Tage           May 4-6, 2001 Braunschweig, Germany                    http://braunschweiger.linuxtage.de/industrie/                            Linux@Work Europe 2001           May 8 - June 15, 2001 Various Locations                    http://www.ltt.de/linux_at_work.2001                             Linux Expo, São Paulo           May 9-10, 2001 São Paulo, Brazil                    http://www.linux-expo.com                              SANS 2001 May 13-20, 2001   Baltimore, MD                    http://www.sans.org/SANS2001.htm                              7th Annual Applied Computing Conference           May 14-17, 2001 Santa Clara, CA                    http://www.annatechnology.com/annatech/HomeConf2.asp                             Linux Expo, China           May 15-18, 2001 Shanghai, China                    http://www.linux-expo.com                            SITI International Information Technologies Week   OpenWorld Expo 2001           May 22-25, 2001 Montréal, Canada                    http://www.mediapublik.com/en/                     Strictly e-Business Solutions Expo    May 23-24, 2001 Minneapolis, MN      http://www.strictlyebusinessexpo.com                     Linux Expo, Milan           June 6-7, 2001 Milan, Italy                    http://www.linux-expo.com                               Linux Expo Montréal           June 13-14, 2001 Montréal, Canada                    http://www.linuxexpomontreal.com/EN/home/                                    Open Source Handhelds Summit           June 18-19, 2001 Austin, TX                    http://osdn.com/conferences/handhelds/                     USENIX Annual Technical Conference    June 25-30, 2001 Boston, MA      http://www.usenix.org/events/usenix01              PC Expo    June 26-29, 2001 New York, NY    www.pcexpo.com                  Internet World Summer July 10-12, 2001   Chicago, IL      http://www.internetworld.com             O'Reilly Open Source Convention    July 23-27, 2001 San Diego, CA      http://conferences.oreilly.com                    10th USENIX Security Symposium           August 13-17, 2001 Washington, D.C.                    http://www.usenix.org/events/sec01/                            HunTEC Technology Expo & Conference Hosted by Hunstville IEEE           August 17-18, 2001 Huntsville, AL   URL unkown at present                               Computerfest           August 25-26, 2001 Dayton, OH                    http://www.computerfest.com                     LinuxWorld Conference & Expo    August 27-30, 2001 San Francisco, CA      http://www.linuxworldexpo.com                    The O'Reilly Peer-to-Peer Conference           September 17-20, 2001 Washington, DC                    http://conferences.oreilly.com/p2p/call_fall.html                     Linux Lunacy Co-Produced by  Linux  Journal  and Geek Cruises                    Send a Friend  LJ  and Enter to Win a Cruise!     October 21-28, 2001 Eastern Caribbean      http://www.geekcruises.com                     LinuxWorld Conference & Expo           October 30 - November 1, 2001 Frankfurt, Germany                    http://www.linuxworldexpo.de/linuxworldexpo/index.html                           5th Annual Linux Showcase & Conference           November 6-10, 2001 Oakland, CA                    http://www.linuxshowcase.org/                            Strictly e-Business Solutions Expo           November 7-8, 2001 Houston, TX                    http://www.strictlyebusinessexpo.com                              LINUX Business Expo Co-located with COMDEX           November 12-16, 2001 Las Vegas, NV                    http://www.linuxbusinessexpo.com                           15th Systems Administration Conference/LISA 2001           December 2-7, 2001 San Diego, CA                    http://www.usenix.org/events/lisa2001                                         Newlix ServerWare            Newlix Corporation  has developed an intelligent and customisable administration solution for Linux based server appliances. Newlix ServerWare contains an intelligent administration engine so intuitive that it creators say ""it can be seen as having an entire IT team sucked right into the server appliance!""  This technology is intended to improve the functionality and ease of use of server appliances. Full details are   available  on the Newlix website.                   eCluster Internet Server Clustering         eCluster from   XGforce  is a scalable, Intelligent load-balance  cluster system, which can be scaled up to 1024 Internet cluster groups and each contains 1024 cluster nodes(1024X1024).  With round trip time load balance algorithm, one can cluster  any OSes on any CPUs, such as NT, Novell,  UNIXes (SUN SPARC, OS2000 BSD, Linux), etc. The  support of load balance or fail safe mode, ensured non-stoppable and fast business transactions for SQL Database Servers, such as  Oracle, MS SQL, Informix, MySQL, Postgress, etc.    A load balance algorithm is used which includes CPU load, weighted load,  vm usage, round trip time, CPU usage, etc.  Other features include Network Traffic Distribution, Network Failsafe, CFS(tm), and Large Network Management for both Internet and Intranet.   Ports for LINUX, SUN, FreeBSD, and NT are available and free support  is provided. For more information, consult the XGforce  website .              ActiveState Launches ASPN Initiative             ActiveState  has launched a new initiative to enable programming with open source technologies.  The ActiveState Programmer Network (ASPN) includes quality assured binary distributions of Perl, Python and Tcl; multi-language and platform IDEs; technical references, sample code, recipes and more.  For additional details or go to the    ASPN website .              OTG Software         OTG Software  has announced its acquisition of    Smart Storage , a privately held provider of standards based DVD and CD storage management software. OTG expects Smart Storage's CD/DVD technology to speed its entry into the rich media market, to boost its international momentum, and to enable it to offer more solutions for storing and accessing data on the UNIX and Linux platforms.      OTG, has also announced its participation and strategic partnership in    BMC Software 's  Application-Centric Storage Management Consortium  (  ACSM ),  a partner program that provides a competitive edge and additional avenues to members for market development, customer services and market expansion.              Linux Fortran      Many of us involved in scientific computing make considerable use of Fortran, either for writing our own code, or for the many libraries which have been written in the language. Dr. Bronson Messer of the University of Tennessee has recommended   http://studbolt.physast.uga.edu/templon/fortran.html  as a good source of information relating to Linux and Fortran. It has comparisons of various compilers, news, tips, etc.                        Here are the May-June articles for the ezine  Linux Focus .       Building a Linux-controlled walking robot   Through the tunnel   Avoiding security holes when developing an application - Part 3 : buffer overflows   Do your job with make!   Introduction to BORG   Real-time mp3 recording, part 2   Game Review - GLTron                   Linux Links          There is a    vulnerability  in kernel 2.4.x IPTables which you should patch if you use Linux 2.4 for firewalling.  Quoting from the SANS Institute's alert: ""A vulnerability in the ip_conntrack_ftp module, which is responsible for tracking incoming FTP connections, has been found. This vulnerability could be used to bypass IPTables firewall rules if IPTables is configured to allow RELATED connections to pass unhindered, which is a standard configuration used with FTP servers. An attacker can trick the ip_conntrack_ftp module into creating RELATED connections, thus allowing various outbound connections to the network of the firewall itself."" A   patch  is available.     The Duke of URL  has the following links to tempt you:             review  of SuSE Linux 7.1     http://www.thedukeofurl.org           Review  of the Pogo Linux Velocity, a desktop Linux machine which sports     IDE RAID 1 or RAID 0.           Wireless LAN Overview  Part 2: the Devices. This is a good article for     anyone interested in how the new 802.11b devices run on both Linux and     Windows systems.  Both cards are tested on each OS.      An       editorial  on V.92, its benefits, if you're eligible for the update     and if V.92 is really that much better than the older V.90 standard for     modems.       Since the point of FAQ's is to get newbies up to speed, let's take this opportunity to direct attention to   The linux-kernel mailing list FAQ . Then when you have digested that, you can see what's happening   on-list .     SlashDot  has offered the following links in the past month:         An       article  discussing the differences between FreeBSD, NetBSD, OpenBSD and     Apple's OS X/Darwin       Slashdot have an            interview  with Microsoft's Doug Miller                 Parrot:  how the April Fool's joke of the Perl and Python merger was     perputrated.    Suresh Ramasubramanian mailed a link to    an article  he has prepared, providing a HOWTO on configuring a linux box dialup connection, complete with configuring email services (using sendmail, exim and postfix as the MTA and mutt as the MUA) on the box. You might find this useful.     Bryan Pfaffenberger writes about    Why Open Content Matters  in his Linux Journal web column ""  Currents "".    And please, some paper-clip sized sympathy for The Microsoft Office help clip who became the latest (and most welcome ;-)   redundancy  in the tech-sector recently.    Finally, not strictly Linux, but   UnixSpace.com  have announced a free on-line internet access   service  to their ConteXt database server. Includes 30Mb space, Unix shell command line, and some GUI treats focused on DataBase building.                Software Announcements                 SSH            Open SSH  have announced the release of version 2.5.2 of their software. The Open SSH suite includes the ssh program which replaces rlogin and telnet, scp which replaces rcp, and   sftp  which replaces ftp.  Also included is sshd which is the server side of the package, and the other basic utilities like ssh-add, ssh-agent, ssh-keygen and sftp-server. OpenSSH supports SSH protocol versions 1.3, 1.5, and 2.0. You cannot afford to ignore security!               PostgreSQL 7.1 version announced      The    PostgreSQL  open source database core development community have announced the official release of the  PostgreSQL 7.1 version. Check their  news  page for more information. PostgreSQL 7.1 will feature several upgrades and improvement from the previous version, including:        full support for outer joins    removal of the notorious 8k row length limit    write-ahead logging performance enhancement    even greater support for complex queries    support for a larger number of complex queries    a boost in overall performance (speed)    improvements to the JDBC and ODBC interfaces and backup/restore features    Fuller support for ANSI SQL92 standards.   PostgreSQL version 7.1 includes contributions from more than 120 members of the PostgreSQL open source development community.               Python         Python 2.1  has been released. Find out    what's new , and read the full   release notes .              Cylant IDS for Linux: prevents unknown attacks too         Cylant Technology  have released CylantSecure for Linux, an intrusion detection system that protects against both known and previously unknown forms of attack. It uses a modified kernel in conjunction with custom kernel modules to provide system protection -- and becomes part of the running kernel. Unlike other IDS products, CylantSecure does not use rules or patterns for identifying attacks, eliminating the need to rely on a database of known attack signatures. Instead, it focuses on actual software behaviour and builds a statistical model of nominal system behaviour. It enables a computer to distinguish between normal and abnormal behaviour, and then uses that information to stop malicious attacks before any damage can occur. Details on the software are in an online   press release .               ICS Integrates Themes Into Open Motif         Integrated Computer Solutions  has announced the Developer's Release of its initiative to add themes to Open Motif. Themes is a capability supplied with Linux desktop environments that provides users with the ability to personalise the overall look of the user interface of their desktop. The Developer Release of Themes for Open Motif works with GTK themes created for Gnome. Currently, themes are converted by hand into a format that Open Motif can process. As the Open Motif Themes capability evolves, no conversion will be necessary and Open Motif based applications will automatically adopt the theme set by the end user. The objective of the initiative is to support both the Gnome and KDE desktop environments. ICS is actively looking to recruit other Open Source developers to help with this project. Further details can be found at the ICS forum    website .              Internet Exchange Messaging Server 5       Messaging software developer   International Messaging Associates  have launched the beta version of its latest product, Internet Exchange Messaging Server 5 (IEMS 5). IEMS 5 supports distributed computing environments and is said to run well on mixed Linux and Windows platforms.  ""Currently, we are working on providing support for several Linux distributions,"" said Tim Kehres, IMA Managing Director.   These Linux distributions include RedHat, SuSE, VALinux, Turbo Linux, Caldera, Mandrake, among others.  This product enables users to access their mailboxes via POP3 or IMAP4-capable clients such as Microsoft Outlook, Netscape Navigator, Eudora Mail, as well as the Internet Exchange Web Mail Client.    You can get a copy of IEMS 5 at    http://www.ima.com/download/v5eval.html . The product overview can, also be    downloaded . Beta participants of the Linux-Windows-based Internet Exchange Messaging Server (IEMS) 5 shall get a US$300 price reduction (about 30% off) if they purchase the messaging solution now than wait for its forthcoming official release.                  Other software        Better Access Networking  in Leuven is   Teamware's  new reselling partner for Teamware Office 5.3 for Linux in Belgium. Teamware Office for Linux completes Better Access' product offering by bringing e-mail, calendar and document management functionalities to Linux. Teamware have also made a partner agreement with   Coresys AB  in Sweden. For latest news, check out the Teamware   newsletter .        The new version of    Mailman , 2.0.4, compatible with   Python 2.1 , is out.   LWN  have the    story .      Insignia  sponsored a technical interest forum at the recent Embedded Systems Conference. The subsequent detailed press release is wide-ranging and available   online .            Copyright © 2001, Michael Conry and  the Editors of  Linux Gazette .  Copying license  http://www.linuxgazette.com/copying.html  Published in Issue 66 of  Linux Gazette , May 2001                      The Answer Gang           By Jim Dennis, Ben Okopnik, Dan Wilder, Breen, Chris, and the Gang,  the Editors of Linux Gazette...   and You!  Send questions (or interesting answers) to   linux-questions-only@ssc.com     There is no guarantee that your questions  here will  ever  be answered.  You can be published anonymously   - just let us know!           Contents:     ¶: Greetings From Heather Stern        help installing telnetd   touch files recursively linux mandrake 7.2   Winprinters   your mail --or--  Search and Replace Without Breaking Permissions    your mail --or--  Kernel Panic after putting disk back    Procmail and regular expressions....(Snowwhite...)   Need to milk you again --or--  Timely Samba Release?    3d linux   linux vectoring synergy   Why linux for routing   disappearing act   getting 2 dynamic ip addresses           Greetings from Heather Stern     Once again, welcome to the wonderful world of The Answer Gang.  The peeve of the month this time is a tie:      AOL users asking for help regarding things which clearly would     not be answered by AOL's tollfree tech support by anything but closing the    offending account.      Folks, AOL doesn't  have  a Linux version, not even for SVGAlib.         The closest we can get are a zillion instant messanger clients,         including Netscape, for which the universal trick is ""tell it who you         are on AOL, then start IM'ing your friends.""  If you can't figure         out who you are on AOL, we certainly don't know!  So, we can't answer          any AOL questions at all.  Even ethical ones.      Business people who want us to do  their  homework -    asking very complicated questions clearly worth a certain amount of    consulting time, frosted with an automatically tacked on ""This message    is confidential and may not be given to anyone but the intended recipient,    legal mumbo jumbo, etc. etc."" message which they may not even be aware of,    and possible cherry on top ""Please hurry.""      Understand we're not really peeved at the person who's asking, so much     as the presumption.   Linux Gazette  is for everyone ... to      make Linux just a little more fun ... and if we don't get to (potentially)     give your answer to the masses, too, then  LG  isn't getting     ""paid"" to pass your question along to us.     If you're a corporate type with an outbound mail gateway that adds such     notes, and you're fairly sure your answer will be useful (maybe even fun)     for the rest of the  Linux Gazette  readership, then  give us permission to     publish the thread, up front, when you ask the question.       Your company will still be anonymous.  You can be anonymous too, if      you say so.     As for ""hurry"" -- if you want a timely answer, or even to be sure of     getting one, pay a consultant.    (Cheap plug: some of the Gang happen to be consultants.  But not   all of us.)     We could probably use a few more articles that appeal to corporate users, though!  Enough of that, though.  Onward to something fun.  The fun I took on this month is to upgrade my system.     Oh boy.    Surely I mentioned that I've been on a continuous upgrade path of      SuSE  since early 5.1?  No?  Well,    okay, I admit, I did a ""real"" reinstall sometime around 6.1 or so,    and then have chugged along on security updates and adding RPMs from    the latest 6.x branch for a while.  With an occasional graft from    Debian packages and source tarballs.    Like any normal user I also have lots of different things I do, so     my home directory's a bit messy, I have a few projects here and there,    and I haven't been real prissy about which account I use to download    general things like cartoons (Hi      Shane !)   or new kernel sources into.  Usually I remember to move them to   someplace under /usr/src eventually.    As Piglet was fond of saying, ""Whatta... whatta mess.""    Surely it would have been easier for me if I hadn't decided to buy an    extra hard disk at the same time, discovered that my floppy bay stopped    working (p.s. can't boot from my CD.  Something to do with it being a SCSI    device in an IDE system), and (eek!) was reminded that we'd like to get    the column fragments in early this month.    Of course, I was able to abuse about a CD's worth of free disk space to    cover for this. I made the extra hard disk a feature rather than more    trouble by installing the new setup solely to it.    The install went fine, but it wasn't completely smooth.  Here's a few hints if you're plotting an upgrade, and I promise, they don't depend on you using SuSE:      Decide how much stuff you're going to put on there  before   you lay out your partitions, so you have enough.   I ended up experimenting with  parted  after I foolishly    made  /usr  a bit small (Hint: 2 Gb is  not  big enough.      What was I  thinking ?  Oh yeah.  My old drive didn't use Gnome and K    desktop.  Now they're par for the course.  Heh.)   parted  works    great so far, provided you've had prior training with the ""Towers of    Hanoi"" game first.  It can resize partitions, and it can move them, but    it can't slide them forward.  I had this great wooden Hanoi game when    I was a kid, and while I was juggling partitions I could almost hear the    wooden clicks and swaps in my head.      Check that you're going to be able to use the same account   numbers.   This is more of a biggie if you're completely changing distros, but     it still applies.  If you've created ""system level"" accounts for a     database or something, and it wasn't a package designed for your     distro, you may discover that something else expects to use that number      now.  Whether you move your own, or decide to do something about the     interloper, things aren't going to work right until it's fixed.     If you can't, and you're restoring accounts from a tarball, then  just make sure you have the user and group accounts you need  already assigned to their new numbers before you restore.  Then   tar  will deal with the number change for you.      While we're talking about version numbers, check that config files     haven't completely changed style during the upgrade.   If they have, you probably cannot just drop the old ones back in     safely at all.  In this category, I got off light... maybe because     I'd already gone and upgraded a few things on my own.      If it's in the retail channel, it's out of date -- get your security     patches.   The new version of YaST makes this easier, but I also had a few things     of my own to add to the security plan.     Beyond these normal things, I really needed to get some of these projects    into directories of their own, so it's clear where I should put stuff for    those things from now on.  Rather like ordering the teenager to clean up    their room...    Next thing I know the end of the month is approaching, and my dreams of     handling TAG at a dreamy summertime pace are dashed again       I still think backups are your friend, but at least I didn't need 'em    this time.  All I need is more RAM and I'm set!  The weather is     improving and I'm having a great time.  So here's those answers --    share and enjoy.            help installing telnetd     From dtrott      Answered By Ben Okopnik          Hi  I have recently installed debian 2.2, i was just wonderin if someone had a link or could suggest where i might find some basic instructions on setting up telnetd.     [Ben] <Warning! Opinion time!> I can give you a one-word instruction manual:     Don't.     Telnet is insecure, and its capabilities are seriously limited by comparison with SSH. Install ssh/sshd, and create an executable file in your  /etc/init.d/  directory called ""sshd"" with the following content:    See attached  sshd init script    Now, create a symlink in your  /etc/rc2.d/:      ln -s /etc/init.d/sshd /etc/rc2.d/S20sshd     The ""S20"" part says to 'S'tart the service (rather than 'K'illing it); the '20' places it (on my system, at least - take a look at your own ""rc2.d"" and number it appropriately) just after the link to ""inetd"". The position of the link is not all that critical; next to ""inetd"" (which starts other network services) seems appropriate, though. If you want to run the server immediately after doing this, but don't want to reboot, simply type     sshd     at the command prompt.     That's it. Just type 'ssh' where you would usually type 'telnet'. Oh, and make sure to at least skim the 'ssh' and 'sshd' man pages; this will make you aware of the many options that are available with this protocol.     I have not researched SSH in great depth, by the way; ""kill telnet"" is sorta common wisdom at this point, and I've read just enough to agree with it. After using telnet for a number of years, I find that I'm very pleased by the configurability of SSH; that alone, security aspects aside, made it worth switching for me. It would be nice if the other TAG members chimed in with their take on the proper usage and better reasons, but I'm highly satisfied with my installation.              touch files recursively linux mandrake 7.2     From  Martin Colello       Answered By Ben Okopnik      This is probably so easy as to be considered a joke, but I can't figure out how to do it.     I need to touch a bunch of directories recursively.  All the directories and their contents, but I can't find any option in the touch command that allows this.     Any help appreciated, thanks!     [Ben] I've never seen a 'recurse' option in any ""touch"" I've used. Doesn't mean that one doesn't exist, though. Since yours doesn't, try this:     find DIR -exec touch {} \;     where DIR is either the path to the top directory that contains all the subdirectories you want to touch, OR is a list of the paths to those subdirectories themselves. One of those two options should do what you want. If you want to touch only the files (not the directories), add the '-type f' option before '-exec'.     It can also be a healthy idea to try it with ""echo"" instead of ""touch"" the first time; I test a lot of my ""dangerous"" scripts that way before letting them loose on live data.      [Mike] Or:     find DIR | xargs touch      Hi, just wanted to let you know the command worked great, I never thought of using any other argument with find except -name.     [Ben] ""find"" is a  very  cool utility. The man page is pretty big, but it's well worth reading up on. Lots and lots of good options.     Linux Gazette rocks, thanks a lot for your help.     [Ben] Yeah, we know.        You're welcome!     Just out of curiosity, the reason I needed to touch everything was because my anonymous ftp server wouldn't show certain files even though the permissions were the same as others that worked.  But I found if I touched one then it showed up.  Now they all show up thanks to you, by why should this have happened in the first place?     [Ben] I haven't experienced any problems with setting up FTP servers, so I can't really comment.     [Heather] Readers, if you think you know what it might have been, let us know. You can reach The Answer Gang as  linux-questions-only@ssc.com .             Winprinters    From jzaragoza alberich      Answered By Mike Orr, Heather Stern     I know what a winmodem is. I know too that they must be thrown off. All of them. But what is a winprinter? How can they be recognized? Must they be thrown off too? Or do they work under Linux?     [Mike] Beware of any hardware that lists only Windows operating systems on the box.  If it says ""Windows and Macintosh"", there's a good chance it will work with Linux too.  But if it lists only Windows 95/98/2000, NT and Me, be suspicious.  It could be like a Winmodem, where vital parts of the modem functionality are missing in the modem and must be emulated by the driver. or it could mean there's Windows-specific code  in the printer .  For instance, instead of using a standard page-description language like PCL or Postscript, the printer may be tied to the Windows printing system directly (e.g., it may communicate with the computer via Windows API calls).     [Heather] A winprinter (like a winmodem) does not have complete printer brains. It uses WIndows GDI calls to preprocess a buffer with the printable image and then just accepts it straight.  If I read the original description right.  Anyways like a winmodem it rally hits CPU when trying to get work done.     Under Windows that means the driver is really tiny, since GDI is part of the default DLLs that make the rest of the GUI work.     Under Linux that means if it's a Lexmark you can convince it to work, and if it's something else, you  could  try the Lexmark winprinter  drivers ... and if they don't work, oh well, give that to someone who only  uses windows and needs a cheap printer.     Under a debian system you can use the package lexmark7000linux. For others you should try  Henryk Paluch's website:  http://bimbo.fjfi.cvut.cz/~paluch/l7kdriver      [Mike] Combined printer/fax/copier/scanners should especially be avoided unless you know that model works with Linux.     [Heather] It turns out there's a really great site that keeps track of all sorts of things about printing under linux.  Wouldn't you guess, it's:  http://www.linuxprinting.org       Thank you very much. You are very kind. Of course it will be an honor to get into your magazine. Perhaps would you find it interesting to talk about other ""winsoftware"": scanners, digital photography devices, joysticks, etc.             Search and Replace Without Breaking Permissions     From  Peagler Kelley       Answered By Ben Okopnik        Hi,     I am doing a global search and replace on some files via a unix script. I use the sed command (saving a copy of the original in $file.old) like so:     sed ""s/$INPUT_TXT/$OUTPUT_TXT/g"" $file > $NEW_FILE     Then I perform a diff on the original file ($file) and the new file ($NEW_FILE) and redirect the output to  /dev/null . If there is a difference between the two files, then I move the new file to the old file. Unfortunately I end up changing the permissions on all the files in the directory, depending on whatever default umask is set. Is there a way that I can either 1) find out what the permissions of the original file are and change them accordingly to the new file, or 2) move the new file to the original file while keeping the permissions of the old file?? Please let me know. Thanks!!     [Ben] ""sed"" is not the best tool for ""in-place editing"" of the kind you want to do - all you really want is to change the data in the file, right? Perl offers a solution that reduces it from a three-step process (change/diff/move) to one:     perl -i -wpe 's/$INPUT_TXT/$OUTPUT_TXT/g' $file     That's it. The editing is done in the file itself; the permissions are unchanged. No muss, no fuss, no greasy aftertaste.         I agree with you. I wanted to use perl, but the person who I'm creating this for does not know perl and will be responsible for supporting it. I like your quick, dirty solution and I may force them to use it just because it's easier   . Thanks!             Kernel Panic after putting disk back     From hma      Answered By Heather Stern           Hi,     I like to thank u guys for great job. Am still going thru your past issues. I have sent 2 questions here and I have not heard anything from u guys.. is my pattern wrong?     [Heather] 1. We can't reply to every message.  There are hundreds and hundreds of them every month.  That you received no reply before is not a personal slight. We will never get to all of them.  Just continue to look for whether someone else's answers apply to your questions too.     2. You had no subject this time - that usually doesn't help. For good behavior patterns that help your message get seen, see the TAG entry ""Creed of the Querent"" a few issues ago:  http://www.linuxgazette.com/issue62/tag/5.html      I still have the following problem and I hope U can help now...The problem am having is that when I boot to my linux I recieve the following message: "" Vfs: Kernel panic"" and that it. It doesn't go.     [Heather] This message means the kernel loaded, then could not find what it's looking for next.  VFS means virtual file system - that's what really manages all of Linux' filesystem drivers - it probably can't find the root fs.  Although usually if that's the problem it says so.  Odd.     When I try doing fsck, I get command not found.     [Heather] You're doing fsck from where?  fsck is a linux utility, so you need to come up from a linux rescue disk of some sort.  Toms Root Boot perhaps - handy because you can download and create one using DOS if you have to:  http://www.toms.net/rb      There are Windows utilities for accessing ext2 volumes, but they won't directly help you get back into Linux, and I don't know of a Windows based ext2 analogue to Scandisk.     The problem started when I remove one of my harddisk and after puting it back, I got this problem. But I get into win when I select it.     [Heather] When you select Win from what?  Have you replaced LILO with something else? (LILO doesn't normally have a selector, it makes you type things.  Of course you could have Storm Linux, which replaced the boot: prompt with a cool selector screen.)  Did you move any partitions before you put the drive back? Is the drive now your second drive?     To fix LILO:       Boot from that rescue disk   mount up the  /  volume on some empty directory ...  /mnt   would do nicely ...   don't forget to tell it to use ext2, example:   mount -t ext2 /dev/hda5 /mnt    cd into the mountpoint and run chroot   edit your  /etc/lilo.conf  so it mentions your new volumes... and   points at the right volume as your root partition now! For example, if it's now the second drive, than all your references to  /dev/hda  have to  refer to  /dev/hdb , except for ""boot"" (which says where to put the  LILO first stage)   (If it has become the second drive) you'll also want to edit   /etc/fstab , since all its drive references are off, too.  Otherwise you'll get a failure in the next stage when Linux really spins up.   Run  /sbin/lilo  to put your bootloader back together. Or else fix your new bootloader so it passes good options to your linux kernel - I think NT needs a copy of a (correct) LILO bootsector for its mechanism, in a tiny little file.   In short, LILO hates it when you move stuff around.  Sorry.     I hope u reply now.     [Heather] My inbox load today was light and I'm in a crossplatform mood, so you got lucky.  Usually I leave LILO matters for the rest of the Gang.     Thanks.  Hassan     [Heather] Have a happier day     ... I merged answers about his chroot troubles into the steps above ...     Once again, thanx and keep up the good work...some day when I become a guru, I hope to help too...       Hassan     [Heather] When you feel ready, I'm pretty sure the Gang will still be here to welcome you aboard!             Procmail and regular expressions....(Snowwhite...)     From Andrew Higgs        Answered By Ben Okopnik, Mike Orr, Faber Fedor      Hi all,     While on the subject....any suggestions on a good place to find out about regular expressions and procmail.     I collect mail from one ISP mailbox and send it on to the correct user based on email address. I also have a problem with people who use mailing list groups in Outlook etc. How do  I split these properly?     Any pointers gratiously accepted.     [Ben] ""procmail"" uses extended regexes, much the same as ""egrep"". So, for some good examples and broad-scope explanations of those, try    man procmailex man procmailrc man grep         # The ""REGULAR EXPRESSIONS"" section is a great reference man regex        # Somewhat different ""flavor"", but useful     For single address to multiple local user resolution, read the ""Email Addressing FAQ (How to use user+box@host addresses)"" at  www.faqs.org/faqs/mail/addressing/  - as it happens, I just ran into this thing yesterday, and was much impressed with the logical style and layout of it. Even if this is not  exactly  what you're doing, there are a number of relevant useful techniques described in this document - and it's mostly based on doing it with ""procmail"".      [Mike] Ben!  You even wrote the article about procmail antispam filtering and you didn't mention it.     Just in case Andrew hasn't seen it:      http://www.linuxgazette.com/issue62/okopnik.html       [Faber] Let me through out this little tidbit:     If you use the \< and \> word boundary markers in procmail, keep in mind that they consume (eat) the word boundary.  Every other program I've used the word boundary markers on did  not  eat them.     Makes a BIG difference when your grepping your text (and took me an hour to figure out!).     Regards,  Faber Fedor             Timely Samba Release?     From Andrew     Answered By Andrew Higgs, Jim Dennis         Hello,     I swear that the hardest thing to setup under Linux (at least for me ) has been samba. Running Linux RedHat 6.1 & have a windows 98 se machine. I see the Linux machine when i go into Network Neighbourhood & when i click on it i get the password box but it ALWAYS fails. The message i am getting at the moment is this      [2001/04/08 04:02:05, 0] smbd/server.c:sig_hup(340)    Got SIGHUP  [2001/04/09 00:18:04, 0] smbd/password.c:domain_client_validate(1213)    domain_client_validate: no challenge done - password failed  [2001/04/09 00:18:05, 0] smbd/password.c:domain_client_validate(1213)    domain_client_validate: no challenge done - password failed  [2001/04/09 00:18:09, 0] smbd/password.c:domain_client_validate(1213)    domain_client_validate: no challenge done - password failed  [2001/04/09 00:18:10, 0] smbd/password.c:domain_client_validate(1213)    domain_client_validate: no challenge done - password failed     What i would truley like is to setup Linux as a domain controller so when booting the windows machine validation is done via the Linux machine by verifying against the password file or smbpasswd file & so then u have access to shares at that point. Does it have to be WinNT to get this to work. I know their is the issue with encrypted passwords. Currently my Linux machine is set to yes Regards...     Andrew     [Andrew Higgs] Hi Andrew,     It is very possible to have Win 95 and 98 logon to a Samba domain. I assume you have read the relevant docs which come with Samba.     Have you added a Samba user to correspond with the one (your windows username) you are trying to use. It seems to me that it is failing because the username (and consequently the password) is not there. Try 'smbpasswd -a username' also 'man smbpasswd' for further details. Also bear in mind that Win 95 (and I assume 98) don't let you specify a username when trying to login to the Samba server, they just use your windows username.     I hope this is sorts out your problem.     Kind regards  Andrew Higgs     [JimD] I was just reading about the Samba 2.2.0 release at  http://www.samba.org/samba/samba.html .  The Samba team is continuing to strive towards full domain controller and ""MS Active Directory"" functionality.  You should look at the new release and read every shred of documentation.  Linux/Samba as a domain controller is still cutting edge (sometimes brushing against the cutting edge leaves us dripping a bit of blood).     You'll especially want to read the PDC HOWTO documentation at your nearest mirror of the Samba web site:  http://www.samba.org  Just follow the ""Documentation"" link and look for the FAQs and HOWTOs under the ""New PDC Documentation"" heading.     There are Samba mailing lists and discussion of Samba predominates the discussion on the news:comp.protocols.smb newsgroup.  If you have a connection to a good NNTP server you can post your questions to a forum where hundreds of Samba users and specialists can see it.     Also, no tech support suggestions for Samba would be complete if we didn't point you to the Samba DIAGNOSIS guide.  You can see that at:  http://WWW.samba.org/samba/docs/DIAGNOSIS.html  (where WWW can be www or the names of one of the many samba mirrors).             3d linux     From Philippe CABAL      Answered By Michael J. Hammel      hi     [The Graphics Muse] Howdy.     i am looking for a free multiplateform (win32 + unix) 3d modeling  /  rendering  /  animating software all i found is povray and blender     [The Graphics Muse] That's about it.     but id like a software as open as pov (data souces) as intuitive as a blender     [The Graphics Muse] No such beast.     actually i am a proggramer so i need to have a look at the scene-source isnt there a vrml stuff that do broadcast output ?     [The Graphics Muse] Nope.  You have a few choices, but nothing that fits all your desires here.     If you want VRML, you can try SCED or SCEDA.  Both have pretty primitive interfaces, but are fairly sophisticated underneath.  They include a constraint-based mechanism.  The source is available.  They are the only ones I know of that produce VRML output.     Outside of these two, all the other tools do not provide source:  Blender, Houdini, Maya, etc.  Blender is by far the least expensive but the most sophisticated for the money.  Houdini and Maya are high end, high dollar products.  POVRay is just a rendering engine, not an interactive modelling tool.  A better option for rendering is probably BMRT, the Blue Moon Rendering Tools, which is a Renderman compliant renderer.  It was actually used for several movies.  However, like POVRay, it is just a rendering engine, not an interactive modeller.     Nothing is available on Linux for free and with source provided that can do broadcast output.  You have to string together a few different tools in order to do that - for example Blender for modelling, something else to convert Blender files to RIB files (it doesn't do RIB yet), and then BMRT for rendering.     Blender is really the best thing going in this department, since you can add scripting to it fairly well using Python.  It's interface is production quality.  It just doesn't export to formats that can be used by other rendering engines, like RIB for PRMan (Pixar's rendering engine) or BMRT.     As for cross platform, give it up.  Blender I think is cross platform. POVRay doesn't much care where it's ported to and I believe BMRT has been ported to Windows (much to the consternation of the original author, no doubt).  But cross platform graphics tools are pretty difficult to do since such tools are often very happy close to the hardware, and getting close to the hardware on different OS's is not quite so easy a proposition.     Hope that helps.             linux vectoring synergy     From  darrell rolstone      Answered By Ben Okopnik       Dear Staff of the Answer Gang!     I hope you folks appreciate the occasional question from a non-techie....whose really into seeing and helping the information revolution FLOURISH!     I'm a 52 year old ""synergy design consultant"" from Marin County California....living in Thailand for the last 6 plus years. I was a pioneer in the Wholistic Health movement of the 70's and a student of R.Buckminister Fuller. I'm a world class Nordic Physical Therapist.....and I have trouble with even the simplest technological things like copying something onto a disk! REALLY!     [Ben] <laugh> The two are not necessarily related... but say on.     But inspite of nearly total techno ignorance.....I'm quite skilled in the social aspects of the techno evolution/revolution! And I sincerely want to help that process along it's path.     So, my question('s) to you guru's of ""geekness""....just what is being done in the area of co-ordinating all the linux ""programing development"" that is manifesting? Is there a ""co-operative"" formed? Can a (traditionally ""left-brained"" dominant) programer offer up his/her work to a linux ""group of (traditionally right-brained dominant)marketers"" that will then  take over and bring his/her work to fruition?! (thereby ""sharing the knowledge"" at a higher level of efficiency).     If there is such a ""group""......can you direct me to them? Praises upon you all for sharing your knowledge! Really!     [Ben] Well, Darrell...  that's  a heck of a question to ask of a bunch of traditionally left-brained computer types. <smile> Actually, if you're a student of revolutionary processes, you may find Linux  very  interesting for just that reason.     The Linux kernel itself - as wonderful of a thing as it is - is not (from my perspective) the thing that is responsible for the popularity and the tremendous growth of Linux. What is responsible for it is the Linux/Open Source  model  - that of people working on their own, or with a team, and getting full recognition for their work. The traditional hurdle of marketing a product is largely eliminated, since the greatest majority of the programs for Linux are free; the ""distribution channel"" - the Internet - is also mostly free (the costs are not assignable to Linux, so it is free in this regard.) In those terms, the marketing model for Linux and its software is not the traditional ""push"" - we have no need to stuff it down the gullets of barely willing customers - it is ""pull"": when people need a piece of software, they research it, download it, and install it. As well, the ""feedback loop"" that is usually set up between the programmer and the interested users of the program is a tremendously powerful tool: if fifty thousand people have pounded on your program for a few months, and the flow of bug reports has finally ground to a halt, either that program is as perfect as code can be, or it has simply been cowed into submission.        The effect of this is exactly what Robert Pirsig talked about in his ""Zen and the Art of Motorcycle Maintenance"" (I would guess that you're familiar with the work) - a shift toward Quality being the focus. That, to me, is the most exciting thing about Linux: quality really  is  ""Job #1"".     As to co-operatives... well, have you ever tried herding cats?    There are several things that have worked well in the Open Source community, usually by providing maximum assistance and convenience but minimum direction: any of the large-scale programming projects, such as  WINE , Mozilla, the whole series of GNU projects,  KDE , etc. There is also SourceForge, which provides an archive/code repository/distribution point for development efforts.     I'm not sure if this is any kind of an answer that you were looking for; mostly, these are just the ramblings of a right-brained guy who loves using his creativity in a left-brained way. <chuckle> I think that dichotomy was a no-starter, for me; never could see it...               Why Linux for routing     From Ian Carr-de Avelon      Answered By Mike Orr     In LG#65 I read:  ""Another thing this article does is raise the question, just because we can use Linux in a wide variety of routing situations, should we? Are you choosing a Linux router because it's the most appropriate solution for the task, or simply because ""we're a Linux-only shop""?    ""     Well... What are the choices? Basicly:      CISCO - expensive and involving commands which are unrelated to any other other task you do.    Also ran dedicated routers - less expensive but an ever changing sea of this month's best offer leaving you with a different web based configuration on virtually every router you will buy and if an interface card blows, they don't make them any more. If the system ever gets hacked - they don't provide updates, it is obsolete.   DOS based old PC - cheap but involving commands which are unrelated to any other other task you do. If an interface card blows, it is the same as every PC in your office and local PC store.   Linux based old PC - cheap and allowing you to use the same shell, editor etc which you use for every other computing task (assuming you are Linux based). If an interface card blows, it is the same as every PC in your office and local PC store.     The Linux option has a lot going for it especially if you are an organisation which does not have a team only dedicated to routers, like large telcos do. Routing sits causing no problems for months, while you forget how to work on the router, and then when problems arrive it is panic stations, because nobody can work, clients are not being served and business is being lost. I run a Polish ISP with Linux and one CISCO router, which we bought because I was over ruled, because although the WAN card for Linux was cheaper, the CISCO dealer offered unbeatable financing. I don't see that changing soon.     Yours  Ian     [Mike] You bring up some good points, but that does not invalidate the question. I'm not saying Linux *shouldn't* be used for routing, just that each organization needs to weigh the price-vs-performance-vs-maintainability factors for iteself.  The situation I was thinking about (and perhaps it wasn't clear in the paragraph) was not a small, low-traffic network, for which Linux's price and maintainability certainly runs circles over proprietary systems, but rather an an enterprise-level, high-traffic situation.  Is there an amount of thoroughput above which Linux routers are not (currently) scalable, a point at which Ciscos would be more economical?  I don't know, but a netadmin in that situation would want to explore both options before making a decision.     My point is not so much about Linux vs Cisco, but about jumping on the Linux bandwagon too quickly.  We all know hundreds of companies that refused to consider any alternatives to buying NT servers, WINS servers, Novell servers, etc.  The same can happen in the Linux world, if one refuses to consider an alternative to a Linux router more because it's politically incorrect than because of an actual comparision of price, performance and maintainability and how they would all affect your organization in its situation.             disappearing act     From eric lin       Answered By Ben Okopnik      Hello Answer Gang,     Let me start off by thanking all of you for providing such excellent service.     I'm running RedHat 6.2 with apache 1.3.9 and Sendmail 8.9.3 as an Internal web/mail server. I use it on a daily basis, but haven't changed any of the configurations since the initial install. Yet mysteriously the httpd.conf and the sendmail.conf files becomes null (file size of 0)!!!  This occurs randomly and usually after a reboot of the system.     Since it is internal and no one uses it except for myself, I have no way of explaining why this is.     Do you guys have any ideas???     [Ben] Wow. That's odd.  Very  odd. It sounds like maybe some sort of a config file backup procedure (?) gone wrong. One of the first things I'd do is switch to "" /etc/init.d "" and grep the scripts there for any mention of the above files. I'd investigate anything I found with a  very  sceptical eye, possibly looking for evidence of intrusion (I can see some script kiddie being very interested in those two files...) or just a badly-written script.     If you can't find anything, try setting the immutable attribute on those files via "" chattr "" (see the manpage); this should at least stop them from ""disappearing"". I, for one, would be  very  interested to know what you find out in your troubleshooting process.                 getting 2 dynamic ip addresses     From Christi Gell     Answered By Mike Orr     I have a DSL and I want to get 2 dynamic IP addresses w/it.  I've got a hub, but every time my husband needs to get online, I need to release my IP address.     [Mike] Your hub is connected directly to the DSL modem?  In that case, you will have to contact your ISP to get a second dynamic address from them... if you can.     A more common scenario is to have one computer (the server) connected to the modem and also to the hub.  The second computer is connected only to the hub. The first computer has IP firewalling and IP masquerading compiled into the kernel.  (I assume you're running Linux, since you sent this to a Linux answer forum.  If you're using Windows, you'll have to go somewhere else for help.) Then you enable IP masquerading on the server.  Now the second computer can reach the Internet without needing a second dynamic IP from the ISP.     To set this up, search for ""masquerading"" or ""masquerade"" in the Linux Gazette search engine ( www.linuxgazette.com/search.html ).  Or pick up a Linux configuration book from the bookstore or look in the manual that came with your distribution.          More 2¢ Tips!       Send Linux Tips and Tricks to  gazette@ssc.com       Easy LG browsing 2 cent tip   vim hot color swapping   linux version of dos commands   Booting w/ CD-ROM   dvi and Deskjet   how to find an i/o adress for an specific pci slot   Pam.d questions   Finding my computer at home from the outside LG #65                 Easy LG browsing 2 cent tip  Fri, 20 Apr 2001 20:31:35 +1000 (EST)  bandido ( bandido from drinkordie.com )    This handy dandy function is courtasy of Cobratek on  #Mandrake   on Efnet, it is super kewl, since you can unpack all your LG issues (you  do have all 65 don't you?) and instanty view any one.     Simply add this function to either  ~/.bashrc  or better yet   /etc/bashrc  so everyone on your system can read LG.     function lg () { lynx /home/bandido/docs/Linux.Gazette/$1/index.html ; }     Remember to change path to whatever you unpack your LG issues to, and do not use  ~/  dirname of course if you put the function in   /etc/bashrc         Personally I unpack all issues like this,      /home/bandido/doc/Linux.Gazette/1  /home/bandido/doc/Linux.Gazette/2   3 4 5  etc     Thus, I type lg 20 or lg 35 etc, to open 20 or 35 instanlty in lynx, and I am in prior dir when I exit. Nice and handy, never far away from LG    Feel feel to drop by  #Mandrake  on Efnet too, unlike most linux  channeols, newbies are very much welcome.                 vim hot color swapping  Thu, 19 Apr 2001 07:37:04 -0700  Adam Monsen ( meonkeys from hotmail.com )     Vim's syntax highlighting can be helpful at times at painful at other times. Add this to your  .vimrc  and you can turn colors on and off with  the tap of a button.      "" map F8 to switch on and off syntax highlighting   function Swapcolor()     if exists(""g:syntax_on"")       syntax off       set nohlsearch     else       syntax on       set hlsearch     endif   endfunction   map <F8> :call Swapcolor()<CR>                 linux version of dos commands  Sun, 01 Apr 2001 15:06:34 -0700  Steve Winston ( xee from mediaone.net )    They start with letter ""m."" They look at a floppy disk as ""a:"" or ""a:\"" as Windoze does.  To copy one file to another, use ""mcopy""  If you want to copy a file ""myfile"" from  a:   to your home directory, use this command:     mcopy a:\myfile /home    If you want to copy myfile from  /home  to  a:  use this  command:   mcopy /home/myfile a     To check the contents of a file or directory, use mdir.  To check the contents of a:     mdir a:     Hope that helps a little bit,  stevew                 Booting w/ CD-ROM  Tue, 17 Apr 2001 23:38:57 -0400  joseph.lalingo ( joseph.lalingo from ablelink.org )  Tip from Daniel S. Washko    Hello,     How can I use CFDISK from my REDHAT CD-ROM as though it was from a hard drive linux installation?     If this is during the install process, I am pretty sure you could hit <ctrl><alt><f1-?> to switch to another terminal.  Keep cycling through the keys until you find a free terminal.  You should then be able to use cfdisk.     -- Daniel                     dvi and Deskjet  Sat, 14 Apr 2001 09:55:53 -0400  C. Martinet ( email from cmarti.net )  Tip from Ben Okopnik    Dear answer guy,     I would like to print a dvi file on an HP600 deskjet printer. Is it possible ? I've tried with the commands dvilj, dvilj2p, dvilj4 and dvil4l, but there are all for LaserJet printers. So I have some strange results.     Have you tried ""dvihp""? It's supposed to convert DVIs to HP PCL (Printer Control Language.) Or, you could always just run ""dvips"" - it'll produce a PostScript file that you should be able to print without any problems.  -- Ben                  how to find an i/o adress for an specific pci slot  Thu, 29 Mar 2001 09:35:37 -0800  Christer Olsen ( christer.olsen from cegal.com )  Tip from Mike Orr    i need to find out the slot adress for my pci network card , how can i easily track down this     my network card is in slot 1 and i need to find out the adress (0x0081 or ???)     Does it say in the boot messages?  Run ""dmesg | less"" to see your boot messages again.  If you don't find the right information, please send us back a copy of your boot messages (in particular, the portions beginning with ""PCI: "" and anything that looks like it may be related to the network card).     Each PCI slot corresponds to a fixed address.  Perhaps looking in  include/linux/pci.h  or  drivers/pci/pci.c   in the kernel source would help.   -- Mike                Pam.d questions  Tue, 3 Apr 2001 15:11:42 +1000  andrew ( andrewkennedy from optusnet.com.au )  Tips from Faber Fedor, Ben Okopnik, and Heather Stern    Back for more of your knowledge     And we're still here dishing it out!     I have an authlog file & i keep seeing this info within it     Apr  3 11:31:58 echelon pam_limits[27640]: invalid line 'hard^Icore^I0' Apr  3 11:31:58 echelon pam_limits[27640]: invalid line 'soft^Inproc^I100' Apr  3 11:31:58 echelon pam_limits[27640]: invalid line 'hard^Inproc^I150' Apr  3 11:31:58 echelon pam_limits[27640]: invalid line 'hard^Ifsize^I40000'     Pam was installed via an RPM & seems to be working fine within everything else.     I would just like to fix this area of it if possible     Check your  /etc/security/limits.conf  file.  It seems PAM doesn't like it. Why?  I don't know, but I checked my limits.conf file and my columns were separated by spaces, not tabs.     If you do a  cat -v -t -e /etc/security/limits.conf , you'll see tabs as  ^I  and eon-oflines as  $ . -- Faber     Just to be nitpicky,  cat -A  is a combination of those options. -- Ben      cat -T  is enough to see the dratted tabs as  ^I  but stray spaces at the end of the line still won't be obvious.  -- Heather                 Finding my computer at home from the outside LG #65  Wed, 11 Apr 2001 11:17:02 -0400  Ben Walton ( bdwalton from mail.lakeheadu.ca )    Hi there Linux Gazette Team!     I was browsing through LG today, and came across the article 'Finding my computer at home from the outside'.  This is a topic that interests me, as I like to be able to access my home machine from school.  Although technically accurate, I found that writing these scripts is an extremely cumbersome way to do the job.  (Not to mention that passwordless logins (secure tunnel or no) are just plain bad form...).  I'm not writing this email to complain (you guys do too much good work), but rather to inform!     If you're in a situation like me, and you either can't get (or can't afford) a static IP on broadband, there is a much simpler solution.    http://www.dyndns.org .  A free service (they DO accept donations), DynDNS allows you to register a hostname (within one of their domains...for now), and run a client to update with them each time your IP changes.  After registering with DynDNS, you can download a little client utility (I prefer ipcheck.py), and have it run from your  /etc/ppp/ip-up  script (I'm on DSL, so my connection is still PPP)...which is run every time that your IP changes.     I've found the service to be most valuable.     Thanks  -Ben Walton             ""Linux Gazette... making Linux just a little more fun! ""                 The Weekend Mechanic   By  Thomas Adam                    Welcome to the new Linux Weekend Mechanic!    Table of Contents       What exactly is the Weekend Mechanic?     Customising the shell environment     Setting up and using crontab     Closing Time             What exactly is the Weekend Mechanic?    Welcome to this months new feature.... The Weekend Mechanic . Actually, for those of you who have been avid readers since LG's initial release, you'll realise that this column used to be written by John M Fisk in 1996-1998 and so it is not that new. However, I thought it would be nice to re-introduce this as a regular feature.    The Weekend Mechanic will draw together my experiences of Linux and the problems that I have had to solve either at home or at school each month. So, The Weekend Mechanic will concentrate on the following:       General Linux News  Shell Programming  Shell Customisations  Sed, Awk, hints  Program Reviews  And anything else.....        So, with that in mind, lets begin this months fixing and tinkering session......         Customising the Shell Environment   I have noticed that more and more people when using Linux tend solely to rely on the GUI, hoping in vein that they do not have to type in any commands in fear of deleting their work, making a fatal mistake, etc. Although the only real threat of this happening is if you are logged in as ""root"", I find that people are still wary!! However, there will come a time regardless when typing in commands will be a necessity and it is important that your shell environment is customised so that you can complete your tasks with ease. This article will show you how to customise the login shell so that features such as  Aliases, editors, shells , etc can work in the way that you want them to.    Firstly, we should make sure that you have an appropriate editor installed. There are many console editors to choose from, such as: emacs, joe, jed, pico, vi. Once you have found an editor that you like (I happen to use both Pico and Jed) then you can tell the shell to use. Some programs such as Cron (as we shall see later on..) rely on the shell having an editor set up so that you can edit the crontab.    There are two files that we shall be concentrating on.  They are located in your home directory as:  .bashrc  and  .bash_profile . In my .bashrc file, I find that it begins with the following:   # User specific aliases and functions  alias ls='ls -o --color=auto' alias cad='cat /var/squidGuard/db/blacklist/adverts' alias cc='cd /mnt/cdrom/Mandrake/RPMS' alias mail='mail -v' alias rm='rm -i' alias cp='cp -i' alias mv='mv -i' alias d='ls' alias s='cd ..' alias p='cd -'    Aliases are useful, especially if you find yourself typing out a command that has a deep directory listing. For example, if you found yourself having to keep typing in the command  cd /var/spool/users/home/mail/root/sun to save all that typing you can specify a ""shortcut"" word that automatically does just that. Cool eh?   So to tell the shell that you want to use the word ""checkmail"" to do the command  cd /var/spool/users/home/mail/root/sun you would add to the list:   alias checkmail='cd /var/spool/users/home/mail/root/sun'  Then you could type the alias  checkmail  and hey presto....it works!!   Of course many people like to issue aliases to accommodate their typographical errors; i.e.,  alias eamcs='emacs' alias emcas='emacs'   Personally I think this is a bad idea, and you should learn to type more accurately!     The next section we shall look at is how to tell the shell which programs to run when it is suitable to run them. In my  .bash_profile  file I have among the following:   PATH=/sbin:/usr/sbin:/bin:/usr/bin:/usr/X11R6/bin ENV=$HOME/.bashrc USERNAME=""root"" export USERNAME ENV PATH    This is the section that we shall be concentrating upon setting these variables. Common variables that have not been set are ones like ""EDITOR"" and ""MAIL"". These variables are common to the user that is currently logged in, meaning that different values can be specifies for each user. The variable  EDITOR  specifies the editor to use when editing files. This variable is usually called from programs such as  Pine  and  Cron , but it can be very useful when writing shell scripts.   To set the variable, one has to add it to the ""export"" list, like this: export USERNAME ENV PATH EDITOR   Exporting a variable releases it into the environment, rather than keeping it within a single program. Exporting is done, so that many different programs can use the same variable name with the same value, get it :-).   Once added to the export list, save the file, and exit your editor. So, now that we have defined a new variable, the next thing to do is to tell Bash, that it is there. To do this, you must ""source"" the file. This is a bash builtin that re-reads the file. You can either type this in, in one of two ways. Either you can specify  source filename or you can specify a ""."" thus:   . filename   And that will then active your new added variable. Well, thats it for this section....         Setting up and Using Crontab   Do you ever find yourself repeating common tasks throughout the day, and wished that there was some sort of program that would automate it all for you? Well, look no further, Mr. Cron is here :-)   Cron is a scheduling program, and even more specifically it is known as a  daemon . By daemon, I do not mean that it is a nasty creature with two horns!! A daemon is simply a program that runs in the background waiting for instructions. When it receives them, it executes them and when it has finished, it goes dormant again.   Cron is usually started when you switch to one of your run-levels. However, just to make sure it has started, issue the following command:   ps ax | grep crond    If you get a response similar to:   root       311  0.0  0.7  1284  112 ?        S    Dec24   0:00 crond root       8606  4.0  2.6  1148  388 tty2     S    12:47   0:00 grep crond    Then cron has started, and you are ready to use it. If you don't get ""crond"" returned, then you must start the daemon, by typing  crond   Cron is particularly useful when you find yourself needing to run backup and general maintenance programs. To tell cron when to run a program, you have to fill out several fields. Each separate program that is scheduled via cron is put into a file known as a  crontab  file. The fields are defined as the following:   Min Hour DOM Month DOW User Cmd    And a description of their input values are summarized in the table below:     FIELD   DESCRIPTION     Min   Specifies the minute on or past the hour. Values range from 0 to 59.       Hour   Specifies the hour (Military style) that the script should run at. The range is from 0 to 23 where ""0"" is Midnight       DOM   This is the Day of Month, that you want the command run on, e.g. to run a command on the 23th of each month, the DOM would be 23       Month   Specifies the month to run the script in. Values range from 1 to 12, where ""1"" is January and ""12"" is December. Or it can be specified using the first three letters of the month, e.g. May       DOW   Specifies the day of the week, either as a numeric value of 0 to 7 (0 and 7 are both Sunday) or as the name of the week (using first three letters only), e.g. Mon     User   Indicates who is running the command       Cmd   The path and name of the script/program to be run       You can use a ""*"" (without the quotes) in any of the time fields to mean ""every minute"", ""every hour"", etc.  So, with the above descriptions in mind, the following examples are all valid:   01 * * * * root /usr/bin/script   ""This command is run at one min past every hour""  17 8 * * * root /bin/mail    ""This command is run daily at 8:17 am""  17 20 * * * root /usr/bin/fetch   ""This command is run daily at 8:17 pm""  00 4 * * 0 root /bin/qweb    ""This command is run at 4 am every Sunday""  * 4 * * Sun root /usr/bin/file2rpm   ""This command is run at 4 am every Sunday""  42 4 1 * * root /usr/bin/squidlog   ""This command is run 4:42 am every 1st of the month""  01 * 19 07 * root /usr/bin/xman   ""This command is run hourly on the 19th of July""     See how easy it is? :-).  Cron also accepts more sophisticated time  specifications: run ""man 5 crontab"" for an explanation of these.     Of course this is all very well, but I have not told you where to put any of your cron entries. So.........hang on there, reader.   The most common version of cron installed on linux systems is ""vixie-cron"", and so in the ""/etc"" folder should be a file called ""crontab"". If you have specified the environment variable EDITOR (see the above section) then you can simply type in:   crontab -e    And that will load the file into your text editor  If you did not open it using the above command, then open it using a text editor of your choice and you should find something that looks like the following   SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root@grangedairy.linux HOME=/  # run-parts 01 * * * * root run-parts /etc/cron.hourly 02 4 * * * root run-parts /etc/cron.daily 22 4 * * 0 root run-parts /etc/cron.weekly 42 4 1 * * root run-parts /etc/cron.monthly    The SHELL variable indicates the current shell that we are using   The PATH indicates the path to the most common programs   The MAILTO option indicates to whom the output of the cron result (i.e. whether it has worked or not) and any output from the program is to be mailed. If you find that it is annoying, then you can delete this variable.   The section below ""#runparts"" is supposed to work so that in the folder ""/etc/cron.daily"" for example, whatever script is in there gets executed daily. However, for some strange reason, it has never worked well for me, and I have since found it easier to specify my own cron list.    So, to add the above examples to our crontab, it is just a matter of  copying  and  pasting  them in:   SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root@grangedairy.linux HOME=/  # run-parts 01 * * * * root run-parts /etc/cron.hourly 02 4 * * * root run-parts /etc/cron.daily 22 4 * * 0 root run-parts /etc/cron.weekly 42 4 1 * * root run-parts /etc/cron.monthly  #Custom Crontabs -- Put in by Thomas Adam 01 * * * * root /usr/bin/script   17 8 * * * root /bin/mail 17 20 * * * root /usr/bin/fetch   00 4 * * 0 root /bin/qweb    * 4 * * Sun root /usr/bin/file2rpm   42 4 1 * * root /usr/bin/squidlog   01 * 19 07 * root /usr/bin/xman      Then save the file. Now the last thing we have to do is to tell cron that we have edited the file. That is done, with the following command:   crontab -u root /etc/crontab    And thats it...just sit back and wait..... You should find that by now your workload has diminished by about 25% or so!!!   Cron also has the ability of allowing and denying certain users who are allowed to use cron. To implement this, two files called  cron.allow  and  cron.deny  have to be created in the folder ""/etc"".   These files work in the following way. If for example you wanted nobody to have access to cron, then you would add the line ""ALL"" to the  cron.deny  file. If you wanted only certain people to use cron then you would add their username to the  cron.allow  file.   Rather than having to edit the file each time, I find it much easier to use the following command:   cat username >>/etc/cron.allow    Thats all there is to it....have a go and see what you think......!?!         Closing Time   Well folks, thats it for this month. I had hoped to do more, but unfortunately school work had intervened yet again!! I would really appreciate some feedback, general comments, hints as to articles, etc. Armed with this information I can then go about ""making linux just that little more fun"" :-)   I am now off to go and teach piano, do some Geography revision (yay) and then maybe continue working on some of my ongoing ""bash script projects"". After which, I might even be able to get some sleep. who knows?????   In the meantime however, I wish everyone.... ""happy Linuxing""       Send me comments....   Any comments, suggestions, ideas, etc can be mailed to me by clicking the e-mail address link below:   Thomas Adam                        Copyright © 2001, Thomas Adam.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 66 of  Linux Gazette , May 2001        ""Linux Gazette... making Linux just a little more fun! ""                 HelpDex   By  Shane Collinge                                    For those not into gaming, ""All your base are belong to us"", is a video-game slogan translated from the Japanese.  Read the  LA Times article , see the  history , or watch Clippy sing it on the  Microsoft site  (turn on Javascript and run the mouse back and forth over the links in the left column and watch what the Clippy image does, then click on the ""Click"" button several times).     [Too bad I can't listen to the song, ""It Looks Like You're Writing a  Letter"", since it's in Windows Media format.  I would just like to see  its parody version,   ""It Looks Like You're Writing a Suicide Note"" .  -Mike.]            I read the   overview  by Jason McIntosh about ComicsML over the weekend. There's a lot of sense in what he says: about the ability to define comics and to be able to search archives and automate processes. As an example, just last week I was searching for a specific Far Side and luckily the text had been reproduced within a HTML page so I was able to find it. Otherwise I could have been searching fruitlessly for weeks.    That said, as an artist myself the act of documenting artwork and standardizing it seems to demystify the process. Part of the magic of reading today ""Pearls Before Swine"" or ""Randolph Itch 2am"" is having to track it down and read it. Automating the process turns it into a kind of Shakespeare-via-Brodies-Notes. There is no shortcut to art. Add that to the technical fact that the time taken to draw a strip will now double - once for the art which we already draw and ink, then the marking up of the ComicsML after the fact, thinking of an appropriate teaser, typing the spoken text etc. Sheesh! Most cartoonists barely have enough attention span to brush their teeth,     [And run around chasing villains all day.  -Mike.]     let alone do all this house-keeping for each and every strip.    Art as revenue-raiser also requires that human intervention be present. When HelpDex was running on LinuxToday.com the filenames were randomized so automated scripts or robots COULDN'T simply pull down the pics every day. LT was paying for a service that would entice readers to their site, not robots. There's no incentive to sponsor a strip without being able to quantify the hits or business generated.    I sound harsh, but I'm not. ComicsML does look like a good idea being introduced at a good time. The new breed of cartoonist literate in new technologies such as the ones working in Flash and so on would pick this up quickly and once standardized, could help spread information much more rapidly than currently occurs. I feel from conventional artists such as myself there is bound to be a slow uptake as this simply adds more effort to setup than the benefit it would realise.    What am I trying to say? I think it's a tidy idea but I'm too darn lazy to implement it unless I can see a direct benefit from the extra effort required.           Shane Collinge  Part computer programmer, part cartoonist, part Mars Bar. At night, he runs around in a pair of colorful tights fighting criminals. During the day... well, he just runs around.  He eats when he's hungry and sleeps when he's sleepy.                                                            Copyright © 2001, Shane Collinge.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 66 of  Linux Gazette , May 2001        ""Linux Gazette... making Linux just a little more fun! ""                 Interview with Ben Collins, the new Debian Project Leader   By  Fernando Ribeiro Corrêa & Marcos Martins Manhães  Originally published at  OLinux                                    OLinux: First of all, tell us about your background.                          Ben Collins:         I am generally speaking a programmer and systems       administrator. In the past I have also worked as a Desktop       Publisher and a web designer. I've worked for NASA LaRC,       several ISPs and currently am working at         Winstar        .                    OLinux: Please give a brief summary of    Debian 's History, Philosophy         and Organization on handling free software development?                          Ben Collins:         Our philosophy goes back a long way. Mainly we believe that       it  is  possible to create a completely free operating system       with all of the things you need to do your daily work. That's       what started Debian, and prompted Ian Murdock to write the       Debian Manifesto. From there began our project, and from it       has come the Debian Free Software Guidelines (DFSG), which       defines the type of software licensing we consider to be Free       in the sense of Freedom. Also came the Debian Social       Contract, which defines what we will support for our users.       Later, as we grew, came our Constitution, which defines our       operating procedures, and breakdown of authority within the       project.          We've basically given full control of each package to the       maintainer of that package, so long as it falls within the       guidelines of our well defined Policy. Our Policy is one of       the strengths of the Debian distribution. Without it, we       would not have a cohesive set of packages, and       installs/upgrades would be a nightmare.                    OLinux: How excited you are about being in front of the         Debian Project? Do you have something in mind for the         Debian Project? Are you going to make changes on the way         the work is done?                          Ben Collins:         I'm extremely excited. This is my third run at the DPL       position, and it is a goal I have finally achieved thanks       completely to those in the project that have faith in my       ability to handle the job. I have plans to clean up some       loose ends that have been plaguing our internal organisation       for some time. After this, I plan to tackle some of the more       difficult situations that still linger, or are threatening to       be a problem in the near future.                    OLinux: What are going to be the differences between your         leadership and the predecessor's?                          Ben Collins:         When I first came to Debian, Ian Jackson was finishing his       term as DPL, and he was very inactive (to his defense, I do       not know any details of his situation). Wichert then followed       for two terms. I believe he did an excellent job keeping       Debian going. However, my plans are to get Debian moving       rather than continue to limp along with some of the problems       we face.                    OLinux: How are people organized and what are the tools         used to control the results of the work being done in         different projects and parts of the world?                          Ben Collins:         Within Debian, we have the maintainers (some 800 it seems       now). Each of them is responsible for maintaining one or more       packages (some do not maintain packages, but help with other       projects internally, such as ftp archive, www site, etc.).       They have complete control of their tasks within the       guidelines and policy. Within this, some developers have       grouped together to manage large specific tasks. Examples of       this are the Debian Junior project, as well as the ports (such       as sparc, arm, alapha, powerpc, etc.) and language       projects.          All work is coordinated via mailing lists. Some people       also use IRC as a way of immediate interaction (via       irc.openprojects.net). We also have the Debian Bug Tracking       System to manage bug reports for all of our packages and       systems. This system is available publicly via our web       pages. Anyone can file a bug, and track it's progress       directly with the maintainer.                    OLinux: How many people are working for Debian nowadays?         Are you satisfied with the results?                          Ben Collins:         Last I checked, about 800. I am satisfied with the results.       What I am not satisfied with is the influx of maintainers       without a better scheme to manage them. Work is being done,       but I want to see some other things in this area discussed       and looked at.                    OLinux: What do you think about people saying that the         Debian 2.2 has too much bugs? What are you going to do in         ""Woody"" to change this point of view?                          Ben Collins:         I was not aware that people said that. We have an excellent       security team that fixes all known security related bugs. We       also make regular point releases (2.2r3 is being worked on as       I write this) to update the security patches into a new       release. For woody we have a new ""testing"" mechanism which       should help reduce the amount of time needed to release.       Hopefully this will make more frequent releases possible.                    OLinux: What are your expectations about the ""Woody""         launch?                          Ben Collins:         I look forward to a lot of the things that are going to be       available in woody. Woody also promises to be the most       architectures we have ever released at one time (by any       distribution, that I am aware of).                    OLinux: What are the active projects at Debian? How are         they divided and coordinated in terms of content and staff         for each project?                          Ben Collins:         Usually a project within Debian creates itself to fill a       need. The project manages itself, and delegates within its       own ranks who is responsible for what tasks. I'm not aware       of all such projects, simply because most of them work in the       background, silently making Debian better.                    OLinux: Here, in Brazil, there is a project called                    Debian BR           . This is a project that is translating the Debian content         to Portuguese. Do you know that? If yes, what do you think         about it? If not, you are invited to visit the Debian BR         web site at debian-br.sourceforge.net. Do you know other         projects like this in other countries?                          Ben Collins:         I had not heard of it before. I think it is an excellent       thing, much like the JP and similar projects. The more people       we can get Debian to, the better. I'll have a look at the       web site, and I wish the best of luck to the project for it's       efforts.                    OLinux: Do you consider Debian the leading GNU/Linux         distribution in the world?                          Ben Collins:         On many basis, yes. However, I measure Debian on what's       important to me, and am well aware that it lacks in areas       that are important to others. A recurring topic is our       installer. I'm happy to report that a new modular installer       is being worked on, and it so far appears to exceed, or will       exceed, all of the goals that the group set for itself. It       will probably not be done in time for woody, though.                    OLinux: How is Debian's relationship with the GNOME         Foundation? And with the KDE league?                          Ben Collins:         I'm not able to answer this question. I do know that we have       some developers that work closely with both projects, and       that GNOME and KDE are both fully integrated within our       distribution.                    OLinux: What are the advantages and what differentiates         Debian from         other popular distributions as SuSE or Red Hat, besides being a  non-commercial distribution?                          Ben Collins:         I think we have three major strengths. One is our development       model. No other distribution has all of its developers       available first hand to take bug reports and suggestions from       its user base.          No other distribution has as extensive a set of policies       that allows it to distribute as many packages as we do, all       integrated into our distribution, with easy installation.          No other distribution offers the ease of upgrades that we       do. There have been reports of people being able to       effortlessly upgrade from as far back as Debian 1.3 (bo) to       the current stable 2.2 (potato) (note, this is a libc5 to       libc6 upgrade path). Debian not only supports, but guarantees       upgradability. It is one of our primary goals.                    OLinux: How do you describe Debian Project achievements         and what are the prospects and goals for the next         years?                          Ben Collins:         The fact that Debian is still around, and is still growing is       a major achievement. We have not lost site of our primary       goals; to produce a free and stable distribution. Over the       next few years I hope to see Debian prosper from commercial       acceptance via companies like Progeny. I'm hoping that       vendors will see us as a more viable solution for desktops       and pre-installed systems.                    OLinux: Give us some predictions about the growth of the         GNU/Linux operating system for the next 2, 5 and 10         years.                          Ben Collins:         That's hard to predict. Unfortunately, as free as it may be,       GNU/Linux is directly affected by the economy. The current       trend of Internet companies starting to fail, will likely       scare away of a lot of the venture capital that has flooded       Linux in the past years. Hopefully this will be a good thing,       and the Linux companies will have to start working to make       their money, and not ride the wave of hype. I would guess       that over the next 2 years, Linux's hype will settle down,       and people will start taking it more seriously (not just       those in-the-know).          In 5 years, I suspect that GNU/Linux will be as common as       MacOS, Solaris and Windows in the home. In 10 years, who       knows. That's like an eternity to the technical world, so       Linux may be obsolete by then.                    OLinux: What are the improvements that GNU/Linux needs         to be more deployed in by the corporate market?                          Ben Collins:         An accepted, easy to use interface. KDE and GNOME are working       toward this with great strides. But even with a good       interface, getting accepted and being ""common"" take far       longer than a development cycle.                    OLinux: Debian is definitely the best Linux distro, but         its hardware configuration interface and its installer are         not so friendly. Is the Debian Project going to focus on a         best interaction with the final user or it still a         distribution for the systems administrators only?                          Ben Collins:         Yes, the debian-installer group is working very hard on this.       We do not want to remain a niche distribution only used by       administrators and hard-core hackers.               Fernando Ribeiro Corr&eci;a  I am a computer analyst just about to finish my  graduation at Federal University of Rio de Janeiro. Now, I have built with my staff the best   Linux portal  in Brazil and have further  plans to improve services and content for our Internet users.       Marcos Martins Manhães  I'm a journalist graduated from UFRJ (Federal University of Rio de Janeiro). I'm 25 years old and have been working at OLinux for one year. I began studying mecanical engeneering, but I gave up during the second year. I've spent one year in Rockville (went to Montgomery College), Maryland, and traveled a lot around the USA (that was a great time).                 Copyright © 2001, Fernando Ribeiro Corrêa & Marcos Martins Manhães.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 66 of  Linux Gazette , May 2001        ""Linux Gazette... making Linux just a little more fun! ""                 Converting Linux HOWTOs into Book Format   By  Mark Nielsen                        Introduction   Perl script to convert the Postscript files      Conclusion     References         Introduction  I wanted to print out Linux HOWTOs into book format. However, I am not fond of manually converting the HOWTOs. Instead, since all the HOWTOs are available in Postscript format, I figured out that I could download the Postscript files on a regular basis and use various tools to convert the Postscript files into book formatted Postscript and PDF files. I accomplished this with a relatively small Perl script using a variety of Unix tools. I plan on  have a cron job run at least once a week to update the books.      Perl script to convert the Postscript files    The Perl script is in this section, and you can  also  get the Perl script here .   #!/usr/bin/perl  # ftp://ftp.tardis.ed.ac.uk/users/ajcd/psutils.tar.gz # http://www.dcs.ed.ac.uk/home/ajcd/psutils/  # cp Makefile.unix Makefile # ln -s /usr/bin/perl /usr/local/bin/perl # mkdir -p /usr/local/share/man/man1 # /usr/local/bin/psbook  #system (""lynx --source ftp://ftp.tardis.ed.ac.uk/users/ajcd/psutils.tar.gz > /tmp/psutils.tar.gz)""; # system (""cd /tmp; tar -zxvf psutils.tar.gz; cd psutils; cp Makefile.unix Makefile""); # system (""ln -s /usr/bin/perl /usr/local/bin/perl; mkdir -p /usr/local/share/man/man1""); # system (""cd /tmp/psutils; make; make install; ln -s /usr/local/bin/psutils /usr/bin/psutils"");  # Ignore the lines above, unless you don't have psutils.  # I keep the lines above just so I remember how I installed psutils.  my $TempFile1 = ""/tmp/HOWTO_Convert_1.ps""; my $TempFile2 = ""/tmp/HOWTO_Convert_1.pdf""; my $SourceDir = ""/root/HOWTO""; my $Destination = ""/root/HOWTO_Books""; my $ZippedPDF = ""/root/HOWTO_books_pdf.tgz""; my $ZippedPS = ""/root/HOWTO_books_ps.tgz"";  if (!(-d $Destination)) {system ""mkdir $Destination"";}  print ""Downloading HOWTOs from http://www.ibiblio.org/pub/Linux/docs/HOWTO/other-formats/ps/Linux-ps-HOWTOs.tar.gz\n""; system (""lynx --source http://www.ibiblio.org/pub/Linux/docs/HOWTO/other-formats/ps/Linux-ps-HOWTOs.tar.gz > $SourceDir/Linux-ps-HOWTOs.tar.gz""); system (""cd $SourceDir; tar -zxvf Linux-ps-HOWTOs.tar.gz"");   my @Files = <$SourceDir/*.ps.gz>;  foreach my $File (@Files)   {   my $command=""gunzip -c $File | /usr/bin/psbook -s4 | mpage -2 > $TempFile1"";   print ""Executing psbook and mpage on $File\n$command\n"";   system ($command);   $command = ""ps2pdf $TempFile1 $TempFile2"";   print ""Executing ps2pdf\n$command\n"";   system ($command);    my (@Temp) = split(/\//,$File);   my $NamePDF = pop @Temp;   my $NamePS = $NamePDF;   $NamePDF =~ s/\.ps\.gz$/\.pdf/;   $NamePS =~ s/\.ps\.gz$/\.ps/;   my $NewPS = ""$Destination/$NamePS"";   my $NewPDF = ""$Destination/$NamePDF"";    system (""mv $TempFile2 $NewPDF"");    print ""Created the book-formatted HOWTO, $NewPDF\n"";   system (""mv $TempFile1 $NewPS"");   print ""Created the book-formatted HOWTO, $NewPS\n"";   }  print ""Creating zip files $ZippedPDF and $ZippedPS\n""; system (""tar -zcvf $ZippedPDF $Destination/*.pdf""); system (""tar -zcvf $ZippedPS $Destination/*.ps"");        Conclusion   This is just a simple Perl script I use to download and convert the Postscript HOWTOs. My future goals involve:     using LWP in Perl instead of Lynx. Simple enough.    converting the entire Perl script into Python.    better error checking if the files don't get downloaded or if the   conversion doesn't work.    creating objects accepting text, TeX, Postscript, PDF, or other formats that can be converted into Postscript fairly easily and then into book format.    For now, my simple Perl script works out just fine. I am interested in  converting other documents for people provided that the documentation falls under some form of free documentation, like    Licenses For Documentation  located at www.gnu.org.     References       10/2000  Micro Publishing: Part 3 , by Mark Nielsen  .    7-1-2000    Micro Publishing, part II (Mark's Update)     12-1999 --   Micro Publishing .    If this article changes, it will be available here   http://www.gnujobs.com/Articles/18/HOWTO_Books.html         Mark works as an independent consultant donating time to causes like GNUJobs.com, writing articles, writing free software, and working  as a volunteer at  eastmont.net .                Mark Nielsen  Mark works at ZING  ( www.genericbooks.com ) and   GNUJobs.com . Previously, Mark founded  The Computer Underground . Mark works on non-profit and volunteer projects which promote free literature and software. To make a living, he recruits people for GNU related jobs and also provides solutions for web/database problems using Linux, FreeBSD, Apache, Zope, Perl, Python, and PostgreSQL.                 Copyright © 2001, Mark Nielsen.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 66 of  Linux Gazette , May 2001        ""Linux Gazette... making Linux just a little more fun! ""                 Configuring GDM 2.2   By  Mark Nielsen                        Introduction   Downloading and installing GDM.   Configuring GDM   Conclusion   References        Introduction  GDM or GNOME Display Manager, is a nice GUI login screen which makes it nice and pretty to login to X-windows. It it much nicer for non-linux people to have a GUI interface to login to rather than a console.    One thing that bothered me with some of the older versions of GDM was the fact that I couldn't place the login window anywhere I wanted on the screen. With the latest version, it as very easy. Also, I couldn't figure out how to make logos of people in the login window, and now I figured  that out. The latest version of GDM is really nice and I have figured out how to configure it the way I wanted it to be configured, so I finally decided to write this article.    Downloading and installing GDM.  I could have downloaded an RPM from somewhere, but instead I decided to compile it manually. I was testing it on a RH 6.2 system. As soon as I can get the 7.1 version of RH (as the 7.0 wasn't worth the trouble), I will test it on it as well, and Debian of course.   The danger of not using RPMs to install GDM, is the fact that I am installing a newer version of GDM on top of a GDM version which was installed by RPMs.  This could cause problems if I decided to use an RPM in the future. I found an RPM version at    ftp://ftp.gnome.org/pub/GNOME/stable/latest/redhat/i386/Base/gdm-2.2.0-1.i386.rpm   in case you don't want to install it manually.    Initial Steps     Downloaded GDM from   ftp://ftp.gnome.org/pub/GNOME/stable/latest/sources/gdm-2.2.0.tar.gz    tar -zxvf gdm-2.2.0.tar.gz   cd gdm-2.2.0   ./configure --prefix=/usr   make   make install    After fooling around a bit, I found out that /etc/X11/gdm wasn't being used for the configuration files, so I linked /etc/X11/gdm to the place  that gdm was looking. I probably could have recompiled gdm to fix this problem, but I am being lazy. Also, one directory was missing, so I created it.    Three additional Steps    mv /usr/etc/gdm /usr/etc/gdm_new  ln -s /etc/X11/gdm /usr/etc/gdm  mkdir /usr/share/faces/     Again, I emphasize the fact that you should probably use the rpm and not bother installing it manually.      Configuring GDM  The goals I had were,     Be able to place the login screen anywhere I wanted.    Be able to play a game before someone has to login.    Be able to put images in the background just for fun.    Be able to put a clock on the background.    Be able to put pictures or logos of people on the browser part of GDM.    I had to change some of the settings in the file gdm.conf. My changes were  Browser=true SetPosition=true PositionX=100 PositionY=100 Exclude=bin,daemon,adm,lp,sync,shutdown,halt,mail,news,uucp,operator,nobody,gdm,postgres,pvm,otherlogin GlobalFaceDir=/usr/share/faces/   Also, here was my Init/Default script,   #!/bin/sh  /usr/X11R6/bin/xsetroot -solid ""#363047""  xsri -geometry +5+5 /etc/X11/xdm/Logo2.png xsri -geometry +400+5 /home/mark/public_html/wedding/wed2.jpg xsri -geometry +700+500 /home/mark/public_html/wedding/walk.jpg xsri -geometry +200+500 /home/mark/public_html/wedding/kiss.jpg  xsri -geometry +5+175 /home/mark/public_html/kiss.gif  xsri -geometry +5+500 /usr/local/apache_gnujobs/htdocs/images/zing.png  xeyes -geometry +825+5 &  xclock -digital -geometry +825+125 -update 1 &   xtriangles -geometry +800+300 &    In order to get logos or pictures of people on the GDM screen, I had to make the name of the image exactly the name of username and put it in /usr/share/faces/. To test this, I took my logo for ZING and copied it to  ""/usr/share/faces/root"" like  cp /usr/local/apache_gnujobs/htdocs/images/zing.png /usr/share/faces/root   Notice that there is no extension.      Conclusion   Everything worked perfectly once I followed these steps. Using the rpm might have been easier, but oh well. I will try that out next time. I  highly recommend to back up any gdm configuration files before installing  any new RPMs (though the RPMs should back them up for you). I don't really see any other features that I would need. Some miscellaneous features, like maybe a ticker tape, downloading the weather, or other games besides triangles would be cool. I imagine it is possible, but it isn't necessary for me.  It also might be a security risk to let people play games before they have to login, in case they figure out some way to break out to a shell, so I wouldn't advise putting games into GDM on public computers.   I would have liked to compare KDM with GDM, but I wasn't able to easily find a recent web page for KDM. I am also waiting until I install the latest version of KDE before I mess around with KDM anyways.      References      Gnome Display Manager    6-24-1999  Setting up XDM .   If this article changes, it will be available here   http://www.gnujobs.com/Articles/19/GDM.html         Mark works as an independent consultant donating time to causes like GNUJobs.com, writing articles, writing free software, and working  as a volunteer at  eastmont.net .                Mark Nielsen  Mark works at ZING  ( www.genericbooks.com ) and   GNUJobs.com . Previously, Mark founded  The Computer Underground . Mark works on non-profit and volunteer projects which promote free literature and software. To make a living, he recruits people for GNU related jobs and also provides solutions for web/database problems using Linux, FreeBSD, Apache, Zope, Perl, Python, and PostgreSQL.                 Copyright © 2001, Mark Nielsen.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 66 of  Linux Gazette , May 2001      ""Linux Gazette... making Linux just a little more fun! ""                CVS: Client-Server Version Control    By  Kapil Sharma                    Overview           Getting CVS           The      repository      Multiple      Developers      Rolling      back to previous version      Some common      CVS commands      Other      tools and add-ons to CVS      More      information           Overview    CVS is a version control system. Using it, you can record the history of your source files. CVS helps if you are part of a group of people working on the same project, sharing the same code. Several developers can work on the same project remotely using CVS's client-server model in which the code exists on a central server and each programmer get the source on his local machine from the CVS server (checkout) and save it back on the CVS server (checkin) after development. Each time a programmer checks in his new code into the CVS server, the difference is saved as a new version rather than overwriting the previous version. This allows the server to recreate any previous version upon request, although by default it distributes the latest version.    This article explains how to use CVS in client-server mode and get the most out of it.    Getting CVS    You can find CVS in your Linux distribution or get the source from  http://www.cvshome.org/downloads.html    The home page for CVS is  http://www.cvshome.org .     The repository    The CVS repository stores a complete copy of all the files and directories which are under version control. Normally, you never access any of the files in the repository directly. Instead, you use CVS commands to get your own copy of the files into a working directory, and then work on that copy. When you've finished a set of changes, you check (or commit) them back into the repository. The repository then contains the changes which you have made, as well as recording exactly what you changed, when you changed it, and other such information.     Creating a Repository    To create a repository, run the CVS init command. It will set up an empty repository in the CVS root specified in the usual way .       cvs -d /usr/local/cvsroot init    Here /usr/local/cvsroot will become the repository.     CVSROOT environment variable      Set the CVSROOT environment variable in your shell startup script. For instance, in ~/.bashrc:       $ export CVSROOT=:pserver:username@foo.com:/usr/local/cvsroot     Backing up the Repository    There are a few issues to consider when backing up the repository:        One should either not use      CVS during the backup, or have the backup program lock CVS while doing the      backup.     To lock CVS, you would      create `#cvs.rfl' lock files in each repository directory.       Remote Repositories    Your working copy of the sources can be on a different machine than the repository. Using CVS in this manner is known as client/server operation.     Setting up the server:   Put the following entry in /etc/inted.conf on server:       2401 stream tcp nowait root /usr/local/bin/cvs cvs -f --allow-root=/usr/cvsroot pserver    If your inetd wants a symbolic service name instead of a raw port number, then put this in `/etc/services':       cvspserver       2401/tcp     and put cvspserver instead of 2401 in `inetd.conf'.   After making you changes, send a HUP signal to inetd.     Password authentication for remote repository    For remote password authentication put a file `$CVSROOT/CVSROOT/passwd' . The file will look like:       anonymous: kapil:1sOp854gDF3DY melissa:tGX1fS8sun6rY:pubcvs    The password is in Unix encrypted form. The first line in the example will grant access to any CVS client attempting to authenticate as user anonymous, no matter what password they use. The second and third lines will grant access to kapil if he supplies his respective plaintext passwords.     The third will grant access to melissa if she supplies the correct password, but her CVS operations will actually run on the server side under the system user pubcvs.     Note: CVS can be configured not to check the UNIX real passwd file i.e /etc/passwd for CVS authentication by setting SystemAuth=no in the CVS `config' file ($CVSROOT/CVSROOT/config).      Using the client with password authentication      You have to login to CVS server for the first time:          cvs -d :pserver:kapil@foo.com:/usr/local/cvsroot login    The you can use all the commands of CVS on the remote machine:          cvs -d :pserver:kapil@foo.com:/usr/local/cvsroot checkout someproj    Read only repository access    It is possible to grant read-only repository access to people using the password-authenticated server. There are two ways to specify read-only access for a user: by inclusion, and by exclusion.   ""Inclusion"" means listing the user in the `$CVSROOT/CVSROOT/readers' file, which is simply a newline-separated list of users. Here is a sample `readers' file:       kapil yogesh john    (Don't forget the newline after the last user.)     ""Exclusion"" means listing everyone who should have write access. If the file    $CVSROOT/CVSROOT/writers exists, then only those users listed in it will have write access, and everyone else will have read-only access. The `writers' file has the same format as the `readers' file.     Setting up the files in repository    If the files you want to install in CVS reside in `someproj', and you want them to appear in the repository as `$CVSROOT/someproj', you can do this:       $ cd someproj $ cvs import -m ""Imported sources"" someproj vendor     rel1-1    Here The string `vendor' is a vendor tag, and `rel1-1' is a release tag.     CVS locks in repository    Any file in the repository with a name starting with `#cvs.rfl.' is a read lock. Any file in the repository with a name starting with `#cvs.wfl' is a write lock. The directory `#cvs.lock' serves as a master lock. That means one must obtain this lock first before creating any of the other locks.     To obtain a read lock, first create the `#cvs.lock' directory. If it fails because the directory already existed, wait for a while and try again. After obtaining the `#cvs.lock' lock, create a file whose name is `#cvs.rfl.' followed by information of your choice (for example, hostname and process identification number). Then remove the `#cvs.lock' directory to release the master lock. Then proceed with reading the repository. When you are done, remove the `#cvs.rfl' file to release the read lock.     To obtain a write lock, first create the `#cvs.lock' directory, as with a read lock. Then check that there are no files whose names start with `#cvs.rfl.'. If there are, remove `#cvs.lock', wait for a while, and try again. If there are no readers, then create a file whose name is `#cvs.wfl' followed by information of your choice (for example, hostname and process identification number). Hang on to the `#cvs.lock' lock. Proceed with writing the repository. When you are done, first remove the `#cvs.wfl' file and then the `#cvs.lock' directory.     Symbolic revisions using tags in CVS   The release number of final software releases are different from revisions in CVS. The revision numbers might change for several times between two releases.You can use the linux-questions-only@ssc.command to give a symbolic name to a certain revision of a file.     Change to the working directory and issue the following command for tagging:       $ cvs tag rel1-1 file.c    This command will tag the file ""file.c"" as release 1.1       $ cvs tag rel1-1 .    This command will tag all the files under current directory recursively as revision 1.1    You can use the `-v' flag to the status command to see all tags that a file has, and which revision numbers they represent by issuing the following command:      $ cvs status -v file.c    Now you can checkout any revision of a module by using the following command:       $ cvs checkout -r rel1-1 module1    here ""module1"" is the name of the module. The -r flag with checkout option makes it easy to retrieve the sources that make up revision 1.1 of the module `module1' at any time in the future.    Multiple Developers    File status    The cvs status command gives a status about the states of the files. You can get a status of the file by:       $ cvs status [options] files    Bringing a file up to date    When you want to update or merge a file, use the update command. This brings into your working copy the changes others have recently committed. Your modifications to a file are never lost when you use update. If no newer revision exists, running update has no effect. If you have edited the file, and a newer revision is available, CVS will merge all changes into your working copy.     Resolving Conflicts      If two people simultaneously make changes to different parts of the same file, CVS is smart enough to merge the changes itself. But if two people make changes to the  same  part of a file, CVS cannot tell what the final result is supposed to be, so it gives up and wines, ""Conflict!"" Conflicts arise when one developer commits a change and a second developer, without running cvs update to receive the first developer's change, tries to commit his own incompatible change. Resolving changes can take hours or even days. In this section, I will explain how to resolve source conflicts.     When you enter the cvs commit command to automatically upload all the files you have changed or added to a project, the CVS repository server may inform you that your locally-edited files are not up-to-date with the server or that you need to manually merge one or more files with newer versions that have already been uploaded to the repository by some other developer. Here's a typical warning message that occurred during a CVS commit process:       $ cvs commit cvs commit: Examining . cvs commit: Up-to-date check failed for `andy.htm'  cvs commit: Up-to-date check failed for `sample.htm'  cvs commit: Up-to-date check failed for `index.htm'  ... cvs [commit aborted]: correct above errors first!    You can use the cvs update command to update your local project copy with the latest changes in the cvs repository. To update your entire working copy of the site, open a command prompt, change to the directory containing the project you're developing, and issue the command:       $ cvs update    This will update and automatically merge every file that has changed since you last copied over new files from the CVS repository. Line-by-line updates to individual text files (such as HTML files) can often be handled automatically. CVS will list for you any files that require your attention for manual editing and merging.     Automatic merge example:   You are editing some project file called ""index.html"" locally and when you try to commit that file to CVS repository then CVS will give you the following error:       $ cvs commit index.html     cvs commit: Up-to-date check failed for `index.html'      cvs [commit aborted]: correct above errors first!    This happens because there is a newer version of the same file on the CVS repository. You should use cvs update command to get the latest version from the CVS repository onto your local machine:       $ cvs update index.html RCS file: /usr/local/cvsroot/index.html,v retrieving revision 1.4 retrieving revision 1.5 Merging differences between 1.4 and 1.5 into index.html  M index.htm    After the automatic merge process you should check the merged copy to check if it is working properly. When you are satisfied with the local copy of ""index.html"" file then you can commit it to CVS:       $ cvs commit index.htm Checking in index.htm; /usr/local/cvsroot/index.htm,v <-- index.htm new revision: 1.6; previous revision: 1.5  done    Manual merge example:   In some cases, your recent work on a file might be so different that the CVS needs your manual intervention in order to integrate everyone's work and put it back into the site repository.       $ cvs commit index.html cvs commit: Up-to-date check failed for       `index.html' cvs [commit aborted]: correct above errors first!    Use the cvs update command to bring your local copy of the site up to date:       $ cvs update cvs update: Updating . RCS file: /usr/local/cvsroot/index.html,v retrieving revision 1.5 retrieving revision 1.6 Merging differences between 1.5 and 1.6 into index.htm rcsmerge: warning: conflicts during merge cvs update: conflicts found in activity.htm C index.htm    This time CVS was unable to merge the files automatically, so it created a special copy of the conflicting file in place of the original index.html. The file has marker lines to indicate the beginning and end of conflictiong region(s); e.g.,          <<<<<<<< filename    To resolve the conflict, simply edit the index.html file and replace the text between the markers and test the result until it works. You should also delete the markers       <<<<<<<<========>>>>>>>>     from the file. When you have finished correcting the file and have tested it, use the cvs commit command to put your latest copy of file into the repository:       $ cvs commit Checking in index.html; /usr/local/cvsroot/index.html,v <-- index.html new revision: 1.7; previous revision: 1.6  done    Watches (CVS communication)    CVS can function as a communication device as well as a record-keeper.  A ""watches"" feature provides multiple developers working on the same project with a way to notify each other about who is working on what files at a given time. By ""setting a watch"" on a file/directory , a developer can have CVS notify her if anyone else starts to work on that file by means of sending e-mail or some other method.     To use watches you have to edit two files in the repository administrative area. You have to edit the ""$CVSROOT/CVSROOT/notify"" file (which tells CVS how notifications are to be performed) and ""$CVSROOT/CVSROOT/users"" file(which supplies external e-mail addresses). The best way to modify administrative files is to checkout one copy from the repository ,edit them and then check in to repository .     To specify e-mail notification, first uncomment the following line from ""$CVSROOT/CVSROOT/notify"" file:       ALL mail %s -s ""CVS notification""    This command causes notifications to be sent as e-mail with the subject line ""CVS notification"".     Then you have to create/edit the file ""$CVSROOT/CVSROOT/users"" . The format of each line in the users file is: CVS_USERNAME:EMAIL_ADDRESS. For example:       kapil:kapil@linux4biz.net    The CVS username at the beginning of the line corresponds to a CVS username in CVSROOT/password, or the server-side system username of the person running CVS. Following the colon is an external e-mail address to which CVS should send watch notifications for that user.     E-mail notification with logfile    CVS provides a feature of sending automated e-mail to everyone working on a project  with a log message whenever a commit takes place. The program to do the mailing - contrib/log.pl in the CVS source distribution - can be installed anywhere on your system. You can also install it into ""$CVSROOT/CVSROOT"". You should change the following line in log.pl :       $mailcmd = ""| Mail -s 'CVS update: $modulepath'"";     Once you've setup the log.pl , you can put lines similar to these into your “loginfo” file. The  `loginfo'  file is used to control where  `cvs commit'  log information is sent. You can find it in ""$CVSROOT/CVSROOT"".      projectteam1 CVSROOT/log.pl %s -f CVSROOT/commitlog -m projectteam1@linux4biz.net projectteam2  CVSROOT/log.pl %s -f CVSROOT/commitlog -m projectteam2@linux4biz.net    The %s expands to the names of the files being committed; the -f option to log.pl takes a file name, to which the log message will be appended (so CVSROOT/commitlog is an ever-growing file of log messages); and the -m flag takes an e-mail address, to which log.pl will send a message about the commit. The address is usually a mailing list, but you can specify the -m option as   many times as necessary in one log.pl command line.     Some commands related to setting up watches on files :     If you only want to be notified about, say, commits, you can restrict notifications by adjusting your watch with the -a flag (a for action):       $ cvs watch add -a commit hello.c    Or if you want to watch edits and commits but don't care about unedits, you could pass the -a flag twice:       $ cvs watch add -a edit -a commit hello.c    Adding a watch with the -a flag will never cause any of your existing watches to be removed. If you were watching for all three kinds of actions on hello.c, running       $ cvs watch add -a commit hello.c    has no effect - you'll still be a watcher for all three actions.     To remove watches, run:       $ cvs watch remove hello.c    which is similar to add in that, by default, it removes your watches for all three actions. If you pass -a arguments, it removes only the watches you specify:       $ cvs watch remove -a commit hello.c    To find out who is watching files, run cvs watchers:       $cvs watchers $cvs watchers hello.c    To find out who is editing files, run cvs editors:       $cvs editors $cvs editors hello.c    Note: It is necessary to run ""cvs edit"" before editing any file to be able to watch feature working. To make sure you do, CVS has a feature to remind the someone to use cvs edit with the help of  the watch on command:       $ cd project $ cvs watch on hello.c    By running cvs watch on hello.c, kapil causes future checkouts of project to create hello.c read-only in the working copy. When someone else tries to work on it, he'll discover that it's read-only and be reminded to run cvs edit first.       $cvs edit hello.c    Rolling back to previous version    Sometimes you need to revert back to previous version of your  project.  A project under CVS version control can quickly and conveniently revert to an earlier stage of its life. I will explain some of the common examples:       $ cvs checkout -D '1 year ago' preproject    Here preproject is the name of the project.       $ cvs checkout -r1.4 preproject    1.4 is CVS's revision number for that version.     Some common CVS commands    Some common terms:   Import:    This means taking an existing directory tree and copying it into the CVS repository, creating a new CVS project.   Commit: Apply all your changes to the CVS repository.  Each changed file will be assigned a new CVS version.  Checkout: Get the working copy of files from cvs repository into the local directory.  Export: export is same as checkout. The only difference is that export does not copy out the CVS administrative directories, so you cannot run CVS commands in the resulting tree.  On the other hand, this is how you create your ""final"" copy for distribution.  Upload: General term for Import or commit.  Download: General term for checkout or export.  Checkin: General term, same as commit.    Adding a file to the CVS repository ""My_Files""        $ cvs add File3.txt $ cvs commit    cvs add does not upload the file right away, but registers it to be uploaded at the next commit.          This invokes your default text editor and prompts you to enter a description of your changes. Save the file and quit the editor. CVS will then ask you to continue, and select the option to continue. Now you have uploaded a file to the CVS repository ""My_Files"".     Changing a file to the CVS repository ""My_Files""       This can be done with cvs commit command. Let us add some content to the file File2.txt and then commit it to the cvs repository.    $ ls /var >> File2.txt $ cvs commit    Removing files    To remove files from a site, you run the cvs remove command on the desired filenames in your working copy. As a ``safeguard'', cvs remove will not work if the working copies of your files still exist.  Syntax:    $ cvs remove [options] files        $ cvs remove file.html cvs server: file `file.html' still in working directory cvs server: 1 file exists; remove it first $    To get around this, you may use the -f option with the cvs remove command or remove the file first and then execute the cvs remove command.     $ cvs remove -f oldfile.html cvs server: scheduling `oldfile.html' for removal cvs server: use 'cvs commit' to remove this file permanently $ cvs commit   Or $ rm File3.txt $ cvs remove File3.txt $ cvs commit      This will not delete the actual file from the CVS server yet; it simply makes a note to tell the server to remove these files the next time you commit your working copy of the project.        Removing directories    The way that you remove a directory is to remove all the files in it. You don't remove the directory itself: there's no way to do that. Instead you specify the `-P' option to cvs update or cvs checkout, which will cause CVS to remove empty directories from working directories. (Note that cvs export always removes empty directories.) Note that `-P' is implied by the `-r' or `-D' options of checkout. This way CVS will be able to correctly create the directory or not depending on whether the particular version   you are checking out contains any files in that directory.     Creating the directory structure from number of files in the CVS repository  This cvs import command is used to put several projects in cvs repository.     $ cd source   here source is the files that you want to put in cvs repository.     $ cvs import -m ""Test Import"" My_Files Revision1 start  The string  ‘Revision1’  is a  vendor tag , and  `start'  is a  release tag . “My_Files” is the name of directory in cvs repository. The –m option is to put log message.    Get the working copy of files from CVS      Okay, now we want to download these files into a Working directory.   When we checkout a package from cvs, it will create a directory for us. The parameter ""My_Files"" that we specified when we uploaded the files into cvs will be the name of   the directory created for us when cvs downloads the package for us.     Now we need to get the cvs package.       $ cvs checkout My_Files    Downloading updates that other people make      If you have downloaded a package from a repository that someone else is maintaining, if you wish to download all the changes, then execute the following command,       $ cvs update -dP    The ""d"" creates any directories that are or are missing. The ""P"" removes any directories that were deleted from the repository.     Viewing the difference    You can easily see the difference between two file using cvs.       $ cd project $ cvs diff index.html    This command runs diff to compare the version of `index.html' that you checked out with your working copy.  Here ""project"" is the name of the local project directory.       $ cvs diff -r 1.20 -r 1.21 hello.c    This command will show the difference between two versions of same file.     The annotate Command    With annotate, you can see who was the last person to touch each line of a file, and at what revision they touched it. It gives you more information than the history command:       $cvs annotate    View logs       $ cvs log -r 1.21 hello.c    This will show you the logs for hello.c version 1.21     Other tools and add-ons to CVS    Henner Zeller's CVSweb     It has a feature of browsing the CVS repository by web browser and even shows the latest revision and log message for each file. It presents you with a web-based interface to browse any and all of the sites and projects you manage by  CVS. You can get it from  http://stud.fh-heilbronn.de/~zeller/cgi/cvsweb.cgi/      Martin Cleaver's CVSweb     It features capabilities for file upload as well as file browsing of CVS repository. You can get this software from  http://sourceforge.net/projects/cvswebclient/      LinCVS    A CVS GUI client for Linux. It provides nice features and easy to use. You can get it from:  http://www.lincvs.org/      WinCVS    A CVS GUI client for Windows. It has many good features and I will recommend this software for Windows clients. You can get it from  http://www.cvsgui.org/download.html      More Information    CVS Manual :  http://www.cvshome.org/docs/manual/cvs.html    CVS Mailing lists:  http://www.cvshome.org/communication.html               Kapil Sharma    Kapil is a Linux/Unix and Internet security consultant. He has been working on various Linux/Unix systems and Internet Security for over three years. He maintains a web site ( http://linux4biz.net ) for providing free as well as commercial support for web, Linux and Unix solutions.                Copyright © 2001, Kapil Sharma.  Copying license  http://www.linuxgazette.com/copying.html  Published in Issue 66 of  Linux Gazette , May 2001                  ""Linux Gazette... making Linux just a little more fun! ""                 Stopping Spam on Your Linux Box   By  Suresh Ramasubramanian                     If you have an e-mail account, you are bo doubt getting mail that you have not asked for, and do not want in your inbox - unsolicited e-mail (aka spam).  What's Spam? In 3D ""meatspace"", it is a luncheon meat manufactured by Hormel Corp (which also owns  http://www.spam.com ).  Spam on the net though is unsolicited e-mail, unwanted e-mail, frequently sent in bulk and advertising some commercial proposition. Most of the Spam you probably get, and what this article deals with, is UC/BE (Unsolicited Commercial and/or Bulk E-Mail).     If you have a linux (or *nix) box, you have a set of powerful tools to stop all this spam from cluttering your inbox.  These tools are even more useful to you if you run a production mailserver and want to stop spam from reaching your users.     The three cardinal rules of spamfighting are:       Prevention is better than cure.  Armor yourself against spam.   Filter Spam before it reaches your mailbox   Complain to the spammer's ISP and get him shut down      I. Prevention is better than cure.  Armor yourself against spam.     Protect yourself and prevent spammers from harvesting your address.  Don't expose your primary e-mail addresses where a spammer can get at it and add it to his list.  This includes places like  /. , usenet, publicly archived mailing lists, web based bulletin boards - in short, anywhere online.  Instead, follow one of these steps:     1. Use a ""throwaway"" address (say abcde@yahoo.com) when posting.  If you find that this address is getting spammed, you can just throw it away and switch to another address.  To be on the safe side, when you are posting online, ""munge"" your address to something like abcde@yahoo.com.Spammers.Suck. Obviously, spammers (who use robots to crawl the web searching for mail ids and burn the entire thing into a CD) will not be able to mail you.     2. If you run your own domain, use ""expiring"" mail addresses - addresses which will be valid for a [week|month|year], and will then cease to exist. This address can be something like me-mar31-apr31@mydomain.com.  In case you don't have your own domain, heck, use me-mar31-april31@yahoo.com instead :)     3. Both these measures have a major drawback: you have to keep changing your e-mail address--faster than your girlfriend changes her hairstyle! :) If your ISP uses sendmail, you have another option - ""plus"" addresses.    Plus addresses are available with newer versions of sendmail (8.8 and above). Just add a plus sign and any string you want after the username and before the '@'--the mail will still be delivered properly. For instance, me+foo_bar@myisp.com will reach me - sendmail will ignore everything after the plus.  For a (slightly old) FAQ on how to implement plus addressing in various MTAs (and how to use them in various mail clients) see  http://www.faqs.org/faqs/mail/addressing/ .  (Note that some MTAs use a hyphen instead of a plus sign.  We'll still call them plus addresses here--but maybe we should call them ""minus"" addresses instead!    )    Obligatory disclaimer: before you start using plus addresses in your e-mail, send yourself a test mail with a plus address and check whether it reaches you.     Plus addresses are useful because they reveal just  where  a spammer harvested your mail id from. For instance, if you subscribe to the Linux India Help mailing list, subscribe to it as you+lih@yourdomain.com (and make sure you set your mail client to post messages to the list only using this identity or the list will bounce your mails).  Both PINE and Mutt allow you to use different identities when posting (roles in PINE and folder hooks in mutt).  Another advantage of plus addresses is that, if you start getting lots of spams to a plus address, you can just send all mails reaching that address to be read by Dave Null (aka /dev/null).    See  Appendix #1  below for how to configure multiple identities (including plus addresses) in pine 4.x and Mutt.    II. Filter Spam before it reaches your mailbox     You can do this at the MTA level and by running Procmail filters.  If your remote mailbox gives you a unix shell account, run the filters there instead of on your desktop linux box.  Naturally, for the MTA level config / patching, you have to be root :)    Procmail Filtering     Several procmail recipes are available for you to trap and dev/null (or even complain about) most of the spam you get.  The most popular one is Spambouncer by Catherine Hampton.  Download for free at  http://www.spambouncer.org . Another excellent page is maintained by Concordia University at  http://alcor.concordia.ca/topics/email/auto/procmail/spam/ . You can also check out  SpamDunk  by Walt Dnes.     MTA level filtering (Sendmail)     As most linux boxes come installed with sendmail, I will go into slightly more detail here.  Sendmail 8.8.7 (which came with Redhat 5.1) and above have spam blocking features, which allow you to deny mails from specific domains / domains blackholed in the MAPS RBL and other blackhole lists.  In any case, upgrade to the latest version of sendmail available (currently 8.11.3, or the 8.12 betas).      Compiling sendmail is a really good idea (and is quite easy - with detailed instructions given in a file called INSTALL in the sendmail source tree).  Or you can get prebuilt binaries in whatever format you want (rpm, deb and such).    Stock sendmail installs can reject SMTP connections from domains / addresses based on a database of filter rules - see /etc/mail/access (and /etc/mail/access.db, which you generate using makemap hash access.db < access).     /etc/mail/access can have e-mail addresses, whole domains or even specific ip addresses / ip blocks as keys.      spammer@yahoo.com        550 Get lost - No spammers allowed  spammer.com          550 Go to hell  192.168.212   REJECT     would refuse smtp connections from spammer@yahoo.com, any user from spammer.com (or hosts within the spammer.com domain), and any host on the 192.168.212.* netblock.  For further (extremely detailed) details, see Claus Assmann's page at  http://www.sendmail.org/~ca/email/   (and the sendmail FAQ at  http://www.sendmail.org/faq/  won't hurt either).    Test this by sending a test mail to yourself from that host and then download the message using fetchmail, using the -v argument.  This will allow you to monitor the SMTP transaction - when the FROM address is parsed, if sendmail sees that you have blacklisted the address, fetchmail will flush and delete it.   Obvious warning: never put a reject entry your own mailhost or any host you accept mail from using fetchmail into your access db--you will lose mail if you do this.    You can also reject mail from all hosts listed in the MAPS RBL and other DNS based blackhole lists by enabling the dnsbl features in sendmail.mc and rebuilding sendmail.cf.  See  http://www.mail-abuse.org/rbl/usage.html  for more details.     Oh yes - make sure you are not an open relay, which can be abused by spammers to relay their spam, leaving you with a clogged mailqueue, a mailbox full of thousands of bounces, angry flames from spammed people and possibly a listing in the RBL (if you are slow to fix it).  See  http://www.sendmail.org/tips/relaying.html  and  http://www.orbs.org/otherresources.html  for more details.     Newer versions of sendmail dont make you an open relay - if you resist the temptation to configure sendmail using linuxconf (or most other auto config tools).  Create a sendmail.mc file and regenerate sendmail.cf.  For example, see  http://www.hserus.net/sendmail.html  (part of my Dialup HOWTO at  http://www.hserus.net/dlhowto.html    See  Appendix #2  below for antispam measures (including closing open relays) in other MTAs   III. Complain against spammers, get them shut down.     Spam, being the insiduous, creeping slime that it is, will sooner or later slip through all your filters and enter your mailbox.  A linux box gives you all you need to track the spammer down - basic *nix tools like whois, nslookup, traceroute, and the best one of all: dig. The best solution is to spare a little time (less than five minutes) to send out a few complaints to the spammer's webhost, his ISP, his freemail provider - anyone and everyone who can do serious damage to the spammer.  These tools are also available on the web at  http://www.samspade.org .    See  Appendix #3  below for more links on tracing and reporting spam   Appendix 1     Roles in PINE - With PINE 4.x and above, press S (Setup) and R (Roles).  Add as many roles as you feel like and switch between them using  #  (the Hash character).  Or you can choose between different roles when replying to an e-mail.     Roles in Mutt - Use folder hooks, so that all outgoing mail from a particular folder have the from field set to me+tag@myisp.com      folder-hook linux   ""my_hdr From: me+linux@myisp.com (My Linux Account)""  set envelope_from   # sets the envelope sender, which is what's checked         # by the list server <= mutt 1.2.x and above     Procmail recipe to dev/null all mails sent to a tagged address that attracts too much spam:      # If mail is sent to you+spam_string@yourisp.com trash it  :0:  *^TO_ you+spam_string@yourisp.com  /dev/null     Appendix 2     QMail: See  http://www.summersault.com/chris/techno/qmail/qmail-antispam.html  for a detailed account of anti-spam features in qmail (several of them).    Other MTAs: Debian comes with Exim.  There are other *nix MTAs as well.  See  http://www.mail-abuse.org/tsi/ar-fix.html   (and the websites of each MTA) for a comprehensive howto.     Appendix 3     Reference links:     The abuse.net faq   The Spam-L mailing list FAQ   The Lumber Cartel Search Page --see their home page for the funny story of just  how  the Lumber Cartel has become an in-joke among anti-spammers)   MAPS -The Mail Abuse Prevention System, home of the RBL, RSS and DUL blackhole lists)   ORBS --another DNS based blackhole list   John R Levine's Network Abuse Clearinghouse   CAUCE International   CAUCE India                 Suresh Ramasubramanian   Suresh  is President of the Indian chapter of   CAUCE , an international organization of people dedicated to fighting Spam.  He is webmaster of   KCircle , one of the world's most popular trivia quiz resources.                 Copyright © 2001, Suresh Ramasubramanian.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 66 of  Linux Gazette , May 2001        ""Linux Gazette... making Linux just a little more fun! ""             The Back Page     About This Month's Authors   Wacko Topic of the Month   Not Linux   World of Spam                  About This Month's Authors                Author bios are now at the bottom of the corresponding article.  This was suggested by  Dustin Puryear , and we decided we like the idea.  What do you readers think?                Wacko Topic of the Month                    Yamaha and UFOs     Answered By Ben Okopnik, Mike Orr, Heather Stern       I wanted to ask if you service yamahe music equipment.       [Ben] Hey,  LG   does  mention ""Yamaha"" a dozen times in past issues (the sound card, obviously). Maybe the guy was getting desperate and trying every source... That is pretty wild, though. I'm still waiting for ""Dear Earthlings: I just installed Windows on my UFO, and now I can't get back in...""        [Mike] ""Hey Earthlings, we just installed something called Windoze En-Tee on our flying saucer, and it made all or monitors turn   blue .  There's a message in  white  letters on the screen, but we don't understand the language.  Please help  URGENTLY  as our spacecraft is out of control and is locked on a crash course with Earth.""        [Heather]  Fellow-being: What you need is to install something else quick. Since your saucer can run Windoze (also called MSwin or windows or wind*ws) I recommend ""ZipSlack""   http://www.slackware.com/zipslack/getzip.php . It can load quickly onto the ""FAT"" filesystem MSwin uses and once you have successfully launched that you should stop crashing...    You may want something more well-tuned to your saucer once you have that going.    According to my research (slim pickings, most of our movies about aliens don't describe their software, but one notes you are able to run some of our virus software), apparently your native operating system most closely resembles something here called ""MacOS"".  This is at least part of the problem, nearly  any earthling knows that the MacOS and Windows vendors are at war with each  other.     Unfortunately MacOS is proprietary so getting you a working copy without getting some Earth hardware to go with it, may be a problem, esp. if you  have no Earth currency aboard.    Fortunately, we Linuxers can recommend either   Yellow Dog Linux  or   LinuxPPC 2000  , as well as   Debian .  I can't say which will have the fastest install - a Mac-using friend highly recommends the first... Debian is highly available so you should be able to reach a mirror site no matter which of our land masses you are presently nearest.  To save you time the web link you need is  http://cdimage.debian.org/ftp-mirrors.html .  Normally they discourage getting ISO images directly like that but, they expect you to have a stable system to fetch.  I hope you will have no problems whatsoever creating discs ...  By the way, most earthlings don't understand the funny messages generated by those blue screens either.  Luckily I can assure you they don't help fix  the problem...                     Not Linux                RFC 3092  muses on the etymology of 'foo' and 'bar'.  Among other things, it says the ""wildly popular"" Smokey Stover comic strip of the 1930s by Bill Holman ""featured a firetruck called the Foomobile that rode on two wheels.""      The RFC also has a table of which other RFCs mention ""foo"", ""bar"" or ""fubar"".         Rory Krause and I came up with this one:  the sysadmin's dance: do the Buggy Boogie.           CueJack  is a Windows application that lets you scan a products with a :CueCat scanner, then displays a web page with ""alternative information"" about the product's company. As you can guess, the ""alternative information"" is stuff the company doesn't want you to know.   ""This could be information about corporate abuse, boycotts against the company, even how much money the company is making, their corporate image as presented to shareholders, etc."" Courtesy Slashdot.    Miscellania: The program was renamed from CueHack because another program already had the same name.  The author is working on a Linux version but says there are technical difficulties.                    World of Spam                 Some of the funnier spams found in the  Gazette  mailbox.     ... helps Businesses to eliminate the need of hiring telemarketers  Automated initial customer application process and many more features......... You will smile all the way to the Bank!!    Automatically calls........ To market products and to make announcements. To confirm preset appointments, prescheduled meetings, and conferences.  Our CTI software can be used by businesses and services by calling sequentially or randomly.  Automatically dials up to 2,000 - 10,000 prospects per day without human interference.  When our CTI software calls it can simply leave a message or it can ask for a response. You may obtain responses by recording their voices, asking them to press a key, to respond to choices or transferring to a live operator. Just record your messages, select which group ( Data Bases) you want to call , when you want to start and stop, and then let our CTI software got to work calling everyone.  You will save tremendous time and get results very fast ! without increasing your overheads or hiring extra help.         [ Your Editor got an obnoxious phone call at home recently from one of  these machines.  The recorded message said, ""Please hold until a  representative can get to you.""  Click!           Subject: BOUNCE linux-questions-only@ssc.com:     Message too long (>40000 chars)    It's nice to know the TAG spamfilter is working.   -Mike.]          From: Justin Catterall  Date: Fri, 6 Apr 2001 22:39:05 +0100    Regarding the   Nigerian money scam   in last month's Not Linux.    I've been receiving faxes the same as this for a few years at work, the scam is worse than it looks: they *have* been succesful on several occaions - all UK (if not world) banks know not to let their customers get involved.    What basically happens is A N Idiot agrees to the deal, signs the papers and money appears in his/her account. A N Idiot then transfers most of the money to another account (the scammer's). The money coming into the account then never arrives - originating bank denies knowledge or whatever - A N Idiots bank ha's, in the mean time, sent the money to another bank. The first thing the bank does is debit A N Idiot's account... A N Idiot is holding the can for an awful lot more money than they thought they'd ever see.    Holding the can for more money than you thought you'd ever see is probably better than holding the can for the first million you've just made and is all you have because if you're 999,000 away from paying back 1,000,000 they aren't really going to try to get it back but if you're nearly their they'll clean you out then lock you up.    These scammers are real bastards, if I didn't know it happened I wouldn't believe people could be so bad to other people.    Anyway, I just thought I'd let you know that this scam has worked and how it worked (roughly and AIUI).    Keep up the work with the gazette.           From: James Suttie  Date: Fri, 20 Apr 2001 22:36:48 +0100     keep up the good work with Linux Gazette - here's one of many links to the African spam scam!  http://www.state.vt.us/atg/NIGERIA.htm           Are you planning to rent a Limousine, Sedan or a Private car for your Teen Prom Ceremony this session?           ALWAYS SEND $5 CASH (U.S. CURRENCY) FOR EACH REPORT CHEQUES NOT BE ACCEPTED ALWAYS SEND YOUR ORDER VIA FIRST CLASS MAIL Make sure the cash is concealed by wrapping it in at least two sheets of paper. On one of those sheets of paper, include: (a) the number & name of the report you are ordering, (b) your e-mail address, and (c) your name & postal address.          Free Leads Daily - Spam FREE! No Cost to you!             YOU CAN make over a half million dollars every 4 to 5 months from your home for a one time investment of only twenty five U.S. Dollars.          Subject:  BUSINESS OPPORTUNITY EXTRAORDINAIRE!!    I understand you are seeking information about home based business opportunities.    --LEGITIMATE online business, which is SUCCESSFUL and GROWING.    --PERFECT for someone who has VERY LITTLE TIME to invest or  for someone who LOVES being online!    Please email me at the address below to receive FREE VITAL INFORMATION (You'll very well Kick Yourself and your Modem if you don't)         Our research indicates this information may be of interest to you.           Hello gazette  WOW! This is absolutely amazing! Now you can put money in  your pocket at warp speed using the internet! We're not talking  weeks or even days, but within HOURS!! Wouldn't you like to  be $5,000 richer by the day after tomorrow? Then you can do it  again as often as you like - even every day! For all the fantastic  details, send a blank email to: [address]         E-zine Editors... Authors... Information Publishers...** NEVER BEFORE SEEN ** Techniques For  Turning an Electronic Newsletter Into a $20,000+ a Month Profit Stream!       [Wow, something that's actually relevant to  LG   -Mike.]                 Happy Linuxing!    Michael Orr  Editor,  Linux Gazette ,  gazette@ssc.com                   Copyright © 2001, the Editors of  Linux Gazette .  Copying license  http://www.linuxgazette.com/copying.html  Published in Issue 66 of  Linux Gazette , May 2001"
GX192-24-10621768	Next Previous  Contents     1. Consultant Listings    1.1 Consultant ID: Argentina, BASystem           Manuel ugarte 2328 Buenos Aires, NON United States 1428  Argentina          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: UltraPenguin    Other Specialty Distribution: NA    Reseller Authorizations: Compaq  HP  IBM       Linux Certifications: RedHat  Not Applicable       Company Phone Number: 54-11 4781-9710    Company Fax: 54-11 4789-9228    Support Phone Number: 54-11 4781-9710  Contact Email Address:   clau@basystem.com.ar Company URL:   http://www.basystem.com.ar Primary Contact: Norberto Mayo          1.2 Consultant ID: Argentina, CompuSoft           Drago 23, Piso 5, Oficina 12 Bahia Blanca, NON United States 8000  Argentina          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  System Administration  System Security       Main Distribution: RedHat    Other Distribution: Not_Applicable    Specialty Distribution: LinuxPPC    Other Specialty Distribution: Not_Applicable    Reseller Authorizations: Compaq  HP  IBM       Linux Certifications: Not_Applicable    Company Phone Number: +54(291) 455-3570    Company Fax: +54(291) 453-6735    Support Phone Number: +54(291) 15 648-9284  Contact Email Address:   goburastero@arnet.com.ar Company URL:   http://www.arnet.com.ar Primary Contact: Guillermo Burastero          1.3 Consultant ID: Argentina, CyberWare Information Technology           Zeballos 2774 Rosario, NON United States 2000  Argentina          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: (54)(0341) 156-40-14    Company Fax: Not_Applicable    Support Phone Number: Not Available  Contact Email Address:   soporte@cyberware.com.ar Company URL:   http://www.cyberware.com.ar Primary Contact: Javier  Kohan          1.4 Consultant ID: Argentina, Generic Soft           Defensa 767 ofic. 20 Buenos Aires, NON United States 1065  Argentina          Consulting Specialties: CIFS (Samba)  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 5411-4300-7294    Company Fax: 5411-4300-7294    Support Phone Number: 5411-4300-7294  Contact Email Address:   soporte@generic.findhere.com Company URL:   http://generic.findhere.com Primary Contact: Pablo Lazaro          1.5 Consultant ID: Argentina, Jorge Forte           Calle 47 Nro 826 Dep 9 La Plata, NON United States 1900  Argentina          Consulting Specialties: CIFS (Samba)  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: Caldera    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 542214821914    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   soporte@forte.com.ar Company URL:   http://www.forte.com.ar Primary Contact: Jorge Forte          1.6 Consultant ID: Argentina, NIXE S.R.L.           Pte. Luis S. Pea 366 4 A Buenos Aires, NON United States 1110  Argentina          Consulting Specialties: CIFS (Samba)  Custom Systems  E-Commerce  Firewalls and Internet Security  Netware Connectivity  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: Slackware    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not_Applicable    Linux Certifications: Not_Applicable    Company Phone Number: +54 (11) 4383-7831    Company Fax: +54 (11) 4383-7831    Support Phone Number: +54 (11) 15-4444-832  Contact Email Address:   support@nixe.com.ar Company URL:   http://www.nixe.com.ar Primary Contact: Gustavo Gasparrini          1.7 Consultant ID: Argentina, Nixe S.R.L.           Pte. Luis Saenz Pe#a 366 4A Buenos Aires, NON United States 1110  Argentina          Consulting Specialties: CIFS (Samba)  Custom Systems  E-Commerce  Firewalls and Internet Security  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: Slackware    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not_Applicable    Company Phone Number: +54 (11) 4383-7831    Company Fax: +54 (11) 4383-7831    Support Phone Number: +54 (11) 4383-7831  Contact Email Address:   support@nixe.com.ar Company URL:   http://Not_Applicable Primary Contact: Gustavo Gasparrini          1.8 Consultant ID: Australia, Computer Clinic (WA) Pty Ltd           4/226 Main St Osborne Park Perth WA, NON United States 6017  Australia          Consulting Specialties: Custom Systems       Main Distribution: Caldera    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: HP       Linux Certifications: Caldera       Company Phone Number: 08 94406611    Company Fax: 08 94406610    Support Phone Number: 08 94406611  Contact Email Address:   support@cclinic.com.au Company URL:   http://www.cclinic.com.au Primary Contact: Colin or Garth Hewitt or Atkinson          1.9 Consultant ID: Australia, Cybersource Pty. Ltd.           Level 8, 140 Queen Street Melbourne, NON United States 3000  Australia          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: RedHat       Company Phone Number: +61 3 9642 5997    Company Fax: +61 3 9642 5998    Support Phone Number: +61 3 9642 5997  Contact Email Address:   rh-support@cyber.com.au Company URL:   http://www.cyber.com.au Primary Contact: Con Zymaris          1.10 Consultant ID: Australia, Cyberspace Corporation           3A/426 Burwood Highway Melbourne, NON United States 3152  Australia          Consulting Specialties: Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: IBM       Linux Certifications: Not Applicable       Company Phone Number: +61 (3) 9887 4700    Company Fax: +61 (3) 9887 2756    Support Phone Number: +61 (3) 9887 4700  Contact Email Address:   support@cyberspace.net.au Company URL:   http://www.cyberspace.net.au Primary Contact: Keith Chamberlain          1.11 Consultant ID: Australia, DataSource Pty. Ltd           Not_Applicable SYDNEY, NON United States 2570  Australia          Consulting Specialties: Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +61418675892    Company Fax: Not_Applicable    Support Phone Number: +6146556792  Contact Email Address:   Linux@sysmon.net Company URL:   http://www.sysmon.net Primary Contact: Steve Deadman          1.12 Consultant ID: Australia, EMUSYS Unix Consulting           20 Ivanhoe Rd Croydon, NON United States 2132  Australia          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +61 2 9798 7604    Company Fax: +61 2 9798 2854    Support Phone Number: 0500 500 EMU  Contact Email Address:   support@emusys.com.au Company URL:   http://www.emusys.com.au Primary Contact: Anthony Rumble          1.13 Consultant ID: Australia, Echo Labs           29 Weld St, Nedlands Perth, NON United States 6009  Australia          Consulting Specialties: Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +61 41 356 0008    Company Fax: Not_Applicable    Support Phone Number: Not Available  Contact Email Address:   echo@iinet.net.au Company URL:   http://www.iinet.net.au/~echo Primary Contact: Ralph Billes          1.14 Consultant ID: Australia, Farrow Norris           58 St Georges Pde Sydney, NON United States 2220  Australia          Consulting Specialties: Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet (Web) Programming  Network Administration  System Administration  Virtual Private Networking       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +61 4 1724 3183    Company Fax: +61 2 9546 4468    Support Phone Number: +61 4 1724 3183  Contact Email Address:   support@fn.com.au Company URL:   http://http://www.fn.com.au/ Primary Contact: James Farrow          1.15 Consultant ID: Australia, Hinterlands Consultancy I.T.           1 Crusader Rd Galston NSW., NON United States 2159  Australia          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: Intel and Alpha    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +61 2 9653 2837    Company Fax: +61 2 9653 2937    Support Phone Number: +61 2 9653 2837  Contact Email Address:   support@hinterlands.com.au Company URL:   http://www.hinterlands.com.au Primary Contact: Chris Blown          1.16 Consultant ID: Australia, Informed Technology Pty Ltd           136/138 Railway Pde West Leederville, NON United States 6007  Australia          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: Debian Sparc    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +61-8-9380-4244    Company Fax: +61-8-9380-4354    Support Phone Number: +61-8-9380-4244  Contact Email Address:   support@it.net.au Company URL:   http://www.it.net.au Primary Contact: Andrew Howell          1.17 Consultant ID: Australia, John Pearson           PO Box 3412 Rundle Mall Adelaide, NON United States 5000  Australia          Consulting Specialties: CIFS (Samba)  Firewalls and Internet Security  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +61 407391169    Company Fax: +61 883644231    Support Phone Number: +61 407391169  Contact Email Address:   huiac@camtech.net.au Company URL:   http://Not_Applicable Primary Contact: John Pearson          1.18 Consultant ID: Australia, LINSUP.COM           P. O. Box 689 St. Ives, NON United States 2075  Australia          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: Debian    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +61 2 9144-6131    Company Fax: +61 2 9144-6138    Support Phone Number: +61 2 9144-6131  Contact Email Address:   info@linsup.com Company URL:   http://www.linsup.com Primary Contact: Richard Ames          1.19 Consultant ID: Australia, Linux Garden           Unit 4, 142 Culloden Road, Marsfield Sydney, NSW, NON United States 2122  Australia          Consulting Specialties: Custom Programming  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 61 0417 869242    Company Fax: Not_Applicable    Support Phone Number: 61 0417 869242  Contact Email Address:   shyam@linuxgarden.com Company URL:   http://www.linuxgarden.com Primary Contact: Shyam Govardhan          1.20 Consultant ID: Australia, Studio of Arts And Sciences (SAAS)           PO Box 214 Mosman Sydney, NON United States NSW 2088  Australia          Consulting Specialties: CIFS (Samba)  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: Darwin and all MAC    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +61-2-9453-9100    Company Fax: +61-2-9453-9101    Support Phone Number: +61-2-9453-9100  Contact Email Address:   saas@saas.nsw.edu.au Company URL:   http://www.saas.nsw.edu.au Primary Contact: Roger Buck          1.21 Consultant ID: Australia, Sydnet Group Pty Ltd           PO Box 4664 North Rocks, NON United States 2151  Australia          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Other    Other Distribution: Slackware    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +61 2 9873 6400    Company Fax: +61 2 9873 6411    Support Phone Number: +61 2 9873 6400  Contact Email Address:   support@syd.net.au Company URL:   http://www.syd.net.au Primary Contact: Mark Lipscombe          1.22 Consultant ID: Australia, TereDonn Computer Engineering           Suite 1, 128 Bowen St, Spring Hill BRISBANE, ZZ 4004  Australia          Consulting Specialties: CIFS (Samba)  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: Other    Other Distribution: ALL    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +61 7 32369366    Company Fax: +61 7 32369930    Support Phone Number: +61 414 663053  Contact Email Address:   service@tdce.com.au Company URL:   http://www.tdce.com.au Primary Contact: Terence Giufre-Sweetser          1.23 Consultant ID: Australia, WWWalker Web Development           PO Box 288 Wentworthville, NON United States 2145  Australia          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 61-412-405-727    Company Fax: 61-2-97772058    Support Phone Number: 61-412-405727  Contact Email Address:   dwight@zip.com.au Company URL:   http://www.wwwalker.com.au Primary Contact: Dwight Walker          1.24 Consultant ID: Australia, Win International Networking           Lisle Street Mount Claremont, NON United States 6010  Australia          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Other    Other Distribution: Mandrake    Specialty Distribution: Other    Other Specialty Distribution: various/hand tooled    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +61-409-65535-9    Company Fax: Not_Applicable    Support Phone Number: +61-409-65535-9  Contact Email Address:   leon@brooks.smileys.net Company URL:   http://Not_Applicable Primary Contact: Leon Brooks          1.25 Consultant ID: Australia, linsup.com           P. O. Box 689 St. Ives, NON United States 2075  Australia          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: UltraPenguin    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 61 2 9144-6131    Company Fax: 61 2 9144-6138    Support Phone Number: 61 2 9144-6131  Contact Email Address:   info@linsup.com Company URL:   http://www.linsup.com Primary Contact: Richard Ames          1.26 Consultant ID: Austria, Bernhard Zwischenbrugger           Lerchenfeldestrasse 88-90/17 Vienna, NON United States 1080  Austria          Consulting Specialties: CIFS (Samba)  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  System Administration  System Security  Virtual Private Networking       Main Distribution: Suse    Other Distribution: auto install one dis    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +43/1/4022752    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   bzwische@email.archlab.tuwien.ac.at Company URL:   http://Not_Applicable Primary Contact: Bernhard Zwischenbrugger          1.27 Consultant ID: Austria, Bitsniz Data Systems           Kreuzgasse 60 Vienna, NON United States A-1180  Austria          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Compaq  HP       Linux Certifications: Not Applicable       Company Phone Number: +43-(0)1-4065098    Company Fax: +43-(0)1-4065098-99    Support Phone Number: +43-(0)1-4065098-20  Contact Email Address:   office@bitsniz.at Company URL:   http://www.bitsniz.at Primary Contact: Franz  Antonicek          1.28 Consultant ID: Austria, Dialog Data GmbH           Steyrergasse 76 Graz, NON United States A-8010  Austria          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +43(316)810091    Company Fax: +43(316)826348    Support Phone Number: +43(316)810091  Contact Email Address:   support@dialogdata.com Company URL:   http://www.dialogdata.com/ Primary Contact: Norbert Friesl          1.29 Consultant ID: Austria, EDV-Beratung F.Ganter           Liebiggasse 19 Graz, NON United States A-8010  Austria          Consulting Specialties: Custom Systems  Firewalls and Internet Security  Internet (Web) Programming  System Administration       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +43 699 110 21 621    Company Fax: +43 699 310 21 621    Support Phone Number: Not_Applicable  Contact Email Address:   ganter@ganter.at Company URL:   http://www.ganter.at Primary Contact: Fritz Ganter          1.30 Consultant ID: Austria, Horus GmbH           Jakob-Haringer-Strae 8 Salzburg, NON United States A-5020  Austria          Consulting Specialties: CIFS (Samba)  Custom Programming  E-Commerce  Firewalls and Internet Security  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not_Applicable    Linux Certifications: Not_Applicable    Company Phone Number: +43 (0)662 450363-0    Company Fax: +43 (0)662 450363-30    Support Phone Number: +43 (0)662 450363-0  Contact Email Address:   info@horus.com Company URL:   http://www.horus.com Primary Contact: Thomas 'Dune' Freina          1.31 Consultant ID: Austria, LINUX@work           Hauptstr. 99 Hagenberg, NON United States 4232  Austria          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +43 7236 2200    Company Fax: +43 7236 2200 22    Support Phone Number: +43 7236 2200 13  Contact Email Address:   support@linuxatwork.at Company URL:   http://www.linuxatwork.at Primary Contact: Andreas Hupfau          1.32 Consultant ID: Austria, LinzNet           Floetzerweg 150 Linz, NON United States 4030  Austria          Consulting Specialties: CIFS (Samba)  Custom Programming  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  Virtual Private Networking       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +43 732 370700    Company Fax: +43 732 376554    Support Phone Number: +43 732 370700  Contact Email Address:   support@linznet.at Company URL:   http://www.linznet.at Primary Contact: Rainer Skarke          1.33 Consultant ID: Austria, M.T.G. Handelsges.m.b.H.           Raiffeisenstr. 16/9 Zwlfaxing, NON United States 2320  Austria          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: custom distributions    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +43/676/4091256    Company Fax: +43/1/7065299    Support Phone Number: +43/1/7070750  Contact Email Address:   office@mtg.co.at Company URL:   http://https://www.mtg.co.at/ Primary Contact: Andreas Kostyrka          1.34 Consultant ID: Austria, PSI Providing Services for the Internet           Htteldorfer Strae 193/24 Wien, NON United States 1140  Austria          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: Suse    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +43-1-9117757    Company Fax: +43-1-9117757    Support Phone Number: +43-1-9117757  Contact Email Address:   info@psi.co.at Company URL:   http://www.psi.co.at Primary Contact: Raphael Wegmann          1.35 Consultant ID: Austria, communication.center.one           Hetzendorfer Str.23/20 Vienna, ZZ A-1120  Austria          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +43-1-8045753    Company Fax: +43-1-8031553    Support Phone Number: +43-676-477-70-70  Contact Email Address:   support@ccone.at Company URL:   http://www.ccone.at Primary Contact: Gerhard Beck          1.36 Consultant ID: Austria, g.a.m.s. edv-dienstleistungen gmbh           Stiegergasse 15-17/8 Vienna, NON United States 1150  Austria          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +43 1 895 84 99    Company Fax: +43 1 895 84 99 60    Support Phone Number: +43 1 895 84 99  Contact Email Address:   linux@gams.at Company URL:   http://www.gams.at Primary Contact: Andreas Kainz          1.37 Consultant ID: Austria, iDAS           Gasgasse 13/5 Vienna, NON United States A-1150  Austria          Consulting Specialties: CIFS (Samba)  Custom Systems  Internet (Web) Programming  Network Administration  System Administration       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not_Applicable    Linux Certifications: Not_Applicable    Company Phone Number: ++43-664-2630131    Company Fax: ++43-1-8939122-26    Support Phone Number: ++43-664-2630131  Contact Email Address:   office@iDAS.co.at Company URL:   http://www.iDAS.co.at Primary Contact: Thomas Kirchtag          1.38 Consultant ID: Austria, xS+S           Karmarschgasse 51/2/20 Wien, NON United States A-1100  Austria          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security       Main Distribution: Other    Other Distribution: xS+S Linux    Specialty Distribution: Other    Other Specialty Distribution: xS+S Linux    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +43 1 6060114 0    Company Fax: +43 1 6060114 71    Support Phone Number: +43 1 6060114 10  Contact Email Address:   support@xss.co.at Company URL:   http://www.xss.co.at Primary Contact: Andreas Haumer          1.39 Consultant ID: Bangladesh, Information Services Network Limited           52, New Eskaton Road TMC Building(3rd & 4th Floor) Dhaka, NON United States 1000  Bangladesh          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: Other    Other Distribution: Slackware    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 8802842785    Company Fax: 88029345460    Support Phone Number: Not_Applicable  Contact Email Address:   Not_Applicable Company URL:   http://www.bangla.net Primary Contact: Sumon Ahmed Sabir          1.40 Consultant ID: Belgium, Alexandre Dulaunoy, Consultance OpenSource           4, rue d'Aineffe Borlez Faimes, NON United States 4317  Belgium          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: self-made    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 3219566115    Company Fax: 3219567337    Support Phone Number: 3219566115  Contact Email Address:   adulau@unix.be.eu.org Company URL:   http://http://unix.be.eu.org/adulau Primary Contact: Alexandre Dulaunoy          1.41 Consultant ID: Belgium, BARTH Group's           12, rue de l'Espoir Lige, NON United States 4030  Belgium          Consulting Specialties: Custom Programming       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: RedHat       Company Phone Number: 32 4 367.49.16    Company Fax: Not_Applicable    Support Phone Number: Not Available  Contact Email Address:   BARTH.groups@skynet.be Company URL:   http://www.skynet.be Primary Contact: Wathelet Michel          1.42 Consultant ID: Belgium, Better Access NV           Geldenaakse Vest 6 Leuven, NON United States 3000  Belgium          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: Caldera    Specialty Distribution: Other    Other Specialty Distribution: Custombuilt Linux So    Reseller Authorizations: Compaq  HP  Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +32 16 29 80 45    Company Fax: +32 16 29 80 46    Support Phone Number: +32 16 29 80 45  Contact Email Address:   info@ba.be Company URL:   http://www.ba.be Primary Contact: Jan Guldentops          1.43 Consultant ID: Belgium, CompuSense bvba           Mr Vorsselmanslaan 27 Kalmthout, NON United States B 2920  Belgium          Consulting Specialties: CIFS (Samba)  Firewalls and Internet Security  System Administration  System Security       Main Distribution: RedHat    Other Distribution: SuSe    Specialty Distribution: LinuxPPC    Other Specialty Distribution: Sparc Linux    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +32 75 503503    Company Fax: +32 3 6666579    Support Phone Number: +32 75 503503  Contact Email Address:   herman.willekens@skynet.be Company URL:   http://www.skynet.be Primary Contact: Herman Willekens          1.44 Consultant ID: Belgium, CoolNet           rue Croix Claire 67 NANDRIN, NON United States 4550  Belgium          Consulting Specialties: Custom Programming  E-Commerce  Firewalls and Internet Security  Internet Server Development  Network Administration       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +32 75 93 51 71    Company Fax: +32 4 372 01 38    Support Phone Number: Not_Applicable  Contact Email Address:   marc.brocha@coolnet.be Company URL:   http://www.coolnet.be Primary Contact: marc brocha Not_Applicable          1.45 Consultant ID: Belgium, Double Barrel Consultancy & Productions           Sportstraat 28 Gent, ZZ 9000  Belgium          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +32-9-2227764    Company Fax: +32-9-2224976    Support Phone Number: +32-9-2227764  Contact Email Address:   help@double-barrel.be Company URL:   http://www.double-barrel.be Primary Contact: Michael Vergallen          1.46 Consultant ID: Belgium, FD Informatica Consulting           Merellaan 42 Kapellen, NON United States B2950  Belgium          Consulting Specialties: CIFS (Samba)  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +32 (75) 96 04 93    Company Fax: +32 (3) 605 10 56    Support Phone Number: (only on request)  Contact Email Address:   support@denkens.com Company URL:   http://www.denkens.com Primary Contact: Frederik Denkens          1.47 Consultant ID: Belgium, SPIER bvba           Knaptandstraat 96 Sint-Niklaas, NON United States B9100  Belgium          Consulting Specialties: CIFS (Samba)  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  Virtual Private Networking       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Compaq       Linux Certifications: Not Applicable       Company Phone Number: + 32 3 765 90 61    Company Fax: + 32 3 765 90 62    Support Phone Number: + 32 3 765 90 61  Contact Email Address:   support@spier.be Company URL:   http://www.spier.be Primary Contact: Jan Lybeert          1.48 Consultant ID: Belgium, VirgoPlus           Rue Dartois, 1 Lige, NON United States 4000  Belgium          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +32-4-253 00 59    Company Fax: +32-4-253 00 49    Support Phone Number: +32-4-253 00 85  Contact Email Address:   bruno@virgoplus.com Company URL:   http://www.virgoplus.com Primary Contact: Christophe Ozer          1.49 Consultant ID: Belgium, information technology partners           Klokhof 2 Heusden-Zolder, NON United States 3550  Belgium          Consulting Specialties: E-Commerce  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration       Main Distribution: RedHat    Other Distribution: Suse/Caldera    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +32 11 53 77 53    Company Fax: +32 11 53 77 17    Support Phone Number: +32 11 53 77 53  Contact Email Address:   guy.dillen@skynet.be Company URL:   http://www.skynet.be Primary Contact: Guy Dillen          1.50 Consultant ID: Brazil, 4Web Internet           R. James Watt, 142 - Cj 42 Sao Paulo, NON United States 04576-050  Brazil          Consulting Specialties: E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 55-11-5506-6844    Company Fax: 55-11-5506-6844    Support Phone Number: 55-11-5506-6844  Contact Email Address:   esaito@4web.com.br Company URL:   http://www.4web.com.br Primary Contact: Eduardo Saito          1.51 Consultant ID: Brazil, Abner Graham Jacobsen           Rua Bruno Becacici, 107 Vitoria, NON United States 29042-0320  Brazil          Consulting Specialties: CIFS (Samba)  E-Commerce  Firewalls and Internet Security  Netware Connectivity  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: Conectiva    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 55 027 322-1837    Company Fax: 55 027 223-0562    Support Phone Number: Not Available  Contact Email Address:   ajacobsen@interlink.com.br Company URL:   http://www.interlink.com.br Primary Contact: Not_Applicable Not_Applicable          1.52 Consultant ID: Brazil, Dextra Solucoes em Informatica           Av Jose Souza Campos 1815/1205 Campinas, NON United States 13025-320  Brazil          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +55-19-251-3644    Company Fax: +55-19-253-3742    Support Phone Number: NA  Contact Email Address:   consultoria@dextra.com.br Company URL:   http://www.dextra.com.br Primary Contact: Bill Coutinho          1.53 Consultant ID: Brazil, Dextra Solucoes           Av J Souza Campos 1815 cj 1205 Campinas, NON United States 13025-320  Brazil          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 55 19 251-3644    Company Fax: 55 19 253-3742    Support Phone Number: 55 19 251-3644  Contact Email Address:   consultoria@dextra.com.br Company URL:   http://www.dextra.com.br Primary Contact: Bill Coutinho          1.54 Consultant ID: Brazil, Fernando Mauro Martins           Rua Padre Justino, 44 So Paulo, NON United States 05580-090  Brazil          Consulting Specialties: Custom Programming       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: none    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +55 11 814-5679    Company Fax: na    Support Phone Number: +55 11 814-5679  Contact Email Address:   lalo@webcom.com Company URL:   http://www.webcom.com Primary Contact: Fernando Martins          1.55 Consultant ID: Brazil, INFOX Sistemas e Computadores Ltda           Rua Boquim, 97 - 1. andar Aracaju, NON United States 49.010-280  Brazil          Consulting Specialties: System Administration       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 55-79-211-5122    Company Fax: 55-79-211-0783    Support Phone Number: Not_Applicable  Contact Email Address:   infox@infox.com.br Company URL:   http://www.infox.com.br Primary Contact: Fred Silva          1.56 Consultant ID: Brazil, Kernel LinuxRO           Rua Jacaranda, 910 - Fundos Porto Velho, NON United States 78912-570  Brazil          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: CONECTIVA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +55699844175    Company Fax: +55692273741    Support Phone Number: +55699844175  Contact Email Address:   jbs@portovelho.br Company URL:   http://Not_Applicable Primary Contact: Joao Silva          1.57 Consultant ID: Brazil, Lumina Informatica Ltda           Caixa Postal 1393 Blumenau, NON United States 89010-971  Brazil          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet (Web) Programming  Network Administration  System Administration  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: IBM       Linux Certifications: Not Applicable       Company Phone Number: +55 47 329-0065    Company Fax: +55 47 329-0091    Support Phone Number: +55 47 329-0065  Contact Email Address:   lumina@luminainfo.com.br Company URL:   http://www.luminainfo.com.br Primary Contact: Odilon Mader Netto          1.58 Consultant ID: Brazil, Millennium Consultoria e Informtica Ltda.           758, R. Francisco Parolin Curitiba, NON United States 80.220-360  Brazil          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +55-41-333-5645    Company Fax: +55-41-333-5645    Support Phone Number: +55-41-913-2316 / +5  Contact Email Address:   millennium@millennium.etc.br Company URL:   http://www.millennium.etc.br Primary Contact: Andr A. C. Santos          1.59 Consultant ID: Brazil, Onlinet Com. Serv. de Informtica Ltda.           R. Par, 35 - Cid, Industrial Lorena, NON United States 12600-000  Brazil          Consulting Specialties: Internet Server Development       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: UltraPenguin    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +55 (012) 553-1234    Company Fax: +55 (012) 553-2568    Support Phone Number: +55 (012) 553-1234  Contact Email Address:   suporte@onlinet.com.br Company URL:   http://www.onlinet.com.br Primary Contact: Denys Sene          1.60 Consultant ID: Brazil, Pragana, Filhos E Cia Ltda           CxPostal 721 CDC Aldeia Camaragibe, NON United States 54792-990  Brazil          Consulting Specialties: Custom Programming       Main Distribution: Other    Other Distribution: Slackware    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 55-81-459-1776    Company Fax: 55-81-459-1776    Support Phone Number: Not_Applicable  Contact Email Address:   rpragana@acm.org Company URL:   http://Not_Applicable Primary Contact: Rildo Pragana          1.61 Consultant ID: Brazil, Rodrigo Barbosa           Phone or e-mail contact prefered Santa Rita do Sapucai, NON United States 37540-000  Brazil          Consulting Specialties: CIFS (Samba)  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 55-35-9982-0006    Company Fax: Not_Applicable    Support Phone Number: 55-35-9982-0006  Contact Email Address:   rodrigob@linuxbr.com.br Company URL:   http://Not_Applicable Primary Contact: Rodrigo Barbosa          1.62 Consultant ID: Brazil, TELEMATICA Coml. de Teleinformtica Ltda.           R. Princesa Isabel, 211 Pelotas, NON United States 96015-590  Brazil          Consulting Specialties: CIFS (Samba)  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: Other    Other Distribution: Conectiva Linux    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +55 532 27-7266    Company Fax: +55 532 27-7972    Support Phone Number: +55 532 27-7266  Contact Email Address:   telematica@conesul.com.br Company URL:   http://Not_Applicable Primary Contact: Vagner Farias          1.63 Consultant ID: Brazil, VisualBook           161, Hipolito da Costa  Rio de Janeiro, NON United States 20551040  Brazil          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 55021-8720623    Company Fax: 55021-872-0576    Support Phone Number: 55021-2040333  Contact Email Address:   vb@visualbook.com.br Company URL:   http://www.visualbook.com.br Primary Contact: Luiz Medeiros          1.64 Consultant ID: Brazil, aIPiWorks Network Consulting           R. Conceicao 233, Sala 1514, Ed. Centro Emp. ENCOL Campinas, NON United States 13010-000  Brazil          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Other    Other Distribution: RedHat / Mandrake /     Specialty Distribution: Other    Other Specialty Distribution: Mandrake / RedHat    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 055-19-2281876    Company Fax: 055-19-2281876    Support Phone Number: 055-019-2281876  Contact Email Address:   info@aipiworks.com.br Company URL:   http://www.aipiworks.com.br Primary Contact: Mario R. Williams          1.65 Consultant ID: Brazil, iSNet Servios de Informatica           Av. Othon Gama d'Ea, 900/704 Florianopolis, NON United States 88015-240  Brazil          Consulting Specialties: E-Commerce       Main Distribution: Other    Other Distribution: Conectiva    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: RedHat       Company Phone Number: +55 48 322-0249    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   info@isnet.com.br Company URL:   http://www.isnet.com.br Primary Contact: Paulo Santos          1.66 Consultant ID: Bulgaria, University of Mining and Geology, Dept. Computer S           Studentski Grad Sofia, NON United States 1700  Bulgaria          Consulting Specialties: Custom Programming  Custom Systems  Firewalls and Internet Security  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: Other    Other Distribution: Slackware    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +359 2 62581 /ext.56    Company Fax: +359 2    Support Phone Number: +359 2 62581 /ext.56  Contact Email Address:   support@mgu.bg Company URL:   http://www.mgu.bg Primary Contact: Volin Karagiozov          1.67 Consultant ID: Canada, 4 Office Automation           375 Britannia Road East Mississauga, ON L4Z 3E2  Canada          Consulting Specialties: CIFS (Samba)       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: HP       Linux Certifications: Not Applicable       Company Phone Number: 1-416-463-3423    Company Fax: 1-905-501-1515    Support Phone Number: 1-416-463-3423  Contact Email Address:   hyeung@4office.com Company URL:   http://www.4office.com Primary Contact: Hillman Yeung          1.68 Consultant ID: Canada, 8D Technologies inc.           Pobox 778 Hudson, PQ J0P1H0  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 514.994.2645    Company Fax: 514.994.2654    Support Phone Number: 514.994.2645  Contact Email Address:   info@8D.com Company URL:   http://www.8D.com Primary Contact: Patrick Bernard          1.69 Consultant ID: Canada, ADR Computing           5-1115 West 10th Avenue Vancouver, BC V6H 1J2  Canada          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 1 604 202 2800    Company Fax: Not_Applicable    Support Phone Number: 1 604 202 2800  Contact Email Address:   support@adrcomp.com Company URL:   http://www.adrcomp.com Primary Contact: Chris Airriess          1.70 Consultant ID: Canada, Affinity Systems Inc.           Box 10, RR1 Innisfail, AB T4G 1T6  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 1-403-886-4638    Company Fax: 1-403-886-2663    Support Phone Number: 1-403-886-4638  Contact Email Address:   support@affinity-systems.ab.ca Company URL:   http://www.affinity-systems.ab.ca Primary Contact: James Bourne          1.71 Consultant ID: Canada, Allt Computer Consulting           170 Willow Rd. Guelph, ON N1H 1W8  Canada          Consulting Specialties: CIFS (Samba)  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 519 763-0405    Company Fax: 508 448-0716    Support Phone Number: n/a  Contact Email Address:   allt@netloads.com Company URL:   http://www.netloads.com/allt Primary Contact: Greg Allt          1.72 Consultant ID: Canada, Best Computers           10610 170 St  Edmonton, AB T5S-1P3  Canada          Consulting Specialties: CIFS (Samba)  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: SuSE, Debian    Specialty Distribution: Other    Other Specialty Distribution: Secured Linux    Reseller Authorizations: HP       Linux Certifications: Not Applicable       Company Phone Number: 780-413-9830    Company Fax: 780-413-9831    Support Phone Number: 780-413-9830  Contact Email Address:   support@best-comp.com Company URL:   http://http://www.best-comp.com/ Primary Contact: Kurt Seifried          1.73 Consultant ID: Canada, CAL Consultants Inc.           358 Danforth Ave., Suite 29 Toronto, ON M4K 3Z2  Canada          Consulting Specialties: E-Commerce  Internet Server Development  Network Administration       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Compaq  HP       Linux Certifications: Not_Applicable    Company Phone Number: 01.416.461.7634    Company Fax: 01.416.461.6908    Support Phone Number: 01.416.461.7634  Contact Email Address:   support@cal.ca Company URL:   http://www.cal.ca Primary Contact: Graydon Clipperton          1.74 Consultant ID: Canada, Centurion Services           9351 Blundell Road Richmond, BC V6Y 1K5  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Netware Connectivity  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: IBM       Linux Certifications: Not_Applicable    Company Phone Number: 1-604-279-1857    Company Fax: 1-604-279-1800    Support Phone Number: 1-604-720-1857  Contact Email Address:   jwalter@rogers.wave.ca Company URL:   http://www.rogers.wave.ca Primary Contact: Mr. Jan Walter          1.75 Consultant ID: Canada, Chris Newton           254 Barton Fredericton, NB e3a 5a6  Canada          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: UltraPenguin    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 506-474-0454    Company Fax: Not_Applicable    Support Phone Number: 506-474-0454  Contact Email Address:   newton@unb.ca Company URL:   http://Not_Applicable Primary Contact: Chris Newton          1.76 Consultant ID: Canada, Computing And Networking Centre           POBOX 28117 Dartmouth/Halifax, NS B2W6E2  Canada          Consulting Specialties: Network Administration       Main Distribution: Other    Other Distribution: Slackware    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 902-465-3734    Company Fax: 902-465-3734    Support Phone Number: 902-465-3734  Contact Email Address:   cnc98@sprint.ca Company URL:   http://Not_Applicable Primary Contact: Ahmed  Bentiba          1.77 Consultant ID: Canada, DFC International Computers Inc.           52 Mowatt Court Thornhill, ON L3T 6V5  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: UltraPenguin    Other Specialty Distribution: NA    Reseller Authorizations: Compaq  IBM       Linux Certifications: RedHat  Not Applicable       Company Phone Number: (905)731-6449    Company Fax: (905)731-7684    Support Phone Number: (905)731-6449  Contact Email Address:   support@dfc.com Company URL:   http://www.dfc.com Primary Contact: David Fitzerman          1.78 Consultant ID: Canada, DFC International Computing Inc.           52 Mowatt Court Thornhill, ON L3T 6V5  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: Not_Applicable    Specialty Distribution: UltraPenguin    Other Specialty Distribution: Not_Applicable    Reseller Authorizations: Compaq  HP  IBM       Linux Certifications: RedHat       Company Phone Number: (905)731-6449    Company Fax: (905)731-7684    Support Phone Number: (905)731-6449  Contact Email Address:   support@dfc.com Company URL:   http://www.dfc.com Primary Contact: David Fitzerman          1.79 Consultant ID: Canada, DPD Software Ltd           1455 Waverly St Winnipeg, MB R2W 0RY  Canada          Consulting Specialties: Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: Slak    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: IBM       Linux Certifications: RedHat       Company Phone Number: 204-489-4398    Company Fax: 204-489-4398    Support Phone Number: 204-489-4398  Contact Email Address:   kevind@dpdsoftware.mb.ca Company URL:   http://www.dpdsoftware.mb.ca Primary Contact: Kevin Druet          1.80 Consultant ID: Canada, Diminishing Networks           5330 Entwhistle Dr Nanaimo, BC V9V 1H2  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 1(250) 758-2217    Company Fax: 1(250) 758-2217    Support Phone Number: Not_Applicable  Contact Email Address:   tech@mymail.penguinpowered.com Company URL:   http://www.soatusa.com/DimNet/ Primary Contact: Adam Jordens          1.81 Consultant ID: Canada, G Desktop Solutions           2037 Decarie Blvd #1 Montreal, PQ H4A 3J2  Canada          Consulting Specialties: Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: (514) 996-5153    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   gldesk@gomer.mlink.net Company URL:   http://gomer.mlink.net/~gldesk/ Primary Contact: Greg Patterson          1.82 Consultant ID: Canada, Gedris Linux Consulting           183 St. Andrew Street Ottawa, ON K1N 5G3  Canada          Consulting Specialties: Custom Programming  Internet Server Development  Internet (Web) Programming  System Administration       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: (613)562-0628    Company Fax: Not_Applicable    Support Phone Number: (613)562-0628  Contact Email Address:   vic@worldchat.com Company URL:   http://www.worldchat.com Primary Contact: Victor Gedris          1.83 Consultant ID: Canada, Global Proximity Corporation           RR 7 Woodstock, ON N4S 7W2  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not_Applicable    Linux Certifications: Not_Applicable    Company Phone Number: +1 519 469 3439    Company Fax: +1 519 469 8653    Support Phone Number: +1 519 469 3439  Contact Email Address:   Support@Global.Proximity.ON.CA Company URL:   http://www.Global.Proximity.ON.CA Primary Contact: Chris Tyler          1.84 Consultant ID: Canada, HK Computer Consultants           35 Chalmers Drive Ajax, NON United States l155w8  Canada          Consulting Specialties: Custom Programming  Custom Systems  Network Administration  System Administration       Main Distribution: Caldera    Other Distribution: Slackware    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 905-619-6888    Company Fax: Not_Applicable    Support Phone Number: 905-619-6888  Contact Email Address:   hallamh@excite.com Company URL:   http://Not_Applicable Primary Contact: Hallam  Holder          1.85 Consultant ID: Canada, Hard Data Ltd.           11060 - 166 Avenue Edmonton, AB T5X 1Y3  Canada          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Other    Other Distribution: ALL    Specialty Distribution: Other    Other Specialty Distribution: Hard Hat Linux    Reseller Authorizations: Compaq  HP       Linux Certifications: Not Applicable       Company Phone Number: 01-780-456-9771    Company Fax: 01-780-456-9772    Support Phone Number: 01-780-456-1510  Contact Email Address:   support@harddata.com Company URL:   http://www.harddata.com Primary Contact: Maurice Hilarius          1.86 Consultant ID: Canada, ITPS Groupe Inc.           350 Price Arthur Apt.810 Montreal, PQ H2X 3R4  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Internet Server Development  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not_Applicable    Linux Certifications: RedHat       Company Phone Number: (514) 286-1354    Company Fax: (514) 286-4827    Support Phone Number: (514)-821-1568  Contact Email Address:   Boris.Kuschel@itpsgroup.com Company URL:   http://http://www.itpsgroup.com/ Primary Contact: Boris Kuschel          1.87 Consultant ID: Canada, JDP Computer Systems Inc.           206 Finch Ave. East Toronto, ON L9W 3S9  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 1-416-733-3655    Company Fax: 1-416-733-1839    Support Phone Number: 1-416-733-3655  Contact Email Address:   support@jdp.com Company URL:   http://www.jdp.com Primary Contact: Gordon Gray          1.88 Consultant ID: Canada, Jeff Tranter           1 Laurie Court Kanata, ON K2L 1S2  Canada          Consulting Specialties: Custom Programming  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  System Administration       Main Distribution: Other    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +1 613 836 7697    Company Fax: Not_Applicable    Support Phone Number: +1 613 836 7697  Contact Email Address:   tranter@pobox.com Company URL:   http://www.pobox.com/~tranter Primary Contact: Jeff Tranter          1.89 Consultant ID: Canada, LeadSource Consultants Inc.           1227 Mississauga Road Mississauga, ON L5H 2J1  Canada          Consulting Specialties: CIFS (Samba)  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Other    Other Distribution: slackware    Specialty Distribution: LinuxRouter    Other Specialty Distribution: HoNet    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 905 278 6808    Company Fax: 905 278 6863    Support Phone Number: 905 278 6808  Contact Email Address:   support@leadsource.ca Company URL:   http://http://www.leadsource.ca Primary Contact: Adam Mikolajewicz          1.90 Consultant ID: Canada, Logisoft Technologies inc           718 pl Denise-pelletier Ste-Julie, PQ J3E 2G8  Canada          Consulting Specialties: CIFS (Samba)  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: Mandrake    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: (514) 570-7638    Company Fax: Not_Applicable    Support Phone Number: (514) 580-0050  Contact Email Address:   support@logisoftech.com Company URL:   http://www.logisoftech.com Primary Contact: Guillaume Bourque          1.91 Consultant ID: Canada, MOE Online Enterprises           50 Stephanie, Suite 1008 Toronto, ON M5T1B3  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +1 416 588 0672    Company Fax: Not_Applicable    Support Phone Number: n/a  Contact Email Address:   mozai@canada.com Company URL:   http://ativan.netdesign.net/~moses/ Primary Contact: Moses Moore          1.92 Consultant ID: Canada, Macadamian Technologies Inc.           700 Industrial Avenue Suite 220  Ottawa, ON K1G 0Y9  Canada          Consulting Specialties: Custom Programming  Internet (Web) Programming       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 1-877-7-SYNDEO    Company Fax: 1-613-739-9859    Support Phone Number: 1-877-7-SYNDEO  Contact Email Address:   info@macadamian.com Company URL:   http://www.macadamian.com Primary Contact: Claude Montpetit          1.93 Consultant ID: Canada, Mediabase           3 shenstone rd, (changing soon) North York, ON m2r 3b3 (changi  Canada          Consulting Specialties: CIFS (Samba)  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  System Security  Virtual Private Networking       Main Distribution: Other    Other Distribution: Slackware 4.0    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 4164685400    Company Fax: na    Support Phone Number: Not_Applicable  Contact Email Address:   mediabase@ihosts.net Company URL:   http://www.mediabase.ihosts.net Primary Contact: Cyrus Hill          1.94 Consultant ID: Canada, Minek Consulting Inc.           B403-1331 Homer St. Vancouver, BC V6B 5M5  Canada          Consulting Specialties: Custom Programming       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 1-604-3185875    Company Fax: 1-604-899-2492    Support Phone Number: 1-604-3185875  Contact Email Address:   support@minek.com Company URL:   http://www.minek.com Primary Contact: Dan Rokosz          1.95 Consultant ID: Canada, Montage IT Services           350, 708 - 11 Ave. SW Calgary, AB T2R0E4  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: All    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 01.403.265.4461    Company Fax: 01.403.265.4462    Support Phone Number: Not_Applicable  Contact Email Address:   dboyd@cal.montage.ca Company URL:   http://www.montage.ca Primary Contact: Darren Boyd          1.96 Consultant ID: Canada, MostlyLinux           Not_Applicable Calgary, AB Not_Applicable  Canada          Consulting Specialties: CIFS (Samba)  Custom Systems  Network Administration  System Administration  System Security       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: Small Business serve    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 403-285-1399    Company Fax: Not_Applicable    Support Phone Number: Not Available  Contact Email Address:   Not_Applicable Company URL:   http://Not_Applicable Primary Contact: Scott Barker          1.97 Consultant ID: Canada, Net Direct Inc.           557 Havelock Dr. Waterloo, ON N2L 4Z1  Canada          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: None    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 519-579-5006    Company Fax: 519-745-9940    Support Phone Number: 519-579-5006  Contact Email Address:   support@netdirect.ca Company URL:   http://www.net.direct.ca Primary Contact: John Van Ostrand          1.98 Consultant ID: Canada, Pilkington Software Inc.           1046 Barrington St Halifax, NS B3H 2R1  Canada          Consulting Specialties: Custom Programming  Custom Systems       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 902 423 6033    Company Fax: 902 423 6033    Support Phone Number: 902 423 6033  Contact Email Address:   support@cpsoft.com Company URL:   http://www.cpsoft.com Primary Contact: Charles Pilkington          1.99 Consultant ID: Canada, Pryor and Pryor Inc.           602 - 1230 Comox Street Vancouver, BC V6E 1K7  Canada          Consulting Specialties: Custom Programming       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 604-685-2621    Company Fax: 604-683-3488    Support Phone Number: Not Available  Contact Email Address:   Not_Applicable Company URL:   http://http://www.pryor-and-pryor.com Primary Contact: Roger Pryor          1.100 Consultant ID: Canada, Quist Consulting           219 Donlea Drive Toronto, ON M4G2N1  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: Debian    Specialty Distribution: LinuxRouter    Other Specialty Distribution: UltraPenguin    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 1.416.696.7600    Company Fax: 1.416.978.6620    Support Phone Number: 1.416.696.7600  Contact Email Address:   russ@quist.on.ca Company URL:   http://www.quist.on.ca Primary Contact: Russell Suherland          1.101 Consultant ID: Canada, Real-Time Remedies Inc.           33 Ridgefield Crescent Nepean, ON K2H 6S3  Canada          Consulting Specialties: Custom Systems  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: Intel x86 and NetWin    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 613-277-4944    Company Fax: 616-828-9659    Support Phone Number: Not_Applicable  Contact Email Address:   mlord@pobox.com Company URL:   http://Not_Applicable Primary Contact: Mark Lord          1.102 Consultant ID: Canada, Roaring Penguin Software Inc.           986 Eiffel Avenue Ottawa, ON K2C 0J2  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration       Main Distribution: Other    Other Distribution: Any distro    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 613 851-4379    Company Fax: Not_Applicable    Support Phone Number: Not Available  Contact Email Address:   Not_Applicable Company URL:   http://Not_Applicable Primary Contact: David Skoll          1.103 Consultant ID: Canada, Salmar Consulting Inc.           P.O. Box 52531, 1801 Lakeshore Road West Mississauga, ON L5J 4S6  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: All    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 905-403-8835    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   info@salmar.com Company URL:   http://www.salmar.com Primary Contact: Marcel Gagne          1.104 Consultant ID: Canada, Soft Touch Computers           Not_Applicable Calgary, AB Not_Applicable  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: SUSE    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not_Applicable    Linux Certifications: Not Applicable       Company Phone Number: (403)259-6016    Company Fax: (403)258-0267    Support Phone Number: (403)259-6016  Contact Email Address:   admin@softouchcomputer.com Company URL:   http://www.softouchcomputer.com Primary Contact: Al Green          1.105 Consultant ID: Canada, Stable Network Technologies Inc.           141 Adelaide Street West, Suite 1200 Toronto, ON M5H 3L5  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Virtual Private Networking       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 1 416 367 2745    Company Fax: 1 416 861 0650    Support Phone Number: Not_Applicable  Contact Email Address:   support@snti.com Company URL:   http://www.snti.com Primary Contact: David Kerry          1.106 Consultant ID: Canada, Steve Willer           1544A Queen St. W. Toronto, ON M6R1A6  Canada          Consulting Specialties: Custom Programming  E-Commerce  Internet Server Development  Internet (Web) Programming       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 416-516-8470    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   Not_Applicable Company URL:   http://www.interlog.com/~willer/ Primary Contact: Steve Willer          1.107 Consultant ID: Canada, Technical Consulting Group           25 - 52061 - RR215 Sherwood Park, AB T8E-1B2  Canada          Consulting Specialties: CIFS (Samba)  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: Linux on Alpha    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 780-922-5755    Company Fax: 780-922-6990    Support Phone Number: Not_Applicable  Contact Email Address:   ken.gehring@gov.ab.ca Company URL:   http://Not_Applicable Primary Contact: Ken Gehring          1.108 Consultant ID: Canada, TeleDynamics Communications Inc           7 Forest Place RR#1 Sauble Beach, ON N0H 2G0  Canada          Consulting Specialties: Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not_Applicable    Linux Certifications: Not_Applicable    Company Phone Number: 519-422-1150    Company Fax: 519-422-2723    Support Phone Number: Not Available  Contact Email Address:   teledynamics@canada.com Company URL:   http://http://www.teledyn.com Primary Contact: Gary Murphy          1.109 Consultant ID: Canada, The Net Result           #10 3450 Coast Meridian Rd Port Coquitlam, BC V3B7H2  Canada          Consulting Specialties: Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: Caldera    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: RedHat       Company Phone Number: 604 942 7257    Company Fax: 604 942 7440    Support Phone Number: Not_Applicable  Contact Email Address:   support@result.com Company URL:   http://Not_Applicable Primary Contact: Jay Thorne          1.110 Consultant ID: Canada, The People's Linux           109-288 East 14th Avenue Vancouver, BC V5T 2M6  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Caldera    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 604-709-9512    Company Fax: 604-709-9512    Support Phone Number: 604-709-9512  Contact Email Address:   fred@nuge.com Company URL:   http://http://www.linuxnut.com Primary Contact: Bob  Strasser          1.111 Consultant ID: Canada, Troika Management Services           Unit 4 - 40 Fairfax Court London, NON United States N6G3Y3  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration       Main Distribution: Other    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 1-519-670-4567    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   xbill@xbill.com Company URL:   http://www.xbill.com Primary Contact: William McLean          1.112 Consultant ID: Canada, Troy Ryder           3665 Luxmoore Road Kelowna, BC V1W 4C7  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: Not_Applicable    Specialty Distribution: LinuxRouter    Other Specialty Distribution: Not_Applicable    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 250-764-0917    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   ryder@direct.ca Company URL:   http://www.vanisle.net/ryder Primary Contact: Troy Ryder Not_Applicable          1.113 Consultant ID: Canada, VL           221 BRitannia Ottawa, ON K2B - 5X1  Canada          Consulting Specialties: System Security       Main Distribution: RedHat    Other Distribution: Caldera    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not_Applicable    Linux Certifications: Not_Applicable    Company Phone Number: 1 (613) 292-9818    Company Fax: 1 (613) 829-0967    Support Phone Number: Not Available  Contact Email Address:   Not_Applicable Company URL:   http://Not_Applicable Primary Contact: Hung Vu          1.114 Consultant ID: Canada, Webcon, Inc.           70 Forest Hill Ave. Ottawa, ON K2C 1P6  Canada          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: Not_Applicable    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +1 613 276 6206    Company Fax: +1 613 276 8206    Support Phone Number: +1 613 276 6206  Contact Email Address:   tech@webcon.net Company URL:   http://www.webcon.net Primary Contact: Robert Hardy          1.115 Consultant ID: Canada, iNsu Innovations           3465 Thimmens St-Laurent, PQ H4R 1V5  Canada          Consulting Specialties: E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 514-336-5544    Company Fax: 514-336-8128    Support Phone Number: 514-336-5544  Contact Email Address:   support@insu.com Company URL:   http://www.insu.com Primary Contact: Joel Pomerleau          1.116 Consultant ID: Colombia, Linux Colombia Ltda           Avenida 5AN 23DN68 Oficina 2-118B Cali, NON United States Not_Applicable  Colombia          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Netware Connectivity  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: UltraPenguin    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 57 2 6607908    Company Fax: 57 2 6676596    Support Phone Number: 57 2 6607908  Contact Email Address:   linuxcol@linuxcolombia.com.co Company URL:   http://www.linuxcolombia.com.co Primary Contact: Juan Diego Bolaos Ramirez          1.117 Consultant ID: Colombia, Msoft           Cra 24 No 80-52 Apto G-201 Bucaramanga, NON United States 212  Colombia          Consulting Specialties: CIFS (Samba)  Internet Server Development  Netware Connectivity  Network Administration       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: ++57-7-6384935    Company Fax: ++57-7-6389374    Support Phone Number: ++57-7-6313428  Contact Email Address:   nelsonmauriciosilva@yahoo.com Company URL:   http://Not_Applicable Primary Contact: Mauricio Silva          1.118 Consultant ID: Colombia, Skina Ltda.           Calle 95 #30-61 int 8 Santafe de Bogota, NON United States Not_Applicable  Colombia          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 5712565008    Company Fax: 5712565008    Support Phone Number: cel: 2059620  Contact Email Address:   skina@skina.com.co Company URL:   http://www.skina.com.co Primary Contact: Ricardo Naranjo_Faccini          1.119 Consultant ID: Czech Republic, Martin Knotek, poskytovani software           Havelkova 23 Brno, NON United States 625 00  Czech Republic          Consulting Specialties: Custom Programming  Custom Systems  System Administration       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 420 5 356605    Company Fax: Not_Applicable    Support Phone Number: 420 5 356605  Contact Email Address:   knotekmartin@email.cz Company URL:   http://www.email.cz Primary Contact: Martin Knotek          1.120 Consultant ID: Denmark, Arnecke Informatik           Havnegade 4 Odense, NON United States 5100  Denmark          Consulting Specialties: CIFS (Samba)  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +45 63130050    Company Fax: +45 63130051    Support Phone Number: +45 63130050  Contact Email Address:   info@a-info.dk Company URL:   http://www.a-info.dk Primary Contact: Allan Hansen          1.121 Consultant ID: Denmark, Dansk Data Elektronik A S           Herlev Hovedgade 199 Herlev, NON United States 2730  Denmark          Consulting Specialties: Custom Systems       Main Distribution: Other    Other Distribution: Any well known Linux    Specialty Distribution: Other    Other Specialty Distribution: Not_Applicable    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +45 44572000    Company Fax: +45 44572001    Support Phone Number: +45 44572010  Contact Email Address:   support@dde.dk Company URL:   http://www.dde.dk Primary Contact: Jens Knudsen          1.122 Consultant ID: Denmark, Plomus           Nddelunden 110 Smrum, NON United States DK-2765  Denmark          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Caldera    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +45 44 66 24 16    Company Fax: +45 44 66 25 16    Support Phone Number: +45 44 66 25 16  Contact Email Address:   support@plomus.dk Company URL:   http://www.plomus.dk Primary Contact: Claus Srensen          1.123 Consultant ID: Dominican Republic, microbell           jesus maestr 18, suite A3, mirador sur santo domingo, ZZ 0000  Dominican Republic          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 809 383 2613    Company Fax: 809 540 4025    Support Phone Number: 809 383 2613  Contact Email Address:   microbell@microbell.com.do Company URL:   http://microbell.com.do Primary Contact: homero gonzalez          1.124 Consultant ID: Egypt, AB2           29 Alexander the Great St. Alexandria, NON United States 21131  Egypt          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: Slackware    Specialty Distribution: Other    Other Specialty Distribution: Intel    Reseller Authorizations: Not Applicable       Linux Certifications: Not_Applicable    Company Phone Number: +20 3 482 4756    Company Fax: +20 3 483 5030    Support Phone Number: Not Available  Contact Email Address:   Not_Applicable Company URL:   http://www.ab2.com Primary Contact: Khalid Baheyeldin          1.125 Consultant ID: Finland, Netsol Network Solutions Oy           Hiihtotie 3 A Vantaa, NON United States 01280  Finland          Consulting Specialties: Custom Systems  Firewalls and Internet Security  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Compaq  HP  IBM  Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +358 9 34090410    Company Fax: +358 9 34090404    Support Phone Number: +358 9 34090410  Contact Email Address:   support@netsol.fi Company URL:   http://www.netsol.fi Primary Contact: Timo Virtaneva          1.126 Consultant ID: Finland, SOT Finnish Sofware Engineering Ltd.           Hermiankatu 8 E TAMPERE, NON United States 33720  Finland          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Other    Other Distribution: Best Linux    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +358-3-316 5544    Company Fax: +358-3-316 5959    Support Phone Number: 0600-95549  Contact Email Address:   linux@bestlinux.net Company URL:   http://www.sot.com Primary Contact: Santeri Kannisto Kai Valijrvi          1.127 Consultant ID: Finland, Tmi Netics Konsultointi           Etelniityntie 6 MUSTASAARI, NON United States FIN-65610  Finland          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration       Main Distribution: Other    Other Distribution: Slackware    Specialty Distribution: Other    Other Specialty Distribution: planned with custome    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +358 50 501 2132    Company Fax: Not_Applicable    Support Phone Number: +358 50 501 2132  Contact Email Address:   juhani.puska@netics.fi Company URL:   http://www.netics.fi Primary Contact: Juhani Puska          1.128 Consultant ID: France, ALCOVE           12 - 13 place Indira Gandhi Gennevilliers, NON United States 92230  France          Consulting Specialties: CIFS (Samba)  Custom Programming  E-Commerce  Firewalls and Internet Security  Internet Server Development  System Administration  System Security  Virtual Private Networking       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +33 1 47 33 82 84    Company Fax: +33 1 47 33 76 98    Support Phone Number: Not Available  Contact Email Address:   Not_Applicable Company URL:   http://Not_Applicable Primary Contact: Anne Collet          1.129 Consultant ID: France, Alcove           12-13 place Indira Gandhi Gennevilliers, NON United States 92230  France          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 33147338284    Company Fax: 33147337698    Support Phone Number: Not_Applicable  Contact Email Address:   assistance@alcove.fr Company URL:   http://www.alcove.fr Primary Contact: Anne Collet          1.130 Consultant ID: France, CRAO           19, rue Forcrand Montpellier, NON United States 34000  France          Consulting Specialties: Custom Systems  E-Commerce  Internet Server Development  Internet (Web) Programming       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +33 4 67 63 24 27    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   crao@crao.net Company URL:   http://crao.net Primary Contact: Arnaud Fontaine          1.131 Consultant ID: France, EBC Consulting           16, rue des sorbiers SORBEY, NON United States 57580  France          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security       Main Distribution: Other    Other Distribution: client specific    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +33 (0) 3. 87.64.58.    Company Fax: +33 (0) 3. 87.64.58.    Support Phone Number: +33 (0) 3. 87.64.58.  Contact Email Address:   ebconsul@altavista.net Company URL:   http://www.ebcip.fr Primary Contact: Eric Binger          1.132 Consultant ID: France, Hubert Gregoire           118, avenue Gambetta PARIS, NON United States 75020  France          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +33 (0) 140312326    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   hubert@dune-concept.com Company URL:   http://dune-concept.com Primary Contact: Hubert  Gregoire          1.133 Consultant ID: France, NTCD           11 rue A. Carrel PARIS, ZZ 75019  France          Consulting Specialties: Custom Programming  Custom Systems  Internet Server Development  Internet (Web) Programming  System Administration       Main Distribution: RedHat    Other Distribution: Not_Applicable    Specialty Distribution: Other    Other Specialty Distribution: Debian    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 33 1 40 40 77 09    Company Fax: 33 1 40 40 77 09    Support Phone Number: none  Contact Email Address:   http://www.ntcd.com/hotline/index.htm Company URL:   http://ntcd Primary Contact: Didier Blanchard          1.134 Consultant ID: France, Paralline           71, avenue des Vosges STRASBOURG, NON United States 67000  France          Consulting Specialties: Custom Systems       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 33 3 88 14 17 40    Company Fax: 33 3 88 14 17 41    Support Phone Number: 33 3 88 14 17 40  Contact Email Address:   support@paralline.com Company URL:   http://www.paralline.com Primary Contact: Pierre BRUA          1.135 Consultant ID: France, Paul Boyer Consultants Sarl           20 rue d'Hauteville Paris, NON United States 75010  France          Consulting Specialties: Firewalls and Internet Security  System Security       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +33 1 47 700 801    Company Fax: +33 1 47 700 850    Support Phone Number: +33 1 47 700 801  Contact Email Address:   paulboyer@usa.net Company URL:   http://www.usa.net Primary Contact: Paul Boyer          1.136 Consultant ID: France, Thorvax           39, rue Armand Silvestre Courbevoie, NON United States 92400  France          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: UltraPenguin    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +33 6 80 08 93 83    Company Fax: +33 1 43 33 51 33    Support Phone Number: +33 6 80 08 93 83  Contact Email Address:   Illaire@Club-Internet.fr Company URL:   http://www.penguinpowered.com/~tyrann Primary Contact: Vincent Illaire          1.137 Consultant ID: France, sokram inc           161 rue de la eoquette Paris, NON United States 75011  France          Consulting Specialties: Custom Programming  Custom Systems  E-Commerce  Internet (Web) Programming       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +33614704591    Company Fax: +33140242235    Support Phone Number: +33614704591  Contact Email Address:   sokram@usa.net Company URL:   http://Not_Applicable Primary Contact: Bernard Not_Applicable          1.138 Consultant ID: Germany, Andreas Spengler EDV-Service           Gronauer Strasse 9 Karben, NON United States 61184  Germany          Consulting Specialties: CIFS (Samba)  Custom Systems  Network Administration  System Administration       Main Distribution: Suse    Other Distribution: RedHat    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 6039 44401    Company Fax: +49 6039 44401    Support Phone Number: Not Available  Contact Email Address:   Not_Applicable Company URL:   http://Not_Applicable Primary Contact: Andreas Spengler          1.139 Consultant ID: Germany, Bigge & Langanke GbR           Corunnastr. 1 Iserlohn, NON United States 58636  Germany          Consulting Specialties: Custom Programming  Custom Systems  E-Commerce  Internet Server Development  Internet (Web) Programming       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: Not_Applicable    Company Fax: Not_Applicable    Support Phone Number: Not Available  Contact Email Address:   support@transdata.de Company URL:   http://www.transdata.de Primary Contact: Frank Bigge          1.140 Consultant ID: Germany, CHIRON           Neupullach 3 Hohenlinden, NON United States 85664  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: Selfmade embedded    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 8124 52 83 44    Company Fax: +49 8124 52 83 46    Support Phone Number: Not_Applicable  Contact Email Address:   chiron@chiron.de Company URL:   http://www.chiron.de Primary Contact: M. Brandstetter          1.141 Consultant ID: Germany, Call-a-Server           Not_Applicable Berlin, NON United States D-14129 Berlin  Germany          Consulting Specialties: CIFS (Samba)  Firewalls and Internet Security  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Other    Other Distribution: DLD, RedHat und S.u.    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 +177 7170896    Company Fax: +49 +30 8017423    Support Phone Number: +49 +177 7170896  Contact Email Address:   support@call-a-server.de Company URL:   http://www.call-a-server.de Primary Contact: Joachim von Thadden          1.142 Consultant ID: Germany, Gecko GmbH           Ringstr. 53 Bad Oeynhausen, NON United States 32549  Germany          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49.5731.741010    Company Fax: +49.5731.741013    Support Phone Number: Not Available  Contact Email Address:   support@lizard.de Company URL:   http://www.lizard.de Primary Contact: Eike Sieker          1.143 Consultant ID: Germany, Gerd Aschemann           Osannstr. 49 Darmstadt, NON United States 64285  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: Suse    Other Distribution: Redhat, Caldera    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49/6151/16-2259    Company Fax: +49/6151/16-3052    Support Phone Number: +49/6151/16-2259  Contact Email Address:   Aschemann@Informatik.TU-Darmstadt.de Company URL:   http://www.Informatik.TU-Darmstadt.de Primary Contact: Gerd Aschemann          1.144 Consultant ID: Germany, Grosch & Link GmbH           Friedrich-Ebert-Anlage 18 Frankfurt, NON United States 60325  Germany          Consulting Specialties: CIFS (Samba)  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: Suse    Other Distribution: RedHat    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49699740130    Company Fax: +496997401322    Support Phone Number: Not_Applicable  Contact Email Address:   frankfurt@grosch-link.de Company URL:   http://www.grosch-link.de/html Primary Contact: Mario Oschwald          1.145 Consultant ID: Germany, ID-Pro GmbH           Koenigswinterer Str. 116 Bonn, NON United States 53227  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Other    Other Distribution: All major distributi    Specialty Distribution: Other    Other Specialty Distribution: Not_Applicable    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49-(0)228-42154-0    Company Fax: +49-(0)228-42154-29    Support Phone Number: +49-(0)228-42154-19  Contact Email Address:   support@id-pro.de Company URL:   http://id-pro.de Primary Contact: Daniel Riek          1.146 Consultant ID: Germany, Jochen Laser IT-Services           Fliederweg 2a Woebbelin, NON United States 19288  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: Suse    Other Distribution: others as well    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 (0)38753 80181    Company Fax: on request    Support Phone Number: +49 (0)38753 80181  Contact Email Address:   on request Company URL:   http://Not_Applicable Primary Contact: Jochen Laser          1.147 Consultant ID: Germany, LINUXHAUS           RINGBAHNSTR. 13 BERLIN, NON United States 10711  Germany          Consulting Specialties: CIFS (Samba)  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: SuSE    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 30 890 944 63    Company Fax: +49 30 890 944 64    Support Phone Number: Not Available  Contact Email Address:   support@linuxhaus.de Company URL:   http://www.linuxhaus.de Primary Contact: Joerg Fruehbrodt          1.148 Consultant ID: Germany, Linux-Systemhaus Schulz           Hauptfeld 18 Dortmund, NON United States 44369  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: none    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 0049 172 2362995    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   schulz@linux-systemhaus.de Company URL:   http://www.Linux-Systemhaus.de Primary Contact: Karsten Schulz          1.149 Consultant ID: Germany, Manfred Kunde EDV-Beratung           Hauptstrasse 70 Karben, NON United States 61184  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Internet Server Development  Internet (Web) Programming       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49-(0)-06039-931064    Company Fax: +49-(0)-06039-931065    Support Phone Number: Not Available  Contact Email Address:   Not_Applicable Company URL:   http://http://www.Manfred-Kunde.de Primary Contact: Manfred Kunde          1.150 Consultant ID: Germany, Matthias Stolte Datentechnik           Not_Applicable 33613 Bielefeld, NON United States Not_Applicable  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security       Main Distribution: Other    Other Distribution: SuSE und andere...    Specialty Distribution: LinuxPPC    Other Specialty Distribution: Not_Applicable    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49-521-880056    Company Fax: +49-521-880059    Support Phone Number: Not Available  Contact Email Address:   Not_Applicable Company URL:   http://Not_Applicable Primary Contact: Not_Applicable Not_Applicable          1.151 Consultant ID: Germany, Michael Bussmann EDV-Dienstleistungen           Im Brook 8 Haltern/Westf., NON United States 45721  Germany          Consulting Specialties: Custom Systems  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 2364 108537    Company Fax: +49 2364 4095    Support Phone Number: n/a  Contact Email Address:   michael.bussmann@gmx.net Company URL:   http://Not_Applicable Primary Contact: Michael Bussmann          1.152 Consultant ID: Germany, Michael Krause Software-Entwicklung           Auf der Horst 11 Borgholzhausen, NON United States 33829  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Internet Server Development  Internet (Web) Programming       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 5425 930310    Company Fax: +49 5425 930311    Support Phone Number: Not_Applicable  Contact Email Address:   Not_Applicable Company URL:   http://homepages.teuto.net/mkrause/ Primary Contact: Michael Krause          1.153 Consultant ID: Germany, NetUSE GmbH           Siemenswall Kiel, NON United States 24107  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 431 386 435 00    Company Fax: +49 431 386 435 99    Support Phone Number: Not_Applicable  Contact Email Address:   service@netuse.de Company URL:   http://netuse.de Primary Contact: Heinz Rohde          1.154 Consultant ID: Germany, PiN - Prsenz im Netz Ges. f. Informationstechnolo           Leimbacher Str. 36 Wuppertal, NON United States 42281  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Other    Other Distribution: Alle Distributionen    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49-202-2501164    Company Fax: +49-202-2501165    Support Phone Number: +49-202-2501164  Contact Email Address:   support@pinserve.de Company URL:   http://www.pinserve.de Primary Contact: Andre Dressler          1.155 Consultant ID: Germany, SDC GmbH           Schlossstrase 26 Berlin, NON United States 13507  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Suse    Other Distribution: Redhat    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 30 4309430    Company Fax: +49 30 43094310    Support Phone Number: Not_Applicable  Contact Email Address:   Not_Applicable Company URL:   http://www.sdc.de Primary Contact: Christian Gleich          1.156 Consultant ID: Germany, Simulina GmbH           Trajanstrae  8 LADENBURG, NON United States DE-68526  Germany          Consulting Specialties: Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not_Applicable    Linux Certifications: Not_Applicable    Company Phone Number: +49 6203 92 20 41    Company Fax: +49 6203 92 20 42    Support Phone Number: +49 6203 92 40 41  Contact Email Address:   hk@simulina.se Company URL:   http://www.ncc-mannheim.net/simulina Primary Contact: Hkan Kllberg          1.157 Consultant ID: Germany, Syslab.com oHg           Karl-Theodor Strae 66 Mnchen, NON United States 80803  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 89 306358-90    Company Fax: +49 89 306358-99    Support Phone Number: +49 89 306358-92  Contact Email Address:   support@syslab.com Company URL:   http://www.syslab.com Primary Contact: Manfred Lang          1.158 Consultant ID: Germany, TDS Consulting GmbH           Gustav-Heinemann-Ring 212 Munich, NON United States 81739  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Netware Connectivity  System Security  Virtual Private Networking       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: IBM       Linux Certifications: Not Applicable       Company Phone Number: +49 89 62736-0    Company Fax: +49 89 62736-129    Support Phone Number: Not_Applicable  Contact Email Address:   Peter.Schroff@tds.de Company URL:   http://www.tds.de Primary Contact: Peter Schroff          1.159 Consultant ID: Germany, WebArtists Internet Services           Steendammwisch 49 Hamburg, NON United States 22459  Germany          Consulting Specialties: Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49-40-555 40 427    Company Fax: +49-40-555 40 182    Support Phone Number: 0172/4032506  Contact Email Address:   support@linuxberatung.com Company URL:   http://www.webartists.net Primary Contact: Markus Braasch          1.160 Consultant ID: Germany, Wesemann Software & Consulting           Heinrich-Plett-Allee 18 Bremen, NON United States D-28259  Germany          Consulting Specialties: System Administration       Main Distribution: Suse    Other Distribution: Not_Applicable    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not_Applicable    Company Phone Number: ++49 421 579 579 3    Company Fax: ++49 421 579 58 28    Support Phone Number: +49 421 579 579 3  Contact Email Address:   info@wscnet.de Company URL:   http://www.wscnet.de Primary Contact: Andreas Wesemann          1.161 Consultant ID: Germany, Wolfgang Kirch           Gustav-Heinemann-Ring 51 Eisenberg, NON United States 67304  Germany          Consulting Specialties: Firewalls and Internet Security       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 49 6351 398761    Company Fax: 49 6351 398762    Support Phone Number: Not Available  Contact Email Address:   Kirch.Wolfgang@t-online.de Company URL:   http://www.t-online.de Primary Contact: Wolfgang Kirch          1.162 Consultant ID: Germany, WorNet Internetdienste           Brgermeister-Graf-Ring 28 Geretsried, NON United States D-82538  Germany          Consulting Specialties: Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 8171 41809-0    Company Fax: +49 8171 41809-9    Support Phone Number: Not Available  Contact Email Address:   wornet@wor.net Company URL:   http://www.wor.net Primary Contact: Christian Eich          1.163 Consultant ID: Germany, ariadne_net           Kpenicker Str. 8 Berlin, NON United States 10997  Germany          Consulting Specialties: CIFS (Samba)  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 0493061280438    Company Fax: 0493061280437    Support Phone Number: 0493061280438  Contact Email Address:   aduecker@t-online.de Company URL:   http://www.t-online.de Primary Contact: Andreas Dcker          1.164 Consultant ID: Germany, b.i.t. beratungsgesellschaft fr informations-tech           elisabethenstr. 62 darmstadt, NON United States 64283  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Internet Server Development  Network Administration  System Administration  System Security       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49-6151-827575    Company Fax: +49-6151-827576    Support Phone Number: +49-6151-827575  Contact Email Address:   support@b-i-t.de Company URL:   http://www.b-i-t.de Primary Contact: Andy Schmidt          1.165 Consultant ID: Germany, conIT GmbH           Industriering 7 Grosswallstadt, NON United States 63868  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 (0)6022/262-082    Company Fax: +49 (0)6022/262-101    Support Phone Number: +49 (0)6022/262-102  Contact Email Address:   support@conIT.com Company URL:   http://www.conIT.com Primary Contact: Arnold Weis          1.166 Consultant ID: Germany, dev consulting GmbH           Webereistr. 3 Bielefeld, NON United States 33602  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: Linux Server    Reseller Authorizations: Not Applicable       Linux Certifications: RedHat  Not Applicable       Company Phone Number: Not_Applicable    Company Fax: +49 521 1365803    Support Phone Number: +49 521 1365800  Contact Email Address:   info@devcon.net Company URL:   http://www.devcon.net Primary Contact: Winfried Motzkus          1.167 Consultant ID: Germany, dynamis EDV-Consulting           Bundschuhstrasse 24 76661 Philippsburg, NON United States 76661  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 7256 9326-0    Company Fax: +49 7256 9326-90    Support Phone Number: +49 7256 9326-0  Contact Email Address:   support@dynamis.de Company URL:   http://www.dynamis.de Primary Contact: Jochen Lillich          1.168 Consultant ID: Germany, envi.con KG           Brandenburgische Str. 69 Berlin, NON United States 10713  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Other    Other Distribution: almost all    Specialty Distribution: Other    Other Specialty Distribution: almost all    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49-30-34902670    Company Fax: +49-30-34902671    Support Phone Number: +49-30-34902670  Contact Email Address:   yourx@envicon.de Company URL:   http://http://www.envicon.de Primary Contact: Stefania Rozzi          1.169 Consultant ID: Germany, frontsite AG           Eschollbrcker Strae 4a Darmstadt, NON United States 64283  Germany          Consulting Specialties: CIFS (Samba)  Firewalls and Internet Security  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: high avail. and ISDN    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49-6151-300-88-80    Company Fax: +49-6151-300-88-80    Support Phone Number: +49-6151-300-88-80  Contact Email Address:   info@frontsite.de Company URL:   http://www.frontsite.de Primary Contact: Mark Semmler          1.170 Consultant ID: Germany, intraDAT GmbH           Wilhelm-Leuschner-Str. 9-11 Frankfurt/Main, NON United States D-60329  Germany          Consulting Specialties: Custom Programming  E-Commerce  Firewalls and Internet Security  Internet (Web) Programming  Virtual Private Networking       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 +69-9740-5703    Company Fax: +49 +69-9740-5705    Support Phone Number: +49 +69-9740-5703  Contact Email Address:   email@intradat.com Company URL:   http://www.intradat.com Primary Contact: Manfred Schmid          1.171 Consultant ID: Germany, ipm intranet project management gmbh           Huelchrather Strasse 17-23 Koeln, NON United States 50670  Germany          Consulting Specialties: E-Commerce       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 49-221-97353217    Company Fax: 49-221-97353216    Support Phone Number: 49-221-97353217  Contact Email Address:   support@ipm-koeln.de Company URL:   http://http://www.ipm-koeln.de Primary Contact: Dietmar Horn          1.172 Consultant ID: Germany, loth systemtechnik           Julius-Vosseler-Strasse 136 Hamburg, ZZ D-22527  Germany          Consulting Specialties: Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Suse    Other Distribution: Not_Applicable    Specialty Distribution: LinuxRouter    Other Specialty Distribution: Not_Applicable    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 40 40192181    Company Fax: +49 40 40192183    Support Phone Number: +49 171 5406784  Contact Email Address:   support@loth.de Company URL:   http://www.loth.de Primary Contact: Michael Loth          1.173 Consultant ID: Germany, netServe oHG Mnster           Fresnostrae 10a Mnster, NON United States 48159  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 49-251-98725-0    Company Fax: 49-251-866977    Support Phone Number: 49-251-98725-21  Contact Email Address:   info@muenster.com Company URL:   http://www.muenster.com Primary Contact: Torsten Mueller          1.174 Consultant ID: Germany, ralf geschke internet consulting           Roemerhofweg 1a Erftstadt, NON United States 50374  Germany          Consulting Specialties: Internet Server Development  Internet (Web) Programming  Network Administration  System Administration       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49-177-5262345    Company Fax: Not_Applicable    Support Phone Number: Not Available  Contact Email Address:   support@geschke.nt Company URL:   http://www.geschke.nt Primary Contact: Ralf Geschke          1.175 Consultant ID: Germany, regioconnect GmbH           Bahnhofstr. 11 Steinfurt, NON United States Steinfurt  Germany          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +492551919300    Company Fax: +492551833169    Support Phone Number: Not_Applicable  Contact Email Address:   info@regioconnect.net Company URL:   http://www.regioconnect.net Primary Contact: Michael Rve          1.176 Consultant ID: Germany, unitegs - Unix Systems Technologies           Wacholderweg 11 Ilmenau, NON United States 98693  Germany          Consulting Specialties: Custom Programming  Custom Systems  System Administration       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +49 3677 884620    Company Fax: +49 3677 884621    Support Phone Number: Not Available  Contact Email Address:   support@unitegs.de Company URL:   http://www.unitegs.de Primary Contact: Gunar Schorcht          1.177 Consultant ID: Hong Kong, Cyber Channel Int'l Ltd           Room 1723 610 Nathan Road Kowloon Hong Kong SAR, NON United States Not_Applicable  Hong Kong          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  Virtual Private Networking       Main Distribution: Other    Other Distribution: Slackware    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: IBM       Linux Certifications: Not Applicable       Company Phone Number: 852 23754341    Company Fax: 852 23754148    Support Phone Number: 852 27823211  Contact Email Address:   support@cyberchn.com.hk Company URL:   http://http://www.cyberchn.com.hk Primary Contact: Thomas Lee Paul Lee          1.178 Consultant ID: Hong Kong, Genesis Systems Int'l Ltd.           5/F., 7/F., Honytex Building T.S.T, Kowloon Hong Kong, ZZ Not_Applicable  Hong Kong          Consulting Specialties: Internet Server Development       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +852 2815 0728    Company Fax: +852 2815 0729    Support Phone Number: +852 2199 7255  Contact Email Address:   support@genesis.com.hk Company URL:   http://www.genesis.com.hk Primary Contact: Gyver  Lo          1.179 Consultant ID: Hong Kong, Hong Kong Terminal           72A G/F Tokwawan Road, Kowloon, NON United States Not_Applicable  Hong Kong          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 852-21420007    Company Fax: 852-27814919    Support Phone Number: 852-21420007  Contact Email Address:   support@zero.com.hk Company URL:   http://http://zero.com.hk Primary Contact: Peter Wong          1.180 Consultant ID: Hong Kong, Linux Center (Hong Kong) Ltd.           Unit A, 5th Floor, Comet Comeercial Building , 42A Kowloon, NON United States Not_Applicable  Hong Kong          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Debian    Other Distribution: Not_Applicable    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +852 2959 3675    Company Fax: +852 2959 3672    Support Phone Number: available to custome  Contact Email Address:   available to customers only Company URL:   http://Not_Applicable Primary Contact: Chris Yung          1.181 Consultant ID: Hong Kong, Uniforce System Ltd.           Rm 903B, Kaiser Center, 18 Centre Street, Sai Ying Hong Kong, NON United States Not_Applicable  Hong Kong          Consulting Specialties: Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +852 24464316    Company Fax: +852 21918185    Support Phone Number: +852 24464316  Contact Email Address:   support@uniforce.net Company URL:   http://www.uniforce.net Primary Contact: Francis Kam          1.182 Consultant ID: Hong Kong, Vortex Ltd.           Tsim Sha Tsui Not_Applicable, NON United States Not_Applicable  Hong Kong          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: HP       Linux Certifications: Not Applicable       Company Phone Number: (852) 23021988    Company Fax: (852) 23021212    Support Phone Number: Not_Applicable  Contact Email Address:   scwong@ieee.org Company URL:   http://Comming Soon Primary Contact: Stephen Wong          1.183 Consultant ID: Hong Kong, Yoric Network Ltd.           Rm 801, On Hong Commerical Building, 145 Hennessy  Wanchai, NON United States Not_Applicable  Hong Kong          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: Slackware    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 852 2391 4685    Company Fax: 852 2330 4818    Support Phone Number: 852 2391 4685  Contact Email Address:   support@yoric.com Company URL:   http://www.yoric.com Primary Contact: Vincent Chan          1.184 Consultant ID: Hungary, BalaBit Bt.           42. Bem Street Szekszard, NON United States 7100  Hungary          Consulting Specialties: Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  System Administration  System Security  Virtual Private Networking       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: ++36209683602    Company Fax: Not_Applicable    Support Phone Number: ++36209683602  Contact Email Address:   support@balabit.hu Company URL:   http://www.balabit.hu Primary Contact: Balazs Scheidler          1.185 Consultant ID: India, Atanu M           H1/55, Mahavir Enclave, Palam-Dabri Road New Delhi, NON United States 110045  India          Consulting Specialties: CIFS (Samba)  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 91-11-5033742 91-11-    Company Fax: Not_Applicable    Support Phone Number: 91-11-5033742 91-11-  Contact Email Address:   atanu@poboxes.com Company URL:   http://Not_Applicable Primary Contact: Atanu Not_Applicable          1.186 Consultant ID: India, C Consulting           15/5 18th Cross Bangalore, NON United States 560055  India          Consulting Specialties: CIFS (Samba)  Firewalls and Internet Security  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +91 (80) 3440397    Company Fax: +91 (80) 3341137    Support Phone Number: +91 (80) 3440397  Contact Email Address:   linux-support@cbconsulting.com Company URL:   http://www.cbconsulting.com Primary Contact: Atul Chitnis          1.187 Consultant ID: India, Connect Solutions           Not Applicable Not Appicable, NON United States 10  India          Consulting Specialties: CIFS (Samba)  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security       Main Distribution: Suse    Other Distribution: Easy, Debian, RedHat    Specialty Distribution: Other    Other Specialty Distribution: Testing all kinds of    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: not applicable    Company Fax: not applicable    Support Phone Number: not applicable  Contact Email Address:   sriram@connectsolutions.net Company URL:   http://www.connectsolutions.net Primary Contact: Sriram V          1.188 Consultant ID: India, DSF Internet Services           C-29 Neeti Bagh New Delhi, NON United States 110049  India          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: RedHat       Company Phone Number: 91-11-685-6158    Company Fax: 91-11-685-6157    Support Phone Number: 91-11-685-6158  Contact Email Address:   support@indoworld.com Company URL:   http://www.indoworld.com Primary Contact: Anmol Taneja          1.189 Consultant ID: India, GratiSource Solutions (P) Ltd.           #308, Shakti Sai Apartments, Chapel Rd, Nampally Hyderabad, NON United States 500001  India          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: Debian, Caldera and     Specialty Distribution: Other    Other Specialty Distribution: Not_Applicable    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 91-40-3391937    Company Fax: 91-40-3391937    Support Phone Number: 91-40-3391937  Contact Email Address:   sidcarter@softhome.net Company URL:   http://gratisource.8m.com Primary Contact: Khader Syed          1.190 Consultant ID: India, K K Software Services           B 2, Murugan Towers NAD Kotha Rd Visakhapatnam, NON United States 530009  India          Consulting Specialties: Custom Systems  System Administration       Main Distribution: Other    Other Distribution: Not_Applicable    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +91-891-521102    Company Fax: +91-891-596571    Support Phone Number: Not_Applicable  Contact Email Address:   vijaykittu@yahoo.com Company URL:   http://vizag.8m.com Primary Contact: Vijaya Kittu Manda          1.191 Consultant ID: India, Lateral Software Technology Pvt Ltd           86 TTK Road Madras, NON United States 600 018  India          Consulting Specialties: Custom Programming       Main Distribution: RedHat    Other Distribution: Easy Linux    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +91=044-4671560    Company Fax: +91-044-4910740    Support Phone Number: Not_Applicable  Contact Email Address:   linux@lateralsoftware.com Company URL:   http://lateralsoftware.com Primary Contact: Roshan Thomas          1.192 Consultant ID: India, Netangle Com Pvt ltd           # 2 , Vishal Bhavan , Road no 12, Banjara hills Hyderabad, ZZ 500034  India          Consulting Specialties: CIFS (Samba)       Main Distribution: RedHat    Other Distribution: Debian    Specialty Distribution: Other    Other Specialty Distribution: RPM,TAR    Reseller Authorizations: HP       Linux Certifications: Not Applicable       Company Phone Number: 091-40-3300394    Company Fax: 091-40-3391412    Support Phone Number: 091-40-3328207  Contact Email Address:   goswami@netangle.us-inc.com Company URL:   http://www.netangle.us-inc.com Primary Contact: satyakam goswami          1.193 Consultant ID: India, Shah Micro System           103, Orental House, 229/231, Samuel Street, Musjid Bombay, NON United States 400003  India          Consulting Specialties: CIFS (Samba)  Internet Server Development  Netware Connectivity  Network Administration  System Administration  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: All Linux Flavours    Specialty Distribution: Other    Other Specialty Distribution: All i386 Distributio    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +91-22-8862711    Company Fax: +91-22-8868214    Support Phone Number: +91-22-8862711  Contact Email Address:   dinesh@indiamal.com Company URL:   http://http://members.tripod.com/~dineshah/ Primary Contact: Dinesh Shah          1.194 Consultant ID: Indonesia, Nayaga Reka Media Aplika, PT           Jl. Situsari Wetan no 39 Bandung, NON United States 40265  Indonesia          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Debian    Other Distribution: RedHat, Slackware, M    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +62-22-302764    Company Fax: n/a    Support Phone Number: +62-22-302764  Contact Email Address:   nayagapt@bdg.centrin.net.id Company URL:   http://nayagarekamedia.hypermart.net/index1.htm Primary Contact: Andika Triwidada          1.195 Consultant ID: Indonesia, Netindo Pusaka Prima pt.           Duta Harapan Indah  Blok SS/10, Jl. Kapuk Muara Jakarta, NON United States 14460  Indonesia          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: RedHat       Company Phone Number: +6221 - 6631868    Company Fax: +6221 - 6623606    Support Phone Number: n/a  Contact Email Address:   support@netindo.co.id Company URL:   http://www.netindo.co.id Primary Contact: Andy Luhur          1.196 Consultant ID: Indonesia, PT Cakram DataLingga Duaribu           Jln Gunung Batu 131 Bogor, NON United States 16610  Indonesia          Consulting Specialties: CIFS (Samba)  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +62-251-332122    Company Fax: +62-251-332122    Support Phone Number: +62-251-332122  Contact Email Address:   linux-support@cdl2000.or.id Company URL:   http://http://www.cdl2000.or.id Primary Contact: Maliana Harsoadi          1.197 Consultant ID: Israel, Breakthrough LTD           Hatzabar 18/9 Kiron, NON United States 55106  Israel          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not_Applicable    Company Phone Number: 972-52-442549    Company Fax: 972-3-6356434    Support Phone Number: 972-52-442549  Contact Email Address:   webmaster@breakt.co.il Company URL:   http://www.breakt.co.il Primary Contact: Alex Rier Not_Applicable          1.198 Consultant ID: Israel, Init Computers           35 Hadar St. Herzlia, NON United States 46326  Israel          Consulting Specialties: CIFS (Samba)  Firewalls and Internet Security  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +972-9-9582971    Company Fax: +972-9-9582952    Support Phone Number: Not_Applicable  Contact Email Address:   support@init.co.il Company URL:   http://Not_Applicable Primary Contact: Paolo Supino          1.199 Consultant ID: Israel, Reuven Lerner -- Communications Consulting Ltd.           17 Disraeli Street Haifa, NON United States 34333  Israel          Consulting Specialties: Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +972-4-824-2265    Company Fax: +972-4-826-1219    Support Phone Number: Not_Applicable  Contact Email Address:   reuven@lerner.co.il Company URL:   http://lerner.co.il Primary Contact: Reuven Lerner          1.200 Consultant ID: Israel, vPrise           50, Disengof Tel-Aviv, NON United States Not_Applicable  Israel          Consulting Specialties: Custom Programming  Custom Systems  E-Commerce  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration       Main Distribution: Caldera    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 972-54-654576    Company Fax: 972-151-54-654576    Support Phone Number: 972-54-654576  Contact Email Address:   support@vprise.com Company URL:   http://www.vprise.com Primary Contact: Shai Almog          1.201 Consultant ID: Italy, Alessandro Rubini           Viale Golgi 72 PAvia, NON United States 27100  Italy          Consulting Specialties: Custom Programming  Custom Systems  Firewalls and Internet Security  Network Administration       Main Distribution: Debian    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: ET-Linux (embedded 3    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +39 0382 529554    Company Fax: Not_Applicable    Support Phone Number: +39 0382 529554  Contact Email Address:   alessandro.rubini@linux.it Company URL:   http://www.linux.it Primary Contact: Alessandro Rubini          1.202 Consultant ID: Italy, ERANET snc           13H, Via S. Giuseppe Conegliano, NON United States 31015  Italy          Consulting Specialties: CIFS (Samba)  Custom Programming  E-Commerce  Firewalls and Internet Security  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +39(0)438-415887    Company Fax: +39(0)438-415887    Support Phone Number: +39(0)438-415887  Contact Email Address:   andrea.girotto@usa.net Company URL:   http://www.era-net.it Primary Contact: Andrea Girotto          1.203 Consultant ID: Italy, Francesco Patamia           Via G. Marrazzo, 2 Cropani Marina, NON United States Not_Applicable  Italy          Consulting Specialties: CIFS (Samba)  E-Commerce  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration       Main Distribution: Other    Other Distribution: Slackware    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +390961-961486    Company Fax: +390961-961155    Support Phone Number: +390338-8165310  Contact Email Address:   patamia@biponline.com Company URL:   http://http://www.biponline.com/fpnet Primary Contact: Francesco Patamia          1.204 Consultant ID: Italy, Luca Perugini           Via Furio Camillo 27 Passo Corese (RI), NON United States 02036  Italy          Consulting Specialties: CIFS (Samba)  Custom Programming  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not_Applicable    Linux Certifications: Not_Applicable    Company Phone Number: +390765488457     Company Fax: Not_Applicable    Support Phone Number: +3903473392355  Contact Email Address:   Not_Applicable Company URL:   http://Not_Applicable Primary Contact: Not_Applicable Not_Applicable          1.205 Consultant ID: Italy, Marco Iannacone           Not_Applicable Milano, NON United States I-20090  Italy          Consulting Specialties: CIFS (Samba)  E-Commerce  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  Virtual Private Networking       Main Distribution: Suse    Other Distribution: Red Hat, Slackware,     Specialty Distribution: Other    Other Specialty Distribution: Securty, Network int    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: Not_Applicable    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   Not_Applicable Company URL:   http://www.pippo.com Primary Contact: Marco Iannacone          1.206 Consultant ID: Italy, Marco Michelino           Viale Colli Aminei 36 Napoli, NON United States 80131  Italy          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Network Administration  System Administration  System Security       Main Distribution: Suse    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: Not_Applicable    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +390817418669    Company Fax: Not_Applicable    Support Phone Number: Not Available  Contact Email Address:   mmarco@hempseed.com Company URL:   http://www.hempseed.com Primary Contact: Marco Michelino          1.207 Consultant ID: Italy, Mauro Barella           Via Roma, 8 UDINE, NON United States 33100  Italy          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  Firewalls and Internet Security  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: Not_Applicable    Specialty Distribution: Other    Other Specialty Distribution: Not_Applicable    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +39 0432 512592    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   Not_Applicable Company URL:   http://www.maurobarella.org Primary Contact: Mauro Barella          1.208 Consultant ID: Italy, PROFUSO           Not_Applicable Abano Terme - Padova, NON United States 35031  Italy          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +39 0498059070    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   info@profuso.com Company URL:   http://http://www.profuso.com/ Primary Contact: Giuseppe Zanetti          1.209 Consultant ID: Italy, PROSA Progettazione Sviluppo Aperto           via Degli Zabarella, 3 Padova, NON United States 35121  Italy          Consulting Specialties: Custom Programming       Main Distribution: Debian    Other Distribution: PROSA Debian GNU/Lin    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not_Applicable    Linux Certifications: Not_Applicable    Company Phone Number: +39 049 66 05 19    Company Fax: +39 049 87 80 504    Support Phone Number: Not Available  Contact Email Address:   Not_Applicable Company URL:   http://Not_Applicable Primary Contact: Davide Barbieri          1.210 Consultant ID: Italy, Panservice           Via Nervi - CC LT Fiori - Torre 8 Latina, NON United States 04100  Italy          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Other    Other Distribution: Slackware    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 39 0773 410020    Company Fax: 39 0773 410020    Support Phone Number: 39 0773 410084  Contact Email Address:   helpdesk@panservice.it Company URL:   http://http://www.panservice.it Primary Contact: Giuliano Peritore          1.211 Consultant ID: Italy, Paolo Correnti           Via dei Monti di S.Paolo 55/O Rome, NON United States 00126  Italy          Consulting Specialties: Custom Systems  Internet Server Development  Internet (Web) Programming  System Administration       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 3965250639    Company Fax: ---    Support Phone Number: ----  Contact Email Address:   pcorrenti@iol.it Company URL:   http://users.iol.it/pcorrenti/index.html Primary Contact: Paolo Correnti          1.212 Consultant ID: Italy, Prometeus di Michele Sciabarr           via Marco Polo 31 Martinsicuro, NON United States 64014  Italy          Consulting Specialties: Custom Programming  Custom Systems  E-Commerce  Internet Server Development  Network Administration  System Administration       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 39 0861 761767    Company Fax: Not_Applicable    Support Phone Number: Not_Applicable  Contact Email Address:   michele@sciabarra.com Company URL:   http://www.sciabarra.com Primary Contact: Michele Sciabarr          1.213 Consultant ID: Italy, Studio C           via Romeo Romei 23 Rome, NON United States 00136  Italy          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +39639722036    Company Fax: +39639736598    Support Phone Number: +39639722036  Contact Email Address:   albe@vdi.net Company URL:   http://www.studioc-advertising.com Primary Contact: Marco Capecci          1.214 Consultant ID: Italy, Studio LEADER Pro           Via Pietrastretta 76 TRENTO, NON United States 38100  Italy          Consulting Specialties: CIFS (Samba)  Custom Programming  Firewalls and Internet Security  Internet Server Development  Network Administration  System Security  Virtual Private Networking       Main Distribution: Suse    Other Distribution: Caldera RedHat    Specialty Distribution: LinuxRouter    Other Specialty Distribution: HAL91    Reseller Authorizations: Not Applicable       Linux Certifications: Caldera  Not Applicable       Company Phone Number: +39 461828229    Company Fax: +39 461829826    Support Phone Number: Not Available  Contact Email Address:   info@leader.it Company URL:   http://www.leader.it Primary Contact: Guido Brugnara          1.215 Consultant ID: Japan, M           1-8-19 Toshimaku Minami Ikebukuro Tokyo, NON United States 171  Japan          Consulting Specialties: CIFS (Samba)  Custom Systems  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: Other    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +81 3 5396 5966    Company Fax: +81 3 3983 4542    Support Phone Number: +81 3 5396 5966  Contact Email Address:   fisher@m-t.com Company URL:   http://www.m-t.com Primary Contact: Masahiro Otsuka          1.216 Consultant ID: Kuwait, Internet Universe - Network Solutions           Dasma P.O.Box 2, NON United States non  Kuwait          Consulting Specialties: Custom Systems  Firewalls and Internet Security  Internet Server Development  Network Administration  System Administration  System Security       Main Distribution: Other    Other Distribution: Slackware    Specialty Distribution: LinuxRouter    Other Specialty Distribution: General Linux networ    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: +965-262-5678    Company Fax: +965-262-5679    Support Phone Number: +965-262-5678  Contact Email Address:   support@kuwait-net.com Company URL:   http://www.kuwait-net.com Primary Contact: Faisal  Al-Abhoul          1.217 Consultant ID: Malaysia, JirehBuilderZ Web Techs Snd. Bhd.           Unit 5.06, Fifth Menara PSCI, Penang, NON United States 10050  Malaysia          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: Caldera    Other Distribution: SlackWare    Specialty Distribution: LinuxRouter    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not Applicable       Company Phone Number: 604-3700378    Company Fax: 604-3700377    Support Phone Number: 604-3700378  Contact Email Address:   info@jirehtechs.com Company URL:   http://www.jirehtechs.com Primary Contact: Wai Boon Ng          1.218 Consultant ID: Malaysia, Linux Resources Sdn. Bhd.           No. 33-1, Jalan 46A/26, Pusat Bandar Taman Sri Ram Setapak, NON United States 53300  Malaysia          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: NA    Specialty Distribution: UltraPenguin    Other Specialty Distribution: NA    Reseller Authorizations: Not Applicable       Linux Certifications: Not_Applicable    Company Phone Number: +603-4139010    Company Fax: +603-4139011    Support Phone Number: +603-4139010  Contact Email Address:   drliwa@pc.jaring.my Company URL:   http://www.ihsan.com/linux Primary Contact: Dr. Liwaudin Muhamad          1.219 Consultant ID: Malaysia, MAGNIFIX           2102 Wisma Rampai, Jln 34/26 Kuala Lumpur, NON United States 53300  Malaysia          Consulting Specialties: Internet Server Development       Main Distribution: RedHat    Other Distribution: SUSE    Specialty Distribution: LinuxPPC    Other Specialty Distribution: NA    Reseller Authorizations: Compaq       Linux Certifications: RedHat       Company Phone Number: 603 412 1775    Company Fax: 603 412 1550    Support Phone Number: 603 412 1776  Contact Email Address:   info@magnifix.com.my Company URL:   http://www.magnifix.com.my Primary Contact: Izauddin  Isa          1.220 Consultant ID: Mexico, BUFETE CONSULTOR DE MEXICO           APDO POSTAL 105-336 Mexico CityMMexico City, NON United States 11590  Mexico          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: DEBIAN SUSE SLACKWAR    Specialty Distribution: Other    Other Specialty Distribution: EPHYRA CLUSTERS, RDB    Reseller Authorizations: Compaq  HP  IBM       Linux Certifications: RedHat       Company Phone Number: +(52)5247-0272    Company Fax: +(52)5247-0272    Support Phone Number: Not_Applicable  Contact Email Address:   support@ephyra.com Company URL:   http://ephyra.com Primary Contact: FELIPE BAROUSSE          1.221 Consultant ID: Mexico, BUFETE CONSULTOR DE MEXICO           APDO POSTAL 105-336 Mexico CityMMexico City, NON United States 11590  Mexico          Consulting Specialties: CIFS (Samba)  Custom Programming  Custom Systems  E-Commerce  Firewalls and Internet Security  Internet Server Development  Internet (Web) Programming  Netware Connectivity  Network Administration  System Administration  System Security  Virtual Private Networking       Main Distribution: RedHat    Other Distribution: DEBIAN SUSE SLACKWAR    Specialty Distribution: Other    Other Specialty Distribution: EPHYRA CLUSTERS, RDB    <
GX039-54-16354053	"November 2000, Issue 59       Published by  Linux Journal     Front Page   |   Back Issues   |   FAQ   |   Mirrors   |   Search                         Visit Our Sponsors:                                                                                         Table of Contents:               The MailBag            Help Wanted & Article Ideas         General Mail           News Bytes            Distro News         News in General         Software Announcements           The Answer Gang  ,  by The  Linux Gazette  Answer Gang       More 2-Cent Tips        HAL 91 - a minimalistic Linux distribution  ,  by Matthias Arndt       Open Source is Open for Business  ,  by Bill Bennet       Narval, the Intelligent Personal Assistant --or-- How the French Linux Gazette is Built  ,  by Nicolas Chauvat       HelpDex  ,  by Shane Collinge       Interview with Google's Sergey Brin  ,  by Fernando Ribeiro Corrêa       IBM: The Big Blue Support for the Linux Comunity  ,  by Fernando Ribeiro Corrêa       Alpha in the New Processors Market  ,  by Fernando Ribeiro Corrêa       The Australian History of Tux  ,  by Chris Jones       Tuxedo Tails  ,  by Eric Kasten       PHP Essentials (book review)  ,  by Patrick Lambert       dmesg explained  ,  by Jose Nazario and Natarajan Krishnaswami       Encrypting Data in Web Forms  ,  by Mark Nielsen       Making Smalltalk:  Spreading the OO Fun  ,  by Jason Steffler       The Back Page            About This Month's Authors         Not Linux                                 Linux Gazette  Staff and The Answer Gang     Editor:  Michael Orr   Technical Editor:  Heather Stern   Senior Contributing Editor:  Jim Dennis   Contributing Editors:  Michael ""Alex"" Williams, Don Marti, Ben Okopnik                    TWDT 1 (gzipped text file)   TWDT 2 (HTML file)  are files containing the entire issue: one in text format, one in HTML.  They are provided  strictly as a way to save the contents as one file for later printing in the format of your choice;  there is no guarantee of working links in the HTML version.                   Linux Gazette ,   http://www.linuxgazette.com/   This page maintained by the Editor of  Linux Gazette ,   gazette@ssc.com      Copyright © 1996-2000 Specialized Systems Consultants, Inc.                   ""Linux Gazette... making Linux just a little more fun! ""               The Mailbag!    Write the Gazette at   gazette@ssc.com     Contents:     Help Wanted -- Article Ideas   Gazette Matters                Help Wanted -- Article Ideas      New submission address!    Send tech-support questions, answers and article ideas to The Answer Gang < linux-questions-only@ssc.com >.  Other mail (including questions or comments about the  Gazette  itself) should go to < gazette@ssc.com >.  All material sent to either of these addresses will be considered for publication in the next issue.   Please send answers to the original querent too, so that s/he can get the answer without waiting for the next issue.     Unanswered questions appear here.  Questions with  answers--or answers only--appear in The Answer Gang, 2-Cent Tips, or here, depending on their content.     Before asking a question, please check the  Linux Gazette  FAQ  to see if it has been answered there.               Wed, 11 Oct 2000 12:50:21 +0200  From: Jean-Paul Duyx < jp@duyx.nl >  Subject: Vines Client for linux    On my notebook I run linux, but at my work the network is Banyan Vines. Searching the internet, I could not find any linux client for Vines. Perhaps I didn't look good enough or mayby there is no such thing.I think it would be nice to read something about that. The only thing that i found was a private project to write a client for linux, but that site hasn't been updated for more than a year. it is   http://freespace.virgin.net/paul.grayson/ .               Sun, 29 Oct 2000 14:33:05 +35824  From: Jon Claerbout < jon@kana.stanford.edu >  Subject: Income tax software     Every year I need to struggle with Windoze again in order to work out my income taxes. I heard that there were some web-based systems, but when I dug into it, it turned out that it needed to work with an adobe plugin that didn't work for me.    Hope you can dig up some better solutions for us Linux folk?   --    o   ~  _-'\_  ~ (*)<(*)  ~                Wed, 18 Oct 2000 15:06:53 -0500  From: Matt < matt@1lsn.com >  Subject: Slackware RAID1 problem    HEELP! hehe I have been trying to find a chatroom (or ICQ or something..just aas long as  its live and they are available alot.) with some people (or better yet, one  kind guru with lots of free time) in it that can help me with a slackware  problem I am having..(specifically installing and configuring a RAID1  system). I am VERY new to linux ..have only compiled one kernel in my lifetime and  don't truly understand what it did or why..hehe    All I need is someone to kinda walk me through step-by-step commands  starting with CFDISK and going all the way to the end..a bootable raid1  system. (I can learn how and why later..but am on a bit of a time schedule at the  moment.)    If you know of any places I can go or people to contact, please let me know  as soon as you can.     I already have about 90 pages of printed material and have tried most of  it, but its not working. dunno, maybe the the instructions I have (have about 10 different sets form  different websites) are missing something..    Anyway, I really appreciate any help you might be able to offer..               Fri, 20 Oct 2000 18:06:30 -0200  From: César A. K. Grossmann < ckant@fazenda.gov.br >  Subject: Windows NT Event Log on a Linux Box    I need to consolidate the event log from several machines and produce some reports and even alerts from the data collected. I was thinking that using the Linux tools (cron jobs, scripting languages, and DBMS) could be a good idea, but cannot find how to do this (read the event log of a Windows box from a Linux box).    The best support I can find was the article   http://www.securityfocus.com/frames/?focus=microsoft&content=/focus/microsoft/nt/log1.html . In it I can find:    ""... The Event Log is accessible to remote machines via Remote Procedure Calls (RPC) via applications that utilize the Event Log API, such as the Event Viewer.""    So I think it's possible to have some application that uses RPC (as SAMBA does) to connect to the remote Windows box and get a copy of the event log.    Can you help me? The Windows NT boxes are in an NT Domain, and the Linux box does have the SAMBA installed and running.    TIA    P.S.: sorry the bad english, I'm a brazilian penguinista.                   Gazette Matters                  Fri, 6 Oct 2000 03:24:56 +0300  From: Peter Georgiev < pesho@geocities.com >  Subject: Linux Gazette by e-mail    Here is my 0.02USD tip for all those readers who'd like to receive the  Gazette  by e-mail.    Actually it can be done quite easy. All you need to do is send an e-mail message to bitftp@pucc.princeton.edu with message body:   open ftp.ssc.com chdir /pub/lg binary get lg-issueXX.tar.gz quit      and you will receive back an e-mail containing a uuencoded copy of the requested file. There is plenty of uudecoding  software so I will not elaborate further.    If you need more detailed HOWTO on the matter and a list of other ftp-mail servers send an e-mail message to mail-server@rtfm.mit.edu with message body:   send usenet/news.answers/internet-services/access-via-email      or mailto mailbase@mailbase.ac.uk with message body:   send lis-iis e-access-inet.txt      or visit  http://www.activesol.com/www/drbobfram.htm     There you will also find info on various internet services available via e-mail.    Your Editor comments:   This is certainly easy since it uses standard FTP commands.  Remember to get  lg_base.tar.gz  too the first time, and   lg-base-new.tar.gz  each month.  However, note that the   file sizes  are large: recent issues have been 750KB - 2.1 MB, and lg-base is currently 837 KB.  Some mail gateways reject messages which are over a certain size, frequently one megabyte.  If the files are too large for your gateway, the following suggestion may be more suitable for you.   Ralbright < ralbright5@juno.com > recommends:     Send an email as noted here to any of the  numerous www4 servers.   From: Your  Mail Address Here    To:  www4mail@ftp.uni-stuttgart.de Subject: leave blank nothing here  GETSIZE 50000 XUUENCODE  ftp://ftp.ssc.com/pub/lg/lg-issue58_tar_gz.       this results in 24 msg that are numbered  part 01 of 24 and uuencode. I use uudeview to decode the 24 parts. I then rename each part to aa----ax. 24  parts; then I combine the parts exactly like this. must be this way!!   copy /b aa+ab+ac+ad and finally ax    then press return on the line containing the copy instruction It will ask if you want aa to be overwrote. answer yes and all will now be in aa now re name aa to issue58.tgz and proceed with untgz    I have acquired all 58 issues this way through email only. Hope you can make sense out of this.   Your Editor comments:   That  copy  command is for DOS/Windows sysems.  (No, it's not a  crime to read  LG  on a Windows machine.)  On Linux/UNIX, you'd do this instead:   cat aa ab ac ad ... ax >issue58.tgz    This creates  issue58.tgz , containing all the other files joined together one after the other.  I don't see why you need to rename the files to  aa ,  ab , etc., since you're just going to use them once and  then delete them.  Why not just use whatever names  uudecode  gives you?   Ralbright < ralbright5@juno.com > continues:   E-mail, like everything else, sometimes goes off into never-never land. If, after getting the parts of LG, you discover that some parts are missing, send the following to the www4 server:   GETPART put missing part number here GETSIZE 50000 XUUENCODE  ftp://ftp.ssc.com/pub/lg/lg-issue58_tar_gz.                 Wed, 11 Oct 2000 09:09:50 -0700  From: Linux Gazette < gazette@ssc.com >  Subject: Translations    Thanks to everybody who responded to  last month's request for translators from other languages to English. Currently we have volunteers for:        ROMANCE     Spanish (3), Portuguese (2), French.     GERMANIC     German, Dutch, Norwegian, Danish, Swedish     SLAVIC     Russian (from Russian only)      We don't get a lot of mail in non-English languages, but we have gotten an article in French and one in Spanish, and TAG/Mailbag items in Italian, Spanish and Danish.  I just want to have translators ready in case we need them someday.    Those who wish to translate from English into their own language should contact the foreign-language version of interest, or start your own if there isn't one.  As always, see the  mirrors page .   Note to those who work on  LG's  foreign-language editions:     There is a new mailing list, lg-translators, where I send advance copies of articles after they have been formatted.  This will give you a chance to get your hands on the articles a few days early to lessen the delay between when the English version appears and when your translation is ready.    To subscribe to this list, send a message to   majordomo@ssc.com  with  ""subscribe lg-translators"" in the body.  This is a moderated list: only articles, article revisions, and announcements from  LG  to the foreign editions will be sent.   Musings on the Spanish  LG:   The Spanish  LG   ( La Gazeta de Linux ) could become a significant force in the next several months.  I have been getting inquiries about it every month, moreso than I've received for the other languages.  The Spanish-speaking world in particular seems to have a lot of unmet demand for a  Gazette -like publication.  I suspect that's because of the economic situation in Latin America (an affordable OS is more of a necessity than in Europe), because people are less likely to grow up knowing English, and because there are a whole *lot* of Spanish speakers.    The demand for Spanish  LG  reminds me of the demand for an affordable Macintosh that was built up during the late 80s.  When Apple finally released the MacClassic in 1990, I for one immediately went down and bought one, as did a lot of other people.  Apple was forced to switch to a 3-shift, 24-hour production line to churn them out, just to meet the demand.    Note: all non-English versions of  Linux Gazette  are done as independent projects without  LG  sponsorship.   LG  does not endorse specific translations as being official.  However, we gratefully acknowledge all translations we know about on our   mirrors page .            Thanks  Thu, 26 Oct 2000 13:29:57 -0400  From: Bill Cox < billcox@nc.rr.com >     I was doing a search of your achives and found exactly what I needed.  Thanks for being there.               Mon, 16 Oct 2000 19:41:46 -0500 (CDT)  From: Jason Englander < jason@interl.net >  Subject: ""@"" sign confuses  LG  mirrors    I have no idea when this started because I auto-mirror /pub/lg/www_root and only usually look at it when a new issue comes out... but here's what I get with ftp and with lftp:   -rw-rw-r--   1 698    @ 105    @    30147 Sep 26 11:39 faq/index.html -rw-rw-r--   1 698    @ 105    @    11763 Sep 30 15:38 index.html -rw-rw-r--   1 698    @ 105    @   162592 Sep 30 15:45 lg_index.html -rw-rw-r--   1 698    @ 105    @   134353 Nov 17  1999 tag/kb.html -rw-r--r--   1 698    @ 218    @     1475 Jul 28  2000 tag/kb0.html -rw-rw-r--   1 698    @ 105    @     2379 Mar  1  1999 lg_statement.html -rw-rw-r--   1 698    @ 105    @    86857 Sep 30 15:37 mirrors.html -rw-rw-r--   1 698    @ 105    @      102 Nov  3  1999 robots.txt -rw-rw-r--   1 698    @ 105    @     8866 Aug 31 17:44 copying.html drwxrwxr-x   2 698    @ 105    @     1024 Feb 28  2000 test -rw-rw-r--   1 698    @ 105    @     3021 Mar 30  2000 search.html      The two @ that are in there seem to be botching up ""mget *.html"" type requests and mirroring (I use lftp's mirror), making the ""search.html"" file become ""30  2000 search.html"" (the 30 and the 2000 coming from the date).    Anyone else report this?  I'm going to grab the .tar.gz files now and shut off the nightly updates.     [Nobody else has reported this.  We get the ""@"" symbols on the FTP listings too.  However,  LG  has an rsync server.  Rsync is  reliable and uses less bandwidth than FTP mirroring.  Jason switched to rsync and said it's working fine.  Hints for setting up an rsync client for LG  are  here .  -Mike.]                  This page written and maintained by the Editors of the  Linux Gazette . Copyright © 2000,  gazette@ssc.com . Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 59 of  Linux Gazette , November 2000         ""Linux Gazette... making Linux just a little more fun! ""                Contents:        Distro News      News in General      Software Announcements            Selected and formatted by  Michael Conry  Late additions added by the Editor    Submitters, send your News Bytes items in  PLAIN TEXT  format. Other formats may be rejected without reading. You have been warned! A one- or two-paragraph summary plus URL gets you a better announcement than an entire press release.             November 2000  Linux Journal  The November issue of  Linux Journal  is on newsstands now. This issue focuses on Hardware. Click  here  to view the table of contents, or  here  to subscribe.  All articles through December 1999 are available for public reading at  http://www.linuxjournal.com/lj-issues/mags.html . Recent articles are available on-line for subscribers only at  http://interactive.linuxjournal.com/ .              Distro News          Caldera  Oct. 3, 2000: Caldera Systems has announced that its Linux management solution, formerly known as Cosmos, is entering open beta. This solution will enable administrators to manage the networked systems of any Linux distribution. Caldera aims to allow network administrators to use policies and profiles to manage a half dozen or thousands of Linux systems, without having to individually manage each.  The Beta is available for download from  http://www.calderasystems.com/beta/ .          Conectiva    Duke of URL review.             Lute  Oct. 6th, 2000:  LuteLinux.com . has announced the addition of  ShowMeLinux . to their family of services. LuteLinux will host future issues and will take over as publisher of ShowMeLinux, an on-line magazine 'Bringing news to Business Professionals and Enthusiasts alike.' Contributions to ShowMeLinux are welcome, and should be directed to:  info@showmelinux.com .     In a further initiative LinuxFreeSupport will be authoring  ShowMeLinux's 'Support Line'. The Support Line is a column offering answers to questions posed by readers regarding such topics as installations, networking, administration, applications, and the desktop.          Mandrake   Linux-Mandrake 7.2  is now available for download.  It includes KDE 2.0, GNOME 1.2, PowerPak's ViaVoice voice-recognition software, the CUPS printing system, laptop profile and synchronization utilities, KOffice, ReiserFS (a journalling filesystem), Supermount (transparent access to removable media) and MandrakeUpdate (free automatic online upgrades of system software).  Linux-Mandrake 7.2 speaks several dozen languages and will soon be offered in three commercial versions for home and business users.          Red Flag  Oct. 18, 2000:  Red Flag Linux  is officially launched by Sun Wah Linux Ltd. Included in this launch are Red Flag Linux Server 2.0 and Red Flag E-business Start Kit 1.0. The former, run on 32-bit, 64-bit or higher-end machines, optimizes server hardware performance. This product can improve the efficiency of office work. It provides a complete business Internet/Intranet connection solution, an ISP/ICP solution which can control website traffic and InterScan VirusWall network anti-virus software. All of these functions combine for the best platform for network business. Targeting the growing m-commerce market, Sun Wah Linux and EdgeMatrix have also embarked on a bundling program with WAPgate, residing on Red Flag Linux platform.  Red Flag Linux Server 2.0 was developed strictly in accordance with international L118NUX standards and General Public License regulations.  Red Flag E-business Start Kit 1.0 is an integrated solution for businesses. It consists of six components: Red Flag Linux Server 2.0; e-Office, for users to easily transfer internal data via the Internet; e-Shop, where users can easily create their own e-shops through the Internet; Web Mail, providing an inter-platform e-mail system manager designed for businesses; Web BBS, for customers to offer feedback and suggestions on the message board; and Ez2min, a remote monitoring software for the Linux system operated through the browser.  Mr. Alex Banh, Deputy Chief Executive Officer of SW Linux has expressed a commitment to developing international markets for homegrown Chinese software and to promoting Linux training in local Chinese institutes.          Rock   ROCK Linux 1.3.11  has been released.          SuSE   SuSE  Linux 7.0 Personal Edition equips small office and home users with all the resources needed to install, configure and operate a Linux system and comes on 3 CDs. This package includes over 600 programs including StarOffice 5.2, Netscape and VMWare plus three easy-read manuals. The Personal Edition is retailing at R410.00.  The Professional Edition of SuSE 7.0 contains a collection of power tools including VMWare Workstation for Linux, Emhydra by Lutris Technologies, PostGreSQL. Suse Linux 7.0 Professional is supplied on 6 CDs and four manuals. 90 days of installation and basic configuration support by phone, fax or email are also included in the Professional version, which is available from OS/2 Express for R615. Contact  OS/2 Express . We are advised that a limited number of evaluation packages are available.                News in General          Upcoming conferences & events     Courtesy  Linux Journal's   Events page .               Linux Business Expo (co-located   with COMDEX event)    November 13-17, 2000 Las Vegas, NV    www.key3media.com/linuxbizexpo          USENIX Winter - LISA 2000    December 3-8, 2000 New Orleans, LA    www.usenix.org                      Pluto Meeting 2000    December 9-11, 2000 Terni, Italy      meeting.pluto.linux.it         LinuxWorld Conference & Expo    January 30 - February 2, 2001 New York, NY      www.linuxworldexpo.com         ISPCON February 5-8, 2001 Toronto,   Canada   events.internet.com         Internet World Spring March 12-16, 2001   Los Angeles, CA events.internet.com           Game Developers Conference    March 20-24, 2001 San Jose, CA    www.cgdc.com         CeBit March 22-28, 2001   Hannover, Germany   www.cebit.de          Linux Business Expo    April 2-5, 2001 Chicago, IL      www.linuxbusinessexpo.com          Strictly e-Business Solutions Expo    May 23-24, 2001 Location unknown at present      www.stricltyebusinessexpo.com          USENIX Annual Technical Conference    June 25-30, 2001 Boston, MA    www.usenix.org          PC Expo    June 26-29, 2001 New York, NY    www.pcexpo.com         Internet World July 10-12, 2001   Chicago, IL events.internet.com         O'Reilly Open Source Convention    July 23-26, 2001 San Diego, CA      conferences.oreilly.com         LinuxWorld Conference & Expo    August 10-14, 2001 New York, NY      www.linuxworldexpo.com         Linux Lunacy Co-Produced by  Linux  Journal  and Geek Cruises    October 21-28, 2001 Eastern Carribean      www.geekcruises.com                       Jabber.com Announces Palm Integration and Three-Way Partnership for New Jabber Wireless Initiative  Sept. 25, 2000:  Jabber.com  Inc. has announced Palm and Jabber integration along with a three-way partnership between Jabber.com, WorkSpot Inc., a premier open source Application Service Provider, and IQ3G, Inc., a leader in enterprise wireless solutions. The three-way partnership has been established as the foundation for a new Jabber wireless initiative and marks the beginning of Jabber's efforts in the wireless market. Under the new initiative, WorkSpot, IQ3G and Jabber.com are working together, along with the open source community, to develop Jabber compatibility with Palm devices.  Jabber has also announced a strategic relationship with Red Hat to deliver real-time messaging infrastructure to Red Hat embedded Linux. Elements of this were showcased at the Embedded Systems 2000 show, September, in San Jose, Calif. Jabber is the only open source, XML-based platform for extensible instant messaging applications. For the latest developments on the Jabber landscape, consult their  news site.           Dell First To Market with Red Hat Linux 7  Sept. 25, 2000:  DELL  has announced availability of Version 7 of the Red Hat Linux operating system on Dell PowerEdge(tm) servers and Dell Precision(tm) Workstations worldwide. The new operating system is also available on select configurations of Dell desktop and notebook PC products. Dell and Red Hat, as part of their One Source Alliance, worked closely during the development of Red Hat Linux 7 to ensure smooth installation and interoperability of the operating system on Dell server and client products. Details of a benchmark test of Dell PowerEdge 8450 and Dell PowerEdge 6400 servers running Red Hat Linux and TUX 1.0 have been posted on SPEC's Web site,  http://www.spec.org , since August, 1999, where the Dell machines led the field.          Neoware  KING OF PRUSSIA, PA:  Neoware Systems  , a leading supplier of award-winning software and solutions for the emerging information appliance market, announces that Security Applications, Inc. has selected Neoware's Eon information appliance platform and NeoLinux software to power its new, fully networkable building security panel, e-Panel. Security Applications has ported its proprietary UNIX software to Neoware's Eon platform running the NeoLinux operating system which is based upon Official Red Hat Linux. NeoLinux is the first embedded version of Official Red Hat Linux. Neoware has also announced that the opening of four new US sales offices to continue its growth efforts. This coincides with an recruitment of several key personnel.          VMware Announces New User Group Program  Palo Alto, Calif., Sept. 28, 2000 -  VMware, Inc.  today announced the launch of a new and improved user group program. This program will provide support to relevant user groups around the world in the form of software, giveaways, product collateral and technical guides, presentation materials, consideration for VMware speaker participation at events, and more. Further information is available at VMware's site.  http://www.vmware.com/news/user_groups/index.jsp .          Sensiva partners with Wacom Asia Pacific  Mountain View, California, Oct. 2, 2000-  Sensiva, Inc. , a leading manufacturer of computer graphic tablets and electronic pens, announces a partnership with Wacom Co., Ltd., to offer Sensiva clients interactive symbol recognition functionality in all their tablet products. Through this, people will not only be allowed to copy and paste images directly into the computer but to also navigate much faster through Internet and software applications using simple symbols.          China Internet laws     CNN has a  scary article  about China's Internet laws. ""Internet content and service providers must keep records of all the content that appears on their Web sites and all the users who dial on to their servers for 60 days, and hand the records to police on demand, the rules state.""  Definitions of illegal content are vague, such as ""spreading rumors"", ""disrupting social stability"", gambling and pornography. The rules also forbid ""harming ethnic unity"" and ""advocating cults and feudal superstition"" -- terms often invoked to prosecute suspected Tibetan independence activists and members of Falun Gong and other spiritual movements.           Opera, PalmPalm and Trolltech form Strategic Alliance for Asian Embedded Linux Market  Sept. 25, 2000:   Opera Software ,   PalmPalm Technology Inc. , and   Trolltech  announce the formation of a strategic alliance for the Asian wireless Linux market. The companies will jointly develop ""Linux Total Solution for Wireless Internet Appliance"" for hardware manufacturers in the wireless Internet space.  Linux Total Solution for Wireless Internet Appliance consists of Opera's ""Opera for Linux"" Web browser, Trolltech's ""Qt/Embedded,"" an embedded GUI environment and windowing system, integrated with PalmPalm's ""Tynux,"" a Linux Operating System optimized for the wireless Internet. This is to provide a complete embedded Linux solution for wireless Internet devices.             Linux Links   Linux.com  Talk to Eazel about Linux UI and working in the OSS model  The Duke of URL  Links      Linux Buyer's Guide #5  Includes details on current state of video cards for linux, 3dfx, Matrox, the works. Also, looks at configured systems covering the gamut of price points, and examines where the future hardware advances will take us.      3D on Linux HowTo  Covers setup of NVidia, 3dfx and Matrox accelerated drivers. Plus, an overview of 3D in Linux.      Interview with Nick Triantos  While NVidia has broken into Linux, there is still much mystery behind their drivers. Open source, closed-source, licensed technologies and more are our subjects today with our guest, Nick Triantos of NVidia.      Libranet Linux 1.8  Libranet is based on the Debian Potato, and sports a new breed of user-friendliness and a scaled-down package selection that even includes the likes of QuakeForge. Read a review here.      Wireless LAN Overview  The Duke of URL's newest writer has just whipped up an overview on Wireless LAN technology     Why the world needs reverse engineers  -- or -- What Digital Convergence (the maker of CueCat) wasn't telling its customers  Did Al Gore invent the Internet?    Anchordesk UK links:      Linus   has no problem with large-system vendors making kernel patches  --or--  How a famous 3-letter vendor of Big Iron is trying  hard not to use that other 4-letter f-word that ends in ""k"" and whose second letter is ""o"".     Can Cobalt make Sun shine?   On Sun's acquisition of Cobalt, maker of the Cobalt Qube.    Kernel Wiki  invites contributions of documentation/illumination on aspects of the Linux kernel.  Word processing in Linux  : a business perspective.    The  Ninth International Python Conference .     Gimp-Savvy.com  contains a guide called ""Grokking the GIMP"", which covers the use of the GIMP's core tools and shows how nine major projects were done.    The  HP-HOWTO  shows how to use Linux with various Hewlett-Packard products, and what level of Linux support there is for each product.     European lawmakers  propose to make hacking illegal . (MSNBC)    An interesting proposal to force   abandoned copyrighted products into the public domain . (OS Opinion)    A review of  four Windows emulators  and PC emulators. (Linux World)     Linux in the financial industry . (Tech Web)     Embedded OS licencing fees :  how the lack of licencing fees for embedded Linux products will enable many times more embedded devices to appear on the market and allow smaller companies to get in on the act. (ZDnet)    Interview with Vincent Rijmen of the Rindael AES algorithm, a  DES replacement  which is much harder to crack.  Rindael is unencumbered by  intellectual-property and patent claims.  (Linux Security)               Software Announcements          NetworX Linux Cluster Helps Researchers Fight Disease  SANDY, UTAH, Oct. 3, 2000 -  Linux NetworX, Inc. , a provider of large-scale clustered computer solutions, announced today that the National Center for Macromolecular Imaging (NCMI) at  Baylor College of Medicine  will use the company's clustered computers in its world-renowned molecular imaging research center.  Using a 32-processor cluster system from Linux NetworX, Baylor College of Medicine reconstructs the molecular configurations of disease and illness-causing viruses and other molecules and develops three-dimensional models of their structures. A cutting-edge technique then allows researchers to view the viruses as if they were locks. By properly studying these ""locks,"" they hope to find the ""keys"" to opening and destroying them. In the past, much of this research was done on large supercomputers costing millions of dollars. But today, because of price-performance issues, clustered-computer alternatives are being selected to handle the large amounts of computation, data handling and storage required.  In the past, scientists used trial and error methods to create vaccines and drugs to fight viruses. But now, using clustered computers and other technologies, they are able to define the structure of these viruses and attempt to design drugs that will solve the specific problems each one presents.  In further good news for the company, the Linux NetworX Evolocity (TM) cluster server receives Best of Show Award for Network Servers & Peripherals from InernetWeek and Network Computing at NetWorld+Interop 2000 Atlanta. The Evolocity cluster server, introduced at the show, is designed for managing and optimizing Web traffic in the Internet market.          Tridia  ATLANTA Sept. 25, 2000---  Tridia Corporation , a provider of eSupport tools that facilitate interactive support and remote system administration, has launched Release 2.0 of the company's newest product offering, TridiaVNC (virtual network computing) the first commercially supported release of open-source, virtual network computing software that views and controls Linux consoles. TridiaVNC Release 2.0's Linux viewer and control features make Linux servers remotely manageable from anywhere on the network and from a variety of systems (Linux, Windows, Unix, Mac). A prerelease binary (e.g., beta) will be available by Sept 26 on  www.tridiavnc.com . The source code will also be available to the public via CVS at  www.developvnc.org . Those wishing to contribute to this open-source endeavour may also like to try their hand at naming the TridiaVNC Alien mascot. Further incentive is the US$5000 prize for the winning entry! Entries can be made on the TridiaVNC  website  before November 30 2000.            Teamware Office 5.3 for Linux   Teamware Group  has a Groupware application for Linux called Teamware Office 5.3 for Linux. The product is available in RPM format for a 90-day evaluation period with a 50-user license at  www.teamware.com/linux/ . It is a ready-to-run groupware product for corporate collaboration and communication with a customizable user interface and state-of-the-art communications features. It will be sold for $1000 USD for a 100 user server license.            Proven CHOICE Accounting releases Internet Toolkit  Oct. 2, 2000 ---  Proven Software, Inc.  is pleased to announce the release of the Proven CHOICE Internet Toolkit designed to help developers integrate internet applications to Proven CHOICE accounting. For details, consult this  website.  A sample application using the Proven CHOICE inventory file is available for  inspection.  Proven CHOICE is a powerful multi-user accounting system for linux with the attributes needed by organizations of medium size. Proven Software has been developing multi-user business applications for 18 years and exclusively in Linux for over 5 years.          Workstation Solutions Announces Quick Restore 2.7  AMHERST, N.H., Oct. 17, 2000 -  Workstation Solutions, Inc. , a leader in innovative data protection software, announces major enhancements to Quick Restore 2.7 that provide increased performance and scalability in data protection of network attached storage (NAS) and other platforms. Quick Restore's new performance, scalability, and ease-of-use features allow customers to backup and restore critical business information rapidly and cost-effectively. Quick Restore 2.7 can be used with a host of new devices from Compaq, Exabyte, HP, Breece Hill, Spectra Logic, ADIC, Qualstar, and StorageTek. Quick Restore 2.7 is available immediately from Workstation Solutions. List pricing begins at $2500. As part of their partnership building strategy, Workstation Solutions have formed partnerships with Network Appliance, VA Linux, and Mirapoint to Support Leading NAS Servers. Their aim is for Quick Restore to provide flexible, fail-safe, high-volume data protection for these companies' platforms.          Internet C++ (ICVM) Alpha Release  Bob A. Dayley, inventor of Internet C++ (an open alternative to Java and C-Sharp) recently announced the product's alpha release. This release is a demonstration and test of the virtual machine (ICVM), the compiler (igcc), and libraries. Complete source to Internet C++ and ICVM are available for download, as well as binary releases of ICVM for Unix/Unix-like platforms, including Linux, FreeBSD, and NetBSD. Internet C++ feature a high-speed virtual machine (ICVM) that is fast enough to run Doom with no JIT compilation. Bob invites anyone interested to download their Doom port and check it out for yourself! Further  information  is available.                Other software         The  Opera web browser 4.0  for Linux is now in beta.     Magic Software  is building an e-tailing solution called TISTrade for Toyo Information Systems, based on  Magic eMerchant.  TISTrade will make it easier for manufacturers and retailers outside Japan to sell to consumers in Japan.              Copyright © 2000, Michael Conry and the Editors of  Linux Gazette . Copying license  http://www.Linuxgazette.com/copying.html  Published in Issue 59 of  Linux Gazette , November 2000                     The Answer Gang           By Jim Dennis, Ben Okopnik, Dan Wilder, Dustin Puryear, Anthony Greene,  Brian Finn, Richard Turner, the Editors of  Linux Gazette ...   and You!  Send questions (or interesting answers) to   linux-questions-only@ssc.com          Contents:     ¶: Greetings From Heather Stern        Linux Gazette   table overflow   Sed / Awk Script   Porting to Access   Issues with a modem   LinuxRedHat Errno 404   IP Masq and X   extra keyboard keys under X   cloning with dd   `HELP: Crontab not running   Replacing an MS Exchange Mail Server with Linux   background processes in Linux   serial consoles, install, boot, etc --or--  Serial Consoles    Confused About Internet Access to My Home Computer --or--  Does Internet access require an ISP?           Greetings from Heather Stern    Well, it's autumn at last, and sunny but cold and windy days (with the leaves fluttering around ... heh, that would make a great backdrop on my wallpaper...) are in competition with fluffy grey cloudy days (which I also like).  I'm pretty pleased;  the Gang is growing!   The flip side of that is, I didn't get quite everything in.  Some of the items might well become seperate articles.  Others will be seen next  month.   Anyways, I wanted to babble just a little bit about themes.  Nowadays your computer does not have to be drab and boring.   Or, it  can  be plain - but  your  idea of comfortably plain.  With the fancier window managers you hardly have to be sure that windows under X are still square.   So, what did your computer dress like for All Hallow's Eve?  Mine wants to go as a Tektronix vector terminal, and the best I could find it was a copy of Spacewars...   See you next month, everyone!          Linux Gazette     From  Ben Okopnik  to Jon Lapham on Thu, 5 Oct 2000       If I read your article correctly, you used sendmail to change your ""From"" header and add some aliases.  Why did you use sendmail to do this?  Why not set all this up in your email client?  As a fellow mutt enthusiast, you do know that this can be configured in your .muttrc and that you can set up a global "".muttrc"" for the system?  It seems to me that you should try to make it easy for your brother to do things like add a new alias to his email list.  The sendmail alias solution seems a bit overkill IMO.     I see that I've failed to explain my requirements sufficiently... <grin> I swear, LG readers are the best literary critics in the world!     Changing the  /etc/Muttrc  or the ~/.muttrc only changes the ""From:"" (note the colon), and not the ""From "" header (which does not exist at the time that the e-mail is created; it is added by the MTA). A number of mail readers, including Netscape (at this point, having done some serious fiddling with Muttrc, I'm uncertain about Mutt), use the ""From "" header in forming their 'Received from' and 'On dd/dd/dd, <user> wrote:' lines; since I get quite a lot of mail from other Linux users, I see a lot of ""On dd/dd/dd, root wrote:""... Often (and this is much worse) the sender addy looks normal, but the ""Reply to:"" is set to ""localusername@isp_host.com""   -  if you don't pay attention when you hit ""Reply"", you'll get an unpleasant surprise in 3-5 days (e.g., ""Mail could not be delivered to ' root@geocities.com '..."") In order to fix those headers completely, I change both the .muttrc and the sendmail setup. By the way, I found that in RedHat, the 'send-hook * my_hdr From:' line in Muttrc caused Mutt to give an error message. It works fine on my  Debian  boxes...     Also, rather than adding  aliases , I've caused sendmail to do  address conversions , a completely different issue. An alias is a short name used as a substitute for a recipient's mail address; the conversions are a way for sendmail to know that the local username ""ben"" should be converted to "" fuzzybear@pocketmail.com "" on all outgoing mail.     I install RH linux on peoples machines all the time, and I have to say I almost never have to change the default sendmail setup, even for single user systems connected via ISP.     Try this: once you've set up one of those accounts, send mail to yourself (not the local username, but the mail account at your ISP) and read the headers. You'll most likely find that the ""From "" header has your local username instead of your e-mail address. Of course, if you've found a way to fix this via Muttrc, I would be more than happy to learn it!     Ben Okopnik                 table overflow     From  Heather Stern  and  Jim Dennis  to   james zhuang on Fri, 6 Oct 2000       Hi,     I am runing Redhat Linux 6.x.  Recently I am getting an error message 'neighbour table overflow' pop up in the console screen.     Any ideas,  James    [Heather] Yes, it means your localhost interface is not set up correctly.  I don't know the actual mechanics (perhaps one of the rest of the Gang will chime in) but basically, the message is about your ARP cache going crazy trying to deal with what is really local traffic.     Until you fix it, session based protocols like samba, nfs, ftp and telnet, and ssh will have iffy connections.  Samba and NFS will probably be so annoying you can't really use them; a good ftp client will just feel like it's slow as molasses.     Whereas, if you go into  /etc/sysconfig/network-scripts  and you make sure that you have a valid ifcfg-lo file, things will be properly speedy.    [JimD] I noticed that 'pump' and some other DHCP clients would corrupt your localhost/loopback configuration and remove the routes thereto unless you explicity tell them which interface you want them to work on.  You'd think that 'pump' et al would default to leaving your lo interface alone  ---  but that seemed to be where I was getting it for awhile.                Sed / Awk Script     From  Dan Wilder  to Kopf on Sat, 14 Oct 2000       Could someone tell me how to write a sed script which'll put text at the beginning of each line of a file, and change all the backslashes in the file to forwardslashes?     I need it so that I can change all my .m3u files from windows format to UNIX, IE from:     Deftones\White Pony\Pink Maggit.mp3     to      /mnt/win_c/mp3s/Deftones/White  Pony/Pink Maggit.mp3     Anyone have any ideas?     Haven't tried it, but     #!/bin/sh  #  # call with filename as first argument.  Puts  # out revised file to standard out     sed 's%\%/%g;s%^%/mnt/win_c/mp3s/%' $1     Uses ""%"" as delimiter, to avoid having to escape the more conventional forward slash.  The     s%\%/%g     says to put a forward slash in place of a backslash, and the ""g"" modifier says to do it for every such.     ;     is a command delimiter     s%^%/mnt/win_c/mp3s/%     says to substitute  /mnt...  at the beginning of each line (that's what ""^"" matches).     For more info, see ""man sed"".  This manpage contains one of the several fine introductions to regular expressions, which have the ability to match things like the beginning or ending of a line, strings containing not just particular characters put particular sets of characters, and so on. See also ""man grep"".       ... but, when Kopf tried it ...        Hi Dan,     I entered that in, but it gives me an error of:     sed:  -e  expression #1, char 11: Unknown option to 's'     I don't know what char 11 is, is it the 11th character inside the quotes of what's being sent to sed? I've been messing around with the script, but to no avail...     Any Ideas?     Thanks,     Aengus    Try     sed 's%\\%/%g;s%^%/mnt/win_c/mp3s/%'     The ""\"" has special significance as an escape character, means ""ignore me but take next character literally"".     My bad.                Porting to Access     From  Ben Okopnik  to John Humphre Halliday on Tue, 17 Oct 2000       Hello Answer Guy!     Hello, John -     The Answer Guy/Gang is a column in the Linux Gazette; we answer Linux-based questions for our readers. It just so happens, though, that I was the EDP manager for an insurance company in the Virgin Islands  -  and this company used Clipper (all the in-house apps were written in it). Due to the major Y2K issues inherent in their operations, I convinced them to switch to a different suite of apps  -  which involved converting the old databases to Access.     First, for the Linux community: for those of you who want to read/use Clipper DBFs under Linux, I've written a front end for Martin Schulze's ""dbview"" called ""clipview""; it's a viewer/converter that patches the differences between the two formats. It's available on my site  -   http://www.geocities.com/~ben-fuzzybear/clipview.tgz   -  and Martin may also be including the functionality in future releases of ""dbview"".     I was hoping you'd be able to recommend the quickest way to port from a Clipper/DB2 database to Access 2000.  A client has asked that I do this for them and I know almost nothing about Clipper  -  just that it's a compiler for DB2 type databases (.dbf).  Is it possible to access the tables through an ODBC connection in Access and simply copy/import the tables/data to Access?     You actually have several ways to do it; Access can link the files via ODBC or read them via its ""import"" facility (DB3, DB4, or FoxPro types work fine; I seem to remember DB2 as not working correctly...) Note that linking works fine unless you specify ""shared"" mode; then, it becomes dead slow. If you decide to import the files, make absolutely sure that you index them beforehand; Access can make a really horrible mess of a file that is out of index, and will do so without any notification... By the same token, double-check any files you import (# of records, totals, etc.)     Good luck!  Ben Okopnik                 Issues with a modem    From  Ben Okopnik  to J. Miguel Iglesias S. on Wed, 18 Oct 2000        I have a PC running RedHat 6.2, I also have an internal Motorola ModemSurfr 56k.     Some guy told me he found the way to make it work with linux, so he told me to define the parameters using the setserial function.     Just for the sake of clarity: ""setserial"" is used to configure the serial port, which is necessary for access to the modem; it does not configure the modem itself. In the case of internal modems such as yours, the port is part of the card itself  -  but you should still realize that there is a difference.     Checking the boot log I saw the system runs setserial at boot and detects the port for the modem.     That's pretty standard, at least in the distributions with which I'm familiar; the problem is that the values to which the ports are set are usually 'auto' or default values. It pays to manually configure ""setserial"" to get the best performance (and in some cases, _any_ performance) from your serial ports: after a bit of tweaking, I saw the data transfer rate across my serial link go from just over 9kB/s to just under 12kB/s.     However I used the setserial function and somehow my modem gave me some response using minicom.     A good sign! This says that your modem is _not_ a Winmodem, and you're talking to the right port.     If I use minicom, I'm able to dial to my ISP, but the speed is way too slow (it takes about 30 seconds just to display the greeting from my ISP) so my connection times out before I'm able to login to the ISP.     This sounds like a conflict  -  and in this term, I include hardware as well as software that sets up hardware, such as ""setserial"". Let's go over the possibilities.     1) Serial port. As a guess, I would say that this is most likely the culprit, given that tweaking ""setserial"" is what allowed you to see your modem in the first place. Read the ""setserial"" man page carefully, particularly paying attention to the speed flags such as ""hi"" and ""vhi"". Check the other settings for the port you're using, port and IRQ both, and _specify_ them rather than auto-configuring. ""setserial"" can be used right from the command line, so you do not have to reboot to change the settings; experiment with different values and see if they produce any changes.     2) ""Usage"" conflict. In theory, once some piece of software uses a given serial port, it will write a ""lock"" file that will prevent other software from trying to use it. Unfortunately, this scheme is not perfect: a particularly stupid piece of software (one that does not honor or check for the lock), or one that uses the 'cua' port addressing scheme (as in ' /dev/cua0 ', etc.) may try to use a port that is already in use, causing a problem. Immediately after rebooting and _before_ trying to do anything with the modem, try running the ""fuser"" utility on the appropriate "" /dev/ttySx "" port  -  if another process is using it, ""fuser"" should let you know.     3) IRQ conflict. I've noticed that under Linux, as contrasted against DOS/Win, IRQ conflicts seem to slow down the associated process instead of just crashing the machine; a ""friendlier"" response, as I see it, and certainly easier to diagnose. Try removing the modem from the system and checking "" /proc/interrupts "" for other hardware using the IRQ that it requires (e.g., IRQ4 for ttyS0/ttyS2, or IRQ3 for ttyS1/ttyS3.) Also, check "" /proc/ioports "" for 03F8, 02F8, 03E8, and 02E8  -  the port addresses for ttyS[0123]  -  though I wouldn't expect too much trouble there.     If I use the pppdial in Gnome it simply don't detect my modem.     I would first make sure that the serial port and the modem were working OK before trying to set up a dial-up account  -  i.e., eliminate the conflicts and make a good connection via ""minicom"" (make sure you're using the correct setup values in ""minicom"", as well!), _then_ worry about automating the dial-up.     Good luck,  Ben Okopnik           ... Miguel replies...      I will try all your hints and let you know how it worked, maybe my experience will bring some hope with this modem to other users.     I'm considering to buy an external modem anyway (but still want to make my current modem as well), do you think I should buy a CNet ($70) or I should go safer and buy an US Robotics ($110)?     Thanks a lot for all your help and regards     Miguel     My experience with modems is that ""you get what you pay for"". I've had excellent luck with USR and Hayes modems, variable with other brands; given the above choices, I would certainly plunk down the extra money for the USR.     Along with LinuxMafia's Rick Moen, I believe that internal modems, when ground fine and lightly roasted, make a decent coffee but have little use otherwise; making your existing modem work is good troubleshooting practice, but your idea of replacing it with an external is a good one.     Ben Okopnik, modem curmudgeon                    LinuxRedHat Errno 404     From  Heather Stern  to Ken  on Wed, 18 Oct 2000       I want to change the default of Errno 404, so that the user is redirected to another URL when they request a URL that is not on my server. What directory and file do I need to edit?     In most web servers it's possible to configure it so 404 errors (or other numbered errors, another popular one to force this way is 501 as it sometimes happens from broken scripts) go to a special page of your choice.  A lot of big ISPs have 404 errors lead to a front page for their search engine, explaining that whatever you were trying to find has moved.     On  Apache  under  SuSE , the file to adjust is  /etc/httpd/httpd.conf  but it could as easily be under a home directory for Apache under  /usr  somewhere.  I've no experience with the other servers, but the powerful ones like Roxen Challenger and aolserver should definitely also have the feature available.                 IP Masq and X     From  Heather Stern  to M.K. Laha  on Thu, 19 Oct 2000       My Linux PC is on a private LAN that connects to the internet through a (Linux based) router using IP masquerading.     My problem is that I can't seem to point the DISPLAY environment variable on a remote machine on the internet to that of my Linux PC. So, if I run, say, gnuplot, on the remote server, I cannot see its output on my PC.     I've tried setting the DISPLAY variable on the remote machine to point to the router but that doesn't work. Seeting the DISPLAY variable to point to my PC obviously doesn't work because it is not ""visible"" to the remote machine on the internet.     I shall greatly appreciate any help/pointers. Thanks in advance.      -  Manas Laha     So assuming that you are at one Linux box (Home) and your other Linux box (Work) is behind all this firewall stuff.  (Yours might really have some other relationship to you, but this will help everyone understand what I mean, and usually it's corporate boxes that have better defenses.)     If you have been provided a way to reach Work from Home via ssh, then all you need to do is turn on X11 forwarding.  Then ssh will create a ""virtual"" display (usually Work:10.0) which will acept X GUI commands, but really send them up the ssh pipe back to Home.     So, ot's okay not to be running X on the Work system at all, as long as the libraries are there so programs that you want to run can be good X clients. You do need to be running X on your Home system though.  Launch ssh out of an xterm (eterm, etc.) and both your ssh client plus Work's ssh daemon must be given the options that X11 forwarding is okay.  Why?  Because these days it usually defaults to off, as it's a security risk; X usally has an annoyingly strong root privilege.  You can reduce the risk by using .Xauthority files so only  your  account at Work can use the pipe.     What most people don't think of, is that this trick, where Work's CPU is supposed to display on Home's monitor, used to be the normal way that the X windowing system was used... and that's why the part of X that paints on the monitor is called the server.           ... Manas answers...       Thanks for your prompt reply. I haven't tried using ssh so far, but I shall certainly try it out now.      -  Manas Laha            extra keyboard keys under X    From  Ben Okopnik  to Gavin W. Burris on Sun, 22 Oct 2000        I have a Gateway keyboard with multimedia keys along the top.  Is there any way to use these under X?  Could I press one and have a program or shell script run?  Thank you for your time.     The answer depends on exactly what those keys do. If they are ""programmable"" keys such as Gateway used to have, then their definition is up to you: if you can invoke a shell script by typing something in, then you can invoke it with a ""programmable"" key. As an example, ""icewm"" can use those ""Windows"" keys to pull up the program menu; a combination of arrow keys and the 'Enter' key will invoke any of the listed apps. ""icewm"" can also (I believe this violates the ""window manager mandate"", but works very well for me personally) intercept Ctrl- key combinations, which can then be tied to specific commands.     If, on the other hand, they generate some sort of previously unmapped key codes, then you would have to dig a little deeper into your WM man page and other reference material. The ""key codes must be passed to the application"" directive seems to be one that is ignored by most WMs, and one or more may be capable of being 'told' to intercept these new codes  -  but this would obviously be a per-WM-specific feature.     I recommend taking a closer look at what's happening via 'showkey' in a VT and 'xev' in an xterm. Once you have an idea of what keycodes you're generating, you'll know in what direction to search.     Ben Okopnik                 cloning with dd    From  Ben Okopnik  to Chris Smart on Mon, 23 Oct 2000       Hi, do you know how I can speed up the dd command under Linux when cloning disks. I use dd if=/dev/hd? of=/dev/hd? at the moment, are there any flags that I can use to speed it up. Or maybe you know a quicker way to clone disks that preferably doesn't use Norton ghost or powerquest disk image!     Any help will be much appreciated     There is a ""hard limit"" associated with the type of process that you're talking about: the 'speed', or the maximum data transfer rate of the slowest HD. One tool that could be useful, especially if you're cloning to a number of identical drives, is ""hdparm""  -  the man page gives a good ""tuning"" guide (I got a significant improvement from my laptop HD performance after playing with it for a bit) which can help you maximize the DTR of a given drive. This applies to both of the drives involved.     The other issue is, of course, ""dd"" itself, particularly the 'bs' option which sets the size of the block that is read from 'if' and written to 'of'. Here is a test worth trying:     time dd if=/dev/hd? of=testfile bs=[N]k count=M     where NxM=10Mbytes, and the source and the target are on different drives. Vary N (and consequently M) and see what blocksize gives you the best performance. Given this type of custom-tweaking, I believe you should be able to improve on the performance of any other software...     Ben Okopnik                 `HELP: Crontab not running    From  Richard N. Turner  on Sat, 09 Sep 2000       Dear Editor,     I saw the article mentioned in the subject and some of the followups and had to reply.     I've seen more than my share of people cursing cron and saying: ""But the script runs fine from the command line!"".  Pierre Abbat's reply in the September issue was right on.  Most people will modify the PATH variable to include some directories beyond the major ones that get defined in places like  /etc/profile  and scripts will fail when they attempt to run some commands that rely on this modified PATH.     The thing to remember is that cron doesn't run your .profile when it runs a script.  If you don't explicitly define the full path to a program run from within the script it'll fail.  So you either have to make sure your script contains something like ""/home/mydir/devel/bin/prog1"" (or whatever) or amend the PATH at the top of the script.     Another alternative is to just source, depending on your shell, either .profile or .bash_profile from within your script (assuming that it defines PATH and whatever other environment variables were helping the script run from the command line).  If you include a line near the top of your script like:     . /home/mydir/.profile     or     . /home/mydir/.bash_profile     all things you usually rely on in your interactive environment are defined for your scripts run under cron as well.     If you do decide to source your .profile, you might want to watch for things that depend on there being a display and/or keyboard ""attached"" to the process running the script.  If there isn't, you might see strange error messages like ""not a typewriter"" or ""cannot open display :0.0"".  I have a toolbox of variables and shell functions that I like to use in a file called ""std_functions"" which I source near the beginning of my interactive environment setup as well as my scripts.  One of the things I put in `std_functions' is:          TRUE=""0 -eq 0""      #Lets you define Boolean environment variables and      FALSE=""1 -eq 0""     #makes scripts easier to read six months from now.      if [ -t 0 ]      then           INTERACTIVE=${TRUE}      else           INTERACTIVE=${FALSE}      fi     The ""-t"" test returns `true' if stdin (file handle 0) is associated with a terminal.  Then in your profile, you can do things like run xrdb using:          if [ ${INTERACTIVE} ]      then           xrdb -l ~.Xresources      fi     and not get weird messages from your cron jobs (The above `if' block would, of course, evaluate as false under cron).  I tend to keep my profile arranged so that any setup that I need for my interactive sessions is wrapped by an if-then-fi block.  After all, you don't really need to define aliases and use them in your shell scripts (Ugh!).     Hope this'll help someone...     PS:  I've somehow missed reading the Gazette for the last couple of months.  It keeps getting better.  Keep up the good work.     -- RNT        On behalf of the crew, thanks!  We couldn't do it without you!  -- Heather              Replacing an MS Exchange Mail Server with Linux    From  Dustin Puryear ,  Anthony E. Greene ,  and  Brian Finn  to   hutchins on 11 Sep 00       On this subject, we hear both from the author of a good book  all about it, a serious cross-platform power user, and someone  who simply found something better than Exchange to use in  this fashion.     This is a sort of follow on to your discussion in Issue 56 of reasons not to migrate a Linux mailserver to MS Exchange.     One feature that the MS Exchange Server/Outlook Client (as well as the Lotus Notes Server/Client) offers is a centralized address book.    [Dustin] Dear Jonathan,     I read with some dismay your message to Linux Gazette regarding a lack of ""centralized"" directory services on Linux. Nothing could be further from the truth. There are several LDAP servers ready to run on Linux. Better yet, OpenLDAP, an open-source LDAP server, compiles easily on Linux and can be integrated with MTA's such as Sendmail and Postfix. In addition, you can access the directories on OpenLDAP from Netscape or Outlook 98+ easily. In fact, I have implemented OpenLDAP at my company and it works great!     FYI, I cover both Postfix and OpenLDAP in my book, ""Integrate Linux Solutions into Your Windows Network,"" which is aimed specifically at NT managers wishing to use Linux to their advantage in NT-dominated networks. (Of course, it works the other way around as well--if you wish to bring NT/Windows into your UNIX organization the book just as well.)     Feel free to ask me any specific questions that you may have.     Best regards, Dustin     --- Dustin Puryear  dpuryear@usa.net       Hey Dustin, thanks for joining the Gang!  If anyone sends you good  questions and you copy your answers to  LG  at   linux-questions-only@ssc.com  -- we will publish  them so more people can understand how it all ticks.  -- Heather     [Anthony] There is no reason this would not work for external addresses. I run an LDAP server on my home network for members of my household. Most of the addresses are for external users. I update it using an LDAP client < http://www.biot.com/gq/> ; and the changes are immediately available to everyone.     Netscape has no problem using the LDAP server automatically to resolve partial addresses. I did the same thing in my former organization where Outlook 2000 and Outlook Express were the clients. The Outlook 2000 client needed to be tweaked to use a more flexible LDAP query, but then they both worked fine. Even the StarOffice mail client can use LDAP, but the procedure for selecting addresses in StarMail is tedious and non-intuitive.     The Outlook 2000 installer makes you choose either Internet-Only or Exchange Server mode. If you choose Exchange Server mode (the default, I think), then you will have to edit the registry to get a more flexible LDAP query. The default search looks only at the beginning of the email address. It does not search the 'cn' (commonName), 'sn' (surname), 'givenName', or any other attributes. I changed the search so that it looked anywhwere in the 'cn' attribute. You can figure this out by looking at the man pages for the utilities that ship with OpenLDAP and the registry entry associated with the LDAP server on the Windows client machine.     If you're limited to performing updates from a Winbox, you might look into ldap-abook < http://sourceforge.net/projects/ldap-abook/ >. It's a set of perl scripts and a module that makes it easy to maintain an LDAP address book. You will probably have to edit the scripts to fit your situation, but it can work. I found it easier to do batch updates by updating an LDIF file and re-importing the whole thing during off-peak periods. If you have a large directory, you'll probably want to get a good LDAP client instead. The utility programs that come with OpenLDAP are pretty good if you only have command-line access to the server.        [Brian] In issue 58, an Answer Guy reader was looking for a Linux replacement for Microsoft Exchange. I believe OpenMail by HP ( http://www.hp.com/go/openmail )  could be what he is looking for. Here is a blurb from Info World about it:     ""Summary: HP OpenMail is an impressive, highly scalable mail server. One OpenMail server will handle Microsoft Outlook (with scheduling and calendar), Lotus cc:Mail, Lotus Notes, Microsoft Mail, Web, and standard e-mail clients.     Cost: Free for Red hat Linux servers with up to 50 mailboxes. $41 per mailbox on Linux Servers, $77 per mailbox on other platforms.     Platforms:  Red Hat  Linux 6.x;   HP-UX 10.20 or 11.0;   AIX 4.21 or 4.3;   Solaris 2.5.1 to 2.6     Hope this helps,  Brian Finn                 background processes in Linux    From  Peter Samuelson  to Andy Larkum on Sat, 30 Sep 2000       Regarding a recent LG Two-Cent Tip-- [Andy Larkum asks LG]     I have a small query. I want to log into a Linux machine, set a process running, and log out again, leaving the process running. It has been suggested that I can do this by simply using 'nohup command &' but this didn't work, because the process was killed as soon as I logged out again.    [Heather responds]   screen with autodetach mode turned on would work nicely. We use it here all the time. -- Heather     [Peter] What you want is the 'disown' command, a bash builtin.  It causes the shell to detach a background job from the tty and basically forget it ever existed.     This is really useful in loops.  Often I want to start 100 jobs in the background but don't care about stopping them later.  So:     i=0; while [ $i -lt 100 ]; do some_long_job_involving_$i & disown; ((i=i+1)); done     Note that I use '&' to put each job in the background, then immediately disown it.  That way the job numbers don't accumulate and get in the way.     If you are forced to use a non-bash shell that doesn't support disown, you can get the same effect by running the background job in a subshell:     sh -c 'some_long_job &'     The 'sh' you spawn to run the job exits immediately  --  it's not an interactive shell so it doesn't bother with th job control crap  --  and your login shell is none the wiser about some_long_job still going.     Peter                 Serial Consoles     From  Jim Dennis  to Joseph Annino on Sun, 08 Oct 2000         One thing that is really great about Sun hardware is that you can get rid of the monitor, mouse, and keyboard all together and do everything from install the operating system to change EEPROM settings via a serial console.  While Intel hardware was never designed this way, I cannot find much information about setting up Linux on Intel to approximate this.  Is it possible to install and boot Linux over a serial console?  Log-in in this way is easy, but to be able to completely administer a system the install and boot functions are critical, especially the Lilo prompt would be nice.     Note: Linux on Sun and other SPARC hardware supports the serial console just as you'd expect.  Let's try to remember that Linux is just a ""PC UNIX"" anymore.  I've also used Linux serial console on PReP (PowerPC Reference Platform) systems.     I've heard that some new Intel motherboards include BIOS support for serial console.  However, I haven't seen one of those yet.     As to your question.  Yes, Linux can support a serial console, and it can concurrently support the normal PC console (with virtual consoles) and a serial console.     Your first step is to compile your kernel with serial console support.  That's a standard configuration option in the 2.2.x kernels and it was available as an unofficial patch for years (since the pre-1.0 days).  There is a small text file to explain this support in  /usr/src/linux/Documentation/serial-console.txt  (Obviously depends on your kernel version, but it's been there for awhile so any recent kernel should include it).     Next you have to configure LILO by editing the  /etc/lilo.conf.  There are two parts to this configuration  ---  you want to configure the LILO bootloader itself to include support for prompting and handling input on the serial port, and you want to add a command line parameter to the kernel to enable and configure the serial console support that you had compile into it.     So you need a lilo.conf that looks something like:     boot=/dev/hda2 root=/dev/hda3 install=/boot/boot.b map=/boot/map delay=20 prompt  #      vvvvvvvvv serial=0,19200n8 #      ^^^^^^^^^  image=/boot/vmlinuz  label=new  read-only  #                vvvvvvvvvvvvvvvvv  append=""console=ttyS0,19200"" #                ^^^^^^^^^^^^^^^^^      Note that these different parameters don't have matching syntax.  On the serial= directive (which configures the LILO boot loader support) we have the port number (without the ttyS device name prefix) followed by the speed, parity and data bits.  On the append= drive we are passing a kernel option.  The kernel console= option takes the base name of a device (with the  /dev/  directory name, but with the ttyS* prefix/device name), and then the port speed.     Actually the speed, parity, and bits settings for both of these use the same format and syntax.  So the important difference is that one (the serial=) takes just a serial port number while the other takes a device name (ttyS*).  The first time I tried to get LILO working with a serial console I didn't read it carefully enough and I thought I knew more than the documentation. It took me a few hours to figure out that I needed to remove the ""ttyS"" from my serial= line!     Finally, some newer PC motherboards/chipsets have support for full serial operation.  These tend to be the more expensive keyboards that are designed for rackmount cases and are particularly handy for co-location servers.                 Does Internet access require an ISP?     From  Mike Orr  to Jeffrey Stephens on Tue, 17 Oct 2000          I'm a bit confused.  I was re-reading back issues of Linux Gazette and came across this answer which you provided in the Sept. 98 column, issue 32.  I am running Redhat 6.2 which I configured using the  KDE  workstation option.  I understand you to say in the enclosed answer that no one can access their computer over the internet without making arrangements with their ISP.  Then what's the big deal about securing my cable connection?  Since I haven't made any arrangements with my ISP your answer would seem to suggest that I am secure.  On the other hand, if someone can break into my machine then I ought to be able to connect with it myself over the internet without going through my ISP.  Am I missing something here?     Regards,     Jeff Stephens     [a past reply]    Permission to Set up a Linux Server        Alright, I finally figured out what you were asking. It took a little work, though.     First note: when you set up a Linux system it defaults to providing many services. It is already a ""server.""     What you seem to be asking is: ""How do I make my server accessible via the Internet?""     As you surmised you would have to make arrangements with some ISP to have some dedicated (or at least ""dial on demand"") connection to the net, or to ""co-locate"" your hardware with them.        [Mike] There are several issues here.  One is, what the terms ""server"", ""ISP"" and ""being connected to the Internet"" all mean.  Another is, how do the different types of Internet connections affect how easy it is for a cracker to break into your computer.     If you have Internet access, you are connected to the Internet  through  an ISP (Internet Service Provider) of some sort.  For cable modems, the cable company normally runs its own ISP that all customers must use. My DSL provider allows me to use any of several local ISPs instead of their own.  The cableco or telco connects you to your ISP through some non-Internet means (cable or DSL to the cableco/telco central office, then ATM or Frame Relay or whatever to the ISP), and then the ISP takes it from there.  Your ISP is your gateway to the Internet: no gateway, no Internet.      Being a ""server"" means your computer runs services which other people can use.  Of course, at the most basic level, all Internet-aware computers are servers, because Internet is a two-way street, and if you can ping up other computers, other computers can ping you. But normally ""server"" means you're running application-level services: web, e-mail, ssh, telnet, ftp, etc. that other people can use.  And yes, most Linux distributions come with all these services enabled by default, and yes, this is a security risk.  (See""Linux Security, or Rather, the Lack Thereof"" in last month's News Bytes ( http://www.linuxgazette.com/issue58/lg_bytes58.html#general ).) You should know which services your computer is running and turn off those you don't specifically want to offer.    The answer you quoted was from 1998, and things were different back then.  Cable modems and DSL were not common, at least not in the US. (Although my Canadian friend likes to point out that he had a cable modem in eastern BC a year before we even heard the term ""cable modem"".) Almost everybody used analog modems with dial-up connections.  Dial-up connections are by nature less vulnerable to attack than cable modems are, because the would-be cracker will find that your server:     may be disconnected right now.   may have a dynamic IP, and of course the cracker must know the machine's  current  IP (or domain name) in order to sabotage it.   To solve problem (1), dial-up users need a 24-hour connection or a ""dial on demand"" service.  Dial on demand means the ISP will telephone your computer whenever a packet comes through for it and the link is down. This requires a special arrangement with the ISP, and your computer must be configured to answer the phone, and you have to make sure that nothing else (answering machine, fax machine or person) picks up the phone first.  Most ISPs would not do this, and the few that did charged big bucks for it.     (Note: Linux distributions have the ""diald"" daemon which does dial-on-demand in the opposite direction: whenever your computer or internal network wants to connect outside, it will dial the ISP for you if the connection is down.  But this does not help the problem above, which is  incoming  traffic.)     For any kind of 24-hour connection (dedicated modem with separate phone line, ISDN, Frame Relay, T-1), you would be paying $140-$1000 per month-- out of reach for most individuals.  Those of us who have long desired this are ecstatic that we can now get this service at an affordable rate.     To solve problem (2), you need a static IP (one that never changes) or ""dynamic DNS"" service.  Of course, this affects cable modems as well.  With a cable modem, you may have a dynamic IP (which changes every time you plug in the modem, and perhaps every few days as well). This will at least ensure that even if a cracker breaks in, he (or she) won't be back over the long term, because when he tries to come back, he'll find himself on a different computer and he'll have to start from square one determining its configuration.  Of course the tradeoff is, if you wish to run a web server or e-mail server and you have a dynamic IP, it'll be mighty inconvenient for the public to know your current IP or domain name.     (""Dynamic DNS"" means the nameserver is set up to allow its configuration (which IP your domain name points to) to be changed frequently and conveniently, either by you typing a new number on a web page or by a script on your computer which sends in the new information.)     So yes, people from the outside can crack your computer even if you haven't made special arrangements with your ISP.   Linux Gazette  has published several articles this year on securing your home network, and these are all recommended reading.               More 2¢ Tips!    Send Linux Tips and Tricks to  gazette@ssc.com          Identify services   login --or--  Checking Passwords in Custom Apps    Printing under Linux   subnet needed   companies   Keyboard keys/buttons...   How to read Cisco Documentation CDROM on Linux platform   A note conserning the article ""Making a Simple Linux Network Including   Wanted: articles about non-LILO boot loaders. -- Heather   Grep   2 cent tips - re: Reflections Replacement   Modems   authentication pam and kde   Printing in Netscape                 Identify services   follow up to  issue58/tag/7.html  Mon, 2 Oct 2000 13:38:30 -0400 (EDT)  From: Mathew A Johnston  ( johnston@megaepic.com )    I'm not sure that I'm sending this to the right address, but...     I find the most useful tool in the attempt to identify services and their parents to be  netstat -ple  (process, listening, extended info).  This provides a table of listening sockets, the processes that own them, and the uid of the process.     If you're making an emergency read only anti-hack disk, put this on it - you cant trust your installed version always.     Mathew Johnston                    Checking Passwords in Custom Apps  Sun, 08 Oct 2000 14:14:04 -0700      Hi,     I need to authenticate a user entering a linux os.     I get from the user a username and a password and need to cross it with the  /etc/passwd  file.     How do I cross the password with the existing one ? (How can I enctypr the password the user entered ?)     Thanks you,  Gil.     I presume what you're trying to ask is something like: ""how can my custom script or application determine if a user has given me the password as would be checked by the system?""     The short answer is that your program should use the getpwent(3) and the crypt(3) library calls.     That is a bit of an oversimplification but here's a bit more detail:     Technically you don't ""encrypt"" the password, you ""hash"" it and compare your result with the one that's stored in the  /etc/passwd , or the  /etc/shadow  file, or the one that's returned by NIS, etc.     Here is a link to a simple example I found using Google:      http://oloon.student.utwente.nl/~remco/linux-c-programming/9902/msg00017.html      Glyn Clements is one of the most active and knowlegeable contributors to the linux-admin mailing list.  -- JimD                     Printing under Linux  Tue, 10 Oct 2000 09:52:20 -0600  From: Jim  ( JBRANDV@pnm.com )    In your answer to Gaurav you didn't mention TurboPrint.  I found the current version has full support for my Epson Photo 700 and most other Epson printers as well.  I now have full photo quality printing under Linux.  Support for other printers is growing daily so keep checking back if you don't see it the first time. The URL:   http://www.turboprint.de      It is beta (0.61) but seems to work great!     Jim                     subnet needed  Tue, 10 Oct 2000 19:45:00 -0700 (PDT)  From: Buddy Newton  ( blu3plat3@yahoo.com )    --- ""Arne C. Johnson"" wrote: what does this subnet does this network give you     192.168.160.0  /20      Thanks      192.168.160.1-192.168.175.254 4094 hosts  that's a 255.255.240.0 mask       The trick is that each ""255"" octet is 8 bits.  The number  on the end of the slash is a number of bits set on.  So, 8 + 8 =  16, still not enough, need 4 bits 4 more!  See it's really just that  many 1's counted from the left... which is to say from the    top  of the values, so within the third octet,   that's 16 + 32 + 64 + 128 = 240.  The netmask 1's allow bits  to ""leak through"" and establish the network address... the 0's  block or ""mask"" all the local addresses off.    For a  lot  more detail what this is all about,   see Jim Dennis' fairly verbose   "" routing and subnetting 101 ""   in issue 36. -- Heather                     companies  Sun, 15 Oct 2000 11:46:11 EDT    what are some of the companies that makes ""LINUX"" operating systems?     There are so many, it is hard to count them... and groups which are not companies also produce their own setups of Linux, so we call them ""distributions"".     Linux Weekly News ( http://www.lwn.net ) has a section dedicated to following this question, and a sidebar that has links to a long list of distro's - so you should check it out.  -- Heather                    Keyboard keys/buttons...  Tue, 17 Oct 2000 09:04:19 -0700    anthony buckland wrote:     I live in Japan and would like to replace the Japanese keyboard (buttons) of my NEC laptop with the English keyboard (buttons)--if you know what I mean? Now, do you happen to know of a supplier(s) in the US or elsewhere that I could possibly contact for those English buttons? I thank you, again.     I would contact NEC support via one of the links at  http://www.nec.com/support/index.html  and see if they can help.  Perhaps they can send you the keytops or at least tell you who manufactures them.  -- Mike                     How to read Cisco Documentation CDROM on Linux platform  Tue, 17 Oct 2000 08:41:39 -0700  From: Andrea Montefusco < andrew@montefusco.com >     Are you interested to such micro-howto ?  Regards  Andrea Montefusco     How to read Cisco Documentation CDROM on Linux platform       mount the cisco cdrom ( mount /dev/cdrom /mnt/cdrom )  start httpd apache daemon.  define a virtual server by mean of a listen on a port of your choice  id:    Listen 127.0.0.1:8080      You must include a Listen for your virtual servers in your virtual host configuration (specialized file or httpd.conf file); add the following instructions:   <Virtualhost localhost:8080> Options Indexes FollowSymlinks DocumentRoot /mnt/cdrom AddHandler gunzip .htm Action gunzip /cgi-bin/CiscoDoc </Virtualhost>     put in your CGI directory /home/httpd/cgi-bin the following file:  (text version)    #!/bin/sh # # echo Content-type:text/html echo   FULL_PATH=""$DOCUMENT_ROOT""""$PATH_INFO""  ROOT_FILE=""$DOCUMENT_ROOT""""/home/home.htm""  if [ -f ""$ROOT_FILE"" ]; then     bunzip2 -t ""$FULL_PATH""  1> /dev/null 2>&1     rc2=$?     if [ ""$rc2"" = ""0"" ]; then       bunzip2 --stdout ""$FULL_PATH""    else       gunzip -l ""$FULL_PATH""   1> /dev/null 2>&1       rc=$?        if [ ""$rc"" = ""0"" ]; then        gunzip --stdout ""$FULL_PATH""       else        cat ""$FULL_PATH""       fi    fi  else    echo ""<HTML><BODY>""    echo ""<H1>Root file ("" $ROOT_FILE "") not present</H1>""    echo ""<H2>Did you forget to insert the CD-ROM ? </H2>""    echo ""</BODY></HTML>"" fi  #echo ""<HTML><BODY>"" echo ""<HR>"" echo ""<H4>"" echo ""Cisco Documentation CDROM Reader ver. 0.3 -- A.Montefusco A.Passariello"" echo ""</H4>"" #echo ""</BODY></HTML>""        Make it executable with the command     chmod -c 755 CiscoDoc      Now you can access Cisco Manuals using URL: ""http://localhost:8080/home/home.htm""                      A note conserning the article ""Making a Simple Linux Network Including  Mon, 11 Sep 2000 12:05:12 +0000  From: Samuli Seppnen  ( samuli.seppanen@kolumbus.fi )    Instead of doing an "" echo 7 > /proc/parport/0/irq "" you can put following line to modules.conf:     options parport_pc io=0x378, irq=7     where io / irq should be replaced if necessary. With this you should be able to insmod plip without any problems.                     Wanted: articles about non-LILO boot loaders. -- Heather  Wed, 27 Sep 2000 22:50:54 -0400  From: ""Hoyt""  ( hduff2@att.net )    Neil Koozer of Roseburg, Oregon has created nuni, a boot loader for a Linux system that uses the ext2 file system and IDE drives.     nuni handles various ext2 block sizes and handles both small and large kernels.      www.linuxforum.org/plug/articles/nuni.html      Hoyt Duff                     Grep  Sat, 30 Sep 2000 17:36:39 +0530  From: Rakesh Tiwari  ( rakesh_tiwari@jasubhai.com )    From what i understand, u only want to know users begining with ""potatoe"" in the ""Login"" coloumn.      $finger | cut -f1 -d"" "" | grep potatoe      Regards  Rakesh Tiwari   If you obey all the rules, you miss all the fun.                      2 cent tips - re: Reflections Replacement  Mon, 16 Oct 2000 23:53:00 -0500  From: Rick Cook  ( rcook@hex.net )    Toshiro,     Hi! I would like to access my graphics Linux desktop from my Windows box; I was able to do it using a software called Reflection (I guess you know it), is there any (free) software with the same capabilities of Reflection?     You could also try VNC. If you run a VNC Server on your Linux Machine and a VNC client on your Windows box, you can get a graphical Login (xdm, gdm, kdm) on your Windows Box. See:      http://www.uk.research.att.com/vnc      The Linux version comes included with several distributions, including  Debian .     Good Luck,  Rick Cook                     Modems  Tue, 3 Oct 2000 21:12:17 -0400  From: ""Barry""  ( BarryJJ@ATTGlobal.Net )    I bought the ActionTec Internal Call Waiting PCI -  not  to be confused with the ""56K PCI Pro"" which is labelled as a WinModem  -  'coz it was the  only  one that mentioned Linux support on the box  and  was PCI.  From this I assumed it to be a ""real"" modem.     I haven't actually tried it under Linux yet, but I was impressed to find the instruction book had more pages (10) devoted to getting it to work under Linux than for the Windows variants.  And there is  no  mention of having to install special software ... at least none that I can find.     There are separate headings for PPP,  GNOME  Dialer Applet, KPPP, linuxconf Dialer, and even a paragraph on minicom.  It cites the instructions as having been verified under  Red Hat  5.2 and 6.0, although I found references to my current distribution of choice -  SuSE   -  on their web pages.     I was impressed!  Their web site is   www.actiontec.com      HTH ... BJ                     authentication pam and kde  Mon, 23 Oct 2000 08:25:49 -0700  From: Breen Mullins  < bmullins@asante.com >    At 11:42 AM +0200 10/23/00, Dean Buhrmann wrote:     Hello,     Kapil Sharma gave in the Oktober issue a few security tips. One is blocking users from doing su and only allowing the users from group wheel to do so. [snip]     It works well in virtual terminals. In  KDE  however it is now impossible to su. Authentication rejects now always the root password.     Hi Dean -     This also fails in Gnome if I use the default terminal. Try opening a vanilla xterm  -  I can su if I do it there.     Breen                     Printing in Netscape  Wed, 25 Oct 2000 12:15:56 -0700    In issue 57 ( http://www.linuxgazette.com/issue57/lg_tips57.html ), Matthew Willis suggested using psnup to print two pages per sheet in Netscape.     psnup -c -n 2 | lpr -pprinter     I had to change this slightly to get it to work for me.  I use:     psnup -c -n 2 -pletter | lpr     The "" -pletter "" option says you're using letter-sized paper (the normal page size in the US).  Otherwise it will default to the European A4 size. If you print A4-formatted pages on letter paper, the rightmost part of the content runs off the edge of the page.     The "" -pprinter "" option didn't work for me.  I assume Matthew was trying to select the printer device.  According to my lpr manpage, the option would be "" -P  printer"".  "" -p "" filters the input through pr, which isn't what we want.  (The pr command formats text files.)     -- Mike Orr             ""Linux Gazette... making Linux just a little more fun! ""                 HAL 91 - a minimalistic Linux distribution   By  Matthias Arndt                    Table of Contents     Introduction   What is HAL91?   Features of HAL91   Kernel features of HAL91   HAL91 - what to do with it?   related links        Introduction    Recently, I started studiying computer sciences in conjuction with economics at the  Technical University of Clausthal .     I met another Linux enthusiast,  Christian Perle . He told me about one of his ongoing projects. And that one was maintaining the  HAL91 Linux distribution. .     This article should be a short description of what is  HAL91  and where could it be used for.  Please contact  the maintainer of HAL91, Christian Perle , for further information.     I just want to tell you about its existence...       What is HAL91?    In short, a quote of the  HAL91  boot message:  _/  _/ _____/ _/        _____/  __/ http://home.sol.no/~okolaas/linux/hal91/ _/  _/ _/  _/ _/        _/  _/  __/            -=[ Floppy Linux ]=- _____/ _____/ _/   ___/ _____/   _/                 ver 0.2.0 _/  _/ _/  _/ _/            _/   _/             okolaas@online.no _/  _/ _/  _/ _____/        _/   _/          (c) 1998 0yvind Kolaas        HAL91  is a minimalistic Linux distribution that fits on one floppy disk (1.44MB).     Special about  HAL91  is that it comes along with a whole set of useful utilities for maintaining and troubleshooting a linux system, including some limited networking support.     The  HAL91  Project was started by Oyvind Kolaas but Christian Perle is now the maintainer of the HAL91 distribution.       Features of HAL91    In order to keep  HAL91  as small as possible the whole HAL91 system currently uses the libc5.     Kernel 2.0.36 is the current kernel version.      HARDWARE REQUIREMENTS:  You just a need a minimal system with a 386 processor and 8MB of RAM.  HAL91  comes along with harddisk and CD-ROM support but it runs directly from floppy out of a RAM disk.  A special feature of HAL91 is the included minimal support for NE2000 compliant network hardware and the ability to establish a PPP connection over a null modem cable (via the ppp-nullmodem script).    The following programs and tools are included with the  HAL91  distribution.     tool/program Description  bash   bourne again shell  bunzip2   uncompress bzip2 files  bzip2   compress files to .bz2  cat   concatenate files  chmod   change file permissions  chown   change file ownerships  chroot   change root filesystem  cp   copy files  dd   read/write devices and files  df   show free disk space  dir   show contents of directory (symlinked to ls)  dmesg   show kernel messages  du   show disk usage  e2fsck   check/repair an ext2 filesystem  elvis   clone of the vi editor  fdisk   partition hard disks  free   show memory statistics  ftp   ftp client  grep   search for patterns in files (symlinked to rgrep)  gunzip   uncompress gzip files  gzip   compress files to .gz  halt   halt the system  hostname   show/set hostname  ifconfig   configure network devices  init.net   simple script for configuring ethernet  insmod   load kernel modules  less   display files  ln   create links  loadkeys   load keymaps  ls   list contents of directory  lsmod   show loaded kernel modules  mkdir   create directories  mke2fs   create an ext2 filesystem  mknod   create special device files  mkswap   set up swap partition  more   display files (symlinked to less)  mount   mount filesystem  mv   rename/move files  ncp   server/client to copy files/directories over network  npoll   receive stdin over network (symlinked to ncp)  npush   send stdin over network (symlinked to ncp)  open   open virtual consoles  ping   send ICMP requests  ppp-nullmodem   simple script for PPP using nullmodem cable  pppd   PPP daemon  ps   show process status  reset   clear the screen  rgrep   search for patterns in files  rm   remove files/directories  rmmod   remove kernel modules  route   configure network routes  sh   bourne shell (symlinked to bash)  sleep   pause for a specified time  swapoff   turn off swap (symlinked to swapon)  swapon   turn on swap  sync   synchronize cache with disks  tar   tape archiver  telnet   remote login client  tr   translate characters in files  umount   unmount filesystem  update   automatic syncing of filesystems  vi   vi editor (symlinked to elvis)  zcat   concatenate gzip compressed file (symlinked to gzip)  zless   display gzip compressed files     (And this fits on a single floppy disk!)     The  HAL91  floppy is bootable. Just insert it into your floppy drive and start your computer.     The bootloader  LOADLIN  is also included with the  HAL91  floppy. You can launch  HAL91  directly from a running DOS.     All visible files on the  HAL91  floppy are on a VFAT file system. You can inspect the disk and even copy its contents (with losing the ability to boot directly from it) to anywhere using a DOS or Windows compatible system.       Kernel features of HAL91    HAL91's kernel configuration is shown in the file  kconf  on the disk:  # # Automatically generated by make menuconfig: don't edit #  # # Code maturity level options # # CONFIG_EXPERIMENTAL is not set  # # Loadable module support # CONFIG_MODULES=y CONFIG_MODVERSIONS=y # CONFIG_KERNELD is not set  # # General setup # CONFIG_MATH_EMULATION=y CONFIG_NET=y # CONFIG_MAX_16M is not set CONFIG_PCI=y CONFIG_SYSVIPC=y # CONFIG_BINFMT_AOUT is not set CONFIG_BINFMT_ELF=y CONFIG_KERNEL_ELF=y CONFIG_M386=y # CONFIG_M486 is not set # CONFIG_M586 is not set # CONFIG_M686 is not set  # # Floppy, IDE, and other block devices # CONFIG_BLK_DEV_FD=y CONFIG_BLK_DEV_IDE=y # CONFIG_BLK_DEV_HD_IDE is not set CONFIG_BLK_DEV_IDECD=y # CONFIG_BLK_DEV_IDETAPE is not set # CONFIG_BLK_DEV_IDEFLOPPY is not set # CONFIG_BLK_DEV_IDESCSI is not set # CONFIG_BLK_DEV_IDE_PCMCIA is not set CONFIG_BLK_DEV_CMD640=y # CONFIG_BLK_DEV_CMD640_ENHANCED is not set # CONFIG_BLK_DEV_RZ1000 is not set # CONFIG_BLK_DEV_TRITON is not set # CONFIG_IDE_CHIPSETS is not set CONFIG_BLK_DEV_LOOP=y CONFIG_LOOP_ROOT=y # CONFIG_BLK_DEV_MD is not set CONFIG_BLK_DEV_RAM=y CONFIG_BLK_DEV_INITRD=y # CONFIG_BLK_DEV_XD is not set # CONFIG_PARIDE is not set # CONFIG_BLK_DEV_HD is not set  # # Networking options # # CONFIG_FIREWALL is not set # CONFIG_NET_ALIAS is not set CONFIG_INET=y # CONFIG_IP_FORWARD is not set # CONFIG_IP_MULTICAST is not set # CONFIG_SYN_COOKIES is not set CONFIG_IP_ACCT=y # CONFIG_IP_ROUTER is not set # CONFIG_NET_IPIP is not set # CONFIG_INET_PCTCP is not set # CONFIG_INET_RARP is not set # CONFIG_NO_PATH_MTU_DISCOVERY is not set CONFIG_IP_NOSR=y CONFIG_SKB_LARGE=y # CONFIG_IPX is not set # CONFIG_ATALK is not set # CONFIG_AX25 is not set # CONFIG_NETLINK is not set  # # SCSI support # # CONFIG_SCSI is not set  # # Network device support # CONFIG_NETDEVICES=y # CONFIG_DUMMY is not set # CONFIG_EQUALIZER is not set # CONFIG_PLIP is not set CONFIG_PPP=y # CONFIG_SLIP is not set # CONFIG_NET_RADIO is not set CONFIG_NET_ETHERNET=y # CONFIG_NET_VENDOR_3COM is not set # CONFIG_NET_VENDOR_SMC is not set # CONFIG_NET_PCI is not set CONFIG_NET_ISA=y # CONFIG_LANCE is not set # CONFIG_AT1700 is not set # CONFIG_E2100 is not set # CONFIG_DEPCA is not set # CONFIG_EWRK3 is not set # CONFIG_EEXPRESS is not set # CONFIG_HPLAN_PLUS is not set # CONFIG_HPLAN is not set # CONFIG_HP100 is not set CONFIG_NE2000=y # CONFIG_SK_G16 is not set # CONFIG_NET_EISA is not set # CONFIG_NET_POCKET is not set # CONFIG_TR is not set # CONFIG_FDDI is not set # CONFIG_ARCNET is not set  # # ISDN subsystem # # CONFIG_ISDN is not set  # # CD-ROM drivers (not for SCSI or IDE/ATAPI drives) # # CONFIG_CD_NO_IDESCSI is not set  # # Filesystems # # CONFIG_QUOTA is not set # CONFIG_MINIX_FS is not set # CONFIG_EXT_FS is not set CONFIG_EXT2_FS=y # CONFIG_XIA_FS is not set CONFIG_NLS=y CONFIG_ISO9660_FS=y CONFIG_FAT_FS=y CONFIG_MSDOS_FS=y # CONFIG_UMSDOS_FS is not set CONFIG_VFAT_FS=y CONFIG_NLS_CODEPAGE_437=y # CONFIG_NLS_CODEPAGE_737 is not set # CONFIG_NLS_CODEPAGE_775 is not set CONFIG_NLS_CODEPAGE_850=y # CONFIG_NLS_CODEPAGE_852 is not set # CONFIG_NLS_CODEPAGE_855 is not set # CONFIG_NLS_CODEPAGE_857 is not set # CONFIG_NLS_CODEPAGE_860 is not set # CONFIG_NLS_CODEPAGE_861 is not set # CONFIG_NLS_CODEPAGE_862 is not set # CONFIG_NLS_CODEPAGE_863 is not set # CONFIG_NLS_CODEPAGE_864 is not set # CONFIG_NLS_CODEPAGE_865 is not set # CONFIG_NLS_CODEPAGE_866 is not set # CONFIG_NLS_CODEPAGE_869 is not set # CONFIG_NLS_CODEPAGE_874 is not set CONFIG_NLS_ISO8859_1=y # CONFIG_NLS_ISO8859_2 is not set # CONFIG_NLS_ISO8859_3 is not set # CONFIG_NLS_ISO8859_4 is not set # CONFIG_NLS_ISO8859_5 is not set # CONFIG_NLS_ISO8859_6 is not set # CONFIG_NLS_ISO8859_7 is not set # CONFIG_NLS_ISO8859_8 is not set # CONFIG_NLS_ISO8859_9 is not set # CONFIG_NLS_KOI8_R is not set CONFIG_PROC_FS=y # CONFIG_NFS_FS is not set # CONFIG_SMB_FS is not set # CONFIG_HPFS_FS is not set # CONFIG_SYSV_FS is not set # CONFIG_UFS_FS is not set  # # Character devices # CONFIG_SERIAL=y # CONFIG_DIGI is not set # CONFIG_CYCLADES is not set # CONFIG_STALDRV is not set # CONFIG_RISCOM8 is not set CONFIG_PRINTER=y # CONFIG_SPECIALIX is not set # CONFIG_MOUSE is not set # CONFIG_UMISC is not set # CONFIG_QIC02_TAPE is not set # CONFIG_FTAPE is not set # CONFIG_APM is not set # CONFIG_WATCHDOG is not set # CONFIG_RTC is not set  # # Sound # # CONFIG_SOUND is not set  # # Kernel hacking # # CONFIG_PROFILE is not set         HAL91 - what to do with it?    In short, you could use  HAL91  as a rescue and trouble shooting disk. It comes along with all needed tools and it runs out of the box without requiring the hard disk to run.     The included tools can be used for network trouble shooting.      HAL91  can be used as a boot image for bootable CD-ROMs and it could be used as a base Linux to install another Linux.     Last but not least, it is a very good starting point for learning about the creation of a running distribution.        Related links    Here, you may find links to the homepage of the HAL91 project.      NOTICE:  The webpage mentioned in the current HAL91 boot message does not exist anymore.      HAL91 Homepage   discontinued HAL91 page   Christian Perle's email      written with permission of  Christian Perle                  Copyright © 2000, Matthias Arndt. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 59 of  Linux Gazette , November 2000        ""Linux Gazette... making Linux just a little more fun! ""                 Open Source is Open for Business   *100% free of Monopoly code*   By  Bill Bennet                     So there I was at ComputerAvenue talking with Lin the Wanton and her mates behind the counter. They know I am a Linux user and they like to bring out their complaints about the Monopoly to see what I say.  They may bring up the   death  of Corel just to get a rise out of me. This time the subject turned to credit card access for your business and how do you get it if you are a 100% committed Linux user.  You can have any number of helpers and agents and credit card companies at your door, ready to sell you some credit card action for your eBusiness.  Oh, they just love you to death because there is so much peer pressure on small business to ""get online"". It smells of money and that is blood in the water for these sharks.   It seems that every one of these credit card sellers is on something called IIS and it only runs on NT or Windows of various  mutated  varieties. That is not in itself a bad thing. A webserver is a webserver. However, the company that makes this software has been found guilty of anti-competitive monopolistic practices in a court of law. A scrupulous business will avoid any involvement with such an unsavoury element.  It is obvious to you and to your conscientious customer that when you lie down with dogs, you wake up with fleas.   The question is ""How can a committed Open Source business avoid getting caught up in this IIS webserver for its  most important  transactions?""   The answer is that Open Source and non-Monopoly solutions can be found. I am going to share with you:    a way to get your 100% Open Source business online for free. *   a way to give your customers credit card access for no money up front. *   a way to make credit card transactions 100% free of Monopoly code. *   a way to make money from click-through advertisements. *   an Open Source eCommerce site ready to install. *     online for free    That is right, my website is hosted for free. There are no annoying popup browser windows. There is no monthly fee. There was no money up front.  There has never been any money change hands to keep the site up.   Simple code on each of your html pages will make sure that only a nice controlled banner will appear at the top of each page instead of an annoying popup browser window.  The simple code:   <body> <!--#echo banner=""""-->     That is it. Just make darn sure that the ""echo banner"" is the first thing after the end of the ""body"" tag.  use the force Luke    I see that advertising money can force a search engine to cough up a well financed site to the top of the search results. If your search engine site owns some other sites, it can also get its own sites forced up to the top of the search results. This is not in itself a bad thing, but it will educate you as to how the internet is shaping itself. A search for ""free hosting site"" will always turn up some very big operations in the first page or two of results.  This works in your favour if you can further winnow out the IIS/NT chaff.  My tool for this job is  www.netcraft.co.uk  and their feature page for ""What's that site running now?"".   I found hypermart that way.  They did not use any Monopoly code, so I gave them the business, literally. The nice folks at hypermart have a very fine web-based site manager for you and yes, you can do a little check mark to insert banners automatically.  However, you know and I know that automatic switches can sometimes get turned off; especially on a big site like this.   I have listed   several  sites that are free hosts for your website. Funny, none of the listed sites are using Monopoly coded webservers.  credit card access    The hard part about shopping for an online credit card merchant account is that you have to know how to approach each new vendor.  It helps if you can get a nice professional response because then you can do some straight business without posing.   I must admit, I did do some posing. Here is the result of the search: you are going to need 300.00 bucks US to purchase your very own merchant credit card account. The only advantage to this that I can see is that you can then take ""air money"" for intangibles like Service, Licensing and Donations.   There are many credit card  agents  that can sell you a merchant credit card account. Most of these are using a thing called IIS on something called NT or another one called Windows, with various version numbers. They are sold by the Monopoly and you should be concerned about exactly how much information is being   sent  to the Monopoly headquarters from each transaction on these sites.  no money up front    There are some credit card agents that can do the credit card transaction for you with no money up front because you are using  their  merchant account to sell products on  your  site.   Many times here in Canada I have been sent spam to inform me that I can set up credit card access on some agent in the USA. For the Canadian merchant, it was not available.    Here is one for you that can be used by a Canadian vendor. It is called  CCNow .   Verify the operating system and web server at  www.netcraft.co.uk .   You will find that CCNow runs on Solaris and uses Netscape Enterprise server.  This is Unix, folks, the Monopoly has nothing to do with your customers or their precious information.  It is locked down on a secure Unix server. It is safe.   There are many Linux and Open Source sites available for other payment options. The most well known of these is  PayPal , who have recently started just this kind of credit card access for you. Be cautious; the paypal site uses Apache Stronghold on Linux but the parent site is www.x.com and they use that IIS thing on NT. You will not be able to know if your information is safe and secure on a Unix system in that group of sites. Make a check of the https server at  www.netcraft.co.uk  to be sure. Select ""What's that SSL site running?"".  transactions 100% free of Monopoly code    I can not tell you how important this one registers in the minds and hearts of your Open Source customers. I can say that the Monopoly has created the Open Source movement by abusing their customers. Maybe that is self-evident.     To hammer the point home, I want you to remember that on a Monopoly   controlled  machine secret information is passed between Monopoly headquarters and your machine on the internet.  The privacy statements that you see on every website are there because the Monopoly threatened to pull advertising revenue from sites without a privacy statement. The reason such a big show was made about privacy is because the Monopoly was  caught  sending  user profiles to the Monopoly headquarters from every Monopoly machine every time they went online on the internet.  So there, now you know.   At my little shop, we avoid this secret pitfall by not using any Monopoly code on our credit card transactions. This is done by making sure that our credit card agent uses Sun technology or Open Source technology.  If any other source for software comes up, let them be a sworn enemy of the Monopoly like Sun or let them be as free with their source code as BSD.  I have spoken.  pennies per click    First, you have to have content on your site. A site full of sites is nice, but every  yahoo  and his dog is making portal sites that are sites full of sites.  What you need is actual readable, stealable content in order to get your fair share of visitors. You can not be MacDuffie's or Windy's but you can offer a solid meal at great prices and add something to set you apart.   Now that you have some traffic to offer to a potential advertiser, you can do the rounds of pay-per-click agents.  These are websites full of advertisers willing to pay for clickthrough from your site to their site.  They often pay per  click .     You can identify a clickthrough advertiser when it offers an affiliate program. In contrast, a reseller program requires that you actually do some selling in order to get a commission.  Go to the affiliate program site, give your information and maybe you can get some code to put on your pages to refer your clickthrough pennies.  They will add up.  Open Source eCommerce    Yes, we are under a lot of peer pressure to set up eCommerce, eBusiness, eFood, eToilets, ad nauseum.  Your typical commercial sales outlet for eCommerce is waiting for you to  submit  thousands of dollars for a very nice eCommerce software package.  Well, you now have a freely distributed Open Source eCommerce solution.  Put your money into service and technical support because the code is released under the GPL.   The package is nicely wrapped up into a very  beautiful  ""lady store"" put together by very smart folk at  Open Sales .  You simply download the source code and put the store into operation on your web server. Then after you have worked out any kinks, you go online with a professional eCommerce site.  Open Source and open for business    When it is all built and bug-tested, you will have created an Open Source based, free-economy, world-beater of an eCommerce site.  How much did you pay for hosting? Zero. How much did you pay for credit card access? Zero. How much did you pay for your world class eCommerce software? Zero. How much do you love this concept?  You be the judge.  It is all right here, waiting for you.  Now go and tell your friends.   Rants and References   A click is a LeftButton MouseEvent. It is caused by the carpal tunnel sufferer twitching downwards on his Left Rodent Button while the cursor on the screen is inside the borders of the advertiser's little button or hypertext link.  Agents for credit cards are able to create a merchant credit card account for you with the credit card companies.  You really do need a merchant credit card account because there are so many ways to get money for services rendered.  You see, if you go to a credit card agent that lets you use  their  account for  your  sales, then the legal relationship requires that you sell something real and tangible.  If you want to get rental fees, or fees for time spent, then you will need your own merchant credit card account.  Submit is a word that I expect to hear when you have knocked me down and you have your foot on my neck.  It is not so friendly as it could be.  Please consider converting all of your ""Submit"" buttons into ""Send it"" buttons. I refuse to submit!  Death may be too strong a word. How about infection? With the Monopoly propping up all of their dying competition, we can seriously consider that only the Monopoly has enough money to go into the software business under the old model for proprietary code. Look, you wonder why I write this article? It is because so much of the movement in the business world is driven by foolish decisions to go with the money rather than make a new ballgame. Paying thousands of dollars for software that can not do as much as Linux is just plain stupid. Unless of course, you go with Open Source and Linux for all of your needs. Then this moaning becomes redundant.  Anyway, beware any Linux binaries coming out of Corel now that 24% of the company is in convicted monopolist hands. Source code is ok with me; it is the secret binaries that frighten me. My fear is only based on the Monopoly's past behaviour and convictions in a court of law.  Yahoo is one of a growing number of real words that are getting appropriated by stupid trademarks and silly patents. I hope I have offended all yahoos at Yahoo by using `their' word. Yahoo, yahoo, yahoo.  My meaning for a very beautiful ""lady store"" is one where even a discriminating and classy woman can shop at ease and comfort. You see the clean site layout and feel secure in the knowledge that you are in the very nicest of company. A ""lady store"" is one you can show off to designers, graphic artists, print media professionals and even your mom.  The Monopoly has mutated their software many times and  each time  the captive has to purchase a new version. Mutation is in the eye of the beholder, as evidenced by this  advertisement .  Here are the sites that I have found to be free hosting sites.  In the search engine at netscape I gave the keywords ""free hosting site"". It is in no way an exhaustive list. It is an Open Source list as far as I could tell. My apologies to anyone who is not listed. I did not know about you. You can check their webserver at www.netcraft.co.uk to see what operating system is reported.  www.netcolony.com -- on Linux -- you agree to eat spam  www.netfirms.com -- on Linux --  www.hypermart.net -- on Linux -- you agree to banners or popups  www.microworld.com -- on Linux -- no ads -- small setup fee -- NT/IIS for https -- you can get your own credit card agent    Here are the sites that I have found to be Open Source or non-Monopoly merchant credit card account access sites.  In the search engine at netscape I gave the keywords ""online merchant credit card account"". It is in no way an exhaustive list. It is a clean list as far as I could tell. My apologies to anyone who is not listed. I did not know about you. You can check their webserver at www.netcraft.co.uk to see what operating system is reported.  www.tiggers.net -- on Linux -- goes through datacash.com which is on BSD  www.ccnow.com -- on Solaris -- no fees -- you must sell a real tangible product, like a plush penguin  www.datacash.com -- on BSD -- features international currency settlement  beseen.net -- on BSD  www.cardservice-network.com -- on IRIX -- bounces to www.hostmaster2000.com -- on Linux    Here is what the article will help you to find: the Operating System changes.    www.merchant-systems.com -- on Linux -- https on authorize.net -- on IIS/W2K  www.xoom.com -- on Linux --bounces to nbci.com -- on Solaris    The above example looks like a fine safe Unix style of site for your eCommerce.  Look again. NBCi is owned by the Monopoly.  I did not see much of the Olympics. I have three TV channels over here that I skip over and do not watch. That is right, MSNBC has infected my TV. They already have your WebTV, your Windows Me (them?) and your NT box.   Open for Business   excellent Linux documentation references:   Commercial-HOWTO   Intranet-Server-HOWTO   Networking-Overview-HOWTO   WWW-HOWTO    Made with mcedit on an i486    running RedHat 5.0 GNU/Linux 2.0.35   because nobody forced me to upgrade a working system.   All references to revolution are purely intentional.    ""Linux--where the only monopoly we support has a Boardwalk and a Baltic Avenue.""        [If you didn't follow that link above about the dirty tricks  Microsoft has been caught doing,  here it is again.   It really is worthwhile reading.  -Ed.]                    Copyright © 2000, Bill Bennet. Copying license  http://www.Linuxgazette.com/copying.html   Published in Issue 59 of  Linux Gazette , November 2000        ""Linux Gazette... making Linux just a little more fun! ""                 Narval, the Intelligent Personal Assistant  --or--  How the French  Linux Gazette  is Built   By  Nicolas Chauvat                    Abstract    Narval is an Intelligent Personal Assistant software, released under the GNU Public License by  Logilab . It was used to set up Gazo, a bot that is assisting the group of volunteers that translates  Linux Gazette  into French, by taking care of most of the coordination-related work. Narval features artificial intelligence and agent technologies and contributes to change the way we use the Internet and computers. Narval stands for  Network Assistant Reasoning with a Validating Agent Language .    Gazo, a real-life example    When I took over the coordination of the  French translation of  Linux Gazette , I was quickly faced with the very same problem the former coordinator had to deal with: time. Coordination is no brain work, but it can quickly take up a large amount of time: scan your mailbox for e-mails from people offering to translate an article, check that it is not taken yet, send back an answer, update the web page, merge all the articles into one monthly issue... It seemed to me that I was always losing most of my time with repetitive tasks and losing other people's time when not being able to send back an answer right away saying ""go ahead"" or ""this one is already taken"". In other words, I had an itch to scratch.    I can hear you say ""Just write a server script and let your contributors ask for articles using HTML forms!"". I had three reasons for not doing it. The first one was that some people back then did not have web access, only e-mail. The second reason was that I didn't want to cut off the translation of  Linux Gazette  from the rest of the translation of the LDP, hence I wanted to keep using the mailing-list [1] . Last but not least, I had already been doing some work in the field of artificial intelligence and agents and thought it would be a nice opportunity to try out a couple ideas. I named that agent Gazo, after the magazine you are currently reading.    The first version of Gazo was nothing like the Narval framework. It was a single python script that would get incoming mail from procmail. Gazo was fed a copy of every e-mail I would receive and try to figure out if it concerned  Linux Gazette  by looking for keywords in the subject. If it did, it would parse the subject field using regular expressions, trying to extract the demand of the user, which could be one of the following: ask for an article, send a translation, send a proof-read translation or abandon an article. A typical subject for offering to translate the article F of the issue 58 was "" [lg] asking for article 58 F "". In case Gazo found a match for the subject it would execute several actions.      When someone asks for an article, check he is not already translating two articles and that the article is not already assigned to someone else. If everything is OK, assign the article to that person, send him a confirmation e-mail, update the web page and tell the coordinator (me) what was done.    When someone sends a translation, check that the article was assigned to him, save the attached file to the  in-progress/translated/  directory on the FTP server, send an e-mail to thank the contributor, pick up one of the volunteer proof-readers who has the fewest articles assigned and notify him via e-mail that he has a new article to proof-read, then update the web page and tell the coordinator what was done.    When someone sends a proof-read translation, check that the article was assigned to him, save the attached file to the  in-progress/proof-read/  directory on the FTP server, thank the sender, update the web page and tell the coordinator what was done.    When someone sends an abandon notification, save the attached file to the  in-progress/unfinished/  directory on the FTP server, say ""thank you anyway"", update the web page and tell the coordinator what was done.    Every week, post a list of the articles waiting to be translated and remind the people who are translating articles that they have not sent their translation yet and can abandon it if they do not have time to complete it.      As you can see, there's no surprise here, just writing e-mail, moving files around and keeping everything synchronized. And as you probably know already, in computer science, ""without surprise"" often rhymes with ""can be automated"" (well, could have...;-).    That first script worked well for over a year, but proved to be difficult to extend, because describing sequences of actions and testing for all possible error cases required writing a lot of code. Another itch needed scratching... but it took much longer than the first one and more than myself to deal with it. Ladies and gentlemen, please welcome the Narval Project.    Narval    When you spend most of your day using your computer to work with other people on several projects, keep in touch with friends, try not to lose ground on the news front and answer phone calls, you soon realize that what you really need is someone or something that does part of your work for you. That someone exists and is called a secretary or an assistant. They are real people, work for money, sleep at night and do not necessarily add up two ten digits numbers in 10e-9 seconds. That something exists too. There are a few instances of it in several AI labs, but unlike the former, they're not that smart. Nonetheless, let's be optimistic and call those somethings Intelligent Personal Assistants.    Narval is one of them. It borrows from advanced techniques like petri nets, rule-based systems, programming by contracts, planning, automated learning, component programming and XML, to let one release the pressure of repetitive work.    Narval executes recipes, that are sequences of actions linked by transitions. An action can be downloading a web page, performing a database query, transforming a piece of XML, sending an e-mail or whatever you may want to wrap in a few lines of python code. Conditions can be associated to transitions so that you can control the execution path through the graph representing a recipe. That gives you the basic vocabulary to control the flow of execution through different branches of your recipe and to coordinate concurrent tasks.    Using a graphical user interface named Horn (Narval is French for narwhal or narwhale, see below), a user can create a new recipe in a few mouse clicks by assembling building blocks (actions from the library, other recipes) and specifying the conditions associated to the transitions that link blocks together.    In Narval, everything is represented using XML: action prototypes, pieces of information, recipes, etc. XML provides a basic format to express the structure of the data that is manipulated. If you have ever worked with a Unix shell, you probably have realized the power of the pipes that let you do a lot of work by making a data stream flow thru filters and programs. Similarly, Narval executes recipes by passing XML fragments from an action to another, an important difference being that with Narval, the stream of execution goes thru a graph, not a sequence. At each step, pieces of XML are transformed and/or created. Narval keeps track of what did what.    In Narval, actions have complex prototypes that borrow from programming by contracts. A prototype specifies conditions on the XML nodes the action needs as input and will return as output, whether it can process a list or not, etc. For each input and output a set of XPath expressions is used to define the name of the tag, the value of an attribute, etc. When executing the actions, Narval will use these expressions to detect errors and failures and abort the recipe if it has no way to recover. That provides a permanent run-time verification mechanism that reveals itself quite useful and that Eiffel programmers already know of.    The new version of Gazo is built on top of Narval as a set of recipes. It does the same as its predecessor, but is expressed in a higher-level graphical language, is easier to modify and maintain and will benefit from the other capabilities of Narval, such as error recovery, learning (this user always takes a lot of time, do not let him have more than one article), etc. An image being worth a thousand words,  I won't go thru the details of Gazo's behavior once again, just read the above description while looking at the two screen-shots below, then try to answer the following question: which one is more expressive, those graphs or 1000 lines of python script? The labels prefixed by  Gazo  correspond to bits of python code, the ones with underscores are XSL transformations and the others are recipes. The first screen-shot is the top-level recipe, the second one is the ""Ask for article"" recipe.         What's new in this? One may object that the coordination problem described above could have been solved using a simple web application and that commands have been included in the subject of e-mails even before the first mailing-list management software. Both are true, but completely miss the point. Narval is, in a sense, an interpreter for a high-level graphical language, and draws its power and simplicity of use from features such as complex action prototypes and contracts, run-time arguments selection, rule-based mechanisms, large action library, etc.    Narval is not an application, but a framework to create your personal assistant in a few mouse clicks.    What's next?    Narval's ambition is to be the best Intelligent Personal Assistant available on the Net and to grow into a software that really deserves the adjective Intelligent.    In our group of developers, we already have a Narval that helps to coordinate our projects. Each of us has its own Narval that assists him by filtering out junk ads from web pages, fetches the daily cartoons, summarizes in one page the news from different web sites, checks the agenda and sends reminders for appointments, accepts voice commands and answers using text-to-speech free software.    Applications are endless, as with any programming language. Our plans are twofold. On the one hand, integrate in the libraries all the actions we can think of: voice modem to be able to ""phone home"" and tell your assistant what to do, home automation protocols like X10 to control your home, cell-phone and PDA features, etc. As stated, new actions can easily be added with a few lines of python code. On the other hand, we will develop and implement the intelligent features the Narval framework was designed for, but that are missing at the time of this writing: planning, learning and cooperation with other assistants.    Planning . Once you have a sufficient number of actions, a set of basic recipes and a description of the relations between different concepts, you can start doing planning: you give your assistant a goal, like ""suggest me a movie for tonight"", and it will figure out a sequence of actions that will make it fulfill that goal (extract critics or rankings from a movie web site, compare to the user preferences, look up the theatre schedule and send back the suggestion to the user). The prototypes of the actions are particularly useful for this.    Learning . In Narval, everything is represented using XML. Each piece of information has a structure. Each piece of information has a timestamp. Each piece of information has a trace: what produced it, what used it, for what purpose, etc. If you have any experience with automatic learning, you know that this is a valuable setup on top of which it is possible to implement many algorithms. Using learning techniques, your assistant could realize that every Friday, you visit a web site about movies, then offer you to add that site to your Friday daily newspaper or start searching for movie critics.    Cooperation . Making two people or two assistants cooperate is often a matter of protocols. If you want them to be smarter, it becomes a problem of recognizing what the other is doing. Having recipes as explicit sequences of actions and having all the features mentioned about learning is of real value in tackling cooperation.    Are we alone out there?    Narval is the only Intelligent Personal Assistant released as free software that we know of. At least three companies have commercial products that we consider related, even if they do not belong to the same category for they are not as generic nor customizable and extensible as Narval.    The first one is the software that comes with the  TiVo VCR . It fetches the TV program for you, helps you to set up the recording of a show, and may even suggest a movie to watch depending on what genre of movies you have watched lately.    Prody Parrot , from Mindmaker, was shipped with Sound Blaster sound cards for some time. Working on windows only, it would help you sort your e-mail, remind you of your appointments, download web pages and summarize them, entertain you by dialoguing as if it were a psychoanalyst (ever tried Eliza in Emacs?), using speech recognition and text-to-speech. Those are quite nice features, but you wouldn't set up an assistant like Gazo with that software...    The last one is a web application named  One Red Cube  that acts as a personal communication hub that can redirect your phone calls, your faxes and your e-mails from one device to the other. Nothing like an assistant, but the idea of integration is there.    There are also three free software projects that work on things loosely related to Narval and worth mentioning. The  GNU Bayonne  project, as a Computer Telephony Integrated server, could very well end-up as a valid competitor to One Red Cube. The  Mister House project  is a nice home automation system that implements many features. Provided you're not afraid to write some perl code and get your hands dirty, it will let your house play a song when you walk up the stairs, ask quiz questions during breakfast and download the weather forecast when you ask for it on the phone. Last, the  Piper  project is building a visual shell that let you federate resources from different hosts using a graphical user interface to draw a flow chart analogous to streams and pipes.    Exotic whales     Narval in French, narwhale in English, is a sea mammal that lives in the Arctic Ocean. The male has a tooth that grows out of his mouth and turns into a long tusk. The Narval's tusk was believed to be a unicorn horn and sold in Europe during the middle ages (and later), thus proving the existence of the unicorn.    Our prototype system was called Al, named after the HAL computer in  2001: A Space Odyssey .  When we where looking for a name, we wanted to keep the Al syllable, and we ended up with Narval.  It offers a nice acronym and a nice mascot.(Linux has Tux the penguin; we have Ornicar the narwhale! :-) Since the narwhale is known for its tusk, we wanted to use that name for the companion user interface, but Horn offers a better acronym (Human ORiented Narval interface), so we did as if it was a unicorn horn and not a Narval tusk.    Here are some follow-up links for the curious:         the word ""narwhal"" or ""narwhale""       the word ""narval""       2001: A Space Odyssey       HAL 9000       unicorn horn       unicorn         Conclusion    I hope this article made you feel like trying Narval and learning more about artificial intelligence, agent technologies and their applications to real-life problems. Feel free to join our  mailing lists  to discuss further these matters.    That's all folks, Happy Hacking!    [1]  Like the Linux Documentation Project itself, the French translation project is volunteer work. The principal medium for discussion, help and most of the coordination is a mailing-list. See  http://www.traduc.org/  for details.                  Copyright © 2000, Nicolas Chauvat. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 59 of  Linux Gazette , November 2000        ""Linux Gazette... making Linux just a little more fun! ""                 HelpDex   By  Shane Collinge                                                             Courtesy   Linux Today , where you can read all the latest  Help Dex  cartoons.                 Copyright © 2000, Shane Collinge. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 59 of  Linux Gazette , November 2000        ""Linux Gazette... making Linux just a little more fun! ""                 Interview with Google's Sergey Brin   By  Fernando Ribeiro Corrêa  Originally published at  OLinux                    Google: An important tool to organize information around the world     Sergey Brin, a native of Moscow, graduated with honors with a bachelor of science degree in mathematics and computer science from the University of Maryland at College Park. He is currently a Ph.D. candidate in computer science at Stanford University, where he received his master's degree. Brin is a recipient of a National Science Foundation Graduate Fellowship. Brin's research interests include search engines, information extraction from unstructured sources, and data mining of large text collections and scientific data. He has published more than a dozen publications in leading academic journals, including ""Extracting Patterns and Relations from the World Wide Web""; ""Dynamic Data Mining: A New Architecture for Data with High Dimensionality,"" which he published with Larry Page; ""Scalable Techniques for Mining Casual Structures""; ""Dynamic Itemset Counting and Implication Rules for Market Basket Data""; and ""Beyond Market Baskets: Generalizing Association Rules to Correlations.""    OLinux: What is Google company's mission?      Sergey Brin:  Google's mission is to organize the world's information, making it universally accessible and useful.     OLinux: When did you start this company? What was your initial motivation and how do you see it nowadays?      Sergey Brin:  We started working on Google in 1995, as a research project at Stanford University.  In 1998, we formed the company, Google Inc., and launched the search engine in beta to the outside world.  This happened in September 1998.  Our goal was to created a very simple and easy-to-use website that offers the best search engine in the world.  This is still our goal, and we plan to continue to focus our business on search technology for some time to come.      OLinux: What kind of customers look for Google services and what are your company main clients? How fast Google wants to expand its solutions to other countries around the world?       Sergey Brin:  We have over 100 customers in over 20 countries.  Some of our banner customers include Yahoo!, AOL/Netscape, Cisco, WashingtonPost.com, and VirginNet (in the UK).  Google customers license our technology because they are looking for the fastest, most relevant search on the Internet. Google currently supports 25 language searches, and will continue to aggressively add to this list.  We ultimately hope to support all major languages in the world.     OLinux: How fast revenues are growing? Are there any plans for an IPO?      Sergey Brin:  We're very happy with our business plan.  Revenues are growing every quarter and we've made very few changes to our business strategy since we started the company.  An IPO is something we're considering, but is not in our near-term plans.  We've always managed the finances of our company very carefully, and we are fortunate to still have a very strong cash position from our initial venture financing, which was in June 1999.     OLinux: How did business over Internet has change the use of Google widening client's base and  for searching tools?      Sergey Brin:  We have millions of users a day who use Google to search for products and product information related to their purchasing decisions.  For example, we index almost the entire Amazon.com website.  As more and more information appears on the Internet, Google plans to index it and offer this content to our users.  Google currently is the world's largest search engine, with over 1 billion web pages in our index.     OLinux: What are your responsibilities at Google? Rapidly, describe your daily tasks at Google?      Sergey Brin:  Both my partner, Larry Page, and myself are very involved in almost all aspects of our business.  I spend quite a bit of time each day on hiring, internal management, and marketing.      OLinux: How does Google collaborate with its partners?      Sergey Brin:  Each of our partner relationships is unique, so it's hard to answer this question.  We support our partners in a variety of ways, from simply providing the world's best search technology, to co-marketing, to providing technological assistance, etc.     OLinux: What are the Google marketing strategies and alliances in order to keep itself on the Internet market?      Sergey Brin:  Google actually relies on our users to help with our marketing. We have a very high percentage of our users who often tell others about our search engine.  This has helped Google immensely, and has helped our website traffic grow over 20% per month since we started our company in 1998.     OLinux: How is Google organized? Try to give us an idea of how Google works? How is the coordination and management (servers, directories, contribution, staff payment)? How many people are involved? What are the main problems? Does Google have a central office somewhere or a HQ?      Sergey Brin:  Google has two offices.  Our headquarters are in the heart of Silicon Valley -- in Mountain View, California, which is about 10 minutes from Stanford University, where Google was born.  We also have a small sales office in New York City, with about 10 employees who sell advertising for us.  In total, we have just over 150 employees.  Most of these employees are involved with our technology and engineering department.  We have over 30 PhD's in this group!   Google's servers (we have over 6,000 servers that run RedHat 6.2) are hosted at three data centers across the U.S. -- one in the Washington DC area, and two in Silicon Valley.      OLinux: Please, evaluate rapidly Google evolution in terms of pages served using its tools? Can you describe something that really helped the project to succeeded? Have any idea of number of sites using Google search engine? Number of pages served by google engine every day?      Sergey Brin:  Google currently servers over 20 million searches per day on our own website ( www.google.com ), and over 50 million searches per day on our own site and our partner websites (Yahoo, Netscape, Cisco, etc.).  Have so many smart and talented employees has really helped our company succeed.  There are over 25,000 websites on the Internet that use the Google search engine.     OLinux: Why should a site choose Google search engine instead of others? What are the better features Google bring to users?      Sergey Brin:  Google offers users better quality search results, a simple, easy-to-use interface, high performance, and an exclusive focus on just being a search engine.  We also offer cool features like caches pages, stock quotes, news headlines, links to online maps.      OLinux: Let's talk about Research and Development (R&D) and Software Engineering (SE): How many people work in SE activities developing google main tools? What is its policy toward investment in R&D?      Sergey Brin:  We have about 80 engineers and R&D team members, and we're big fans of investing heavily in R&D.     OLinux: How is the research & development coordinated? What are the analysis and programming tools used? Are there any special quality control, auditing on code produced?What are the main projects under way?      Sergey Brin:  They're very closely intertwined; developers do research and vice versa, and everyone talks a lot.  Communication is very good between both of these groups.  For programming we use gnu tools: gcc, gdb, gnats.  We use p4 for version control.  For network installs, we use a variety of our own software, in addition to rsync.  Machines are built on-site here at Google, configured, then shipped over to one of our three data centers.  We have a detailed regimen for code reviews and testing (QA).  The main projects we're working on, outside of improving the overall quality of our search engine are:  Google wireless search technology, a variety of voice recognition projects, and Google international search technology bringing Google to more users worldwide.      OLinux: Currently, Google search engine runs in more than 5000 Red hat Linux  servers. I read that Google system install and configure 80 servers at a time. What kind of tools coordinate this mass installation? What are the administrative tools used to monitor, check and replace servers failures?  How is Linux used at the Google Projects? Why was Linux choose to improve Google search engine?      Sergey Brin:  Actually, we currently run over 6,000 RedHat servers.  Linux is used everywhere...on the 6,000+ servers themselves, as well as desktop machines for all of our technical employees.  We chose Linux because if offers us the price for performance ratio.  It's so nice to be able to customize any part of the operating system that we like, at anytime.  We have a large degree of in-house Linux expertise, too.   Most of our administrative tools were developed in-house, as well.     OLinux: What is Google security policy and how is it implemented?      Sergey Brin:  Most of our machines are behind a router and not accessible to the outside world.  The outside-accessible machines (webservers) are carefully audited for security holes.   We also use ssh an awful lot.  :-)                Copyright © 2000, Fernando Ribeiro Corrêa. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 59 of  Linux Gazette , November 2000        ""Linux Gazette... making Linux just a little more fun! ""                 IBM: The Big Blue Support for the Linux Comunity   By  Fernando Ribeiro Corrêa  Originally published at  OLinux                       OLinux: What is the group behind Linux at IBM (ibm open source site)? How are they divided and coordinated? Is there a central coordination for the project? Who is responsible for that?        IBM : Linux solutions touch the entire corporation -- hardware, software and services. IBM has established the Linux Technology Center as a focal point for its technical contributions to Linux. The center, which has a dedicated staff of engineers, manages the transfer of IBM technology to the open source community.    OLinux: How and when was Linux at IBM (the site) started? Was it a sort of top level and strategic decision or was it taken after clients/companies started asking for liunx solutions?      IBM : We began to see customer desire for Linux.  IBM started to a formal Linux plan in 1998.  We were begining to see customer desire and visionaries in some of our customer segments. viewing Linux as a wave of the future.  Along with other open standards, such as HTTP, XML and TCP, we view Linux as playing a pivotal role in bringing interoperability to disparate server platforms and providing customers with an open, integrated e-business structure.    OLinux: How is the work coordinated and managed (servers, directories, contribution, staff payment)? How many people are involved world wide?    IBM : IBM's Linux strategy is to Linux enable all hardware, software and services. There are thousands of people working worldwide on this major initiative.     OLinux: How much has IBM invested ($) on research (labs, staff) and marketing it solutions?      IBM : Overall, IBM has invested millions of dollars in Linux. We will invest more than $200 million in a series of Linux initiatives in Europe and Asia Pacific over the next four years. These investments will include Linux development centers across Europe and Asia, alliances with Linux-focused business partners, along with the rapid deployment of about 600 specialized Linux consultants, hardware and software specialists, and services professionals. In the US, IBM has dedicated millions of dollars to help fund the Open Source Development Lab with Intel, NEC, HP and other Linux leaders    OLinux: From the start, IBM has contributed in many ways to chage conceptions on the computing world. How strategic was the decision to embrace Linux platform?      IBM : The decision was very strategic.  For IBM, it's an inflection point that's associated with our focus on creating e-business solutions. We're helping companies build content solutions, commerce solutions, operations solutions--and Linux is a standard that we can use to help integrate all of these. It makes it much easier to move application components around.  As a company, we're very sensitive to what it takes to achieve integration, because we're not just focused on selling this or that hardware platform. Linux will become the application development platform of choice for developers because of its multi-platform nature, and because it's not owned by any vendor. As a result of that, you can have vendors collaborating on standards.     OLinux: Was there any connection related to IBM's decision to suport Linux and the retirement of OS2 platform?    IBM : By embracing Linux, we are providing our customers with a choice of operating systems. The decision to embrace Linux is separate from OS2.    OLinux: What are the main research regarding software development projects going on? Whats the database program and programming tools and languages used (Perl, C)? How many developers work for IBM?       IBM : In the Software Group of IBM, we are currently working very hard to make sure all of our mission-critical software is able to support Linux.  We have an expansive research and development team at IBM, with the actual number of developers in the thousands.    OLinux: Give us an idea of what Monterey Project represents for IBM?     IBM : The Project Monterey initiative was originally intended to enhance AIX with technologies from IBM's DYNIX/ptx (formerly of Sequent) and SCO's UnixWare operating systems, as well as to extend support for this enhanced AIX operating system to Intel's IA-64 bit architecture.  AIX 5L, to be released later this year, demonstrates the success of the Project Monterey initiative, incorporating technology from the world's leading software and hardware providers, while maintaining the robustness of AIX.     AIX 5L -- the next generation of AIX -- takes AIX to the next level with leadership technology, a strong Linux affinity and added support for both IBM's Power and Intel's future IA-64 processor-based platforms, making it the most open UNIX in the industry.  IBM, SCO/Caldera and Intel will continue to work together on AIX 5L for IA-64. We anticipate that future releases of AIX will continue to incorporate valuable technologies from IBM and the industry to satisfy requirements from many OEM system providers, independent hardware providers and independent software providers and deliver AIX 5L for IA-64 offerings and solutions.     OLinux: Tell us about IBM's Linux strategy. What are the main projects involving Linux? Are revenues already representative in terms of  servers and desktops shipped with pre-installed?       IBM:  IBM intends to make all of its server platforms Linux friendly, including S/390, AS/400, RS/6000 and Netfinity servers, and the work is already well underway.  Netfinity servers are certified under the IBM ServerProven Program for Caldera, Red Hat, SuSE and TurboLinux distributions.  In addition, selected models of IBM IntelliStations and ThinkPads are now Linux-enabled.      IBM has delivered all critical elements of its Application Framework for e-business on Linux, including DB2 Universal Database; WebSphere Application Servers, powered by the Apache HTTP engine; Domino; MQSeries; Developer Kit for Java; Tivoli system management tools; and VisualAge for Java. IBM is also working with its business partners to accelerate the development of applications for Linux.  IBM offers a wide range of Linux consulting, design, implementation and technical support services, and a full curriculum of education, training, and certification programs.  IBM consultants skilled in Linux are available worldwide to help customers develop, configure and enhance their Linux hardware and software solutions.    OLinux: What kind of custumers use IBM's services and software running Linux? Can you disclose some important companies using Linux? Any cases of study to reveal to us?     IBM:  The University of New Mexico purchased 256 IBM Netfinity servers clustered with Red Hat Linux, creating the 24th fastest supercomputer.  It is just about ready to go online.  This new supercluster will increase the computing capabilities of the National Computational Science Alliance, a National Science Foundation (NSF) funded partnership, providing researchers with a platform for developing improved cluster management tools, gaining operational experience on large-scale clusters, and exploring the scalability of different types of science and engineering applications.     Weather.com, The Weather Channel Web site, is also using Linux with IBM technology and services to serve its massive volume of maps and images, in an effort to meet the site's extreme traffic demands.  IBM solutions will also become part of the Internet infrastructure for weather.com.    OLinux: Can you explain IBM strategy towards building alliances with Linux companies as Red Hat, Turbo Linux, Transmeta?       IBM:  Our strategy to work with Linux distributors is driven by customer demand.  Our customer base throughout the world has consistantly pointed to the distribution leaders and based on that feedback, we've established solid relationships with Red Hat, SuSE, TurboLinux and Caldera.    OLinux: IBM will ship its ThinkPads with Transmeta Crusoe chip. What this new technologies represent and how IBm plans to deploy it (the Crusoe chip)?    IBM:  We continue to evaluate Transmeta as a possible processor technolog and we expect to finalize our decision soon.     OLinux: IBM supports Suse, Red Hat and turboLinux internationally. Why doesn't IBM support Debian GNU/Linux distribution which is regarded one of the easiest and most secure to work?    IBM:  We base our decisions on customer demand. While Debian is well thought of, our customers have consistently expressed an interest in Red Hat, SuSE, TurboLinux and Caldera - and that's what we're giving them.     OLinux: Is Linux ready for mission critical operations? Will Linux ever substitute most of Unix in mission critical procesing? Are there any researches about Linux being deployed in such tasks like that?      IBM:  Over time, Linux will become a viable enterprise UNIX system, capable of running more workloads requiring high scalability and industrial strength.  We will work with the Linux community to help build such an enterprise Linux offering.  This will take years, with the rate and pace being determined by the Linux community.  Operating systems evolve slowly, and it is uncertain when Linux will have comprehensive enterprise capabilities.     OLinux: What about desktop users: are there any companies asking Linux for desktop apps?      IBM:  Customers are always asking for more applications. We are working with the community to help create more applications for both the desktop and the enterprise.    OLinux: How important is the PartnerWorld and PartnerMarketing strategy for IBM's product selling?      IBM:  Our partners thoughout the world are very important to our core product strategy.  Through our partner programs, we're able to qualify and educate our partners - updating them on trends in the industry, technology advances, new product introductions - quickland easily. Building a solid foundation of key partners has been instrumental in propelling IBM to the forefront of our industry.  We established PartnerWorld years ago as a means of centrally gathering our business partners on an annual basis - giving them an opportunity to hear firsthand new developments from IBM.     OLinux: How was Linux World recent event for the company? Can you describe the event on a business perspective? Can you disclose any results about new clients or companies willing to buy IBM's services?       IBM:  The most recent LinuxWorld in San Jose, California was a huge success for IBM.  We made a significant announcement with Red Hat which allows Red Hat to bundle and resell all of IBM's Linux-based software. This global alliance was incredibly well received.  Also at the show, we announced our support for the newly found GNOME foundation and several open source announcements. Based on customer feedback, this show clearly places IBM at the forefront of the Linux movement.  We have consistantly supported this new operating system and will continue to help move the technology forward.      OLinux: How does IBM sees KDE and GNOME? Do you think a merger would make better results? What relation does IBM have with GNOME? How importante is the GNOME foundation for IBM?       IBM:  KDE and GNOME are innovative, rapidly maturing Linux desktops. Both KDE and GNOME have a large community backing their support. IBM is working with both KDE and GNOME to accelerate Linux on the desktop.     OLinux: In your opinion, how importante is the GNOME foundation to improve Linux usage on the PCs?      IBM:  The GNOME Foundation is important to Linux on the desktop because it was formed to advance the GNOME desktop, the world's leading free and easy-to-use desktop environment for the user.  GNOME has been designed to run on all modern strains of Unix-like operating systems. The support of leading  vendors, including Sun Microsystems, IBM, Compaq, Eazel, CollabNet, Helix Code,  Red Hat, demonstrates that the industry is coalescing behind GNOME as the esktop environment of the future. IBM has already released some technologies to GNOM including SashXB for Linux.                   Copyright © 2000, Fernando Ribeiro Corrêa. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 59 of  Linux Gazette , November 2000        ""Linux Gazette... making Linux just a little more fun! ""                 Alpha in the New Processors Market   By  Fernando Ribeiro Corrêa  Originally published at  OLinux                    OLinux: Alpha supports all major Linux distributions these days. How has been the relation between Alpha and Linux companies and Alpha and Linux community?     Richard Payne:  I think the relationship is great, Alpha support is usually second only to i386 in the Linux kernel and most applications. There have been a few areas where we've had problems (for example Netscape) and there various companies have helped out (for example Compaq releasing the Tru64 libraries so Linux users can run the Tru64 version of Netscape).    In addition I know that both API and Compaq work quite closely with the various distributions, providing assistance when it's necessary.     OLinux: Can you detail the relation between alpha and  Li.org ?    Richard Payne:  Both API and Compaq are members of LI.    OLinux: Does Alpha sponsor any FS/OS event? Or organization?     Richard Payne:  Both API and Compaq sponsor various organizations. API has recently sent two machines to the Alsa group to ensure that Alsa stays supported on Alpha. I know of many kernel developers that have Alphas that have been donated by API or Compaq. API has also donated a machine to the AlphaLinux Organization ( www.alphalinux.org ) and is currently buying banner ad time from ALO.    In addition both companies (and sometimes alphalinux.org) can also usually be found at the major Linux shows.      OLinux: Linux companies are struggling to prove that investor won't have to wait a decade e to see profits or their investments back. Those stocks have lost its initial and phenomenal glamour. Is clear for you that Linux companies can make money and be profitable?     Richard Payne:  I think they can, however it's going to take time. I think over the next few years we're really going to see software become a commodity. If you look back of the last few decades we've had an incredible duplication of effort out there. How many different UNIX types did we have? All with massive development and support organizations behind them. I can't help thinking this is just a massive waste of resources, especially when everybody all of those version basically perform the same functions.     OLinux: Transmeta is planing an IPO and have already launched Crusoe. How do you analyze Trasmeta innovation? Are there any direct moves of aplha related to Crusoe comp competition on chip market?    Richard Payne:  Alpha and Crusoe and in different markets. Transmeta is going after the small low power segment. I see them more competing with the mobile Intel and PowerPC offerings. Alpha is at the other end of the spectrum, high performance but also high power usage and heat, not ideal for a laptop!     OLinux: Alpha supports all major Linux distributions these days. How has been the relation between alpha and Linux companies and Alpha and Linux community?     Richard Payne:  I think the relationship is great, Alpha support is usually second only to i386 in the Linux kernel and most applications. There have been a few areas where we've had problems (for example Netscape) and there various companies have helped out (for example Compaq releasing the Tru64 libraries so Linux users can run the Tru64 version of Netscape).    In addition I know that both API and Compaq work quite closely with the various distributions, providing assistance when it's necessary.     OLinux: Can you detail the relation between alpha and Li.org?    Richard Payne:  Both API and Compaq are members of LI.    OLinux: Does Alpha sponsor any FS/OS event? Or organization?     Richard Payne:  Both API and Compaq sponsor various organizations. API has recently sent two machines to the Alsa group to ensure that Alsa stays supported on Alpha. I know of many kernel developers that have Alphas that have been donated by API or Compaq. API has also donated a machine to the AlphaLinux Organization (www.alphalinux.org) and is currently buying banner ad time from ALO.    In addition both companies (and sometimes alphalinux.org) can also usually be found at the major Linux shows.      OLinux: Linux companies are struggling to prove that investor won't have to wait a decade e to see profits or their investments back. Those stocks have lost its initial and phenomenal glamour. Is clear for you that Linux companies can make money and be profitable?     Richard Payne:  I think they can, however it's going to take time. I think over the next few years we're really going to see software become a commodity. If you look back of the last few decades we've had an incredible duplication of effort out there. How many different UNIX types did we have? All with massive development and support organizations behind them. I can't help thinking this is just a massive waste of resources, especially when everybody all of those version basically perform the same functions.     OLinux: Transmeta is planing an IPO and have already launched Crusoe. How do you analyze Trasmeta innovation? Are there any direct moves of aplha related to Crusoe comp competition on chip market?    Richard Payne:  Alpha and Crusoe and in different markets. Transmeta is going after the small low power segment. I see them more competing with the mobile Intel and PowerPC offerings. Alpha is at the other end of the spectrum, high performance but also high power usage and heat, not ideal for a laptop!                  Copyright © 2000, Fernando Ribeiro Corrêa. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 59 of  Linux Gazette , November 2000        ""Linux Gazette... making Linux just a little more fun! ""                 The Australian History of Tux   By  Chris Jones                     Gday from the land of Oz,    If anyone out there is wondering about the growing popularity of  Linux  and its adoption by Australian writers as a writers true  operating system, perhaps the following may help explain.    On the reason for choosing Tux--the penguin mascot for Linux--Linus Tolvalds, the first of thousands who wrote the Linux computer operating system on the world wide web, had this to say:    When I was in Canberra a few years ago we went to the local zoo ... There they had a ferocious penguin that bit me...      OK now, when Linus says he was bitten by an angry penguin in Canberra and that is a good reason for the Tux mascot which today spells Linux,  there maybe more to the story.    During the 1940s and 50s in Australia there was a literary magazine called, of all things,  The Angry Penguins . This magazine was an avant-garde modernist poetry magazine edited by Max Harris and had modernist painters and writers grouped around it whose names are now legend in Australian art. But at that time they were just considered weird and way out. You know, the stereotype of mad deluded poets and artists starving and living in sub-standard housing.     Anyway, this literary magazine started to get a bit too much of a following. A couple of boring farts, both academic poets, got a bit hot under the collar about this and got together to write and submit a hoax modernist poem under the false name of Ern Malley. As it worked out, these farts are now better known for this hoax and the false name Ern Malley, then their own true names and works.    Now, since most of the archives for the Angry Penguins and a complete set of the journals may be found living in the National Library in Canberra, the question remains: was Linus bitten by a real angry penguin? Could it have been the ghost of Ern Malley? Or much worst still, could it be the ghost of Max Harris? After all, I'd rather be bitten by the ghost of a hoax poet then the ghost of a really angry penguin poet.    But as Linus later admits, it was really a fairy penguin that sucked gently on his finger, thinking it a fish. But, oh my, even more dangerous. Could he have had his digit licked by a queer poet becoming penguin?    So when Linus later writes:    Some people have told me they don't think a fat penguin really embodies the grace of Linux,  which just tells me they have never seen a angry  penguin charging at them in excess of 100mph.  They'd be a lot more careful about what they say if they had.     He isn't wrong!                     Copyright © 2000, Chris Jones. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 59 of  Linux Gazette , November 2000        ""Linux Gazette... making Linux just a little more fun! ""                 Tuxedo Tails   By  Eric Kasten                                [Eric also draws the  Sun Puppy  comic strip at   http://www.sunpuppy.com .  -Ed.]                    Copyright © 2000, Eric Kasten. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 59 of  Linux Gazette , November 2000        ""Linux Gazette... making Linux just a little more fun! ""                 PHP Essentials (book review)   By  Patrick Lambert                     In this short article I will talk about a book on PHP, a web scripting language. But before going into the book itself, let's see what web scripting is and what PHP is all about. Web sites, 5 years ago, were simple text files with some images inserted. They were all done using HTML, the standard markup language. Now, in the year 2000, things have changed dramatically. Sites now provide more than just static, textual information. Web sites include dynamic information, animation files, session management (which allows them to recognize you at each visit) and other modern features. All of these features can't be created using only static HTML pages. Scripting languages need to be used to make the connection to the databases, to handle session management and to do all of the other back-end processing required to have good, modern pages.    PHP is a server-side scripting language. This means that it is composed of lines of code inserted in HTML pages. The web server processes the code, and its output is printed on the web page. Several other server-based scripting languages exist, including Microsoft ASP and CodeFusion. PHP is available on most Unix platforms and on Microsoft Windows.     PHP Essentials  is a book for the HTML writer who wants to get into web scripting. If you have experience in making simple web sites and want to do complex dynamic sites, then this is the book for you. The book was published in Spring 2000 by Prima Publishing, a company that publishes dozens of computer books, and was written by Julie Meloni, a technical director for a multimedia company located in Campbell, California.    The information is very well presented; it is easy to read and is always supported with examples. Another plus is that it uses real life scenarios-- works you may need to accomplish in a real life situation where you need to create web sites. For example, most sites use databases to store user data, so the book thoroughly discusses database connections.    The author also provides an in-depth coverage of most topics. For example, in the first chapter, she talks about the installation phase and describes how to install PHP on various platforms and with several web servers, including Apache and Internet Information Server. In the database section, the book spends some time describing database systems as well as basic queries.    Also, the book is very up to date. It covers the latest PHP version, PHP4. Database examples are based on the MySQL database, which is currently the most popular database with Linux users. It is a recent book, and it shows.    While these are good features, there are also some problems. First, while it covers certain subjects in depth, it doesn't cover everything. Some topics that might be useful for web developers are not covered at all--the book is quite short.     Another thing that would have been nice is a CD-ROM with the example source code and with PHP itself. The book comes with no CD-ROM at all, and this is a down point.    Globally,  PHP Essentials  is a very good book for people who want to learn more about advanced web development using the PHP language. The book is listed at $39.99, which is very reasonable for a computer book. It's not the first book about PHP and most likely will not be the last, but it is the best choice for people beginning with PHP programming.     [The publisher's site is   www.prima-tech.com . The program listings in the book are at   www.thickbook.com .  The hyperlink should go right to the page, but if it doesn't, go to the site and choose ""code"" on the main menu. -Ed.]                     Copyright © 2000, Patrick Lambert. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 59 of  Linux Gazette , November 2000        ""Linux Gazette... making Linux just a little more fun! ""                 dmesg explained   By  José Nazario  and  Natarajan Krishnaswami                     Abstract     Often someone will write to a Linux help list asking for help with a particular device they want to get working under Linux, and a standard reply is ""check the output of the dmesg command"". This leaves a lot of new users befuddled, and this document is here to hopefully help them navigate this powerful debugging tool. Two sets of kernel boot messages are presented and annotated, from an i386 system and a Linux-Pmac system.      Introduction     The Linux kernel is the central interface between the user and the hardware. As such, it has to incorporate support for hardware if you are to use it.  Often, though, cryptic device names are used by the system, making it difficult at first inspection to determine if some particular hardware is supported. The command 'dmesg', which is used to print kernel messages, is very useful in determining if a piece of hardware has been found, and if so, what the system is referring to it as.   This artcle, including the title and format of the dmesg comments, were directly inspired and copied from the OpenBSD Explained article by the same name. I felt one on Linux would be useful for people.     The manpage for dmesg is quite simple:  DMESG(8)                                                 DMESG(8)   NAME        dmesg - print or control the kernel ring buffer  SYNOPSIS       dmesg [ -c ] [ -n level ] [ -s bufsize ]  DESCRIPTION        dmesg is  used  to  examine  or  control  the kernel ring        buffer.    Upon boot, the dmesg output is from the kernel booting, showing the devices it has found and if it has been able to configure them at all (aside from userland configuration). This log is also available in the  file  /var/log/dmesg .     Kernel output on an i386 system      Shown below is a dmesg from an x86 system immediately after boot. The output is indented by several space, and comments and descriptions are left justified.            Linux version 2.2.14-5.0 (root@porky.devel.redhat.com) (gcc version egcs-2.91.66 19990314/Linux (egcs-1.1.2 release)) #1 Tue Mar 7 20:53:41 EST 2000       First up is the kernel version (2.2.14) and build (5), along with who built it, with what compile it was built, and when it wass built. This can be some inportant information, as some kernel versions and the GCC project don't interact correctly.            Detected 300683434 Hz processor.       My K6/2-300 processor running at 300 MHz.            Console: colour VGA+ 80x25       A standard PC console screen (15 inch monitor).            Calibrating delay loop... 599.65 BogoMIPS       The useless benchmark of BogoMIPS. They're bogus (hence the name), but are often used as a relative processor speed indicator.            Memory: 63008k/65536k available (1084k kernel code, 412k reserved, 968k data, 64k init, 0k bigmem)       My memory statistics. My machine has 64MB of real memory.            Dentry hash table entries: 262144 (order 9, 2048k)       The dentry cache (dcache) represents the kernel's view of the namespace of mounted filesystems.  There's pretty good documentation of it in Documentation/filesystems/vfs.txt in the kernel source tree.            Buffer cache hash table entries: 65536 (order 6, 256k)       In 2.2, the buffer cache is used for caching and aggregating data for writes to block devices.  After 2.3.6, it is used for caching fs metadata, such as inode information.            Page cache hash table entries: 16384 (order 4, 64k)       In 2.2, the page (VM) cache is used for caching swap, read and mmap data (which was bad, because shared writable mappings were ugly). After 2.3.6, it also is used for write data (i.e., the buffer and page caches are mostly unified), and all became happiness and light (sorta like BSD).            VFS: Diskquotas version dquot_6.4.0 initialized       My kernel support quotas (though I'm not using them).            CPU: AMD AMD-K6(tm) 3D processor stepping 00       A quick identification of the processor.            Checking 386/387 coupling... OK, FPU using exception 16 error reporting.       Checking 'hlt' instruction... OK.       I seem to recall there being some Intel processor issues, which the kernel has to know about if it's to invoke corrections.            POSIX conformance testing by UNIFIX       PCI: PCI BIOS revision 2.10 entry at 0xfb490       And we start the probing of the PCI bus for peripherals.            PCI: Using configuration type 1       PCI: Probing PCI hardware       PCI: 00:38 [1106/0586]: Work around ISA DMA hangs (00)       Activating ISA DMA hang workarounds.       Linux NET4.0 for Linux 2.2       This kernel supports the Net4 networking codebase, which has a lot of features yet to be fully utilized.            Based upon Swansea University Computer Society NET3.039       NET4: Unix domain sockets 1.0 for Linux NET4.0.       NET4: Linux TCP/IP 1.0 for NET4.0       IP Protocols: ICMP, UDP, TCP, IGMP       My core IP protocols supported. While not needed, IGMP can be fun. Note that some networks do not support muticasting.            TCP: Hash tables configured (ehash 65536 bhash 65536)       Initializing RT netlink socket       Starting kswapd v 1.5       Detected PS/2 Mouse Port.       Should be quite obvious...            Serial driver version 4.27 with MANY_PORTS MULTIPORT SHARE_IRQ enabled       ttyS00 at 0x03f8 (irq = 4) is a 16550A       ttyS01 at 0x02f8 (irq = 3) is a 16550A       The information about my serial ports.            pty: 256 Unix98 ptys configured       apm: BIOS version 1.2 Flags 0x07 (Driver version 1.9)       My motherboard supports the APM standard for sleeping.            Real Time Clock Driver v1.09       RAM disk driver initialized: 16 RAM disks of 4096K size       My kernel supports RAM disks. While I'm not using any most days, sometimes I do use them; if you have the memory, they make a real fast filesystem (like /tmp or, for a webserver, the main pages loaded).             VP_IDE: IDE controller on PCI bus 00 dev 39       VP_IDE: not 100% native mode: will probe irqs later       ide0: BM-DMA at 0xe000-0xe007, BIOS settings: hda:DMA, hdb:DMA       ide1: BM-DMA at 0xe008-0xe00f, BIOS settings: hdc:DMA, hdd:DMA       My IDE controllers.            hda: Maxtor 51369U3, ATA DISK drive       My hard drive in the machine.            hdb: IDE/ATAPI CD-ROM 32X, ATAPI CDROM drive       My CDROM drive.            ide0 at 0x1f0-0x1f7,0x3f6 on irq 14       hda: Maxtor 51369U3, 12949MB w/2048kB Cache, CHS=6577/64/63       hdb: ATAPI 16X CD-ROM drive, 128kB Cache       Disk information.            Uniform CDROM driver Revision: 2.56       Floppy drive(s): fd0 is 1.44M       FDC 0 is a post-1991 82077       Floppy drive information.            md driver 0.90.0 MAX_MD_DEVS=256, MAX_REAL=12       raid5: measuring checksumming speed       raid5: MMX detected, trying high-speed MMX checksum routines       pII_mmx : 761.238 MB/sec       p5_mmx : 726.567 MB/sec       8regs : 447.675 MB/sec       32regs : 308.610 MB/sec       using fastest function: pII_mmx (761.238 MB/sec)       A bunch of RAID and MD (used in multiple device devices, like disk arrays) information, again not used.            scsi : 0 hosts.       scsi : detected total.       While the kernel supports SCSI, I'm not using any on this host.            md.c: sizeof(mdp_super_t) = 4096       Partition check:       hda: hda1 hda2 < hda5 hda6 >       My disk partition information. The brackets indicate extended partitions.            autodetecting RAID arrays       autorun ...       ... autorun DONE.       Like I said above, I'm using not using any RAID arrays.            VFS: Mounted root (ext2 filesystem) readonly.       At this point we're almost done with the kernel and ready to start the system.             Freeing unused kernel memory: 64k freed       Adding Swap: 66488k swap-space (priority -1)       ne2k-pci.c:vpre-1.00e 5/27/99 D. Becker/P. Gortmaker http://cesdis.gsfc.nasa.gov/linux/drivers/ne2k-pci.html       ne2k-pci.c: PCI NE2000 clone 'RealTek RTL-8029' at I/O 0xe800, IRQ 11.       eth0: RealTek RTL-8029 found at 0xe800, IRQ 11, 00:80:AD:41:22:10.       My ethernet device is a PCI NE2000 based device. (A real cheap NIC, but almost every OS supports it.)            VFS: Disk change detected on device fd(2,0)       At this point, the kernel is done booting and we're ready to start /sbin/init (unless we supplied some information about init upon boot). The system then starts rc.sysinit and begins normal boot operations. The kernel has finished booting.     Kernel output on a Linux-Pmac system      And, for comparison's sake, this is the output of Linux 2.2 on a PowerPC system. Again, the dmesg output is indented and the description and comments are left justified. For this system I was using BootX, which loads  the kernel into memory from within the MacOS, then completes bootstrapping  it after ditching the MacOS. Options can be passed to the kernel, as you  would with LILO on an Intel based PC, from within the app.             device tree used 17860 bytes       PowerPC systems use what is known as OpenFirmware, rather than a PC like BIOS, and it has a 'device tree', which is arranged a bit like a UNIX filesystem. This one uses about 16kb.            Total memory = 72MB; using 512kB for hash table (at c0280000)       Again, total physical RAM available.            Linux version 2.2.6-15apmac (root@video.linuxppc.org) (gcc version       egcs-2.91.66 19990314 (egcs-1.1.2 release)) #1 Mon May 31 03:54:09      EDT 1999       Kernel version (2.2.6 build 15 on a Pmac), who built it (root@video.linuxppc.org), what version of gcc (or egcs), and when it was built. This can be diagnostic as some versions of the Linux kernel don't play well with some versions of GCC.            PCI bus 0 controlled by bandit at f2000000       PCI bus 1 controlled by chaos at f0000000       Two PCI busses. OpenFirmware (OF) calls their controllers bandit and chaos.            System has 32 possible interrupts       via_calibrate_decr: decrementer_count = 100001 (600010 ticks)       Console: colour dummy device 80x25       Calibrating delay loop... 239.21 BogoMIPS       Ahh... sweet BogoMIPS, which mean pretty much nothing.            Memory: 69900k available (1532k kernel code, 2184k data, 112k init)       [c0000000,c4800000]       After the initial bootstrap, about 68 MB of memory is left, having reserved some for the kernel and core system.            VFS: Diskquotas version dquot_6.4.0 initialized       POSIX conformance testing by UNIFIX       PCI: Probing PCI hardware       Let the PCI probing begin!            USB: Universal USB Driver v$Revision: 1.2 $       USB-OHCI: USB Open Host Controller Interface Driver       USB-HUBD: UUSBD Hub Driver v$Revision: 1.2 $       USB-HIDD: USB Human Interface Devices Driver v$Revision: 1.2 $       USB-HIDBP: USB HID Boot Protocol Driver v$Revision: 1.2 $        USB support is in the kernel, though I have no USB devices on the system.            adb devices: [2]: 2 2 [3]: 3 1       ADB, or Apple Desktop Bus, has two devices, the keyboard and the mouse.  We'll see them detected below.            Linux NET4.0 for Linux 2.2       Based upon Swansea University Computer Society NET3.039       NET4: Unix domain sockets 1.0 for Linux NET4.0.       NET4: Linux TCP/IP 1.0 for NET4.0       IP Protocols: ICMP, UDP, TCP, IGMP       Core networking protocols (NET4) built into the kernel. The IGMP comes from multicast support (see Stevens for more info).            Starting kswapd v 1.5       MacOS display is /bandit/IMS,tt128mb8       Recall that bandit is the PCI controller (bus0). I use an IMS Twin Turbo 8  MB video chipset.            Console: switching to colour frame buffer device 80x30       fb0: IMS TT (TVP) frame buffer; 8MB vram; chip version 2       Monitor sense value = 0x73f, using video mode 6 and color mode 0.       fb1: control display adapter       Some video settings. On PowerMac hardware, sometimes this can be important if you've loaded a kernel level video driver, which can cause havoc on some systems. This is useful stuff to check on a PPC that has some video problems (ie in X).            ADB mouse at 3, handler set to 4       ADB keyboard at 2, handler set to 5       PowerMac Z8530 serial driver version 1.01       tty00 at 0xc900e020 (irq = 15) is a Z8530 ESCC, port = modem       tty01 at 0xc9011000 (irq = 16) is a Z8530 ESCC, port = printer       It found the ADB devices and also the two serial ports. It's useful to know which ones are which. Recall that Macintosh machines have one labeled modem and one labeled printer, so this is useful info to know.            pty: 256 Unix98 ptys configured       Macintosh ADB mouse driver installed.       DMA sound driver installed, using 4 buffers of 32k.       RAM disk driver initialized: 16 RAM disks of 4096K size       loop: registered device at major 7       fd0: SWIM3 floppy controller       fd0, or the floppy drive 0, on PowerMacs uses a controller called 'SWIM3'. Unfortunately, in this instance of the kernel, it's broken.            md driver 0.90.0 MAX_MD_DEVS=256, MAX_REAL=12       USB-HUBM: Starting kusbdd (pid 2)       USBD: No USB hosts found       linear personality registered       raid0 personality registered       raid1 personality registered       raid5: measuring checksumming speed       If I had RAID controllers, this would be neat. As such, it's just sucking up space in my kernel.            8regs : 140.970 MB/sec       32regs : 122.301 MB/sec       using fastest function: 8regs (140.970 MB/sec)       scsi0 : MESH       scsi1 : 53C94       scsi : 2 hosts.        I have two SCSI controllers, both onboard, with one being internal (the MESH one) and one being external (the 53C94 controller).            mesh: target 0 synchronous at 10.0 MB/s       Vendor: IBM Model: DPES-31080 Rev: S31S       Type: Direct-Access ANSI SCSI revision: 01 CCS       Detected scsi disk sda at scsi0, channel 0, id 0, lun 0       Vendor: QUANTUM Model: CTS80S Rev: 4.05       Type: Direct-Access ANSI SCSI revision: 02       Detected scsi disk sdb at scsi0, channel 0, id 1, lun 0       mesh: target 3 synchronous at 5.0 MB/s       Vendor: MATSHITA Model: CD-ROM CR-8005A Rev: 4.0i       Type: CD-ROM ANSI SCSI revision: 02       Detected scsi CD-ROM sr0 at scsi0, channel 0, id 3, lun 0       mesh: target 4 synchronous at 10.0 MB/s       Vendor: SEAGATE Model: ST31200N Rev: 8648       Type: Direct-Access ANSI SCSI revision: 02       Detected scsi disk sdc at scsi0, channel 0, id 4, lun 0       Vendor: QUANTUM Model: FIREBALL_TM2110S Rev: 300X       Type: Direct-Access ANSI SCSI revision: 02       Detected scsi disk sdd at scsi1, channel 0, id 2, lun 0       scsi : detected 1 SCSI cdrom 4 SCSI disks total.       Uniform CDROM driver Revision: 2.54       SCSI device sda: hdwr sector= 512 bytes. Sectors= 2118144 [1034 MB]       [1.0 GB]       SCSI device sdb: hdwr sector= 512 bytes. Sectors= 166200 [81 MB]       [0.1 GB]       SCSI device sdc: hdwr sector= 512 bytes. Sectors= 2061108 [1006 MB]       [1.0 GB]       SCSI device sdd: hdwr sector= 512 bytes. Sectors= 4124736 [2014 MB]       [2.0 GB]       Disk detection. I'm not a big fan of how Linux names its disks (in the order it finds them), but it found all of my devices.            PPP: version 2.3.3 (demand dialling)       TCP compression code copyright 1989 Regents of the University of       California       PPP line discipline registered.       Kernel PPP support. Compressed TCP headers in PPP is a great feature, by the way, in keeping message overhead low.            eth0: MACE at 00:05:02:10:e6:6d, chip revision 9.64       Good old eth0, the ethernet device. It's MACE on a PowerMac. If this had been a modular driver, it wouldn't have shown up here but only after the module had been inserted.            Partition check:       sda: sda1 sda2 sda3 sda4 sda5 sda6       sdb: sdb1       sdc: sdc1 sdc2 sdc3 sdc4       sdd: sdd1 sdd2 sdd3 sdd4        The partition check is useful for knowing what the disks are laid out as.            md.c: sizeof(mdp_super_t) = 4104       autodetecting RAID arrays       autorun ...       ... autorun DONE.       VFS: Mounted root (ext2 filesystem) readonly.       Freeing unused kernel memory: 112k init 32k prep       Adding Swap: 131428k swap-space (priority -1)       And we're done booting.     Concluding remarks     Like I noted above at the end of the i386 dmesg output, the kernel, once  finished, then moves on to  /sbin/init  unless an argument poiting it elsewhere has been passed to the kernel at boot time. An example would be telling the kernel "" init=/bin/sh "", such that it would execute a shell upon boot, rather than  /sbin/init  (and what follows). Note that the kernel only mounts the root filesystem read-only, so if all you do is boot the kernel you have to mount your disks read-write in order to affect changes on them (ie editing  /etc/passwd  to rescue root's password).   While this isn't the most thorough of jobs, I hope that this little tour has been enjoyable for everyone, and educational.                    Copyright © 2000, Jose Nazario and Natarajan Krishnaswami. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 59 of  Linux Gazette , November 2000        ""Linux Gazette... making Linux just a little more fun! ""                 Encrypting Data in Web Forms   By  Mark Nielsen                        References      Introduction      Using Blowfish      Converting Encrypted key to Hex.      Encrypt and Decrypted Methods      Why do this stuff?      Conclusion        References         http://www.perl.com/CPAN-local/modules/by-category/14_Security_and_Encryption/Crypt/Crypt-Blowfish-2.06.readme    http://www.perl.com/pub/doc/manual/html/pod/perlfunc/pack.html        Introduction  There may be times when you want to send encrypted data to a user on your web server. For example, if you want to hide the numeric id of an account. However, there is a problem sending encrypted data, it is binary. Also,  there aren't too many packages that are easy to encrypt data in Perl.         Using Blowfish  Blowfish is the easiest encryption module to use in Perl. It doesn't have any licensing restrictions either.  I believe some other modules also recently lost their resctrictions, but I always go with the ethically pure software if it is just as good as the other unethical software.       Here is an easy way to encrypt and then decrypt the data. Note, I don't print the binary encrypted string because it won't be printable.   use Crypt::Blowfish;  my $Blowfish_Key = ""An extremely dumb password you should change.""; my $Blowfish_Cipher = new Crypt::Blowfish $Blowfish_Key;    ### Remember, sentence has to be 8 long my $Sentence = ""DumbWord""; my $Encrypted = $Blowfish_Cipher->encrypt($Sentence); my $Decrypted = $Blowfish_Cipher->decrypt($Encrypted);  print ""Do the next two lines match?\n""; print ""$Sentence\n""; print ""$Decrypted\n"";       Converting Encrypted key to Hex  ""pack"" and ""unpack"" can be a little confusing to use in perl. Basically, they convert data into different formats. Like converting characters into their numeric ASCII equiv or converting hex numbers to integers,  etc.   All we want to do is convert binary data to hex data. Why is hex data important? It is alphanumeric and  won't screw up a browser with weird characters. There is no security using hex, but it is compact, and it is always a fixed length. It converts each character into a 2 hex characters (or numbers). Always having an exact length per character makes it easy to convert back to binary data.    Here is a simple command to convert a sentence to hex, and then converting it back to text.  my $Sentence = ""This is a dumb sentence.\n""; print ""$Sentence\n""; my $Hex = unpack(""H*"",$Sentence); print ""$Hex\n""; my $Sentence2 = pack(""H*"",$Hex); print ""$Sentence2\n"";       Encrypt and Decrypted Methods for cgi webpages  Here is a older smaller version of what we use at gnujobs.com, and it doesn't have a ""new"" method. This is just a simple package. Here is how you can call the methods:   First, I assume you are using mod_perl. In your root directory for the apache webserver, create this directory,   mkdir -p lib/perl/MyPackage   Then copy the module below to the location  lib/perl/MyPackage/Misc.pm .    To encrypt data,  use MyPackage::Misc; my $Data = ""Just a dumb sentence I want to encrypt""; my $Encrypted = MyPackage::Misc->Encrypt($Data);     To decrypt info,    use MyPackage::Misc; my $Decrypted = MyPackage::Misc->Decrypt($Encrypted);      And here are the methods. You should really customize these modules for your needs. I kept $Blowfish_Cipher as a global variable for the package so that it only needs to get compiled once. I guess I might as well copyright it with the GPL just to promote GPL. Here is the   GNU GPL  license.  (text version of this listing)     #!/usr/bin/perl  # Copyright (C) 2000 Mark E. Nielsen at GNUJobs.com  # This program is free software; you can redistribute it and/or # modify it under the terms of the GNU General Public License # as published by the Free Software Foundation; either version 2 # of the License, or (at your option) any later version.  # This program is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the # GNU General Public License for more details.  # You should have received a copy of the GNU General Public License # along with this program; if not, write to the Free Software # Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.  # Web-Encrypt-Example version 0, Copyright (C) 2000 Mark E. Nielsen at GNUJobs.com # Web-Encrypt-Example comes with ABSOLUTELY NO WARRANTY. # This is free software, and you are welcome # to redistribute it under certain conditions.  # The Computer Underground, Inc., hereby disclaims all copyright # interest in the program `Web-Encrypt-Example' # written by Mark E. Nielsen. # Mark E. Nielsen, President of The Computer Underground  package MyPackage::Misc;  use strict; use Crypt::Blowfish;  my $Blowfish_Key = ""An extremely dumb password you should change.""; my $Blowfish_Cipher = new Crypt::Blowfish $Blowfish_Key;  #----------------------------------- sub Encrypt { my $self = shift; my $String = shift;  my $Temp = $String; my $Encrypted = """"; while (length $Temp > 0)     {     ### If less than 8 characters, padd it with tabs   while (length $Temp < 8) {$Temp .= ""\t"";}     ### Ecnrypt the 8 length segment   my $Temp2 = $Blowfish_Cipher->encrypt(substr($Temp,0,8));     ### Add it to the end   $Encrypted .= $Temp2;      ### If it is 8 or less, abort, otherwise get the next segment   if (length $Temp > 8) {$Temp = substr($Temp,8);} else {$Temp = """";}   }  my $Unpacked = unpack(""H*"",$Encrypted);  return ($Unpacked); }  #-------------------------------- sub Decrypt { my $self = shift; my $String = shift;  my $Packed = pack(""H*"",$String);  my $Temp = $Packed; my $Decrypted = """"; while (length $Temp > 0)     {   my $Temp2 = substr($Temp,0,8);     ### In theory, we could up with less than 8 characters, check   if (length $Temp2 == 8)      {     my $Temp3 = $Blowfish_Cipher->decrypt($Temp2);     $Decrypted .= $Temp3;     }    if (length $Temp > 8) {$Temp = substr($Temp,8);} else {$Temp = """";}   }    ### Getting rid of tabs at the end, which could be a bad thing    ### but is how I did it.  $Decrypted =~ s/\t+$//g;  return ($Decrypted); }       NOTE: There is one special thing you ought to do when decrypting information. Check to see if it contains valid data. If it is numeric, make sure it is a number.Usually a smart idea is to always assume the number is positive and less than a billion, and do something like this,     my $Error = 1; if (($Value >0) && ($Value < 1000000000)) {$Error = 0;} if ($Error == 1) {print ""Darn it, this sucks, no valid data, bye bye!""; exit;}        Why do this stuff?  The need to encrypt data so that people can't put in arbitrary values can be very useful sometimes.  Granted, a web server shouldn't ever be setup to let people put in arbitrary values, but sometimes if you are not careful, people can download all information out of your database by simply changing unique identifiers in a web form. Most people don't care, but some do.    Also, if correctly setup, the encrypted data won't interfere with the person's web experience if you keep the encrypted data in hidden fields in the webpage.    If you wish to send out an email message to a user to view data on your website, sending an email with a link that contains encrypted data can be a way to protect people from understanding how your web pages work. It doesn't protect you too much, but the more irritating you make it, the more likely it is for someone to just not bother trying to figure out how you do things.       Conclusion    I haven't tested PHP or Python to see if they have an easy module for encrypting data. The only module that was easy to use in Perl was Blowfish. It was painful to get any others for Perl installed. If you come across any that were as easy to use, or easier than Blowish, please let me know at   info@gnujobs.com .                          Copyright © 2000, Mark Nielsen. Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 59 of  Linux Gazette , November 2000        ""Linux Gazette... making Linux just a little more fun! ""                                     Spreading the OO Fun (Series Introduction)      By  Jason Steffler                   Abstract         When I wrote the first Making Smalltalk with the Penguin  article back in March of 2000   [LL] , my target audience was experienced programmers who didn't have much exposure to  OO  programming or to Smalltalk.  The article's intent was to give an overview of my favourite programming language on my favourite operating system.  Since then, I've had a fair amount of email asking introductory type questions about Smalltalk and OO programming.  So I thought I'd try my hand at a small series.  It's been a while coming as after the first article I relocated from KS->CT and had a baby (obviously using the corporate 'I' here! :-)      The target audience for this series are people new to OO or new to programming altogether.  The intent is to not only introduce OO programming, but to also spread the fun of Smalltalking.  Why do this format/effort when there's lots of good  tutorials out there ?  Two reasons really:  1) Tutorials are great, but can be static and dated pretty quickly.  2) An ongoing series tends to be more engaging and digestible.      To help address the second reason above, my intent is to keep the articles concise so they can be digested in under an hour 1 .  Hopefully, as newbies follow along, they can refer back to the original article and make more sense of it.  I plan on having a touch of advanced stuff once in a while to add flavour and as before, the articles are going to be written for read-along or code-along people.      Something new I'm going to try is to make the ongoing series viewable in a contiguous fashion and downloadable in one chunk for people who want to browse the series locally.  To do this, click on TOC grapic to right.  The articles are going to have 2 sets of links:  one set for www links, another set for local links, indicated as:  [LL]       If you like what you're reading,  drop me a line  letting me know, and I'll keep putting precious time into it.       Why Smalltalk?      Before we can get into OO stuff, I feel the need to set the context of the articles.  Unfortunately, this will take up the bulk of this first article, but it's an important thing to do.  We'll finish with a little bit of OO stuff at the end, and get into it more in the next article.      I believe Smalltalk is  the best  environment to learn OO programming in because:     Smalltalk has a very active and very helpful community; when you post a question to the Smalltalk newsgroups you very often get an answer, unlike many other newsgroups     is very easy to learn... one of it's original design intententions was to be a learning environment for children     is a pure OO environment and encourages OO programming (as opposed to encouraging procedural/Object mixed programming)     cutting your teeth in Smalltalk makes you a better OO programmer in any other language, because of the previous bullet     is a portable environment:  write once, run anywhere, so people can learn on whatever OS they're running  (as opposed to just the M$ variety)     can look at and manipulate objects in real time; I haven't seen this ability in any other environment     Smalltalk is written in Smalltalk.  You can view how the language is put together to learn the language, and you can change anything that you don't like about it.     has garbage collection, no manual memory management, no explicit pointers     is a literate language; by this I mean the syntax is very simple and is geared towards programmer readability.     there's lots of Cool Things that you can do in it that I haven't seen anywhere else (will have some examples along the way)     ...and best of all:  it's fun .    In particular, I'm going to use  Squeak  as the playing vehicle.  You'll notice this is a different flavour of Smalltalk than I used in my first article.  I've never used Squeak before, so this'll be a learning experience for me too.  The reasons for this are:     It's a completely opensource project     It has some Really Cool features that I haven't seen in other flavours of Smalltalk     It has a comparitively small footprint and it's very easy to install     It has a strong  Swiki site   (a  Wiki  site hosted in Squeak, hence  S queak  Wiki )        Quote of the day  In essence, Smalltalk is a programming language focused on human beings rather than the computer.          -Alan Knight    Installation stuff        Note:  before you fire up Squeak, I need to warn you to not be put off by the sparten GUI.  There's actually two types of GUIs in Squeak:  MVC & Morphic, both of which have skins to implement specific look-n-feels.  For at least the beginning of the series, I plan on sticking to Morphic without skins, as it's the newer GUI and I want to keep things simple.       To install Squeak, you basically need to download and unzip 4 files.  RPMs are available for people who prefer them.  For instructions on downloading and installing Squeak, see these  installation instructions , or these  installation instructions.   (Note: I'm using v2.7 of Squeak, which isn't the latest version, but for the purposes of these articles, the latest-n-greatest version is not required unless otherwise noted)     First Looks       Note:  do not save anything until we get to that point below.  The initial orientation and setup of squeak is a little painful, but by the time we're done here it'll be much more friendly.       Now that you have Squeak installed, let's fire it up.  Go to a command prompt, cd to the directory where squeak is, and type  squeak Squeak-2.7.image .  You'll see a window open, with 10 windows within it.  Feel free to read the  Welcome To...  and  Getting Started...  windows.  If you want to skip this and read them later, that's fine too.  You'll notice that the look-n-feel is ""weird"", don't worry about this.  There are reasons for this that I'll get to in a future article.  You can also play around with the various  Play With Me s (there's some neat things there).  Feel free to mess around to your heart's content, try resizing things, moving them ,etc.  Don't worry about breaking anything as we haven't saved anything yet.  When you click on  Play With Me 3, 6, 7 or 8 , you need to click on the window to get into it.  To get out of it,  left click  on the window background, and select  previous project .      When you're done playing, and you're back in the main view you started out in,  middle click  on the squeak background somewhere, and select  quit , and  no , as we don't want to save any changes.  Now restart squeak, and move the  Welcome To...  window somewhere.  Now  middle click  on the squeak background somwhere, and select  save and quit.   Now, restart sqeuak again... notice that the window is in the place where you left it.  In fact, every time you save in sqeuak  the state of the IDE is saved exactly as it was!   2  All the window placements, all the code - everything is exactly where you left it.  This is great for getting back up to speed quickly on what you were doing.      For the read-along folks, here's what the  Welcome To...  & two of the  Play With Me  windows look like:            Now, let's do a little customization before we move on to examples.  Open a workspace ( middle click  on the squeak background, select  open...>workspace. )  You'll notice that it's the same type of window as the  Welcome To...  and  Getting Started...  windows.  Enter in the following code snippits:      Preferences setPreference: #noviceMode toValue: true.       Preferences setPreference: #inboardScrollbars toValue: true.       Preferences setPreference: #useGlobalFlaps toValue: true.        Then highlight both lines and execute the code ( middle click>do it ).  This is known as 'doing it' in Smalltalk.  Congratulations, you just ran your first Smalltalk code.  Don't worry about the symantics right now, just be aware that we set some preferences.  Now, remember when I mentioned that we'd be using the morphic GUI type for these articles?  To do this,  middle click  on the squeak background, select  open...> morphic project .  You'll see a small window appear called  Unnamed1 .  Let's name this project something, as you've already probably experienced, clicking on the title of the window will bring up a rename prompt.  Type in  Making Smalltalk.  If you want, you can resize the window to see the whole title.      Now, let's enter the project, do this by clicking on the project to give it focus, then clicking on it again.  You'll notice there are four tabs  arranged around the screen ( Menus, Squeak, Tools, and Supplies ).  If you mouse over the tab, a pop up menu will appear with neat stuff on it.  If you mouse over the  Menu  tab you'll see the  open...  menu in the top left corner, select  workspace  to open up a workspace.  You'll notice the look-n-feel is a little different now, as we're using the Morphic type of GUI; this project will be the basis of these articles.    One thing you'll notice from the menus, is that there's no saving option.  Since we want to save everything we've done, let's get that menu.  To do this,  right click  on the project background, you should see a series of different coloured dots around the screen.  We're not going to get into their purpose just yet.  Now  left click  on the  red dot  in the top left hand corner of the screen, you'll see a playfield menu, select  keep this menu up .  Now the menu is sticky, and you can move it around.  Let's move it out of the way of the flaps to the bottow left hand corner of the screen.  Finally,  let's save what we've done, on that menu you just made sticky, click on  save .  Your window should look something like:         Getting to objects      As I mentioned, the bulk of this article is going to be setting the stage for future articles.  Now we can finally start addressing the topic at hand.  There are many different definitions of what an object is.  One way of thinking about it is that an  object  is anything you can think of that is a noun.  A window, a menu, an array, a GUI, a string, an integer, a person, a tree, etc.  This is a very simple view of what an object is, and we'll refine the definition over time.      In Smalltalk,  everything is an object 3 .   Unlike other languages where small building blocks like integers or strings aren't objects, everything is an object.  If you have procedural programming experience, this is a good mantra to repeat for about 6 months.      Let's start with the venerable Hello World example, but with a minor update (sheesh, we're not back in the '60s here).  Instead of printing a string to the stdout (to the command line), let's open a window with the string in it.  In the workspace enter and 'do':      (Workspace new contents: 'Hello World') openLabel: 'Hello World Workspace'       You'll see:        Remember when I said everything is an object?  Well, we asked a new Workspace object to make its contents  Hello World,  then asked it to open itself with the label  'Hello World Workspace'.   Notice there's no 'main' method, no compiling and linking step, no switching between a text editor and a compiler.  The simplicity of being able to just type Smalltalk code and run it is very refreshing.       ...but this old example is pretty worn out.  Let's do something a little more up to date 4 .  Let's make a line; in the workspace enter and do:      World addMorph:           (PolygonMorph            vertices: {50@50. 200@200}            color: Color red            borderWidth: 20            borderColor: Color red)       You'll see:        Here, we asked the project (World) we're in (projects are objects too) to add a morph that is a red line from point 50x50 to point 200x200.  Now, let's play with this object a little bit, if you right click on the line object, you'll get the various multi-coloured points again (these are called halos).  If you mouse over the line object, you'll see pop-up help describing what the halos do ( Rote, Change size, debug, Duplicate, Move, etc) .   Left click  on the yellow halo, and resize the line a few times.  Try the  rotate, duplicate, move  buttons to play some more.  Finally  left click  on the 'X'  button  when you want to get rid of the line object(s).      To make this first article digestible, I'm going to stop off here.  Before I go though, I'm going to introduce the 'Sweet Squeak' section...    A Sweet Squeak  This section won't explore/explain code or example, but merely present a neat thing to try out 5 .  This time, lets view a shockwave file.  If you have an internet connection up, try entering this code and do it:   (note, might take a while over 28.8; I did this at a friend's place with a 128K ISDN and it was pretty snappy)      (FlashMorphReader on: (HTTPSocket           httpGet: 'http://www.audi.co.uk/flash/intro1.swf'           accept:'application/x-shockwave-flash'))       processFile startPlaying openInWorld.        Looking forward  The next article will discuss Objects again as well as classes, messages and encapsulation.  Also, if any Squeakers out there know of something neat that can be easily done, let me know and I'll add it if the"
GX054-43-4629318	"Secure Programming for Linux and Unix HOWTO Prev Chapter 7. Structure Program Internals and Approach Next 7.4. Minimize Privileges As noted earlier, it is an important general principle that programs have the minimal amount of privileges necessary to do its job (this is termed ``least privilege''). That way, if the program is broken, its damage is limited. The most extreme example is to simply not write a secure program at all - if this can be done, it usually should be. For example, don't make your program setuid or setgid if you can; just make it an ordinary program, and require the administrator to log in as such before running it. In Linux and Unix, the primary determiner of a process' privileges is the set of id's associated with it: each process has a real, effective and saved id for both the user and group (a few very old Unixes don't have a ``saved'' id). Linux also has, as a special extension, a separate filesystem UID and GID for each process. Manipulating these values is critical to keeping privileges minimized, and there are several ways to minimize them (discussed below). You can also use chroot(2) to minimize the files visible to a program, though using chroot() can be difficult to use correctly. There are a few other values determining privilege in Linux and Unix, for example, POSIX capabilities (supported by Linux 2.2 and greater, and by some other Unix-like systems). 7.4.1. Minimize the Privileges Granted Perhaps the most effective technique is to simply minimize the highest privilege granted. In particular, avoid granting a program root privilege if possible. Don't make a program  setuid root  if it only needs access to a small set of files; consider creating separate user or group accounts for different function. A common technique is to create a special group, change a file's group ownership to that group, and then make the program  setgid  to that group. It's better to make a program  setgid  instead of  setuid  where you can, since group membership grants fewer rights (in particular, it does not grant the right to change file permissions). This is commonly done for game high scores. Games are usually setgid  games , the score files are owned by the group  games , and the programs themselves and their configuration files are owned by someone else (say root). Thus, breaking into a game allows the perpetrator to change high scores but doesn't grant the privilege to change the game's executable or configuration file. The latter is important; if an attacker could change a game's executable or its configuration files (which might control what the executable runs), then they might be able to gain control of a user who ran the game. If creating a new group isn't sufficient, consider creating a new pseudouser (really, a special role) to manage a set of resources - often a new pseudogroup (again, a special role) is also created just to run a program. Web servers typically do this; often web servers are set up with a special user (``nobody'') so that they can be isolated from other users. Indeed, web servers are instructive here: web servers typically need root privileges to start up (so they can attach to port 80), but once started they usually shed all their privileges and run as the user ``nobody''. However, don't use the ``nobody'' account (unless you're writing a webserver); instead, create your own pseudouser or new group. The purpose of this approach is to isolate different programs, processes, and data from each other, by exploiting the operating system's ability to keep users and groups separate. If different programs shared the same account, then breaking into one program would also grant privileges to the other. Usually the pseudouser should not own the programs it runs; that way, an attack who breaks into the account cannot change the program it runs. By isolating different parts of the system into running separate users and groups, breaking one part will not necessarily break the whole system's security. If you're using a database system (say, by calling its query interface), limit the rights of the database user that the application uses. For example, don't give that user access to all of the system stored procedures if that user only needs access to a handful of user-defined ones. Do everything you can inside stored procedures. That way, even if someone does manage to force arbitrary strings into the query, the damage that can be done is limited. If you must directly pass a regular SQL query with client supplied data (and you usually shouldn't), wrap it in something that limits its activities (e.g., sp_sqlexec). (My thanks to SPI Labs for these database system suggestions). If you  must  give a program privileges usually reserved for root, consider using POSIX capabilities as soon as your program can minimize the privileges available to your program. POSIX capabilities are available in Linux 2.2 and in many other Unix-like systems. By calling cap_set_proc(3) or the Linux-specific capsetp(3)  routines immediately after starting, you can permanently reduce the abilities of your program to just those abilities it actually needs. For example the network time daemon (ntpd) traditionally has run as root, because it needs to modify the current time. However, patches have been developed so ntpd only needs a single capability, CAP_SYS_TIME, so even if an attacker gains control over ntpd it's somewhat more difficult to exploit the program. I say ``somewhat limited'' because, unless other steps are taken, retaining a privilege using POSIX capabilities requires that the process continue to have the root user id. Because many important files (configuration files, binaries, and so on) are owned by root, an attacker controlling a program with such limited capabilities can still modify key system files and gain full root-level privilege. A Linux kernel extension (available in versions 2.4.X and 2.2.19+) provides a better way to limit the available privileges: a program can start as root (with all POSIX capabilities), prune its capabilities down to just what it needs, call prctl(PR_SET_KEEPCAPS,1), and then use setuid() to change to a non-root process. The PR_SET_KEEPCAPS setting marks a process so that when a process does a setuid to a nonzero value, the capabilities aren't cleared (normally they are cleared). This process setting is cleared on exec(). However, note that PR_SET_KEEPCAPS is a Linux-unique extension for newer versions of the linux kernel. One Linux-unique tool you can use to simplify minimizing granted privileges is the ``compartment'' tool developed by SuSE. This tool sets the filesystem root, uid, gid, and/or the capability set, then runs the given program. This is particularly handy for running some other program without modifying it. Here's the syntax of version 0.5:   Syntax: compartment [options] /full/path/to/program  Options:   --chroot path   chroot to path   --user user     change UID to this user   --group group   change GID to this group   --init program  execute this program before doing anything   --cap capset    set capset name. You can specify several   --verbose       be verbose   --quiet         do no logging (to syslog)  Thus, you could start a more secure anonymous ftp server using:     compartment --chroot /home/ftp --cap CAP_NET_BIND_SERVICE anon-ftpd  At the time of this writing, the tool is immature and not available on typical Linux distributions, but this may quickly change. You can download the program via  http://www.suse.de/~marc . Note that  not  all Unix-like systems, implement POSIX capabilities, and PR_SET_KEEPCAPS is currently a Linux-only extension. Thus, these approaches limit portability. However, if you use it merely as an optional safeguard only where it's available, using this approach will not really limit portability. Also, while the Linux kernel version 2.2 and greater includes the low-level calls, the C-level libraries to make their use easy are not installed on some Linux distributions, slightly complicating their use in applications. For more information on Linux's implementation of POSIX capabilities, see  http://linux.kernel.org/pub/linux/libs/security/linux-privs . FreeBSD has the jail() function for limiting privileges; see the  jail documentation  for more information. There are a number of specialized tools and extensions for limiting privileges; see  Section 3.10 . 7.4.2. Minimize the Time the Privilege Can Be Used As soon as possible, permanently give up privileges. Some Unix-like systems, including Linux, implement ``saved'' IDs which store the ``previous'' value. The simplest approach is to reset any supplemental groups if appropriate (e.g., using setgroups(2)), and then set the other id's twice to an untrusted id. In setuid/setgid programs, you should usually set the effective gid and uid to the real ones, in particular right after a fork(2), unless there's a good reason not to. Note that you have to change the gid first when dropping from root to another privilege or it won't work - once you drop root privileges, you won't be able to change much else. Note that in some systems, just setting the group isn't enough, if the process belongs to supplemental groups with privileges. For example, the ``rsync'' program didn't remove the supplementary groups when it changed its uid and gid, which created a potential exploit. It's worth noting that there's a well-known related bug that uses POSIX capabilities to interfere with this minimization. This bug affects Linux kernel 2.2.0 through 2.2.15, and possibly a number of other Unix-like systems with POSIX capabilities. See Bugtraq id 1322 on http://www.securityfocus.com for more information. Here is their summary:  POSIX ""Capabilities"" have recently been implemented in the Linux kernel. These ""Capabilities"" are an additional form of privilege control to enable more specific control over what privileged processes can do. Capabilities are implemented as three (fairly large) bitfields, which each bit representing a specific action a privileged process can perform. By setting specific bits, the actions of privileged processes can be controlled -- access can be granted for various functions only to the specific parts of a program that require them. It is a security measure. The problem is that capabilities are copied with fork() execs, meaning that if capabilities are modified by a parent process, they can be carried over. The way that this can be exploited is by setting all of the capabilities to zero (meaning, all of the bits are off) in each of the three bitfields and then executing a setuid program that attempts to drop privileges before executing code that could be dangerous if run as root, such as what sendmail does. When sendmail attempts to drop privileges using setuid(getuid()), it fails not having the capabilities required to do so in its bitfields and with no checks on its return value . It continues executing with superuser privileges, and can run a users .forward file as root leading to a complete compromise.  One approach, used by sendmail, is to attempt to do setuid(0) after a setuid(getuid()); normally this should fail. If it succeeds, the program should stop. For more information, see http://sendmail.net/?feed=000607linuxbug. In the short term this might be a good idea in other programs, though clearly the better long-term approach is to upgrade the underlying system. 7.4.3. Minimize the Time the Privilege is Active Use setuid(2), seteuid(2), setgroups(2), and related functions to ensure that the program only has these privileges active when necessary, and then temporarily deactivate the privilege when it's not in use. As noted above, you might want to ensure that these privileges are disabled while parsing user input, but more generally, only turn on privileges when they're actually needed. Note that some buffer overflow attacks, if successful, can force a program to run arbitrary code, and that code could re-enable privileges that were temporarily dropped. Thus, there are  many  attacks that temporarily deactivating a privilege won't counter - it's always much better to completely drop privileges as soon as possible. There are many papers that describe how to do this, such as  ""Designing Shellcode Demystified"" . Some people even claim that ``seteuid() [is] considered harmful'' because of the many attacks it doesn't counter. Still, temporarily deactivating these permissions prevents a whole class of attacks, such as techniques to convince a program to write into a file that perhaps it didn't intend to write into. Since this technique prevents many attacks, it's worth doing if permanently dropping the privilege can't be done at that point in the program. 7.4.4. Minimize the Modules Granted the Privilege If only a few modules are granted the privilege, then it's much easier to determine if they're secure. One way to do so is to have a single module use the privilege and then drop it, so that other modules called later cannot misuse the privilege. Another approach is to have separate commands in separate executables; one command might be a complex tool that can do a vast number of tasks for a privileged user (e.g., root), while the other tool is setuid but is a small, simple tool that only permits a small command subset. The small, simple tool checks to see if the input meets various criteria for acceptability, and then if it determines the input is acceptable, it passes the data on to the complex tool. Note that the small, simple tool must do a thorough job checking its inputs and limiting what it will pass along to the complex tool, or this can be a vulnerability. These approaches can even be layered several ways, for example, a complex user tool could call a simple setuid ``wrapping'' program (that checks its inputs for secure values) that then passes on information to another complex trusted tool. This approach is especially helpful for GUI-based systems; have the GUI portion run as a normal user, and then pass security-relevant requests on to another program that has the special privileges for actual execution. Some applications can be best developed by dividing the problem into smaller, mutually untrusting programs. A simple way is divide up the problem into separate programs that do one thing (securely), using the filesystem and locking to prevent problems between them. If more complex interactions are needed, one approach is to fork into multiple processes, each of which has different privilege. Communications channels can be set up in a variety of ways; one way is to have a ""master"" process create communication channels (say unnamed pipes or unnamed sockets), then fork into different processes and have each process drop as many privileges as possible. If you're doing this, be sure to watch for deadlocks. Then use a simple protocol to allow the less trusted processes to request actions from the more trusted process(es), and ensure that the more trusted processes only support a limited set of requests. Setting user and group permissions so that no one else can even start up the sub-programs makes it harder to break into. Some operating systems have the concept of multiple layers of trust in a single process, e.g., Multics' rings. Standard Unix and Linux don't have a way of separating multiple levels of trust by function inside a single process like this; a call to the kernel increases privileges, but otherwise a given process has a single level of trust. This is one area where technologies like Java 2, C# (which copies Java's approach), and Fluke (the basis of security-enhanced Linux) have an advantage. For example, Java 2 can specify fine-grained permissions such as the permission to only open a specific file. However, general-purpose operating systems do not typically have such abilities at this time; this may change in the near future. For more about Java, see  Section 10.6 . 7.4.5. Consider Using FSUID To Limit Privileges Each Linux process has two Linux-unique state values called filesystem user id (FSUID) and filesystem group id (FSGID). These values are used when checking against the filesystem permissions. If you're building a program that operates as a file server for arbitrary users (like an NFS server), you might consider using these Linux extensions. To use them, while holding root privileges change just FSUID and FSGID before accessing files on behalf of a normal user. This extension is fairly useful, and provides a mechanism for limiting filesystem access rights without removing other (possibly necessary) rights. By only setting the FSUID (and not the EUID), a local user cannot send a signal to the process. Also, avoiding race conditions is much easier in this situation. However, a disadvantage of this approach is that these calls are not portable to other Unix-like systems. 7.4.6. Consider Using Chroot to Minimize Available Files You can use chroot(2) to limit the files visible to your program. This requires carefully setting up a directory (called the ``chroot jail'') and correctly entering it. This can be a fairly effective technique for improving a program's security - it's hard to interfere with files you can't see. However, it depends on a whole bunch of assumptions, in particular, the program must lack root privileges, it must not have any way to get root privileges, and the chroot jail must be properly set up (e.g., be careful what you put inside the chroot jail, and make sure that users can never control its contents before calling chroot). I recommend using chroot(2) where it makes sense to do so, but don't depend on it alone; instead, make it part of a layered set of defenses. Here are a few notes about the use of chroot(2):   The program can still use non-filesystem objects that are shared across the entire machine (such as System V IPC objects and network sockets). It's best to also use separate pseudo-users and/or groups, because all Unix-like systems include the ability to isolate users; this will at least limit the damage a subverted program can do to other programs. Note that current most Unix-like systems (including Linux) won't isolate intentionally cooperating programs; if you're worried about malicious programs cooperating, you need to get a system that implements some sort of mandatory access control and/or limits covert channels. Be sure to close any filesystem descriptors to outside files if you don't want them used later. In particular, don't have any descriptors open to directories outside the chroot jail, or set up a situation where such a descriptor could be given to it (e.g., via Unix sockets or an old implementation of /proc). If the program is given a descriptor to a directory outside the chroot jail, it could be used to escape out of the chroot jail. The chroot jail has to be set up to be secure - it must never be controlled by a user and every file added must be carefully examined. Don't use a normal user's home directory, subdirectory, or other directory that can ever be controlled by a user as a chroot jail; use a separate directory directory specially set aside for the purpose. Using a directory controlled by a user is a disaster - for example, the user could create a ``lib'' directory containing a trojaned linker or libc (and could link a setuid root binary into that space, if the files you save don't use it). Place the absolute minimum number of files and directories there. Typically you'll have a /bin, /etc/, /lib, and maybe one or two others (e.g., /pub if it's an ftp server). Place in /bin only what you need to run after doing the chroot(); sometimes you need nothing at all (try to avoid placing a shell like /bin/sh there, though sometimes that can't be helped). You may need a /etc/passwd and /etc/group so file listings can show some correct names, but if so, try not to include the real system's values, and certainly replace all passwords with ""*"". In /lib, place only what you need; use ldd(1) to query each program in /bin to find out what it needs, and only include them. On Linux, you'll probably need a few basic libraries like ld-linux.so.2, and not much else. Alternatively, recompile any necessary programs to be statically linked, so that they don't need dynamically loaded libraries at all. It's usually wiser to completely copy in all files, instead of making hard links; while this wastes some time and disk space, it makes it so that attacks on the chroot jail files do not automatically propagate into the regular system's files. Mounting a /proc filesystem, on systems where this is supported, is generally unwise. In fact, in very old versions of Linux (versions 2.0.x, at least up through 2.0.38) it's a known security flaw, since there are pseudo-directories in /proc that would permit a chroot'ed program to escape. Linux kernel 2.2 fixed this known problem, but there may be others; if possible, don't do it. Chroot really isn't effective if  the program can acquire root privilege. For example, the program could use calls like mknod(2) to create a device file that can view physical memory, and then use the resulting device file to modify kernel memory to give itself whatever privileges it desired. Another example of how a root program can break out of chroot is demonstrated at  http://www.suid.edu/source/breakchroot.c . In this example, the program opens a file descriptor for the current directory, creates and chroots into a subdirectory, sets the current directory to the previously-opened current directory, repeatedly cd's up from the current directory (which since it is outside the current chroot succeeds in moving up to the real filesystem root), and then calls chroot on the result. By the time you read this, these weaknesses may have been plugged, but the reality is that root privilege has traditionally meant ``all privileges'' and it's hard to strip them away. It's better to assume that a program requiring continuous root privileges will only be mildly helped using chroot(). Of course, you may be able to break your program into parts, so that at least part of it can be in a chroot jail.  7.4.7. Consider Minimizing the Accessible Data Consider minimizing the amount of data that can be accessed by the user. For example, in CGI scripts, place all data used by the CGI script outside of the document tree unless there is a reason the user needs to see the data directly. Some people have the false notion that, by not publicly providing a link, no one can access the data, but this is simply not true. 7.4.8. Consider Minimizing the Resources Available Consider minimizing the computer resources available to a given process so that, even if it ``goes haywire,'' its damage can be limited. This is a fundamental technique for preventing a denial of service. For network servers, a common approach is to set up a separate process for each session, and for each process limit the amount of CPU time (et cetera) that session can use. That way, if an attacker makes a request that chews up memory or uses 100% of the CPU, the limits will kick in and prevent that single session from interfering with other tasks. Of course, an attacker can establish many sessions, but this at least raises the bar for an attack. See  Section 3.6  for more information on how to set these limits (e.g., ulimit(1)). Prev Home Next Separate Data and Control Up Minimize the Functionality of a Component"
GX090-57-10805011	"Secure Programming for Linux and Unix HOWTO Prev Chapter 6. Structure Program Internals and Approach Next 6.3. Minimize Privileges As noted earlier, it is an important general principle that programs have the minimal amount of privileges necessary to do its job (this is termed ``least privilege''). That way, if the program is broken, its damage is limited. The most extreme example is to simply not write a secure program at all - if this can be done, it usually should be. For example, don't make your program setuid or setgid if you can; just make it an ordinary program, and require the administrator to log in as such before running it. In Linux and Unix, the primary determiner of a process' privileges is the set of id's associated with it: each process has a real, effective and saved id for both the user and group (a few very old Unixes don't have a ``saved'' id). Linux also has, as a special extension, a separate filesystem uid and gid for each process. Manipulating these values is critical to keeping privileges minimized, and there are several ways to minimize them (discussed below). You can also use chroot(2) to minimize the files visible to a program. 6.3.1. Minimize the Privileges Granted Perhaps the most effective technique is to simply minimize the the highest privilege granted. In particular, avoid granting a program root privilege if possible. Don't make a program  setuid root  if it only needs access to a small set of files; consider creating separate user or group accounts for different function. A common technique is to create a special group, change a file's group ownership to that group, and then make the program  setgid  to that group. It's better to make a program  setgid  instead of  setuid  where you can, since group membership grants fewer rights (in particular, it does not grant the right to change file permissions). This is commonly done for game high scores. Games are usually setgid  games , the score files are owned by the group  games , and the programs themselves and their configuration files are owned by someone else (say root). Thus, breaking into a game allows the perpetrator to change high scores but doesn't grant the privilege to change the game's executable or configuration file. The latter is important; if an attacker could change a game's executable or its configuration files (which might control what the executable runs), then they might be able to gain control of a user who ran the game. If creating a new group isn't sufficient, consider creating a new pseudouser (really, a special role) to manage a set of resources. Web servers typically do this; often web servers are set up with a special user (``nobody'') so that they can be isolated from other users. Indeed, web servers are instructive here: web servers typically need root privileges to start up (so they can attach to port 80), but once started they usually shed all their privileges and run as the user ``nobody''. Again, usually the pseudouser doesn't own the primary program it runs, so breaking into the account doesn't allow for changing the program itself. As a result, breaking into a running web server normally does not automatically break the whole system's security. If you  must  give a program root privileges, consider using the POSIX capability features available in Linux 2.2 and greater to minimize them immediately on program startup. By calling cap_set_proc(3) or the Linux-specific capsetp(3)  routines immediately after starting, you can permanently reduce the abilities of your program to just those abilities it actually needs. Note that  not  all Unix-like systems implement POSIX capabilities, so this is an approach that can lose portability; however, if you use it merely as an optional safeguard only where it's available, using this approach will not really limit portability. Also, while the Linux kernel version 2.2 and greater includes the low-level calls, the C-level libraries to make their use easy are not installed on some Linux distributions, slightly complicating their use in applications. For more information on Linux's implementation of POSIX capabilities, see  http://linux.kernel.org/pub/linux/libs/security/linux-privs . One Linux-unique tool you can use to simplify minimizing granted privileges is the ``compartment'' tool developed by SuSE. This tool sets the fileystem root, uid, gid, and/or the capability set, then runs the given program. This is particularly handy for running some other program without modifying it. Here's the syntax of version 0.5:   Syntax: compartment [options] /full/path/to/program  Options:   --chroot path   chroot to path   --user user     change uid to this user   --group group   change gid to this group   --init program  execute this program before doing anything   --cap capset    set capset name. You can specify several   --verbose       be verbose   --quiet         do no logging (to syslog)  Thus, you could start a more secure anonymous ftp server using:     compartment --chroot /home/ftp --cap CAP_NET_BIND_SERVICE anon-ftpd  At the time of this writing, the tool is immature and not available on typical Linux distributions, but this may quickly change. You can download the program via  http://www.suse.de/~marc . FreeBSD has the jail() function for limiting privileges; see the  jail documentation  for more information. There are a number of specialized tools and extensions for limiting privileges; see  Section 3.10 . 6.3.2. Minimize the Time the Privilege Can Be Used As soon as possible, permanently give up privileges. Some Unix-like systems, including Linux, implement ``saved'' IDs which store the ``previous'' value. The simplest approach is to set the other id's twice to an untrusted id. In setuid/setgid programs, you should usually set the effective gid and uid to the real ones, in particular right after a fork(2), unless there's a good reason not to. Note that you have to change the gid first when dropping from root to another privilege or it won't work - once you drop root privileges, you won't be able to change much else. It's worth noting that there's a well-known related bug that uses POSIX capabilities to interfere with this minimization. This bug affects Linux kernel 2.2.0 through 2.2.15, and possibly a number of other Unix-like systems with POSIX capabilities. See Bugtraq id 1322 on http://www.securityfocus.com for more information. Here is their summary:  POSIX ""Capabilities"" have recently been implemented in the Linux kernel. These ""Capabilities"" are an additional form of privilege control to enable more specific control over what priviliged processes can do. Capabilities are implemented as three (fairly large) bitfields, which each bit representing a specific action a privileged process can perform. By setting specific bits, the actions of priviliged processes can be controlled -- access can be granted for various functions only to the specific parts of a program that require them. It is a security measure. The problem is that capabilities are copied with fork() execs, meaning that if capabilities are modified by a parent process, they can be carried over. The way that this can be exploited is by setting all of the capabilities to zero (meaning, all of the bits are off) in each of the three bitfields and then executing a setuid program that attempts to drop priviliges before executing code that could be dangerous if run as root, such as what sendmail does. When sendmail attempts to drop priviliges using setuid(getuid()), it fails not having the capabilities required to do so in its bitfields and with no checks on its return value . It continues executing with superuser priviliges, and can run a users .forward file as root leading to a complete compromise.  One approach, used by sendmail, is to attempt to do setuid(0) after a setuid(getuid()); normally this should fail. If it succeeds, the program should stop. For more information, see http://sendmail.net/?feed=000607linuxbug. In the short term this might be a good idea in other programs, though clearly the better long-term approach is to upgrade the underlying system. 6.3.3. Minimize the Time the Privilege is Active Use setuid(2), seteuid(2), and related functions to ensure that the program only has these privileges active when necessary. As noted above, you might want ensure that these privileges are disabled while parsing user input, but more generally, only turn on privileges when they're actually needed. Note that some buffer overflow attacks, if successful, can force a program to run arbitrary code, and that code could re-enable privileges that were temporarily dropped. Thus, it's always better to completely drop privileges as soon as possible. Still, temporarily disabling these permissions prevents a whole class of attacks, such as techniques to convince a program to write into a file that perhaps it didn't intend to write into. Since this technique prevents many attacks, it's worth doing if completely dropping the privileges can't be done at that point in the program. 6.3.4. Minimize the Modules Granted the Privilege If only a few modules are granted the privilege, then it's much easier to determine if they're secure. One way to do so is to have a single module use the privilege and then drop it, so that other modules called later cannot misuse the privilege. Another approach is to have separate commands in separate executables; one command might be a complex tool that can do a vast number of tasks for a privileged user (e.g., root), while the other tool is setuid but is a small, simple tool that only permits a small command subset. The small, simple tool checks to see if the input meets various criteria for acceptability, and then if it determines the input is acceptable, it passes the data on to the complex tool. Note that the small, simple tool must do a thorough job checking its inputs and limiting what it will pass along to the complex tool, or this can be a vulnerability. These approaches can even be layered several ways, for example, a complex user tool could call a simple setuid ``wrapping'' program (that checks its inputs for secure values) that then passes on information to another complex trusted tool. This approach is especially helpful for GUI-based systems; have the GUI portion run as a normal user, and then pass security-relevant requests on to another program that has the special privileges for actual execution. Some operating systems have the concept of multiple layers of trust in a single process, e.g., Multics' rings. Standard Unix and Linux don't have a way of separating multiple levels of trust by function inside a single process like this; a call to the kernel increases privileges, but otherwise a given process has a single level of trust. Linux and other Unix-like systems can sometimes simulate this ability by forking a process into multiple processes, each of which has different privilege. To do this, set up a secure communication channel (usually unnamed pipes or unnamed sockets are used), then fork into different processes and have each process drop as many privileges as possible. Then use a simple protocol to allow the less trusted processes to request actions from the more trusted process(es), and ensure that the more trusted processes only support a limited set of requests. This is one area where technologies like Java 2 and Fluke have an advantage. For example, Java 2 can specify fine-grained permissions such as the permission to only open a specific file. However, general-purpose operating systems do not typically have such abilities at this time; this may change in the near future. For more about Java, see  Section 9.6 . 6.3.5. Consider Using FSUID To Limit Privileges Each Linux process has two Linux-unique state values called filesystem user id (fsuid) and filesystem group id (fsgid). These values are used when checking against the filesystem permissions. If you're building a program that operates as a file server for arbitrary users (like an NFS server), you might consider using these Linux extensions. To use them, while holding root privileges change just fsuid and fsgid before accessing files on behalf of a normal user. This extension is fairly useful, and provides a mechanism for limiting filesystem access rights without removing other (possibly necessary) rights. By only setting the fsuid (and not the euid), a local user cannot send a signal to the process. Also, avoiding race conditions is much easier in this situation. However, a disadvantage of this approach is that these calls are not portable to other Unix-like systems. 6.3.6. Consider Using Chroot to Minimize Available Files You can use chroot(2) to limit the files visible to your program. This requires carefully setting up a directory (called the ``chroot jail'') and correctly entering it. This can be a fairly effective technique for improving a program's security - it's hard to interfere with files you can't see. However, it depends on a whole bunch of assumptions, in particular, the program must lack root privileges, it must not have any way to get root privileges, and the chroot jail must be properly set up. I recommend using chroot(2) where it makes sense to do so, but don't depend on it alone; instead, make it part of a layered set of defenses. Here are a few notes about the use of chroot(2):   The program can still use non-filesystem objects that are shared across the entire machine (such as System V IPC objects and network sockets). It's best to also use separate pseudousers and/or groups, because all Unix-like systems include the ability to isolate users; this will at least limit the damage a subverted program can do to other programs. Note that current most Unix-like systems (including Linux) won't isolate intentionally cooperating programs; if you're worried about malicious programs cooperating, you need to get a system that implements some sort of mandatory access control and/or limits covert channels. Be sure to close any filesystem descriptors to outside files if you don't want them used later. In particular, don't have any descriptors open to directories outside the chroot jail, or set up a situation where such a descriptor could be given to it (e.g., via Unix sockets or an old implementation of /proc). If the program is given a descriptor to a directory outside the chroot jail, it could be used to escape out of the chroot jail. The chroot jail has to be set up to be secure. Don't use a normal user's home directory (or subdirectory) as a chroot jail; use a separate location or ``home'' directory specially set aside for the purpose. Place the absolute minimum number of files there. Typically you'll have a /bin, /etc/, /lib, and maybe one or two others (e.g., /pub if it's an ftp server). Place in /bin only what you need to run after doing the chroot(); sometimes you need nothing at all (try to avoid placing a shell there, though sometimes that can't be helped). You may need a /etc/passwd and /etc/group so file listings can show some correct names, but if so, try not to include the real system's values, and certainly replace all passwords with ""*"". In /lib, place only what you need; use ldd(1) to query each program in /bin to find out what it needs, and only include them. On Linux, you'll probably need a few basic libraries like ld-linux.so.2, and not much else. Alternatively, recompile any necessary programs to be statically linked, so that they don't need dynamically loaded libraries at all. It's usually wiser to completely copy in all files, instead of making hard links; while this wastes some time and disk space, it makes it so that attacks on the chroot jail files do not automatically propogate into the regular system's files. Mounting a /proc filesystem, on systems where this is supported, is generally unwise. In fact, in very old versions of Linux (versions 2.0.x, at least up through 2.0.38) it's a known security flaw, since there are pseudodirectories in /proc that would permit a chroot'ed program to escape. Linux kernel 2.2 fixed this known problem, but there may be others; if possible, don't do it. Chroot really isn't effective if  the program can acquire root privilege. For example, the program could use calls like mknod(2) to create a device file that can view physical memory, and then use the resulting device file to modify kernel memory to give itself whatever privileges it desired. Another example of how a root program can break out of chroot is demonstrated at  http://www.suid.edu/source/breakchroot.c . In this example, the program opens a file descriptor for the current directory, creates and chroots into a subdirectory, sets the current directory to the previously-opened current directory, repeatedly cd's up from the current directory (which since it is outside the current chroot succeeds in moving up to the real filesystem root), and then calls chroot on the result. By the time you read this, these weaknesses may have been plugged, but the reality is that root privilege has traditionally meant ``all privileges'' and it's hard to strip them away. It's better to assume that a program requiring continuous root privileges will only be mildly helped using chroot(). Of course, you may be able to break your program into parts, so that at least part of it can be in a chroot jail.  6.3.7. Consider Minimizing the Accessible Data Consider minimizing the amount of data that can be accessed by the user. For example, in CGI scripts, place all data used by the CGI script outside of the document tree unless there is a reason the user needs to see the data directly. Some people have the false notion that, by not publically providing a link, no one can access the data, but this is simply not true. 6.3.8. Consider Minimizing the Resources Available Consider minimizing the computer resources available to a given process so that, even if it ``goes haywire,'' its damage can be limited. This is a fundamental technique for preventing a denial of service. For network servers, a common approach is to set up a separate process for each session, and for each process limit the amount of CPU time (et cetera) that session can use. That way, if an attacker makes a request that chews up memory or uses 100% of the CPU, the limits will kick in and prevent that single session from interfering with other tasks. Of course, an attacker can establish many sessions, but this at least raises the bar for an attack. See  Section 3.6  for more information on how to set these limits (e.g., ulimit(1)). Prev Home Next Secure the Interface Up Avoid Creating Setuid/Setgid Scripts"
GX118-32-8188874	"Secure Programming for Linux and Unix HOWTO Prev Chapter 6. Structure Program Internals and Approach Next 6.3. Minimize Privileges As noted earlier, it is an important general principle that programs have the minimal amount of privileges necessary to do its job (this is termed ``least privilege''). That way, if the program is broken, its damage is limited. The most extreme example is to simply not write a secure program at all - if this can be done, it usually should be. For example, don't make your program setuid or setgid if you can; just make it an ordinary program, and require the administrator to log in as such before running it. In Linux and Unix, the primary determiner of a process' privileges is the set of id's associated with it: each process has a real, effective and saved id for both the user and group. Linux also has the filesystem uid and gid. Manipulating these values is critical to keeping privileges minimized, and there are several ways to minimize them (discussed below). You can also use chroot(2) to minimize the files visible to a program. 6.3.1. Minimize the Privileges Granted Perhaps the most effective technique is to simply minimize the the highest privilege granted. In particular, avoid granting a program root privilege if possible. Don't make a program  setuid root  if it only needs access to a small set of files; consider creating separate user or group accounts for different function. A common technique is to create a special group, change a file's group ownership to that group, and then make the program  setgid  to that group. It's better to make a program  setgid  instead of  setuid  where you can, since group membership grants fewer rights (in particular, it does not grant the right to change file permissions). This is commonly done for game high scores. Games are usually setgid  games , the score files are owned by the group  games , and the programs themselves and their configuration files are owned by someone else (say root). Thus, breaking into a game allows the perpetrator to change high scores but doesn't grant the privilege to change the game's executable or configuration file. The latter is important; if an attacker could change a game's executable or its configuration files (which might control what the executable runs), then they might be able to gain control of a user who ran the game. If creating a new group isn't sufficient, consider creating a new pseudouser (really, a special role) to manage a set of resources. Web servers typically do this; often web servers are set up with a special user (``nobody'') so that they can be isolated from other users. Indeed, web servers are instructive here: web servers typically need root privileges to start up (so they can attach to port 80), but once started they usually shed all their privileges and run as the user ``nobody''. Again, usually the pseudouser doesn't own the primary program it runs, so breaking into the account doesn't allow for changing the program itself. As a result, breaking into a running web server normally does not automatically break the whole system's security. If you  must  give a program root privileges, consider using the POSIX capability features available in Linux 2.2 and greater to minimize them immediately on program startup. By calling cap_set_proc(3) or the Linux-specific capsetp(3)  routines immediately after starting, you can permanently reduce the abilities of your program to just those abilities it actually needs. Note that  not  all Unix-like systems implement POSIX capabilities, so this is an approach that can lose portability; however, if you use it merely as an optional safeguard only where it's available, using this approach will not really limit portability. Also, while the Linux kernel version 2.2 and greater includes the low-level calls, the C-level libraries to make their use easy are not installed on some Linux distributions, slightly complicating their use in applications. For more information on Linux's implementation of POSIX capabilities, see  http://linux.kernel.org/pub/linux/libs/security/linux-privs . One Linux-unique tool you can use to simplify minimizing granted privileges is the ``compartment'' tool developed by SuSE. This tool sets the fileystem root, uid, gid, and/or the capability set, then runs the given program. This is particularly handy for running some other program without modifying it. Here's the syntax of version 0.5:   Syntax: compartment [options] /full/path/to/program  Options:   --chroot path   chroot to path   --user user     change uid to this user   --group group   change gid to this group   --init program  execute this program before doing anything   --cap capset    set capset name. You can specify several   --verbose       be verbose   --quiet         do no logging (to syslog)  Thus, you could start a more secure anonymous ftp server using:     compartment --chroot /home/ftp --cap CAP_NET_BIND_SERVICE anon-ftpd  At the time of this writing, the tool is immature and not available on typical Linux distributions, but this may quickly change. You can download the program via  http://www.suse.de/~marc . 6.3.2. Minimize the Time the Privilege Can Be Used As soon as possible, permanently give up privileges. Some Unix-like systems, including Linux, implement ``saved'' IDs which store the ``previous'' value. The simplest approach is to set the other id's twice to an untrusted id. In setuid/setgid programs, you should usually set the effective gid and uid to the real ones, in particular right after a fork(2), unless there's a good reason not to. Note that you have to change the gid first when dropping from root to another privilege or it won't work - once you drop root privileges, you won't be able to change much else. It's worth noting that there's a well-known related bug that uses POSIX capabilities to interfere with this minimization. This bug affects Linux kernel 2.2.0 through 2.2.15, and possibly a number of other Unix-like systems with POSIX capabilities. See Bugtraq id 1322 on http://www.securityfocus.com for more information. Here is their summary:  POSIX ""Capabilities"" have recently been implemented in the Linux kernel. These ""Capabilities"" are an additional form of privilege control to enable more specific control over what priviliged processes can do. Capabilities are implemented as three (fairly large) bitfields, which each bit representing a specific action a privileged process can perform. By setting specific bits, the actions of priviliged processes can be controlled -- access can be granted for various functions only to the specific parts of a program that require them. It is a security measure. The problem is that capabilities are copied with fork() execs, meaning that if capabilities are modified by a parent process, they can be carried over. The way that this can be exploited is by setting all of the capabilities to zero (meaning, all of the bits are off) in each of the three bitfields and then executing a setuid program that attempts to drop priviliges before executing code that could be dangerous if run as root, such as what sendmail does. When sendmail attempts to drop priviliges using setuid(getuid()), it fails not having the capabilities required to do so in its bitfields and with no checks on its return value . It continues executing with superuser priviliges, and can run a users .forward file as root leading to a complete compromise.  One approach, used by sendmail, is to attempt to do setuid(0) after a setuid(getuid()); normally this should fail. If it succeeds, the program should stop. For more information, see http://sendmail.net/?feed=000607linuxbug. In the short term this might be a good idea in other programs, though clearly the better long-term approach is to upgrade the underlying system. 6.3.3. Minimize the Time the Privilege is Active Use setuid(2), seteuid(2), and related functions to ensure that the program only has these privileges active when necessary. As noted above, you might want ensure that these privileges are disabled while parsing user input, but more generally, only turn on privileges when they're actually needed. Note that some buffer overflow attacks, if successful, can force a program to run arbitrary code, and that code could re-enable privileges that were temporarily dropped. Thus, it's always better to completely drop privileges as soon as possible. Still, temporarily disabling these permissions prevents a whole class of attacks, such as techniques to convince a program to write into a file that perhaps it didn't intent to write into. Since this technique prevents many attacks, it's worth doing if completely dropping the privileges can't be done at that point in the program. 6.3.4. Minimize the Modules Granted the Privilege If only a few modules are granted the privilege, then it's much easier to determine if they're secure. One way to do so is to have a single module use the privilege and then drop it, so that other modules called later cannot misuse the privilege. Another approach is to have separate commands in separate executables; one command might be a complex tool that can do a vast number of tasks for a privileged user (e.g., root), while the other tool is setuid but is a small, simple tool that only permits a small command subset. The small, simple tool checks to see if the input meets various criteria for acceptability, and then if it determines the input is acceptable, it passes the input is passed to the tool. This can even be layerd several ways, for example, a complex user tool could call a simple setuid ``wrapping'' program (that checks its inputs for secure values) that then passes on information to another complex trusted tool. This approach is especially helpful for GUI-based systems; have the GUI portion run as a normal user, and then pass security-relevant requests on to another program that has the special privileges for actual execution. Some operating systems have the concept of multiple layers of trust in a single process, e.g., Multics' rings. Standard Unix and Linux don't have a way of separating multiple levels of trust by function inside a single process like this; a call to the kernel increases privileges, but otherwise a given process has a single level of trust. Linux and other Unix-like systems can sometimes simulate this ability by forking a process into multiple processes, each of which has different privilege. To do this, set up a secure communication channel (usually unnamed pipes or unnamed sockets are used), then fork into different processes and have each process drop as many privileges as possible. Then use a simple protocol to allow the less trusted processes to request actions from the more trusted process(es), and ensure that the more trusted processes only support a limited set of requests. This is one area where technologies like Java 2 and Fluke have an advantage. For example, Java 2 can specify fine-grained permissions such as the permission to only open a specific file. However, general-purpose operating systems do not typically have such abilities at this time; this may change in the near future. For more about Java, see  Section 9.6 . 6.3.5. Consider Using FSUID To Limit Privileges Each Linux process has two Linux-unique state values called filesystem user id (fsuid) and filesystem group id (fsgid). These values are used when checking against the filesystem permissions. If you're building a program that operates as a file server for arbitrary users (like an NFS server), you might consider using these Linux extensions. To use them, while holding root privileges change just fsuid and fsgid before accessing files on behalf of a normal user. This extension is fairly useful, and provides a mechanism for limiting filesystem access rights without removing other (possibly necessary) rights. By only setting the fsuid (and not the euid), a local user cannot send a signal to the process. Also, avoiding race conditions is much easier in this situation. However, a disadvantage of this approach is that these calls are not portable to other Unix-like systems. 6.3.6. Consider Using Chroot to Minimize Available Files You can use chroot(2) to limit the files visible to your program. This requires carefully setting up a directory (called the ``chroot jail'') and correctly entering it. This can be a fairly effective technique for improving a program's security - it's hard to interfere with files you can't see. However, it depends on a whole bunch of assumptions, in particular, the program must lack root privileges, it must not have any way to get root privileges, and the chroot jail must be properly set up. I recommend using chroot(2) where it makes sense to do so, but don't depend on it alone; instead, make it part of a layered set of defenses. Here are a few notes about the use of chroot(2):   The program can still use non-filesystem objects that are shared across the entire machine (such as System V IPC objects and network sockets). It's best to also use separate pseudousers and/or groups, because all Unix-like systems include the ability to isolate users; this will at least limit the damage a subverted program can do to other programs. Note that current most Unix-like systems (including Linux) won't isolate intentionally cooperating programs; if you're worried about malicious programs cooperating, you need to get a system that implements some sort of mandatory access control and/or limits covert channels. Be sure to close any filesystem descriptors to outside files if you don't want them used later. In particular, don't have any descriptors open to directories outside the chroot jail, or set up a situation where such a descriptor could be given to it (e.g., via Unix sockets or an old implementation of /proc). If the program is given a descriptor to a directory outside the chroot jail, it could be used to escape out of the chroot jail. The chroot jail has to be set up to be secure. Don't use a normal user's home directory (or subdirectory) as a chroot jail; use a separate location or ``home'' directory specially set aside for the purpose. Place the absolute minimum number of files there. Typically you'll have a /bin, /etc/, /lib, and maybe one or two others (e.g., /pub if it's an ftp server). Place in /bin only what you need to run after doing the chroot(); sometimes you need nothing at all (try to avoid placing a shell there, though sometimes that can't be helped). You may need a /etc/passwd and /etc/group so file listings can show some correct names, but if so, try not to include the real system's values, and certainly replace all passwords with ""*"". In /lib, place only what you need; use ldd(1) to query each program in /bin to find out what it needs, and only include them. On Linux, you'll probably need a few basic libraries like ld-linux.so.2, and not much else. It's usually wiser to completely copy in all files, instead of making hard links; while this wastes some time and disk space, it makes it so that attacks on the chroot jail files do not automatically propogate into the regular system's files. Mounting a /proc filesystem, on systems where this is supported, is generally unwise. In fact, in 2.0.x versions of Linux it's a known security flaw, since there are pseudodirectories in /proc that would permit a chroot'ed program to escape. Linux kernel 2.2 fixed this known problem, but there may be others; if possible, don't do it. Chroot really isn't effective if  the program can acquire root privilege. For example, the program could use calls like mknod(2) to create a device file that can view physical memory, and then use the resulting device file to modify kernel memory to give itself whatever privileges it desired. Another example of how a root program can break out of chroot is demonstrated at  http://www.suid.edu/source/breakchroot.c . In this example, the program opens a file descriptor for the current directory, creates and chroots into a subdirectory, sets the current directory to the previously-opened current directory, repeatedly cd's up from the current directory (which since it is outside the current chroot succeeds in moving up to the real filesystem root), and then calls chroot on the result. By the time you read this, these weaknesses may have been plugged, but the reality is that root privilege has traditionally meant ``all privileges'' and it's hard to strip them away. It's better to assume that a program requiring continuous root privileges will only be mildly helped using chroot(). Of course, you may be able to break your program into parts, so that at least part of it can be in a chroot jail.  6.3.7. Consider Minimizing the Accessible Data Consider minimizing the amount of data that can be accessed by the user. For example, in CGI scripts, place all data used by the CGI script outside of the document tree unless there is a reason the user needs to see the data directly. Some people have the false notion that, by not publically providing a link, no one can access the data, but this is simply not true. Prev Home Next Secure the Interface Up Avoid Creating Setuid/Setgid Scripts"
GX155-64-10775451	Avanti   Indietro   Indice     4. Versioni del software trattate    Questo HOWTO assume che si usi un kernel di Linux 1.2.x con il software di PPP 2.1.2 oppure Linux 1.3.X/2.0.x e PPP 2.2.    Al momento della stesura di questo HOWTO, l'ultima versione ufficiale disponibile di PPP per Linux era ppp-2.2f. La nuova versione (ppp-2.3) è ancora in beta.    È possibile usare PPP 2.2.0 con kernel 1.2.13. Ciò richiede delle patch per il kernel. Si raccomanda agli utenti del kernel versione 1.2.13 di installare il ppp-2.2 in quanto corregge diversi bug.    Si dovrebbe notare, in particolare, che non è possibile usare il software PPP 2.1.2 con i kernel di Linux versione 2.0.x     Si noti che questo documento  NON  discute i problemi causati dall'uso dei moduli caricabili del kernel 2.0.x. Si veda il kerneld mini-HOWTO e la documentazione kernel/module del 2.0.x (nei sorgenti di Linux 2.0.x in  /usr/src/linux/Documentation/... ).    Poiché questo documento è pensato per assistere i nuovi utenti, si raccomanda fortemente di usare la versione del kernel di Linux e la giusta versione di PPP, che siano notoriamente stabili assieme.       Avanti   Indietro   Indice
GX052-10-7918372	"February 2002, Issue 75       Published by  Linux Journal     Front Page   |   Back Issues   |   FAQ   |   Mirrors   |   Search (www.linuxgazette.com)                   Table of Contents:               The MailBag        More 2-Cent Tips        The Answer Gang        News Bytes        Secure Printing with PGP  ,  by Graham Jenkins       A Pioneer for a New Century -- Alan Turing, part 1  ,  by G James Jones       Installing and using AIDE  ,  by Ariel Maiorano       GPL or BSD? Yes  ,  by Mark Nielsen       The Foolish Things We Do With Our Computers  ,  by Mike ""Iron"" Orr       Simple Package Management With Stow  ,  by Allan Peda       Why I wrote Install Kernel (ik) and How It Works  ,  by Justin Piszcz       Writing Documentation, Part III: DocBook/XML  ,  by Christoph Spiel       The Adventures of Little Linus In GNU/Wonderland  ,  by D Clyde Williamson       Modest Home on the Web  ,  by zhaoway       The Back Page                  Linux Gazette  Staff and The Answer Gang     Editor:  Michael Orr   Technical Editor:  Heather Stern   Senior Contributing Editor:  Jim Dennis   Contributing Editors:  Ben Okopnik, Dan Wilder, Don Marti          TWDT 1 (gzipped text file)   TWDT 2 (HTML file)  are files containing the entire issue: one in text format, one in HTML.  They are provided  strictly as a way to save the contents as one file for later printing in the format of your choice;  there is no guarantee of working links in the HTML version.         Linux Gazette ,   http://www.linuxgazette.com/   This page maintained by the Editor of  Linux Gazette ,   gazette@ssc.com      Copyright © 1996-2002 Specialized Systems Consultants, Inc.                                       Comments on: Play with the Lovely NetCat   LLG #74 Mailbag: Desktop Support   Good attitude!   Mountpoint permissions   Sorry / Saludos   attn: Ben Okopnik et al   Tux' Gender                 Comments on: Play with the lovely netcat  Fri, 11 Jan 2002 19:11:53 +0800  zhaoway ( zw from debian.org )   I've forwarded these comments about my Jan article in Linux Gazette:   Play with the lovely netcat .  Could you post it in your Mailbag? Thanks!     zw       The purpose of yes   Date:  Thu, 3 Jan 2002 16:05:19 -0700 (MST)  From:  Bruno Melli < bruno from fc.hp.com >     Hi zhaoway,     I was enjoying your column in the latest Linux Gazette and came upon your description of  /usr/bin/yes . I'm by no mean a Unix historian, but from what I understand the yes command had a very basic purpose:     The original rm command didn't have a -f option. So if you did  rm -r /some/dir   (or rm * where the current dir had lots of files) and if the permissions weren't set right you ended up having to type in a bunch of 'y' because rm asked you if you wanted to overwrite the permission.     Try it:   touch /tmp/haha chmod 000 /tmp/haha rm /tmp/haha     Imagine how annoying that becomes if you tried to rm hundreds of files at once.     The solution, if you didn't have access to the rm source, (or took the basic philosophy of Unix to the extreme):     yes | rm -r     bruno.         Author of Netcat   Date:  Wed, 2 Jan 2002 16:21:27 -0800  From:  ""Golden_Eternity""   < bhodi_jabir from yahoo.com >     In your article ""Play with the Lovely Netcat: Reinvent  /usr/bin/yes "" you comment on the anonymity of the author of Netcat.     I could be wrong, but I'm fairly certain that the author is Hobbit of the l0pht (currently @stake). There's a Win32 version by Chris Wysopal, as well.      http://www.atstake.com/research/tools/index.html#network_utilities                  LG #74 Mailbag: Desktop support    We got two messages on this topic.          pls pass this onto Dennis Field - his email doesn't work   Date:  Fri, 28 Dec 2001 20:23:50 +0000  Luke Worthy ( lukew from linuxmail.org )    re: Winning the Battle for the Desktop     Dude - quit you're Linux laptop whining...heh - jk         http://www.linux-laptop.net      and btw: try Mandrake, it has excellent PnP - they at least have a chat-style site for support, and it's all pretty good - just make sure you're winmodem is supported:      http://www.linmodems.org      That's usually the most important thing.     Luke           Regarding all these comments about desktop support ---    Date:  Thu, 17 Jan 2002 02:54:19 -0800  Iron ( LG Editor )      There are two major classes of desktop: home and office.  The former is novices and hobbyists (who help the novices).  The latter has help desks.     Linux's economics have little chance of winning over novice desktops. That's because the cost of tech support for the few is borne by everyone who buys the software.  Thus, a $50 package can afford to bear a 15 minute tech support phone call, and still turn a profit.       Actually, they cannot.  The retailer and distributor will take 20-50% off the top.  That leaves $25.  Even with low-paid support staff, a 15-minute call can't cost less than $5 unless it's a simple answer (in which case the call would have taken one minute) and all the infrastructure costs to main the help desk and its resources are externalized as overhead. If they sell one copy, they would not have enough profit to take the call, unless the company was tiny and had a tiny customer base (in which case the customer-service staff or other staff would double as tech-support staff, so they would have to be employed anyway).     If they sell a hundred copies (or whatever the number is), they can take that 15-minute call.  If the person calls back, they will have lost all of their profit on those hundred copies.  If another of those hundred customers also calls in, the company will lose money.     That's why unlimited free tech support has disappeared, why limited free tech support has long been in danger, and why so many companies have put their knowledge bases online and run product newsgroups.  It's much cheaper to have support staff monitor a newsgroup two hours a day than to wait by the phone, in terms of the number of customers that will be helped during that time, because others with the same question (or who may have the same question in the future), will see the answer.  Actually, that's how The Answer Gang works too....     There are exceptions.  The author of MetaKit ( http://http ://www.equi4.com/metakit/index.html), a non-SQL database server, offered unlimited free technical support, although I assume it was e-mail support rather than phone support.  He did it because he wanted to hear how clients were using the product and what kinds of problems they encountered: he considered that his payment because it helped him improve the product. I'm not sure whether he still offers this--the web page now points users with questions to a mailing list.  But there's obviously an upper limit on the number of customers you can offer ""free unlimited support"" to.         Linux is complex enough that the price really needs to be higher to support all the included software.      John Kawakami ( johnk from woodstock.com )   True, although this is more a responsibility of the distributions that market to newbies than a responsibility of the Linux community as a whole.     On the other hand, Linux could do okay in the corporate desktop, where in-house helpdesks keep people away from the ""free"" tech support you get from the vendors.  (It's not free if you're paying someone to wait on tech support.)  The simpler Linux apps are easier to ""fix"" when errant users make mistakes, and with VNC, the service can be done remotely.  Plus, overall stability pays off with fewer internal support staff.     ---- John Kawakami        If the in-house help desks know Linux.  Often, the only people who know Linux are the IT staff who run the servers.  -- Iron                 Good attitude!  Tue, 1 Jan 2002 14:50:04 -0500  mike ( mike from toadwart.darktech.org )  linux-questions-only (linux-questions-only@ssc.com)    Regarding: LG 74, 2c Tips #26    I really like the attitude expressed by the whole answer gang, and a subtle rtfm after the question is answered is a good thing, I think. Before the answer it's a provocation, afterwards it becomes good advice. Happy New Year,     Mike List                     Mountpoint permissions  Thu, 03 Jan 2002 21:42:34 -0500  Rick Holbert ( holbert.13 from osu.edu )    Use chown, chgrp and chmod to change the owner, group and permissions on the mount point.        Err, no. The querent actually stated that he tried those; I'm willing to believe him (the same situation obtains when you mount a VFAT partition; the owner/perms of the mount point are irrelevant.) I don't have a Samba setup at hand right now, and it's been a while since I had to do one, but I'm pretty certain that Mike Martin's suggestion - setting the ""uid/gid"" parameters in the conffile - is the right thing to do. -- Ben                   Sorry / Saludos  Tue, 8 Jan 2002 08:44:56 +0100  Andres Legarra ( alegarra from ikt.es )    Perdon!!     Me he confundido al pinchar el mensaje que queria responder.  Sorry, I mispelled when I picked the message to reply (This awful M$ Outllok Express...) By the way, I found some things on Linux Gazette very useful.  Congratulations     Usted escribe un buen español!!  Saludos     Andres Legarra Albizu                  attn: Ben Okopnik et al  Fri, 11 Jan 2002 22:33:00 -0800 (PST)  Mather Cotton ( mathercotton from yahoo.com )     http://www.linuxgazette.com/issue63/okopnik.html      That url saved my ass.  Thank you so much!     Cotton                 Tux' Gender    We got two messages on this topic.      re: Lady Penguins   Date:  Wed, 02 Jan 2002 04:50:22 -0500  Rachel Rawlings ( rrawlingsw from nyc.rr.com )      That might refer to Linus' original comment that penguins are happy because they have just stuffed themselves full of herring or have been hanging out with lady penguins. We only  /know/  that Tux is stuffed full of herring, but we can assume Tux hangs out with lady penguins. -- Heather     Which actually doesn't get say definitively whether Tux is male. Tux could hang out with lady penguins cf. Marlena Dietrich, or be a high-class drag king.        However, speaking as a dyke with a largish stuffed animal collection (one of whom is a female Peter Rabbit named Katja) my Tux is male. Other users' Tuxen may vary according to the needs of the user, much like their kernel configurations.        Interesting.  I wonder if Eric Raymond's enhanced kernel configurator will have a question for which sex your kernel should be built as.  -- Mike         All the Girls like him   Date:  Fri, 18 Jan 2002 11:26:17 +0100  patrick.op.de.beeck ( patrick.op.de.beeck from belgacom.be )      But, we couldn't publish his very cute note because it was marked confidential.  Sorry folks! -- Heather               This page edited and maintained by the Editors  of  Linux Gazette    Copyright ©  2002  Published in issue 75 of  Linux Gazette  February 2002   HTML script maintained by   Heather Stern  of  Starshine Technical Services,   http://www.starshine.org/           More 2¢ Tips!       Send Linux Tips and Tricks to  linux-questions-only@ssc.com        pseudo-chroot   See LILO only when you need it   Active Directory...   CSS2? Try XML and its kin instead   Linux with win2000   Cable Modem Setup   read a timestamp... the EASY way   How to manually label a tape in linux   Problem faced while using script to backup   Posters for [LG 72] help wanted #7                 pseudo-chroot  Fri, 4 Jan 2002 09:34:18 -0500  trevor ( tlist from vtnet.ca )    hi,     in issue 74 there's a question from Faber Fedor asking about how to setup an environment so that a user can't wander from their home directory.     i believe the person asking the question was looking for something along the lines of a restricted shell. tell the person asking the question to look at the ""-r"" option to bash, smrsh, and/or do a google search for ""restricted shell"".     best regards,  trevor                  See LILO only when you need it  Fri, 04 Jan 2002 13:21:36 -0800  John R. Jones ( jonejr from gat.com )    Hello gazette,     Being a new Linux administrator, I had ""hardened"" down my install by implementing a ""protected"" and ""password=<pass> entry in my  /etc/lilo.conf  file to keep people just as dangerous as myself out of single mode.     I also rem'd out the timeout= value so my install would always boot straight into Linux.     My question for the day was ""how could I boot Linux Single if I had to? a Boot and Root set would work, but I discovered this...     After the BIOS Mem check, hold down either control key and the LILO boot ""screen"" is displayed! And of course, you'd need the password=<value> to use it...     Wow, Now I am scary on 2 platforms.        -- Thank you,     John R. Jones     3, if you count that he's an Oracle DBA. -- Heather                 Active Directory...  Fri, 04 Jan 2002 01:38:57 -0600  John Lederer ( john from jhml.org )    OpenLDAP is the Linux equivalent of Active Directory.     Regards.  John     There's been enough small-comment interest in this, it would probably be good to see an article on the subject of setting up this sort of environment the Linux way. -- Heather                CSS2? Try XML and its kin instead  Sun, 30 Dec 2001 22:18:56 -0500  XunDog ( dwight1 from attcanada.ca )    Ok,     If the feature is unique to CSS2 then you won't replicate it with CSS1 and cross-platform browser support for either is restrictive ...     so .... I would suggest using Xml, xsl, xslt and either DTD or xsd schema formats ...     this is more completely supported ... just a little (mabye a lot) more work ... Check out the books by Benoit Marchal ...     regards  XunDog                 Linux with win2000  Mon, 14 Jan 2002 13:56:00 -0500 (COT)  nadeem ( abc from studiosmile.com )  answered by John Karns (The Answer Gang)    Anybody please tell me about installation of linux with win2000. I already installed linux 7 on my pc. now i want that without format my system i install win2000 on my pc.     any body pls give me any utility. don't tell me FAQ. this is boring for me. if anybody wants help me out than pls provide me utility.     If you find reading FAQ's boring, I don't think you're going to like Linux too much.     Three recommendations:     For disk partition manipulation:     fips or   Partition Magic (there are others, but these are two I've used)     For installing and running Windows (MSW) with Linux.  3) VMWare     It would be nice to be able to avoid MSW entirely, but since my work demands it, using VMWare allows me to run it without having to reboot and leave the Linux environment.     -- John Karns                 Cable Modem Setup  Wed, 2 Jan 2002 10:26:11 +0100   Eugene Poole ( etpoole from attglobal.net )  answered by Yann Vernier and Mike Orr (The Answer Gang)    On January 3, 2002 I'm having a external cable modem installed. I've been looking around for some simple suggestions on what needs to be done, confuguration wise, to my Linux machine. Can you help? Naturally, the normal statement has been made - ""We don't support Linux"". The Linux machine that it's being connected to has a second NIC installed and I've accessed the machine via the second NIC to that's all set up. Where do I go from there?     We can't know the next step until you have the instructions for how to connect using the cable modem. If you are using  Debian  GNU/Linux, a simple way to prepare for running a masquerading gateway is to install the ipmasq package, but we don't know if you need PPPOE, DHCP, or some special login methods. A useful resource may be  http://www.cablemodeminfo.com/LinuxCableModem.html      Good luck! -- Yann        The extra Ethernet card should be all you need.  Beyond that, just follow the Windows dialogs in the manual and see whether it's dhcp or a static IP, which nameservers to put in  /etc/resolv.conf , etc.     Yann is right about setting up masquerading if you have a local network.  I don't think of that as ""setting up a cable modem"" though. That's another step, connecting a local network to the Internet.     Be glad you have an external modem.  It would be much harder to set up if it were internal, because it would probably require some proprietary DLL that isn't available for Linux.  -- Mike                   read a timestamp... the EASY way  Wed, 2 Jan 2002 23:19:54 -0500  Joe Smith ( jes from martnet.com )    I was looking for a solution to extract the timestamp of a file with plain shell methods.     ... (Lots of all-too-complicated suggestions followed)       What's wrong with     date -r file     Which only goes to show that we  really  need a friendly way to query the vast obscurity which is Unix documentation... sigh.     <Joe          <laugh> Bravo! Well done, sir!     This illustrates the point that I often make to folks just learning Unix: the tools are in there,  somewhere . It's  finding  them that's the problem. -- Ben       ......... the original querent replies .........     Indeed.     Especially when some of your man pages are out of date. In my case,     date --help     would have given the solution, while     man date     just keeps this secret. Sob.      -- Regards, Fakir                 How to manually label a tape in linux  Wed, 9 Jan 2002 10:18:29 +0530  FRANCO FERNANDES ( franco from lauren.co.in )  Answered by Jay Ashworth (The Answer Gang)    I manually backup my linux server every day for that i need to put a label on my tape according to the date, I backup my server. Does anyone know how to manually label a tape in linux is there any command for doing that.     Please help  Thanks in Advance  Franco.F      Well,  my  approach to this is to create a directory called  /tmp/TIMESTAMP , and, just before you make a backup, clear out all the files, then use     touch /tmp/TIMESTAMP/`date +%Y%m%d-%a%H%M%S`     This wlil give you a label for the backup which you can read without having to actually load any data.     Cheers,  jra            Problem faced while using script to backup  Wed, 9 Jan 2002 10:26:14 +0530  FRANCO FERNANDES ( franco from lauren.co.in )  answered by Dan Wilder (The Answer Gang)      I have created a automated script to backup my server for that i want my log file to display the date it backsup my server every day. My script has this line ,    echo "" BACKUP OF fileserver STARTED "" >> /var/log/bkuplogs/fileserver/mainlog      Is there any parameter which has to be put like %m %h %d. Any kind of help will be highly appreciated       Try     echo "" BACKUP OF fileserver STARTED $(date +'%c') "" >> whatever     See     man date     for other format strings. -- Dan Wilder                 Posters for [LG 72] help wanted #7  Fri, 28 Dec 2001 11:36:12 +0100  Yann Vernier, Chris Gianakopoulos, Jim Dennis ( The Answer Gang )  Brian Keyse ( bkeyse2 from yahoo.com )    I feel I must recommend O'Reilly's ""Anatomy of a Linux System"" poster. It is a large, colourful poster giving a rough overview of how things fit together and recommending (O'Reilly, of course) books.     Their address is  http://www.ora.com  but I didn't find the poster in their product list; it is probably promotional material which you'll have to ask them for. -- Yann      It's available as a PDF file:  ftp://ftp.oreilly.com/pub/poster/oreilly_linux_poster.pdf   -- Brian Koyse      I saw some sort of a thing like that for Linux.  Is it 3 or 4 feet in diameter and it shows the ring structure of the operating system? You know..., the kernel in the middle, with the applications at the outer ring?  If that's the thing, it's kinda cool.  I think that I am gonna get one of those. -- Chris G.      Hmmm.  The one I saw was just of the Linux kernel sources. Core memory management and scheduler in the center and VFS and core networking support forming a second tier, with filesystems and specific device drivers on the periphery. That one was a sort of a fractal star or ""peacock."" -- JimD      I'll have to look at the chart when I go back to work next week.  There's a book entitled ""The Design of the Unix Operating System"" by Maurice Bach. The poster that I saw, for Linux, looks like the structure on the cover of that book.     Regards, Chris G.               This page edited and maintained by the Editors  of  Linux Gazette    Copyright ©  2002  Published in issue 75 of  Linux Gazette  February 2002   HTML script maintained by   Heather Stern  of  Starshine Technical Services,   http://www.starshine.org/                        The Answer Gang           By Jim Dennis, Ben Okopnik, Dan Wilder, Breen, Chris, and...  ( meet the Gang ) ...  the Editors of Linux Gazette...   and You!  Send questions (or interesting answers) to   the Answer Gang  for   possible publication           Contents:     ¶: Greetings From Heather Stern        How does one examine a core file           Greetings from Heather Stern     ... you stand there waiting for Heather to look up from her keyboard...   Oh!  Hi everybody!  It's certainly been an active month here with The Answer Gang.   We had almost 700 slices of Gazette related mail come past my inbox. The longest thread (not pubbed this month, look forward to it next time) was over 50 messages long.  Less than 20 people got no answer whatsoever (not  counting the occasional spammer) and the top reason for not getting a post answered, appeared to be simply a lack of interest in that message.   Crazy attachments are down a LOT since our sysadmin improved the filters.  Ben did a bit more cleanup on the  TAG FAQ  and  Knowledgebase  and we  have a new  posting guidelines page   which I hope you find easy to read.  In the land of Linux I'm pleased to note that the 2.4 series kernel is resembling stable since 2.4.17 is over a month old now.  A lot of work is being done in 2.5.  Flu struck my area and melted my mind back down to a mere single CPU when I'm used to being an SMP system.  Bleh!  And before you ask ... yes, I'm feeling better.  Lots of liquids, chicken soup, all that.  It appears as though Ghostscript is my evil nemesis of the month.   I haven't had time to finish compiling support for that new color printer of mine.  In a moment of foolishness I upgraded my Dad-in-law's box and the next few days were completely nuts since kword and gs refused to agree on what fonts to print, or even to get the metrics right so margins would work.  They're happy again since I forced ghostscript to uninstall completely and then reinstall.   And we still wonder what the heck happened to gnucash in Debian/Woody, though I admit, I haven't looked very hard.  Cheerfully for my mortgage I've had a lot of consulting work this month. Between 600 plus messages and all that, though, there wasn't time for me to fit the usual ten pack (this blurb and nine of the juiciest TAG threads) in under a tighter than usual deadline.   Mike will be enjoying a Python conference much of this next month.  I hope it counts for a well deserved vacation on his part.    I've not left you completely wanting, though.  Here's a few days in the  life of The Answer Gang, troubleshooting one of those day to day things that drives everybody nuts once in a while -- segfaults.  Core files are a mess.  Good thing we have a dustbin around here.          How does one examine a core file     From Faber Fedor      Answered By Jim Dennis, Dan Wilder, John Karns,   with side comments from Ben Okopnik and Heather Stern        I've got a problem with a RH7.1 machine and no error messages to look at, so I'm wondering how does one debug a problem like this?     Moved a machine from NY to NJ yesterdy.  When I left it last night, everything was running, esp.  Apache .  This morning, normal maintanence occurred at 4:02 AM, and when the system (syslog?) went to restart httpd, the restart failed.  It's been failing ever since too!     The only http related message in  /var/log/messages  is    Dec 22 12:27:13 www httpd: httpd startup failed     Access and error logs for httpd are empty.     Running  /usr/sbin/httpd  (with and without command line parms) generates the message    Segmentation fault (core dumped)     and the requisite core file:    core: ELF 32-bit LSB core file of 'httpd' (signal 11), Intel 80386, version 1, from 'httpd'     File size and date of  /usr/sbin/httpd  matches my local copy.     Any ideas where to look next?   -- Regards, Faber         Jim Dennis pontificates about troubleshooting apache's startup... -- Heather       [JimD] First, I would run  /etc/init.d/httpd  or  /etc/init.d/apache , or whatever it is on your system.  Run it with the ""start"" option.     (Actually I'd  read  the  /etc/init.d/  start script for that service, and probably I'd manually go through it to figure out what I needed to do in order to run this particular installation of Apache correctly).        Did that.  That's what I meant by ""it crashed at the command line with and wothout parameters.        [JimD] To dig further I might replace the httpd with a short ""strace wrapper"" script:     #!/bin/bash exec strace -f -o /tmp/apache/strace.out /usr/sbin/httpd.real ""$@""       This  definitely  goes into my bag of tricks (once I   decode it   )       [JimD] (be sure to mkdir  /tmp/apache , and make it writable to the appropriate UID/GID --- whatever the webserver runs as).     I'd look through the strace.out file for clues. Don't leave this running in this fashion for too long.  The strace.out files will get  huge  very quickly; and your performance should suffer a bit.     Considering that it used to work, you did a shutdown, moved the system, brought it back up,  and then, presumably, CONFIGURED IT FOR A NEW NETWORK, I'd look very carefully at network masks, routes and related settings.       Very close!  The problem turned out to be that the name server the box was using is no longer accessible (the box is there, but dig returns ""no name servers were found"") and there were no backup name servers in  /etc/resolv.conf  (mea culpa).     I wouldn't have expected apache to segfault under those conditions, but it did.     [JimD] Also, consider upgrading to RH7.2 if you can.       [Faber] I just got my hands on it earlier this week so I'm still evaluating it.          Red Hat 's distribution has been very consistent in it's release history: avoid the .0, skip the .1, and wait for the .2; that's been the rule since 4.2!        [Faber] Normally, that's what I do, but we needed to upgrade to PHP4 ASAP and it was alot easier to upgrade the whole system to 7.1 (from 6.2).     thanks again!  Regards, Faber          [JimD] You're welcome.         ... while Dan took a different approach, considering the core file itself. -- Heather     [Dan] 0) Start by making sure there's no error in your httpd.conf by running     apachectl configtest     No doubt there's nothing there.  But if there is, you are not apt to find it by examining core files, etc.     If you're an expert C developer       [Faber] At one point in my life, I might have said that, but then only to impress women like Heather.          [Dan] I don't expect Heather's that easily impressed.  Especially by guys like me that mistype ""developer"".    That's ok, I fixed it.  That's what editors are for,  at least sometimes.  I'm more impressed by how people solve  problems than by whether they're an expert in everything around  them.  It's nice if they can solve  my   problems, though. -- Heather         [Dan]  and have the source tree to your apache handy, examining the core file might yield you something.       [Faber] IOW, no, I don't want to do that.            [Dan] Naah, me neither.  Last resort.       Mostly it's pretty indirect.  Segfaults are typically caused by out-of-bounds pointers or array references, references to allocated memory since freed, confusion about number or type of parameters passed to a function, and the like.   The error happens earlier, when the bad pointer is parked someplace, memory is erroneously freed, etc.  The fault happens later, when something is dereferenced.     I've spent many a happy and well-paid hour trying, sometimes without success, to track backwards from fault to error. And when you find the error, you may still a long and winding road back to the defect which caused the error.    Defect    --------->  Error  -------------> Fault  (Improper          (Something bad       (Result becomes code construct)     happens)             observable as                                          unexpected result)     Unless you're an expert C developer, and patient and lucky as well, it's more likely you'll find the problem by a process of elimination.     1) What's changed recently?  New application?  Change in httpd.conf? New module installed?  Try backing out any recent changes, one by one.  Restart apache after each thing you back out.     2) Is it possible there's filesystem corruption?  Corrupted binaries often fail to run well.  Take the machine down and run     fsck -f     on all filesystems.  If you find anything amiss, determine what files were affected.     3) Reinstall apache just in case, anyway.     4) Could the machine have other hardware problems?  If you have the kernel development packages installed, build the kernel eight or ten times.  If you get ""died with signal 11"" or other abnormal termination, proceed with hardware troubleshooting procedures.     5) Figure out what area of apache is affected.  Save your httpd.conf and start with a default one.  Will apache start?  If so, re-introduce features from the running copy of httpd.conf a few at a time until apache begins dying at startup.     Let us know how you do.  Depending on where you find trouble, the gang can offer further advice. -- Dan Wilder       Jim has quite a bit to say about   using strace  -- Heather    #!/bin/bash exec strace -f -o /tmp/apache/strace.out /usr/sbin/httpd.real ""$@""     [JimD] In runs a shell (bash) which then exec()s (becomes) a copy of the strace command.  That strace command is told to ""follow forks"" (so we can trace the system call of child processes) and writes its output to a file in our  /tmp/apache  directory.  strace then runs (fork()s then exec()s) a copy of the ""real"" httpd with a set of arguments that matches those that were passed to to our script.     The distinction between   exec() 'ing a command and invoking it in the normal way is pretty important.  Normal command invocation from a UNIX shell involves a   fork()  (creating a clone process which is a subshell) and then an exec*() by that shell to transform that subprocess into one which is running the target command.     Meanwhile the parent shell process normally does a wait*() on the child.  In other words, it sits there, blocked until the child exits, or until a signal is received.     When we use the shell exec command, it prevents the   fork()  (there's no creation of a subprocess).  The ""text"" (executable binary code) of the process that was running a copy of your shell ( /bin/bash  in our case) is overwritten by the ""text"" of the new program; all of the heap and stack segments (memory blocks) of the old process are freed and/or clear) and the only traces of the old memory image that remain available are the contents of the process' environment.  In other words, the exec command is a wrapper around the one of the exec*() system calls (there are several different versions of the exec*() system call which differ in the format of their arguments, and the preservation/inheritance versus creation of environments).     Actually I think that Linux kernel implements   execve()  as a wrapper around its   clone()  system call, and that libc/glibc provides the handling for all of the variations on that.  The three ""variables"" on these exec variations are:       format of the command argument list:  (which is either done through C varargs --- like   printf()  and friends, or is a pointer to an array of NUL terminated strings), (execv* vs. execl*)      environment handling:  whether the process keeps its current environment or overwrites it.  The   execle()  and   execve()  versions have an extra parameter pointing at an NUL terminated of NUL terminated strings.      path searching:  The first argument of the   execvp()  and   execlp()  functions can be a simple command basename --- while all other variations require a qualified path.  The ""p"" versions will search the PATH as a shell would.       It appears that you can either search the PATH or create a new environment, but not both.  Of course you can use a simple   execl()  or   execv()  to do neither.  Of course you can read the man exec(3) manual pages in the library functions section of your online docs to read even more details about this.     When I'm teaching shell scripting I spend a considerable amount of time clarifying this worm's eye view of how UNIX and the shell handles fork()s and exec*()s.  I draw diagrams representing the memory space and environment of a process, and another of a child process (connected by dotted lines labeled   ""fork() "").  The I crosshatch most of the memory space --- leaving the environment section, and label that exec*().     When I do this, people understand how the environment really works.  The ""export"" shell command moves a shell variable and its value from the local heap ""out"" to the environment region of memory.  Once they really understand that, then they won't get too confused when a child process sets a shell variable, exports, and then their original process can't see the new value.  (""export"" is more of a memory management operator than an inter-process communications mechanism; at best it is a one-way IPC,  copying  from parent to children children).     After than I generally have to explain about some implicit forms of sub-process creation (forking) that most people miss.  In particular I remind them that pipes are an *inter-process* communications channel.  So, any time you see or use a | operator in the shell, you are implicitly creating sub process.  That's why a command like:     unset bar; echo foo | read bar; echo $bar     [Ben] Oh,  that's  cute. I go through pretty much the same spiel - some of it admittedly cribbed from your description of this, because I liked it the first time I heard it - but the way I've been demonstrating it is with a     while read bar; do echo $bar; done < file     loop. This nails down the other end.  Very  cool.     (Scribbling notes in newly acquired Palm Pilot)      [JimD] ... will return an empty value in most shells.  The read command is executed in a subprocess which promptly exits, freeing the memory that held  its  copy of the bar variable/value pair.  (I say  most  shells because ksh '93 and zsh, create their subprocesses on the left hand side of their pipe operators.  That's one of those subtle differences among shells.  Personally I think bash and others do it wrong, the ksh/zsh semantics are superior and I hope bash 2.x or 3.x will adopt them, or offer a shopt, shell option, to select the desired semantics).     The "" $@ "" ensures that the arguments that were passed to us wil be preserved in count and contents.  If we used "" $* "" we'd be passing a single argument to our command.  That single argument would contain the text of all of the orginal arguments, concatenated as one string, separated by spaces (or by the first character from IFS if you believe the docs).  If we used  $*  (no soft quotes) we'd be having the current shell resplit the number of arguments --- they'd have the same contents, but any arguments that had previously had embedded spaces (or other IFS characters) would be separated accordingly.     The "" $@ "" handling is the most subtle part of this script. An unquoted  $@  would be be the same as an unquoted  $*  (as far as I can tell).  It is just the "" $@ "" that gets the special handling. ( $*  and "" $* "" aren't special cases, they  are expanded and split in the normal way; "" $@ "" is expanded and  sort of ""internally requoted"" to preserve the  $#  --- argument count).     If you were going to need to do this frequently we might write a ""strace.wrapper.sh"" shell script which would work a bit like this:      #!/bin/bash  OLDMASK=$(umask)  umask 077  TMPDIR=/tmp/$(basename $1)$$  mkdir ""$TMPDIR"" || exit 1   ## make a temporary directory or die  umask $OLDMASK  TARGETCMD=""$1""  shift  exec strace -f -o ""$TMPDIR/strace.out"" ""$TARGETCMD"" ""$@""     In this example we call strace.wrapper.sh with an extra argument, the name of he command to be ""wrapped.""  We then fuss a little with umask (to insure that our process' output will have some privacy from prying eyes, and doing an atomic ""make a private dir or die trying"" (This is the safest temp file handling that can be managed from sh, as far as I know).     Then we restore our umask, (so we don't create a Heisenbug by challenging one of our target command's hidden assumptions about the permissions of files  it  creates).  We than grab our target command, shift it off our argument list (which does NOT disturb the quoting of the remaining arguments) and call our strace command as before --- with variables interpolated as necessary.     Mind you I don't use this script.  I don't bother since I can do it about as easily by hand.  Also this script wouldn't be the best choice for CGI, inetd launched, or similar cases. In those cases we're better renaming the original binary.       Of course we were all happy when Faber found what it was!  We encouraged  him to send in his bug report -- Heather       I wouldn't have expected apache to segfault under those conditions, but it did.     [JimD] Report it as a bug (after upgrading to the latest stable release). Try to isolate the .conf directive(s) that are involved, if possible.      [Dan] ...  The error happens earlier, when the bad pointer is parked someplace, memory is erroneously freed, etc.  The fault happens later, when something is dereferenced.     Well, as I told Jim, the fact that it couldn't find a name server caused it to segfault.  Weird; you would have thought it would have exited wih a message at least.     [John K] It sounds like there's a bug or some abnormality with apache's handling of a situation which is doesn't expect in normal operation.  IOW, a problem with error handling.  If the apache version is not the latest stable version, you might want to consider upgrading.  If it is the latest, then you may want to consider reporting it to the apache developers.       ...and of course we congratulated him on his success, with some extra  thoughts on general troubleshooting. -- Heather     [Dan] Congradulations on solving the problem.     That's what I call the ""natural history approach"".  Examine carefully the behavior and habitat of the creature in question, and think carefully about what you've observed.     I've probably fixed a lot more bugs in my life by the natural history method, than I have by the method of examining core files, or for that matter running under a debugger or emulator.     Strace, mentioned separately in this thread, is a little harder to classify. A program that attaches itself to a running process and dumps out information about system calls, it affords a level of information about a program that may sometimes come close to what you'd see using a debugger.     Mostly it doesn't, but sometimes it provides that key observation not available by other means which allows us to finally come to grips with a bug.  I'd group it with natural history tools, perhaps as an analog to a radio collar.  You know where the animal's been, but maybe not why, or what it did there. -- Dan Wilder     [JimD] I like to use the classic ""OSI reference model"" as a rough troubleshooting sequence.  Keep going down the stack (from application, down through network and to the physical layers until you isolate the problem, then proceed back upwards correcting each problem until the application works).               This page edited and maintained by the Editors         of  Linux Gazette   Copyright ©  2002  Published in issue 75 of  Linux Gazette  February 2002   HTML script maintained by          Heather Stern  of         Starshine Technical Services,          http://www.starshine.org/       ""Linux Gazette... making Linux just a little more fun! ""              Contents:     Legislation and More Legislation   Linux Links   Conferences and Events   News in General   Distro News   Software and Product News        Selected and formatted by   Michael Conry        Submitters, send your News Bytes items in   PLAIN TEXT  format.  Other formats may be rejected without reading.  You have been warned!  A one- or two-paragraph summary plus URL gets you a better announcement than an entire press release.                 February 2002  Linux Journal          The February issue of  Linux Journal  is on newsstands now. This issue focuses on Small Office/Home Office (SOHO).  Click   here  to view the table of contents, or   here   to subscribe.     All articles through October 2001 are available for public reading at   http://www.linuxjournal.com/magazine.php .   Recent articles are available on-line for subscribers only at   http://interactive.linuxjournal.com/ .                 Legislation and More Legislation                Jon Johansen Indicted by Norwegian Authorities Regarding DeCSS       Unhappy news this month, as it emerged that Jon Johansen has been    indicted  by Norwegian authorities for his part in creating and distributing the DeCSS code.  This comes two years after he and his father were    first  taken from their home in connection with the same software. The initial report is available   in Norwegian , and a    translation  was posted in the Slashdot   discussion  of the story.    It appears that the case against Jon is unusual in that he is being charged under laws which are generally applied in cases involving breaking into computers and theft of electronic records or company files.  Pressure from the MPAA and the US entertainment industry appears to have encouraged the Norwegian authorities to try this experimental attempt to secure a conviction.   The   Electronic Frontier Foundation  have extensive resources on    this case . Particularly interesting are   some legal arguments  as to why no offence has been committed under Norwegian law and   transcripts  including Jon Johansen's testimony at the 2600 Magazine trial in New York under the DMCA (July 20, 2000).   A   mailing list  has also been set up to discuss issues concerning the case, including how to support Jon and how to protest against the indictment.    The sorry truth is that cases like this are likely to become more common in the future.  Governments internationally are harmonising their intellectual property laws through measures such as   the WIPO copyright treaty  which will come into force in March (having recently secured its 30th signatory).  The result will be that all countries might eventually enact legislation akin to the DMCA to protect the media multinationals' intellectual property and access-control technologies.  Countries attempting to resist this trend will not be well received.  Slashdot    reported recently  that Ukraine is subject to US trade sanctions for not using an ""optical media licensing regime"" for blank CDs and CD recorders.  The best way to resist at an individual level is to make your voice heard and start lobbying and writing letters.  Your local LUG could form a focus for this activity.                Support From Washington         Congressman Rick Boucher  has been receiving a lot of press lately for the position he has taken with regard to issues such as digital rights management and the DMCA.   Dotcom Scoop  recently   reported  that Congressman Boucher has    written  to the RIAA expressing his concern at the introduction of copy-protected compact discs.  He feels that such developments ""...may prevent or inhibit consumer home recording using recorders and media covered by the Audio Home Recording Act of 1992"". A   report  on the same story in The Register, however, indicated that the copy protection measures probably are legal.  It seems that though the record label cannot sue you for making a legitimate personal copy of your new CD, they are not obliged to make it easy for you! ZDNet has   reported  [ Reuters ] that Boucher is planning to introduce a bill that would eliminate the ""anti-circumvention"" clause of the DMCA.  It is certainly encouraging to see an elected representative taking an overtly pro-consumer line on these issues.   Another elected representative who seems to understand a thing or two is Rep. Darrell Issa, a member of the US House of Representatives' Judiciary Committee.     Speaking  to  Linux Journal's  Don Marti, he indicated that the SSSCA was ""dead on arrival"". Though this is encouraging,  it might be foolish to get too relaxed until the grave is actually occupied.  Don comments that Issa also seemed well informed on other issues in this area (DMCA, etc.,).   Perhaps when campaigning on issues of concern, it would be wise to be alert to good as well as bad news.  Elected representatives careers are based on achieving public support and they can be very sensitive to public opinion.  It could not hurt to mail guys like Boucher and Issa to tell them if you like what they are doing.              UCITA         LWN reported that   UCITA is back again . The main issue for the free software community would be that the UCITA, if it came into US law in its current form, would prohibit the distribution of software to consumers without warranty.  This would mean that by distributing a free software utility, you could be held responsible by consumers for any flaws in the product (even though you have disclaimed all warranties, etc.,).  This story was also  reported  by TheRegister, who linked to   this article  by Richard Stallman on ""Why We Must Fight UCITA"".               Legislative Links         Indianapolis'    attempt  to keep minors from playing violent video games in public arcades was ruled unconstitutional, at a cost of $318,000 to taxpayers.    NY Times   review  of the year in tech law, which makes a nice lead in to their   preview  of what might be to come.  Both articles feature the input of various experts from the field, and both require registration.     Essay  on cryptome.org by Mike Godwin on digital rights management and the battle  between computer companies and entertainment companies. (Courtesy Crypto-Gram)           Linux Links      Jun Jungho mailed to announce a LG Korean translation site at   http://www.whiterabbitpress.com/lg/ . He and fellow volunteers have tested this site for 5 months, and would now like to inform others. ""I wish that this site gives more fun & infomation to Korean Linuxers.""       ASCII: American Standard Code for Information  Infiltration  by Tom Jennings. A very interesting, and in-depth article. Covers history of ASCII, and its various developments over almost half a century.     Courtesy    crypto-gram  is a link to a   review  [pdf] of the year in vulnerabilities.  This contains a list  of all the operating systems and applications with vulnerabilities.     Newsforge has a   story  on one person's experiences with    Gentoo Linux  , a distribution that requires the user to start the installation by compiling new compilers. In a similar vein, DistroWatch have a   review  of Sorcerer GNU Linux, which again compiles much of the system from source during install.      ZDnet   asks  `is Linux ready for the desktop?' While   Cio.com  tell us   how to run  a Microsoft-free shop.      Linux Journal  have   looked back  over the problems exposed in SSH during the past year, and the solutions which have resulted.     Some links and stories that appeared on  SlashDot  over the past month:         Kerneltrap           interview      with Alan Cox about the kernel, DMCA and more.     Linux Today reported Alan's recent release of           2.4.18PRE3-AC1      and           2.4.18PRE3-AC2  (due to popular demand!).               Interview      with Rick van Riel, kernel developer.     Talks about virtual memory controversies (among other things).               Kernel 2.5.2          The Linux Cookbook           book review .               Story      about flashing a mini Linux OS onto 802.11b firmware with           screenshots .           Linux Today  have featured the following links which you may be interested to follow:     LinuxSecurity.com   article  on a vulnerability in the Linux encrypted loop device.     Also from LinuxSecurity.com is an   article  on using statistical tools with the  Snort  IDS.     Caliban.org   article  on getting more from Bash.     Bram Moolenaar writes about   Vim, an open-source text editor , dealing both with technical issues and the background to his selection of the Charityware licence.     LinuxLookup have   reviewed  VMWare 3.0 Workstation for Linux.     The BBC is   trialing  Ogg Vorbis streams for online listeners.     The Guardian   reports  on free software's fortunes during the downturn.         TheRegister's Thomas Greene reported on getting   superior benchmarks  for Quake-3 FPS on Linux as opposed to Windows. Hardly a scientific test, but nice to see none the less.     From the   O'Reilly  stable of websites, the following may interest you:       An article  covering some of the issues in integrating WinXP into your existing heterogeneous network.     An   introduction  to CVS.     Automating Network Administration,    Part One  and   Part Two .     A discussion on the   question  of whether publicly funded research should result in open source code? Related to this issue is a recent Salon   article  on intellectual property and universities.  The current head of the Berkeley department responsible for intellectual property reckons they should have licensed the TCP/IP stack and collected royalties all the way to the bank.         Scientific American   article  on really   bad patents . If you find those interesting, you might like to look at IBM's new    patent  for a toilet reservation system    highlighted  by Hartmut Pilch on the    patents mailing list  at   aful.org .       What to do  after a computer break-in.     Some    Linux Weekly News  highlights:         LWN has           analysed      the controversy surrounding Eric S Raymond's kernel auto-configuration     software. Eric has been defending the project using stories detailing     the plight of        Aunt Tillie      as she tries to reconfigure her kernel. LWN has further amusing links.         Final version of            LWN 2001 timetable          Taking a            look at      the phenomenon of people setting up multiple alternative kernel trees,     as a demonstration and staging area for their patches.  Could other     projects benefit from this approach?     LWN's Jonathan Corbet    comments  on the processes at work behind `large' Linux kernel changes, and how these processes differ from practice in proprietary software development.       The Washington Post have an interesting article by Lawrence Lessig entitled    ""Who's Holding Back Broadband"" . It appears issues of control loom large in this area, with media companies loath to take any move which might loosen their grip on the ""content industry"".  Embracing broadband would be just such a move.     Two    IBM  whitepapers ( here  and  here ) on security issues relating to ""Linux in Enterprise Systems"" (and we are not talking about Klingons off the starboard bow). Both pdf's, and quite large.  IBM appears to be strengthening their support for Linux. Slashdot  reported  that IBM's new $400,000 Z-series mainframe will not be sold with z/OS, but rather with Linux.           Upcoming conferences and events     Listings courtesy  Linux Journal .  See  LJ 's  Events  page for the latest goings-on.                      LinuxWorld Conference & Expo (IDG)            January 30 - February 1, 2002 New York, NY              http://www.linuxworldexpo.com/                    The Tenth Annual Python Conference (""Python10"")           February 4-7, 2002 Alexandria, Virginia                    http://www.python10.com/                    Australian Linux Conference           February 6-9, 2002 Brisbane, Australia             http://www.linux.org.au/conf/                    Internet Appliance Workshop    February 19-21, 2002 San Jose, CA               http://www.netapplianceconf.com/                    Internet World Wireless East (Penton)    February 20-22, 2002 New York, NY        http://www.internetworld.com/events/weast2002/                    Intel Developer Forum (Key3Media)           February 25-28, 2002 San Francisco, CA      http://www.intel94.com/idf/index2.asp                    COMDEX (Key3Media)    March 5-7, 2002 Chicago, IL             http://www.key3media.com/comdex/chicago2002/                 BioIT World Conference & Expo (IDG)           March 12-14, 2002 Boston, MA             http://www.bioitworld.com/                 Embedded Systems Conference (CMP)           March 12-16, 2002 San Francisco, CA              http://www.esconline.com/sf/                 CeBIT (Hannover Fairs)           March 14-22, 2002 Hannover, Germany                    http://www.cebit.de/                 COMDEX (Key3Media)            March 19-21, 2002 Vancouver, BC               http://www.key3media.com/comdex/vancouver2002/                 FOSE           March 19-21, 2002 Washington, DC                    http://www.fose.com/                  Game Developers Conference (CMP)            March 19-23, 2002 San Jose, CA             http://www.gdconf.com/                 LinuxWorld Conference & Expo Singapore (IDG)            March 20-22, 2002 Singapore                  http://www.idgexpoasia.com/                 Software Solutions / eBusiness World           March 26-27, 2002 Toronto, Canada             http://www.softmatch.com/soln20.htm#ssebw                 SANS 2002 (SANS Institute)            April 7-9, 2002 Orlando, FL             http://www.sans.org/newlook/home.htm                 LinuxWorld Conference & Expo Malaysia (IDG)           April 9-11, 2002 Malaysia             http://www.idgexpoasia.com/                 LinuxWorld Conference & Expo Dublin (IDG)           April 9-11, 2002 Dublin, Ireland                           Internet World Spring (Penton)            April 22-24, 2002 Los Angeles, CA             http://www.internetworld.com/events/spring2002/                 O'Reilly Emerging Technology Conference (O'Reilly)           April 22-25, 2002 Santa Clara, CA             http://conferences.oreillynet.com/etcon2002/                 Software Development Conference & Expo, West (CMP)            April 22-26, 2002 San Jose, CA             http://www.sdexpo.com/                 Networld + Interop (Key3Media)            May 7-9, 2002 Las Vegas, NV             http://www.key3media.com/                 Strictly e-Business Solutions Expo (Cygnus Expositions)            May 8-9, 2002 Minneapolis, MN             http://www.strictlyebusiness.net/strictlyebusiness/index.po?                 Embedded Systems Conference (CMP)            June 3-6, 2002 Chicago, IL             http://www.esconline.com/chicago/                 USENIX Annual (USENIX)            June 9-14, 2002 Monterey, CA             http://www.usenix.org/events/usenix02/                 PC Expo (CMP)            June 25-27, 2002 New York, NY             http://www.techxny.com/                 O'Reilly Open Source Convention (O'Reilly)           July 22-26, 2002 San Diego, CA                    http://conferences.oreilly.com/                 USENIX Securty Symposium (USENIX)            August 5-9, 2002 San Francisco, CA             http://www.usenix.org/events/sec02/                 LinuxWorld Conference & Expo (IDG)           August 12-15, 2002 San Francisco, CA      http://www.linuxworldexpo.com                 LinuxWorld Conference & Expo Australia (IDG)           August 14 - 16, 2002 Australia             http://www.idgexpoasia.com/                 Communications Design Conference (CMP)           September 23-26, 2002 San Jose, California             http://www.commdesignconference.com/                 Software Development Conference & Expo, East (CMP)           November 18-22, 2002 Boston, MA                    http://www.sdexpo.com/                    News in General                 Euro Support       As many of you have surely noticed, the euro became a real paper and coins currency on the first of January 2002.  Being able to type the euro symbol is now something which will be necessary for very many computer users.   The Debian Project   have released the   Debian Euro HOWTO  by Javier Fernndez-Sanguino Pea which details how to enable support for the symbol in your Linux system.  Much of the advice will be of use to users of distributions other than Debian.   Long-term, the best solution may be a move towards Unicode. This is particularly the case when interoperability with Windows systems is required.              Athlon/Duron and Linux Bug      A bug in AMD's Athlon family of processors has been   reported  on TheRegister, following an earlier revelation by  Gentoo Linux .  The issue relates to extended memory paging sizes and is a bug in the processor, not the kernel. Those using Linux 2.4 kernels, and AGP may experience problems with memory corruption.  The fix is to pass the option ""mem=nopentium"" to the kernel at boot-time (via GRUB or LILO).  Gentoo have a good description of the situation on their main webpage at the moment, and an analysis of how this was neglected for so long (since September 2000!).              Linux Adoption                 TheRegister.co.uk  recently   reported  that Korea is to convert 120K civil servants to Linux desktop use.  This appears to be as much a fightback by local favourite Haansoft (producers of Hancom Linux, and HancomOffice) as a victory for Linux, but it is still good news.   In a separate development, NewsForge   reports  that Red Hat India is helping to introduce GNU/Linux as part of a scheme to meet the software needs of the Indian education system. The program will include not only software, but also free training to help get the scheme off the ground.   Spinning the globe again, this time to China, we see more penguins on the march.  Linux Today have a   report  that Linux is making an impression on many in China.  Apparently the Chinese Academy of Sciences have published a report highlighting the savings which could be achieved by using Linux as an alternative to Microsoft solutions.  This follows a Gartner   report  that Microsoft recently lost out on a major IT investment in China, while indigenous firms including Red Flag Linux were favoured.               Penguin Art          A new issue of TUX (Terminator Unit X) online comic is now available at:   http://www.thelinuxreview.com/TUX/ .  the reports of TUX's death have been greatly exaggerated.    Also in the artistic vein,   IBM  have updated their   Linux Cartoons  page. Flash or Real Player required.              Linux Trojan Found          qualys.com  have    announced  that they have discovered a Linux Trojan, in the wild. This follows qualys's discovery of a very similar linux trojan    last year .  This story was also   picked up  by Newsbytes.com, and from there Slashdot    got in on the act .  To be infected, you must execute the trojan as root, so there is likely to be a need for some sort of social engineering in getting this one to propagate.  Main risk would be if a binary in a Linux distribution became infected, since most people trust the binaries on their install media.  At the very least, this is another very good reason to be very very careful what you do as root.               DOSSIER, Documentation Source            DOSSIER  is a convenient new way to get printed documentation for Free and Open Source software.  Current topics include ""Email"", ""File Systems"", ""Kernel"", PostgreSQL"", ""Python"", and ""Text"".  The demand-printed volumes may be ordered from    BSDMall . The motivation and rationale for DOSSIER are covered in  ""  DOSSIER and the Meta Project (Part 1) "", in    Daemon News .           Distro News               BrlSpeak      BrlSpeak is a new mini-distribution of Linux that comes with support for  braille  and  speech  built-in.  The objective is to offer an easy-to-install solution for blind persons who wish to install a Linux distribution on their computer without any assistance from a sighted pereson.  BrlSpeak provides a built-in preconfigurer so that you should be able to preconfigure the BrlTty Makefile before starting Linux.  Compilation and automated activation of the braille device is the next step, and will be performed when booting the distrib.  BrlSpeak was based on Matthew campbell's ZipSpeak mini-distribution, that's why it contains the SpeakUp screen reader for supporting speech synthesizers.  The BrlSpeak is available in many languages.  To download it, visit the    BrlSpeak Projet Home Page .   Author: Osvaldo La Rosa, freely distributable, UMSDOS mini-distribution, size: 36MB, available as: zip or iso, website:    en ,   fr ,   nl . Any contributions welcome!                Debian         Debian GNU/Linux  2.2r5 has been released.  This fifth revision adds security updates and some bug fixes to the stable `potato' release.  A list of FTP and HTTP mirrors is available at   http://www.debian.org/distrib/ftplist . Point apt (see the sources.list(5) manual page) at an up to date mirror and then run apt-get update; apt-get upgrade The complete list of all accepted and rejected packages together with rationale is on the    preparation page  for this revision   It is a good idea to keep an eye on   http://security.debian.org/  or to subscribe to the debian security announce mailing list.  There have been quite a few security announcements in the past month.          Debian Weekly News   reported  that new ""Debian on CD"" Web Pages have been    launched . These replace the old pages on    cdimage.debian.org , which ""were often criticised by visitors of the website"". The new pages feature improved documentation, direct download links for images, a CD vendor list Apart from an extended FAQ, the new pages offer direct download links for CD images, a list of CD vendors, artwork, and info on   jigdo , the new distribution scheme for downloading CD images from any normal Debian mirror.             Linux Today  highlighted a    report  on the size of Debian 2.2, which includes more than 55,000,000 physical SLOC: The COCOMO model estimates that its cost would be close to $1.9 billion USD to develop Debian 2.2.              Also highlighted by   Linux Today  was this   bugreport , which comments on vulnerability notification and the Debian Social Contract. ""Over the past few months, the GNU/Linux community has slowly adopted a way of dealing with security issues which closely resembles the approach suggested by Microsoft last year: more-or-less systematic hiding of security problems from end users, at least for some time. Some Debian maintainers seem to participate in this process, and hold back security fixes, waiting for events to happen which are external and not related to the Debian project (for example, other distributors being ready to publish fixes).""               Mandrake         Linux Planet have started a 'Month Later'  addition to their Distribution Watch section.  The first distro to receive this    second look  is Mandrake 8.1. The review discusses the process of getting settled in and smoothing out the routine bumps and curves of this distribution.               Red Hat       The Washington Post Washtech.com site has   reported  that AOL Time Warner is in talks to buy Red Hat.  Everything is very vague (""fluid"" appears to be the official term), so it is difficult to know what the chances are such a deal actually coming off.  Andrew Orlowski of TheRegister is somewhat   sceptical  about the rumours.  He also makes some good comments about what the wider implications of such a deal could be.            Software and Product News                 GUI Based DSSSL/XSLT DocBook Tool Released            Command Prompt  is pleased to announce the release of DocPro 0.2.0.   DocPro  is a tool for professional technical authors whom maintain a large amount of SGML/XML based documentation. DocPro will take any DocBook document and transform it into a user defined format (Postscript, HTML etc...).    DocPro will correctly transform multiple documents, to multiple output formats. It includes the capability to arbitrarily set font sizes, margins, callout definitions etc... via a GUI interface.    DocPro currently runs on x86 Linux only, though there will be a release for YellowDog Linux (PPC) and MacOS X shortly. The Deluxe version of DocPro comes with the popular DocParse tools for converting HTML to DocBook.              Adobe GoLive 6 Integrates Zend PHP Debugger         Adobe Systems  will include    Zend 's PHP Debugger in its new release of GoLive 6, its flagship product for Web site development. This will give GoLive developers integrated access to advanced PHP debugging for their toughest applications and dynamic Web sites using scripting languages.              CxProtect            CxProtect  is an AntiVirus Solution for Linux Mail Servers.  It is a binary based solution that using the Command AntiVirus API.  The software offers detection and disinfection of attachments being transported via the Linux Mail Server.  The only change required to the existing Sendmail.cf is to register CxProject as the MDA.  Post-install configuration is done via a web browser interface.   Download available at   http://www.calibretechnologies.com/downloads/CxProtect.tar.gz                  Mahogany 0.64 Released         A new release of   Mahogany , has been made. Mahogany is an OpenSource cross-platform mail and news client, available for X11/Unix and MS Windows platforms. It supports many of the internet protocols and standards, including POP3, IMAP4, SMTP and NNTP. Mahogany also supports MIME and many common Unix mailbox formats.   Source and binaries for a of Linux and Unix systems as well as binaries for Win32 are    now available .                  Copyright © 2002, Michael Conry and  the Editors of  Linux Gazette .  Copying license  http://www.linuxgazette.com/copying.html  Published in Issue 75 of  Linux Gazette , February 2002        ""Linux Gazette... making Linux just a little more fun! ""                 Secure Printing with PGP   By  Graham Jenkins                    The Brother Internet Print Protocol    A recent article   ""Internet Printing - Another Way""  described a printing protocol which can be used with some   Brother  printers. It enables users of Windows machines to send a multi-part base-64 encoded print file via email directly to a Brother print server.    The article went on to show how the functionality of the Brother print server can be implemented in simple Perl program which periodically polls a POP3 server to check for jobs whose parts have all arrived. When such a job is detected, its parts are downloaded in sequence and decoded for printing.    A subsequent article   ""A Linux Client for the Brother Internet Print Protocol""  showed a  simple client program which can be used on Linux workstations for sending print jobs to a Brother print server. That program was implemented as a shell script which split an incoming stream into parts and placed them in a scratch directory for subsequent encoding and transmission.    I have since developed a Perl client program which processes the incoming stream on-the-fly and requires no temporary storage. This is, of course, a much neater way to do things. The down-side is that there is no way of ascertaining the total part-count until the last part is being processed. A slight modification to the server program was therefore required to accomodate an empty ""total-parts"" field on all except the final part.    A Hole Big Enough to Drive a Truck Through    The whole arrangement as outlined above has been in use at my place for several months, and has saved us a whole lot of time and trouble. However, as pointed out by one reviewer, what we really have here is a security hole big enough to drive a truck through! Anybody in the whole wide world can send celebrity pictures to your color printer, and there's not a lot you can do about it.    Somebody else asked why we go to the trouble of splitting a large job into parts without first trying to compress it. And indeed there are a great number of jobs whose size can be significantly reduced through compression.    Then there were the Windows (and other) users, who thought that everything should be written in Perl for portability. And the Standards Nazis, who thought that the job parts should be sent as 'message/partial' entities in accordance with RFC 2046.    Who's Printing Pamela Anderson Pictures?    Of all the issues outlined above, the most serious is indubitably that of client authentication. And the solution is blindingly obvious; why not use one of the Public Key Encryption mechanisms now available? What we need here is for the sender to digitally sign the entire message using his private key. Upon receipt at the server, the message can then be authenticated by application of the sender's public key. There's no need for any secret key-entry rites at the server, so the whole server operation can be automated.    A message signed in this fashion can be signed in 'clear' form;  the message itself is then sent as is, with a digital signature appended to its end. If you elect not to use 'clear' signing, the message will (if usual defaults are accepted) actually be compressed and the signature will be incorporated therein. This comes pretty close to what we need!    There is a set of Perl modules (Crypt::OpenPGP) which can perform the necessary signature and verification procedures, so we can actually write the entire client and server programs in a portable form. I had some difficulty with installing these, since they require that a number of other modules be installed, and they require the 'PARI-GP' mathematics package. I elected instead to use  pgp-2.6.3ia ;  GnuPG-v1.0.6  will also work with the programs in this article.    There are a couple of Perl modules (Crypt::PGPSimple and PGP::Sign) which can be used to call pgp-2.6.3ia and its equivalent executables, but each of them creates temporary files, and that's something I try to avoid where possible.    Appeasing the Standards Nazis    RFC 3156   (""MIME Security with OpenPGP"") describes how the OpenPGP Message Format can be used to provide privacy and authentication using MIME security content types. In particular, it decrees that after signing our message by encrypting it with our private key, we should send it as a 'multipart/encrypted' message. The first part should contain an 'application/pgp-encrypted' message showing a version number in plain-text form; the second part should contain our actual PGP message.   This is a bit over-the-top, but the overhead is small, and the whole deal is easily done using the Perl MIME::Lite module, as shown in the 'SEPclientPGP.pl' program hereunder.    So how do we send a long message which needs to be broken into parts for passage through intermediate mail servers? RFC 3156 tells us we should use the MIME message/partial mechanism ( RFC 2046 ) instead! I think what they actually mean is ""as well"". So our output from 'SEPclientPGP.pl' is actually fed into the 'SplitSend.pl' program (also hereunder) which extracts the message ""To:"" and ""Subject:"" lines and replicates them into each sequentially numbered 'message/partial' component that it generates.    The Client Program    Here's the  client program . It's pretty much self-explanatory. A pipe to the 'SplitSend.pl' program is opened for output. If the passphrase is supplied on the command-line (dangerous, but sometimes necessary!), it is planted in an environment variable.    The multipart MIME message as previously described is then constructed, taking its second body part from a pipe fed by the PGP executable. If the executable doesn't find a suitable passphase in the appropriate environment variable, it requests it in a terminal window.    #!/usr/local/bin/perl -w # @(#) SEPclientPGP.pl Secure Email Print client program. Ref: RFC 3156. #   Takes incoming stream and generates PGP-signed message #   which is piped to split-and-send program for email #   transmission to server. Requires 'pgp' program. #   Graham Jenkins, IBM GSA, Dec. 2001. [Rev'd 2001-12-30]  use strict; use File::Basename; use MIME::Lite; use IO::File; use Env qw(PGPPASS);  die ""Usage: "".basename($0)."" kb-per-part destination [passphrase]\n"".     "" e.g.: "".basename($0)."" 16 lp3\@pserv.acme.com \""A secret\"" < report.ps\n"".     ""       Part-size must be >= 1\n""   if ( ($#ARGV < 1) or ($#ARGV > 2) or ($ARGV[0] < 1) );  my $fh = new IO::File ""| /usr/local/bin/SplitSend.pl $ARGV[0]""; if( defined($ARGV[2]) ) {$PGPPASS=$ARGV[2]} if( ! defined ($PGPPASS)) {$PGPPASS=""""} # Plant passphrase in environment and my $msg = MIME::Lite->new(  # create signed message.                 To      => $ARGV[1],                 Subject => 'Secure Email Print Job # '.time,                 Type    => 'multipart/encrypted'); $msg->attr  (   ""content-type.protocol"" => ""pgp-encrypted""); $msg->attach(   Type    => 'application/pgp-encrypted',                 Encoding=> 'binary',                 Data    => ""Version: 1\n""); $msg->attach(   Type    => 'application/octet-stream',                 Encoding=> 'binary',                 Path    => ""/usr/local/bin/pgp -fas - |""); $msg->print($fh);   # Pipe the signed message into a __END__     # split-and-send program.     Split-and-Send    Here's the   split-and-send program . The main loop at the end works just as described above - extract the destination and subject fields, accumulate lines until we are about to exceed the message-size limit supplied as a parameter, then feed what we have to an output routine.    The output routine needs to re-insert the destination and subject fields, and also insert a message-identifier, part-number and total-part-count. The total-part-count is only required on the final part. All fairly easy - except we don't know whether the current part is the final part until we look for the next part. So we get around this by using a double-buffer arrangement, where we don't actually output a buffer's contents until we have the next buffer.    Using MIME::Simple in this program is really overkill; however, what it does accomplish is that it tries to find an appropriate mailer program on whatever platform it executes.    #!/usr/local/bin/perl -w # @(#) SplitSend.pl Splits and sends an email message (Ref: RFC 1521, 2046). #   Graham Jenkins, IBM GSA, December 2001.  use strict; use File::Basename; use MIME::Lite; use Net::Domain; my ($Id,$j,$Dest,$Subj,$part,$InpBuf,$OutBuf,$Number,$Total);  die ""Usage: "".basename($0)."" kb-per-part\n"".     ""       Part-size must be >= 1\n"" if ( ($#ARGV != 0) or ($ARGV[0] < 1) );  $Id=(getlogin.""\@"".Net::Domain::hostfqdn().time) or $Id=""unknown_user"".time; $Number = 0; $Total = """"; $OutBuf=""""; $InpBuf=""""; print STDERR ""\n"";  sub do_output {    # Output subroutine.   die basename($0)."" .. destination undefined!\n"" if ! defined($Dest);   $Subj = """"                                      if ! defined($Subj);   if ($OutBuf ne """") {   # If output buffer contains data,      $Number++;    # increment Number, and check whether     $Total=$Number if $InpBuf eq """"; # it is the last buffer.     print STDERR ""Sending part: "", $Number,""/"",$Total,""\n"";     $part = MIME::Lite->new(               To      => $Dest,  # Construct a message containing the               Subject => $Subj,  # output buffer contents.               Type    => 'message/partial',               Encoding=> '7bit',               Data    => $OutBuf);     $part->attr(""content-type.id""     => ""$Id"");     $part->attr(""content-type.number"" => ""$Number"");     $part->attr(""content-type.total""  => ""$Total"") if ($Number eq $Total);     $part->send;   # Send the message.   }   $OutBuf = $InpBuf;   # Move input buffer contents to   $InpBuf = """"    # output buffer and exit. }  while (<STDIN>) {   # Main loop.   if ( (substr($_, 0, 3) eq ""To:"")      && (! defined($Dest)) ) {     $Dest = substr($_, 4, length($_) - 4); chomp $Dest; next }   if ( (substr($_, 0, 8) eq ""Subject:"") && (! defined($Subj)) ) {     $Subj = substr($_, 9, length($_) - 9); chomp $Subj; next }   if ( (length($InpBuf . $_)) > ($ARGV[0] * 1024) ) {do_output}   $InpBuf = $InpBuf . $_ } foreach $j (1,2) {do_output}  # Flush both buffers and exit. __END__     The Art of Jigsaw Assembly    There is no guarantee that the segments of our print-job will arrive at the server in the same order as they left the client. We cannot be sure that there will even be the same number of segments, since message-transfer agents along the way are allowed to re-assemble message/partial entities as they see fit.  So what we have at the server end is a set of jigsaw puzzles, with the pieces of each puzzle being related by a common message-identifier, and their placement within that puzzle being determined by their part-numbers.    For a full listing of the 'SEPserverPGP.pl', see the attached  text version . I haven't bothered to replicate all of it hereunder, since much of it is the same as the program shown in ""Internet Printing - Another Way"".    Basically, the program is intended for invocation via an entry in '/etc/inittab', and loops continually thereafter, with half-minute pauses between each loop. During each loop, it visits the mailboxes of one or more printer-entities on a POP3 server, and deletes any stale articles therein before tabulating the message-id's and part-numbers of the remaining articles. When it finds a full set of message/partial entities, it sucks each of them in part-number sequence from the server, and throws their contents into a pipe. The program-extract hereunder shows what happens then.    The relevant message content is deemed to begin at the ""-----BEGIN.."" line in the first part. For subsequent parts, it begins after the first blank line once an ""id=.."" line has been seen.    Once in the pipe, the composite message content passes to the PGP executable for validation/decryption, and thence to an appropriate printer.  Validation output is passed to a scratch file, and then recovered from there for logging. A validation failure results in no output to the printer.              for ($k=1;$k<=$tp{$part[0]};$k++){ # Check if we have all parts.             goto I if ! defined($slot{$part[0].""="".$k});           }                $fh=new IO::File            ""| /usr/local/bin/pgp -f 2>$tmp | lpr -P $user >/dev/null"" or goto I;           for ($k=1;$k<=$tp{$part[0]};$k++){ # Assemble parts into pipe.              $message=$pop->get($slot{$part[0].""="".$k});             $l=0; $buffer=""""; $print=""N"";             while ( defined(@$message[$l]) ) {               chomp @$message[$l];   # Part 1: start at ""-----BEGIN"",               if( $k == 1 ) {   # stop before 2nd blank line.                 if( @$message[$l]=~m/^-----BEGIN/ ) { $m=-2;  $print=""Y""}                 if( $print eq ""Y"" ) {                   if( @$message[$l] eq """" ) { $m++; if( $m >= 0)   {last} }                    $buffer=$buffer.@$message[$l].""\n""                 }               }     # Part 2,3,..: skip 1 blank line               else {    # after ""id="", then start; stop                 if( $print eq ""Y"" ) {  # before next blank line.                   if( @$message[$l] eq """" )                        {last}                    $buffer=$buffer.@$message[$l].""\n""                 }                 if( @$message[$l]=~m/id=/ )                  {$print=""R""}                 if((@$message[$l] eq """") && ($print eq ""R"")) {$print=""Y""}               }               $l++;             }             print $fh $buffer or goto I;           }           $fh->close || goto I;           open $fh, $tmp;           while (<$fh>) { chomp; syslog('info', $_) }           close $fh;           for ($k=1;$k<=$tp{$part[0]};$k++){             $pop->delete($slot{$part[0].""="".$k})           }           goto I;         } J:    }      } I:}     Copycat Crime    In the scheme outlined above, there is nothing to prevent a determined trouble-maker replicating and replaying an entire authenticated message. To cover this possibility, you need to retain each log entry for a week or so, and to reject any incoming message having a corresponding signature and signature-date.    If, in addition, you wish to prevent someone from viewing the actual data travelling to your printer as it traverses the Internet, you need to change the PGP executable parameters at the client end so that the data is encrypted with the server's public key as well as signed; you will also need to feed a passphrase into the PGP executable at the server end.    GNU Privacy Guard    I have a mental image of somebody reading this and saying: ""How come he's using pgp-2.6.3ia if he doesn't like un-necessary temporary files?"" It's a good question, because pgp-2.6.3ia creates temporary files both during encryption and during decryption.    To get around this, or to comply with whatever laws are applicable in your country, you may wish to use GnuPG-v1.0.6 (or later version of the same) instead. In the client program, you will need to change the parameters with which the executable is called. And you won't be able to plant your passphrase in an environment variable.    I have attached for your interest a 'Lite'  GPG client program  which will execute on Windows machines with 'out-of-the-box' ActiveState Perl or IndigoPerl, and requires no extra modules.    During decryption to a pipe, the 'gpg' executable actually outputs data to the pipe until (and in some cases, after) it encounters a problem. So you will need to send your output to a scratch file - then send that scratch file to your printer if the decryption process completed satisfactorily.              Graham Jenkins   Graham is a Unix Specialist at IBM Global Services, Australia. He lives in Melbourne and has built and managed many flavors of proprietary and open systems on several hardware platforms.                  Copyright © 2002, Graham Jenkins.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 75 of  Linux Gazette , February 2002        ""Linux Gazette... making Linux just a little more fun! ""                 A Pioneer for a New Century -- Alan Turing, part 1   By  G James Jones   Originally published at  System Toolbox .  Reprinted with permission.                     Last time, we took a look at the life and some of the achievements, and near achievements, of  Charles Babbage , the Godfather of Computing.  Babbage made great leaps in our understanding of what would become the field of computer science by considering, and then demonstrating, that mathematical processes could be carried out quickly, repeatedly and without error through mechanical means.  This was such a simple idea, but it was ground breaking in its implications.  Babbage had been frustrated by the errors that crept into the lookup tables that serious mathematicians used for their calculations.  His drive to create calculating machines grew out of the desire to remove these errors from the process of creating those tables.  Babbage was ahead of his time. He was a pioneer of the 19th century. If his work hadn't been rediscovered, his achievements would have been almost entirely forgotten by the time the idea of  automatic calculations  through machines began to take hold in the 20th century.    One of the proponents of such  automatic, mechanical, calculations  was a mathematician in King's College, Cambridge; a young Alan Turing.  It's almost a natural progression for this series to move from the  cog wheel brains  of Mr. Babbage to the  theoretical thought machines   of Alan Turing.  Out of the necessity to answer one of the most critical mathematical questions of his time, Turing started down the road of what would become the fields of modern computer science and cryptography.  As one of the single men whose achievements helped turn the tide of World War II, he is a hero. As developer of some of the original ideas about digital computers and for helping solve Hilbert's final question of Mathematics, he is a genius.  Being human, his life is ultimately marked by complexity and, unfortunately... tragedy.    This article will focus on Alan Turing's life leading up to, and including, his invention of the ""Turing Machine.""  Next month, we will tackle his achievements in cryptography during World War II, his ideas on the digital computer, and the controversial events that led to this hero's, one of my heros, tragic death.   Early Signs of a Remarkable Mind     Alan Mathison Turing was born to Julius Mathison Turing, an Indian Civil Service officer, and Ethel Stoney on June 23, 1912 in Paddington, England. Alan's father was still under active commission in India and feared the risks of raising family in the remote provinces over which he held jurisdiction.  After Alan's birth, his father decided to leave his family in England instead of risking those uncertainties, choosing instead to make the trip back and forth between India and England while leaving his family with friends in England.    Like Babbage (and many others in this field), Turing showed early signs of, what I like to call, the ""personality disorder"" that leads to a such vocations as engineering and mathematics.  Alan's natural inquisitiveness was often confused with mischief, where ""planting"" broken toys in hopes of resurrecting them was probably interpreted as ""getting rid of the evidence.""  At a very early age, he is said to have taught himself to read in only three weeks and his discovery of numbers brought about the distracting habit of stopping at every street light in order to find its serial number. At the age of seven, while on a picnic in Ullapool, Scotland, Alan had the idea of gathering wild honey for the afternoon's tea.  By plotting the flight paths of the bees among the heather, he was able to find the intersection point that marked their hive and provide an unexpected treat for the family.    There's another anecdote that made an appearance in Neal Stephenson's spectacular work of fiction,  The Cryptonomicon , in which Turing plays a supporting role.  It seems that Alan had a bicycle that had a problem with its chain. He discovered that the chain would dislodge itself from the gears after a regular, repeatable, number of revolutions.  At first, the young Alan would count the revolutions of the gears throughout his ride until it was time for the chain to be forced to derail.  He would then get off his bike and re-adjust the chain.  As this got to be cumbersome over longer treks, he finally rigged a mechanical device that would maintain the count and readjust the chain itself. Supposedly, it never occurred to him to just buy a new chain to solve the problem. I believe that it is more likely that the chain's issues presented a unique problem set for Turing's mind to solve.  It challenged him to think in a different way.  It was challenging and fun; buying a chain was not.      Getting an Education     At the age of six, Alan's mother enrolled him in a private day school, St. Michael's, in order for him to learn Latin.  Thus began Alan's introduction into the system that would shape his intellectual and personal development for the next fourteen odd years.  The English educational system would prove to be both a conflict and a collaboration with Turing's sensibilities.  The collaboration is epitomized by his early respect for rules and their relationship to his concept of fairness.  These ideas are probably best illustrated by an anecdote of his mother skipping part of  The Pilgrim's Progress . Judging one section to be too theologically weighty for the youngster, she had skipped it while reading aloud in order to spare him.  Alan objected and felt that the story was ruined; skipping parts, in his sensibility, was against the rules of reading.    The conflict, in his relationship with the English school system, was partially rooted in Alan's resolve that he was nearly always right. Personal opinions were held as closely as fact.  He was one of those people that  knows  something and doesn't  think ,  feel  or have an  opinion  on them.  This type of mind set was definitely at odds with an education system built on tradition and firm in the belief that it  knew  what was best for its charges.    Early on, Alan was marked with the label of ""genius"" by the Headmistress of St. Michael's, a proclamation that would be echoed a few years later by a gypsy fortune teller.  Despite such proclamations, Alan was required to follow the natural order of the English school system and, upon finishing his studies at St. Michael's, followed his brother's path to his next school, Hazelhurst and then to his first  public school , Marlborough. Public school showed the ugly side of the English school system and Alan had his first troubles with bullies, proclaiming that he learned to run fast in order to ""avoid the ball.""   Brushes with Science     Alan was introduced to science through Edwin Tenney Brewster's  Natural Wonders Every Child Should Know .  Brewster's book sought to introduce topics that help children understand their place in the world and what they had in common and how they differed with and from other living things.  This discovery, and that of mathematics, would sustain Turing in a life-long love affair.  The rules and discoveries of science and mathematics fit his general sensibilities of the world; it had order and could be explored with reason. Sense could be made of life if observed in the correct way. Brewster's book was probably is the first to link the concept of machine and biology in Alan's mind, explaining that the human body was a complex  machine  with complicated processes that carried out the duties and chores of maintaining life.    While school offered many torments, it also opened up a world of knowledge to the young Turing.  He showed an early interest and ability in languages, especially French, and treated it as a code that would allow him to carry on covert communications.  Also, having always had a fascination with various process oriented activities, Alan was exposed to chemistry for the first time and fell instantly in love.  Turing would go on to dabble in chemistry for the rest of his life, often co-opting family basements and guest rooms as chemistry labs.  His habit of concocting various chemical solutions would later play a part in his untimely death as a adult.   Sherborne    At the age of 13, Alan was enrolled to attend the Sherborne boarding school.  At the time of the school's summer term of 1926, England had just been brought to a stand still by the first day of the general strike.  No buses or trains were running.  Turing made something of a stir, being reported in the local newspaper, by bicycling the sixty miles from his home in Southampton to Sherborne, staying overnight in an Inn at a halfway point.    Sherborne and Alan were not the best match.  Sherborne, as many English schools of the time, was concerned with creating  citizens  and not  scholars .  The headmaster, at the time of Alan's enrollment, espoused the idea that school was originally created to be a miniature society.  Students would learn to navigate the complexities of their later adult lives by learning to survive the power plays of their current public school life. Authority and obedience held more sway than the ""free exchange of ideas"" and the ""opening of the mind.""  Not long after arriving, the already shy Turing became even more withdrawn.    Alan sought solace in his books and course work.  In 1927, he was able to find the infinite series of the ""inverse tangent function"" from the trigonometric formula for tan1/2x (tan -1 x = x - x 3 /3 + x 5 /5 - x 7 /7 ...) without the aid of elementary calculus (Alan had yet to be exposed to it).  It was a significant enough achievement to have his mathematics instructor include himself among the roster of people that had proclaimed the boy's genius.  Such a proclamation didn't hold much sway with the school.  While the accomplishment was extraordinary, Sherborne's headmaster, not a particular fan of science, felt he was wasting his time and was in danger of becoming a scientific specialist and  not  an educated man.  This disrespect of science was not uncommon at the school.  Alan's autumn form-master, a classicist who was enthralled with Latin, called scientific subjects ""low cunning"" and felt that the only reasons that the Germans lost World War I was because they placed to much faith in science and engineering and not enough in religious thought and observance.    Alan's dogged persistence to study such  low  subjects, finally earned him some respite.  As long as he made a few concessions to the formalities of the school, he was left to his own devices.  In 1928, he became enthralled with the theory of relativity and lost himself in the English translation of Einstein's  Relativity: The Special and General Theory .  Probably one of only a few, if any, sixteen year olds who actually grasped Einstein's theories, Turing was able to fully grasp Einstein's doubts of the veracity of Galilei-Newtonian laws.  He was even able to deduce Einstein's Law of Motion (""the separation between any two events in the history of a particle shall be a maximum or minimum when measured along its world line"") from his readings alone (it wasn't specifically stated in the text). By 1929, Alan had begun to study quantum physics.  It was a heady time as Schroedinger and others turned what was considered a ""dead"" science on its head.  Schroedinger's quantum theory of matter was only three years old and Alan and his friend Christopher Morcum immersed themselves in these emerging discoveries.  Alan was in his element.   King's College    Turing had originally planned on attending Trinity College at Cambridge.  As far as he was concerned, it was the center of scientific and mathematical thought in England and he wanted to attend.  After a number of failed attempts at passing his final examinations, more out of abstinence in engaging his ""classical"" work, he finally missed a scholarship to Trinity but was able to obtain one to King's, the college of his second choice.    King's College agreed with Alan.  Though he was still somewhat of a social misfit, his studies and the freedom from the petty tortures of public school life allowed him to relax and find his rhythm.  King's also turned out to be a good fit due to the caliber of its faculty. Turing's mathematics professor was one of the most distinguished mathematicians of his time, G.H. Hardy, who had recently left Oxford to take up the Sadleirian Chair at Cambridge.  He was also among 85 other students engaged in scientific study, as compared to the one or two he had to seek out during his Sherborne days.  As happens today with many high school geeks, college offered a chance for Alan to emerge from his protective shell and begin to engage the world on his own terms.    During the 20's, Cambridge had moved to establish itself as second in the world in the field of new maths.  It had been able to stake this claim on the developments that its faculty and students were making in the realms of quantum theory and  pure  mathematics.  It was widely regarded as second only to Gottingen University in Germany, a place that supported such genius as John Von Nuemann.    Von Nuemann and Turing were to cross paths a number of times throughout their lives.  In 1932, Turing read Von Nuemann's  Mathematische Grundlagen der Quantemechanik  and was deeply affected by the text.  His interest in quantum theory continued into the studying of the works of other luminaries like Schrodinger and Heisenberg.  This exposure to the  greats  in an emerging field totally engaged the young Turing and set him to exploring the questions that their discoveries raised.  It was this exposure and new found focus that put Turing on an crash course with Hilbert's  Three Questions of Mathematics .   A Question of Mathematics and Turing Machines    In 1928, developments in  pure  mathematics seemed to be unraveling the foundations of the field.  It seemed that the world was on the cusp of unlocking the vary foundations of mathematics.  It wouldn't be long before core axioms were nailed down and mathematics would be just a set of easily applied rules that would lead directly, inevitably to the solution of any problem.  No problem would be beyond the reach of mathematics.  Appropriately applied, mathematics would make the world a better place (sounds kind of like the commotion surrounding the Internet, doesn't it?).    It was during this period, in 1928, that Hilbert, already famous for his development of Hilbert quantum spaces, posed a number of questions about the core of mathematics, whose unexpected answers would shake the field and push it into new realms of discovery and reason. Hilbert's agenda was to find a general algorithmic procedure for answering all mathematical inquiries, or at least proving that such a procedure existed.   Three of those questions at the heart of his agenda were:   Was mathematics  complete ?  Meaning, could every assertion be proven or disproven with the  rules  of math?   Was mathematics  consistent ? Meaning, could a false statement never be proven true with the  rules  of math?   Was mathematics  decidable ? Meaning, were there definite steps that would prove or disprove an assertion?      While nobody, including Hilbert, had been able to offer solutions to these questions by proof in 1928, Hilbert was confident that the answer to each was  yes .  In his mind, there had to be a solution for every problem, if only to prove that it was unsolvable. This failed assertion, as bad as it sounds, would actually save mathematicians a lot of effort spent pursuing blind alleys. So, it was still a solution; its a  math  thing.    The issue lay in  proving  that mathematics was  complete ,  consistent , and  decidable .  At the same gathering, the young mathematician Kurt Godel dealt a serious blow to this line of queries, by showing that math must be  incomplete  because, as he showed, there are assertions that can be stated that can be neither proved nor disproved.  An assertion, encoded in the form of mathematics, that said, in effect, ""this statement is unprovable"" showed this disturbing (if you are into that sort of thing) property. An attempt to prove it true or untrue leads to contradiction.  At least in the form of the question phrased by Hilbert, Godel had proved that arithmetic was incomplete.  There are nuances to this, of course, but it was still damaging.  Godel also showed that mathematics could  not  be proven consistent  and  complete.  However, he was not able to shake loose an answer to Hilbert's question as to the  decidability  of arithmetic.    Alan's professor Hardy, for one, was happy that Godel couldn't topple Hilbert's final question.  In his view, a mechanical process that could perform a solution to all mathematical problems would put every serious mathematician out of a job.  Everything would have been done.    It was time for the student to instruct the teacher, at least in part. After a day of running, an activity that Alan found to nicely clear the mind, he stumbled onto the idea of a machine of simple, though improbable, design that could tackle any sort of problem put to it. The powerful machine would only understand the digits  0  and  1 ; the first binary computer.  It would move a read/write mechanism across an infinite tape of these numbers and, based on their particular arrangement, solve various types of problems.  Alan's breakthrough was that he had defined, in specific language, what a  general algorithm  actually was.  The Turing Machine, as his construct would be called, was a thought experiment that helped codify the features of algorithms.  During his exploration of the wonderful ideas that this  machine  inspired, Turing found that, despite the simple, general, nature of his algorithm, there did exist problems that it could not solve.  This discovery  proved  Hilbert's assertions were incorrect, the answer to Hilbert's final question, the  Entscheidungsproblem  was ""no, mathematics is not decidable.""    The young mathematician from King's College, Cambridge had bested one of the greatest mathematicians of his time at the age of 23.  He gained a fair measure of acclaim for his achievement and the word ""genius"" began to be tossed around again.  Had he done only this, he would be remembered in some history books and higher math students would get acquainted with him at some point.  At any rate, a small amount of historical immortality, as obscure as it may be, would be granted in his memory.  However, it was what he did next that changed the course of human history.    Next month, we will explore the workings of a Turing Machine and follow Alan into the war effort.  We will see how a single man's true genius can turn the tide of war, and we will shake our heads in disbelief at a hero's humiliation and eventual death.  Stay tuned.    ------     © 2002 G. James Jones is a Microcomputer Network Analyst for a mid-sized public university in the midwest. He writes on topics ranging from Open Source Software to privacy to the history of technology and its social ramifications. This article originally appeared at System Toolbox ( http://www.systemtoolbox.com ). Please email  me  and let me know where it is being used.  This article is dedicated to the memory of Dr. Clinton Fuelling.  Verbatim copying and redistribution of this entire article is permitted in any medium if this notice is preserved.                       Copyright © 2002, G James Jones.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 75 of  Linux Gazette , February 2002        ""Linux Gazette... making Linux just a little more fun! ""                 Installing and using AIDE   By  Ariel Maiorano                        Introduction     If your system was compromised, chances are that the hacker, cracker, trojan, worm or whatever replaced system files, or installed new ones, generally backdoors or hostile code. Imagine a replaced version of the login program, which lets someone in with root access after supplying a magic password (like the ones included in most rootkits), or a trojanized ssh client, which emails server, user and password information to someone when used (something like this happened in an important site last year).      File integrity checkers can help us by keeping checksums or hashes, and various attributes like size, owner, permissions, etc. of files in a database to later, and regularly, compare this information checking for changes. So if the login binary is replaced, or a /tmp/.hidden/backdoord is installed, you would be alerted.      This article will try to explain how to install and use an AIDE, an open source Intrusion Detection System (IDS) of the host-based type, or file integrity checker, if you prefer. Quoting from the AIDE website...      ""AIDE (Advanced Intrusion Detection Environment) is a free replacement for Tripwire. It does the same things as the semi-free Tripwire and more.""      The installation of the whole system will be done on a floppy disk.  We'll check for changes in various files and directories, being a little paranoid. That will take more time and generate more false alarms or false positives, but I think it makes things less complicated, and, hopefully, not less secure.  When you set up your own configuration, you can start with my example, and then after a couple of weeks of use you will know what should be changed.  You'll mount the disk each time you're ready to do the checks.  That requires more steps, but if an attacker gets in, he will not be able to (A) change our database, and (B) not even notice we check our system regularly with AIDE.     Installation     First we will make the filesystem in the floppy disk... (mine is on /dev/fd0, drive A: under DOS, if you use B: under DOS you will use /dev/fd1 here.)  root@pc2:~#  root@pc2:~# mkfs /dev/fd0 mke2fs 1.22, 22-Jun-2001 for EXT2 FS 0.5b, 95/08/09 Filesystem label= OS type: Linux Block size=1024 (log=0) Fragment size=1024 (log=0) 184 inodes, 1440 blocks 72 blocks (5.00%) reserved for the super user First data block=1 1 block group 8192 blocks per group, 8192 fragments per group 184 inodes per group  Writing inode tables: done                             Writing superblocks and filesystem accounting information: done  This filesystem will be automatically checked every 37 mounts or 180 days, whichever comes first.  Use tune2fs -c or -i to override. root@pc2:~#    mount it, and create the aide directory...  root@pc2:~#  root@pc2:~# mount /dev/fd0 /mnt/floppy root@pc2:~#  root@pc2:~# mkdir /mnt/floppy/aide root@pc2:~#         Now we will get the sources of AIDE, compile them in a temporary directory, install the system in the floppy disk (pay attenton to the --prefix option when running configure), strip the aide binary before doing the make install, and finally remove the temporary directory...  root@pc2:~#  root@pc2:~# mkdir /tmp/aide root@pc2:~#  root@pc2:~# cd /tmp/aide root@pc2:/tmp/aide#  root@pc2:/tmp/aide# wget http://www.cs.tut.fi/~rammer/aide-0.7.tar.gz --12:54:47--  http://www.cs.tut.fi/%7Erammer/aide-0.7.tar.gz            => `aide-0.7.tar.gz' Connecting to www.cs.tut.fi:80... connected! HTTP request sent, awaiting response... 200 OK Length: 219,837 [application/x-tar]      0K .......... .......... .......... .......... .......... 23% @  34.84 KB/s    50K .......... .......... .......... .......... .......... 46% @  50.97 KB/s   100K .......... .......... .......... .......... .......... 69% @  65.45 KB/s   150K .......... .......... .......... .......... .......... 93% @  46.38 KB/s   200K .......... ....                                       100% @   7.17 MB/s  12:54:52 (50.40 KB/s) - `aide-0.7.tar.gz' saved [219837/219837]  root@pc2:/tmp/aide#  root@pc2:/tmp/aide# tar xvfz aide-0.7.tar.gz  aide-0.7/ aide-0.7/Makefile.in  [...]  aide-0.7/include/compare_db.h aide-0.7/include/gnu_regex.h root@pc2:/tmp/aide# root@pc2:/tmp/aide# cd aide-0.7 root@pc2:/tmp/aide/aide-0.7#  root@pc2:/tmp/aide/aide-0.7# ./configure --prefix=/mnt/floppy/aide  creating cache ./config.cache checking for a BSD compatible install... /usr/bin/ginstall -c  [...]  creating aide.spec creating config.h root@pc2:/tmp/aide/aide-0.7#  root@pc2:/tmp/aide/aide-0.7# make make  all-recursive make[1]: Entering directory `/tmp/aide/aide-0.7'  [...]  make[2]: Leaving directory `/tmp/aide/aide-0.7' make[1]: Leaving directory `/tmp/aide/aide-0.7' root@pc2:/tmp/aide/aide-0.7#  root@pc2:/tmp/aide/aide-0.7# strip src/aide root@pc2:/tmp/aide/aide-0.7#  root@pc2:/tmp/aide/aide-0.7# make install \Making install in src make[1]: Entering directory `/tmp/aide/aide-0.7/src'  [...]  make[2]: Leaving directory `/tmp/aide/aide-0.7' make[1]: Leaving directory `/tmp/aide/aide-0.7' root@pc2:/tmp/aide/aide-0.7#   root@pc2:/tmp/aide/aide-0.7# cd .. root@pc2:/tmp/aide# cd .. root@pc2:/tmp# rm -r aide root@pc2:/tmp#         Finally we will create a very simple configuration file, that will check for changes in permissions, inode number, number of links, user owner, group owner, size, modification time, creation time and md5 checksums in various directory files (including all files under them), and generate the database...  root@pc2:/tmp#  root@pc2:/tmp# cd /mnt/floppy/aide/bin/ root@pc2:/mnt/floppy/aide/bin#  root@pc2:/mnt/floppy/aide/bin# cat aide.conf database=file:/mnt/floppy/aide/bin/aide.db database_out=file:/mnt/floppy/aide/bin/aide.db.new /vmlinuz        R /boot           R /etc  R /bin            R /usr/bin        R /usr/local/bin  R /sbin           R /usr/sbin       R /usr/local/sbin R =/var/log       R /tmp            R /var/tmp        R root@pc2:/mnt/floppy/aide/bin#  root@pc2:/mnt/floppy/aide/bin# ./aide --config=./aide.conf --init root@pc2:/mnt/floppy/aide/bin#  root@pc2:/mnt/floppy/aide/bin# mv aide.db.new aide.db root@pc2:/mnt/floppy/aide/bin#    The config file is only a working example, and i use it this way, but of course you may or should change it to suit your needs, remember the database generated must reside in the floppy disk. Check the end of this document to download the example aide.conf. We can now umount the floppy and are ready for regular use (checks and updates).     Regular use (checks and updates)     Now that we have the floppy disk with the generated database we can use it regularly to check for changes in the files to be audited. I will create a file in the /tmp directory to show an example of how AIDE tell us about it...  root@pc2:/#  root@pc2:/# cat > /tmp/.hidden hidden root@pc2:/#  root@pc2:/# mount /dev/fd0 /mnt/floppy/ root@pc2:/# cd /mnt/floppy/aide/bin/ root@pc2:/mnt/floppy/aide/bin# ./aide --config=./aide.conf --check AIDE found differences between database and filesystem!! Start timestamp: 2002-01-21 15:22:56 Summary: Total number of files=1443,added files=1,removed files=0,changed files=1  Added files: added:/tmp/.hidden Changed files: changed:/tmp Detailed information about changes:  File: /tmp Mtime: old = 2002-01-21 13:36:25, new = 2002-01-21 15:22:03 Ctime: old = 2002-01-21 13:36:25, new = 2002-01-21 15:22:03 root@pc2:/mnt/floppy/aide/bin#    So here you see clearly what happened, of course if an existing file was modified you would be alerted in a similar way.      Now imagine that /tmp/.hidden is a file that you placed there, you will not remove it and wish to stop seeing it in the reports, you can update the database, like this...  root@pc2:/mnt/floppy/aide/bin#  root@pc2:/mnt/floppy/aide/bin# ./aide --config=./aide.conf --update AIDE found differences between database and filesystem!! Start timestamp: 2002-01-21 15:28:58 Summary: Total number of files=1443,added files=1,removed files=0,changed files=1  Added files: added:/tmp/.hidden Changed files: changed:/tmp Detailed information about changes:  File: /tmp Mtime: old = 2002-01-21 13:36:25, new = 2002-01-21 15:22:03 Ctime: old = 2002-01-21 13:36:25, new = 2002-01-21 15:22:03 root@pc2:/mnt/floppy/aide/bin#  root@pc2:/mnt/floppy/aide/bin# mv aide.db.new aide.db root@pc2:/mnt/floppy/aide/bin#  root@pc2:/mnt/floppy/aide/bin# ./aide --config=./aide.conf --check  root@pc2:/mnt/floppy/aide/bin#        Finally... conclusion, files, links, etc.     Remember to keep all the AIDE stuff in the floppy disk, umount and remove it after use, change the example configuration file to suit your needs, try to not leave any information in the system that may reveal to an attacker that you are using AIDE. You are encouraged to read the manual pages and manual.html of AIDE, it's a very flexible program. And finally, quoting the 'General guidelines for security' section of the AIDE manual:   "" Do not assume anything   Trust no-one, nothing   Nothing is secure   Security is a trade-off with usability    Paranoia is your friend "".      The example aide.conf configuration file:  misc/maiorano/aide.conf.txt       Home of the AIDE project:  http://www.cs.tut.fi/~rammer/aide.html    download AIDE tarball:  http://www.cs.tut.fi/~rammer/aide-0.7.tar.gz       Home of the more famous alternative to AIDE, Tripwire:  http://www.tripwire.org       Some papers and articles for further reading...      An interesting article at securityfocus.com titled 'You may already be hacked.':  http://www.securityfocus.com/columnists/12       An article at linuxsecurity.com titled 'Getting Started with Tripwire (Open Source Linux Edition)':  http://www.linuxsecurity.com/feature_stories/feature_story-81.html       'Network- vs. Host-based Intrusion Detection - A Guide to Intrusion Detection Technology' from ISS, interesting reading also:  http://secinf.net/info/ids/nvh_ids/       A more commercial point of view from NetworkWorldFusion, 'Getting the drop on network intruders':  http://www.nwfusion.com/reviews/1004trends.html                 Ariel Maiorano   I'm a free-lance programmer in Argentina, working mostly on web and security development.                  Copyright © 2002, Ariel Maiorano.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 75 of  Linux Gazette , February 2002        ""Linux Gazette... making Linux just a little more fun! ""                 GPL or BSD? Yes   By  Mark Nielsen                      What is the GPL software license?   What is the BSD software license?   Which is better for you?   Which is best for me?   Conclusion   References      Introduction    What is the GPL software license?    The GNU General Public License   is a bit lengthy (in my opinion) and tries to promote a ""community"" of programmers who share software freely and openly. It obfuscates the meaning of ""free"" and ""freedom"", since it really restricts the freedoms of people who don't want to openly share software that has the GPL license. Rick Holbert is suggesting we use the word ""liberated software"" instead of ""free software"". It still confuses me, because GNU software is not truly liberated, you can't so with the software whatever you want, but the word ""liberated"" is much better than the word ""free"".   The GPL license forces people who make changes to the software to openly share those changes. Thus, it forces freedom on the ""recipients"" of the software, but not to the ""programmers"" who make changes to the software. It can be a little confusing, since it takes freedom away from the programmers, but strengthens the freedoms of the ""recipients"" of the software. In general, for people who wish to donate their software for the better of humanity, it seems to me the GPL license satisfies those goals because the software becomes open sourced and free for all people to use and to add to.   Sometimes, from a  business perspective, you want to take software you can make proprietary  so that  you can create a product which has hidden value.  If you close source software that has value, and your changes have value, then you can charge people for the software because they can't make the software themselves or it is too difficult and time-consuming for them to do so. You want to look at the BSD-style licenses under those cases.   In a different scenario, if you care more about service rather  than software products, then the GPL license isn't something you should fear. For example, IBM is using Linux for various servers. If you develop a business model on top of GPLed software, you don't have anything to worry about. In addition, any software you create from scratch or you use that as a BSD-style license you can keep closed sourced running on top of your GPL software. There are still plenty of ways your business can use GPL software without threatening your business. Customers don't really care about how things are done, they just want it done. A good example is the crappy software produced in the most popular desktop OS. 99% of the customers who use that horrible nasty software don't know all the garbage put into it, and most of them wouldn't  care. Look at all the people who are very happy to get patches to their  ""most stable and reliable version"" of their OS, when really the logic is backwards. Shouldn't it have been stable and reliable from the beginning? And if the current version is the most stable and reliable and it crashes and has tons of bugs, then the previous versions were garbage? I keep on trying to emphasize to people that something that is more stable and reliable than garbage is still garbage that is only slightly more reliable and stable. It doesn't mean much. In business, it really isn't the quality of the product that sells, but if you meet the minimum requirements for people to use and you can sell it cheap on a mass market --- or if you can get a monopoly and brainwash people and congress with ads and money that your software is the best, when you know it isn't. Bottom line, if you are scared of the GPL license for business reasons, you probably haven't thought through your business model hard enough. The most popular Linux OS in the US isn't the  best in the world, and lacks many features a respectable Linux OS should have, but it stays the most popular because it has market share and they improve with every version, which keeps their customers happy, even though the customers don't know how much better the software really could be.    What are the BSD-style Licenses?    FreeBSD Copyright Information   has a variety of licenses. In general, you have freedom to do whatever you want with the software, as long as you acknowledge it came from the project you are working on. In some sense, you have more freedom to do whatever you want with this software, but when you make changes, you can ""restrict"" the freedom of others who receive the software you modified.    The BSD style licenses don't have any ""pass-thru"" freedoms. They don't promote ""freedoms"" for the recipient. This can be a beneficial if you wish to take software other people have developed, make a few changes, and sell the product, or just try to prevent people from understanding what you did.    When a non-programmer only understands what a piece of software does, but not how it does it, then you can sell the software to that person  with good marketing skills, even if you really didn't do any of the work in creating the software. Take the most popular OS for desktops and you will get a good idea of a company which has no programming skills whatsoever, but are very good at marketing and selling garbage for software. Having the ability to include software from other developers (who knew what they were doing) without revealing the changes you make can be a very powerful if you can't program worth a darn but you are good a selling. From a business perspective whose goal is to make money (as all businesses are suppose to do), if you can use software that falls under the BSD-style incenses, do it. You can have better control over your OS and prevent people from copying a marketable product. The top two OSes for desktops have done this.    For the record, it seems like BSD programmers are very good at what they do, so I don't want to sound like software that comes from BSD programmers can be garbage. As far as I am concerned, as long as I can look at the source code, it isn't garbage because it can always be changed, but as soon as it does get closed sourced, then it becomes garbage, because I don't know what it is really doing. All the open-sourced stuff from the BSD-style licensed software it great.   Which is best for you?  There is one important belief you must understand: A LICENSE IS NOT BETTER OR WORSE THAN ANY OTHER LICENSE except from your point of view involving the goals you want to accomplish. A license is a foundation of how people are to behave, just like a government. From a business point of view. the US has a great government where money rules all. From a humanitarian point of view other governments have better ideas and goals. But neither government  is better or worse if they accomplish the goals the people want.  If the license does what you want  it to do, then it is good for you, might not be good for someone else, but who  cares about them. Thus, ONLY IDIOTS CLAIM ONE LICENSE IS BETTER THAN ANOTHER IF THEY DON'T UNDERSTAND WHAT YOUR GOALS ARE. Once we know what your goals are with the software you are creating, then we can determine which license is best for your software. Even then, it is still an opinion open to debate.   Whenever I talk to BSD people, I usually get them to admit GPL is not a bad thing. How? As I have stated, licenses are there for people to use. Nobody is forcing you to put your software under BSD or the GPL license. Thus,  IF YOU CHOOSE to put your software under the GPL, and don't mind people having full rights to the source code, why is that bad? You agreed to it, you don't mind, and you aren't looking to make profit off of it with some closed source version, and you really don't want someone to come along and make profit  off of a closed source version off of something you worked really hard at doing when you didn't get a dime. GPL levels the playing field so that everybody has equal opportunity to make profit given the same software and they can't prevent anybody else from having an equal opportunity as well. Looks like good market driven competition to promote business and let the best people win. Again, you choose to put this software on an equal basis for all to use. If  they don't want to share like you did, fine, they can invest the millions  of dollars needed to create their own software.  Nobody is preventing them.    Please license your software under more than one license. For example, Perl is licensed under the GPL and the Artistic Licenses. If you want your software to be used with other free software, you must license it for more than just GPL. GPL tends to not work very well with other free software licenses.    One criticism of the free software community, as far as GPL goes: they are ""stealing"" the word freedom. Question: Does a dictator have the freedom to be a dictator? Yes. Freedom has nothing to do with a ""community"". Freedom means you can do whatever you want whenever you want however you want. People should have the freedom not to be free. One thing that irks me, although I understand from a political perspective why they are doing it, but the FSF and GPL dudes tend to redefine freedom what they want it to mean, but  really they are only looking a very small subset of freedom, not ALL freedom. They are interested is freedom for people to share open sourced software and in the community, but not the freedom of an individual to do with a piece a software however they wish -- such as making a closed source version of a GPLed piece of software. Hence, GPL doesn't really promote ""freedom"" in the true sense of the word freedom, but freedom for a community to use software. I don't like how they are redefining the word freedom and how some the the zealots won't even talk to you unless you use the words ""free"" and ""freedom"" in a fashion they understand. However, I suppose it is good from a political point of view, because it forces people to think about freedom and most people don't have time to think in our crazy 80 hour workweek schedules.     Now, for BSD, it is not bad either. It is meant for the programmers who like to create closed sourced programs. I understand why this is so  attractive. I understand why this is important for some people, but let me raise a very important point about BSD which doesn't make sense from a philosophical point of view:   If people create software under the BSD license, somebody can take all the work created under that license and create a closed source version where they don't have to tell people what changes they made. Thus a whole group of developers can work for years creating a cool piece of software  where  a single person or company can ""steal"" the software by creating a slightly different closed source version, promoting it as the standard,  and ruining any chance of the real programmers for the software from ever benefiting from it. I just don't understand why so many people want to work so hard to make others millionaires. GPL prevents this. It  levels the playing field for all who wish to use the software. Everybody has a fair shot.    A clear case of how dangerous the BSD license is and how it promotes a virus from spreading around (that nasty operating system from a first-rate marketing but 2-bit programming company) around the world.  Take a look at this disaster    with Kerberos . What a horrible thing to do. For myself, when an evil nasty company corrupts a piece of software and there is no legal way to force them to be cooperative with the rest of society, I will boycott all versions of that software. I cannot afford to worry about different versions that are incompatible popping up all over the place. Kerberos is ruined, and I  will never use it. Why is it ruined? The corrupted version has too much  influence in the world, that is isn't worth my time using similar software knowing one day future versions can be completely closed sourced ruining any chance of the versions I use being compatible with the closed sourced versions. The threat of not being compatible with other businesses who don't care about politics is too great for me for me to use this type of software. It is on my banned list if I can avoid using it (hopefully).   With all the benefits and complaints I have about GPL and BSD, which is best to use? Either, neither, both. Just understand what the licenses do, and if you don't mind the consequences, great! Even though I really don't like the  BSD-style licenses for my uses, if you don't mind other people taking your software and making closed sourced versions they can sell, then the BSD-style licenses might be good for you.    Which is best for me?  Which license is best for me? The answer is yes, both. However, I only use GPL. Why? I am so grateful for all the free software, I don't really create any software that can be sold (I usually create web scripts in Python), and anything I produce for the world I would want someone to take up after I am done with it, it makes sense for me to use GPL. I really don't ever see myself using the BSD-style licenses because I don't want the evil empire from taking my software and using it to make profit without revealing that they did to give other people the same shot at business. The reason why the BSD-licenses are also good for me, is because, it is an option for the future. I don't use the BSD-style licenses, but I am glad they are an option.    Conclusion     Anonymous Coward  made a good point:   I was all set to write a long essay in response, but most of the readers here would probably just appreciate a summary:  The GPL license is conducive to liberating software.  The BSD license is conducive to liberating people.  With the GPL license, the software maintains more of the freedom than the programmers who work on it.  With the BSD licenses, the programmers maintain more of the freedom with what they are allowed to do with derivative code.    I prefer to think of it as the following:    GPL promotes freedom for the end-user.   BSD promotes freedom for the programmer.      In conclusion, anybody who says one license if better than another is a simple-minded troll who doesn't understand that they can only make a judgment for themselves and not others. I really want to emphasize that these people need to be sterilized so that their DNA doesn't spread and create politicians, generals, and judges who like to make decisions for people in other subjects in life.  I have complete disrespect and contempt for anybody who makes a decision for other people about software licenses,  and limited disrespect and contempt for anybody who lets people make their decision for them. I don't mind theories about how licenses affect society, BUT DON'T CLAIM ONE IS BETTER THAN ANOTHER, because that is an opinion based on certain values, not a fact. I will accept as fact what you think is the best license for you, but not your opinion about what you think is best for other people -- that is just an opinion and  theory.     There seems to be 10 times the amount of BSD people who hate GPL. I imagine that is because Linux is tens time more popular, but I really  don't know. If FreeBSD was ten times more popular then Linux, I imagine you would have 10 times more GPL guys  moaning than the BSD guys. For me personally, I am unaware of BSD software on a daily basis, and so, I have no reason to voice my opinions actively. I suppose I really don't like people who complain about the other licenses for two reasons:     They haven't thought through the situation carefully enough to realize there is nothing wrong with licenses.    It reminds me of when I was a little younger making outrageous statements because I didn't think through problems. However, the older you get, the more boring you become, so making outrageous statements should still be a daily occurrence to prevent yourself from becoming an old fart, as long your statements are harmless.       Nuff said.     References  Thanks to Rick Holbert for suggesting how I can improve the article and for letting me know that ""liberated"" is a better term than ""free"" to use when talking about ""free software"" in the GNU sense.      Slashdot  discussion which contains a lot of good points and I think makes a good case for BSD people not to hate GPL.     If this article changes, it will be available here   http://www.gnujobs.com/Articles/24/nielsen.html                Mark Nielsen  Mark works as an independent consultant donating time to causes like GNUJobs.com, writing articles, writing free software, and working as a volunteer at  eastmont.net .                 Copyright © 2002, Mark Nielsen.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 75 of  Linux Gazette , February 2002        ""Linux Gazette... making Linux just a little more fun! ""                 The Foolish Things We Do With Our Computers   By  Mike ""Iron"" Orr                    Drill   By  Tony Pepin     This happened a long time ago, when a 20-megabyte hard disk was a giant, both in capacity and size. My friend had a Corvus 20 meg drive that was shared among five PCs which were used to run the accounting department of a small manufacturing business.  The owner of the company was extremely pleased with my friend and the efficiency of the computerized accounting group.    One day, in the middle of month-end processing, the electric motor on the Corvus burned out. Payroll and Accounts Receivable needed to be done by the end of the day, and there were no backups of the data files.  Since the Corvus had never failed, my friend had not bothered making backups.    Not having anything to lose, he opened up the case and removed the burned out motor.  He then took an old electric hand drill with a variable speed motor and chucked it directly to the hard disk.    I wrote a quick and dirty program that read one sector of data and displayed a message when the read was successful.  He ran this  program while squeezing the trigger on the drill until it reported successful reads.    Once he had the speed right, he used black tape and taped the trigger so that it would not move.    The accounting group finished their month-end processing using the  drill as the hard disk motor.  He continued to use the drive with the drill for several weeks, after carefully making backups of the data however.          Zap   By  John J Tobin     Here is a foolish story of what I did to a computer I was building.    Back before I had a lot of money to buy new hardware and such I had to make due with the few parts that I had lying around. One was an old XT case with a working power supply, I had enough money to get a motherboard and a DX4-100 chip, however cases and power supplies were expensive back then so I decided to use the XT case that I had. Since the XT motherboards were non-standard as far as mounting holes go and the new board wouldn't line up I had the great brainstorm to mount the board on the anti-static bag, I though ""Sure it's anti-static it'll be safe."" I ran it and it would boot up but the keyboard controller was failing. I took it back to the place that I bought and and I was explained to how the anti-static bag will actually conduct electricity and that I fried the board. Luckily he was willing to refund me half of my money, I then had to shell out for another board and a case this time. The lesson I learned was that if I am going to mount a board on anything but the pegs of the case I better use wood, something that is definitely and insulator.             By  Kirk      Here follows the story of  the geekiest use I've ever put my Palm III to.    I bought a Used Sparc Classic and it came with a hard drive, RAM,  keyboard and mouse.  It did  not  come with a monitor.  Since I planned  for it to be a server, the lack of a monitor wasn't a big deal except  that I couldn't install Linux on it (or anything else for that matter)  without being able to see what I was doing.    Palm III to the rescue!  I had a serial cable that plugged into the  bottom of the Palmpilot connected to a gender bender, connected to a  DB25 <-> DB9 cable to plug into the serial port of the Sparc.  The  serial port on the Sparc actually has the wiring for both /dev/ttyS0   and  /dev/ttyS1, but the first serial port has the same wiring as a PC,  so it worked fine.  Last but not least, I unplugged the keyboard.    Now that the hardware side was figured out, I downloaded a freeware  vt100 program for my Palmpilot and configured it for the proper baud  rate, stop bits and such.  When I turned on the Sparc, it tried to find  a keyboard and failed.  Then it found a vt100 terminal on the serial  port and used the Pilot as a console.  I installed RedHat 6.2 to my  Sparc using that tiny little screen.    After the install was done, I rebooted and telnetted in from my PC.   Everything worked perfectly.      [If you have a story about something foolish or ingenious you  did to your computer, send it to   gazette@ssc.com -Iron.]               Mike Orr    Mike (""Iron"") is the Editor of  Linux Gazette .  You can read what he has to say in the Back Page column in this issue.  He has been a Linux enthusiast since 1991 and a Debian user since 1995.  He is SSC's web technical coordinator, which means he gets to write a lot of Python scripts. Non-computer interests include Ska/Oi! music and the international language Esperanto.  The nickname Iron was given to him in college--short for Iron Orr, hahaha.                   Copyright © 2002, Mike ""Iron"" Orr.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 75 of  Linux Gazette , February 2002          ""Linux Gazette... making Linux just a little more fun!  ""                          Simple Package Management With Stow     By  Allan Peda                            When running a single box with tried and true software, tracking the versions  of software that you use may be a no-brainer. That is to say, you use whatever Red Hat, Debian, or Sun provided (yes, I will touch on non-Linux issues here) if you could find or build the necessary package. But wait: what if you have been running the same machine for years and you simply must have the latest Emacs?  What if you are developing your  own   software and don't want to create RPMs, or Debian dpkg each time you pause  at a version? What if you don't trust that software package written by a 14 year old in that far away country with an unstable government? In short, what if you are heeding  Obi-Wan Kenobe's advice, and  using the source ? How do you make it easy to rip out those configuration files, man pages, binaries, and libraries that you may want to replace in the future?                              Well, when you think about it a little bit, Unix has sort of provided  the raw materials to do that, in the form of a symbolic link or  symlink  . Symlinks are a powerful tool because they allow you to configure software  so that its  implementation  does not necessarily connect directly  to it's  interface  (sound familiar?). I might be playing a  little loose with the definitions, but that really is what is being done  when, for  example, postfix mimics sendmail. The implementation, that is postfix,  is presenting the same interface as sendmail, which has become a de facto standard  interface to the Unix mail transport agent ( MTA ).                           In the case of symlinks, you might have a program  /opt/bin/new_cat  linked  to  /opt/bin/cat .  So if you looked at the link, you'd know right away what version was being run, but it would still seem to be the same familiar program. In this way the actual program being run can change as a better implementation (algorithm, etc.) is developed.  Yes, environmental variables, as used in scripts, allow this, but try retrofitting all the variables that point to a program after the fact.  It might not be so easy.  Symlinks may be the answer. For example symlinks are typically used to ease the building of  motif  from source via the  lndir  utility.  Of course this symlinking stuff could get out of hand, and should not be abused, but you get  the idea. What the folks at the GNU project did was write a little  Perl script that automates  that entire process of symlinking the  code you are using to the interface that you want to present to the user.  Note that  hard links  are subtly different, because there is no differentiation  between the original file and the link (really a second name since they share inodes, and hence   are  identical). I find hard links to be of minimal  use, because it becomes too easy to lose track of which filename should be deleted and which should be kept.                            Introducing Stow                           Right away I want to emphasize that  stow  is not a replacement for a full package management database, but it does allow one to get many of the  benefits of a complex package management system from a humble Perl script. As an aside, there is a package that  will allow source to be entered into a Slackware, RPM, or Debian package database, called   checkinstall   . As an example I will go through the steps to install stow, then the steps to install a mail ( MUA )  replacement called  nail   . This is a good example because it includes multiple files so that you can see how one might encounter inadvertant collisions with previous versions.  Also, nail a great enhancement to standard Berkeley mail, since it allows sending  binary attachments on the command line, while offering the same base functionality.        Stow is so simple to install that really no in depth discussion is needed.  It should work if you have Perl 5.005 or later (this version is stock on Solaris 8 AFAIK). Simply download the source from the GNU website or a local  mirror , extract to a source directory with tar xzf and repeat the familiar  ./configure  ,  make , and  make install  sequence.  Despite appearances,  nothing is compiled, but a few things like the manual still need to get built.  The  make install  step will place  stow  into the   /usr/local/bin  directory.  This is the default location, and  I chose this setting to simplify this discussion.  The reasons  will hopefully become apparent by the end of this article. The  location of the installed  stow  executable is shown on the last line of the  sample output below. I used   the  type  command, but you could also use  which  or perhaps  whereis .             Unpacking and installing stow                                                                                                             [zippy@mybox zippy]$ cd src/ [zippy@mybox src]$ gunzip -c ../stow-1.3.3.tar.gz | tar xf - [zippy@mybox src]$ ll total 8 drwxrwxr-x    2 zippy   zippy       4096 Jan  6 06:19 stow-1.3.3 [zippy@mybox stow-1.3.3]$ ./configure  creating cache ./config.cache checking for a BSD compatible install... /usr/bin/install -c checking whether build environment is sane... yes checking for mawk... no checking for gawk... gawk checking whether make sets ${MAKE}... yes checking for a BSD compatible install... /usr/bin/install -c checking for perl... /usr/bin/perl updating cache ./config.cache creating ./config.status creating Makefile creating stow [zippy@mybox stow-1.3.3]$ make make: Nothing to be done for `all'. [zippy@mybox stow-1.3.3]$ sudo make install make[1]: Entering directory `/home/zippy/src/stow-1.3.3' /bin/sh ./mkinstalldirs /usr/local/bin  /usr/bin/install -c stow /usr/local/bin/stow /bin/sh ./mkinstalldirs /usr/local/info  /usr/bin/install -c -m 644 ./stow.info /usr/local/info/stow.info /bin/sh ./mkinstalldirs /usr/local/man/man8  /usr/bin/install -c -m 644 ./stow.8 /usr/local/man/man8/stow.8 make[1]: Leaving directory `/home/zippy/src/stow-1.3.3' [zippy@mybox stow-1.3.3]$ type stow stow is /usr/local/bin/stow                                                  At this point  stow  is installed under /usr/local/bin. Make sure to include this directory your  $PATH    Under The Hood    To describe  stow , one first needs to understand the  configure  script, because these two scripts work together, with  configure  building all the software components, and  install ing them on your machine.  The configure script is a marvelous convenience.  It sniffs  the system, checking for various prerequisite software.  The results of these tests are used to design a set of  Makefile s  which will build and install your software to fit your system configuration. There are many options to configure, in fact there are alternate versions of this script as well, but for our purposes the options of greatest interest is the  --prefix  argument.  Note a second argument, the  --exec-prefix  allows some finer tuning  of the actual installation process, but this option will not be discussed in much detail.     So now we understand that  configure  builds the scripts that build the code, and that the location of the installed code may be specified via  configure 's  --prefix  command-- line argument.  It turns out that if you pick a single special spot to install all source code,  stow  can then cleanly automate the creation of symlinks to the installed code in such a way that the source tree is readily evident, and can be replaced and removed.  For example, invoking the configure script as   ./configure --prefix=/opt/stow/foo-1.2.1    will install your package under  /opt/stow/foo-1.2.1        I'm Still Confused. What is this prefix and exec-prefix stuff?    Feel free to skip this section, and come back to it later, after you have digested the rest of this article. Once you are comfortable with the notion of an  actual  install location being separate from the  apparent  location of a program you can consider the parts of the puzzle that don't fit the this ideal scenario.  Imagine the case of installing software across multiple machines where  everything  is installed in a symlinked directory tree isolated from the apparent location (found in the  $PATH , or  $MANPATH ).  Depending on your intentions, this might not be what you want.   Consider the situation where an application might be built for multiple architectures, for example source code could be built for Solaris and linux systems as follows (assuming an identical cross mounted source trees, but separate build directories):    sun$ cd sunsparc sun$ ../foolib-1.1/configure --prefix=/usr/local \ > --exec-prefix=/usr/local/sunsparc sun$ make sun$ make install    Then from another xterm:  sun$ ssh pengie pengie$ cd linux pengie$ ../foolib-1.1/configure --prefix=/usr/local \ > --exec-prefix=/usr/local/linux pengie$ make pengie$ make install      The bottom line is that the developer has to decide which files are architecture dependant, and which are not, and you might not agree with her.  Obviously documentation, and possibly configuration files could be considered architecture independent.  Still, if you use stow, you are free to remove symlinks by ""unstowing"" files. Since this does  upgrading will not overwrite the old source, instead it will only  break the links, and you can hand copy configuration files back.  Just ""restow"" the package and try again you get the upgrade  right. Personally, I don't use the  --exec-prefix  option  much, preferring instead to manually link the (hopefully) few configuration files that I want to treat specially, fixing broken links after upgrading. So far I think it's been a good approach for the simple situations I've encountered.       Installing Software With Stow    When I first started using  stow  a few years ago, I had some frustration with it because I had already started setting up the system (an HP-UX server) without it.  There were frequent collisions with info files and manpages, ironically this was encountered the most with emacs.  Naturally, following what is going on is easier for simple packages.  The MUA software  nail , is about as simple as you can get, since it consists of the executable, the documentation, and the config files (while you might want to link to  /etc  BTW).           Configuring for alternate locations                                                                                                             [zippy@mybox src]$ gunzip -c ../nail-9.29.tar.gz  | tar xf - [zippy@mybox src]$ cd nail-9.29/ [zippy@mybox nail-9.29]$ ./configure --prefix=/opt/stow/nail-9.29 creating cache ./config.cache checking for a BSD compatible install... /usr/bin/install -c checking for iswprint... yes ... ..... lots of stuff ... updating cache ./config.cache creating ./config.status creating Makefile creating config.h [zippy@mybox nail-9.29]$                                                 What we are doing here is telling  configure  to put the files under  /opt/stow/nail-9.29   but (implicit as far as stow is concerned) that the installed package will appear to be under /opt for run time files. ( If you're curious, you can look at the generated  Makefile  to see that the  prefix  variable is set via the  --prefix  option).                 Building the source code                                                                                                             [zippy@mybox nail-9.29]$  [zippy@mybox nail-9.29]$ make              gcc -DHAVE_CONFIG_H -I. -I. -I.     -g -O2 -c version.c gcc -DHAVE_CONFIG_H -I. -I. -I.     -g -O2 -c aux.c ... more stuff ... gcc -DHAVE_CONFIG_H -I. -I. -I.     -g -O2 -c tty.c gcc -DHAVE_CONFIG_H -I. -I. -I.     -g -O2 -c vars.c gcc  -g -O2  -o nail  version.o aux.o base64.o cmd1.o cmd2.o \ cmd3.o cmdtab.o collect.o dotlock.o edit.o fio.o getname.o \ head.o v7.local.o lex.o list.o main.o mime.o names.o popen.o \ quit.o send.o sendout.o smtp.o strings.o temp.o tty.o vars.o   [zippy@mybox nail-9.29]$                                                   Now that we have compiled everything, we can install the software.                              Running the Install                                                                                                             [zippy@mybox nail-9.29]$ sudo make install make[1]: Entering directory `/home/zippy/src/nail-9.29' /bin/sh ./mkinstalldirs /opt/stow/nail-9.29/bin mkdir /opt/stow mkdir /opt/stow/nail-9.29 mkdir /opt/stow/nail-9.29/bin   /usr/bin/install -c  nail /opt/stow/nail-9.29/bin/nail /bin/sh ./mkinstalldirs /opt/stow/nail-9.29/man/man1 mkdir /opt/stow/nail-9.29/man mkdir /opt/stow/nail-9.29/man/man1  /usr/bin/install -c -m 644 ./nail.1 /opt/stow/nail-9.29/man/man1/nail.1 test -f /etc/nail.rc || \         { /bin/sh ./mkinstalldirs /etc; \         /usr/bin/install -c -m 644 ./nail.rc /etc/nail.rc; } make[1]: Leaving directory `/home/zippy/src/nail-9.29' [zippy@mybox nail-9.29]$                                                  So it's apparent from the previous listing that the file was  tucked under /opt/stow/nail-9.29 as desired.  Stow then assumes that all the subdirectories of the package are to be symlinked to their corresponding locations under  --prefix   (or  ${prefix}  if you look in the Makefile), so that  /opt/stow/nail-9.29/bin  becomes  /opt/bin   Similarly  /opt/stow/nail-9.29/man/man1  becomes  /opt/man/man1  etc. This convention makes it very easy to isolate files  used from the install locations.  The only step left is to actually create the symlinks by running stow.             Stow ing the binaries                                                                                                             [zippy@mybox nail-9.29]$ cd /opt/stow/ [zippy@mybox stow]$ sudo stow -vv nail-9.29/ Stowing package nail-9.29... Stowing contents of nail-9.29 Stowing directory nail-9.29/bin LINK /opt/bin to stow/nail-9.29/bin Stowing directory nail-9.29/man LINK /opt/man to stow/nail-9.29/man [zippy@mybox stow]$ ls -ltr /opt/  [zippy@mybox stow]$ ls -ltr /opt  total 4 drwxr-xr-x    3 root     root         4096 Jan  9 16:33 stow lrwxrwxrwx    1 root     root           18 Jan  9 16:33 man -> stow/nail-9.29/man lrwxrwxrwx    1 root     root           18 Jan  9 16:33 bin -> stow/nail-9.29/bin stow/nail-9.29/bin [zippy@mybox stow]$ PATH=/opt/bin:$PATH type nail nail is /opt/bin/nail                                                  Some explanation may be in order here, I cd'd to the stow directory ( ${prefix}/stow  by default), and simply typed  stow -vv  plus the name of the subdirectory  to recursively symlink.  The -vv simply adds verbose output for illustrative purposes.  So now all that needs to be done is to modify the $PATH variable,  and your files are installed. Stow has created all the necessary links. Note that to uninstall the files (thus breaking the links) simply  unstow  them. This will disconnect (unlink) the installed binaries, but will  not  delete any files, so it's really quite a useful safety net.                                                   Unstowing a directory                                          [zippy@mybox stow]$ pwd /opt/stow [zippy@mybox stow]$ ls -l total 4 drwxr-xr-x    4 root     root         4096 Jan  9 16:33 nail-9.29 [zippy@mybox stow]$ sudo stow -Dvv nail-9.29/ Unstowing in /opt UNLINK /opt/bin UNLINK /opt/man [zippy@mybox stow]$                                                     And all the installed files are neatly out of the way.  Of course to   restow  the files you simply repeat the previous commands. This may seem like a lot of extra work, but once you get in the habit of using it, and experience the convenience of being able to unlink and entire package you'll find it's worth it.  Finally, you might want to install nail yourself, and use it, possibly via an alias or shell function, as a mail replacement. But that could be an entire article in itself.         Happy hacking!                              References         GNU stow               Maintained by Guillaume Morin                      http://www.gnu.org/software/stow/stow.html         GNU stow entry on Savannah                      http://savannah.gnu.org/projects/stow                Checkinstall               by Itzo                http://freshmeat.net/projects/checkinstall/               Nail, a replacement for the mail MUA               by Gunnar Ritter               http://omnibus.ruf.uni-freiburg.de/~gritter/               Linux Filesystem Hierarchy Standard, (FHS)               Maintained by freestandards.org        http://www.pathname.com/fhs/               GNU Autoconf, Automake, and libtool               By Gary V. Vaughan, Ben Elliston, Tom Tromey, and Ian Lance Taylor        offers an excellent review of the concepts behind exec-prefix options       to the  configure  script.                http://sources.redhat.com/autobook/        ISBN 1-57870-190-2                                                             Allan Peda   Allan has been enjoying Linux since about 1995, discovering Perl shortly  thereafter. Currently he works as a programmer analyst at Rockefeller University, and does part time Linux consulting work in the NYC area.  He enjoys surfing and sailing, and dreams of owning a charter boat in  tranquilo  Costa Rica.                     Copyright  2002, Allan Peda.   Copying license  http://www.linuxgazette.com/copying.html    Published in Issue 75 of  Linux Gazette , February 2002           ""Linux Gazette... making Linux just a little more fun! ""            Why I wrote Install Kernel (ik) and How It Works       By  Justin Piszcz        ik (Install Kernel) is available at  http://freshmeat.net/projects/ik  and  http://www.ramdown.com/war/ik .  In December 2000, after four years of using Linux, compiling and installing kernels became a waste of my time. I chose to write my own kernel installation and setup script called Install Kernel, because no other scripts existed at the time, and I needed something that would install the Linux kernel and automatically setup my bootloader configuration file with no user intervention. Install Kernel interfaces with the Linux operating system by moving and editing files. When not using ik, the majority of time consumed when updating a kernel mainly consists of moving files around and setting up configuration files. The ik script has three basic parts: dependency checks, compiling the kernel and moving the files to their proper locations, and editing boot loader configuration files. Install Kernel aims to help  people who are either new to installing the kernel or people who choose to use their time efficiently.  Every operating system has some type of kernel; the kernel is the core of the operating system. The current kernel version as of this writing is Linux 2.4.17. Most users either recompile or upgrade their kernels. One may choose to upgrade his or her kernel in order to add support for a certain device attached to his or her computer. For instance, if one bought a Universal Serial Bus (USB) scanner, he or she would have to make the appropriate changes to the kernel configuration file, and recompile and install the new kernel. Reasons for upgrading the kernel may include a better virtual memory subsystem, or important security fixes. An example would be Linux kernel version 2.4.11. This kernel was vulnerable to a symlink denial of service attack, prompting users running 2.4.11 to immediately upgrade to 2.4.12 when it became available due to this vulnerability. These are the fundamental reasons of why one may want to either recompile or upgrade his or her kernel.  Install Kernel interfaces with the Linux operating system by running a series of functions or groups of commands that automate the compiling or recompiling and installation process. It consists of three groups of functions: checking dependencies, building the kernel and moving files, and editing the boot loader configuration file. Grouping all of the functions in these three groups makes maintaining and altering the script much easier. Install Kernel can also be considered a program, because a program does checking and makes choices accordingly. A script is usually a file, which contains a certain number of commands with no logic in mind. Therefore, while ik is technically a script, it can also be called a program.  Dependency checks are to make sure the current system configuration and settings are properly setup before proceeding with the kernel build. There are seven dependency checks, they are: a root check, space check, link check, boot check, boot loader check, configuration check, and a module check. First, the root check makes sure the user is a super user; which means they are capable of editing important system files only accessible to the root account. The space check makes sure there is at least 200 megabytes available. The kernel source these days is around 150 megabytes just for the source code. When one compiles the kernel, it may increase the size to 50 megabytes or more. Therefore, ik checks for at least 200MB available in order to successfully compile the kernel without running out of space. Next, it is not required, but it is standard to have a symbolic link of /usr/src/linux pointing to /usr/src/linux-x.y.z. The fourth check makes sure the user has a /boot directory, this is where the Linux kernel files will be installed to. The fifth check determines the bootloader that will be used. There are two main boot loaders in Linux. LILO and GRUB are the two most popular for booting the operating system. This check accurately finds whether the kernel was booted from either LILO or GRUB by checking which bootloader was used last. It then tells the rest of the script to edit the correct one accordingly. The sixth configuration check is to make sure users have created a proper kernel configuration file, which is used in the process of building the Linux kernel. The final check is a module check, if modules are turned off, the script will determine this and alter the installation process to install with no module support. The main idea behind the depdency checks is to make sure the user cannot damage his or her system if they do not do something right.  The installation process also contains seven functions. The installation process is usually several commands. However, because of the differences that can occur in a user's configuration file, each part of the building process must be checked and the building process may need to be altered. The first function makes sure the dependencies are setup correctly for all files in the kernel source tree. The second function deletes stale object files and or old kernel files. Next, the third function is the kernel build function; this function runs a command to build the Linux kernel. Next, functions four and five make and install modules if the user had specified module support in his or her kernel configuration file. The sixth function moves the Linux kernel and its System dependency map to the boot partition. The last function of the build process sets up module dependencies for the new kernel if modules were defined. The installation process also includes a small error check for each part of the kernel build process. If any part of the kernel build process fails; the script will abort, not modifying any boot loader configuration files. This is important; because if it did not abort, it may alter the boot loader configuration files, thus rendering the system unbootable. It is important to support every Linux configuration possible because of the wide use of this script.  The boot loader configuration and setup process is probably the most important aspect of installing a new kernel. An improper boot loader configuration may leave one with system that does not boot; or simply does not boot the new kernel. It is also important, as some systems may have two or more boot loaders installed. There are four functions defined for this process. The first function uses the boot loader, which was defined during the configuration checks. The second function defines where the LILO or GRUB configuration files are located. Next, depending on which boot loader is found, either LILO or GRUB configuration files are edited automatically by sed. Sed is a stream editor, which edits a file with no user intervention. If user intervention were required, the user would have to be present between certain parts of the kernel installation. With ik, it makes efficient use of a user's time because only one command needs to be entered to complete the entire installation and setup process.  Install Kernel is a useful tool for those who are new to Linux, rebuild their kernel often, or value their time. It reduces the commands for installing the kernel from about thirteen to one. Users new to Linux may find this attractive. This is because the entire process is automated; and if something is not correct, in most cases ik will notify the user what is incorrect, and how to fix the error. On the other side, for experienced users who do not wish to spend valuable time installing a new kernel, this is also very handy. Install Kernel is efficient by requiring no user intervention and reducing time spent on kernel installs, and effective by giving new to Linux the option for an easy kernel upgrade.           Copyright © 2002, Justin Piszcz.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 75 of  Linux Gazette , February 2002       ""Linux Gazette... making Linux just a little more fun! ""                 Writing Documentation, Part III: DocBook/XML   By  Christoph Spiel                    To cite from ``DocBook -- The Definitive Guide'' (see  Further Reading  at the end of this section),  DocBook provides a system for writing structured documents using SGML or XML . In the following, I shall focus on the XML-variant of DocBook, because the SGML-variant is being phased out.    DocBook has been developed with a slightly different mindset than the  systems I discussed in the two previous articles   ( POD article ,   LaTeX/latex2html article ).       ``Text'' in a DocBook document is better understood as ``textual data''. Along the same lines, a DocBook document is better thought of as a human-readable database.    DocBook, as a standard, prescribes how valid documents must be formed and how the output produced from a DocBook document has to ``look''. I put quotes around ``look'', because DocBook documents are not restricted to being viewed on a screen, but can also be transformed into speech, for example in a car navigation system. (Imagine your SUV asking you: ``Do you want to install KDE version 3 now?'')    When transformed into any output format, DocBook documents are rigidly verified whether they conform to a given structure. This structure is defined in so-called document type descriptions, or DTDs for short.    By changing the DTD, almost arbitrary constraints can be imposed on a DocBook document. For example, an organizing committee of a conference might adapt the DocBook DTD in such way that all the article of the conference's proceedings will have a uniform look and all the necessary author information.        The particular features of DocBook mentioned, imply uses of DocBook documents that are not possible, at least not easily, with POD or LaTeX documents.      Because of their structure, DocBook documents are easily created, modified, or queried programmatically.    For example, we load the  XML::DOM  module into Perl to access XML compliant documents, and Python ships with the  xml.dom  module, which has been designed for the same purpose.    The World Wide Web Consortium (W3C,   http://www.w3c.org)  has even defined a language for XML translations, called XSLT (see for example   http://www.w3.org/TR/xslt  and   http://www.oasis-open.org/cover/xsl.html).  XSLT itself is a language defined within the SGML framework, which makes XML and XSL look quite similar: loads of angle brackets.      Various tools transform DocBook sources into HTML, TeX, GNU Texinfo and many other -- including audio -- formats. This is again different to the source formats we looked at before, where only a single application does the transformation.    Popular transformation tools are:      OpenJade (http://openjade.sourceforge.net/), which uses DSSSL (see for example   http://www.jclark.com/dsssl/  and   http://www.oasis-open.org/cover/dsssl.html),  as a Lisp-like language to describe the transformations from XML-DocBook to HTML, TeX, and so on and    Saxon (http://saxon.sourceforge.net/), which uses XSL to do the job.      The installation of both tools including the necessary  DSSSL stylesheets  or  XSL stylesheets  is quite tricky, thus I would like to recommend to beginners the installation from   .deb  or  .rpm  packages.        Being general purpose translators, both tools are not restricted to transforming DocBook documents. If you feed them the right style sheets, they will do other translations, too.    Syntax    The DocBook/XML syntax resembles HTML. The fundamental difference between the two being the strictness with which the syntax is enforced. Many HTML browsers are extremely forgiving about unterminated elements, and they often silently ignore unknown elements or attributes. DocBook/XML translators reject non-DTD complying input with detailed error messages, and refuse to produce any output in such cases.     DocBook/XML is spoken in several variants, where the variants differ in interpreting the closing tag of an element. The most verbose dialect always closes  <tag>  with  </tag> . Another variant allows for abbreviating the closing tag to  </> , yet another allows dropping the closing tag for empty elements all together. I prefer writing out every end tag, a style that has proven advantageous in deeply nested structures such as nested lists. So, in this article only the form  <tag> ... </tag>  will appear.    Special characters are written with the ampersand-semicolon convention as they are in HTML. The most frequently used special characters are      Ampersand, `` &amp; ''    Less-Than Sign, `` &lt; '' and    Greater-Than Sign, `` &gt; ''.      Comments are bracketed between `` <!-- '' and `` -- >''.    Document Structure    As already mentioned, DocBook documents must adhere to the structure that is defined in a DTD. Every document starts with selecting a particular DTD:        <!DOCTYPE                                       (1)      book                                           (2)      PUBLIC ""-//OASIS//DTD DocBook XML V4.1//EN""    (3)      ""/usr/share/sgml/db41xml/docbookx.dtd""         (4)      [ ]                                            (5)     >     where I have broken the expression (from ``<'' to ``>'') into several lines for easier analysis, and added numbers in parentheses for reference.    Part (1) tells the system that we are about to choose our DTD. Part (2) defines element  book  to be the root element of our document. part (3), the public identifier selects the DTD to use. The public identifier is the string in quotes. The system identifier, part (4) tells the translation tools where to find the DTD on the local computer system. Within the square brackets, part (5), we could place so called entity definitions, but I do not want go into detail on entities in this introduction, so we leave this space empty.    Now, we start the text with the root element, in our case  book . What elements go into  book  is defined in the DocBook DTD. These are, for example,  bookinfo  or  chapter . For a comprehensive list of allowed elements, consult ``The Definitive Guide''. The elements allowed within  bookinfo  or  chapter  are also defined in the DocBook DTD as are all elements. The only way constructing a valid document is by obeying all the rules prescribed by the DTD.    What might look like a drag on first sight -- Rules? Rules suck! -- is the key to open up the document to programmatic access. As the document complies to the DTD, all post-processing can rely on that very fact. Good for the programmers of the post-processors! I have to admit that the number of elements and the elements' mutual relationships is tough to pick up. However, the relations are logical: a chapter contains one ore more (introductory) paragraphs and one or more Level 1 sections. No section, on the other hand, contains a chapter, that would be nonsense. Having a copy of ``The Definitive Guide'' right next to the keyboard also helps to learn DocBook. Further down, there is a short compilation of commonly used tags.    Here comes a very short, but complete DocBook document.        <!DOCTYPE book PUBLIC ""-//OASIS//DTD DocBook XML V4.1//EN""                           ""/usr/share/sgml/db41xml/docbookx.dtd"" []>         <book>         <bookinfo>             <title>XYZ (version 0.8.15) User's Manual</title>         </bookinfo>             <chapter id = ""chapter-introduction"">             <title>Introduction</title>                 <para>                 This chapter provides a quick introduction to XYZ.             </para>                 <sect1 id = ""section-syntax"">                 <title>Syntax</title>                     <para>                     In this section we present an outline of the                     syntax of the XYZ language.                 </para>             </sect1>                 <sect1 id = ""section-core-library"">                 <title>Core Library</title>                     <para>                     Even if no additional libraries are loaded to a                     XYZ program, it has access to some core library                     functions.                 </para>             </sect1>         </chapter>             <chapter id = ""chapter-commands"">             <title>Commands</title>                 <sect1 id = ""section-interactive-commands"">                 <title>Interactive Commands</title>                     <para>                     ...                 </para>                     <sect2 id = ""section-interactive-commands-argumentless"">                     <title>Argumentless Commands</title>                         <para>                         ...                     </para>                 </sect2>             </sect1>                 <sect1 id = ""section-non-interactive-commands"">                 <title>Non-Interactive Commands</title>                     <para>                     ...                 </para>                     <sect2 id = ""section-non-interactive-commands-argumentless"">                     <title>Argumentless Commands</title>                         <para>                         ...                     </para>                 </sect2>             </sect1>         </chapter>     </book>     Useful Tags    To help the aspiring DocBook writer making sense of the loads of elements, the DocBook standard defines, I have compiled a bunch of useful tags, which are used often.    Root Section Tags    Root section tags define the outermost element of any document.      book      <book>      I<paragraphs or chapters>     </book>      article      <article>      I<paragraphs or level 1 sections>     </article>        Sectioning Tags    Sectioning elements divide the document into logical parts like chapters, sections, paragraphs, and so on.       chapter ,  sect1 , ...,  sect6      <chapter id = "" label "">    title    followed by    paragraphs or level N+1 sections    </chapter>    Define a section. Commonly, chapter and section elements carry the   id  attribute, which allows for referencing the elements with, for example, <xref linkend = ""label""></xref>.      para      <para>    paragraph text    </para>    Group several lines of text together to form a paragraph. This is the workhorse element in many documents.       programlisting      <programlisting role = "" language "">    program text    </programlisting>    Render a longish piece of program text -- preserving the line breaks. The program is assumed to be written in the language specified in the  role  attribute. Note that within  programlisting  all special characters retain their meaning!    This means in particular that you cannot use the control characters `` < '', `` > '', and `` & '' inside of it.  The several workarounds for this problem.  Either you replace all  control characters with their mnemonic equivalents (`` &lt; '', `` &gt; '', and `` &amp; '' in our example), or you wrap the program code in a  CDATA , like, for example,        <programlisting>         <![CDATA[             cout << ""value = <"" << &p << "">\n"";         ]]>     </programlisting>     or, if the program is stored in file  my-program.pl , pull in the whole file with        <programlisting>         <inlinemediaobject>             <imageobject>                 <imagedata format = ""linespecific""                            fileref = ""my-program.pl""></imagedata>             </imageobject>         </inlinemediaobject>     </programlisting>         List-Making Tags    Generate the three typical types of lists.    The  item s or  definition s are typically formed by one or more paragraphs, but they are allowed to contain program listings, too. The  term s usually are one or more words, not paragraphs.      Itemized List    <itemizedlist>        <listitem>             first item        </listitem>        <listitem>             second item        </listitem>        ...    </itemizedlist>      Enumerated List    <enumeratedlist>        <listitem>             first item        </listitem>        <listitem>             second item        </listitem>        ...    </enumeratedlist>      Description List    <variablelist>        <varlistentry>            <term> first term </term>            <listitem>                   first definition            </listitem>        </varlistentry>        <varlistentry>            <term> second term </term>            <listitem>                   second definition            </listitem>        </varlistentry>        ...    </variablelist>        Inline Markup Tags      emphasis      <emphasis> text to be emphasized </emphasis>    Highlight a short part of the document; usually a single word.      filename      <filename> filename or directory name </filename>    Mark word as filename.      literal      <literal> literal something </literal>    <literal role = "" classification ""> literal something </literal>    Mark a word as being a literal expression. Use this tag only as last possibility, if no other more specific tag matches. To calm one's bad conscience,  literal  often gets decorated with a  role  attribute, which describes more precisely the kind of literal.       replaceable      <replaceable> placeholder name </replaceable>    Mark a meta-variable.      title      <title> title </title>    Give a name to a section or a formal element, like a table.        Cross References    Cross references refer to other parts of the same DocBook document or to other documents on the World Wide Web. Targets of the former are all elements that carry an  id  attribute, targets of the latter are selected with universal resource locators (URLs).      link      <link linkend = "" target ""> item </link>    Install a (hyper-)link to the spot identified via  target  within the current document.      ulink      <ulink url = "" complete URL ""> item </ulink>    Install a hyper-link to a WWW-accessible document identified by a   complete URL . A complete URL includes the protocol, for example,   http:// .      xref      <xref linkend = "" target ""></xref>    Install a (hyper-)link to the spot identified via  target  within the current document. A translator will add text around an  xref  element. For example, a  xref  to a section might be decorated with the text `` see section ''.        What I Have Left Out    Ugh, I left out tons of stuff, but only to give you a smooth,  non-frightening introduction. Some great things DocBook handles that I have not discussed are      Tables,    Graphics (with automatic selection of the ``appropriate'' format), and    Automated index generation.      Also left out is everything related to changing the DTD or changing the style sheets.    Pros and Cons      Pros          DocBook is an official W3C standard    Access to text via (user-defined) programs    Texts carry a rich marked up        Cons          Slow transformation    The DocBook format is very verbose. Unless the writer uses a special editor, a lot of typing is required.          Further Reading       Norman Walsh and Leonard Muellner,  DocBook: The Definitive Guide , O'Reilly & Associates, first edition, ISBN: 156592-580-7 at   Amazon . It is also available   online  (as second edition)       DocBook website       Norman Walsh's (chairman of the DocBook steering committee)  website        DocBook Steering Committee        Next month: Texinfo               Christoph Spiel   Chris runs an Open Source Software consulting company in Upper Bavaria, Germany. Despite being trained as a physicist -- he holds a PhD in physics from Munich University of Technology -- his main interests revolve around numerics, heterogenous programming environments, and software engineering.  He can be reached at   cspiel@hammersmith-consulting.com .                  Copyright © 2002, Christoph Spiel.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 75 of  Linux Gazette , February 2002        ""Linux Gazette... making Linux just a little more fun! ""                 The Adventures of Little Linus In GNU/Wonderland   By  D Clyde Williamson   Originally published at  System Toolbox .  Reprinted with permission.                    In Which Little Linus Finds GNU/Wonderland     It was a sunny afternoon, and Linus was happily playing in his backyard.  He was busy with all the things that little Linuses do on sunny days in their backyards. He was sitting in the shade of a large tree when he noticed something very out of place in a Linuses backyard. Waddling across the yard was a penguin! Every few yards, this penguin would pull out a Compaq Itsy, consult it, put it back in his pocket and say, ""I'm late, I'm late, I'm late for my release date!""    Little Linus had never seen a penguin this close before. He had also never seen an Itsy. And he was rather sure that penguins shouldn't be talking or consulting Itsys. So as any curious Linus would do, he followed the penguin. No matter how quickly Linus walked, the penguin seemed to be the same distance away. The penguin didn't waddle any faster, Linus just couldn't seem to get any closer.    Suddenly, the penguin stopped at the very tree Linus had been sitting under. ""Ah, here's what I was looking for... root access!"" the penguin muttered. Then he popped into a small hole in one of the roots of the tree.    Linus decided to follow. He squeezed into the hole, and suddenly realized that he was falling. Everything below him was dark, so he couldn't see the bottom. He continued to fall wondering what was next. He began to look at his surroundings and noticed that there was a brick wall on one side of the hole. As he looked closer he could make out a set of eyes in the wall, falling at the same speed as he was. One of the eyes winked at him. Linus was slightly startled, but remembered his manners. ""Hello, umm, Mr. Wall,"" Linus began cautiously, not quite sure how one should address walls.    To his surprise, a nose, mustache and mouth formed below the eyes and the entire face continued to slide down the wall at the same speed as Linus. ""Hello young man! How are you this fine day?"" the wall asked Linus.    ""Well"", Linus replied, ""I'd feel much better if I knew how to stop falling.""    ""Ah"", the wall nodded sagely, ""Usually, one stops when they hit the bottom. But, as the camel says, 'there's more than one way to do it'.""    Linus didn't quite understand the bit about the camel. However, he was sure that hitting the ground wasn't the best way to stop. He looked at the wall. ""Ummm, I'd really rather stop in a way that didn't hurt me...""    The wall looked at him a bit then said, ""Well, I suppose I can ask the camel to catch you.""  The face disappeared.    Linus continued to fall and realized that he hadn't looked down for awhile. Indeed it seemed that there was a light coming up from below. As he looked down, he saw the ground about thirty feet away. There directly under him stood a camel. Before he knew it, he had landed quite softly and safely between the camels humps. The camel turned and smiled at him, flashing his perly white teeth.    The wall spoke again. ""The camel will help you get started here. He's quite user friendly.""  Then the face was gone again.    Linus looked at the camel, then remembered why he was here to begin with, ""I was following a penguin, but I seemed to have lost his trail."" The camel nodded and began walking towards a nearby wood.     In Which Linus Meets Several Strange Inhabitants of GNU/Wonderland     As they approached the wood, Linus noticed a taco walking up the road towards him. The taco appeared to be carrying several newspapers under his arm. ""News for Nerds!"" he was calling, ""Get your News for Nerds here.""    Linus stopped the camel and walked over to get a newspaper. However, before he could reach the taco, he heard a loud noise. Several thousand creatures, boys, girls, rabbits, unicorns, trolls and all other sorts of animals came rushing toward the taco. They all hit the taco at once, grabbing for the newspapers. Linus watched as wave after wave of things rushed across the poor taco. Then as suddenly as they had come, they were gone. Linus ran over to the taco, ""Are you hurt?"" He asked with concern.    ""Not bad, at least this time no one dumped any breakfast cereal on me,"" the taco replied getting up and brushing himself off. [1]    Linus thought about querying further on the subject of breakfast cereal, however, he decided to skip it. After making sure the taco was OK he climbed back on the camel and set off again.    He had not traveled far when he heard a strange noise in the forest beside the path. ""Perhaps it is a bear,"" he thought. However, before he could urge the camel to pick up the pace a man stepped out of the woods onto the path. He was an odd looking man, with hair that pointed anywhere except where hair usually points. Linus figured the man must have forgotten he owned a beard, since it looked like the beard had wandered off on its own quite awhile ago.    ""Hullo, boy!"" the man waved at Linus. ""I am GNUman. Who are you?""    ""My name is Linus, and it's nice to meet you, Neuman."" Linus got down to shake the man's hand.    ""Not Neuman, it's GNUman. Say it right!""  The man said loudly.    Linus looked at the man carefully, then deciding he wasn't dangerous, shook his hand and said, ""It's nice to meet you GNUman.""    ""Well, of course I'm more than happy to meet anyone around these parts.  By the way, here's the rules to my game,"" GNUman said solemnly, handing Linus a scroll. ""The rules are, that anyone can change the rules, as long as they tell everyone what rules they changed. That way everyone can make the rules fit their needs.""    Linus wasn't quite sure what GNUman was talking about. However, he politely took the scroll and promised to read it. GNUman smiled and wandered off into the woods.    After a few hours of riding around on the camel, Linus noticed party sounds emanating from a nearby clearing. The camel noticed his interest and moved in that direction.    As they broke into the clearing there was an amazing sight. A long table set with coffee, doughnuts, pizza, as well as Chinese, Indian, and Mexican food. At one end was a keg of Guinness. At the head of the table was a man with a bushy black beard, long black hair, sunglasses and a red fedora. He motioned Linus over to a chair.    ""I've been waitin' a bloody long time on you,"" the man said with a British accent. ""Do you know how hard it is to keep all this food hot?""    Linus, beginning to get used to the odd people of this land, smiled and apologized for taking so long. Of course he had no idea that he was even expected, let alone late.    ""Oh, not to worry,"" the English fellow said in a nicer tone, ""I'm sure you were busy.""    They began to eat, and Linus was amazed at the energy that this special food gave him. After eating in silence for awhile, he noticed that other creatures were sitting at the table enjoying the food as well. Oddly, he hadn't seen any of them sit down. Indeed, the large dog sitting next to him had appeared from nowhere. Linus had seen many canines before, but this was the first dog that he had seen with a big white beard.    The dog noticed Linus and flashed him a very big smile. He paused to wipe some white foam from his mouth and began eating again. Linus was a bit concerned that the dog may be 'mad'... Excusing himself, he got up to leave.    The Englishman at the head of the table motioned for him. ""You can't leave yet,"" he exclaimed, ""You have to do what you came for.""    Linus had no idea what the man was talking about, so he waited patiently while the Englishman fiddled around in a big black box.    ""Ah here it is,"" the man said, pulling out a single kernel of corn. ""We need your blessing on this... ummm, here!""    With that the man handed Linus the piece of corn, and a crystal container filled with a yellow liquid. the bottle was labeled ""Warning, contains hP2.""    Linus stood there for a minute, everyone at the table had stopped eating and was watching him closely. He opened the stopper and sprinkled some of the 'hP2' on the corn. Everyone cheered and the kernel began to shake and jump. It bounced out of Linus' hand and fell onto the ground. It began to sprout and grow, a huge green plant came out of it and grew and grew, all the time the diners at the table were laughing, saying things like ""Now that's scalability"" or ""Look at that, 40 feet high and still standing... How stable can you get!!""    Linus began to worry that he was expected to do something. But, before he could figure it out, the Dog that had sat next to him was again beside him.    ""Well, what are you waiting for?"" the dog asked. ""You should already be climbing it.""    ""Ummm, why would I climb it?"" Linus asked.    ""No time for questions, I'll meet you up there,"" the dog replied, and promptly disappeared. The only thing left was the bushy, white beard which slowly faded.     Linus And The Cornstalk     Linus had been climbing the cornstalk for what seemed like hours when he finally found himself at the top. There before him was a giant building with a sign outside that read ""Warning, Home of The RedMond Giant...  all trespassers will be 'Embraced and Extended'.""    Linus wasn't sure what that meant, but it didn't sound like something he wanted to have done to him. He began to look around, when he noticed fading into existence, a white bushy beard. Following the beard was the rest of the Dog, which he had seen down below.    ""Hey again!"" the dog said, smiling, ""I see you made it.""    ""Yes, though I have no idea why you wanted me to climb up here. I really don't want to be embraced and extended by a giant.""    ""Oh, its ok, you have GNUman's rules, don't you? They're the only magic strong enough to defeat the giant.""    Linus pulled out the scroll and looked at it carefully. ""It doesn't look very magical to me,"" he said.    The dog smiled and began walking to the castle. Linus shrugged and followed him. As they got closer, he began to hear a loud voice singing, ""Biddle, Bidele, Boddle, Bandard, I smell the smell of an Open Standard.  Be it old or be it new, I'll make it part of my proprietary brew!""    Linus stopped, the voice was very loud, and a voice that loud had to come from a mouth that was very big. However, the dog continued to trot toward the castle, without a moments pause, so Linus followed. Finally he reached the formidable gates of the building. ""There's no way in,"" Linus said relieved. ""There is an awful lot of security around this place.""    The dog laughed, ""The only thing worse that the giant's silly rhyme, is his security! Trust me, there are many, many ways to get past it.""    Sure enough, with just a slight bit of poking, a whole section of the fencing fell apart, leaving a gaping hole. The dog led Linus into the compound. As they walked across the yard toward the front door... several security people rushed to the point where they broke in. One of them, apparently the leader stood up on a podium and began to speak loudly.    ""This is only a theoretical way of breaking into the giants compound. Anyone who is concerned about this is just being paranoid. Besides, only bad people would break into the compound, and we all know that bad people are stupid. So they wouldn't know about this hole.""    As he spoke, several kiddies began knocking holes in other parts of the fence, following the example of Linus and the dog. The security people ignored them.    ""Furthermore, there is very little likelihood that anyone will be able to duplicate this hole. In fact, if this fence were upgraded to version 2.000 then we wouldn't need to be concerned at all.""    Immediately, all the other workers began putting up the next version of the fence. It looked bigger and stronger than the earlier fence. Linus looked at the dog. ""It will be hard to get back out.""    ""Nonsense, I told you their security is hopeless. This new fence will likely be even worse than the first.""    So Linus and the dog continued into the building, completely unnoticed by the security people. Within a few moments they were inside the building. The dog looked at Linus. ""Ok, open the scroll and read the magic words of GNUman,"" he whispered.    Linus opened the scroll and read, ""The GNU General Public License, Preamble...""    Linus read and read and read. Finally, as he reached the end of the very long magic incantation, he heard a noise. He looked up from the scroll, and saw huge cracks forming in the walls and ceiling.  The building began to shake and shudder. The dog looked at Linus and said, ""Let's get out of here. You've done what you came to do!""    They ran to the door and into the courtyard. Behind them they could hear the giant bellowing for his people to fix the holes and cracks, but it was too late, the home of the RedMond Giant was collapsing. Linus and the dog reached the brand-new fence, and to Linus' surprise, they realized that the entire fence was made of Swiss cheese, they climbed through the holes in the fence, and ran for the cornstalk.    The dog began to fade, he looked around at Linus, ""Thank you so much...  we all thank you. Have a nice life...""    ""Wait,"" Linus shouted, ""What am I supposed to do now?""    The dog was gone again, except for the beard. ""Just get to the cornstalk.  That new kernel will take care of you.""    Linus reached the cornstalk, and began climbing down as fast as he could, but he lost his footing and before he knew it he had begun to fall. The ground was getting closer and closer, and suddenly, he found himself, laying on his back, on the ground. He blinked his eyes, and looked up at the Corn Stalk. He rubbed his eyes and looked again. It wasn't a cornstalk at all.  It was the old tree in his back yard!    Linus got up, rubbed his eyes and walked toward the house. Once inside, he noticed a package sitting on the table, there was a card that read ""To Our Dear Son"".  He opened the package, and to his delight there was a brand new 386 computer, just for him.    The End (or is it?)     Footnotes     [1] The author doesn't condone the abuse of any forum by trolls. This includes comments about hot grits. However, this small joke just couldn't be resisted.                  D Clyde Williamson   Clyde is a network security specialist for a large corporation in the US. He writes articles on Technology, Open Source Advocacy and History (pre-1600). After writing the above article, he lives in prepetual fear of Lewis Carrol's ghost seeking revenge.                  Copyright © 2002, D Clyde Williamson.  Copying license  http://www.linuxgazette.com/copying.html   Published in Issue 75 of  Linux Gazette , February 2002               Modest home on the web   By  zhaoway               Introduction     We will build a small homepage site without server side scripts. This is suitable for people who do not run their own web servers or have no priviledge to use server side facilities. We will use JavaScript and Lex to simulate some effects of template files to ease the maintaining tasks. We will use Makefile to automate the uploading, and use CSS to provide fancy formatting effects. We will use only standard HTML in our main content file, thus provide a good chance for any browsers to surf our web site easily.    The weird choice of using Lex to present a template effect is because I want to pretend that I am a guru. And gurus often use complicated or even brain damaged tools to fulfil simple and sometime stupid tasks. Of course, if I am a true guru, I'd rather write a similar tool by myself from scratch using LISP or C. But since I am only pretending I am one, so forget about it.   HTML and CSS     There is a wonderful  Debian  package which provides great documentation on standard CSS and HTML practice. That is  wdg-html-reference  package. If you are serious into HTML 4 and CSS, then you'd better  apt-get  into that package, and read the documents there. They're easy to follow. Only remember one thing though, a good understanding on CSS does NOT mean that you should use every possible effects on your homepage. A good taste is more important than a good technique. At the end of this article, I presented some  example files , you could keep them handy when reading through.    I will not duplicate those excellent documentation on HTML and CSS here, and there are many more high quality documents outside on the web and in the bookstore. Even better, you could use your browser's ""View Source"" menu item to sneak in every webpage that you're interested to learn from. I will provide you one advice though, that is you should keep it simple, keep your homepage simple unless you have a big team of webmasters and webmistress work for you, or you have a lot and a lot of free time to work on your homepage.    Simple does not necessarily mean ugly, sometime simple is considered beauty, expecially when the CSS is available to nearly everyone now. So your best practice (pretending that I am an expert. heh) is to use standard HTML in your content file, and use the HTML tags as logically as you can.    For example, you may want to use  <i>  to empasize a sentence or a word, DON'T, use  <em>  instead. Then use CSS to provide the desired effects. That's the whole point. And not to forget to appreciate the  Mozilla  web browser which is nearly the most standard compliant one out there. (Hint, use it to test your webpage!)   Using JavaScript     Why using JavaScript? Since we are only building a modest homepage, we won't need those fancy features, not to mention those annoying pop-ups. The reason we are using JavaScript is that it could present us some template like features which could ease our task maintaining big bunch of webpages. Modest homepage does NOT mean that we cannot put many files there. ;)    For example, if we want to present a navigation menu for our webpage, we will have to copy and paste our menu paragraph in HTML into every content file (as mentioned above, we do not have enough priviledges to use any server side facilities.), and what if we want to change the style used for our menu? That's a big nightmare to adjust each webpages for that.    Instead we could write our menu in a JavaScript, and include the following in each of our webpages:      <script type=""text/javascript"" src=""header.js"" charset=""iso-8859-1""> </script>      When we want to add an item to our menu, we only need to change the  header.js  file, then viola, every webpages are changed accordingly.    The syntax of JavaScript is very easy to learn, by reading some  examples , you could get nearly the whole idea. Since we are using JavaScript to present navigation menus, we could even ease the task of generating menus by hand too. Go check out the example  header.js  at the end of this article.   Using Lex     Lex is presented in the Debian package  flex . It is a GNU tool. What lex do is to scan the input file, and whenever a regular expression is met, execute some C code. So we can use it to scan our templates then generate the HTML files. Lex could turn your dull project of maitaining a stupid personal homepage into an exciting C programming journey. Isn't it wonderful?    Lex is a scanner generator, which means, we use lex to generate our scanner, then using our scanner to scan our template files to generate HTML files. How could lex generate a scanner? It does this by reading a rules file written by us. Basically, we design some set of rules, then using this rules in our content files. And we write a rules file for Lex, then we use lex to read our rules file and generate a scanner, then we use the scanner to scan our content file to get the desired HTML file. And, it's very simple! Gurus R Us!    What makes a rule? A rule is made of two parts. The first part is a regular expression (regex) similar to that you found in  perl  or  egrep . The second part is a small part of C code. Whenever a regex is found met, then the C code will be executed. The following is a sample rule from our example rules file:   \""header\"" {   if (flag_lex == 1 && flag_key == 1 && current_key == HERE)     {       fprintf(yyout,        ""<!DOCTYPE HTML PUBLIC \""-//W3C//DTD HTML 4.0//EN\""""        ""\""http://www.w3.org/TR/REC-html40/strict.dtd\"">""        ""<html><head><title>{zhaoway} %s</title>""        ""<link rel=\""stylesheet\"" href=\""style.css\"" type=\""text/css\"">""        ""<meta http-equiv=\""Content-Type\"" content=\""text/html; charset=utf-8\"">""        ""<meta name=\""description\"" content=%s>""        ""<meta name=\""keywords\"" content=%s></head><body>""        ""<script type=\""text/javascript\"" src=\""header.js\"" charset=\""iso-8859-1\"">""        ""</script>\n"",        keys[TITLE], keys[DESCRIPTION], keys[KEYWORDS]        );        flag_key = 0;     }   else ECHO; }      The above code means that, when ""header"" is appeared in the input file, and some conditions are satisfied, then we will replace it with a big bunch of HTML codes. The corresonding example content file is as the following:   <lex title=""home page"" description=""zhaoway's homepage."" /> <lex keywords=""zhaoway, personal, homepage, diary, curriculum, vitae, resume"" /> <lex here=""header"" />     Making the upload     When doing the upload, to decide which file on the server needs to be updated is difficult, and that task should be automated indeed. So we use Make to do it. The basic idea is to touch a blank  some.html.upload  file whenever  some.html  is uploaded. When  some.html  is newer than  some.html.upload  that means it needs to be uploaded to the server again. The following  Makefile  rule shows that:   %.upload: %  lftp -c ""open -u \""$(USER),$(PASS)\"" $(SITE); put $<""  touch $@     Conclusion     Makefile and Lex themselves warrantize lengthy articles. They are very traditional Unix tools for C development. But could be very useful in maintaining webpages. We cannot explore the details of them very carefully. This article is just mean to raise your imagination with these traditional Unix tools.   Example files available        Makefile       scan.l  Lex rules file       index.scan  Template file for index.html       header.js       footer.js       style.css         You could visit  my homepage  for the resulted effects. Have fun and good luck!        zhaoway    zhaoway lives in Nanjing, China. He divides his time among his beautiful girlfriend, his old Pentium computer, and pure mathematics. He wants to marry now, which means he needs money, ie., a job. Feel free to help him come into the sweet cage of marriage by providing him a job opportunity. He would be very thankful! His  curriculum vitae  is at his  homepage . He is also another volunteer member of the  Debian GNU/Linux  project.              Copyright © 2002, zhaoway.  Copying license  http://www.linuxgazette.com/copying.html                ""Linux Gazette... making Linux just a little more fun! ""             The Back Page   The back Page is short this month because Your Editor is similtaneously (A) working on another project, (B) going on vacation, and (C) preparing a talk for the   Python conference , all at the same time.  I'll be writing an article about the conference for  Linux Journal , and presenting a paper called  Cheetah: the Python-Powered Template Engine , and leading a BOF (Birds of a Feather) discussion on Cheetah, a project I'm a volunteer developer for.    There will be more Esperanto announcements next month.  Meanwhile, baibilu pri Linukson on a new mailing list, linux-esperanto ( http://www.ssc.com/mailman/listinfo/linux-esperanto/ ). (If you missed the Esperanto grammar discussion from January's LG,   here it is .)           Happy Linuxing!    Mike (""Iron"") Orr  Editor,  Linux Gazette ,  gazette@ssc.com                   Copyright © 2002, the Editors of  Linux Gazette .  Copying license  http://www.linuxgazette.com/copying.html  Published in Issue 75 of  Linux Gazette , February 2002"
GX051-68-13981491	"December 1999, Issue 48       Published by  Linux Journal     Front Page   |   Back Issues   |   FAQ   |   Mirrors   |   Search                         Visit Our Sponsors:                                                                                 Table of Contents:               The MailBag            Help Wanted & Article Ideas         General Mail           News Bytes            Distro News         News in General         Software Announcements           The Answer Guy  ,  by James T. Dennis       More 2-Cent Tips        It's Only a One Day Conference...  ,  by Stephen Adler       SAMBA, Win95, NT and HP Jetdirect  ,  by Eugene Blanchard       LinuxThreads Programming  ,  by Matteo Dell'Omodarme       A Brief History of the 'ls' command  ,  by Eric Fischer       Advanced Programming in Expect: A Bulletproof Interface  ,  by David Fisher       Linux, Java and XML  ,  by Eoin Lane       DHCP for the Home Network  ,  by JC Pollman, Bill Mote       The Back Page            About This Month's Authors         Not Linux                                         TWDT 1 (gzipped text file)   TWDT 2 (HTML file)  are files containing the entire issue: one in text format, one in HTML.  They are provided  strictly as a way to save the contents as one file for later printing in the format of your choice;  there is no guarantee of working links in the HTML version.                   Linux Gazette ,   http://www.linuxgazette.com/   This page maintained by the Editor of  Linux Gazette ,   gazette@ssc.com      Copyright © 1996-1999 Specialized Systems Consultants, Inc.                 ""Linux Gazette... making Linux just a little more fun! ""             The Mailbag!    Write the Gazette at   gazette@ssc.com     Contents:     Help Wanted -- Article Ideas   General Mail                Help Wanted -- Article Ideas     Answers to these questions should be sent directly to the e-mail address of the inquirer with or without a copy to gazette@ssc.com. Answers that are copied to  LG  will be printed in the next issue in the Tips column.     Before asking a question, please check the  Linux Gazette  FAQ  to see if it has been answered there.               Mon, 1 Mar 1999 14:28:50 -0800  From: Vijaya Kittu < vijaykittu@hotmail.com>   Subject: Visual Basic for Linux ???    I'm looking for a good and easy ""Basic"" Language Port (such as VB in Windoze) on X-Windows.    If any one is using any Visual Development tool, kindly send comments back to me.                Fri, 29 Oct 1999 16:22:22 +0200  From:  < Douwe.vanderVeen@95.Student.WAU.NL>   Subject: connecting SPARC and 386 for printing purposes    having a SPARCstation 10/20 with Redhat 5.1/SPARC working fine on it, I wanted to connenct a printer to the system.  Since the parallel port is not supported under S/Linux, I wanted to connect my SPARC with a cheap 386. The 386 is working under MS-DOS.    I bought an ethernet card for my 386, and connected the in-board ethernet card on the SPARC with the ethernetcard on the 386. The cable is twisted-pair, since only two computers are to be connected.     If I turn on both computers, I can start a testing program for the ethernet  card on the 386. It will wait for any external signal.  When booting the SPARC (the 386 sensing for any action), the SPARC checks for  'eth0' but finds no other computer on the other side.    Questions:  (1) how can I  let my 386 tell to the SPARC he is there? (2) How can I make the 386 accessible (that is: the parallel printer port)  from the SPARC?    Thanks in advance for any help!!                 Sat, 30 Oct 1999 21:19:01 +0200  From: Dr. Bodo Zimmermann DD-260 < dozi@iwka.de>   Subject: problems with tcp/ip in kernel 2.2.x    I have found problems with ftp aund telnet (tn3270, x3270) in the kernel 2.2.5 and 2.2.10 when connecting to IBM mainframes (VM/ESA). I cannot tranfer any data!    There are no problems at all with a kernels 2.0.x    Whom may I address?               Sat, 30 Oct 1999 23:25:05 EDT  From: Richard Monte < richard_monte@hotmail.com>   Subject: Running MS applications on Linux?    I was wondering if I can run my MS applications on Linux?  What would I  need?    If I can, what are the advantages and/or disadvantages of doing so?    Are there any legal issues related to running MS applications on a  non-Windows OS?    -Rick               Sun, 31 Oct 1999 12:54:24 +0100 (MET)  From: Mika Numminen < mika@Oink.Midgard.HIG.SE>   Subject: Hmmm.... don't know how to categorize this..       I usually log into my machine with SSH from home (no concole access) and I was wondering if there is a way to have processes still running after I log out. For instance an ftp-session loading an ISO, etc..                 Mon, 1 Nov 1999 18:53:32 -0600  From: lordj < lordj@iaw.on.ca>   Subject: linux sound problems    I run sndconfig and the friggin thing just fails. it finds my card and then sets up the irqs and all that rot, and then when it trys to play the sound sample i get the failure ""don't know what to do with CONFIG CTL002b/4886122 ... error parsing file"" and stuff like that. what is wrong with it?                 Tue, 02 Nov 1999 18:21:51 +0800  From: Zon Hisham Bin Zainal Abidin < zon@mad.scientist.com>   Subject: Telnet 110 fails    Now that my LILO is back (up and running), it's time for something else.    I have 6-7 pcs in the office on LAN. I am on RH6.0 and the rest on W98. I am trying to configure my pc as the email server for this small LAN.    I have managed to correctly setup DNS. A remote PC can resolve the DNS server correctly. Then I went into Linuxconf and setup the Email server portion. My Linux PC by the way is named svr and the domain is cma.com    We are using Netscape as the email client. I entered      svr.cma.com    as the Incoming and Outgoing mail servers. Netscape client can sent email but were unable to receive (email) with the message: ""Netscape's network connection was refused by the server svr.cma.com   The server may not be accepting connections or may be busy. Try connecting again later.""    I did a  telnet svr.cma.com 110  with a ""Unable to connect to remote host"" message. But a  telnet svr.cma.com 25  is ok. That explaint why sending is OK but not receiving rite?    How do I fix this?      rgds.               Tue, 02 Nov 1999 20:53:57 +0000  From: Anatoli B. Titarev < Anatoli_Titarev@swin.edu.au>   Subject: HELP with LT Win Modem and SB 16 Sound Blaster wanted!    I am a new Linux Red Hat 6.0 user.    I cannot connect to the Internet (still using Winows 98). My LT Win Modem connected to com3 is not working under Linux. (Someone wrote that trying to config Win modems for Linux is waste of time, is it true?)    Connection: 8, parity - none, stopbit - 1. I told the 'modemtool' to use to use the serial port  to which my modem is connected. I removed the word 'lock' in /etc/ppp/options file.    I get 'modem is busy' in kppp configuration program or 'mode is locked' errors in other programs.    I also have a problem with SB 16 sound blaster. 'sndconfig' program doesn't help!    I am looking for anybody who can help me to make my modem and sound blaster working with Linux.    Please help!!!                 Tue, 2 Nov 1999 16:09:01 -0600  From: smita narla < snarla@cse.unl.edu>   Subject: Re: your mail      hello,  I'm doing a general survey on the testing techniques used in open source.I've a questionnaire with some 12 questions.Since you are a developer can you answer this questionnaire.I'm doin this for one of my class projects and i need to send the questionnaire to some 200 developers.Can you send me the addresses of some other developers ?    I'll be glad if u can send me some questions to improve my questionnaire.    Thank you smita        The Editor sent some suggestions, and Smita responded:     Hello,  thanks for your response. i 've ghone to the sites u have mentioned in you previous mail. i got some info but not exactly what i'm looking for. i need some nice multiple choice questions for my Survey of testing techniques in open source.Some of the questions I've found are:    2.       When ever you make a minor release do you make a complete regression tests and test for the bugs fixed in this released ?    3.       For every major/minor release do you make tests for the bugs you fix ?    4.       Will there a any test planning carried parallel to development of coding ?    5.       What will be the acceptance criteria for the source you releasing (based on the test results) ?    6.       Are you satisfied that test you are planning to execute will cover all the required conditions.                  But i dont think they will serve the exact purpose. Ineed some real good multiple choice questions (which are easy to answer with out much thiking from the developers point of view).    I'll be glad if you could help with some nice questions and some mailing lists of open source developers.    thank you, smita                 Wed, 3 Nov 1999 00:14:11 +0100  From: cabotzen < cabotzen@wanadoo.fr>   Subject: a problem    This is a multi-part message in MIME format.    Hello i'm french and i love linux, but i try to install it on a notebook with win98, i have a samsung's notebook. After i have installed all the paquages, the instalation stopped when it wanted to reconize the mouse and i can't continue the instalation. CAN YOU HELP ME PLEASE. Good buy                Tue, 2 Nov 1999 18:14:44 -0500  From: Paul Nathaniel  (NOL1NXP) < nol1nxp@ups.com>   Subject: Linux command questions    fsck /usr: What does this command do? What is its NT equivalent.   What is this command: cat /etc/passwd; and what is it's NT equivalent?               Wed, 03 Nov 1999 07:44:42 CST  From: Jim Bradley < jbradley@msc.net>   Subject: slowwwww ftp and partition problem    I have encountered two problems with linux (Mandrake 6.1) that I haven't figured out how to overcome.    The first problem is the logon speed for ftp. I have 3 desktops and a laptop that I have networked with 100 Mbps ethernet. 2 of the 3 desktops are dual booted with OS/2 and linux, the remaining desktop and the laptop are linux only. If I try to connect to ftpd on linux with an ftp client on either OS/2 or linux, there is an approximately 3-5 minute wait before a logon prompt is returned. This is clearly not running properly! I can use a linux client to an OS/2 ftpd, and promptly get the logon prompt. I've tried ""renice"" at both -20 and +20 using KDE's task manager. What do I need to do to speed this up?    The second problem is: I have one machine with an 8 Gb drive partitioned into a 2Gb,6Gb, and 128k swap. Mandrake 6.1 is installed on the 2Gb partition, hda1. The 6Gb partition, hda3, is an ext2 partition. After linux boots, the 6Gb partition is mounted to /mnt/hda3. The problem that I've encountered is that when copying files to /mnt/hda3, it is the first partition that fills up, not the second. What's happening here? I was using kdisk to monitor the disk size when mirroring another site to /mnt/hda3, and it wasn't the correct partition that enlarged. After this occurred, totally filling the smaller partition, I could no longer umount the partition, either, getting a message ""device is busy.""    Any help to solve either of these problems??               Wed, 3 Nov 1999 10:49:32 -0600  From: Hunter, Kevin < Kevin_Hunter@AFCC.com>   Subject: LinNeighborHood      Thu, 28 Oct 1999 14:54:48 +0100   From: Network Desktop User < G.F.Wood@shu.ac.uk  >  Subject: Linneighbourhood  Hi, sorry to bother you with inconsequential mail but I think you of all people should know this !! I'm looking for some software called Linneighbourhood. It's a network neighbourhood browser for Linux. I have scoured the net for it but to no avail !! Can you help??       http://www.bnro.de/~schmidjo/      From: Graeme Wood < G.F.Wood@shu.ac.uk> :    I think their is a gnome program that lets you browse the net neighbourhood as in win 9X. i do not know the name right now. but if you want i will figure it out                         Wed, 03 Nov 1999 10:14:02 -0800  From: Chuck Newman < cnewman@cncnet.com>   Subject: Linux Communications    Is there a Linux based communications program similar to pcAnywhere or Carbon Copy?  I need remote PC control.  Don't need to transfer files.               Mon, 08 Nov 1999 16:18:50 -0500  From: Sunshine Smith < sunshine@margaritaville.com>   Subject: Installing RH6.0    I am trying to install RH 6.0 on a Thinkpad 760ED, unfortunately the cdrom (Teac 44E) does not appear on the supported cdrom drives, does anyone have any ideas other than buying an external (supported) cdrom drive.    Thank you                Tue, 09 Nov 1999 10:36:19 +0200  From: Lucian Hanga < lhanga@saguaro.dnttm.ro>   Subject: about ESS Solo 1    ESS Solo 1. Unfortunately I have one !!!! If smbd. kwon how to make it works !!!! Please email me !!!!!!    10x                 Wed, 10 Nov 1999 16:54:20 -0000  From: Ben Huckel < ben.huckel@virgin.net>   Subject: Virtual Terminals in windows    Can you offer any advice....? I am currently considering a project for my third year project of a bsc(hons) in computer science which would implement virtual terminals for windows 95/8...... Do you know if there is any info on this sort of thing, has it already been done? Any help or ideas would be greatly appreciated.                 Thu, 11 Nov 1999 00:06:50 +0000  From: Nadeem Oozeer < nadeemooz@intnet.mu>   Subject: SDRAM Problem     I've got a PII with 128MB SDRAM PC100, with 8MB AGP onboard, running windows and Linux Red Hat 6.0. I've been told that the AGP uses 8MB from the SDRAM that's why on windows I get 120MB in system. On Linux however, I get only 64MB of RAM in /etc/meminfo .... How can I get all the 128 MB ? I've tried append in lilo.comf, but it freezes my PC with strange codes ?                Thu, 11 Nov 1999 12:22:57 +0800  From: Brian < c6028408@comp.polyu.edu.hk>   Subject: How to set the Linux as a router!    I would like to set a single PC as a router by using Redhat 6.0. However, I find difficulties in finding the related topics in books or journals. Can you tell me how I can find the related topics? Thanks!    Best regards, Yvonne.                Thu, 11 Nov 1999 13:47:55 -0600  From: anthony < aokrongly@galacticmarketing.com>   Subject: Looking for open-source programmers    I need to start somewhere, so I'll start here.  I am trying to find programmers interested in developing a new piece of software.  I thought I would give Linux Open License types the first shot at it.  We are looking for this solution for our small company, but are willing to share it to help defray development costs.    Can you help direct me?  Or am I spinning my wheels?    The initial write up on the proposed application is   attached .  I know this isn't the normal way to develop software, but I wanted to give it a try.    Anthony O'Krongly, Dir. of I.T.      [If you just want to throw a project idea out and see if anybody is  interested in helping, I'll put it in the Mailbag.  (Which I'm doing now. :)    If it's a critical piece of software for your company and needs to be completed ""soon"" and with ""professional quality"", you might have a  look at www.cosource.com and www.sourcexchange.com instead.  They act as auction brokers between those willing to pay to help get open-source software developed and those who wish to work on such projects.    The GNU Gnats program may partially meet your requirements.  It allows one to keep track of ""job requests"" in several categories, and to see which ones have been followed up on and what needs to be done with the remaining ones.  The Tkgnats program is a GUI front-end.  Perhaps this could link into your ordering and accounting system somehow. -Ed.]                Thu, 11 Nov 1999 19:41:36 -0000  From: ggg < nice@simpm.freeserve.co.uk>   Subject: help please    please can you help me im new to remote booting i have got the hardware one network card with a  boot rom  and one with out so im fine on the hardware side but how do i configure linux for  remote booting  i am new to linux  so i really have not got the foggiest.                  Thu, 11 Nov 1999 17:20:41 -0800  From: Johnny Lam < truelightpip33@hotmail.com>   Subject: hi    Hi, i'm very new to Linux but i got a question, it may sound silly but pls help me with it. I've just install linux 6.1 as a server, but for some reason i can't get the x-window to work, can u pls tell me how i can use x-window as a server?  thank you very much                  Thu, 11 Nov 1999 20:51:35 -0500  From: Gary R. Cook < grcook@erols.com>   Subject: X-windows application for communicating over /dev/ttyS1 (COM2)    Does anyone know where I can find a utility (with source code) that uses an xterm window for communicating with a remote asynchronous device over /dev/ttyS1?                                                                Thanks!!                Sat, 13 Nov 1999 03:18:19 +1100  From: Greg W < greg@ausit.com>   Subject: Hello    I am sure you get swamped with questions, now that I have acknowledged that, I feel better about asking if you know, or know someone who can point me to a good working example for ipchains for a machine that is standalone, I have 64 IPs all routed through a PC, this PC is not Linux based, so I dont want MASQ or ppp examples    A straight up script to disallow spoofing, and everything else besides the ""normal"" services  (i can easily add or remove as necesarry)    All examples seen so far dont work because they are based on like I said, MASQ or ppp0 being present.                     Sat, 13 Nov 1999 20:42:18 -0500  From: zak < zak@acadia.net>   Subject: Apollo P-1200 Inkjet Printer    Today I purchased an Apollo P-1200 inkjet printer at the local drug store (yes, drug store!), the main attraction being it cost $90 *before* a $50 rebate!  This is supposed to be a new 'low-end' printer, using H-P technology. The downside is that the CD that came with it only covers installation for 'doze. Has any other LG reader purchased one of these?  If so, where can I find an appropriate Linux driver for it?  I tried the http://www.myapollo.com site, but all that's there is also 'doze stuff. If anyone knows the nearest this thing is with any H-P driver, that would also be useful.  I mainly use a printer for printouts of txt and html documents, and with Corel Word Perfect 8.0 for Linux. Thanks in advance for any assistance. Zak               Sun, 14 Nov 1999 02:43:43 -0000  From: George Christofi < george@slamdog.co.uk>   Subject: Getting linux to authenticate to nt domains.    I want to get linux to authenticate to my NT network. As a newbie, I am stunned by the complexity of the whole Linux thing. I find it easier and more reliable to do things with NT Server. I am not thick (just MCSE qualified), but cannot see how to get it to perform this seemingly simple task.                 Sun, 14 Nov 1999 12:40:36 -0800  From: Kenneth MacCallum < tandk@primex.co.uk>   Subject: Linux memory woes     Hi, I've just installed Red Hat 6.0 and it's not detecting all of my memory. I tried typing linux mem=64M at the LILO prompt as recommended but then the boot-up fails. As it is it only detects 14M or so of my 64M.    I had a look in my bios, and I noticed a line saying that there is a memory hole at 15M. I'm guessing that this is causing Linux to not see memory above this, but I don't know why this ""hole"" is there. I had a look in my motherboard manual (PC Chips M577) but it didn't mention anything useful. This hole doesn't seem to upset Windows; is there anything I can do to get Linux to work too?    I also tried swapping my DIMMs around, thinking that if the hole was due to a bad DIMM it might move up to 47M (?) but it doesn't.    I've been searching about the web for some insight but  I've had no luck so far.    Can you help?                 Mon, 15 Nov 1999 12:12:50 -0500  From: Bruce Kramer < bruce.kramer@PaineWebber.COM>   Subject:     Editor, I'm looking for some help in the Detroit, MI area. I have a son, 16 yrs old - junior in high school, presently enrolled in some special projects at school.  One of which is to learn Linux.  He recently removed Windows from our home computer to install Linux.  After attempting this for four weeks now he is frustrated and ready to give up.  Rather than giving up and going back to Windows I thought that it might be possible to find someone in our area who could help get Linux up and operating on our computer.  Any suggestions?     [Look at  www.linuxjournal.com   under ""User Groups (GLUE)"" and see if there are any contacts in your  area. -Ed.]                Mon, 15 Nov 1999 22:00:36 -0500  From: Pierce C. Barnard < pbarnard@ultranet.com>   Subject: Looking for the Korn shell    Hi, I recently obtained Redhat V6.0 and I found out to my dismay, that it does not have the Korn shell with it.  Does anybody know where I can find a copy of it?  Thanks.                 Wed, 17 Nov 1999 19:16:38 +0800  From: Yvonne Chung < yychung@doramail.com>   Subject: How to set a PC as a router with Linux6.0?    Dear Sir/Madam,    I would like to set a single PC as a router by using Redhat 6.0. However, I find difficulties in finding the related topics in books or journals. Can you tell me how I can find the related topics? Thanks!    Best regards, Yvonne. --                  Wed, 17 Nov 1999 13:03:37 +0100  From: Harold Konijnenberg < hhkonijn@worldonline.nl>   Subject: ipop3d/imap server problem    Problem with IMAP/Ipop3d server    I have a problem with getting the Ipop3d/Imap server to work. I use the Imap 4.5 package on my Red Hat 6.1 system. After installing RH 6.1 and configuring the system all services like Samba, Apache, FTP, telnet are working fine. But now I want to add a pop3 server. I checked my /etc/services file and Imap and pop3 services are enabled here. in the /etc/inetd.conf file the imap and pop3 services are not enabled, so i uncomment de following lines   #pop-3   stream  tcp     nowait  root    /usr/sbin/tcpd ipop3d #imap    stream  tcp     nowait  root    /usr/sbin/tcpd imapd      After uncommenting these lines in the inetd.conf file i kill the inetd proces to reload /etc/inetd.conf with the following command:  killall -HUP inetd      When i try to telnet in to the linux box now by:   telnet 192.168.1.254  (my linux box) i can't connect. FTP'ing into the linux box gives a problem with the in.ftpd daemon.    When i restore the original /etc/inetd.conf all problems are disappeared and eveything works fine again.    I can't figure out what is the problem. I know that the problem starts when changing the /etc/inetd.conf file, so perhaps its some kind of security issue???    Any help is very welcome,                  Thu, 18 Nov 1999 17:06:03 IST  From: nayab shaikh < nayabs@hotmail.com>   Subject: How to configure isdn on linux    Hi friends,    Can anybody of you guide how to configure isdn on linux.I have Red Hat linux  6.0 server installed on my computer.I have a 56.6 kbps ext modem ....also is  RADIUS is possible with it.(remote athentication dial in user service)....     Waiting for your reply...    Nayab                    Sat, 20 Nov 1999 12:22:12 +0530  From: Sivaraman Manivasagam < sivsons@vsnl.com>   Subject: Regd Lexmark Printer Drivers    I've recently installed Redhat Linux 5.2 am having a problem installing  my Lexmark Optra E ( PS Support  ) Laser Printer .I have been to the Lexmark site and there are no drivers for Linux.Any help in this matter would be appreciated.    Kindly mail to :  sivsins@vsnl.com  a copy to       :  mani@amoebatel.com                 Sat, 20 Nov 1999 19:24:56 -0500  From: GZukoff < Gzukoff@onebox.com>   Subject: None    I have stumbled upon your website and was exterely pleased!!!  I am a newbie to Linux but have been interested in alternate OS's for about 18 months after trying (in vain) to install FreeBSD. I have downloaded and am installing Corel Linux 1.0 and was hoping you wil be doing a write up regarding it son.  I am anxious to see how it stacks up against the other Linux releases.                  Sat, 20 Nov 1999 22:33:04 -0500  From: outofstep < outofstep@mindspring.com>   Subject: xwindows display problems?    i recently installed redhat 6.1,, i have a voodoo banshee 2 graphics card, and i get ditorted pixels on the screen when i scroll and move windows... is there a driver update or something i need to fix this? please help. so far i love linux, and this is my only problem :)                Sat, 20 Nov 1999 21:27:52 -0700 (MST)  From:  < steve@mailandnews.com>   Subject: Question    Hi    I hope this is the right address to right to with a Linux question.    I have a lot of Joliet format CD's made with DirectCD in Windows. Linux can read the CD's, but on files with long names (Over 20 characters or so) the filesize is dramatically misreported. 6-7 meg files are listed as 2-3 meg files. Linux can't see it all, and this of course means the file is pretty much corrupt and of no use in Linux. The CD's are readable fine in Windows, but not Linux. I've searched high and low and can find no answer to this problem. I hope you can help.    Thanks    Steve - mr_drood@mailandnews.com      angry fruit salad  (n.)     A bad visual-interface design that uses too many colors. (This term   derives, of course, from the bizarre day-glo colors found in canned  fruit salad.) Too often one sees similar effects from interface  designers using color window systems such as X; there is a tendency  to create displays that are flashy and attention-getting but  uncomfortable for long-term use.      JARGON FILE, VERSION 4.1.4                     Thu, 18 Nov 1999 21:47:28 -0500  From: Edith & Steve Dolesch < nedes@sprint.ca>   Subject: Fw: Disability Features.    I just need to know if Linux has disability features like Windows (all versions)? I'm a disabled person and use StickyKeys to write with one hand if needed and the Numeric Pad to move the mouse cursor.        [The   Linux Access-HOWTO  explains the capabilities Linux systems have for people with disabilities.  It says that X-windows has a StickKeys feature, and the FVWM window manager can be controlled without a mouse. -Ed.]                   Tue, 23 Nov 1999 10:30:53 +0800  From: ZHOUKM < zhoukm@red.semi.ac.cn>   Subject: winNT+MSproxy+linux question    My PC is in a WindowsNT-based LAN which has a MSproxy system, under win9x session in order to connect to  internet I have to login the WinNT domain, and Of course the win9x is equiped with msproxy client.  A linux system is also installed in my machine, but how to visit the internet?    Thank you                Mon, 22 Nov 1999 21:55:00 EST  From:  < Hlinlin@aol.com>   Subject: do you know the USB(network adapter 10T) can run under linux?       Do you know the Universal serial bus with ehternet 's network adapter can work under Linux?  or where we can down load driver?    hope to get your reply and help                 Mon, 22 Nov 1999 21:10:13 -0800  From: Yunfei Deng < greenmoon@ureach.com>   Subject: Setup network printer    I have RedHat 6.1 installed, but need to figure out how to use the network printer.  The network printer is shared on a NT domain which is available to use if I login in NT. Any tip is welcome.                 Tue, 23 Nov 1999 11:16:44 -0600  From: Carlos Alarcon < carlos.alarcon@softtek.com>   Subject: Hi!!! I have a big problem    I just bought a new computer. It has an ""on-board"" video card, Intel 810 chipset. I couldn't configure X to work with this type of card. First, I let Linux probed, it failed. Then I looked at the list, of course, it wasn't there. Then I tried an unlisted card and configured it as a general svga, it still failed. What to do now?                 Tue, 23 Nov 1999 21:09:22 PST  From: Edgar Henry < edgar_henry@hotmail.com>   Subject: Accessing previous partition (path 16 and 32)    I am trying to install redhat linux 6.0 on my PC which is dual booting on  Windows 98 and windows NT and has a patition of Path 16 and 32. When I try  to install Redhat Linux choosing the workstation its automatically  installing and I cannot access my data anymore using the windows 98 or NT  since it is not recognizing the partition.    It is possible for me to get my data from my previous windows.    Thank you very much                Wed, 24 Nov 1999 02:57:15 -0800  From: kevin hartman < kevinh@hsaeug.com>   Subject: Direct Cable Connection between Win95 and Linux, by Thomas P. Smyth    Would you happen to have a current e-mail address for Thomas P. Smyth, author of Direct Cable Connection between Win95 and Linux?                       General Mail              Sat, 30 Oct 1999 17:47:57 +0100  From: Andy D Williams < andy.d.williams@btinternet.com>   Subject: a complaint about issue 47    Hello    I am a regular reader of your gazette magazine who is using windows 95.  I download and extract your magazine onto a local disk for reading at my pleasure and I find it very useful and informative about installing and use of linux.  I intend to move over to a unix like system permanently sometime in the future and prefer to read your magazine on my windows hard disk while I'm learning to get to grips with linux.    So onto the complaint!  How can I read your magazine if your tar.gz files won't extract onto my hard disk!  Why won't they extract or why won't issue 47 extract?  Your issue 47 tar.gz appears to be using a dos/windows reserved system name for a directory or filename!  the lg/issue47/aux directory can't be created on my windows disks because aux is one of those names.   Assuming you or your contributors have used dos and windows in the past why didn't they know about these names in dos and windows?    Are you trying to stop windows users from learning about linux?    I have been able to read your excellent magazine from issue 1 to issue 46 without any problems and would like to continue until and after I am no longer using windows as my primary operating system.    Thank you very much    Andy Williams     [Argh, I forgot  aux  is a reserved devide name under   DOS/Windows.  This was corrected in early November.  (The directory  name is now  misc .)        I also corrected  a link to a program listing in JC Pollman's and Bill Mote's article   Backup for the Home Network .  If you were unable to view these files earlier, please try again now.  Apologies to the authors of an excellent article which is being widely  read, judging from the number of messages I received about this link.     Starting in issue 47, I have been moving all program listings into  their own text files rather than keeping them inline as part of the   HTML.  This will hopefully be a convenience for readers who wish to  run the programs or borrow code from them. --Ed.]                 Fri, 12 Nov 1999 10:05:43 +0100  From: Joachim Krieger < krieger@the45er.de>   Subject: AW: Duplicate messages, unreadable listings, Pollman article      [The following are excerpts from a larger conversation.  The issue is,  after there's been a correction to the  LG  FTP files, how does  one tell whether the file(s) s/he has are the old ones or the new ones?  If the file date at the main FTP site is newer, obviously the user has  an old file.  But if the user's program or a mirror site   touch ed the file, its modification date could be misleadingly  recent. -Ed.]      Is there any criteria that allows to distinguish the old issue47 from  the new one ? ( beside the file-date/time )    OK - I got the fix and offer it on our server. ( http://www.the45er/lg  resp. ftp://ftp.the45er.de/pub/lg )    Not your - but my problem is, that the .gz-file carries date/time-stamp of  my download - and that's Nov 11.    Assume: Someone has an old version - including the problems you've fixed. This  person is looking for the fixed file. Question: does this person have to download 'lg-issue47.tar.gz' and unpack it      to find out he/she got the same (old) stuff    or he/she got that, whats wanted.     File date/time can't be the criteria, because of touching by some clients...     The  Linux Gazette  Editor wrote:     I'm not sure how to deal with that situation.  I'll put it in the Mailbag and see if somebody can come up with a solution.  It might be worth adding a changelog to the README, but that won't help you decide whether the file you have is the old one or the new one.  I could link the new file to a different filename (lg-issue47-fixed-nov-2.tar.gz), but that would cause too much clutter in the directory and may not be  welcomed by the mirrors.    It seems like this is what the modification date is for, and if some programs aren't preserving it on downloads, the solution is to fix those programs or figure out how to work around them (e.g., set up an alias with the correct command-line options to preserve the timestamp); otherwise, you'll have even more problems later with other files, trying to figure out what is up to date and what isn't.    Joachim responded:     maybe one solution could be an aditianal note apended to one of the files - or a new file with that. The result should be a different filesize of the newly created tar.gz.    Perhaps publishing the size of the old - and the size of the new file may help.      [Readers, would this be helpful?  Or exactly what information would  be most helpful to you? -Ed.]                    Fri, 05 Nov 1999 09:57:04 -0500  From: Darren and Kristen Morin < sarcasmo@choice.net>   Subject: Excellent job!     Yeah, THIS is the kind of content I like to read.    Hello my name is Darren and I have been a linux user for about two years.  While I may be past the point of out-and-out newbie, I'm certainly NOT a Guru.  The articles in the Nov.99 issue are excellent1 It is almost like you folks were picking my brains, because these were the kinds of issues on my mind right now, especially the features on security and running unix as a home user.  More features like this, please!    Keep up the great job folks. I don't know if you get many encouraging letters, considering this as one of them.      Bye for now                Mon, 1 Nov 1999 23:19:07 -0800 (PST)  From: Heather < star@betelgeuse.starshine.org>   Subject: Re: New format: My 2 cents       Sorry, not to offend, but I really don't like the new Answer Guy  format!  I prefer to read it in ""The Whole Damn Thing"" format.      TWDT is always available but please, read onward...        I find that I can pick out the things that interest me much easier  if I can scan the message contents as well as just the titles.  I  usually just use the down arrow and pagedown keys to browse through the  articles.      November's style *not* a new format;  this is a special edition.  People  have been asking for the titles to be indexed, and it was clear that some i of them did not spot the ""Index to Past Answers"" gadgets found at the  bottoms of the single messages (see October issue, any message, footer).     There were a great many messages this month, but they will be published in December's issue, in the same format that October's was.        I understand that the new format is more search engine friendly so  maybe a compromise is in order.  How about a complete page in TWDT  format for each primary topic. That way those of us that like to scan a  whole series can do so without having to bounce back and forth between  individual articles and the index and the associated page reload  delays.      Not mentioned before is that cooking the TWDT version is a normal part of my submission at the end of the month... Mike, this sounds like a request to normally link that in at the Answer Guy Index level.     Of course this returns us to torturing the search engines as it would hit on TWDT.lg_answerNN.html for every amazing topic in linuxdom.  (Because we get a wide variety of questions each month, and so few search engines search for the keywords being anywhere near each other.)   I'm not at all sure  I favor this.  This is why it hasn't been linked in even though my submits have included TWDT format subfiles for a long time.  Mike, Jim, any opinions?    However, Rob, to address what you really seem to be asking for: No. Sorry. I am *not* going to republish the whole of the past answer guy messages in TWDT format by the topics I selected.  It's weird enough that I only picked one classification each, when several of them fit more than one. Several of them are superseded long ago by changes in Linux itself. It's an *index* ... that means it does *not* contain anything but pointers. Since it doesn't point to any new content, it would be a waste of time better spent on the newer messages.  Please bear in mind I do this work for LG on a volunteer basis.  I have consulting work to do as well, and would like to limit the time I spend on this.     As a side note, I usually read the Gazette on my work machine which is  that other OS :-( which complicates the process of reading the tar.gz  version.      -Rob-     That question is answered in the FAQ.  WinZIP for ""that other system"" handles tar, gzip, or tgz files without complaint.   If you insist on  doing it the hard way I believe tar and gzip might have been ported as  commandline utilities, but you'll have to go find them yourself, perhaps  at winfiles.com.    I hope you enjoy next month's column.    * Heather Stern, HTML Editor for ""The Answer Guy""     [I'm currently doing a lot of ""under the hood"" work on how the   Gazette  is linked together.  That is, writing scripts  to auto-generate the links and update them, rather than placing  the links by hand.  Once this is complete, we can look at adding  links to make The Answer Guy more readable.  But first, we have to  get used to the new Answer Guy format for a couple issues, so we can  see what is working well and what isn't. -Ed.]                 Tue, 16 Nov 1999 10:08:03 +0100  From: marco masini < m.masini@attrezzeriamarin.com>   Subject: ""great ideas""  ???  :-))    Hi guy  How are U? U make a good work with linux gazette    Why U don't create an ""index"" by word (analitical index is better?  :-)  ) ?    I' m looking for emacs but I don't know how to find something about it on your pages.    Bye    PS.  I apologize for my englis      [There is a search engine at the main site.  Starting this  issue there is a ""Search"" link near the top of both the Table of   Contents and the Front Page.     I typed ""emacs"" into the search dialog and got lots of links back.  -Ed.]                  Mon, 15 Nov 1999 11:43:26 -0800  From: Guillermo Schimmel  Subject: Re: I can't access ftp.ssc.com    I can't access ftp.ssc.com anymore.  Is my problem or the server is down?     [The server has PARANOID turned on, which means your (the client's)  forward and reverse DNS names must match or it won't allow access.  Could that be the problem?     I asked our sysadmin if we could turn off the PARANOID feature,  since the files are public anyway.  However, he was adamant that it's a  necessary security measure. -Ed.]                 Sun, 31 Oct 1999 10:21:14 +0100  From: Paul Dunne < paul@dunne.dhis.org>   Subject: to MIME or not to MIME?    I can't take issue with your plea for writers-in to stop using HTML. But I do take exception to this:       And if your mailer splits long lines by putting an ""=""  at the end of the line and moving the last character or two to the  next line, please try to turn that feature off. Also some mailers  turn punctuation and foreign characters into """" and ""=E9"" and the  like. I can't reformat those, since I don't know what the original  character was! -Ed.  P.S. This the first time ever I have resorted  to blinking text, which I usually despise. I understand some mailers  don't allow you to turn off this obnoxious ""multimedia"" formatting.  But if you can, please do so.      If your mailer can't understand MIME, and translate a so-encoded document it back into proper text when appropriate, then your mailer is broken, and you need either to fix it, or get another that isn't broken.  It really is as simple as that.     [I use mutt, which is supposed to be one of the most MIME-capable  mailreaders around.  -Ed.]     From: Pepijn Schmitz < p.schmitz@xpuntx.nl>     You can use any extensions you want, as long as you configure your webserver to use the text/plain MIME type for them. It's the mime type that the browser uses to decide whether or not to display a file, not the extension. Only when the web server doesn't provide a MIME type does the browser try to guess at it using the extension.    Also, regarding your request to turn off quoted printable characters (, etc.), my question is: why? It's a lot better than leaving the original 8-bit characters in, which may display very differently on your screen than the author of the email intended, or may be control characters which will screw up your terminal settings. Quoted printable characters (and also the ='s at the end of a line) are part of the MIME standard and should be converted back by any MIME compliant mail reader.    HTML email is even better, because it allows you to include international characters in a platform independent way (quoted printable is not platform independent). If I were you, I'd upgrade to an email reader that will handle all these things, such as Netscape Messenger.                31 Oct 1999 14:00:10 -0800  From: Stephen R. Savitzky < steve@theStarport.org>   Subject: Re: Filename extensions for web program listings    You [the  LG  Editor] write:       My question is, which filename extensions are safe to use so that  they'll show up properly as text files in the browsers?  I'm wavering  between using a language-specific extension (.c, .sh, .pl, .py, etc.)  vs putting .txt at the end of all of them (or .sh.txt, etc.) What about  listings that don't have an extension on the source file? They display  as text on my browser, but do they display properly on yours?      The correct solution is to use the correct language-specific extensions, and to configure your server to give files with those extensions the MIME type ""text/plain"".  This means that the browser doesn't need to guess (and guess wrong, in most cases) about what type the file really is.    Language-specific extensions would be the most ideal, because they   offer the possibility of syntax highlighting if the browser supports   it. (Does any browser support this?) However, I know I've tried to   view files on other sites that I know perfectly well are   text-readable, but the browser insists on downloading them rather than   viewing them because it doesn't recognize the type. (Of course, that's   better than the corollary, where it tries to view .tar.gz or .mp3   files as text.)      All browsers should use the type supplied by the server in the headers; only if the server fails to provide a ""Content-Type:"" header is the browser permitted to guess.  If your server is Apache, for example, you can perform the extension-to-type mapping in a "".htaccess"" file in the directory containing the listings -- see the Apache documentation for details.    Syntax highlighting can be done by providing two versions of the file, one in plain text and the other (with, e.g., a "".c.html"" extension) in HTML as generated by a clever highlighting programm that you run once, on the server side.  Again, nothing is left up to the browser; it's all done on the server.   From: Rich Brown < rabmar@FreeMars.org> :     My suggestion is xxxxx.c.txt, yyyyy.sh.txt, zzzzz.pl.txt, and so on.    Keep up the great work.  LG is one of my prime resources.     From: Anthony E. Greene < agreene@pobox.com> :      I'd say no extensions should be used. Most web servers default to text/plain when sending unknown files to browsers. I've never seen a browser that supports highlighting, so language-specific extensions are of limited utility.    From:  < helpdesk@buzco.penguinpowered.com> :       What about listings that don't have an extension on the source file?  They display as text on my browser, but do they display properly on  yours?       Not easily (am using StarOffice-5.1a).     Language-specific extensions would be the most ideal, because they  offer the possibility of syntax highlighting if the browser supports  it. (Does any browser support this?)     [...]    The answer to both objections is an easy-to-use, GUI, Mime setup program. The other side of this is that so many software packages ignore the system (and user for that matter) mailcap and mime-type files in favor of their own.    No extension should not be an option. Without an extension there is *no* handle to decide what to do with the file. Add "".txt"" to these.    Where an extension is already present, leave it, but provide an alternative of the same filename + "".txt"". Thus ""foo.c"" would be available both as ""foo.ads"" and ""foo.ads.txt"".    Hope this helps,  == Buz :)    From: walt < walt@aye.net>     use the .txt extension    and if you really feal froggy, call it "".text"" so the point and click crowd doesn't get confused.    From: Vrenios Alex < Alex.Vrenios@motorola.com>     First, I believe that I can ""set"" my text editor to be called up when a "".sh"" or a "".csh"" suffix is found. But that might be oo much of a pain for most people (even me) to do for every possible extension. Here's my recommendation:    Given mountfloppy.csh, a C shell script that mounds a floppy disk, use mountfloppy_csh.txt    Given convertIP.c, a C language program that converts an IP address from hex to dotted decimal or back, use convertIP_c.txt    The use of that underscore is visually descriptive, letting everyone know exctly what kind of file it is intended to be, which the dot-txt tells your OS which editor to bring up, for every one of these ascii files.    Are there any files that you are considering setting up that are -not- ascii text files? If not, maybe this will work. Good luck.    From: Jeff Rose < whisper@iag.net> :     Subject: Filename extensions for web program listings ...    I'm enjoying reading this issue of LG on my Palm Vx after downloading your text version then using a small conversion util to format into PDBformat.    Anyway, I vote for the age-old '.txt' extention for filenames. Why re-invent the wheel? And the less formatting - the better. We have _plenty_ of utilities for conversion: but TEXT vs. PDF, etc., .txt is the painless route.    My $0.02.      From: Sylvia Wong < swon074@yahoo.co.uk>     Language specific extension wouldn't work coz it's too much hard work to change the mailcap to browse a few program listing. I prefer language extension + .txt. This way, when I want to save the file (I'm using Netscape), I could just delete the .txt and don't have to type a .pl or .c or whatever.    Does Windose handle files with 2 extensions well? (Or maybe we don't care about them at all as why would anyone read Linux Gazette using windose).       [I decided to go the  *.sh.txt  route, using a language-specific  extension when one exists, but always ending in  .txt .  This  should ensure the files can be both read and downloaded verbatim on the  widest variety of web servers and browsers.      BTW, a lot of people do read the  Gazette  on Windows   machines. -Ed.]                         Thu, 04 Nov 1999 18:49:22 +0100  From:  < AntonioM.=?iso-8859-1?Q?Mu=F1oz?=Crespo>   Subject: Spanish tranlations of Linux Gazette    Dear editor,    As you said in your reply to Mr. Offret currently there's no Spanish translations of Linux Gazette. However, the only Linux on-line magazine translated into Spanish is Linux Focus (ok, they're your competitors, but it's the only you can get in Spanish for free). There're also a number of Linux magazines in Spanish but, as far as I know, they're all printed editions and they're not free!. Here is a list:       ""Solo Linux""    ""Linux Actual""    ""Linux Journal"" <-- Yes, it's published in Spanish since october or september '99!.      All of them are published by the same publisher ""Prensa Tecnica"". I don't know if you can get these magazines outside Spain.                 Sat, 6 Nov 1999 14:49:51 -0500  From: Gerard Beekmans < glb@dds.nl>   Subject: Re: Compiling everything myself       Greetings, ladies and gentleusers.     I would like to compile my own Linux system. Not just the kernel.  Everything. I've got enough room and partitions on my  disk(s) to do it. Do not tell me do buy a distribution. Until now, I've  tried a lot of them - I count eleven on my shelf - I do not  like one of them the way I would like a self-created one.     I just need a place to start. All of the distributions must have started  at some point or another - how did they do it? Please  point to a location where info may be obtained. The LDP seem to provide  _nothing_ concerned to this task.     Every hint will be highly appreciated. I would also love to contribute  documentation of the process to the Free Software  community.     Every reader is invited to answer via email.       I currently am writing a series or articles that do this exact same thing: building a new Linux distribution from scratch. Every program is built from source (though you do need a working Linux to get it initial working (eg: you need to have a running Linux + compiler to compile a compiler so you can install that on the new system and start compiling other things there).     There's one downside for you I'm afraid: I'm writing these articles for a Dutch/Belgium Ezine and therefore the articles are in Dutch (surprised? ;) But wait, there's a good side: I'm also in the process of translating these articles into English. I decided to start translating these articles a week or so ago and I haven't started doing so yet (the usual excuse; too busy with other things).    I'm also thinking of giving them to the LDP so they can be distributed as a HOWTO of some sort.     Another reason I haven't started this translation yet is because I don't know yet how usefull they would be (ie; if people actually are thinking of doing this besides me). The Dutch articles aren't done yet either because I got stuck after a while since I don't know 100% how to configure every program and things like that (building from scratch for me means also completely making your own sendmail.cf file and things like the ruleset's are just a bit over my head at the moment).    If you're interested picking up this project I'd be happy to start translating the articles I already have written and then continue finishing them with you (and possible other people who read this since I CC'ed it to LG aswell).    Hope to hear from you soon.                Wed, 10 Nov 1999 09:25:22 -0700  From: TJ Miller jr < tjmiller@datc.tec.ut.us>   Subject: Will The Priests Please Refrain From Kicking The Heathens?    Listen my children, and ye shall receive news, of a troublesome plague that sweepeth across the Land of The Holy Penguin...    Allow me to confess the blight which lay upon my soul:  I am cursed by professional necessity with an MCSE,  but I want someday to hear the revelation, the revelation that a Microsoft certification is about as worthless, as worthless an ArcNet certification would be this very day. Verily, I further want to have the luxury of looking upon my MCSE and saying ""there shalt not be further need to keepeth this foul brand upon my wretched soul...""  Can I get an ""Amen!?""    The problem remains that, in order to maketh a living, I have to prepareth my high-school aged disciples for the IT industry at large...and that necessitates teaching them the blasphemy that is Microsoft. (On a happy note, I finally got permission to get decent Linux curricula going - it will be out in January. Refer to http://www.linuxgazette.com/issue47/lg_mail47.html for more information, and pitch some more opinions at me - I'm about half-way down that page.)    But enough of the digression, my dear flock...let us kneel together, to meditate upon the source of my distress...    However, let's do it in plain English...because all kidding aside, we've got a growing and serious problem here:    While perusing the web for ideas about what would make a good set of Linux classes, I come across a disturbing trend, one that was once only an insignificant bother, but hath now become enough of a problem to warrant attention:    Linux Over-Zealotry.    I guess it began to demand notice (for me) during the badly-managed PCWeek NT vs. Linux security tests. Now, I believe that PCWeek made a huge mistake (they forgot an RPM patch), but, IMO, an honest one...could have happened to anyone. The reaction sickened me... zealots everywhere began screaming about how PCWeek was ""Microsoft's Whore"", and how they were suddenly a part of some huge conspiracy to quash Linux... I then begin to look about the various Linux forums, to see even more venom and flame, directed at anyone who dares to say that perhaps Microsoft does have software that will do certain things better than Linux.    I have a newsflash for the zealots: In some cases, NT is better than Linux. In Others, Linux is better than NT. It all depends on your specific needs and circumstances. Any real-world IT manager with more than three working brain cells will tell you the very same thing.    Now, what motivated me to write this was an article I noticed, which read:    ""The people who complain about it not supporting 100% of games or whatever don't seem to get what the alternative is. It's easy to say Linux is better than a certain monoploy(sic) based OS but to put your money (ok it's free but nevermind) where your mouth is, is something else.""        -James Rogers, recently in osOpinion    Now, if I owned a business, didn't know much about computers, and needed an OS that was compatible with all of the machines I have, the last thing  I want to hear is: ""Too bad you Microsoft scum!""    If I were Joe Six-Pack, wanting a decent OS  at home to do my bills and send the occasional e-mail to mom with (and an OS with all the cool games for my kids, of course), the last thing I want to hear would be: ""no way, d00d - you gotta conform to the Linux way or else! We don't support yer fave games, so deal with it!""    You notice a trend here (at least I hope you do...): I used regular, typical situations. If you want Microsoft's piece of The Market Pie, you're going to have to woo these exact types of people away from their MS-run boxes...    A Very Big Clue: You won't capture the heats and minds of MS users by calling them ""sheeple"". You won't do it by insulting their intelligence. You won't do it by shouting like a spoiled child whenever Linux gets bad press (no matter the reason.) And most importantly, you certainly won't lure them away form Microsoft by demanding that they do something the hard way, when for only $85 they can do it easier with (insert big, bad, monopoly OS product upgrade here.)    You also won't do it by letting others perform these same indecent act without nary a comment from members of the Linux community who happens to catch them in the act...    Now, it had always been (at least, used to always be) the case that Linux adapted to needs - someone needed a driver for (insert oddball peripheral item here), odds are that all he/she needed to do was ask, and there was more than likely a driver written for it by (insert friendly programmer's name here), and that it can be downloaded for free at (insert URL here).    If Linux wants a bigger market share, this is exactly what needs to continue happening....customer-focused, friendly service to the world community at large.    I recall - that there indeed is a perfect article for describing how we can advocate, and by extension make Linux a dominant OS in this world...I propose that we all read it at least once in our lifetimes: http://www.ssc.com/mirrors/LDP/HOWTO/mini/Advocacy.html    After all, if you want converts, you don't do it by kicking the heathens you want to proselytize...especially not in a consumer-driven market such as computer products.     There is one other note: If you see anyone misbehaving, thereby giving Linux a bad name, then go out of your way to show that person the light...and in the process showing the world at large that the Linux community won't tolerate childish behavior...which would make an ever better impression on the undecided and the unknowing.     Now go forth my precious flock, to spread peace and Open Source among the perilous world in which we live...     TJ Miller jr (tjmiller@datc.tec.ut.us) is a secondary education teacher in the Utah ATE (read: Vocational Technologies) school system, specializing in the instruction of Unix, Networking, and (because they make me do it) that big, bad GUI-based OS we've all heard of. He putzes around with Linux far more than is considered healthy, but enjoys the outdoors enough to go hunting, skiing, hiking and fishing whenever weather and time permit.                Mon, 1 Nov 1999 13:35:49 +0800  From: Li Wei < leeway@kali.com.cn>   Subject: comment    the 47th issue is the most boring lg i ever read. in other lgs, i can always find some interesting articles.     [Which kinds of articles do you consider ""interesting"" and ""boring""?  -Ed.]                 Thu, 11 Nov 1999 11:26:51 -0800 (PST)  From: Nicolas Chauvat < nico@ISI.EDU>   Subject: Re: Duplicate messages, unreadable listings, Pollman article     The [ LG ] FTP file for issue 47 is 2.6 MB.  This is due to the  large number of graphics.  Next month will have fewer graphics to bring  the file size down.      Graphics shouldn't be a problem. You have a lot more graphics in some web pages and the whole thing is much lighter than this. The problem is that most graphics are not compressed... well, they are, but not enough, or the image depth is to high. Just make the authors follow the basic rules of image making for the web and it will be fine, even if you have more graphics.    Use jpg for photos (lots of colors, no line or clear boundary)  Use gif for others (fewer colors, sharp boundaries)  Use png for either one.  Try with different compression levels (jpg) and different image depth/palette (gif).    There are programs out there that do that for you, i.e. take the image and output the same with the best compromise size/quality. I don't remember the names though, but they are probably listed on freshmeat or linuxberg.    Hope this helps,    -- Nicolas, Coordinator of the french translation of the Linux Gazette     Hi, I'm a deadly e-mail virus, please copy me into your .signature file  to help me spread. :: Bonjour, je suis un dangereux virus. SVP  copiez-moi dans votre fichier .signature pour m'aider =E0 me propager              [There's one of those pesky  =E9 's again.  Wish I had a table  to convert it to its Latin-1 equivalent.  Must be an    à . -Ed.]                   31 Oct 1999 09:33:31 -0700  From: Eric Hanchrow < offby1@blarg.net>   Subject: Suggestion for TOC pages on the web    I'm looking at http://www.linuxgazette.com/issue47/lg_toc47.html, and I see many bulleted items, each corresponding to one article in the current issue of Linux Gazette.  It would make my life a tiny bit easier if each of those items showed me, not just the article's title, but the first few lines of the article itself.  That way I could tell if I wanted to read the entire article.  As it stands, I have to guess.   This is especially true for the articles that appear to be regular features.     [There isn't enough room in our current table of contents layout  for these lines.  For the Mailbag, 2-Cent Tips and News Bytes, it  wouldn't make sense because these columns consist of a lot of small  items which are not related to each other, and thus, the first letter  is not representative of them all.  Also, it would mean a lot more  manual editing to decide which lines to include.     Thanks for the suggestion, though, and I'm open to hearing any  others you may have. -Ed.]                      This page written and maintained by the Editor of the  Linux Gazette .  Copyright © 1999,  gazette@ssc.com   Published in Issue 48 of  Linux Gazette , December 1999      ""Linux Gazette... making Linux just a little more fun! ""              Contents:     Distro News   News in General   Software Announcements                           December 1999  Linux Journal         The December issue of  Linux Journal  is already on the newsstands. This issue focuses on system administration.     Linux Journal  has articles that appear ""Strictly On-Line"". Check out the Table of Contents at   http://www.linuxjournal.com/issue68/index.html  for articles in  this issue as well as links to the on-line articles.  To subscribe to  Linux Journal , go to   http://www.linuxjournal.com/subscribe/index.html .       For Subcribers Only :  Linux Journal  archives are available  on-line at    http://interactive.linuxjournal.com/                 Linux Journal / Linux Gazette  Millenium Edition Archive CD-ROM          Can't find that April 1996 Linux Journal? Someone borrowed the September 1998 copy?    Now you can have it all!  All of Linux Journal (issues 1-56; 1994-1998) and  all of Linux Gazette (issues 1-45; 1995-1998) on one archive CD.    Click  here  for more information.         Distro News                Caldera         Antarctica IT and Caldera Team Up     Framingham, MA, November 11, 1999 - Antarctica IT, Inc. and Caldera Systems, Inc. will work together to provide Linux services in Boston and New England.               Corel           Corel Signs Linux OEM Agreement With PC Chips                 Libra             NORTH VANCOUVER, BC, November 2, 1999 - Libra Computer Systemstoday announced the release of 'Linux by Libranet', based on Debian. The CD, includes one year of support via email and fax, Linux HOWTO documentation and the Debian-Guide, a concise, easy to follow guide to the use of the Debian Linux Distribution. The CD may be purchased for $27.00 at  www.libranet.com .  Libra Computer Systems is a privately held company based in North Vancouver, BC, Canada.                Red Hat         Red Hat acquires Cygnus, promotes Matthew Szulik to CEO   See press releases at the  Red Hat home page , and the commentary    Red Hat acquires Cygnus .     Red Hat to Support Leading Open Source Application     Durham, N.C.--November 3, 1999--Red Hat, Inc., today announced an expansion of its services program that will provide the consulting and support enterprise organizations need for nearly all of the popular, powerful, open source software applications used by enterprises worldwide.    As the first step in the program, Red Hat's worldwide services group will immediately offer expanded Service Programs for popular open source software solutions, including top Internet software like the Apache Web Server, Sendmail and Postfix. Apache is the number one Web server and runs more than 55 percent of the Internet's Web sites. Sendmail is a messaging solution that powers 80 percent of Internet Service Providers (ISPs).    The sweeping initiative will expand in the coming months, embracing more open source solutions. This broad support program delivers enterprise users a single, trusted source for their open source computing needs.      Center for Open Source     DURHAM, N.C.--November 1, 1999--Red Hat, Inc. announced  the formation of a new non-profit organization, the Red Hat Center for Open Source (RHCOS), that will sponsor, support, promote and engage in a wide range of scientific and educational projects intended to advance the social principles of open source for the greater good of the general public.     eSoft     eSoft Inc. , a company that develops and markets the TEAM Internet Linux software suite for small businesses, has joined Red Hat Inc.'s Development Partner Program.     Pact With RSA To Enhance Security     Red Hat, Inc. has  entered into a new    strategic agreement  with RSA Security, Inc.  to enhance security for professional users of  the Red Hat Linux OS package...                 SuSE        Photodex and SuSE Give Linux an Imaging Boost      Austin, Texas -- November 8, 1999 --   Photodex  Corporation, a leading supplier of digital content management, imaging and multimedia software, and SuSE Inc., announced today their partnership to provide CompuPic Digital Content Manager software for the SuSE Linux operating system.    ""CompuPic brings powerful, yet user-friendly imaging capabilities to the SuSE Linux desktop, enabling SuSE Linux to compete head-on with other platforms.  These tools should not be taken for granted,"" said Paul Schmidt, CEO, Photodex.  ""Professional web developers need powerful tools to more easily develop and maintain web sites.  Even novice users find it easier to use the Linux desktop when familiar applications are available.  CompuPic solves these problems and more.""     E-Commerce on SuSE's Portal     Linux vendor SuSE announced this week that it has tapped  outsource solutions provider Digital River, Inc. (Nasdaq: DRIV)  to turn its online information portal into an    e-commerce site .                 Storm         Storm Linux 2000 to Ship with VMware     Vancouver, Canada - November 17, 1999 - Stormix Technologies, Inc., announces that Storm Linux 2000 will ship with the VMware evaluation binaries, a software technology that allows the running of other operating systems, including Windows, from within Linux.    Stormix also announced Storm Linux will ship with a full version of StarOffice, and a demo copy of Enhanced Software Technologies' BRU (Backup and Restore Utility).             News in General                C.O.L.A news          TheStuff.net  is a new, online source for information and tools encompassing all free Unix operating systems.     Spanish translation of the Linux Administrator's Security Guide        Dual chrooted Bind/DNS servers Mini-HOWTO                  News from The Linux Bits          LG  got a nice little mention in TLB issue 23  ( http://www.linuxdot.org/tlb/24.html ):    The latest edition of the ""New York Times of Linux e-zines"" - Linux  Gazette - was released today, featuring the usual crop of interesting  reading -- and plenty of it. Once again we get a few mentions.  ""Gee  ma, we're famous."" :)      Other news in issue 23:        Creative Labs To Embrace The Open Source Philosophy       From issue 22  (  http://www.linuxdot.org/tlb/24.html ):         ATI Embraces Linux      Tom's Root/Boot Disk  A good rescue disk to have.   [Our sysadmins use it to do workstation  installs and can't sing enough praise of it.  -Ed.]      Emacs Tutorial #1: Basic Editing     ""A complete command reference list. Perfect for printing off and having at your side whilst you struggle to        become proficient with this scary package.""      TLB's Laurence Hunter wrote to the  LG  Editor:    If there's ever an article that you particulary like in any issue (even  back issues) feel free to use it, change the formatting to your liking,  and edit it to your heart's content. You don't need to ask our  permission either. Like you we put together The Linux Bits purely for  fun so no copyrights etc exists on them and we ask nothing in return.  Anything to help out the Linux community is plenty payment for us.     [Thanks!  I'll remember that. -Ed.]                  Upcoming conferences & events          The Bazaar : ""Where free and open-source software meet the real world"". Presented by EarthWeb. December 14-16, 1999. New York, NY.  http://www.thebazaar.org/       SANS 1999 Workshop On Securing Linux .  The SANS Institute is a cooperative education and research organization. December 15-16, 1999. San Francisco, CA.  http://www.sans.org        IDG Communications France, organisateur de LinuxWorld, et Sky Events, organisateur de LinuxExpo, unissent leurs efforts pour crer une manifestation unique,  LinuxWorld/LinuxExpo . Cet vnement Linux ouvrira ses portes du 1er au 3 fvrier 2000, au Palais des Congrs de Paris (Porte Maillot).               Linux File, Print & CD Thin Server in Flash-ROM         KYZO has today released the commercial version of its hugely popular PizzaBox Linux distribution, so called because a prototype server was built in a Pizza Hut Takeout box - take a look -   www.kyzo.com     In the first month the site took over 500,000 hits has recently registered 75,000 in one day. Registered users that have downloaded and run the free PizzaBox Server include both the Goddard Space Flight Centre and the Jet Propulsion Laboratories at NASA.     The commercial version is the same basic software as the free version, which will still be available, but differs in one significant respect. It is shipped pre-installed in a bootable Flash-ROM and comes with the the circuit board you need to make it boot in any 486 (or above) PC. With 10 times the life span of a hard disk, the package is aimed at system builders who are fed up with having to send skilled engineers to sites for days on end to re-install a File Server every time a hard drive goes down.     The system includes File, Print & CD sharing, remote access (for full remote administration), UPS monitoring, Tape backup, Hardware monitoring, APM. It will automatically accept both SCSI & IDE hard drives and comes with a sophisticated, JavaScript enabled, web management interface. It is aimed squarely at the SME market where current offerings from the big players are overcomplicated for the SME sector.                   Cobalt Networks Selected by Allegiance Telecom         Cobalt Networks has announced that its RaQ 2 server appliance will be the dedicated web hosting platform for Allegiance Telecom customers.  The RaQ 2 provides a way for ISPs like Allegiance to offer top quality dedicated web hosting with a low TCO and a quick ROI.      This news comes on the heals of last week's introduction of the RaQ 3i, Cobalt's third-generation server appliance.  The RaQ 3i rounds out Cobalt's product family by offering ISPs a high-end server appliance that can handle high-traffic Web portals, e-commerce, and application hosting at a price that the small to mid-sized business market can afford.     www.cobaltnet.com                     E-Commerce Minute            EBIZ Re-Launches TheLinuxStore                        E-Exams announces a Linux System Adminstration exam        E-Exams announces a Linux System Adminstration exam. With E-Exams you can create customized technical exams to assess potential employees.  Among the many exams E-Exams is offers, is an exam for Linux System Administrators. Companies who have signed-up for the service, can have potential employees take a web based exam. Questions range from beginner, to intermediate to expert. The results can be used to determine whether the candidate should take the next step in the hiring process. The Linux System Administration exam is distribution neutral. It also among the first exams which the company is offering. The company is planning to create many more exams, including some distribution specific nes, starting with a Red Hat Linux exam. Specific topics such as networking with Samba are also in the works.    You can learn more about E-Exams at:  www.eexams.com                          National Semiconductor announces Linux support for its geode webpad reference design       November 15, 1999 - National Semiconductor Corporation today announced that Infomatec AG will port its custom Linux-based basic platform Java Network Technology (JNT) operating system to the National Geode WebPAD platform - a complete hardware and software reference design for a wireless Internet personal access device (PAD). This collaboration is the first result of an agreement signed earlier this year by National and Infomatec to partner on the development of information appliances such as set-top boxes, thin clients and PADs.                    Is Linux available on my platform?         The   Current ports of the Linux OS  web page lists a wide variety of  architectures and platforms Linux is available on.    The main ports are :    - Special PCs and Near-PCs SGI-Linux (intel-SGI), MCA Linux (MicroChannel), Linux/98 (NEC PC-98), LinuxIA64 (new 64bits-merced- intel chip)    - Motorola processors Linux/m68k (Motorola 68000), LinuxPPC (PowerPC)    - SPARC chips S/Linux (Sun SPARCstations), UltraLinux (Sun UltraSPARC)    - Compaq (former Digital) chips and equipments VAXlinux (VAX computers), Linux/Alpha (Alpha processors)    - Other RISC chips ARM Linux (ARM/StrongARM), Linux PA-RISC (HP's PA-RISC), Linux/MIPS (MIPS chips)    - Handhelds, Microcontrollers, embedded and other small systems LinuxSH3 (Hitachi SH3), Linux/Microcontrollers (Palm,Motorola ColdFire), ELKS (8086-80286), VMELinux (VMEbus embedded systems), LinuxCE (to substitute WindowsCE), PDAs in general    - Microkernels and real-time MkLinux (Linux on Mach =B5-Kernel for Apple PowerMacintosh, HP PA-RISC and x86), DROPS (Linux on the L4 =B5-Kernel and Fiasco =B5-kernel), Real Time Linux (RTLinux and KURT)    - Multimedia Computing, QLinux    - SMP and clustering MOSIX for Linux (a bridge between SMP and MPP), Beowulf Project (parallel clusters), Linux SMP(multiprocesor)    - Misc ports Linux on IBM 370/390, Linux/AP+(Fujitsu AP1000+), Linux-AS/400(IBM AS/400)    - Cool things running Linux Not ports, but who cares?                    ""Linux Administration Made Easy"" (LAME) guide         The ""Linux Administration Made Easy"" (LAME) guide, recently updated for Red Hat 6.1, attempts to describe day-to-day administration and maintenance issues commonly faced by Linux system administrators.    This 130+ page guide is geared to an audience of both corporate as well as home users, and attempts to summarize the installation and configuration, as well as the day-to-day administrative and maintenance procedures that should be followed to keep a Linux-based server or desktop system up and running.    LAME can be found at    www.LinuxNinja.com/linux-admin/  in a variety of document formats.                Linux Links           The legal findings in the antitrust case against Microsoft     An article that alleges  Microsoft is operating a pyramid scheme  to artificially boost its stock price.       Parodies of Linux and its friends and enemies :  mages, webpage sendups, poetry, songs, articles, etc. Stars a Microsoft Myths spoof page.     Linux Fool.com  is a new web site offering Linux users an unbiased forum for discussions and information sharing. LinuxFool.com is an official mirror of the Linux Documentation Project.     /www.QuestionExchange.com   allows users or system administrators to name their price for high-end tech support in open systems -- Linux, Apache server, Sendmail, etc.     How the   University of Georgia English Department  is using Linux.    A   Linux-Windows comparision , and other Linux-related stuff.     Transmeta's Crusoe        LinuxMall Re-Launches With New Look                         Software Announcements               C.O.L.A software news          Kmahjongg 0.5 (beta)        Warbird  is ""a new silly 3D game"" using VRML.      HTMLDOC v1.8 HTML document conversion  to PDF, Postscript and indexed HTML.                 Calerga SysQuake Viewer         Lausanne, Switzerland, November 2, 1999 - Calerga announces today SysQuake Viewer for Linux, a port to the Linux operating system of the software for understanding systems by interactive manipulation of graphics.    SysQuake is a ground-breaking application for understanding and designing complex systems by the use of interactive graphics. Interactivity lets the user manipulate graphics, observe how phenomena are related, and change parameters to improve the design of a technical device. Understanding how initial conditions affect a simulation or how the parameters of a feedback controller determine the behavior of a dynamic system is made much  easier than with the static graphics created by existing software.      www.calerga.com/SQViewer/index.html                   EasyCopy screen capture utility         SAN JOSE, Calif., October 19, 1999 - AutoGraph International (AGI) is demonstrating its commitment to the Linux community through our EasyCopy suite of products.  The Linux operating system has always played an immense role in AGI and some of our developers are active in the Danish Linux community.  In fact, Linux engenders a decidedly emotional response from our normally cool, analytical development staff.      Enhanced X Capture offers full screen, selected window or an arbitrary rectangular area capture.  All original colors of the windows are preserved with any combination of windows.  Even when a window appears in false colors on the screen due to color table overrun, it is captured in its original colors by EasyCopy and printed correctly.     www.augrin.dk                   DataKeeper           DataKeeper  by PowerQuest (maker's of PartitionMagic) ensures backup protection by continuously monitoring file activity in the background,   and supporting compressed backups on the fly. The user configures the programme and specifies   backup methods to backup drives, folders and files, and DataKeeper then follows these commands automatically, and unobtrusively.      Because DataKeeper creates a backup each time a file is modified, scheduling is unnecessary.      Any removable disk drive, network drive, hard disk or floppy drive is supported by DataKeeper.   And because it uses a high compression rate, DataKeeper saves disk space.                   News from Loki Entertainment Software         TUSTIN, CA -- November 1, 1999 -- Loki announces  the Linux demo version of Railroad Tycoon II: Gold Edition.    Loki released the full version of Railroad Tycoon II, along with The  Second Century Expansion Pack, last month to strong reviews. This  real-time strategy simulation game places gamers in a world of big  business, expansion and engineering in which all aspects of the railroad  industry can be controlled. It features a simulated stock market and  sophisticated economic system, and as the years progress, gamers must  solve modern problems such as the increasing demand for mass  transportation in major cities.     The demo allows users to exercise their tycoon tendencies in five  different scenarios, and is now freely available for   download .    TUSTIN, CA, November 3, 1999 -- Loki is now developing the Linux version of Heroes of Might and Magic(tm) III.    Heroes of Might and Magic III is the latest installment in the series of  top-selling, critically-acclaimed strategy games. This turn-based,  strategy war game set in the popular Might and Magic(r) fantasy world has  already captivated legions of PC gamers. It was awarded 5 out of 5 stars  from both Computer Games Magazine and the CNET Gamecenter, as well as an  Editor's Choice Award from Computer Gaming World Magazine.    Heroes III will be available for the Linux operating system wherever  software is sold by mid-December.    The Loki Hack hacks on the Linux version of Activision's Civilization:  Call to Power are   now available  for public consumption.     TUSTIN, CA -- November 4, 1999 -- Loki Entertainment  announces today the  creation of a CVS server to facilitate public access to its Open-Source  projects.    ""One reason we've been successful is that we create Open Source tools to  replace proprietary code in our games,"" said Scott Draeker, president of  Loki. ""We give these tools back to the community in the form of Open  Source projects. We hope other developers will evaluate our tools for  projects and choose to use them rather than the proprietary alternatives.""    The Loki CVS server allows the public to access the latest development  source code for Loki's several Open-Source projects, including SMJPEG, a  motion JPEG library, SMPEG, a MPEG-1 playback library, and Setup, a GUI  Installer. Other modules available for viewing include SDL, a  cross-platform multimedia development API, and Mixer, an enhanced version  of the sample SDL audio mixer.    Loki's Open-Source projects are freely available for download from  www.lokigames.com , and are offered under the GNU Library Public License (LGPL). A web interface for the CVS server is available at  cvs.lokigames.com .                    Other software            Anti-virus software  from Central Command, Inc. and Kaspersky Lab.     Max for Linux  is a new product for compiling and running Xbase code on Linux-based computers, and is available for dowload.     Photogenics  is an award-winning  graphics package, first released on the Amiga five years ago.  It will soon be available on Linux.     Cycas  is a new 2D + 3D CAD software, based on GTK.  In addition to typical CAD functions, it offers special elements and techniques for architectural design.     The  CRiSP  visual text editor from Vital.      txt2pdf  from Sanface converts text reports to PDF format.  Can colorize words using Perl regular expressions, add  border to every page, print in  2-column format, and more.                 This page written and maintained by the Editor of the  Linux Gazette .  Copyright © 1999,  gazette@ssc.com   Published in Issue 48 of  Linux Gazette , December 1999      Contents:   Greetings From Jim Dennis        PCI Winmodem --or--   Why Winmodems Don't Work Under Linux, Yet!     Do you know of any V.90 internal modems that are not winmodems? --or--   Linmodems.org     LI_ DOH! --or--   Major Hardware Problems     Clearing Lilo from MBR   modem problems --or--   Modem Problems on a Win '95 System     Questions about Linux --or--   Setting COM port speeds     virus protection --or--   Virus Protection for Linux: A Non-Issue ... But....     Telnet trouble   Modem Noises --or--  Quiet, Modem!    Dual Booting without Re-Partitioning   Regards from Argentina   re: Helpless (issue 45 of linuxgazette)   Thanks!   thanks answer guy! --or--   Just Buy a REAL Modem     Red Hat --or--   Telnet gives: ""Connection closed by foreign host...""     multiple root accounts --or--   Multiple Root Accounts: Delegation     opl3 yamaha/SAx sound card --or--   Soundcard Drivers for Win '98?     Another ""respawning"" question --or--   Author Responds to ""gdm Murdered Mysteriously""     Unable to login to SuSE --or--   Upgrade to  6.2 from 6.1 Disables Login     Doslinux --or--   Euphoria      Dell EIDE TR5 Tape Drive    Some basic ftp questions --or--   FTP Daemon: Special Requirements     RedHat Login Problems --or--   login, su, and passwd dies: Everybody dies!     Files invisible via Telnet? --or--   Files invisible via Telnet?     Thanks for the sendmail info in September's column --or--   sendmail Masquerading, Configuration, and User Masquerading Revisited     Segmentation Faults --or--   General S. Fault     Problem of Linux connecting to the Internet thro' MS Proxy --or--   Linux Workstations Behind a Proxy/Firewall     LILO Lockup --or--   LILO Stops at LI     Need help !! --or--   Protocols on top of Protocols:  It's Protocols ALL THE WAY DOWN!     Uninstall Linux --or--   Uninstalling Linux     your web --or--   Who is Jim Dennis?     FoxPro 2.6 on Linux --or--   FoxPro 2.0 (SCO) Running Under Linux: Try Flagship?      Coping with Bad Sectors    Linux memory management --or--   Homework Assignment: Write about Linux Memory Management     Lt Modem --or--   HP with LT Winmodem     about slackware --or--   Linux to HP9000 Through RAS?     TCPMUX on Linux --or--   TCPMux Revisited:  You'll need a Daemon for it, or a Better inetd     probs --or--   Overwrote NT with RedHat: Good Idea But Bad Move     Need Advice --or--   Partitioning Advice     Unix emulator under Linux. --or--   UNIX Emulation Under Linux?  iBCS     PAM applications running as root (Was Re: WebTrends Enterprise Reporting Server)   Looking for help --or--  International Keyboard Mappings for    rsh --or--   Really Wants 'rsh' to Work.  Really     RedHat 6.0 - various problems --or--   Laundry List of RH 6.0 Problems or Hardware Blues     spying --or--   More AOL Instant Messenger Spying     X respawning question and answer --or--  Another Solution, or a Different Problem    Using LILO to boot directly to dos --or--  Setting the LILO Default    glibc --or--  Multiple Concurrently Installed Version of glibc    lg #45: Limiting Internet Access through Cable Modems    The Linux Startup Script?    Comcast and IPmasq --or--  Short names for Long Domains?    serial port snooping --or--  Snooping on a Serial Port    Maximal mount reached; check forced --or--  Maximal Mount Count Reached   plus, Ted T'so replies.   QUESTION --or--  Selecting a Lotus Notes Platform    RedHat 6.0:Telnet has no login prompt --or--  ""telnetd connected:"" But No ""login"" Prompt    A Staging Server --or--  Staging Server on localhost    CDR used in scsi emulation --or--  Mounting CDs on IDE CDRW Drives            Greetings from Jim Dennis     I was working on a long, involved, probably tasty message to use for my greetings this month.  Unfortunately, it's long, involved, and I think I want to rearrange it a bit, but don't have a lot of time because we're heading down to L.A. to be with family -- specifically, a science fiction convention we attend every year.      So, I'll aim for something less lofty.  I'm finally getting a chance to work a bit with my new improved workstation, and I must say I'm quite  pleased with console-apt (a curses interface for Debian's ""apt"" package manager).  We still have quite a mixed bag of distributions around the  house though.  I think I might write an article comparing the various  package management styles available.  I may or may not focus only on Linux for that.    Sadly I get to spend even more time in Arizona after I get back.  Most people would call me crazy, but I like it a bit better when it's gray and rainy -- reminds me of my youth in Oregon.      Happy Thanksgiving, everyone.           Why Winmodems Don't Work Under Linux, Yet!     From Chuck Winters  on Thu, 23 Sep 1999         What is the difference between a winmodem and a regular modem and why will it not work on a Linux box.  I have been looking all over for this information, and I can't find it.  All I can find is that a Winmodem doesn't work on a Linux box.  Could you also put up some reference links to some reading material on the web.  Thanks.     Chuck Winters     Check out  http://linmodems.org      Also look at my recent rants on the topic using the Linux Gazette search engine (WebGlimpse) ( http://www.linuxgazette.com/search.html ).                 Linmodems.org     From Dick King  on Thu, 23 Sep 1999         It's kind of annoying.  You can't tell by looking at the ad or sometimes even the box [unless you notice that it requires a Pentium, but they don't always admit that].  I would rather buy an internal modem because the only space i have on my cluttered desk is inside the tower and my transient absorber has no room for one of those little power cubes    but it looks like i need to go external to be safe.     -dk     Try following the FAQ link somewhere under  http://linmodems.org      There is an interesting discussion about Linux support for Winmodems and a link to someone else's FAQ for identifying the bloody things.     (I like the idea of ""linmodem"" as a generic cheap telephony interface card.  We'll see what it does to performance and all that, when someone ships code).                 Major Hardware Problems     From Rian Kruger  on Thu, 23 Sep 1999         Here is my problem.     I have been asked to fix a computer which uses LILO to Boot and is partitioned WinNT, Linux. Fine and Dandy.     The problem is that one morning the computer desides not boot. All I get is LI_ where it should say LILO: and then boot up.     I have a rescue disk but this was created when installing Linux on another machine. Both Destributions are  Red Hat .     I insert the disk and start the machine     So then I get LILO: it then says type rescue, which I did... Alls well, till the machine asks:     VFS: Insert root floppy disk to be loaded into ramdisk and press ENTER     On pressing error things go well enough for long enough to give you a false sense of security before hitting you with.     floppy0: data CRC error: track 0, head 1, sector 12, size 2 floppy0: data CRC error: track 0, head 1, sector 12, size 2 end_request: I/O error, dev 02:00, sector 29     repeatedly     If I try to boot linux from the same Boot disk.     [crash messages ellided]     Thats when I got desperate and tried to boot from a NT repair disk (also created on another machine during installation)     And the Computer Says:     The emergency Repair Disk is not startable.     Repairing a damaged Win Nt Installation is an option available at the beginning of the win NT Instalation.     To start setup bla bla bla....     If I take this root, am I going to have to reformat the entire machine, will I loose all the Linux info, How do I save the situation. Please help, sagely advice would be much appreciated.     Thanks  Rian     Sounds like a bad controller, or a dead DMA chip.  Might be some memory that went wacky.     It sounds like hardware failure.                 Clearing Lilo from MBR     From Norman Elliott  on Thu, 23 Sep 1999       Just read the item on clearing lilo.     All I do is boot from a Dos ( 5 or greater ) boot disc and issue the command:     fdisk  /mbr      that seems to fix anything including boot sector viruses. Maybe Linux fdisk would take the same parameter. I enjoy your column, keep up the good work, best wishes,     norm     The  /MBR  option was undocumented and only introduced in MS-DOS 5.0.  I don't remember the question to which you were referring.  If I didn't mention FDISK  /MBR  it was probably because I was not assuming that the user was trying to restore an MS-DOS 5.0 or later boot loader to their system.     Linux fdisk is a different program and doesn't touch the boot code in the MBR.  It only works on the partition tables (which comprise the last 66 bytes of the MBR and possibly a set of others for extended partitions).     There are several Linux programs which do write boot records.   /sbin/lilo  is the most commonly used.  'dd' will do in a pinch (if you have a .bin image to put into place).     BTW: don't count on  /MBR  to fix a virus.  Some viruses encrypt portions of your filesystem, thus causing major problems if they aren't removed corectly.  To prevent infection by boot sector viruses, disable the ""floppy boot"" options in your BIOS.  You should only enable those long enough to perform an OS installation or system recovery and disable it immediately thereafter.  To prevent viral infect by ""multi-partite"" and ""file infector"" viruses, stop running MS-DOS.  To avoid MS Windows macro viruses, avoid MS Office, MS Exchange and related software (with virus^H^H^H^H macroing hooks built into them).                 Modem Problems on a Win '95 System     From Benedict, Kevin F  on Thu, 23 Sep 1999         I have a windows 95 system, and was using a U.S. Robotics 33 external modem. It started working spiratically. I received a U.S. Robotics 56k external modem as a gift. It was new. I hooked it up, and now my machine will not boot up unless the modem is turned off, or  the serial cable is unplugged. The control panel identifiles com 2, . If I boot up, and then connect it, and try to add it to the system, the system locks up. On boot up, the system gets all the way to ""starting windows 95"" , access the cd rom drive light briefly, then the modem trsl ight, then locks up.  Microsoft says it is a hardward problem, and U.S. Robotics took the modem in for service, and returned it, saying nothing was wrong with it. I have replaced the cable, with no effect. I can boot up in safe mode o.k.. Is there something that could help me besides taking the machine into a shop? thanks for your consideration.     Well, it's an external modem.  So, it will probably run under Linux.  Of course the machine might have problems running Linux --- so you might want to replace that and your OS.  I'd start by just replacing MS Windows '9x with Linux or  FreeBSD .  See if that works.     BTW: I'm the Linux Gazette Answer Guy.  You might want to read some of the back issues, or the FAQ, to understand why my answer is so obtuse.  More importantly you might want to actually READ some of the web pages that come up when you're desperately searching for support that your software vendor clearly is not providing.  If you'd READ any of the links from which you found my e-mail address then you might have seen that I don't DO Windows.  Most importantly you if you READ before you e-mail question you won't sent ""off-topic"" questions to UNIX, MacOS, and other ""answer guys"" that don't DO Windows.                 Setting COM port speeds     From Jason_Magill on Thu, 23 Sep 1999         Answer Guy,     I have an application that I am running that requires me to read the serial port (Com2).  The problem is that I need to read it at 9600 7-E-1.  How would you go about doing that so when the system is rebooted it will automatically read the serial port at 9600 7-E-1?     I could really use your help.     Thanks, Jason     You should be able to do that with the following command:       stty 9600 parenb cs7 < /dev/ttyS1     ... or something like that.     Note you must redirect  INPUT  from the serial port to the 'stty' command.  This is because the terminal settings are accomplished through an  ioctl() .     You might also look at the 'setserial' program.  It works a bit differently (and is Linux specific) whereas the 'stty' program has been around for UNIX for many years.     Note also that we use ttyS1 for MS-DOS COM2.  This is because Linux counts these devices from zero.  There is no guarantee that Linux will detect these ports in the same order as MS-DOS, but usually COM2 should be  /dev/ttyS1.      The parenb is to set ""parity even"" (I don't know why the have the ""b"" there --- for ""byte"" maybe?) and the cs7 is to set the ""character size.""  There are many other 'stty' settings available.  Read the 'man' page for details.                 Virus Protection for Linux: A Non-Issue ... But....     From muzician  on Thu, 23 Sep 1999         Subject: Re: virus protection I cant find any references to that.  I am installing 6.0 for the first time, and need to know what to do.     Basically viruses are a non-issue for Linux and other forms of UNIX.    While it is technically possible to create them, the multi-user design of UNIX-like systems coupled with the widespread practices that separate ""normal use"" (access to applications, and user data) from ""administration"" (use by 'root' user) make the OS very hostile to virus propagation.     You can write a virus, but it won't spread.     This is one of the benefits to the convention of logging in as a ""normal user"" for most of your Linux work and reserving the ""root"" account for upgrading and installing software.    Another benefit is that it limits the damage you'll do with a careless user command.     This is not to say that Linux and UNIX are immune to viruses, trojan horses and other forms of hostile code.  Far from it. There are many programs that run with ""root"" privileges on a typical installation.  Any of these  might  be ""tricked"" into acting on an attackers behalf.  They can be subverted, which leads to the compromise of the whole system's security.     Any program that can be ""tricked"" (subverted) into running foreign code, or otherwise compromise the user's and system administrator's intentions has a bug.  When we find these bugs we fix them.     Finding the ways in which such programs can be commandeered by hostile users, and by anonymous attackers over networking connections is an ongoing effort by thousands of programmers throughout the open source community.  There is nothing Linux specific about these efforts.   OpenBSD  ( http://www.openbsd.org ) is most renowned for it's accomplishment of a comprehensive audit of its own code.  Some of that code is being re-ported to Linux (for example the BSDish FTP daemon that's included with some distributions).     Linux and UNIX code auditors tend to focus on programs that are run ""SUID"" (with the effective permissions of the program's owner, rather than those of the owner of the executing process) and with ""daemons"" (programs that act as ""servers"" for network protocols and provide other local services).  These are the most obvious cases where programs are an interface between ""security contexts.""     For a cracker (any anonymous attacker of your systems) the ""mother lode"" is a network process that runs as 'root'  and has a remotely exploitable bug (often a buffer overflow, a particular sort of bug where an expected input is filled with an excessively long response which contains some hostile code). Finding one of these allows a cracker to remotely assume control of a whole system.     These sorts of bugs are not specific to Linux, or UNIX.  They're possible under NT and most other operating systems as well.  They are commonly detected on UNIX systems and quickly fixed (and occassionally re-introduced in future versions and new programs). It is believed that there are about as many exploitable bugs in NT and MacOS servers as there have been in Linux and UNIX.  They usually show up as ""hangs"" or ""abends"" (abnormal ends) in the services or on those systems, rather than complete, interactive exploitation.     (The reasons for this have to do with the rather poor remote administration features and somewhat more complicated programming models of these other systems).  So on the surface NT and MacOS seem to ""failsafe"" (die without giving the attacker access) --- although this is probably an illusion, waiting to be dispelled by the next generation of crackers).     Again, these are NOT viruses.  However, they have similar results, someone runs code on your system that you didn't approve and don't want.     So these vulnerabilities (especially buffer overflows in network daemons like popd, imapd, mountd, ftpd, etc) are the greatest risk to the security of your system.  That's why companies put up firewalls.  That's why sysadmins tell you not to leave ""ports open"" (these services available) on your systems, or to use TCP Wrappers (pre-installed on every major Linux distribution) to limit the networks and systems that can access those services that you REALLY need.     I mentioned that security auditors focus on SUID progams and networking daemons.  This is a matter of priorities as those are the most ""attractive"" points for an attacker to probe.  However, we have to be aware that security auditing and robust code is necessary ANY TIME A PROGRAM ACTS AS AN INTERFACE BETWEEN/AMONG DIFFERENT SECURITY CONTEXTS.     We must be concerned about bugs IN ANY CODE THAT PROCESSES UNTRUSTED DATA.     (I'm shouting about this since it is a point that is often overlooked, even by some of the most respected programmers that I know).     For example, when you sent me e-mail.  Your mail comes from one security context (the outside world, from a complete stranger).  My mail user agent (MUA) acts as an interface between you data and me.  If there's a bug in my mailer (or the editor that my mailer invokes when I want to respond) then you might be able to craft a piece of e-mail that will crash my program, and possibly even subvert it.     Such a ""black widow"" would be very hard to write for any UNIX mailer (though the addition of MIME handling features did introduce some such bugs in some mailers).  It would also be limited in its effect.  It probably could only affect one mailer under one operating system.  It might not propagate through POP servers and/or through certain POP clients (like 'fetchmail').     There are dozens of common MUAs (mailers) used by UNIX and Linux people.  So any such bug is likely to only hurt a few of them (and not propagate from them to others).   Likewise for many other classes of programs.     The worst security risks are incurred by ""monocultures"" (a term borrowed from agriculture).  If we all grow the same strains of the same crops, one blight and we all starve.  If a few of us grow one strain, others grow a different crop, etc --- then the damaged is limited and the blight doesn't spread as far or as fast (since the various fields of any one crop/strain are separated by buffer zones).     When you think about the effects of Melissa, and WinExplorere.zip and the many other MS Windows macro viruses you see the inherent risks in monoculture.  (You also see that Microsoft added features to their office suite and mail client which make it easy to write trojans and worms).     Computer systems and networks exhibit similar characteristics in the face of hostile programmers.     (In other words diversity is good. Some of us should run  FreeBSD , Solaris, and some completely non-UNIX operating systems that aren't even C derived.  Some of us should run Linux on x86, while others use Alphas, PowerPCs, etc.  Uniformity has some short-term cost and training benefits --- but that way lies great danger!).     How bad is this danger?     Well, I've been running an experiment.  I administer a system (a web server for a small literary organization, a non-profit) which is exposed to the Internet and gets very little administrative attention.  I tend not to upgrade it until I have to.  It's been cracked twice in three years.  It  probably  hasn't been cracked on other occasions since I actually do have a sneaky trick up my sleeve that allows me to detect and recover from the garden variety ""script kiddie"" attacks fairly quickly (and remotely).  I do say ""probably"" since anyone that asserts that he or she has ""never"" been cracked or that he or she is ""sure"" that they are secure is really a bit foolish.  You can have a very high degree of confidence ---  but certaintly in this case is a sin.     That is on a box which is effectively ""wide open.""  With a modicum of configuration (not running inetd, limiting access to any services you  must  run, updating your packages as bug fixes are announced, etc) you can limit your chances of being compromised to very low values.  Read the Linux Security HOWTO and with about five percent of the effort described there you'll eliminate well over ninety percent of the risk.     Note:  Symantec is apparently shipping an anti-virus for Linux. I've heard that Trend is also testing one.  I guess these are designed to catch the two strains of viruses that have been heard of for Linux.  I also gather that they will scan your system for MS-DOS and Windows macro viruses (well over 10,000 of those). This is to protect the clients that might be using your Linux system as an FTP, Samba, or NFS server, and to save you from the infection on your ""other OS"" on those multi-boot systems.     Personally I suggested to Symantec (back when I worked there) that the best Linux product they could release would be a simple terminal to the PCAnywhere package.  Let me use a window on my Linux system to remotely manage any MS Windows PC's that I have to deal with.     They didn't listen, and now we don't need it.  VNC (*) seems to do the job well enough, and we may stomp out most of MS Windows before Symantec could code up a new PC Anywhere client.     (Apparently ORL got aquired, so VNC is now at:  http://www.uk.research.att.com/vnc )   There are also a couple of packages for UNIX (some with Linux ports) that will scan your mail for embedded PC/MS-DOS viruses as it's relayed through your mail server.  This can help catch many macro viruses (though the things are so easy to write that the anti-virus software companies will always be a reactive coping mechanism rather than a true solution).     Remember, a virus is just a bit of programming code.  It does things that most recipients don't want --- but nothing short of a brilliant AI (artificial intelligence) can be relied upon to distinguish a virus from any other (benign) program.  ""Heuristic"" virus scanners have been written --- they haven't fared significantly better than the traditional reactive signature scanners.     (I used to work for Symantec, and for McAfee.  I've read, heard, and dealt with far more about PC and Mac viruses than I can possibly type here).     Summary:  Don't worry about viruses on your Linux box.  They aren't a problem.  As for the security concerns, just lock down those stray networking services and don't give accounts out on your system to people you don't trust.  If all you do is add the following to your  /etc/hosts.deny:      ALL:ALL     ... you've done plenty to secure your home system from the occasional portscan attack through your dial-up ISP connection.     If you read the Security HOWTO (*) by Kevin Fenzi and Dave Wreski and follow most of their suggestions then you'll probably never have a problem.  Under Linux you can keep your system as wide-open or just about as locked down as you like.     ( http://www.linuxdoc.org/HOWTO/Security-HOWTO.html )                 Telnet trouble     From Mathew  on Sat, 25 Sep 1999      Dear Jim    Your email did help me to solve the problem with the telnet in linux. It works fine now. Thanks a million.....     I have a small doubt. Let me explain......  My network has a NT server, LINUX server and 20 windows 95 clients. I followed your instructions and added the address of all the clients into the  /etc/hosts  file on the LINUX machine and voila the telnet worked immediately.     But the NT server was the one who was running a DHCP server and dynamically allocating the addresses to the clients. The clients were configured to use DHCP and were not statically given and ip addresses.  I managed to see the current DHCP allocation for each client and add those address into the  /etc/hosts  file on the LINUX server but my doubt is what happens when the DHCP address for the client changes? Then again we'll have to change the address in the  /etc/hosts  file right? This seems silly.  Is there anyway to make the LINUX hosts file to automatically pick up the DHCP address from the NT server?     Also another important thing is I am still unable to ping from the NT server to the LINUX server using the name. It works only with the IP address. Is there any way to make the NT DHCP to recognize the LINUX server?     Well, either you shouldn't use dynamic addressing (DHCP) or you should use dynamic DNS.  You could also disable TCP Wrappers (edit your  /etc/inetd.conf  to change lines like:     telnet stream  tcp     nowait  root    /usr/sbin/tcpd in.telnetd     ... to look more like:     telnet stream  tcp     nowait  root    /usr/sbin/in.telnetd in.telnetd     (and comment out all of the services you don't need while you're at it).     Thanks Jim for all your help....you've become my LINUX guru.............     Perhaps you should consider getting a support contract (or joining a local users group).  I may not always respond as quickly nor as thoroughly as you'd like.     Best Regards  bob                 Quiet, Modem!     From qed on Fri, 24 Sep 1999         Hi,     I know this is a nitpicky thing, but I bounce back and forth between Linux and that other operating system(Doors?), and the thing that's bugging me is that I can turn off the modem noises in Win95, but I don't know how to reroute them to  /dev/null  in Linux.     Later, Jerry Boyd     echo ATL0M0 > /dev/modem      ... Actually you want to add the  L0M0  (those are zeros) to your init strings in whichever Linux programs you're using with your modem (like your PPP chat scripts).     (You many want to check with your modem to make sure it understands these AT commands --- but it should if it's even moderately Hayes compatible).                 Dual Booting without Re-Partitioning     From Hoyt  on Fri, 17 Sep 1999       In addition to the suggestions you made, you could also look at Lnx4Win, a Mandrake Linux product. Read more about it at  http://linuxforum.com/99/07/linux4win.html      Hoyt             Regards from Argentina     From Horacio Pea  on Wed, 15 Sep 1999       Jim and Heather:     I just want to thank you for the extraordinary job you both are doing with the ""Answer Guy"". The whole Gazette is wonderfull; I have all issues, but the Answer Guy is the first thing I read. I have learned a lot with it. Carry on !  PS: my regards to all folks at the Gazette.      Horacio Pea           -           Quilmes Oeste  [[ Argentina ]]             re: Helpless (issue 45 of linuxgazette)     From Alex Brak  on Thu, 9 Sep 1999       Hi,     In the Answer Guy article titled ""Helpless"" ( http://www.linuxgazette.com/issue44/tag/33.html ), I think Leslie was referring to Data Access Objects (DAO), a Microsoft data access API/toolkit. AFAIK, there's no Linux/Unix version, as it is a MS-proprietary technology.     btw, the answer to his/her question is that DAO will work on Win98, as it did with Win95 -- he/she will, however, have to install the latest DAO runtime redistributable K to develop software using DAO. One should be able to find it on the Microsoft Developer Network site:  http://msdn.microsoft.com      I'm not sure why leslie sent this to you of all ppl        keep up the good work,     Alex Brak             Thanks!     From Moore, John R  on Sat, 4 Sep 1999       Mr. Dennis:     I just sent a pathetic pleading letter from a confused newbie (me)to an author of a PPP HOWTO begging for some clarification on how to setup the necessary files to communicate with my ISP using RH5.2.     In yet another desperate attempt to find the truth, I ran across you response to some other poor souls similar dilema dated Tuesday August 31 of this year.     Finally, some answers I think I can understand. You'd most certainly expire laughing if you knew what I've been through to get on the net. Only now, after reading your article, do I understand that I must create a script that runs, rather than just typing in the commands at some terminal window.     It is no wonder that so many users run as fast as they can in the opposite direction. In a time when the Linux  community is trying to be ""picked up"" by the corporate world and become a viable ""player"", I find it amusing that so many in that same community can't understand why they get repelled rather than attracted. I myself spent the past three weeks trying to configure my one computer to establish a link on the internet without any success. Oh sure, I was ble to get minicom to dial my ISP...ooohhh, look out big blue! Watch out Bill Gates! C'mon corporate world...jump on the Linux band wagon...we're great! I was beginning to suspect that most new members of the Linux community are bald from pulling their hair out...I know I was getting that way.     And then along comes your informative, albeit wordy (like myself) article that will hopefully clear some of the haze. It is refreshing to read an article that doesn't assume we all grew up in Berkley with nothing better to g  /etc/host  for hours on end. Still some assumptions were made, but hopefully, this time next week, I'll be sending you email on a Linux box, looking over at my Windows box with a sly grin, rather than visa versa with a look of total frustration.     Sincerely,     John Moore             Just Buy a REAL Modem     From Jonathan J. Rakocy  on Thu, 26 Aug 1999       Dear AnswerGuy,     Well thanks for your response answer guy.  I apprieciarte the prompt reply.     To the tech store i go!  Happy computing and maybe I talk to you again? I f you have a mailing list add me if possible.  Thanks again!     Sincerely Jonathan Rakocy <lunar>     At 09:48 PM 8/25/99 -0700, you wrote:       Hello answer guy.  My name is Jonathan. I am a tired windows user     trying to educate myself on the in and outs of open source, and in my case linux.  i love the idea and concepts behind it. I've been downloading pages and saveing links. buying books and reading till 3 in the morning like now.     so to my point.  First i installed linux along side windows.  i need     it ( unfortunatly for school so far).  ihope to  learn how to work around it.  but as you probably know by now, i am quite green.  I ve not been able to connect ot the www.  Now it comes down to the modem i think.  i have a winmodem and i ve recently learned that the y are junk. after reading the essay on them in the gazette, my fears are confirmed.  do i truely lose? or is there something i can do?  say rewrite something?  where can i find more in formation on this or do i just go buy a new modem if i wnat to continue?  thanks for your patience. it is late and my eyes are blurry.  have a good day. Sincerely Jonathan Rakocy linux Supporter     The answer is still:     Just Buy a REAL Modem!                 Telnet gives: ""Connection closed by foreign host...""     From Martin Osvaldo Mauri on Wed, 13 Oct 1999         Dear James:     I've had a problem with  Red Hat  6.0 while trying to telnet from one machine to another. All the configurationfiles seems to be OK, but when I telnet, it gives me the message ""connection closed by foreign host...""     Any suggestion? best regards,     Martin O. Mauri     What does the syslog ( /var/log/messages ) say on the server?     This message indicates that the remote system is disconnecting you.  Probably the remote system is enforcing some security or access policy, or you're missing a file (such as the  /usr/sbin/in.telnetd  program).     I'd look at the  /etc/hosts.allow  and  /etc/hosts.deny  files.  I'd also look at the  /etc/inetd.conf  file.     In  /etc/hosts.allow  and hosts.deny there might be a set of rules specifying a list of services (such as in.telnetd).  Each of these services can be associated with a list of host/domain and network address patterns. Entries in the hosts.allow are allowed to access the specified services while entries in the hosts.deny are disconnected (as you described).  All attempts to access any service are logged.     There are two groups of network services for which access can be controlled through these two hosts files: those that are dynamically launched through the 'inetd' dispatcher (any lines that refer to  /usr/sbin/tcpd ), and any ""standalone"" services which are linked to the ""libwrap"" libraries (such as the portmapper daemon that's shipped with most Linux distributions).     At a guess I'd say that your problem is not related to entries in  /etc/hosts.allow  and  /etc/hosts.deny.   Most Linux distributions ship with those as empty files; they're just placeholders with comments.     It's more likely that you're actually missing your  /usr/sbin/in.telnetd.   This should show up in your logs as a message like:  ""unable to execute""     If that's the case: mount up your CD (on the server), change to the RPMS directory and type a command like:     rpm -Uvh telnet*.rpm     ... that should install the telnet server and client. Red Hat 5.2 used to put those both in a single package. I don't remember if RH 6.0 split those into separate packages or not.     While you're thinking about this you should consider avoiding telnet, rsh, and other insecure protocols.  They are not appropriate for use over untrusted networks. The telnet protocol transmits all information as ""plain"" text.  This means that your passwords can be ""sniffed"" as you type them into your login and 'su' prompts.     We won't even get into the many problems posed by rsh/rlogin.  Suffice it to say that these suffer from a very weak authentication model in addition to being ""sniffable.""     So, you may want to install a set of cryptographically secure tools for your remote access needs.  'ssh' is a secure (cryptographically enabled) program that works like rsh and rlogin.  It's the most popular tool for this sort of work.  There are also tools like STEL (secure telnet) and ssltelnet.     Most of these are freely available.  ssh version 2 is only free for some forms of ""personal use"" while the older ssh version 1.2 is free for a broader interpretation of ""personal use.""    STEL was developed by the Italian CERT (computer emergency response team) and is ...     I've talked about the many free cryptography tools available for Linux in a previous column (The Answer Guy 35: FS Security using Linux  http://www.linuxgazette.com/issue35/tag/crypto.html )     I hope most of those links are still valid.  Meanwhile let me assure you that the most useful site on the Internet for getting free crypto packages is still: Replay Associates ( http://www.replay.com ).     [ Replay Associates has moved to   http://www.zedz.net/ .  Apparently ReplayTV really  wanted the name they had    -- Heather ]     They currently have one of my favorite Latin quotes on their web page:     ""Quis custodiet ipsos custodes?""     Hope that helps.                 Multiple Root Accounts: Delegation     From R Dalton  on Wed, 13 Oct 1999         Hello Answer Guy     I'm wondering if it is possible to setup multiple root accounts on a linux system for more than one unix admin to monitor a system ?     If this is possible how ? also can they have different root directories ?     Thanks. R Dalton     It is possible to have multiple accounts with 'root' privileges.  The easiest way is to edit the  /etc/passwd  file (using 'vipw') and make extra copies of the line that starts with ""root"" (the root account entry).     Then you edit the login name field (the first one), and the full name (GECOS) field, the home directory field, and the shell field.  Then you issue the 'passwd' command to set each of the initial passwords for each of these.     Example (excerpt from an  /etc/passwd  file):     root:x:0:0:root:/root:/bin/bash toor:x:0:0:Alternative Root Acct:/root:/bin/bash ruut:x:0:0:Cracker Jack:/root:usr/bin/pdksh jonroot:x:0:0:Jon Doe:/home/jon/root:/bin/bash tomroot:x:0:0:Tom Boote:/home/tom/root:/bin/bash jillroot:x:0:0:Jill Tedd:/home/jill/root:/bin/tcsh jimd:x:500:123:Jim Dennis:/home/jimd:/bin/bash     In this example I have the customary root account followed by 'toor' (""root"" backwards) and 'ruut' (punny spelling of ""root"").  Then I have a set of root equivalent accounts for Jon, Tom, and Jill.     I've followed those entries with a token ""normal"" user account for comparison. The only important detail is that the 3rd field on the root equivalent accounts is set to '0' while all non-root accounts have other numbers (UIDs).     All kernel and filesystem data structures that store and manipulate ownership (of files, processes, etc) and check permissions use the numeric UID.  The  /etc/passwd  file is the primary way to map names to UIDs and vice versa.     Note that this works in any form of UNIX.  However, it is not necessarily the best way to do things. Some programs will do get a login name by looking up the UID.  When we have non-unique UIDs, we can confuse those programs (of course, you probably shouldn't be running those programs as 'root' anyway).     There are other potential problems with this strategy. Obviously having more people and more passwords that give the same level of access increases the risk that unauthorized people will guess or steal those passwords, or trick one of the admins into doing ""bad things"" (social engineering).  Also this mechanism provides no tracking of who did what.  There is no way to distinquish between what jillroot and tomroot did (since they have the same UID --- which is all the system uses for marking file ownership and checking privileges).     A better way for most situations is to install '  sudo '      The sudo package allows you to selectively give access to specific users and groups, allowing them to execute specific programs and with specific options. The users run the 'sudo' command, which prompts them for their own (normal user account) password.     In your case you might just start by installing sudo and configuring it to allow access to a command shell ( /bin/sh  and/or  /bin/bash ).  That's pretty simple.  It effectively gives you the benefits of the multiple account entries (though it doesn't set up separate home directories).  One advantage is that it does logging of who used which sudo commands at what time.     (Obviously a 'root' user can edit the local syslog entries and can stop, restart, and resplace the local syslogd daemon to ""cover his tracks"" --- 'sudo' to root access doesn't protect you from unreasonable expectations.  But the logging can help a bit).     As you more clearly define the precise operations that you need to delegate; you can edit your  /etc/sudoers  file to more precisely limit your users and groups to those specific programs and scripts that they need.     The sudoers file is relatively to understand.     The only confusing part is that its entries refer to network hosts and ""netgroups"" (a Sun NIS concept).  This is intended to allow sites to create a single  /etc/sudoers  file and distribute that to all of their systems.  The reason I found this confusing when I first installed 'sudo' is that 'sudo' itself doesn't providing any networking or distribution mechanism (and the man page doesn't actually explain  why  they put these hostname references there or how you'd use them).  It assumes that the sysadmins using the package will want to create a uniform sudoers file and know how to do it (through rdist, ssh/scp, rsync, etc).     cfengine is another package you might want to consider. It has nothing to do with authority delegation (giving out root privileges to more users), but may be useful for automating your system monitoring and configuration tasks.     cfengine is a host configuration utility.  It implements a language to describe certain sorts of system administration policies and corrective actions.  It's an intriguing concept that I've only played with a little bit.  However, it is gaining popularity in sysadmin circles (along with the healthy respect that one reserves for a loaded firearm --- one mistake in a cfengine script can make thousands of changes on hundreds of hosts).                 Soundcard Drivers for Win '98?     From Adam Moore  on Tue, 12 Oct 1999         hello i'm currently trying to find a driver for the OPL3 YAMAHA/SAx sound card for win98 any help you can give me would be appreciated.     thanks     I don't do (MS) Windows.  Contact Microsoft, or your sound card manufacturer, or your local retailer.                 Author Responds to ""gdm Murdered Mysteriously""     From Martin K. Petersen  on Tue, 12 Oct 1999         Sorry about the delay. I've been attending Linux Kongress the past week.     The fact that the version of  GNOME  gdm that shipped with  Red Hat  6.x can't gracefully handle (clean up after) an inadvertant shutdown or other mishap is very disappointing.     Well, contrary to common belief X display management isn't trivial at all. Since gdm is a complete redesign/rewrite of xdm, it is bound to have problems.  I have never tried to conceal the fact that gdm has issues.  It even says so on the web page.     That being said, gdm works ok for local display management, provided the X server is relatively well behaved (i.e. not buggy).     The fact that the version of GNOME gdm that shipped with Red Hat 6.x can't gracefully handle (clean up after) an inadvertant shutdown     Yes it can. You're speculating.     I find it disappointing that a person like you, who has been in the Linux business for several years, resorts to spreading FUD.  Don't answer questions, if you don't know the answer.     The right answer here, like in 99% of all other cases concerning system daemons, would be to consult the syslog.     I believe I did consult the syslogs.  I remember that I did have to remove some sort of lock file or something before I could get gdm working again (but I don't remember the details).     I did NOT see this question listed in their FAQ (which surprises me, since I would think that this would be a very commonly encountered problem among RH6/GNOME users). However, I did find a link to a bug tracking system. From there I searched for messages related to our ""murdered mysteriously"" problem.  There was some indication that Martin K. Petersen is the contact for gdm and that he posted patches to resolve that (and several other) gdm issues.     The ""murdered mysteriously"" message is a non-critical warning, not a failure.  Thus it hasn't and never will be ""fixed"".  Neither have I posted any patches to resolve it.     The message indicates that something killed the master gdm process or something left Xlib in a state which it couldn't handle gracefully. I.e. gdm was forced to about without cleaning up.  However, this doesn't affect subsequent startups in any way.     /Martin     This suggests that a simple [Ctrl][Alt][BackSpace] or a 'telinit q' command should restore 'gdm' to functioning. Or is there some sort of state preserved by Xlib in the filesystem?     I'm sorry if my message offended you.  I was frustrated when I first encounted this error message (in front of a class full of new Linux students, in fact) and I seem to recall that the problem persisted through a reboot, and required some fussing with lockfiles or unix domain socket entries, or something.     I was also frustrated when I got the question for my column.     Since I don't run GNOME on my home systems or my workstation I don't have an easy way to attempt to reproduce the problem myself.  The user didn't provide me with much info either.     (Thus I am forced to speculate: frequently and for many of my answers.  I try to let people know when I'm guessing and when I'm speaking from first hand experience.  Sometimes I fail).     I have seen Red Hat 6.0 systems FAIL to bring up gdm in a persistent way.  I've seen the message ""gdm murdered mysteriously"" associated with this failure.  It might not be a failure of gdm's --- but the gdm error message is certainly occurring at about the same time.     Anyway, hopefully GNOME will be more stable in Red Hat 6.2 or 6.3.  Overall I think Red Hat Inc has been pushing it on to too many desktops a little too quickly.                 Upgrade to  6.2 from 6.1 Disables Login     From Dave  on Tue, 12 Oct 1999         I recently began setting up a SuSE linux system to replace my Win9x system. The installation of SuSE 6.1 went great.  As well as XFree86 and several software packages including Netscape and RealPlayer.     While under X I installed the base RPM upgrades for SuSE 6.2.  The only packages it replaced are at  ftp://ftp.suse.com/pub/suse/i386/update/6.2/a1 .     Nothing that would affect my logging I thought.  After logging out as root I was unable to log back in as root or my user account. It would just give me and ""invalid login"" message.  I tried going into rescue mode and clearing the root password entry in the  /etc/shadow  file as well as the  /etc/passwd  file.     The login error remains.  Can you give any suggestions as to where the source of this problem might be?     Thanks, -- Dave N.     My wife just did the same thing this weekend.  She's still working on it.   Her plan is to push forward with the full system upgrade.  She's using one of the other systems to fetch all the RPMs to a local mirror (since full FTP installation/upgrade over the Internet is far too unreliable to complete; she tried that already).      So, she's still waiting on the DSL line to finish that process.  She has a  Debian  laptop and we have a couple of others Linux boxes around, so it's not like she's totally stuck.     [ I was solved fairly quickly once I got enough of the  base back in sync with itself.  Because I was foolish enough to   do my update over the net (I was too impatient to wait for the  boxed copy to arrive at my local store) I had to wait for hours  that were lightly travelled around here, and a mirror that had  free ftp logins available around that hour.      Many things about my system seem more stable now, although gimp  and enlightenment appear to have an allergy with each other.  -- Heather ]      I would guess that there's a problem with the libc libraries.  I guess that S.u.S.E. 6.2 installs glibc 2.1 libraries.  Some of the programs that are linked to glibc2 (libc.so.6) are failing on some differences between 2.0 and 2.1.  (Those programs probably should have been linked more tightly --- to 2.0 rather than just 2).     Anyway, your best best is probably to push forward and upgrade the whole system.  You might be able to temporarily fix your system (well enough to log in) by booting from a rescue floppy, mounting your root filesystem and tweaking the symlinks under  /lib.   Basically make the libc.so.2 link point to libc.so.2.0 rather than libc.so.2.1.  (If the links don't look something like that when you get there, it blows my theory; there'd have to be something else wrong).  If you do find the symlinks wrapped like I'm thinking --- change them around, cd to the root of filesystem (the top level mount point below your rescue, usually  /mnt ) and run the command:     usr/sbin/chroot .  /sbin/ldconfig      ... that should force the ldconfig command to execute properly on your filesystem tree.     This ""chroot"" stuff is very handy for working on rescue disks.  You boot on the rescue, mount your normal filesystems under  /mnt , cd to there and ""chroot .  /bin/sh "" Then you can work on your normal fs structure and the commands you use like  /sbin/lilo , rpm, ldconfig, passwd, et al, will all find things where they're ""supposed to be"" (like the  /etc  directory, the rpm dbm files under  /var/lib/redhat , and the  /lib  directory).     It's a bit confusing to describe.  Play with it a bit and see what you figure out.                 Euphoria     From Greg Phillips  on Tue, 12 Oct 1999         I've been using Doslinux for quite some time now, and am quite impressed.  Unfortunately, Kent Robotti doesn't answer his email, it seems =)     I'm a member of a mailing list, which pertains to Euphoria.  No, not intense joy, but a relatively new and unknown programming language. While the number of users is small, we're very passionate about Euphoria.  Recently, a linux version was released, and many users wanted to use it.  A fair chunk of them were hesitant to repartition their hardrive and install a new OS, so I recommended Doslinux.  While it worked well for some users, others had trouble installing Euphoria, and other applications.  This was no fault of their own: Doslinux documentation is a little bit skimpy, if you're new to Linux and don't know where to look.  Being the resident Doslinux veteran, I was soon flooded with questions (How do I install X? How can I get  KDE  to run? How do I log in? Why doesn't this work?).  So I opted to make a CD for the Eu community, with Doslinux, all the extras (gcc, x, kde or gnome, euphoria, etc.) already installed.  Unfortunately this proved to be a lot of work. Trying to stuff a bunch of software into a pre-made distribution was getting to be painful.     So, after some reading, experimenting, etc., I decided to create EuLinux.  The same idea as Doslinux, but customized towards Euphoria users.  So, here's my question:  How?     I've read everything I can get my eyes on, and, as I understand it, this is how DOSLinux works in a nutshell: It uses a loopback filesystem as the root device.     To install the whole system, a ramdisk device is mounted, which is used to create an empty file of a fixed size on the dos partition. The linux system can then be copied into that empty file, which can be booted with LOADLIN.     I know there's a lot more to that, but I hope I've got the basics correct.     Am I right? Can you point me to some documentation?  Is it even worth trying?     Thank you, Greg Phillips     Well, it certainly sounds like an interesting and worthwhile project.  However, I might suggest a slightly different approach.     It would be nice if  Debian  could be installed on a FAT filesystem (sort of a blend of DOSLinux and Debian).  Then you could create a Debian package (and an RPM).  This would make Euphoria accessible to most Linux users with a minimum of fuss while make DOSLinux capable of installing a very large number of well-maintained packages.     I suggest the DOSLinux/Debian merge for a couple of reasons.     First Debian has more packages that  Red Hat ,  S.u.S.E.  etc. Many Debian packages are smaller and more focused, while Red Hat tends to put more stuff in a given package.  That leads to coarser dependency granularity for Red Hat.     Also Debian has developed ""virtual packages"" and ""alternatives"" which allow for more choices without having to work around the dependency/conflict management features of its packaging system.  (For example in Debian some packages depend on ""MTA"" which is a virtual package that can be provided by exim, sendmail, qmail, etc).     Debian packages tend to ""fit together"" a bit better than those from Red Hat and other RPM distributions.  Debian are hundreds of volunteer maintainers.  Many of those maintainers tend to more proactively patch the base sources and feed their patches ""upstream"" (to the program authors).  They seem to have closer ties between their package maintainers and the software authors (probably since there are so many maintainers, so each can afford a bit more time on the few packages that each one maintains).     Meanwhile Red Hat,  Caldera , S.u.S.E., TurboLinux and other distribution maintainers each have a smaller number of professional developers.  The various RPM distributions tend not to have compatible package dependencies and they duplicate quite a bit of the packaging effort.     Keep in mind that the core software among all of these is mostly the same.  The differences show up in packaging, dependency and conflict management, and configuration tools. Debian package configuration mostly falls into the ""it's ugly but it works"" model --- where a package might prompt for one to five answers (with reasonable defaults).  This is done basically as a simple list of ""echo/read"" (shell script) questions.  It's not pretty, but it is elegant and minimal --- and it works better than linuxconf.     (Don't get me started about linuxconf.  I've banned that from my systems until further notice!)     So, that's what I'd like to see.  A DOSLinux that could be used as the base system for a Debian system.  (For that matter any improvement to the Debian bases system install would be welcome.  It's a really good system once you get it up --- but that first step is still a bit of a doozy.                 Dell EIDE TR5 Tape Drive     From Yixin Diao  on Tue, 12 Oct 1999         Hi, Jim,     I know you after I read your message ""Open Letter Re: Linux on Dell Hardware"". May I ask you a question? Can Dell's tape drive ""10/20GB EIDE TR5 Tape Backup"" work well under Linux?     Thanks! Yixin     Ahh Yes!  The old ""open letter to Dell.""   Of course I can't take any credit for the fact that Dell does now offer Linux pre-installed on selected models.  I don't even know if my letter ever made it to Micheal Dell or anyone beyond ""secretary.""  Ironically I work for the company that provides Linux technical support to Dell.     I haven't played with any TR5 tape drives.  However, I suspect that it should work.  Be sure to compile a kernel with support for IDE tape drives (it's in the menuconfig options after IDE CD-ROM drives, and IDE hard drives).     According to  /usr/src/linux/Documentation/ide.txt  you should be able to use  /dev/ht0  to access your IDE tape drive, just as you'd use  /dev/st0  to work with a SCSI tape drive.                 FTP Daemon: Special Requirements     From William Dawson  on Tue, 12 Oct 1999         Hello, Mr. Dennis.     I'm in desperate need of help...I'm down to only one functioning nerve...     After much brain-strain and (I don't mind saying) heavy persistence, I finally found the right man pages to tell me how to change the port that ftp listens on, and other things of the like.  My problem now is that can't seem to figure out how to set the maximum  number of simultaneous ftp users (limit<class><n><times><message_file> seems not to work in the ftpaccess file...<times> format is of particular concern).  Also, how do I limit users to only one ftp connection (login) at a time?     If you can help me out with any of this, I would be eternally grateful.     Are you sure you're running WU-ftpd?  Other FTP daemons don't necessary read the  /etc/ftpaccess  file.     If you're using the BSD ftpd (possibly reported from  OpenBSD ) then it would ignore  /etc/ftpaccess  (unless then changed it).  If you're using ProFTPd, BeroFTPd, or ncftpd then you'd use different files to configure each of them.     Also are you SURE you want to change the port on which you are running your FTP daemon.  I could see cases where you might want your ftpd to selectively bind to some interfaces or IP aliases and to ignore others (which means that you can support FTP virtual hosting, among other things).  However, running it on a different port seems like a bad idea since many FTP clients (especially those in MS Windows) don't offer options to connect to non-standard ports.     The limit directive in the WU-FTPD doesn't give you a way to limit the number of concurrent connections  PER USER .  (At least I don't remember such a thing). It's intended to limit the total number of connections for each ""class"" of users (mostly to insure that anonymous users don't bog the machine down so much that your own employees, students, etc can't access the system).     I think you might want to look at the documentation for the ProFTPd and/or the ncftpd packages before you fight too much with your current FTP daemon.  Please note that ProFTPd has been hit with a couple of security exploits recently --- so make sure you get the most recent version (with bug fixes) and you what the 'net for alerts.  There may be more bugs waiting to be discovered in this package.  (Of course that's true in every software package.  But some have a better reputation than others; and write now WU-FTPD and ProFTPd are at the high end of that reputation scale.).     ncftpd is not free software.  However, Mike Gleason, its author has a good reputation in the open source community. His ncftp CLIENT is free and is one of the best.     You can find these at:     NcFTP Software  http://www.ncftp.com      ProFTPd  http://www.proftpd.org      WU-ftpd  http://www.wu-ftpd.org      BeroFTPd  http://apps.freshmeat.net/download/895008043      pftpd  http://apps.freshmeat.net/download/918313631      I tossed in links to a couple of other FTP daemons that might be interesting.                 login, su, and passwd dies: Everybody dies!     From Tim Kientzle  on Mon, 11 Oct 1999         I'm having a hard time finding good technical archives for Linux. I've been searching 'linux login' trying to find someone else who's had this problem; I stumbled across a couple of your columns in the process.     In any case, I have a useful factlet for you regarding login problems: The  KDE  'add user' program by default does not assign a login shell.  Thus, accounts that cannot be logged into.     For myself, I have a RedHat 6.0 machine that does not accept any logins, not even root.  It never gets to a password prompt.  This is true of getty, telnet, ftp, and KDM logins.  I brought the machine up in single-user mode, and found that 'su' and 'passwd' both crash, also.  It looks as though any program that needs to touch the password file simply dies at that point.  (Note that 'su' does not crash if you use it to go from root to a non-root user.)     Oddly enough, this problem arose spontaneously; the machine has worked fine (about 8 functioning accounts) for a week.  I came in this morning, and tried to telnet into that machine; the connection dropped at the telnet prompt.  I rebooted the machine (which required hitting the big red button, since I can't login as root to safely shut down) and then KDM won't come up; it seems to crash the X server.  No useful messages to  /var/log/messages , just a machine that can't even be reasonably debugged.     I'm almost ready to drop RedHat and go with  FreeBSD  instead. <sigh>     - Tim Kientzle     It sounds like massive corruption to your libraries or to your  /etc/passwd  file.  I'd start by booting from a rescue diskette (as you've already done once) and editing the  /etc/passwd  and  /etc/group  files.     If those look alright (compare their formatting to the ones on your rescue floppy) then check the  /etc/shadow  file.  You could just rename the etc/shadow file and try the 'passwd' command again.     (The libraries use the existence of an  /etc/shadow  file as a hint to use shadow passwords).     Another thing to try is the following commands:     cd  /mnt/  && usr/sbin/chroot .  /bin/sh  rpm -Va     (or, if you have a copy of the 'rpm' command on your resuce diskette you can use: 'rpm --root  /mnt  -Va')     This rpm command will check the integrity of the system files, libraries and binaries, and the ownership, modes, and other particulars for every file that included in any package you installed.     You can use the 'rpm -qf' command to match the filenames that the verification reports to the package names that you might need to re-install.     Of course you could re-install from scratch.  However, it would be very unsettling to me to do that with no understanding of what went wrong.  I suspect that you feel the same; how can you trust a system that ""did that"" all of a sudden.     One possibility is that your system was cracked (incompetantly).  The programs you mention are some of the same ones that are replace by most ""rootkits."" If some script kiddie broke into your system and tried to install a rootkit that was pre-compiled for libc5 then I could see it give symptoms just like those you've described.     The 'rpm -Va' command might uncover this.  Script kiddies and their canned cracker tools don't seem to have added ""rpm dbm patchers"" YET.  However, it's only a matter of time before they do.     In a past issue(*) I've described more robust techniques for using write-protected boot floppies, you original CD, the rpm command and some shell utilities to perform a system integrity audit on a  Red Hat  or other RPM based system. That article was long-winded since I explained the method in some detail.     ( http://www.linuxgazette.com/issue37/tag/44.html  search the page for ""pkg.inst"")   As for running FreeBSD:  It's a nice system.  It's a bit more carefully integrated then most Linux distributions and it can run most Linux binaries.  I've suggested that intermediate and advanced Linux users give it a try some time (next time you're about to install an OS on a new machine and you have a couple of days to ""tinker"" with it).     You might also try  Debian .  I'm slowly switching my home systems and laptop over to it.  I just got my new personal workstation up and running this weekend, got my home directory tree (700Mb, mostly of e-mail archives) transferred and have spent all day answer e-mail on it.     Let me give an example of what I like about Debian.     I chose a minimal installallation to start with (about 100Mb total. I upgraded it from the CD version to the latest version of everything in ""unstable"" by editing one file ( /etc/apt/sources.list ) and issuing one command (apt-get update && apt-get dist-upgrade -f).  It sucked down 120 packages from the 'net and put them all in place.     Then I installed a curses package selection tool (console-apt) and used that to select a few other programs that I wanted (things like xemacs).  apt-get and console-apt use the same selection database, and use the dpkg command under the hood. They automatically get any libraries and ancillary packages to resolve dependencies.     Later, after I'd transferred all of my home directory files, I starting working like I prefer (running xemacs, in viper-mode under 'screen').  At some point I typed a word that look ""wrong"" and I hit [F3][$] (my personal xemacs macro for spell-checking the word under my cursor). Ooops, ispell wasn't installed!     So I switch to another VC, type:     apt-get install ispell iamerican     ... wait about 30 seconds and go back to my editing. my spell check now works.     Another time a few weeks ago I was answering a question about LPRng.  I logged into my other Debian system (a little file and mail server, antares), installed the package, read the doc page I was looking for, and removed it.  That was faster than hunting for it in Yahoo!     That's what I like about Debian.  I've been doing that sort of thing for months on my machine at the office.     In fairness to Red Hat and it's ilk, the 'rpmfind' command ( http://rufus.w3.org ) makes RPMs  almost  as easy to manage.  However, debian does have a lot more packages and apt-get seems more stable than rpmfind.     So far the Debian apt-get facility is the only one that I've ever trusted with automatic system upgrades.  I've been running regular dist-upgrades on my box at work for months --- on the UNSTABLE development series, the betas --- and I haven't broken my system yet (sometimes one or two packages get a bit messed up; but nothing that's caused real problems).     Meanwhile Debian is not for the UNIX novice.  Most users would not know that xemacs and emacs call on a program named 'ispell' and most wouldn't know that the various dictionary/wordlist files for ispell are named like iamerican, ibritish, etc.  While Debian has more packages, part of this is because they them to a finer granularity.  They don't put an IMAP daemon and a POP daemon in the same package.  Also many of the Debian packages are alternatives or are fairly obscure.  They are the sort of thing that     Of course the FreeBSD ""ports"" system is also pretty good.  I'd still like to see something like it for Linux.  (It gets the prize for most comprehensive use of the 'make' command).     Anyway, I hope you track down the problem.  If it does turn out to be a cracker, be sure to get the latest security fixes when you re-install.  There have been a number of bugs with wu-ftpd and ProFTPd recently and they are being actively exploited. (Fixes for the known bugs are at the Red Hat updates site, and at the archive sites for most other Linux distributions.     As usually you should disable any services that you don't absolutely need to run, limit access to your non-anonymous services (using TCP Wrappers and/or ipchains) wherever that's possible, replace 'telnet' support with 'ssh', 'ssltelnet' or 'STEL', use shadow passwords, etc.     Read the Security-HOWTO ( http://www.linuxdoc.org/HOWTO/Security-HOWTO.html ) and the Linux Administrator's Security Guide ( http://www.seifried.org/lasg ) for lots of details on that.                 Files invisible via Telnet?     From Norris  on Mon, 11 Oct 1999         First off, thank you for a good site, a real valuable source on all those little (and not so little) problems you run into        Second, im not sure if I should go and ask questions directly to you, but it seems others have done so, but if i am in error, please just ignore me        You did it right: mail to the  answerguy@ssc.com . It's a shame that so many people still send their questions to  jimd@starshine.org  (which is the same mailbox) because I can auto-sort LG mail from personal mail.  However, that just comes with the territory.     The Problem:     I have allowed telnet acces to my server, and i can login fine, i can su and so forth, but a lot of files just dont show up via telnet? i have messed with many combinations of file permissions, but that doesnt seem to do it... any help would be appreciated, thank you        Linux and UNIX have no mechanism for selectively ""hiding"" files based on the protocol through which you've logged in.  Unless you are running your telnet daemon or inetd in a ""chroot jail"" (a fairly obscure custom configuration) then you should be able to see everything.     Now, if you mean that some files don't appear to be readable through your terminal (you do an 'ls' and see ""blanks"" where there should be files) then that's another matter entirely.  Trying using the command:     ls --color=never     ... if your files are suddenly visible then you're just suffering from a bad terminal type (TERM environment variable) setting.     You could also try the commands:     export TERM=dumb find . | less     ... (assuming you're using a Bourne compatible shell -- like the default 'bash').   This should show you all your files.     The 'ls --color' trick has to do with the ncurses color support in the GNU version of 'ls'.  Some distributions set a system default alias like:  alias ls='ls --color=auto' so that you'll see your files in pretty colors when using a color capable terminal (such as the console, or a color xterm).  If your TERM environment variable is set correctly, and your terminfo libraries and data files are installed correctly then this alias should automatically disable the use of color when necessary.     Unfortunately the MS Windows version of TELNET.EXE is pretty wretched.  It defaults to settings which do not implement enough VT100, VT220 or VT330 support to be usable for most Linux tasks.  You're usually better off forcing that telnet client to use the older, less powerful VT52 mode.  You'd be MUCH better off to replace it with a good telnet client, such at K'95 (The Win '95 port of Columbia University's Kermit package).     Of course I'm just guessing at what you mean by ""invisible.""  It's possible that you are in a ""chroot"" jail (in which case you wouldn't see ANY files and directories ""above"" a certain point in the real directory tree.  This would probably be quite confusing to you since you'd have to have duplicate  /etc ,  /dev , and  /usr/bin  directory structures and filesets.     I've set up systems like that (in fact I've just configure my new personal workstation in this way this weekend).  However it's a relatively obscure and advanced technique that almost no one uses. You couldn't have set that up ""accidentally"" or without knowing about it.     So I'm assuming the more likely interpretation of your question.  (I usually have to do that in this business).                 sendmail Masquerading, Configuration, and User Masquerading Revisited     From Willy Lee  on Mon, 11 Oct 1999         Hi Mr. Dennis,     The information in your September 1999 column regarding fiddling with sendmail configuration was very informative, and very welcome!  I knew that sendmail looked at sendmail.cf, and that you were supposed to run a file through m4 to generate sendmail.cf, but I didn't know how to do it, now I at least have some idea.     Unfortunately Netscape rendered the backquotes rather oddly, so I labored for about an hour under the mistaken impression that they were pairs of single quotes, instead of backquote/quote pairs.     Sorry.  I'll try to remember to mention that next time I use unusual syntax such as m4's.     You said, ""For this to work smoothly you should create an account on your system that matches your account name on your ISP, and use that to work with your e-mail from that address.""  Unfortunately my desired username was already taken at my ISP, so my mail address is 'willy2' instead of 'willy', which is my account on my machine at home.     I use Gnus from within Emacs as my MUA and I've told it my correct mail address.  I believe it sets the Reply-to field, so that should be ok, shouldn't it?     Well, if I get a reply from you, then I'll know that my Gnus/sendmail setup is working        Your method seems to be working.  Under some systems you can't easily set the return addresses from your MUA.  You can have sendmail rewrite the username portion of the addresses by using the genericstable FEATURE.     I didn't want to get into that last time I was talking about this since it just adds a bit more complication.  The original correspondent was probably having enough trouble digesting all that I said as it was.     Thanks for all your columns!     You're welcome.  Glad I could help.                 General S. Fault     From dlancas on Mon, 11 Oct 1999         Along the lines of ""wha'appen?"", I started using  KDE  the other day, and klicked on my kcalc and waited... and waited.... and then I klicked again just for the heck of it.  When I tried to start the calculator from the terminal, I got the wonderful segmentation fault.  This happened previously with xosview which was working great then stopped working one day.  I recently upgraded KDE to the newest stable version (1.1.2) and noticed that along with the calculator, some other programs are also giving me segmentation faults (such as the KDE text editor).     Just who is segmentation and why is my computer blaming him for screwing up my system?  I looked in numerous books, etc, and can not find any mention of this.  Thanks in advance.     Doug Lancaster www.lancompworx.com     Maybe ""Segmentation"" is General Protection Fault's middle name        Actually a segmentation fault is Unix technese for: ""that program stepped out of bounds!""  It is similar to the old MS Windows ""General Protection Fault"" or the old QEMM ""Exception 13"" etc (except that segfaults don't make Linux kernels unstable and don't indicate that we should hastily save all our work and reboot ""before it's too late!"").     The way that Linux keeps user programs from interferring with system operations, and other user programs is through memory management.     When a program is loaded it is allocated some memory for it's binary executable code (ironically called ""text""), it's static data segment (the ""BSS""), and its stack and heap (dynamic data).  If the program needs more memory it must request it through the  malloc()  system call.  If a program ever tries to access memory outside of its segments it is stopped by the processor (on x86 and some other platforms) or some other hardware MMU (on some other CPU architectures).  This processor or MMU ""exception"" (or ""trap"" as its known in some architectures) then calls on a kernel exception handler, which then summarily kills the program, (optionally) dumps a post mortem debugging file, usually named 'core' (and consequently known as a ""core file""), and signals the program's parent process (with a SIGCHLD).     When the parent process is the shell, it prints a message like the one you describe:  ""segmentation fault, core dumped""     So, probably the programs in question have bugs in them. Perhaps they swallowed a corrupt bit of data that the programmer wasn't quite clever enough to foresee in his parsers.  Possibly some of the libraries on which these programs depend have changed or differ from the versions that the programmer was using.     Of course there are other possibilities. Perhaps the binaries or some of their libraries have been corrupted on the disk.  Possibly you have some bad memory chips (possibly some RAM that only misbehaves under specific conditions, such as when you are running the video card is specific resolutions).  Those sorts of problems usually give other symptoms like the infamous ""Sig 11"" problems ( http://www.bitwizard.nl/sig11 ).     I'd definitely shutdown and force a full fsck of all your filesystems ASAP.  If that doesn't report any problems then it probably is just the software.     Probably the latest ""stable"" KDE is not as stable as your previous version.  Maybe you need to upgrade some libraries to go with the new release.     Good luck.  You might try downgrading back to the older version to see if that clears it up.                 Linux Workstations Behind a Proxy/Firewall     From anil kumar  on Mon, 11 Oct 1999         Hi Jim,     This is Anil from India.I saw your letter in the red hat site & wanted some details on how to access the internet from my Linux box. I dual boot it with my NT.Now,I am behind a Proxy(MS Proxy & firewall)& my Ip address has been given permission to access the internet.I access it in the  usual way from NT but when i boot thro' Linux, I dont get any option to configure the Proxy server.Does the name resolution request go to the DNS configured in our local network first & from there upon not resolving to the next higher level that is, the local ISP DNS ?But i have configured my Linux box for the DNS.Now how do i configure my Linux to access the net?.I would appreciate if you would throw some light on it.     Thanx in advance, Anil.     You're probably expected to use SOCKS clients. Most proxying firewalls conform to the NEC SOCKS proxy traversal protocol (a standard way for client programs to contact a proxy and request a service).     The normal Linux client software (telnet, ftp, etc) are not ""SOCKSified"" (linked to library functions which check for proxying).  So you want to install the socks-clients RPM package.     You can find a copy of that at:     socks5-clients-1.0r6-1.i386 RPM  http://rufus.w3.org/linux/RPM/turbolinux/3.0/RPMS/socks5-clients-1.0r6-1.i386.html      It will replace most of your network client software utilities.   You'll then have to edit the  /etc/libsocks5.conf.   One of mine looks like:     socks5          -       -       -            -          192.168.1.5 noproxy         -       192.168.1.           - noproxy         -       123.45.67.0/255.255.255.240          -     Creating this file is the hardest part of using the SOCKS client RPM.  You have to put in your SOCKS proxy server at the end that first line.  That's an IP address. Then you can put into IP address patterns on your noproxy line(s).  I have set a noproxy for one RFC1918 address block, and one (sanitized) ""real"" address block with a netmask.  This would be a typical arrangement if there where a block of servers on our DMZ (Internet exposed network segment) that were directly accessible from my station.   In many other cases you wouldn't have that 3rd line, you'd go through the proxy to get to your DMZ, too.     The programs provided by this RPM will all read the  /etc/lib5socks.conf  file automatically.  There is also a shared library which can be used to ""socksify"" many ""normal"" TCP programs.  In particular, under Linux it's possible to over-ride the normal shared library (DLL) loading sequence, forcing a program to preload (LD_PRELOAD_PATH) a custom dynamical library.  Thus with a short wrapper script (described in the documentation of this package) it's possible to redefine how a program implements some library calls without recompiling the package.     Of course these libraries can also be used explicitly (by linking programs to them).  This obviates the need for LD_PRELOAD_PATH shenanigans.  Personally I haven't used this ""socksify"" technique.     Some programs (like ncftp) might have to be replaced separately.  In some cases you'll have to fetch the sources and compile programs with non-default options.  In other cases, like Netscape Navigator, you'll want to just configure them (under Navigator and Communicator look for ""Edit, Preferences, Advanced, Proxying"" and fill in the dialog box).     Some software and some protocols will not work through SOCKS proxying or will have to be patched to do so.  (Some of the Pointcast, RealAudio, CU-See-Me, and other protocols don't support SOCKS, or require proprietary proxying packages in order to traverse your firewall).     The canonical site for information about SOCKS is:     SOCKS Proxy Protocol  http://www.socks.nec.com      In particular you'll want to read the Socks FAQ ( http://www.socks.nec.com/socksfaq.html )     You probably don't need a SOCKS server (you've already got one) you just need the client software for there protocols you plan to use through this firewall).     However, I provide pointers to some server software for other readers.  You can download NEC's SOCKS software for Linux (in source form) from the web site listed above. However, you'll want to read the license on that before using or distributing it.     In addition to the NEC SOCKS implementation, Linux supports a couple of alternative SOCKS servers (NEC's SOCKS is not under GPL or BSD and it's not fully ""free"" software).     One that I've used is DeleGate ( http://wall.etl.go.jp/delegate/ ) Another that I've read about but never used is Dante ( http://www.inet.no/dante/ ).    DeleGate and Danta are free under the BSD license.     One thing I like about DeleGate in particular is that it's possible to manually traverse it.  In other words, if you have a favorite ftp or telnet client that doesn't know how to talk the SOCKS protocol, you can manually connect to DeleGate, type some magic commands at it, and it will then open up the same sort of connection that the SOCKsified client would have.  (This is like the FWTK and other manually traversed proxy systems).     There are a number of other firewall and proxying packages available for Linux.                 LILO Stops at LI     From Peter.Oliver2 on Mon, 11 Oct 1999         James,     I hope that its OK to email you here!     I recently installed OpenLINUX v2.2.  After installation, everything seems to work fine.  When I restarting LILO starts to boot with the first two letters LI and then everything locks up. None of the keys work and the only way round is a hardware reset.     I used a RedHat6.0 boot floppy which gets OpenLinux2.2 up and running.  When finally back in linux I ran fdisk.  fdisk reported that my hard drive has 1027 cylinders and warns that more than 1024 can cause problems with some programs such as LILO.     Do you think that this is the cause of the LILO boot problem?     In addition when booting from the floppy disk OpenLinux2.2 does not work properly eg. automount for the floppy disk and cdrom does not work.     If you get around to having a look at this I would appreciate it very much!     Thanks Peter Oliver     This symptom is one of those that would I expect from trying to load a kernel image or boot map that is inaccessible to your BIOS.     However, I would expect that a boot floppy would work. So long as your kernel is on the floppy (or CDROM) and your kernel supports the controller to which your hard disk is attached.  Of course it's possible to create a floppy which just has a LILO primary boot block on it (with no kernel or boot map files).  That's pretty rare so I wouldn't have expected you to make one of those (none of the common distributions would have set it up that way).     If you have a copy of MS-DOS/Win '9x on that drive, I'd used LOADLIN.EXE to run Linux.  I've described it many times before so do a search on the term LOADLIN and you'll find explanations of how that works.  Basically it lets you load Linux from a DOS command prompt.     Allegedly there was an effort to write a version of LOADLIN to run from the NT CMD.EXE console (a Win32s version). However,   I've never seen that.     So, if you have NT installed, and you don't want to repartition the first portion of this drive (to make a small Linux  /boot  partition), and you don't have MS-DOS installed (so you can run LOADLIN.EXE), then you'll want to use a floppy (with a properly configured kernel on it) to boot Linux.  Considering how rarely most of us boot Linux this is not much of a hardship.  Note: for your purposes you only need the kernel on the floppy.  You don't need a root filesystem (like you'd find on a Tom's Root/Boot or some other rescue floppy).     You can put a kernel on an MS-DOS formatted floppy, and run syslinux on that.  This lets you select kernel options and pass command line parameters to the kernel (like LILO).  You could also put an ext2 or minix filesystem on a floppy, copy your kernel to that and use  /sbin/lilo  on that.  That too will let you configure various parameters, prompts, boot passwords, etc.  You can even 'dd' a kernel directly on to a floppy (with no filesystem on it).  This will still boot --- but it won't give you any prompt, so you can't pass command line options to the kernel or through it to init.  That makes booting into single user mode (or any non default mode) rather difficult, so I don't recommend it.     Of course it's much easier if you just re-partition the drive.  You can create a small Linux partition that's below the infamous 1024 cylinder boundary.  That should be about 16 to 32 megabytes.  You'd configure that as  /boot  (a separate small filesystem mounted off of the rootfs). You can use Linux' fdisk to put that partition near the beginning of the drive, while putting your other Linux partitions near the end.     The only hard part in that is getting NT, MS-DOS, or other operating systems to work around it.  If you make a small C: drive under your MS OS' then you can still fit  /boot  in under the 1024 cylinder mark.     Another approach is to install a second drive.  PC can boot from the first or second hard disk on the primary controller.  (If you have CD-ROMs, IDE tape drive, DVD, etc. put them on the secondary and tertiary controllers).     Yet another approach is to use a commercial utility like Partition Magic, or a different freeware boot loader like GRUB ( http://www.gnu.org/software/grub ) although the FSF apparently still considers GRUB to be in ""alpha"" (as in ""unreleased, unstable, no ready for prime time"").     I hope you can see that the problem is not with Linux here. You're fighting against the legacy of the PC architecture which has never handled multiple boot gracefully and was never designed for hard drives of over 1024 cylinders.  The first PC hard drives were 5 and 10 Mb.  The early IDE drives were limited to 540Mb, which was extended to 8Gb through LBA ""translation"" (a technique for having the BIOS combine the traditional cylinder head sector (CHS) co-ordinates into linear block addresses (LBA) which were then converted back into real sector locations by the drive's electronics). Many BIOS still need to use CHS addresses to boot (thus the 1024 cylinder limits, which is 10 bits out of the 16-bit value that stores cylinder and sector).     Now we have UltraDMA drives of 15, 20, and 30 Gigabytes and some BIOS can't handle them.  The MBR only has room for about 466 bytes of program loader code (the other 66 bytes are the partition table and a flag to tell fdisk that this isn't a blank drive).  Thus the need to create small ""partition manager"" or ""boot manager"" partitions to provide room for more software, to work around these firmware limitations.     I'll be so glad to see the demise of PCs!                 Protocols on top of Protocols:  It's Protocols ALL THE WAY DOWN!     From Alicia Romero  on Mon, 11 Oct 1999         Hello my name is Alicia; I'm a student looking for help     I have a class of networking and there is one thing I don't get the Questions is What protocol is use typically by UNIX to connect to a network using TCP/IP?     Can you help me ??     It sounds like you are underestimate how much you don't get.     TCP/IP   IS  a set of networking protocols!     The question you ask, answers itself.  UNIX uses the TCP/IP suite of protocols for almost all of its networking. IP (internet protocol) is the lower portion of the suite. TCP (transport control protocol), UDP (unreliable datagram protocol), ICMP (internetwork control messaging protocol), and other protocols work over IP.     IP packets have source and destination IP addresses.  TCP packets add source and destination ports, sequence numbers, and options/flags to support flow control, acknowledgement and handshaking.  UDP packet headers lack some of features of TCP packets, so they are different variations of an IP packet.  ICMP packets (which are used by the 'ping' and some versions of the 'traceroute' commands) have headers that are different from UDP and TCP.     In addition to TCP, UDP, and ICMP there are also some other protocols that ride directly over IP (for example GRE, a routing encapsulation protocol).     Other (applications level) protocols are built over TCP and UDP.  (ICMP is used for very specific operations, so protocols aren't generally built over that)(*).     (An aquaintance who's wired into the   black hat scene once told me about a kernel hack that implemented a ""stealth telnet and file transfer protocol"" by using the normally unused data payload portion of ICMP packets.  This would require kernel modules or patches since normally ICMP packets are not routed to user space applications.  I'm not sure if this story is apocryphal.  If not it makes for a scary way for crackers to traverse many ""naive"" packet filtering schemes.)     So, protocols like telnet, HTTP, and FTP are implemented over TCP while protocols like SNMP, syslog and FSP(*) are implemented over UDP.     (a fairly obscure file sharing protocol,   which used to be particularly popular among purveyors of ""warez"" -- pirated software)     Some services use UDP and TCP.  For example SMB uses hybrid protocols over both. DNS uses UDP for normal name resolution and uses TCP for ""zone transfers"" (updating secondary authority servers).     (Another, mythical stealth communications tool   apparently uses DNS/UDP packets with ""magic"" domain names as the communications mechanism. That's even scarier since there are lots of sites that block ICMP while there are fewer that would block DNS).     So, you have applications protocols over transport protocols.  Under the IP layer you have network layer protocols like ethernet CSMA/CD, token ring, ARCnet, etc.  Under that you have media layer (physical) protocols which describe the wires, fibres, voltages, frequences and modulation parameters of the signals that actually carry all of these protocols.     So, your question is a bit confusing.  It's like asking:     What driver does a bus driver use to drive a bus?     UNIX and Linux predominantly use TCP/IP for most of their applications protocols. Connecting UNIX to a network involves running many protocols over the TCP/IP suite.     It's worth noting that Linux and some other forms of UNIX also offer support for some other transport protocols like Novell's IPX/SPX, Apple's DDP and DEC's DECnet (Pathworks) protocols.     All of this material should have been covered in the first day of any decent computer networking class. (Except for the references to FSP, and those mythical/apocryphal ""stealth"" protocols, of course).     Consider taking a better course, getting better text books to study on your own, or something --- because it sounds like this one is just not doing it for you.                 Uninstalling Linux     From Victor Turner  on Mon, 11 Oct 1999         Hi - hope you can help me,     I found and read your answer to how to uninstall Linux [dated 18th Dec     1998 from Tom Monaghan] - which related to uninstalling  Red Hat  Linux 5.2 - and thinking that I could use the info you gave in the answer to remove & uninstall my version of Linux which is  Caldera  open Linux 2.2, I followed the instructions . .     but as a complete moron when it comes to computers I somehow failed to obtain the results expected and linux won't go away ! I have it installed on my Olivetti Echos 133EM laptop PC  which has 1.6gig hard drive partitioned [during the Linux install] to 2 partions, 1 of 92% & the other of 8%     there is 80 meg RAM/  CD-ROM & Floppy drive The Caldera open Linux 2.2 used a built in version of Partition magic to partition thye hard drive during installation.     I SHOULD have waited until I obtained a second hard drive for my desktop PC where I could 'play' with Linux and learn to my hearts content whist still having my laptop [which used to have Win95 for work related stuff ] - but I was not patient and now seem to be suffering for it as I can not find out any information [other than your answer to Toms question] - which was for a different breed of Linux.     Can you help me PLEASE !  Yours in anticipation,     There is nothing special about the suggestions I offered. It doesn't matter what Linux distribution (or even what operating system) you're trying to remove.  The process boils down to:      Run fdisk (from a Linux rescue diskette) and delete the Linux partitions.  That will leave the space that those filesystems occupied as ""unallocated"" so far as MS-DOS and other operating systems are concerned.  (You con't actually have to remove the data that was in those partitions --- simply removing the partition table entries that describe the should be sufficient).  Boot from an MS-DOS floppy and type FDISK  /MBR.      This last step makes sense for versions of MS-DOS after version 5.x.  Win '9x is really still just MS-DOS with a GUI glued over the front of it.  So most of this should apply to it as well, when you manage to get in behind the GUI. Alternatively you should be able to use the command:     lilo -U     ... BEFORE you delete your Linux partitions.     When you first install Linux using LILO, the  /sbin/lilo  command will create a  /boot/boot.0XXX  file, a backup of the MBR that it originally found on the system.  The -U and -u options of the  /sbin/lilo  command will put that backup copy back into place (if it exists and with some sanity checks).     Note:  The lilo -U command is basically the same as using a command like:     dd if=/boot/boot.0XXX of=/dev/hdX count=446     ... though it should be a tiny bit safer.  In any case I highly recommend performing a backup of your system before doing any software installations, upgrades, or removals.     Incidentally, if you really want to wipe data from those Linux filesystems before you remove the partitons you can use a command like:     dd if=/dev/zero of=/dev/hdXXX     ... do over-write a whole partition or drive with ASCII NULs.  Note: if you do that with of= (output file)  /dev/sda  you'll wipe your entire first SCSI hard drive. If you do it with  /dev/sda1   you'll only much the first partition on that drive.  If you use  /dev/hdb3  you'll destroy the number three primary partition on your second IDE drive,  /dev/hda6  will get the second LOGICAL partition on your first IDE drive, and so on.     If that doesn't scare you then you didn't read it carefully enough.  You can wipe out whole drives or individual partitions using the 'dd' command.  It should be treated like a six-foot razor!     Also note that you really want to do these operations while booted from a rescue floppy.  Otherwise you'll destroy shared libraries, swap partitions, and other data that Linux needs to complete your swipes.     In the worst case to a backup of your entire DOS/Win '9x system.  Test it.  Then boot from a rescue floppy, zero out the whole drive; re-install MS Windows from scratch and restore your data.  I know that's inconvenient and scary.     It's the shame of the whole computer industry.  Backups and restores are slow, expensive, unreliable and instill little confidence in most users.  That problem is hardly unique to Linux, or PCs; I hear that from all sorts of users.     (My preferred means of doing software and OS upgrades is to perform the installation on a new system, then copy my data and configuration over.  I just did that to canopus this weekend, so I'm writing from canopus2.  In a week or so I'll wipe out the old canopus and rename my new host to use the old name).                 Who is Jim Dennis?     From SeanieDude on Mon, 11 Oct 1999         hey why did it take you so long to respond i don't even know what i searched for anymore     I've been busy.     anyway go to my page at    http://go.to/3d~now      Yuck!  Looks really ugly in Lynx.  Of course you seem to be selling banner ad graphics design services and you seem to want frames and require JavaScript to view your site.  So Lynx users wouldn't be interested anyway.     Sean                 FoxPro 2.0 (SCO) Running Under Linux: Try Flagship?     From Joseph Gazarik  on Mon, 11 Oct 1999         Dear James,     Hello, my name is Joe Gazarik.  I am a software support specialist     with Signal Software in Pittsburgh, PA.  Signal produces accounting software for the automotive aftermarket.  Our current product, TireWorks Gold is FoxPro 2.6 based running on SCO.  I have been commissioned to get that FoxPro 2.6 SCO program working in Linux.  I would appreciate any and all help that you could lend me.  Do you have any suggestions in getting FoxPro 2.6 runtime for SCO Unix running on Linux?  Thanks in advance for your assitance!     Best Regards, Joe Gazarik     Well, I don't know of a Linux port of FoxPro.  It seems unlikely that we'd see one any time soon since Fox software was aquired by Microsoft.     In general you can run SCO compatible software under Linux by using the iBCS libraries.  For that I'd run  Caldera 's OpenLinux since they provide a kernel with iBCS patches already applied.     For FoxPro specifically you might find that they rely on some of SCO's proprietary libraries.  You'd have to copy those unto your Linux system from your SCO system --- and you'd have to watch the licensing issues that relate to that.  Obviously that might cause some serious problems for your software distribution plans.     You could port your software to Flagship ( http://www.wgs.com/fsad.html ). That is a package from WorkGroup Solutions which provides a set of programming tools for compiling dBase code (with Fox, Clipper and other xBase extensions).     You can then create and distribute standalone native applications using your existing xBase sources. The resulting programs are royalty free and should run on Linux systems without any need for iBCS or any proprietary libraries.     As a commercial software developer this sounds like it would be your best bet.     In addition it looks like Flagship offers modules to support connections to SQL backend databases.  This could be useful if you develope client/server versions of your package in the future.                 Coping with Bad Sectors     From excess6 on Mon, 11 Oct 1999         Hi, i found out my 4month old quantum hdd has some bad clusters, is there a way i can fix it? what happed was i turned off ym poota in windows and later on i turned it on and it said data error reading c: i did scandisk surface scan and it found 1 of my sectors was bad, i rebooted later and windows is working but is there anything i can do to like isolate the sector so i dont put inportant stuff on that sector or something. -cheers excess     I would hope that SCANDISK.EXE would mark bad sectors so they would no longer be used.  If not, get a copy of Norton Utilities or download some shareware utilities for MS-DOS.  There used to be a few utilities with names like MARKBAD.COM that would mark clusters as bad under MS-DOS.  (Windows '9x filesystems are mostly the same as MS-DOS FAT with some hackery involving extra ""volume labels"" to get long filename support.  MS should have called their new variant KFAT -- for ""kludge"" rather than VFAT).     Of course if you were using Linux you could just use 'e2fsck -c' to check your filesystems, test them for back blocks and automatically assign any bad blocks to a special system list (thus prevent them from every being accessed by anything else).     When you create new filesystems under Linux, you should also use the -c option to mkfs (or check the appropriate box/option in any GUI/dialog that you happen to be using).                 Homework Assignment: Write about Linux Memory Management     From Rhymer,Robert  on Mon, 11 Oct 1999         I was wondering if you knew a site where I can get alot of information on Linux's Memory Management.  I am doing a report on it and need as much infomation I can get. Websites, books, etc.. any info will help. Thank you for your time.     How about the source code?  That would be the most authoritative resource on the topic.  Look through the sources in  /usr/src/linux/mm  for starters.     If you look at my ""LDP by Topics"" page and search on ""programming"" you'll find a list of all of LDP HOWTOs and guides that relate to Linux programming.  In particular there the ones that refer to the ""kernel.""  That might be a good introduction; help you get your bearings.     There is also the  ""The Linux Programmer's BouncePoint"" at  http://www.ee.mu.oz.au/linux/programming  and the Linux Programming page at the #LinuxOS (IRC Channel) home page:  http://www.linuxos.org/Lprogram.html  Another site is Rik van Riel's Linux Memory Management page at:  http://www.linux.eu.org/Linux-MM  (though this is really pretty preliminary -- it has links to related topics.  Rik apparently started this, then got side-tracked to write a performance tuning guide. (An understandable priority, considering things like the Mindcraft fiasco).                 HP with LT Winmodem     From Bob Gregg  on Mon, 11 Oct 1999         I have just purchase a HP computer with LT Winmodem . DEspite loading new and latest drivers etc I can only connect at 28,800 to my isp . I have tried other isp's as well spoken to HP at length and to no avail.  any suggestions.     Bob Gregg     It sounds like you're not running Linux.  So my first suggestion is: don't send non-linux questions to the Linux Gazette Answer Guy.     If you're getting 28.8 then be happy.  Speed claims beyond that are dubious and likely to occur only under optimal conditions, rarely and briefly.  If you really need faster access you'll have to look at alternative technologies (ISDN, cable modem, leased line, DSL, etc).                 Linux to HP9000 Through RAS?     From hansmok on Mon, 11 Oct 1999         Dear Jose L. Torres Reyes,     I am a beginer who have interest in linux in South Korea.     First, please don't send e-mail in HTML format. Most people won't appreciate it.  (Obviously if you have some friends who prefer it, you can do what you like with them.     The best way to send e-mail is as plain, simple ASCII text with no special characters, and simple line, space and tab formatting.  Keep the lines down to about 72 characters or less.  For best results leave a few spaces or a tab on the left as a ""margin.""     [ We've no idea who Mr. Reyes is, either.  But it was,         at least, a Linux question.  -- Heather ]     I tried contacted between  personal computer(operating system:slackware linux) and HP9000 unix server(operating system:UNIX) through PPP(point to point protocol) method.     I checked success in login into HP9000 unix server but failed after inserting password.     I don't know the reason that failed  in contacting  into HP9000 unix server.     I use RAS(Remote Access Service) in contacting. I'd like to receive your answer as soon as possible.     Bye.     There are many ways to set up PPP among UNIX and Linux systems.  I don't know what your HP-UX is referring to as ""RAS"" (remote access server).  It could be that they've implemented some service that is designed to allow NT systems to log into theirs. (That would be the most likely meaning of the term RAS in this context).     The Linux PPP daemon would not normally function as a RAS client.  There maybe options to do that, however it seems like it would just complicate matters.  I'd suggest that you just play with the HP PPP settings (see their docs for info on that --- or talk to their technical support) so that they allow simple PAP or CHAP authentication.  Then configure your Linux pppd accordingly.     The difficult thing about PPP in general is that you have to make sure that your settings and those of your remote (ISPs in most cases, the HP9000 in yours) all match.  Different PPP implementations use slightly different terms for some of the many features that they offer, and most of them have completely different configuration file formats, locations and command line options.     Be sure to spend time with the Linux PPP HOWTO at  http://www.linuxdoc.org/HOWTO/PPP-HOWTO.html .                 TCPMux Revisited:  You'll need a Daemon for it, or a Better inetd     From Helpdesk  on Fri, 1 Oct 1999       Thnx jim (hope i can call you that).     i could make my work do with the Mike Neuman's BINETD, ""Better INETD"" at:  http://www.engarde.com/~mcn/binetd/index.htm )     works ok till now.     will be in touch.     ciao     jaggu             Overwrote NT with RedHat: Good Idea But Bad Move     From tonyray  on Mon, 11 Oct 1999         Hi there answer guy,     Im tonyray form philippines, got a big problem.     I was installing a redhat 5.2 on my computer, with 1st hardrive ide-with nt4 normally working, 2nd hardrive for redhat5.2.  What happened the nt4 hardrive was deleted reformatted into linux native.  Is there a way to get back my nt4 files, like unformat?     please help thanks tonyray     Unformat would NOT help in this situation regardless of which OS or platform was involved.  You didn't merely reformat your drive or delete those files.  You've overwritten most or all of them.     The only reasonable way to get back your files is from a backup. I realize that you probably don't have one --- I've found that too many people walk the software installation and upgrade high wire with the safety net of a recent, tested backup of their data.     Sorry I can't offer you better news or more hope.  If your data is worth quite a bit more than your computer you could look into data recovery using ""magnetic force microscopy"" (a technique used in criminal crime labs computer forensics).     Of course the procedure would probably cost more than my annual salary and probably only be partially successful.  So that suggestion is not practical.                 Partitioning Advice     From Stock Watch  on Fri, 15 Oct 1999         Greetings James,     Hi, I'm Wong. I need your advice on how to partition a 6.2GB hard disk so that it can optimize the usage of Linux. This is my first time installing Linux. I intend to set it as a full Linux server. The main purpose of the Linux server is to act as a mail server besides doing other functions. I also learn that it need a swap partition. Please advice. Thanks in advance.     Cheers, Wong     This is a very common question.  There are differing views and philosophies on the subject as well.     Here's my suggestions:       /boot     31Mb   /   127Mb   (swap)   127Mb   /usr  1635Mb (1.5Gb)   /tmp   127Mb   /home  2047Mb  (2Gb)   /var  (rest: ~3Gb)     ... and on some systems I'd add other filesystems on another drive.  For example a filesystem on  /var/spool/mail  can be mounted with the ""sync"" (insuring that all writes to that filesystem are done synchronously --- minimizing the damage down by a power failure).     This set of values is based on years of experience.  It leaves plenty of room for extra kernels, initrd images and System.map files on  /boot , gives plenty of room for paging (swap).   /usr  is big enough to install LOTS of software.  If this was going to be used exclusively as a mail server then you don't need anywhere near that much space on  /usr.   Of course you shouldn't need anywhere neer 3Gb for normal mail and POP services either.     That should get you started.  If you find that you do manage to outgrow your disk space, you can add additional drives pretty easily.  I've described that process in previous Answer Guy columns.                 UNIX Emulation Under Linux?  iBCS     From antonio on Fri, 15 Oct 1999         Hi James,     i read an answer of your's in Linux Gazzette regarding Unix emulators.     I seem to understand that Lucent's Inferno is a Unix emulator for Linux??     I have a problem. There is a program for Pharmacy's here in Italy (very widely used) which has the function of registering medical codes etc. but which runs only under Unix. But Unix OS's are not free so Pharmacies are forced to buy Unix OS (Open Server) only for the sake of letting the computer run for that specific prog i mentioned above. Linux instead is free so pharmacies would not have to afford the price of the OS. Though the company that wrote the prog is not willing to port it under linux ... for obvious reasons of economical interest as they handle the licence of the OS and thus have a share on that too. With linux they would have to give up the that share. Can you help me??     First Lucent's Inferno operating system is not a form of UNIX.  It can run as a ""standalone"" (traditional) operating system, and it can apparently run as a ""rehosted"" OS (that is an operating system which runs under another system's kernel, and accesses the system hardware through the host OS' system calls).  So, Inferno can run under Linux.     Now onto your core question.  When you say that this proprietary software runs ""only under Unix"" what do you really mean?  UNIX is not a single product or operating system.  UNIX is a family of operating systems and related utilities, and a philosophy or paradigm for system design. In that sense Linux  is  UNIX.     It is meaningless to say that UNIX is not a free OS.  FreeBSD , 386BSD,  OpenBSD ,  NetBSD , all have as much historical claim to ""being UNIX"" as any AT&T SVR4 system. Those are all free operating systems.  Linux was independently developed.  So it can't claim to  be  UNIX on historical or ""familial"" grounds.     What I think you were saying is that this proprietary pharmaceutical management product is written to run under one of SCO's UNIX products (Open Server, or Open Desktop).     If that is the case than you might be able to run the package under iBCS.     iBCS is the ""Intel Binary Compatibility Specification"" --- an old (pre-Linux) standard binary format for executables on x86 forms of SVR4 UNIX.  At one time there were over 20 different commercial competitors to SCO on x86 hardware. There was a lackluster effort among these vendors to share a common executable file format and suite of libraries so that ""shrinkwrapped shelfware"" could be developed for ""any"" version of UNIX on the x86.     SCO OSVR and ODT programs are iBCS by default (if I understand it correctly).     Linux does support iBCS through a set of optional libraries.  (Ironically SCO and Solaris now support Linux binaries through their lxrun packages.  FreeBSD has been able to run Linux binaries for years).     So, it might be technical possible for you to run this proprietary application.  Then again the app. might be linked against some SCO proprietary libraries --- which you might not be licensed to copy to your Linux systems.     Aside from the technical issues you must consider the legalities.  It might be a violation of your license to run this software under a different OS.  Of course it might also be an illegal and unenforcable contract in your jurisdiction.  If this company requires that you buy a given product with theirs (bundling), you might have legal recourse.     I don't know.  I'm not a lawyer.     So, I'll just get back to the technical issue.  You can probably get this to run under Linux by using iBCS.     The iBCS libraries ship with most Linux distributions. You can also find them on line with a simple Yahoo! or Google search.                 PAM applications running as root (Was Re: WebTrends Enterprise Reporting Server)     From Darren Moffat on Sun, 17 Oct 1999       You can run the server as root or as some other user. In order to use PAM (Pluggable Authentication Module) it has to run as root.     A general comment about PAM rather than this specific problem.     It is NOT a requirement of the PAM framework that application be running as root.  There are two cases though that make login type applications need to run as root.     1) The password is stored in  /etc/shadow  which only root can read     If the password was in NIS/NIS+/LDAP then the authentication could succeed are an ordinary user.     Actually it should be possible for  /etc/shadow  to be group readable and associated with a ""shadow"" or ""auth"" group.  Then SGID programs could authenticate against it.     A different level of access could be required to modify it (that would presumably be reserved for root, since the ability to modify the  /etc/shadow  and  /etc/passwd  files on those systems that are configured to honor local files will consitute root access in any event).     2) the login application needs to make setuid/setgid calls this     usually happens in the application after PAM authentication has been completed and is thus nothing to do with PAM.     If the OS has privileges/capabilities then the application would assert PROC_SETID/CAP_SETID instead of being root to make the setuid/setgid calls.     Linux 2.2 has privs implemented in the kernel.  There is, as yet, no filesystem system support for storing the priv. bitfield metadata.  So, anyone wishing to ""capify"" the Linux authentication system would have to do so through wrappers.     I'm personally disappointed by the lack of progress in this field.     It seems that we should have at least attained the ability to emulate BSD securelevel (wrap"
GX232-64-6342275	Checking for Flash          5 player...
GX052-74-1309580	"September 1999, Issue 45 Published by  Linux Journal                         Visit Our Sponsors:                                            Table of Contents:     The Front Page    The  Linux Gazette  FAQ     New feature!   The MailBag      Help Wanted & Article Ideas   General Mail     News Bytes       News in General   Software Announcements     The Answer Guy , by James T. Dennis  More 2 Cent Tips   Living La Vida Linux , by Bill Bennet  Setting Up A Java Development Enviroment For Linux , by Chris Gibbs  Stripping and Mirroring RAID under RedHat 6.0 , by Mark Nielsen  Linux Humor , by Mike Orr  Mail for the Home Network , by JC Pollman and Bill Mote   Experiments with SMTP , by Jan Stumpel  Linux is Better Here , by Trenton G. Twining  Sharing a Linux server under X in the classroom , by Alan Ward  The Back Page      About This Month's Authors   Not Linux         There is no  Graphics Muse  this month.  The column will return next month.                            TWDT 1 (gzipped text file)   TWDT 2 (HTML file)  are files containing the entire issue: one in text format, one in HTML.  They are provided  strictly as a way to save the contents as one file for later printing in the format of your choice;  there is no guarantee of working links in the HTML version.                   Linux Gazette ,  http://www.linuxgazette.com/   This page maintained by the Editor of  Linux Gazette ,   gazette@ssc.com      Copyright © 1996-99 Specialized Systems Consultants, Inc.                    ""The Linux Gazette... making Linux just a little more fun! ""                   The  Linux Gazette  FAQ     Updated 31-Aug-1999       Contents        Questions about the  Linux Gazette         Why this FAQ?     Where can I find the HTML version of the  Gazette ?     Which formats is the  Gazette  available in?     Which formats is the  Gazette   not  available in?     How can I find all the articles about a certain subject?     May I copy and distribute the  Gazette  or portions thereof?     You have my competitor's logo on the Front Page; will you put mine up too?             Linux tech support questions        How can I get help on Linux?     Can I run Windows applications under Linux?     Do you answer Windows questions too?     How do I find the help files in my Linux system?            This FAQ is updated at the end of every month.  Because it is a new feature, it will be changing significantly over the next few months.              Questions about the  Linux Gazette      1. Why this FAQ?     These are the most Frequently Asked Questions in the  LG  Mailbag. With this FAQ, I hope to save all our fingers from a little bit of typing, or at least allow all that effort to go into something No (Wo)man Has Ever Typed Before.              2. Where can I find the HTML version of the  Gazette ?        The main web site--  www.linuxgazette.com .      Mirror sites in 47 countries , some with translations in other languages.     Indirect mirrors, including    Linux Documentation Project  mirror sites.     In the   Debian/GNU Linux  distribution, as ordinary *.deb packages.     On CD as part of a  Linux Journal  archive CD-ROM .  There may also be other companies that include the  Gazette  on their CDs--we don't keep a central list.  (But we may in the future.)                   3. Which formats is the  Gazette  available in?         As a single HTML file.   Every issue includes a TWDT (The Whole D--- Thing) file containing a copy of all the articles in one file.  This may be useful if you have a slow modem, or if you want to print it all out at once.  Look for ""TWDT"" near the bottom of the issue's Table of Contents.  Hyperlinks in this version are not guaranteed to work.      As a single text file.   This is a text-only version of the above.  Look for ""TWDT"" near the bottom of the issue's Table of Contents.      Via FTP.   Each issue is available as a *.tar.gz file, containing both the ordinary HTML files and the TWDT files.  See   ftp://ftp.ssc.com/pub/lg/README  for details.  Other FTP sites are listed on our   mirrors  page.                  4. Which formats is the  Gazette   not  available in?     Other archive formats.  We need to keep disk space on the FTP site at a minimum for the sake of the mirrors.  Also, the Editor rebels at the thought of the additional hand labor involved in maintaining more formats.  Therefore, we have chosen the formats required by the majority of  Gazette  readers. Anybody is free to maintain the  Gazette  in another format if they wish, and if it is available publicly, I'll consider listing it on the mirrors page.     Zip,  the compression format most common under Windows. If your unzipping program doesn't understand the *.tar.gz format, get Winzip at  www.winzip.com .     Macintosh formats.   (I haven't had a Mac since I sold my Mac Classic because Linux wouldn't run on it.  If anybody has any  suggestions for Mac users, I'll put them here.)     Other printable formats.          PostScript      You can use Netscape's ""print to file"" routine will create a PostScript file complete with images.        PDF      I know Adobe and others consider PDF a ""universal"" format, but to me it's still a one-company format that requires a custom viewer--not something I'm eager to maintain.  If you can view PDF, can't you view HTML?      Word      I'll be nice and not say anything about Word....        E-mail.   The  Gazette  is too big to send via e-mail. Issue #44 is 754 KB; the largest issue (#34) was 2.7 MB.  Even the text-only version of #44 is 146 K compressed, 413 K uncompressed.  If anybody wishes to distribute the text version via e-mail, be my guest.  There is an announcement mailing list where I announce each issue; e-mail  lg-announce-request@ssc.com  with ""subscribe"" in the message body to subscribe.  Or read the announcement on  comp.os.linux.announce .     On paper.   I know of no companies offering printed copies of the  Gazette .                5. How can I find all the articles about a certain subject?     Use the  Linux Gazette    search engine . A link to it is on  the Front Page , in the middle of the page.  Be aware this engine has some limitations, which are listed on the search page under the search form.    Use the  Index of Articles .  A link to it is on the Front Page, at the bottom of the issues links, called ""Index of All Issues"".  All the Tables of Contents are concatenated here onto one page.  Use your browser's ""Find in Page"" dialog to find keywords in the title or author's names.             6. May I copy and distribute the  Gazette  or portions thereof?     Certainly.  The  Gazette  is freely redistributable.  You can copy it, give it away, sell it, translate it into another language, whatever you wish.  Just keep the copyright notices attached to the articles, since each article is copyright by its author.  We request that you provide a link back to  www.linuxgazette.com .    If your copy is publicly available, we would like to list it on our  mirrors page , especially if it's a foreign language translation.  Use the submission form at the bottom of the page to tell us about your site.  This is also the most effective way to help  Gazette  readers find you.               7. You have my competitor's logo on the Front Page; will you put mine up too?    All logos on the Front Page and on each issue's Table of Contents are from our sponsors.  Sponsors make a financial contribution to help defray the cost of  producing the  Gazette .  This is what keeps the  Gazette  free (both in the senses of ""freely redistributable"" and ""free of ads""   )  To recognize and give thanks to our sponsors, we display their logo.    If you would like more information about sponsoring the   Linux Gazette , e-mail  sponsor@ssc.com .               Linux tech support questions     This section comprises the most frequently-asked questions in The Mailbag and The Answer Guy columns.              1. How can I get help on Linux?     (A proper answer will be posted in the next issue.  In the meantime...)    Check the FAQ.  (Oh, you already are. :)    Questions sent to  gazette@ssc.com  will be published in the Mailbag in the next issue.  Make sure your From: or Reply-to: address is correct in your e-mail, so that respondents can send you an answer directly.  Otherwise you will have to wait till the following issue to see whether somebody replied.    Questions sent to  answerguy@ssc.com  will be published in The Answer Guy column.    If your system is hosed and your data is lost and your homework is due  tomorrow but your computer ate it, and it's the beginning of the month and the next Mailbag won't be published for four weeks, write to the Answer Guy.  He gets a few hundred slices of mail a day, but when he answers, it's direct to you.  He also copies the Gazette so that it will be published when the month end comes comes along.    You might want to check the new Answer Guy Index and see if your question got asked before, or if the Answer Guy's curiosity and ramblings from a  related question covered what you need to know.             2. Can I run Windows applications under Linux?     An excellent summary of the current state of WINE, DOSEMU and other Windows/DOS emulators is in issue #44, The Answer Guy,   ""Running Win '95 Apps under Linux"" .    There is also a program called  VMWare  which lets you run several ""virtual computers"" concurrently as applications, each with its own Operating System.  There is a  review  in  Linux Journal  about it.              3. Do you answer Windows questions too?    Answers in either the Tips or Answer Guy columns which relate to troubleshooting hardware, might be equally valuable to Linux and Windows users. This is however the  Linux  Gazette ... so all the examples are likely to describe Linux methods and tools.   The Answer Guy has ranted about this many times before.  He will gladly answer questions involving getting Linux and MS Windows systems to interact properly;  this usually covers filesystems, use of Samba (shares) and other networking, and discussion of how to use drivers.   However, he hasn't used Windows in many years, and in fact avoids the  graphical user interfaces available to Linux.  So he is not your best bet  for asking about something which only involves Windows.  Try one of the  Windows magazines' letter-to-the-editor columns, an open forum offered at  the online sites for such magazines, or (gasp) the tech support that was  offered with your commercial product.  Also, there are newsgroups for an  amazing variety of topics, including MS Windows.             4. How do I find the help files in my Linux system?    The usual command to ask for a help page on the command line is the    word  man  followed by the name of the command you need help    with.  You can get started with  man man .  It might help you to     remember this, if you realize it's short for ""manual.""   A lot of plain text documents about packages can be found in      /usr/doc/packages  in modern distributions.  If you installed    them, you can also usually find the FAQs and HOWTOs installed in     respective directories there.   Some applications have their own built-in access to help files (even those    are usually text stored in another file, which can be reached in other    ways).  For example, pressing F1 in  vim , ? in  lynx ,    or ctrl-H followed by a key in Emacs, will get you into their help system.    These may be confusing to novices, though.   Many programs provide minimal help about their command-line interface if    given the command-line option  --help  or  -? .  Even if these    don't work, most give a usage message if they don't understand their command    line arguments. The GNU project has especially forwarded this idea.  It's    a good one;  every programmer creating a small utility should have it    self-documented at least this much.   Graphical interfaces such as  tkman  and  tkinfo  will    help quite a bit because they know where to find these kinds of help files;    you can use their menus to help you find what you need.  The better ones    may also have more complex search functions.   Some of the bigger distributions link their default web pages to HTML    versions of the help files.  They may also have a link to help directly from    the menus in their default X Windowing setup.  Therefore, it's wise to    install the default window manager, even if you (or the friend helping you)    have a preference for another one, and to explore its menus a bit.                This page written and maintained by the Editor of  Linux Gazette ,  gazette@ssc.com  Copyright © 1999, Specialized Systems Consultants, Inc.,             ""Linux Gazette... making Linux just a little more fun! ""             The Mailbag!    Write the Gazette at   gazette@ssc.com     Contents:     Help Wanted -- Article Ideas   General Mail                Help Wanted -- Article Ideas     Answers to these questions should be sent directly to the e-mail address of the inquirer with or without a copy to gazette@ssc.com. Answers that are copied to  LG  will be printed in the next issue in the Tips column.     Before asking a question, please check the new   Linux Gazette  FAQ  to see if it has been answered there.                  Wed, 04 Aug 1999 06:09:15 +0300  From: Marius Andreiana < Marius_And@usa.net>   Subject: Article idea    Hi this is Marius.    I think a very good article could be made about PostgreSQL. One which wouldn't repeat what's in the HOWTO, but present how to use it on the web, some  interfaces to it ( like Java, Php3, Perl, ... ), with  advantages/disadvantages, links to good sites for newcomers etc.    I used to developed some Visual FoxPro applications, but I'd like something more powerful ( and free ) for use over TCP/IP. I've read the web section in the HOWTO but I don't have the time to get the tools described there ( must learn for getting admitted in university ).    Thank you, Marius              Thu, 05 Aug 1999 09:25:03 +1000  From: Dave Mason < 91001832@snetnzwe.cpg.com.au>   Subject: Which distribution for an advanced user?    i was just curious if you had a mailing list? if you i would be very grateful if you could add me to your mailing list.. as i am interested in learning the problems and solutions of Linux and other important information.    Which distribution of Linux would you recommend for an Advanced Linux user? at the moment i am using Debian 2.0 as my root source and Redhat 5.1 as my server...  I've installed and ran FreeBSD 2.8.8 but i find linux more useable...     [See the  LG  FAQ  for the mailing list  question.     I use Debian because it doesn't get in the way of the advanced  user the way some other distros do.  Plus I like the ""designed by  volunteers"" aspect, and the fact that I can participate in the  development process to whatever extent I want.  (I'm not a developer,  but I read debian-devel sometimes and worked at the Debian booth at  LinuxWorld in March.)     The question is, are you dissatisfied with your current systems?  If not, why switch? -Ed.]      Thanks Alot Sifer              Fri, 30 Jul 1999 23:21:57 -0400  From: AP < adpias@golden.net>   Subject: modem     I am a new Linux Red Hat 6.0 user.    I cannot connect to the Internet (still using W98). My 3com-USR 56K voice faxmodem-V90 is not working under Linux. The serial # of my modem is 5685. It's p-n-p Sportster with jumper to set com-port and IRQ manually.    I could not get any help from Red Hat!    I am looking for anybody who can help me to make this modem working with Linux.  If it is impossible, which modem should I buy?    Please help, don't leave me with Windows!    Adam               Sun, 01 Aug 1999 04:00:26 -0400  From: Zeb Morgan < n4zm@mindspring.com>   Subject: Digitizing program    I have a ton of documents that I wish to digitize.  Is there a program running under Linux that is similar to PaperPort, Pagis Pro, and/or PageKeeper?    Thanks.                Tue, 3 Aug 1999 12:32:35 -0000  From: JUIN Aymeric < Aymeric.JUIN@DGI2000.com>   Subject: linux on a laptop    I'm a linux newbie.  I installed linux (redhat 5.2) on a laptop with an ATI rage LT PRO AGP2X, and there's no driver for this graphic card to run Xwindow, I tried to find one on the web, but without success, I also tried other ATI drivers (like ATI rage pro and other MACH64 drivers) without better results. Is there any solution ? Please help me...    PS : sorry for my poor english.               Thu, 05 Aug 1999 07:36:55 +1000  From: Dave Mason < 91001832@snetnzwe.cpg.com.au>   Subject: Running Windows Programs In Linux?    Is there any way of Running Windows Applications and Programs from Linux? i've heard of dosemu, but that only supports some of the dos games, if there is such a product, could you tell me the name of it and where to get it from... and is it also multi-platform Unix?,     [This is answered in the  FAQ . -Ed.]                 Thu, 5 Aug 1999 00:49:33 +0100  From: Advanced one corporation < advanced1@ibm.net>   Subject: I have a question   I hope you don't mind this question, but I am a newbie at Linux Red Hat 5.2 and I am trying to find out what is a mount point and how do I define it during installation?  T       A mount point is an empty directory upon which another disk  partition is (or will be) mounted.  When mounted, it creates the  illusion that the entire partition is inside that directory.  This is  how UNIX handles multiple partitions, different from the C: D: E: drive  letters that Dos/Windows uses.     I use Debian, so I'm not very familiar with Red Hat's installation  program.  I believe the partitioning dialog (Disk Druid?) has a column  where you define the mount point for each partition, and it  automatically creates directories as needed.     Later, you'll use mount points to access floppy disks, CD-ROMs,  network filesystems, etc, the same way.  The ""mount"" and ""umount""  commands (or an equivalent GUI dialog) open and close access to these  devices, through the mount point directory. -Ed.                   Thu, 05 Aug 1999 00:19:16 -0400  From: M.Myszkowski < myszy@home.com>   Subject: Network with Win98    Hi,    I want to put in network my two computers. First one as a server has Win98 and is connected to the internet via cable modem (using different ethernet card).Second one - client has Red Hat Linux 5.2 Deluxe. I am a beginner with Linux and I don't know how to set up network configuration in both computers.    Thanks,  Marek                Wed, 04 Aug 1999 22:09:27 -0400  From: Myk < mykill5@mindspring.com>   Subject: Essential Software...When will we get it?    I have been using Linux from the early days when Slackware and Debian where the kings. I have always had a dislike for Windows 3.1 straight through to Win 98; but the one thing Windows has is some great software from great vendors Like Macromedia. I switch from Windows to Linux just to use programs like Flash, DreamWeaver, QuarkXpress, as well as small programs like Rio GUI, ReBirth, etc. When can we see these programs ported to Linux? Are there any rumors of companies trying to port se to Linux? Is there a competant Emulator available that can run these programs without a problem? I now use Linux as my OS of choice. It dominates my HD and I use nothing else; but I do miss some of the great WYSIWYG HTML Editors and Flash etc...Oh well guess I will have to make do with what I got.  The other thing is that I just purchased a laptop and before it is delivered is there anything I should know about installing Linux on my Laptop with minimal casulties? How should I go about installation? What about video, sound, etc...?     Thanx,    Lance Miller               Wed, 4 Aug 1999 21:55:42 -0700 (PDT)  From: BurleyRon@aol.com < BurleyRon@aol.com>   Subject: A Request for Assistance     When I first read of Linux in a catalog, I had hopes that it would be my  personal ticket out of Microsoft's sticky hands.  I had hoped it would be  analogous to a modern DOS or something like that.  I would typify myself as  an expert in pre-Windows DOS and as passable in post-Windows DOS.      Well, frankly, I hardly understand many of the words.  Right away I knew I had made a mistake.  This Linux is for computer jocks and developers of the first magnitude.    My question for you is, ""Am I right?""  Have I stepped through the  looking-glass of computer literacy into the wonderland of the developmental  dervish?  There could be one other explanation -- I jumped into the middle of  the story when I should have begun at the beginning.  Is there a beginning  for the computer literate person -- where terms are defined, examples are  given, teachers are patient and I can begin to gradually ""wean"" myself from  Mother Windows?                Fri, 6 Aug 1999 12:13:28 +0100  From: Geoff Hare < geoff@hare21.freeserve.co.uk>   Subject: Setting up LINUX     I am in the process of acquiring a new PII - 450 Machine.  I have decided to have 2 x 10Gb hard drives.  One of these drives will be partitioned for LINUX programmes and LINUX Data.    Is these anyone in the CROYDON-CATERHAM-CRAWLEY area would be interested enough to help me carry out the installation process?    Geoff Hare (who spotted Linux some time ago and felt that it might come to something!)                 Mon, 09 Aug 1999 09:35:19 -0400  From: Rajani K Yellamanchili < Rajani.Yellamanchili@wmich.edu>   Subject: Unix Startup    Dear Administrator:    I am a student at Western Michigan University, and am currently collecting resources for the startup tasks performed by unix/linux. I request you to help me if you can. I state my exact requirement below.    I am looking for all the files invoked/used by the init process at startup, when a work station boots up in a network. I am also looking for the organization of the /etc directory and its probable contents.    Looking forward for your reply, I remain    Regards  Raj     The boot loader starts init, which reads /etc/inittab.  See man 8 init,  man 5 inittab.   Most distributions follow the Linux Filesystem Standard for the sake of  interoperability.  A newer document is the File Hierarchy Standard; the  distributions have not yet implemented this, but are expected to in the  near future.     http://www.pathname.com/fhs/    The runlevels use configuration files in or near /etc/init.d and  /etc/rc.d.  The ""System V"" method is used by Debian and Red Hat.  In  it, /etc/init.d contains scripts named after a package.  Symbolic links  in the /etc/rc*.d directories (numbered according to runlevel) specify  which services should be started or killed when switching to that  runlevel.  The ""BSD"" method is used by older (and current?) Slackware  systems: /etc/init.d doesn't exist, and /etc/rc*.d are scripts (one for  each runlevel) which handle the starting and stopping of services. -Ed.                    Wed, 11 Aug 1999 18:38:04 +0000  From: R. Smith < rsmith13@tampabay.rr.com>   Subject: Why are they trying to telnet in to my Linux box?    Sir,    Recently I noticed that, most every time, my niece used her Win 95 computer (on my lan),  I would start getting a lot of telnet attempts to my Linux masq box.  Most of them  were from dalnet.somthing.or .other.  So I sent email to several of them asking why they were trying to telnet to my box.  Here's the reply that I got from one:    Jason wrote:       Dear Sir or Madam,    The ""attack"" you have seen is not an attack at all, but a check for an  open Wingate or SOCKS server on your computer.    Toledo Internet Access is the host of glass.oh.us.dal.net.  We have  recently implemented a policy of checking users on connect for open  Wingate and SOCKS servers to attempt to cut back in the abuse of Dalnet  via these often abusive services.    We apologize for any inconvience this may have caused you.    Jason Slagle  Network Administrator  Toledo Internet Access    Raistlin_Mejere - CSOP - Dalnet IRC Network      It seems that every time a client connects to a irc server, the server tries to telnet into the client's box!  This is about the dumbest thing that I have ever heard of!  I don't like having my intruder alarm go off at 2 am because my niece wanted to use irc.  I don't like  anyone trying to telnet in to my box for any reason!  No sir, I don't like it at all.    I suppose I will have to turn irc access off for my niece.    --  Rick,   The  Linux Gazette  Editor wrote:    Hi.  This will be printed in the August Linux Gazette at the end of  the month.  In the meantime...    I don't use IRC, SOCKS or WinGate, so I can't say whether they're being  reasonable or not.      This is something  new that the irc servers, all have started doing in the past few weeks.     Of course, you can always comment out telnetd in inetd, if you don't  otherwise need it.      I only allow telnet in from local machines (via hosts.allow).  I have everything else turned off in inetd per standard practice.  I have host.deny setup to log all incoming attempts and wavplay to sound an alarm.  (I haven't had any trouble since getting Road-Runner but I've been port scanned  a few times  with my previous IP.)  I just wrote a new log script that will skip the alarm if the in.telnetd attempt is from a ""know"" dalnet server.  (So I can get some sleep!) It still logs the suckers though!       I'm not sure whether [disablling telnet] would cause the IRC  servers to refuse service or not...      I doubt it, they are use to working with win 95.  How many 95 boxes are running incoming telnet service?  That's what they are trying to find out.     [Have other people had problems with IRC authentication recently?  What are the servers doing and why?  Why should they care whether  Win95 boxen are running telnetd or not? -Ed.                  Fri, 13 Aug 1999 04:42:18 +0500  From: Zahid Mannan Butt < zmbutt@hotmail.com>   Subject: Sis6326 Driver    I am new user on Lunix IS There any way to configure my SIS6326 8Mb AGP card for lunix?  Even I contect to the vendors but they can't Help me.  Please If you Know something about to configure it tell me other then sis.com.tm/driver/driver    Thanks  Zahid Mannan Butt                 Fri, 13 Aug 1999 14:19:13 +0530  From: regan < to_regan@hotmail.com>   Subject: Help Help     Hi!    I've installed RedHat 6.0 and have a SiS 6215 display card. During installation, I had to specify the card details as Red Hat was unable to detect it.    Now in Gnome, my display is larger than my monitor screen. I can only see the top 4 icons on the desktop. Also when I open any folder, the size is four times my screen size. Is there any way I can change my resolution or find support for this particular card. I've tried the SiS home site and redhat.com but there's nothing available there. If anyone has any info as to how I could solve this problem, contact me at to_regan@hotmail.com    Thanks  Regan < regan@irpl.com>  India              Fri, 13 Aug 1999 06:08:47 -0700  From: Bobby Prater < bprater4@bellsouth.net>   Subject: Problems with the speed my computer connects and scrolls while connected to my phone line.    Is it possible the phone line we had installed solely for internet use could slow my computer down? I have 400mhz and 128 meg ram, We decided since all other ideas failed we would try what a friend suggested and just bring my hard drive to their home and see if we had the same problem, Amazingly it performed as it should I was so happy thinking when I came home it would do for me as well as when on his phone line; IT DID NOT!!!! it's as poky as ever. I have tried connecting to ebay.com to view and bid on some items for over three hours and after we connect an error message pops up as I'm waiting for their reply, I have never had this problem. I'm ready to quit because it is impossible for me to find spare time in the bulk presently required to use the net. I am completely out of solutions to try so please if you have any ideas or suggestions email me    please! Any help will be greatly appreciated.  Thank You,  Mrs. B. Prater                Fri, 13 Aug 1999 16:16:38 +0000  From: R. Smith < rsmith13@tampabay.rr.com>   Subject: Re: Why are they trying to telnet in to my Linux box?    Linux Gazette wrote:                Sat, 14 Aug 1999 06:04:01 PDT  From: Zahid Mannan butt < zmbutt@hotmail.com>   Subject:     I read your message Kindly I thanks you to response me but I try to  configure the driver from www.suse.com (both) but I am fail Tell some other than www.suse.com this one I am really thanks you again Zahid Butt     ______________________________________________________ Get Your Private, Free Email at http://www.hotmail.com               Sun, 15 Aug 1999 18:16:03 PDT  From: Joe Bubba < gundog1@hotmail.com>   Subject: RedHat 6.0    To whom it may concern,        I am trying to download RedHat 6.0 from a mirror site but WSFTP.exe  errors out. It errors out in the \misc directory.  The files that cause the errors look like part binary or part folder icons (a file  that contains a directory structure).  I am using WSFTP32.exe on a Win95/NT  machine and my goal is to copy the files to a hard drive and burn them to a  CDROM later.    The only information I could find was to create a mirror, then copy the  files to a CDROM.    Any help would be greatly appreciated,    Rob  gundog1@hotmail.com               Mon, 16 Aug 1999 09:00:42 -0700  From: Douglas Nichols < dnichols@fhcrc.org>   Subject: Concerning the Toshiba 8000    I have installed Red hat 6.0 distribution of Linux on my Toshiba 8000. I have not been able to boot into any runlevel except 5, otherwise linux doesn't seem to respond to the keyboard- I believe this has something to do with the mouse. Everything else is working fine with apm I am using gnome. The pcmcia card was a problem, but I finely upgraded to 3.0.14 and everything seems to work well now. Periodically some process doesn't allow to umount the disk( I think it's gnome) and when I reboot, I have to fsck. If I can provide you with a ccopy of any of my config files just e-mail me.    --  Cheers, dn               Mon, 16 Aug 1999 20:08:34 -0400  From: Mulualem Takele < m.takele@worldnet.att.net>   Subject: MS WinModem Linux    Before a month I purchased a Dell Dimension XPS T450 Pentium (r) III PC with US Robotics 56K Voice Win (soft ware driven) Modem.  Unfortunately, I realized now that the modem I ordered is not supported by Redhat/Linux 6.  Now, I am wondering if there is anything I have to do so that I can run Netscape Navigator on Linux. If not, what possibilities do I have?     [Get another modem.  Until the winmodem manufacturers release Linux  drivers, or provide enough technical info so we can write our own  drivers, that's your only choice.       In any case, a winmodem is not a complete modem.  Several hardware  parts are missing, which are emulated by the Windows driver.  But why  waste CPU time and memory doing something the modem should be doing?  Look for a modem that says it will work with UNIX, DOS or Macintosh as  well as Windows.  If it can work with anything besides Windows, it  should be OK.  The US Robotics Sportster series is good, as are other  brands.  (PS.  US Robotics is owned by 3Com.  So if you see a 3Com  modem, it's the same as a US Robotics modem.) -Ed.                  Tue, 17 Aug 1999 01:55:51 EDT  From:  < HUEBRIGHT@aol.com>   Subject: 466 dell    When I try to mount my CD ROM and floppy through my system it says it is  unable.  I am running my CD ROM through a sound blaster 16  help    Jim               Tue, 17 Aug 1999 19:12:49 +0900  From: hansy < sysop@ultari.co.kr>   Subject: Can you tell me the way to adduser by cgi-script?    hi.  This is seyong from Korea.      I have so many users above 60,000, and now i have to make them the shell id.    can you tell me the way to adduser by cgi-script? i will be waiting and waiting for your reply.    if you can't, i'm so thank you.    my website is http://www.ultari.com (now under construction because of the +cgi-script). and now i'm using the redhat linux 6.0. thank you.   The  Linux Gazette  Editor wrote:    Hi, Seyong.  This will be published in the September Linux Gazette on  August 31.      Just to make sure I understand your question:  You want a form and a CGI script that runs the ""adduser"" command?      I do not know of any.  There are Linux products which allow central  administration of a network, and some of them have web interfaces, but  I do not know the names of the products.      You can of course write a CGI script yourself which runs adduser,  or hire a programmer to do this.  But allowing a CGI script to run as  root (which it would have to, to have permission to run adduser) is a  potential security nightmare.  Be sure the program analyses its input  very carefully before passing it on to ""adduser"".      hi, this is seyong han. i'm so thanks for your replying. i want to adduser by web interface. the program will run as root mode. i made an java application to run the cgi. it will run as root mode. so i want the cgi program it get id and password and then add user to +/etc/passwd.     [Is there any existing code to do this? -Ed.               Wed, 18 Aug 1999 18:10:55 +1000  From: Cooma School of Music < csm@cooma.snowy.net.au>   Subject: Downloading Redhat 6    Hi there. Sorry about the From, but I can't seem to change it. I really want to have Redhat linux, but it's been hell trying to find a document how how to download it. I assume these are in packages or images or something. Could you possibly publish a guide on how to download it, or could you tell me the location of a how-to.     -- SK                Thu, 19 Aug 1999 09:24:20 +0200  From: Carlo Vinante < vinante@igi.pd.cnr.it>   Subject: upgrade problem    Hi ti everybody.    I would ask some help on a problem recently occourred to me during an upgrade of my system. I ran SuSe 5.3 very smoothly until I decide to upgrade it to rev. 6, with kernel 2.2.1. then I have encountered two problems : 1) I'm not anymore able to print, except using the copy command to the printer. The aps filter is configured for my printer (a HP Dj 550c); the lpr command doesn't ""exist"".  2) no sound .....    Does anybody know a good ""rule of thumb"" to avoid these kind of problems when performing an upgrade ?    Thanks to everybody    Greetings Carlo               Sat, 21 Aug 1999 02:07:53 -0500  From: Lawrence A. Bombac II < Lawrence_A_Bombac_II@lor.net>   Subject: hey     would you be able to direct me to a place that will give me the source code for linux,or could you send it to me yourself,preferably a version that is not copyrighted,if that makes any sense      [Do you mean the Linux kernel or an entire distribution?     The source code to the Linux kernel is available at FTP sites all  over the world.  A list of major sites is at   www.kernel.org/mirrors .    See also the  www.kernel.org home page .  This is the core of the Linux system, or what differentiates Linux from  all other operating systems.  I cannot email it because it is 14 MB  big.     However, you need more than just the kernel to have a useful  computer system.  You also need hundreds of third-party programs and  utilities.  The easiest way to get a hold of the source code to all  these programs at once is to buy or download a Linux distribution.  Be  sure the product says it ""includes source"".  Before downloading an  entire distribution of several hundred megabytes, remember that it's  often cheaper and more convenient to simply buy a CD instead.     The Linux kernel and the vast majority of programs included in any  Linux distribution are copyright according to the GNU Public License  (GPL)    www.gnu.org/copyleft/gpl.html  or to a similar license  which allows the copying and distribution of both the source code and  compiled programs without asking anybody's permission or paying  royalties.  In fact, the GPL in particular *requires* that any company  that sells a GPL'd program (and the Linux kernel is GPL'd) *must* make  the source code available. -Ed.                   Sun, 22 Aug 1999 03:28:18 +0200  From: Philippe COVAL < philc@writeme.com>   Subject: Question: HD brute format    Question: HD brute format    How to format a disfunctional HD ? (hum, i know the ""buy a new one"" solution)    how to low level format it ? partitioning can't be aplied using fdisk ?    whazup?                Sun, 22 Aug 1999 21:33:30 -0400  From: Robert Rocconella < roko@worldnet.att.net>   Subject: module not found    I have installed Mandrake 6.0 on a P166 system. It runs fine except for. I have a 4mm DAT Archive PYTHON drive, booting off a SCSI 1Gig drive. On bootup when the system looks at my Buslogic controller and identifies devices, it shows the tape drive as st0. The unit was in the system when I installed it. BUT during the bootup it will report module not found when it gets to the part where I assume it is trying to initialize the driver used to access the st0 device. I have been looking thru various sources of documentation but cannot find a reference to the module not found problem or where to install it from. Thanx in advance.                Mon, 23 Aug 1999 11:38:21 -0000  From: JUIN Aymeric < Aymeric.JUIN@DGI2000.com>   Subject: RE: linux on a laptop  I'm a linux newbie. I installed linux (redhat 5.2) on a laptop with an ATI rage LT PRO AGP2X, and there's no driver for this graphic card to run Xwindow, I tried to find one on the web, but without success, I also tried other ATI drivers (like ATI rage pro and other MACH64 drivers) without better results.  Is there any solution ? Please help me...     PS : sorry for my poor english.    The  Linux Gazette  Editor replied:      Can you use the standard SVGA driver?     Aymeric responded:     No, it works so bad. it seems to interlace about 5 vertical stripes on the screen.  I think several linux-users have this problem, because ATI rage LT pro is a widely used graphic card on notebook.               Mon, 23 Aug 1999 22:57:18 -0400  From: wible < wible@uplink.net>   Subject: installing linux on laptop.    i'm trying to fegure out haw to install linux on my laptop.but i can only have a floppy or a cd-rom.they use the same slot.so how do you istall a cd without a boot floppy?  I'm comleattly new to this OS.please advise.               Tue, 24 Aug 1999 22:52:01 +0200  From: Hans Borg < Hans.Borg@Physics.umu.se>   Subject: Color depth 8/16 and Xlib    Hi everybody,    I am not sure this is the right forum, but if anyone can give me some hints to solve the problem or give an alternative FAQ-site it would be utmost appreciated.    I have written a number of Xwindow applications for special purposes. They do all run without any problems if the Xserver is configured for a color depth of 8. Actually those applications do not need many color- map entries (less than 10). However, for other applications like xv and netscape a color depth of 16 is preferred. There are no problem to run eg. xv and netscape with a depth of 16 (I guess they set up their own colormap). But if in depth 16 then my own applications can't set up its color entries. The idea is to be able to run simultaneously both my own applications and applications like xv,netscape with a reasonable color resolution.    To set up my colors I basically do:    screen=3DDefaultScreen(display);     colormap=3DDefaultColormap(display,screen);   XLookupColor(diplay,colormap,""color"",exact_color,screen_color);     or alternatively    XAllocNamedColor(.....);      When in depth 16 both XLookupColor and XAllocNamedColor both raises the Xerror: BadValue (parameter out of range) ... something like this. I don't know which parameter causing it and apart from display it must be colormap or ""color"". It is hardly ""color"" and if so it must be the colormap. I have checked the ""visual"" on colormap and it seems OK. I have also tried XCreateColormap(...) and other ""give it a chance"" methods but I am stuck.    So, please, anyone having an idea, let me know.    With my best regards.    Hans.                 Tue, 24 Aug 1999 18:57:47 -0500  From: Amy Bellows < enigma99@earthlink.net>   Subject: ls color    Hi, I have a small yet annoying problem. I'm running RedHat Linux 5.2, and I'm still fairly new to the whole OS.    I can't get ls to display defined extensions in my chosen colors, although it does color directories, executables, etc..  I have tried changing definitions in /etc/DIR_COLORS, and get nothing. Is there something I'm missing?              Fri, 2 Jul 1999 00:18:00 -0400  From: Coleman, James (GEP) < james.coleman@gepex.ge.com>   Subject: color ls headache    OK. I've used Linux for just over a year but have a problem with one of three Linux PCs in our household. On one, a 486DX 50, I get color ls on every user ID except one. I've configured /etc/bashrc as usual  (alias ls = ""ls --color"") and as I've done on each of the other Linux boxes. An ls command produced a colored display with every user except one! I've tried adding an ls alias to that user's own .bashrc file but nothing helps. If I type ""ls --color"" as that user, I get color! Without it, black and white. What might be going on and what should I look for?     The problem PC is running RedHat 5.2 with all the errata upgrades. Stock kernel, though... The other PCs are all running version 6 (stock kernels).    Thanks!!!              Wed, 25 Aug 1999 20:21:07 +0100  From: helen < helen@dougal1.freeserve.co.uk>   Subject: Suse Linux 6.1     Hi All, I am a new user (possibly) who is having problems setting up xf86config. I have an old IBM PS1/50 which has an xga-2 video card in it, (2 megs mem on card). After trying a lot of the video card database entries, it still refuses to work. All other parameters in xf86config are correct. Has anyone any idea which driver is compatible for the ibm xga-2 video card?    The problem starts when I type STARTX. In most cases I get a screen which is nor resolvable, or, I get the following message:  The file XF86_xxxx (binary of X-Server) does'nt appear to be a binary file. Please check it or / and install a new X-Server binary.      Regards to All.  Geoff < Geoff_G0GLW@yahoo.com > Geoff_G0GLW@yahoo.com                Mon, 30 Aug 1999 20:58:36 -0300  From: Carlos Massolo < litos@ciudad.com.ar>   Subject: Problems with Diamond SpeedStar A50    I am new to linux and learning fast. I just got one problem when I use startx or kde my screen just shows Black and gray stripes. I have a Diamond SpeedStar A50 AGP card and a Samsung SyncMaster 3Monitor. I tried the Options nolinear, noaccel and swcursor and none worked. Any help would be great.    Litos                 Wed, 25 Aug 1999 12:48:22 -0400  From: wible < wible@uplink.net>   Subject: Re: installing linux on laptop.    i'm trying to fegure out haw to install linux on my laptop.but i can only have a floppy  or  a cd-rom.they use the same slot.so how do you istall a cd wethout a boot floppy?i'm comleattly new to this o/s.please advise.   The Editor wrote to Wible, and Wible responded, adding:       it sez cdrom includes caldera open linux 1.3 and staroffice 4.0... and no my laptop doe's not boot to cd. is there a way to start the install from dos using a command line or somthing? and can you install over a network card in pcmica by booting to the floppy?     [You can install it over the network if you have another computer that  can act as an FTP server.  Or as a NFS server, if your installation  program supports installing via NFS.     As far as having a DOS/Windows command that installs Linux  (LINUX.EXE?), people have talked about this theoretically, but I don't  think it's ever been tried. -Ed.                Thu, 26 Aug 1999 10:41:58 -0400  From: Mark Jenkins < jenkinsm@mint.net>   Subject: USR 33.6 Modem Help    I am running redhat 6.0, I have tried to my modem going in minicom (say  already online) I have tied in the KDE PPP dialer (get modem busy error) I  have tried setting and the jumpers for coms 2,3,4 with coresponding IRQs.   Each time I do set the modem com port in the control panel.  Any help  would be great, I assume it may be a string command, I just can't seem to  find anything on it.    Thanks Mark               Thu, 26 Aug 1999 17:58:38 IST  From: Bala Krishna H.V. < balak@pushpak.india.hp.com>   Subject: Telnet would not work     I installed Linux on my PC successfully.But when I try telnet or ftp to log on to the PC I get the error ""login incorrect"". I tried changeing the password and even removing it.But no use. Finally I changed the default shell to sh.Still I can't log on. Could you help?    --   With Regards,   Bala Krishna                  Thu, 01 Jul 1999 07:40:36 +0200  From: Christopher Richardson < rdn@tara.n.uunet.de>   Subject: Help Wanted - How to best install glibc onto an existing system    I have the SuSe 5.1 distribution on my machine which works fine - as I do not want to fix a running system I need some advice on how to best install the glibc package on my machine. Newer software is linked usually written to be linked to this package. My computer is busy compiling the glibc package, but I am going to wait until I hear from someone before I install.    Thanks Chris Richardson                  Fri, Jul 02, 1999 at 12:15:06AM -0400  From: robert Nuzum < rnuzum@earthlink.net>   Subject: Unzipping commands    I would like some info on good sources about how to run commands, especially when unziping files.  I'm trying to get some sound on Netscape but can't seem to get the downloaded x-audio file to be recognized in order to unzip it.  I'll probably stumble upon the solution after playing around with it, but shortcuts would be appreciated.    I have SuSE Linux 6.1 installed.   Bob     [There is an  unzip  command which will unzip *.zip files.  If Netscape won't unzip it on the fly, you may have to save it to  a file and unzip it yourself.     There are several books now which give an overview of Linux  commands.  Try your local bookstore. -Ed.]                Wed, 4 Aug 1999 23:46:00 -0700  From: Mark Wagnon < mwagnon1@home.com>   Subject: Article Idea: Setting up Procmail    Hi,    I found the article ""Setting Up Mail for a Home Network Using Exim"" (July 99) extremely helpful on setting up mail services for my home network. How about a follow up on using procmail to filter mail into separate folders?               Sun, 29 Aug 1999 22:09:56 -0400  From: Steve Allen < steveallen@earthlink.net>   Subject: Publishing Dynamic IP address on startup     I have my Linux machine hooked to an X-10 teleresponder so I can dial-up and turn the Linux box remotely, and I have it set to dial my ISP as soon as it boots.  I want to publish the dynamic IP address given by my ISP to my home page as soon as I connect.  I've been successful getting the dynamic IP address by referring to the variable $4 in the script ""/etc/ppp/ip-up"" that's called by pppd.  The problem is FTP'ing it to my homepage.  When I try FTP'ing with a script containing the following line from the command line as root, it works fine (I have my logon/passwd and init macro defined in .netrc in my Linux home directory for root).    ftp ftp.homepagesite.com    However, when I insert the above line in my ""/etc/ppp/ip-up"" script, nothing seems to happen as my homepage is not updated with the new IP address.  Any suggestions on how to easily publish my dynamic IP address as soon as I log on?  Thanks.                From: peter < peter@anet.lv>   Subject: IDE Zip drive    Hello! I have some problem! How I can Install ZIP-Drive ATAPI verssion?               Tue, 10 Aug 1999 22:25:57 EDT  From:Symeon Vafiadi < >   Subject: AOL and minicom    How do I dial from Linux using minicom having an AOL account?  Everytime I dial in it asks me for my login and when I put in my login name it says incorrect login.                   General Mail                 Fri, 27 Aug 1999 20:04:32 +0200  From: Bjorn Eriksson < mdeans@algonet.se>   Subject: SV: Ooops, your page(s) formats less-optimum  when viewed in Opera (http://www.operasoftware.com/)      [Bjorn wrote in to say that recent issues of the  Gazette    (starting with #39, April 1999) do not format properly under Opera.  Is anybody else experiencing this?  Any clues about how to make Opera  happy?  Here are sample screenshots of the middle of the screen:       Opera       Internet Explorer            Opera is a commercial web browser for Windows.  A 30-day evaluation   version is available at    www.operasoftware.com .  The Linux port is 25% complete; ports to  other platforms are also in progress. -Ed.]                 Sun, 08 Aug 1999 17:43:37 +0530  From: Prakash Advani < prakash@freeos.com>   Subject: FreeOS.com    Hello,    I am posting this message to thank Linux Gazette for publishing my article last December and all the readers who have responded positively and helped in developing our website   www.freeos.com     The site is finally up and running and is being updated regularly.  Any more people willing to help can e-mail me.    Regards,  Prakash               Fri, 13 Aug 1999 02:14:21 +0200 (CEST)  From:  Roland Smith < rsmith@xs4all.nl>   Subject: Re: Ramdisk for Linux    Hi Mark,    I've got a quaestion about your ramdisk article.    AFAIK Linux uses all the memory that is not in use by programs as a unified buffer-cache. So I'd guess that all frequently used files will probably be cached in RAM, assuming you've got enough RAM.    So why go to all the trouble of using ramdisks? Is there really an substantial speed increase?   Regards,  Roland              Thu, 19 Aug 1999 00:49:03 -0400 (EDT)  From: Nicholas Bodley < nbodley@shell2.tiac.net>   Subject: Original definition of bench mark     It's quite possible that this is a surveying term, for accurately-located reference markers embedded into the ground; these are used as working references when doing a survey. I'm just about sure you'll see bronze domes (almost flat), maybe 4"" in diameter, surrounded by concrete, with their exact latitude and longitude (and altitude?) marked on them.  Tampering with them is a criminal offense, I believe.     Sorry not to offer much help in how the term came to mean what it does to the computer community; perhaps the idea of comparing to a reference explains it.     Any surveyors ""out there""?     Regards to all.              Sat, 28 Aug 1999 19:01:31 -0500  From: DENNIS L PHIFER < den1317@intellisys.net>   Subject: inconsiderate    My opinion you have to much stuff on the net . U got in the way of my search. Out of 391 u had at least 350 . Hope your paper goes under with highest malice.               Sun, 29 Aug 1999 11:40:20 -0400  From: Mark Moran < mmoran@mmoran.com>   Subject: DNS for home network    I just wanted to drop a quick note of thanks for the article: ""DNS for the Home Network"" in the August 1999 (Issue 44) issue of the Linux Gazette.  I had tried on several occasions to setup bind on my home Linux server only to become frustrated and give up after hours of work.  Well thanks to your succinct and accurate article my home DNS server is working great now for a few hours!    Mark Moran              This page written and maintained by the Editor of  Linux Gazette ,  gazette@ssc.com   Copyright © 1999, Specialized Systems Consultants, Inc.    Published in Issue 45 of  Linux Gazette , September 1999       ""Linux Gazette... making Linux just a little more fun! ""              Contents:     News in General   Software Announcements                News in General                   October 1999  Linux Journal         The October issue of  Linux Journal  will be hitting the newsstands in mid-September. This issue focuses on embedded systems.     Linux Journal  now has articles that appear ""Strictly On-Line"". Check out the Table of Contents at   http://www.linuxjournal.com/issue66/index.html  for articles in this issue as well as links to the on-line articles.  To subscribe to  Linux Journal , go to   http://www.linuxjournal.com/subscribe/ljsubsorder.html .       For Subcribers Only :  Linux Journal  archives are now available  on-line at  http://interactive.linuxjournal.com/                  TuxFinder.com Launched          TuxFinder.com  is a  Linux-dedicated group of search engines designed to help you find anything you need as a Linux user. Whatever you are looking  for: packages, RFCs, FAQs, or HOWTOs, TuxFinder.com can help you.  TuxFinder.com is also a mirror for the Linux Documentation Project. With  both English- and French-language capability, it is growing in popularity on  both sides of the Atlantic due to its simplicity, power and efficiency.      Co-founder Olivier Macchioni said about TuxFinder.com: ""As a Linux user,I wanted something like this, and wondered how easy it was to program. Well, it's easy and fun - and hopefully useful for some other Linux users too.""                   Debian chooses new logo       The  Debian  project has chosen ""The Swirl"" as its new distribution logo.   Actually, a pair of logos was chosen.  This is the ""open use"" logo, which anybody can use to refer to Debian with.  The ""official"" logo is only for Debian-endorsed products.  It shows the swirl rising up like smoke out of a genie's bottle.  See    www.debian.org/logos/  for more samples of both logos.                   Corel preview Corel LINUX         San Jose, California August 10, 1999 -- Today at LinuxWorld in San Jose,  Corel Corporation (NASDAQ: CORL, TSE: COR) unveils its distribution of the  Linux operating system, Corel LINUX, to the public for the first time.    Corel LINUX is based on the Debian/GNU distribution of the Linux OS and  includes the K Desktop Environment (KDE). In its distribution, Corel has  enhanced the graphical user interface and created a new installation  program that greatly simplifies the installation process. A beta version of  Corel LINUX will be available in September 1999, and the first release is  planned for the end of the year.    Corel LINUX will be available as a stand-alone product and will also be  bundled with the upcoming WordPerfect Office for LINUX suite, which is  expected to be available in early 2000. The prices for both the stand-alone  version and the suite will be announced at a later date.                MandrakeSoft announces North American Support          Dallas, TX August 17th, 1999.  MandrakeSoft SA, publisher of the popular Linux-Mandrake, announced today the selection of Bynari Systems Group to provide Mandrake's customers in North America with complete support services.                  Upcoming events              Atlanta Linux Showcase    October 12-16, 1999  Atlanta, GA   http://www.linuxshowcase.org         COMDEX Fall / Linux Business Expo    November 15-19, 1999  Las Vegas, NV   http://www.comdex.com/comdex/owa/event_home?v_event_id=289      http://www.zdevents.com/linuxbizexpo/            A more complete list of events is at   www.linuxjournal.com/events/index.html                Operating System Supertest         The massive Operating System Supertest, held by   reviews 'r' us  has begun work today, and Linux still looks set to be the star of the show. Still, the Supertest as a whole should a good read, and with a bit of luck draw more people away from the windows domination. This supertest has over 30 Articles and interviews, and countless reviews of free, and commercial software. With over 40 volunteers offering their services, the date of publication has been reduced to the end of August.    We still need help with this supertest though, and if you feel you could help at all, in any way, please email Sandy Smith ( sandy@reviews-r-us.com )and offer your services. We need this to be the biggest, best ever definition of Operating Systems, and a comparison of many types, and articles that everyone from beginner to expert will find interesting.    Current roles needing filled: PR person, Artwork, reviewing of software.    Do you need more info? Background info? please please tell me if you do                  O'Reilly releases Perl CD Bookshelf         Sebastopol, CA--Arguably the best Perl books in print--""Programming Perl"", ""Learning Perl"", ""Perl in a Nutshell"", ""Perl Cookbook"", ""Learning Perl on Win32 Systems"", and ""Advanced Perl Programming""--are now available on a single CD ROM in the immensely convenient ""Perl CD Bookshelf"" by O'Reilly & Associates.    Together these 6 books would retail for $199.70, but the ""Perl CD Bookshelf"", which includes all 6 on a searchable CD-ROM as well as a hard copy of ""Perl in a Nutshell"", sells for only $59.95.    For more information about the book see: http://www.oreilly.com/catalog/perlcdbs/                Tru64 UNIX and LINUX Update          Tru64 UNIX & LINUX JumpStart  Las Vegas, NV  September 8-10  Orlando, FL  November 1-5    Due to popular demand, ISA has extended it's UNIX JumpStart to include LINUX, the fastest growing Operating System in the World.    The Digital UNIX JumpStarts have been a huge success. Students have raved about this unique training venue which has enabled them to get a quick and comprehensive immersion into UNIX technology in a time efficient manner.  Check out our website for the new LINUX Track and the new and updated Tru64 UNIX courses.       www.softadv.com/UNIX/Digital_UNIX_JumpStart/Tru64_UNIX_&_LINUX_Home_Page.htm                        Ziatech introduces LinuxPCI Development System          Ziatech Corporation ,  the leading innovator of applied computing solutions for telecom and Internet applications, introduced today the first in a series of LinuxPCI development systems, a rack mount CompactPCI=AE development platform using the Linux(tm) operating system. Designed to speed the development of carrier-grade computing applications, the new LinuxPCI 1000 Development System for Applied Computing combines the reliable, open CompactPCI architecture with MontaVista Software's Hard Hat(tm) Linux software.  Open CompactPCI platform for OEM fast-track development Original equipment manufacturers on the fast-track to develop Linux-based applications for DSL systems, PBX systems, IP telephony, voice processing, and other telecom and Internet equipment, now have an open architecture platform designed with the bandwidth, reliability and features those applications require.  The LinuxPCI 1000 comes with the first version of Linux designed specifically for embedded applications. The Hard Hat Linux operating system from MontaVista Software, Inc. (Sunnyvale, CA,  www.mvista.com ) combines the cost-effectiveness, openness and flexibility of Linux with the reliability and responsiveness required for embedded and applied computing applications. MontaVista will supplement the operating system's enhancements with comprehensive technical support, porting and customization services.                 Clustering for TurboLinux         TurboLinux is releasing the industry's first high-availability clustering software solution for the enterprise-TurboCluster Server.  TurboCluster Server is the industry's FIRST Linux clustering application available and scalable for Web servers on Intel and Alpha architecture platforms.   Unlike Beowulf clustering systems that are designed for highly specialized scientific computing applications, TurboCluster Server delivers clustering technology for Linux servers running mission-critical Web applications.   For Net businesses, the availability of TurboCluster Server offers, for the first time, a low-cost alternative to proprietary and more expensive Microsoft NT and UNIX cluster solutions.  Additional information on TurboCluster Server, including a white paper and FAQ, is available at   www.community.turbolinux.com .                 Linux Webdrive available          SAN DIEGO, Aug. 8--StoragePoint.Com announced that it now offers a Linux version of WebDrive, providing secure file management features never before available to Linux users.    Linux WebDrive from StoragePoint becomes the only Web-based file manager offering automatic folder management, encryption, compression, with integrated e-mail, calendar, and contact manager.  The free service is compatible with Netscape 4.5+ and Linux version 2.2.    For more information see   storagepoint.com .                  GBdirect Delivers UK's Largest Ever Linux  Training Programme?         Release Date: 11th August, 1999.    GBdirect and Planet Online, both leading players in the European market for Linux skills and services, today announced what is believed to be the UK's biggest ever Linux training programme. Over the next six weeks, 60 delegates from Planet Online will attend GBdirect's basic, intermediate and advanced courses in Linux Systems Administration.  The students will be engineers and technical staff from Planet's Leeds headquarters, the home of Freeserve, and already the greatest concentration of Linux expertise in Europe.    The GBdirect's company web site is at  www.gbdirect.co.uk  and their Linux  training site is at   www.linuxtraining.co.uk . The Planet Online web site can be visited at  www.theplanet.net .                Linux Press book: The Best of Linux Distributions          PENNGROVE, CA (August 16, 1999)   Linux Press  today announced the second title in its new Linux Resource Series. Designed to provide comprehensive documentation for the latest Linux distributions and concepts, the Linux Resource Series enables users of all levels to access Linux information.    The Best of Linux Distributions is based on Matt Welshs cult classic Linux Installation & Getting Started. Revised, expanded, and updated, The Best of Linux Distributions includes a general introduction to Linux; detailed explanations of drive partitioning, filesystems, and software package installation; distribution-specific instructions for installing Debian GNU/Linux, Slackware, Caldera OpenLinux, and Red Hat Linux; a complete, low-stress Linux tutorial; system administration under Linux; X Window; and Networking.    Also included are 4 CD-ROMs containing the latest Linux operating system for Red Hat Linux, Caldera OpenLinux, Debian GNU/Linux, and Slackware.                Linux System Solution Limited (LSSL) and INFOMATEC - IGEL Asia LTDP cooperate         Linux System Solution Limited (LSSL) and INFOMATEC - IGEL Asia LTD have today formally announced their co-operation in the Internet device, Thin Client and Networking arena.    IGEL Asia LTD will endeavour to promote, market and educate customers towards a complete Linux based Thin Client / Server solution based on TurboLinux's product ranges complementing IGEL's Firmware. LSSL will help promote, support, develop application solutions and, provide maintenance and support services in the use of Thin Clients for corporate, commercial and educational use.    LSSL and IGEL will co-operate in the localisation and development of Chinese applications and solutions via their respective engineering and research departments.   Linux System Solution Limited is a strategic partner of TurboLinux who are deemed as the major Linux player in the Asian Market. The Japanese version of TurboLinux has been outselling Microsoft Windows and this trend looks set to continue throughout the Asian Region.                TurboLinux partnership with Enlighten Software           SAN FRANCISCO, Calif. (August 9, 1999) - TurboLinux and Enlighten Software Solutions, Inc. (Nasdaq: SFTW), announced today a strategic partnership to bundle the first enterprise-ready workgroup systems management software for Linux with the full line of TurboLinux products.    TurboLinux will be bundling a full multi-platform working version of EnlightenDSM administration and event management software on its entire product line for immediate, single-point management of all TurboLinux machines.  In addition, the bundled product is immediately ready for customers to monitor and manage their existing heterogeneous Linux, UNIX and Windows environments from the same single console.                32BitsOnline.com to Develop UnixApps.com         Vancouver, BC - August 19, 1999 - Medullas Publishing Company, parent company of 32BitsOnline Magazine, and Linux Applications announced its new upcoming site, Unix Applications  ( www.UnixApps.com ), today.    The new software download portal will merge Linux Applications and include applications from all Unices including FreeBSD and Herd operating systems. Moreover, Unix Applications will also feature applications from BeOS and other operating systems.    Unix Applications will feature a brand new interface and will be rolled out along with  0x20.com  and   linuxtalks.com  this Fall.                Network giants install Linux-based test bed         Chicago, IL (August 23, 1999) -Linux continues to receive solid backing from major players, with Cabletron Systems, Xylan and FORE Systems installing network test equipment based on the popular open-source software. Designed by benchmarking specialist Neal Nelson & Associates, the Network Stress Test is the first large-scale tool to use real clients and servers to send actual network traffic at very high bit rates.  The speed and bandwidth capacity of the Linux platform, coupled with Nelson's unique testing methodology, enables manufacturers and potential buyers alike to evaluate new products using the most extreme, real-world network traffic patterns.    Unlocking the power of Linux ""Linux is an excellent operating system for large clusters of computers,"" comments John Hynds, Director of Systems Engineering for Xylan.  ""It has very efficient LAN drivers, can generate high volumes of network traffic and comes with a full set of client and server application software.  Also, there are no additional licensing charges when it is installed on a cluster with any number of individual machines.  It is a very powerful and cost-effective option.""    Real network traffic provides superior testing While other testing methods generate artificial packets of data from simulated applications, Nelson's breakthrough in network testing enables technicians to quickly and easily configure thousands of real clients talking to thousands of real servers in a laboratory environment.  Billions of bits per second of real network traffic are generated by the technique, and the network throughput can be immediately analyzed to uncover problem areas.    ""This type of testing makes a lot of sense,"" says Kevin Brown, Senior Marketing Director for Cabletron.  ""Using high volumes of real network traffic is completely different from, and in some ways superior to, testing with artificial traffic generators.  Neal Nelson's method assures us that we have put our products through the most realistic stress test possible.""    Automated test execution: the Network Stress Test is a fully automated benchmark that can conduct long and complicated tests with just a few clicks of the mouse.  Vendors can now conduct quality testing more efficiently, ensuring that their products are of the highest reliability before they are released in the market.  This automation significantly improves on the industry standard 30-minute tests, which needed to be re-set manually.    The Network Stress Test runs on a cluster of Linux-based computers with multiple local area network adapters in each machine. The infrastructure can support 10,000 simultaneous user sessions and perform a variety of common network activities like web browsing, Telnet/Rlogin sessions, FTP file transfers, email, streaming video and multicast communications.    Neal Nelson, founder of Neal Nelson & Associates, originally developed the testing infrastructure for use at the US Army Technology Integration Center in Fort Huachuca, Arizona.  He comments:  ""Modern networks are being challenged to handle increasingly complex loads that include huge volumes of World Wide Web traffic, audio streams, video streams and multicast data.  These rapid innovations in network technology required that we develop similar advances in network testing techniques.  The result is our Network Stress Test - one tough test that can assure vendors and buyers that their products won't let them down in high-traffic, real-world conditions.""    About Cabletron: Cabletron Systems is a pioneer in high-performance computer networking and provides dependable network access and communications to millions of people worldwide. With scaleable products designed for Fortune 1000 enterprise networks, service providers and small businesses, Cabletron provides simple, reliable and cost-effective business solutions for the information age.    About FORE Systems: FORE Systems is a leading global supplier of high performance networking solutions. FORE's Networks of SteelT deliver the increased capacity, resiliency and scalability necessary to build networks that last. Thousands of enterprise and service provider customers worldwide have put FORE Systems' solutions at the heart of their networks.    About Xylan:  Xylan is an Alcatel company focused on developing powerful internetworking products for enterprises and service providers. For enterprise customers, Xylan's networks are so powerful that they can bypass an entire generation of network change. They combine ease of management, high performance, and easy integration with existing equipment and software. For service providers, Xylan builds equipment for high-speed multi-service VPNs. Xylan's solutions integrate broad connectivity options, advanced software for partitioning and security, and any-to-any switching. Xylan helps service providers build profitable networks.    About Neal Nelson & Associates: Neal Nelson & Associates is an independent testing and consulting company founded in 1973.  It is not affiliated with any manufacturer or vendor and offers a number of products and services including the Business Benchmark, the industry's premier multi-tasking artificial batch benchmark.  The firm has its primary office and a testing laboratory in Chicago. Neal Nelson & Associates' client list includes companies such as: FedEx, IBM, McDonald's, Northern Telecom, Sprint and major government agencies including the Internal Revenue Service, US Department of the Air Force, US Department of the Navy and US Department of the Army.                 Aspen Systems ships 64-bit Alpha Linux         Wheat Ridge, Colorado, August 23, 1999 -   Aspen Systems, Inc. , a leading high-performance computer designer and integrator, has commenced shipping its Twin Peaks II line of 667MHz, 64-bit dual-Alpha 21264 processor workstation, server, and cluster solutions.      Twin Peaks II is a ruggedized line of custom solutions that incorporates the world's fastest microprocessor technology with high-performance hardware and the latest Linux and Tru64 UNIX versions to create performance-optimized solutions for key markets such as scientific, multimedia, ISP, and other critical applications.  At SPECfp95 53.7, Twin Peaks II offers not only the fastest Linux and UNIX processing, but also a price/performance ratio that is up to eight times better than its nearest competitor.                News from LinuxMall         Here at LinuxMall.com we've finally unleashed our new  web site ,  and we're very pleased with the results. We've added tons of new features, and improved old ones.      Legislative Lunacy     Some very scary pieces of legislation are floating around these days. The National Conference of Commissioners on Uniform State Laws (NCCUSL) has voted in favor of The Uniform Computer Information Transactions Act (UCITA).  The UCITA would deregulate software licensing - something that would allow software publishers more power and guarantee the end user even fewer rights.      [For more information about this, see      Shrink-Wrapped UCITA  on the  Linux Journal  web site. -Ed]      Linux and Education     Two Open Source projects focusing on education have been initiated recently. SEUL-EDU is part of the Simple End User Linux project and provides a mailing list and central Homepage for all aspects of educational uses of Linux, by teachers, parents, and students. You can find out more about SEUL-EDU at:   www.seul.org/edu/     The OpenClassroom Initiative has announced a distribution and server tools designed to be of use in an educational environment. All of the materials are available free of charge and are under the GNU Public License. You can check out the OpenClassroom Inititiative at:    www.openclassroom.org/developers     --------------------------------------------------------------------------------   Cracking Windows2000 beta      Eric S. Raymond comments   on Microsoft's latest publicity stunt: putting a Windows2000 beta machine on the Net and daring anyone to crack it. Someone did, apparently, but it wasn't up long anyway - it promptly crashed under the load.  Eric explains why he doesn't think that Windows is a platform that's capable of being secure or stable.      More Linux Newsletter articles .  Distributed via GPL.                     Seagate is Linux-compatible          COSTA MESA, Calif.,  June 28, 1999 --   Seagate Technology, Inc.  (NYSE: SEG) today announced that its entire line of tape backup drives has  been certified with Linux, which is quickly gaining momentum as a powerful network operating system for servers.  After thorough testing, Seagate received certification on its Hornet Travan, Scorpion DAT and Sidewinder AIT tape drives through the Linux tape certification program, managed by Enhanced Software Technologies, Inc., (EST).               PC-Tel software modem         San Jose, CA - August 2, 1999 -  PC-TEL  announced the  availability of the industry's first Linux-compatible software modem.  This newest version of PC-TEL's popular host signal processing (HSP) technology will facilitate the availability of low-cost, Internet-enabled devices featuring the Linux open-source operating system.    HSP modems offer leading hardware OEMs a faster time to market, higher system reliability and a lower cost of manufacturing.  Perhaps more importantly, these solutions are much more flexible than traditional hardware modem technology, enabling easy modem upgradeability and international customizability through simple software changes.  The Caldera OpenLinux 2.2 version and Red Hat Linux 6.0 of PC-TEL's Linux-PCI based MicroModem are available immediately to OEMs developing systems requiring Internet access.                Linux Links         Linus announced his intention for a   kernel code freeze  to pave the way for Linux 2.4.  (Most of the discussion in this thread is about the state of the ISDN drivers.)    ""Linus the Libertator""  -- a San Jose Mercury-News interview with Linus that discusses his background, family and life.    DVD drives and Linux : the current state of the art.  DVD is also mentioned in an  article by Bill Bennet  in this month's   Gazette .      Linux Not Mission Critical Ready?  IBM says 'think' again .  ZDnet article. Thanks to LinuxMall for bringing this to our attention.     Scary airport photo .              Software Announcements               Sun acquires StarOffice, makes it available for download         Sun Microsystems has acquired Star Division, the German company who made the StarOffice office suite.  For a free download or a $9.95 CD (plus shipping), point your browser to  sun.com .    Sun plans to make the application suite more web-centric, so that you can use it via a web browser.    The source code will be available through Sun's Community Licensing program to encourage industry-wide collaboration on future versions of the software.              C.O.L.A software news          OpenDIS  -- Open Digita Services 0.0.2.  A library and utility program for cameras such as the Kodak DC-220 and DC-260 that run Flashpoint's Digita Operating system. The utility (""ks"") is a simple command-line program for standalone downloading, taking, deleting of photos and querying and moding the camera.     r2d2  uses a configuration file rather than the symlinus of System V Init.          FTP site       ftp.guug.de/pub/members/truemper/r2d2/      Mailing list       www.guug.de/lists/      Rationale       www.guug.de/lists/r2d2/msg00012.html        Weekly Linux Newsletter.  No spam, no advertising, just heaps of Linux tips, tricks and news from the world of Linux.  subscribe@thebits.co.uk .     Hinv  produces a concise hardware inventory of your system.  GPL.     KStock  -- a KDE stock ticker.                  H-P Openmail to support Linux             PALO ALTO, Calif., Aug. 2, 1999 -- Hewlett-Packard Company today    announced that OpenMail 6.0, HP's strategic business-messaging and    collaboration solution for UNIX(R) system computers, also will support    the Linux operating system.  By supporting Linux, OpenMail 6.0 will    provide its upgraded functionality and e-services(1) capabilities to    the growing number of Linux-based businesses, offering a low-cost    alternative to other enterprise-messaging solutions.          HP expects OpenMail for Linux to be available in September.  A free    beta version is available now on the Internet at     http://www.hp.com/go/openmail .          ""HP believes that many Linux-based businesses need the type of proven    enterprise capabilities that today's OpenMail customers enjoy,"" said    Nigel Upton, general manager of HP's OpenMail business.  ""OpenMail    gives the Linux community a compelling alternative to 'generic'    Internet e-mail servers.""          In addition to robust Internet e-mail-standards support,   the Linux edition of OpenMail will include rich support for Microsoft(R) Outlook (including full wide-area calendar/schedule access)      and OpenMail 6.0's new Web client.              More OpenMail information is available at on the web at  http://www.hp.com/go/openmail .                    Voice over IP from Vovida Networks         First Free Open Source (GNU LGPL) MGCP and RTP Stacks Running On Linux Operating System Available from Vovida Networks     MGCP is a protocol used for controlling Voice over IP (VoIP) Gateways from external call control elements. MGCP is the emerging protocol that is receiving wide interest from both the voice and data industries. RTP is a protocol used to carry streaming real-time multi-media data over IP Networks.     For further information about Vovida Networks, support packages and downloading of the MGCP and RTP stacks, please visit the Vovida Networks web site at  www.vovida.com .  Download code at   www.vovida.com/sub_mgcp.html  and  www.vovida.com/sub_rtp.html .                  Cygnus Shipping Code Fusion IDE for Linux         LINUXWORLD, San Jose, Calif., August 09, 1999 - Cygnus Solutions, the leader in open-source software, announced today it is shipping Code Fusion*, the industry's highest performing(1), most complete Integrated Development Environment (IDE) for Linux developers. Code Fusion IDE makes it possible for developers familiar with programming on Windows platforms to quickly become productive in developing applications for Linux.      With Code Fusion, Cygnus combines the latest Cygnus-certified, open-source GNU tools release with an intuitive graphical IDE framework.  It features a C, C++, and Java tools project manager, editor, graphical browsers and the Cygnus Insight debugger.    Code Fusion IDE is priced at $299.  For more information see  www.cygnus.com/codefusion .      Cygnus also announced version 2.0 of its  GNUPro Development Kit .  See   www.cygnus.com/linux  for details.                Magic Software news         At a press conference held at the LinuxWorld Expo in San Jose, Jack Dunietz (CEO of  Magic Software Enterprises ),   announced that Magic had ported its award-winning e-commerce solution (eMerchant ) to the Linux platform.                   Intel LANDesk Management Suite          AMERICAN FORK, UT, Aug. 9, 1999 -- Intel Corporation today announced it has extended the Intel LANDesk Management Suite to provide support for Linux-based systems. A new software module for Intel LANDesk Management Suite 6.3, available today for download from the Internet, enables IT managers to inventory the hardware and software assets on Linux-based laptops, PCs and servers and take remote control of those systems when diagnosing or repairing problems.  ""As many of our customers deploy Linux-based systems throughout their organizations, especially for web, e-commerce and file and print servers, it is imperative that they have the tools to manage and maintain these heterogeneous environments,"" said Ed Ekstrom, vice president and general manager for Intel's Systems Management Division.  ""Intel is committed to supporting IT managers across the application environments they support.""                    HELIOS slashes cost of network computing         August 10, 1999 =8B Garbsen, Germany  HELIOS Software GmbH , a leading vendor of network and prepress server software, announced a new 5-user version of EtherShare to retail at just $1,490 USD.    Helios EtherShare 2.5.1 offers state-of-the-art file, print, font, mail and timeservers with extremely fast AppleTalk routing, AppleShare IP file transfers, and user friendly remote administration. And, when combined with PCShare, EtherShare OPI 2.0, PDF Handshake and Print Preview, the Helios server suite provides a true cross-platform solutio n that can handle even the most demanding networking and printing environments.    Smart Ideas for Better Networking HELIOS software products support the UNIX and Pentium-based Linux operating systems, in addition to Apple Computer's new Mac OS X Server platform.    Helios products run on powerful and scalable servers from Apple Computer, Data General, Digital, HP, IBM, Motorola, a wide vareity of Pentium-based CPUs, SGI, and Sun, providing reliable cross-platform support for Macintosh, DOS/Windows, Windows 2000, Linux and UNIX-based clients. Distributors sell Helios products worldwide to value-added resellers who provide complete networking solutions to customers. Helios software products are also available as part of OEM solutions by many major vendors in the prepress industry.                Stalker CommuniGate Pro 3.1          MILL VALLEY, CA - August 9, 1999 - Stalker Software, Inc. today announced the version 3.1 of their hi-end CommuniGate Pro messaging system. CommuniGate Pro is a Unified Messaging Server which supports most major operating systems. CommuniGate Pro is recognized for its many features, high speed and reliability.    Since its first commercial release in September 1998, Stalker has expanded the operating systems it supports to include Linux/LinuxPPC, Solaris, FreeBSD, WindowsNT, MacOS X, BSDi, AIX, D/Unix, and IRIX. On all platforms, CommuniGate Pro presents the same interface and uses the same file formats, allowing any organization to switch server platforms in less than an hour.    CommuniGate Pro can support 100,000-200,000 accounts from one server making it a viable solution for small to mid-size ISP's. For extra large ISP's handling millions of accounts, CommuniGate Pro offers clustering support.    In addition, the new 3.1 version of CommuniGate Pro supports Personal Web Sites with automated publishing. Users can create their own Web sites and upload web files to the CommuniGate Pro server using any composer application that supports the HTTP PUT method (like Netscape(r) Composer). Besides, Personal Web Sites can be updated using simple HTML forms. Support for uploading via the CommuniGate Pro FTP server should follow in the next release.    CommuniGate Pro supports secure connections for all services it supports. Not only the HTTP services (Web Administration and WebUser interface to E-mail) can be used via secure internet connections, but all other communications, such as IMAP, POP, SMTP, LDAP, ACAP can be secured.    There is a Free Trial Version available at    www.stalker.com/CommuniGatePro/ .                  Giganet cLAN (MPI Software Technology)         At Linux World,  Giganet  announced  that MPI Software Technology, Inc. will distribute its cLAN server cluster interconnects for Windows NT and Linux.  The cLAN cluster interconnects, combined with MPI Software Technologys MPI/Pro (Message Passing Interface) software, enable compute-intensive applications to scale at new levels of performance at a very low-cost.      Applications such as weather modeling, fluid flow analysis, real-time ray tracing and molecular modeling, traditionally have been run on supercomputers. Through the clustering of high-performance Windows NT servers or Beowulf Linux clusters, engineers and scientists can achieve the advantages of speed and availability, leverage the latest technologies and lower costs.  The clustered systems work in parallel on a scientific challenge, coordinating with each other on the intermediate results.  The combined MPI/Pro and cLAN solution enables high-speed passing of messages among systems, with minimal delay.                 Udanax (Xanadu) hypertext system now open source         Monterey, California(August 23, 1999):  Ted Nelson announced today that the source code for a working implementation of the Xanadu  hypertext system are being made open source for developers.   Udanax.com -- formerly Xanadu Operating Company (XOC, Inc.)  -- released the code and will serve as the focal point for continuing development and application of these powerful hypertext systems.       In 1960, Nelson, who coined the term ""hypertext"", envisioned a revolutionary system of publishing.  He foresaw the power of publishing over computer networks like the World Wide Web but his original vision exceeded the capabilities of the Web.   Nelson termed this vision ""Xanadu"" and has sought to implement it through numerous efforts.  Udanax is the result of some of this effort.         With the Xanadu schemes developed by Udanax.com:      links do not break -- no matter how documents are moved or edited, links remain intact;    many versions can be compared to track the evolution of documents;    links go two ways -- you can see the links pointing into a document as well as pointing out;    documents can be edited by multiple authors allowing real time collaboration    documents can be created out of portions of other documents -- and you can track the source of all portions.      According to Nelson, ""The Web is a foam of ever popping bubbles, rather than stable literature.""   The key technical difference between the Udanax implementations of hypertext and the WWW mechanism (HTML) is in how connections between documents are tracked.  In HTML, the links are embedded in the document itself and are essentially named by the location of the machine where the document is stored.  Move the cited document -- the link breaks (404 errors). In the Udanax systems, the connections between documents are managed independently of the documents using sophisticated software algorithms.      The Udanax development efforts focused on the ""back-end"" or server component of the software.  By making Udanax open source, developers can work on ""front-ends"" or browsers for different applications.  ""Rather than focusing on a glossy user interface, the Udanax team has focused on building a complex and robust system to manage the information."" Gregory said.  To date, over 1,500 developers have indicated interest in developing applications for the Udanax system.      udanax.xanadu.com                Memory-resident Anti-Virus Protection for Linux           Moscow, Russia, July 15, 1999 -- Kaspersky Lab, a fast-growing international anti-virus software development company, reports the release of beta-version of world's first memory resident virus interceptor for Linux - AVP Monitor.    AVP Monitor for Linux is a client part of AVP Daemon that intercepts all file operations (starting, opening and initialisation of modules) and checks objects for viruses. Constant presence of the program in computer's memory allows reliable control over all possible ways of virus attacks on a computer or corporate network. Besides, AVP Monitor makes anti-virus defense very convenient and easy to use: it is enough to install and launch the program each time the computer starts.    A beta-version of AVP Monitor for Linux is available free of charge at Kaspersky Lab's WWW site at  www.avp.ru .     Kaspersky Lab is a fast-growing international company with offices in Moscow, Russia, Dublin, Ireland and Cambridge, UK. Started the business in 1992 is has concentrated in development of world-leading anti-virus technologies and software.                Other software          CodeWizard for C++ 3.0      Linda and Paradise , parallel and distributed computing development tools, by Scientific Computing Associates, Inc.Trial versions of the software are included on Red Hat's Applications CD, part of Red Hat's Official Linux 6.0 operating system.             This page written and maintained by the Editor of  Linux Gazette ,  gazette@ssc.com   Copyright © 1999, Specialized Systems Consultants, Inc.    Published in Issue 45 of  Linux Gazette , September 1999       Contents:   Greetings From Jim Dennis        Linux to NT PPP Connection Over Null Modem    Printing --or--   Printing to old ""Pin Printer""     Internet Access Control --or--   Limiting Internet Access through Cable Modems     unix question --or--   Quotas on a Sublet Web Server?     Mars NWE --or--   MarS NWE: HOWTO and Docs in English?     java curses library and jxterm? --or--   Old Question Revisited: Java Curses Support     RH6 Virtual Email - POP3 problem --or--   Virtual E-mail Domains     Setting up Windows and Linux --or--   Dual Booting without Re-Partitioning     LINUX File System Standard. --or--    /bin  vs  /sbin  and the FHS Revisited     How to Print 2 pages on 1 sheet --or--   Saving Trees: Laying up Multiple Pages per Printer Sheet     Telnet trouble --or--   More ""Can't Telnet Around My LAN"" Problems     Getting on the Internet --or--   Getting Access to the Internet     Cash In On ... Spam!           Greetings from Jim Dennis      So, I spent half of the month in Japan.  The first week that I was   there I was too busy, tired and disoriented to get any e-mail.    So my column this month is a bit thin.  Of course there is this one   message that's pretty long.  I think it's the second longest I've   ever written here.  The longest was on Internet Routing.  That one    is being used as supplemental reading for a couple of college   course from what I hear.   This one is not likely to join it.    Meanwhile I still have about 3000 messages in my backlog folder   which will take some going through.  Luckily I use MH, so I'll   probably develop a script to process most of the routine stuff.    Speaking of ""routine"" Mike Orr, and Heather have taken steps to   reduce the number of ""routine"" questions we get here in Linux   Gazette.  They've created an  FAQ  and    an  index to all of my previous     ""Answer Guy"" questions.  I haven't seen it yet --- but   hopefully we can convince people to use it.   There are about 900 questions that I've answered listed.    That, and the fact that the WebGlimpse engine at Linux Gazette   (http://www.linuxgazette.com) seems to be working at last, might   help people answer alot of their own questions (which is the whole    reason I put so much time into TAG anyway).              Linux to NT PPP Connection Over Null Modem     From Neal Gieselman on Wed, 28 Jul 1999        Hello,     You got any tips on how to get Linux to connect to NT over a null modem cable?  We intend to eventually replace the null modem with a wireless connection.     Neal Gieselman     I don't know anything about supporting NT PPP.  I've never used it. For the Linux end you'd just use the directive ""local"" instead of ""modem.""  So, look for a similar option among the NT GUIs and dialogs.  They might have a ""modems"" or ""serial ports"" control panel which might have a ""null"" or ""direct"" entry in the list of supported modem models.  Try that first.     Call MS technical support for info on making  any  sort of null modem PPP connection (ask them how to make two NT boxes connect over a null modem cable).  Whatever they suggest --- if it is standards conformant PPP or even close --- Linux should be able to cope with it when you replace one NT endpoint with your Linux system.     Why isn't there an NT answer guy?     You'd probably be better off installing ethernet cards in the two boxes in question, and running a cross-over cable between them.     Questions to the rest of the readership:  Are there any short-haul modems out there that provide the same interface as a basic Hayes compatible modem?  Are there any devices which emulate dial-tone (TM), DTMF signaling and ring/busy signals?  (Such telco wire simulators would obviously be quite handy for teaching PPP and other modem skills in a class room setting).               Printing to old ""Pin Printer""     From Philippe  on Mon, 26 Jul 1999         Hello Answerguy!     I have been unable to print with Applixware 3.5. I am using RH6.0 and my printer is an (old) NEC pinwriter. I use the Epson LQ850 driver with Windows. Of course, it is not a Postscript printer. I checked all the How-To but I am still clueless. Could you please help?     Thanks in advance.  Philippe.     Install Ghostscript.  This will implement PostScript on your system, and it's drivers will convert that to pin rasters that most printers can handle.     Once you have Postscript emulation working, you can feed your Applixware output to it through the normal lpr/lpd (BSDish) print filtering facilities (as listed in your  /etc/printcap  file).               Limiting Internet Access through Cable Modems     From Chris Dahl  on Fri, 20 Aug 1999         I have a Linux box set up at home that is connected to the Internet through a Cable Modem. Myself and my kids share this connection through IP-Masquerading using Windows Clients. Is there a program, or option that will run on Linux that will allow me to control when they use the Internet and for how long?     Or is this better controlled through the workstation?     Chris     There isn't an option or program that I know of.  However, it should be possible to write some.     To limit them to specific times of the day I'd just set up a set of cron jobs that periodically remove and replace the routes and packet filters between your kids' systems and the Internet.     Let's say you give the kids' systems IP addresses like  192.168.2.* , and you give your own systems  192.168.1.*  addresses.  Now you can have cron jobs that add packet filtering  REJECT  statements that prevent the masquerading system from forwarding packets from the  192.168.2.0  network.     The exact rules would depend on your needs and the version of the Linux kernel that was running on your router.     Setting up limits own now long their connections are allowed to persist would be more challenging.  I'd probably look at doing that using DHCP --- where you'd assign each kid's system an IP address (via it's ethernet MAC address)  and you configure the leases so that they expire in a set time.  Then you hack the DHCP daemon's code a bit so that it refuses to reissue those specific IP addresses within some other set time period (say, one day).     Another approach would be to hack up a copy of diald to just add and remove routes/IP masquerading entries (read through the sources, find out where it's calling the PPP daemon and replaces those  system()  calls --- or whatever they are, with your own calls to the  ipfwadm  or  ipchains  utilities.  The same code that adds your masquerading entries can also use an ' at ' command to schedule a time to remove them).     These don't sound like horribly difficult programs to write --- although it might be easier and ultimately more effective to enforce your household rules through old-fashioned parental supervision.               Quotas on a Sublet Web Server?     From Tim Pellett  on Fri, 20 Aug 1999         AnswerGuy,     I found you on the internet and was wondering if you could answer my question/problem.     I am renting space on a Unix/ Apache  server and am at the user level. We are allowed to redistribute the space given to us and I want to set up file quotas. I do not want to give space to other people w/o setting up file size limits.     I asked the ISP and they said I can do it myself using 'file quota software'. I cannot find such a product for a unix/apache server. Everything is Win 95/NT etc. I cannot use the quota command b/c I do not have access to sys admin files.     Do you have any suggestions? I have been trying to figure this out for months now, and am getting frustrated!     Thanks, Tim     Let's see if I got this right ... you have some virtual hosted web space (not a co-located server but an account on your ISP's web server).  They somehow allow you to create further accounts in your virtual space.  You want to do this, and to apply quotas to those sublet accounts.     I can't help but ask the obvious economic question, why would someone go through you to get this service rather than getting directly from your ISP?  Is there really enough wiggle room in the margins for an arbitrage opportunity here?     In any event, getting back to the technical question...     You don't mention which version of UNIX you are using. Suppport for system quotas is one of those things that varies considerably from one version of UNIX to another.     If your ISPs support people say it can be done with software that they know of --- please press them for the specifics.     My guess would be that the solution would depend quite a bit on which version of UNIX this system was running, and a bit on the specifics of their account management system.  If they are providing you with your own chroot jail, and giving you access to create your own UNIX accounts within that jail, they'd have to be providing some pretty hairy clones to a large number of administrative utilities in order to have any chance of maintaining any semblance of system security.     (Technically all of the account management in UNIX is done in user space.  The kernel only respects UIDs and GIDs for making access determinations.  Consequently, you could theoretically create almost any sort of account management scheme you wanted, if you were willing to rewrite enough of the utility and library infrastructure to support it.  I doubt they've done this, so I have serious misgivings about the security of their approach).     Of course I'm guessing that you're talking about some sort of relatively generalized shell/FTP/mail support for these ""sublet"" user IDs.     If you're willing to force your customers to go through a custom interface to update their web pages (and you're constraining them solely to web page publication) you could use somewhat simpler models.     Let's assume that you are only interested in web page publication.  I'm guessing that the account management then boils down to something like a set of CGI/PHP scripts that allow users to update their accounts (and manage the usernames, passwords, directory structures and any accounting data that you maintain).     You'd also be providing some sort of mechanism for them to upload their new web masterpieces.  Whatever mechanism you provide to do this (presumably a set of CGI programs or scripts) can perform the quota calculations and implement your policy enforcement.  It seems like quite a lot of custom coding to duplicate a set of functions that are already provided by the underlying operating system.     All in all it seems like it would be much easier and not much more expensive to co-locate a server of your own at some ISP site.  Then you could use established OS system features and utilities to manage all of this.     Otherwise I can see a general solution to your question that doesn't involve an utter lack of security on the part of your ISP.  If they essentially give you 'root' access to this shared server then you have to ask what protection they are offering their customers from one another.  That becomes a question of how they are protecting your customers from their other customers (some of whom might be your competitors in this bizarre multi-level ISP scheme).     I notice that you don't actually say you're trying to sell this space to other people.  The technical problems are the same in any event.     In any event you'd have to provide quite a bit more details about what version of UNIX this ISP is using, (and keep in mind that I'm the  Linux  AnswerGuy so Solaris, AIX, and other UNIX questions may be ignored), about what account management mechanisms they are using, about which services you intend to provide and about what mechanisms and protocols you intend for them to use in updating their web pages.               MarS NWE: HOWTO and Docs in English?     From Paul Sullivan  on Fri, 20 Aug 1999         Hi Jim,     I'm not sure if it's fair to address this question to you, but I've drawn a blank everywhere.     No one seems to ever make mention of the   Netware  emulator for Linux ""Mars"" (in english anyway).  I've done a few searches on the web, and can only find communication in a foreign language.  Is there anywhere (group of english folk) that discuss mars?     Regards Paul Sullivan     Hmm.  It looks like you're right.  Martin Stover, the author of MarS NWE (and presumably the person after which it gets its first name) seems to be German (or at least the pages I looked at list a .de e-mail address for him).     I did find some docs and READMEs in English at a mirror site in Columbia University:      http://omnicam.cs.columbia.edu/linux-docs/mars-nwe-0.99pl10      But that looks like the same files you'd get from the package itself.     It looks like your best source of information is the IPX HOWTO ( http://metalab.unc.edu/LDP/HOWTO/IPX-HOWTO.html ) which seems to cover it reasonably well.               Old Question Revisited: Java Curses Support     From Wilson Yeung  on Fri, 20 Aug 1999         Hello James,     I don't mean to be too critical -- afterall, I realize that you must be faced with many emails and deadlines when writing your articles for The Answer Guy.     Still, I thought I should point out that you didn't help Spencer T. Kittelson when he asked for a ""Java equiv. of a C curses library"". You pointed him to Java terminal emulation applications like JXTerm or SCO's Tarantella.  If he was asking for a java telnet program, I'm sure JXTerm would have been a good answer.  Unfortunately, he wasn't (I think the use of the words ""curses library"" gives it away here).     That's an old one.  I remember that I searched around quite a bit on the net for the suggestions that I did give him.  SCO's Tarantella is closed source, of course. I remember that part of what I was looking for was an open source Java terminal emulator (on the silly idea that this might be built over a curses-like library).     Come to think of it, how hard would it be to port ncurses to Java?  Of course you have to get Java to provide a terminal interface (which is why I started with the suggestions that related to that).     In actual fact, he was asking for a framework/library for developing terminal applications in the Java Programming Language.  In other words, he wanted to be able to write in Java something like PINE or ""top"" or irc-ii, but without Swing or AWT and relying solely on a user having only terminal capabilities.     -Wilson     Oh!  That is a different interpretation of the question.     Using Java to write curses mode programs?  Well, that would be nice --- but I don't think it will gain any attention. I'd think that C and Python and PERL have that space pretty solidly sewn up.     Python seems to have pretty decent curses support, and it has many of the same OO features and dynamic protections that Java promises.  Meanwhile text-mode/curses support seems so far away from Java's core focus that it seems like an unlikely avenue for future development.               Virtual E-mail Domains     From Netvigator  on Fri, 20 Aug 1999         Dear Answerguy,     I recently install RH6 and use linuxconf to add virtual email domain as well as POP3 account. I test it with sending email to that virtual email domain and sucessfull without returning mail. However, I cannot retrieve mail using POP3. Can you give me any idea about that ? (The DNS setup is OK since the Web virtual domain can function properly).     Regards     When you send mail to the account into which you are funneling this virtual e-mail domain traffic, is the spool file created under  /var/spool/mail/?      Is it a normal mbox file (a text file with a series of e-mail messages concatenated together, delimited by lines of the form  ^From ....* )?     Does your POP daemon work for any of your other accounts?     What mail client are you using?  Does ' fetchmail ' work when you use it to fetch your POP mail from localhost?     Are there any messages in  /var/log/messages  that might be related to any of this?     You'll have to at least isolate the problem to the MTA (mail transport agent, presumably  sendmail ) or the MSA (mail storage agent: presumably UW's IMAP/POP3 daemon package), or the client/delivery agents ( procmail ,  fetchmail ,  or whatever you're using).     Once you've isolated a problem down to the relevant subsystem you can then work on isolating it to a specific operation.  Is your POP3 daemon being started by  TCP wrappers, tcpd (almost certainly)?  Is tcpd preventing the access from your client (quite a common problem)?     The fact that this is being done through  linuxconf  doesn't offer me any clues.  I've only played with linuxconf very briefly, and so far I don't like it and wouldn't trust it to set up a virtual e-mail domain.     Is it generating a  .mc  file for sendmail?  I don't want to see a  sendmail.cf  --- those are too long and too tedious to read.  However, if the mbox file(s) are being properly created under  /var/spool/mail  as you expect then you don't need to worry about the MTA at all.     Incidentally, the fact that your virtually hosted web server works doesn't actually eliminate the possibility of DNS problems.  It could be that you have MX records pointing to never-never-land.  Those would take precedence over the A records (which are all that are required for web browsers to resolve your server's IP address).     Try doing a bit of troubleshooting to isolate the symptoms in more detail.  That will probably make the problem more clear and suggest a solution.               Dual Booting without Re-Partitioning     From John Vance  on Fri, 20 Aug 1999         Until I migrate fully to Linux, I want to keep Windows 95/98 installed, due to the fact that I do all my school assignments on my Win98 OS. Is there an easy way to dual boot besides using any of the partitioning software? I am studying UNIX/Linux at College and need to be able to do this so I can study and further investigate Linux     Well there are several options for you.     First you can install a ""Mini-distribution.""  There are several distributions of Linux which can be installed in a subdirectory of your MS-DOS or Win '9x system and started via LOADLIN.EXE.     Linux supports a filesystem driver called UMSDOS (including UVFAT for FAT32 and VFAT drives under Win '9x).  This allows Linux to store and use UNIX filesystem semantics (including ownership, group association, and permissions) under MS-DOS compatible filesystems.  It's even possible (with the hackery employed by these mini-distributions) to mount a subdirectory of your C: or other MS-DOS compatible drive as the root filesystem under a Linux kernel.     The most popular Mini-distribution these days is probably Kent Robotti's DOSLinux.  You can find that at:     DOSLinux at Tux.org:  http://www.tux.org/pub/people/kent-robotti      [ You could also try ZipSlack:          http://www.slackware.com/zipslack    It's designed to fit on a ZIP cartridge, and uses UMSDOS. -- Heather ]      That's probably the easiest approach.  Of course there are other options.  You could install a second (or third or fourth, etc.) hard drive.  In that case you wouldn't need to re-partition.  Just put your Linux filesystems on some parts of the new drives.  (Of course you can devote the whole new drive to Linux if you like).     I'd still use LOADLIN.EXE.  The difference here is that you're only storing a copy of the LOADLIN.EXE program and a copy of any kernels that you want to boot on your C: (or other MS-DOS) drive.  The Linux kernel can be told to mount root filesystems off of any drive that it can access (through its built-in drivers, or via the drivers and programs stored init its initrd, initial RAMdisk).  There is no constraint that requires a Linux kernel to be located on the same filesystem or even on the same drive or physical system as it will be mounting for its rootfs.     Yet another option would be to convert your system fully over to Linux.  Then you'd purchase and install VMWare or one of its clones.  You'd use it to create a Win '9x partition and re-install your copy of Win '9x under that.     This is a relatively new option.  Also VMWare is not free or open source software.  However, it does seem to be much more usable than the currently available free software in the same class (Bochs,  WINE , etc.).     One of the founders at Linuxcare ( http://www.linuxcare.com  : where I currently work for my ""day"" job) chuckles every time he gets a ""blue screen of death"" under NT --- as he kills that Linux process and boots up a new virtual machine.     (I also know one guy who is running a copy of Linux under a VMWare virtual machine that's running under a different distribution of Linux.  It's an odd way to test a new distribution).     My preferred approach is to buy an extra hard drive. They are pretty inexpensive these days --- and you'll probably find some way to use the extra space, even if you decide to consolidate all of your operations unto one OS.               /bin  vs  /sbin  and the FHS Revisited     From Greg Morse on Fri, 20 Aug 1999         I enjoyed your little write up on bin vs  /sbin  etc. Is there somewhere that a file standard for non-linux systems exists? I have heard reference to a system V standard. How different is it from Linux?     There are many standards that relate to various facets of various forms of UNIX.  However, I don't know of anything quite like the FHS for non-Linux systems.     I've heard that HP was looking at the Linux FHS as a possible model for their own HP-UX filesystem/layout specification.  However that is an unsubstantiated rumor.  Of course UNIX vendors are welcome to adopt the FHS and adapt their systems to match it.  This would be of benefit to all UNIX and Linux users.     Also linux does not seem to have a  /opt  filesystem which is quite heavily used on my AIX and HPUX boxes. What is the Linux equivalent?     Linux does offer  /opt.   I usually make mine a symlink to  /usr/local/opt.   It is supposed to be for ""applications binaries"" (so things like  KDE , WordPerfect, Applixware, and StarOffice all go into the  /opt  hierarchy.     I would also appreciate it if you could go a bit deeper down the directory tree, explaining as you go. The whole unix directory structure is a mess and could really do with some xplanation as to what the common idoms are. Thank you.     Oooh!  That would be a bit of a project.  I don't think I have time for it this month (that two week trip to Japan and the demands of a full-time job are catching up to me). However, I'll leave this in my inbox until the end of the month in case I can spend a bit more time on it.      Note that there is a bit of a fractal quality to some parts of the typical/conventional Linux/UNIX directory tree.     For example we find bin, sbin, etc, lib and doc subdirectories under  /usr/local/  which serve purposes that are analogous to the same directories that are found under  /  and/or under  /usr.   We commonly find a similar set of directories under  /opt.   It's also common to see users who put tmp, bin, src, and even lib subdirectories under their home directories.     Some of the same things can be seen under the  /usr/X11R6  directory tree.     Beyond that quite a bit of the directory structure is specific to the packages that are installed.     Remember all of these are guidelines rather than strict rules.  Sysadmins frequently will set things a bit differently --- though deviating too far from the expectations of their software will require quite a bit of programming and patching on their part.               Saving Trees: Laying up Multiple Pages per Printer Sheet     From Kong Liong Wong on Tue, 24 Aug 1999         Hi Answerguy     I'm running Solaris 2.6 and I'm using HP Jetadmin to administer my network HP laser printers. I've seen some organization who are able to print double pages on 1 sheet, with the time stamp, user as well as page number information neatly printed on the side. All I'm able to achieve now is printing 1 page per sheet and the formatting is ugly. I know I can use HP JetPrint to format my printing, but is there any other alternative way?     Please help     regards Kong Liong     Is this a PostScript (TM) printer?  If not you probably want to install a Ghostcript filter so that any PostScript that you send to the queue will be converted into your printer's native control language (some version of PCL for your HP).     Once that is accomplished it's very easy to configure your system to perform lay up as you describe.  There's a program called ' mpage ' which is commonly available with Linux distributions (you'll have to dig around to find the sources and compile them for Solaris).  It's what you want.     ' mpage ' ( http://gate.mesa.nl/pub/mpage ) allows you to print 1, 2, 4 or 8 pages of text per side of a printed sheet.  It does this by arranging the text into PostScript pages, and using the scaling and rotation features of PostScript to do the the layout.     ' mpage ' will add a small frame and a set of headers and footers to each printed sheet by default.  It offers a number of options to disable or control these features.  There's where you can get your filename, date, username and other information onto the output.     That's fine for text.  However, your output is already in PostScript there's a program called ' pstops ' which can do a PostScript to PostScript ""conversion/translation"" according to the parameters you specify.  In that model you can provide it with parameters to scale each odd numbered page to 60%, rotate it ninety degrees, position it on an output sheet, take every even numbered page, scale it, rotate it another direction, add it to your output page, etc.     Notice that I gave an example of scaling/reducing the pages by less than 50% for a reason.  It turns out that typical margins around your original pages are just a bit larger than they need to be when you do this layout.  So scaling by 55% to 65% actually produces better looking and more readable output.     It can be a bit tricky to get your pstops parameters right. While I was writing my book I'd generate the PS file from my LaTeX  .dvi  files (using ' dvips '), then for some of the draft printouts I'd use ' pstops ' to lay that out and ' gv ' to select the even sheets (print those), and finally use ' gv ' to toggle my sheet/page selections, turn the paper around and print the other sides.  Most of the work was done by my book's Makefile (using ' make ').  The result was that I could generate a full draft of my book while only using about 100 sheets of paper for 400 pages of writing.  (Luckily my eyes are fine with the reduction).     Here's a sample ' pstops ' command like the one that I used:     pstops -q -pletter ""2:0L@.7(21cm,0)+1L@.7(21cm,11.6cm)""                 lsa.ps > /tmp/quarto.ps     (The term ""quarto"" is probably a misnomer here --- but that's what I called it in my Makefile).     While writing this I've been running a couple of web searches in my other ' screen ' terminals (to get a good URL on mpage and to check the man page).  While I was doing that I noticed that ' mpage ' wasn't installed on my  Debian  box so I did an ' apt-get install ' of that and found that it apparently supports layup of PostScript as well as text files.  It's probably a newer version than I remember.  Possibly it's just a feature that's been there for years, which I just never noticed before.     Considering how obtuse the ' pstops ' command arguments can be perhaps you should just stick with ' mpage '.     ' pstops ' is part of the PSUtils page by Angus J. C. Duggan ( http://www.tardis.ed.ac.uk/home/ajcd/psutils ).  There are a number of other free tools that he's provided which might be of interest to anyone with advanced printing needs.  In fact, glancing at his web page I see that I probably should have been using ' psnup ' instead of ' pstops ' for what I was doing.     Oh well.  Live long enough and you can learn lots.  One of the reasons I spent so much time on TAG is that it gives me the incentive to double check the man pages and look up the web sites for packages that I use --- so I often learn new tricks in the process.     Incidentally I'd like to make a special notice on Angus' web page for the PSUtils package.  It's beautiful.  There's lots of very useful information about the package --- and he's taken the time to give credit to a large number of people that inspired his work or otherwise contributed to the package.     Thanks, Angus.  (I've copied you, and the current maintainer of ' mpage ' on this message.  It will be published in the Linux Gazette Answer Guy column later this month.  Linux Gazette is at  http://www.linuxgazette.com  --- which is odd since it's a free webazine with very little commercial sponsorship).     [ Given the number of commercial support bullets, and the generous          hosting by SSC, I'm tempted to disagree on the amount of commercial          sponsorship, though I must admit that I'm very pleased not to          see it smothered with ""regulation size"" banner ads. -- Heather ]     In any event, Mr. Wong, I hope these tips will help you get what you want out of your printer.  Of course, there are many other print filtering packages available for Linux and other forms of UNIX.  I'm sure I'll learn about a few more, probably as a result of some future ""Answer Guy"" question.               More ""Can't Telnet Around My LAN"" Problems     From Bobby Mathew  on Thu, 22 Jul 1999         I have a lan of 20 machines with one NT server and remaining Win95 clients and today I just added my LINUX Server. After Installation of the RedHat 5.2 LINUX I have trouble telnetting to the machine from any other machine on the lan.  I am able to ping the ip address of the LINUX server from the nodes and visa versa but not able to ping its name.  When I try telnet from the Win95 clients by specifying the ip it says connected but nothing appears...no username..no password nothing......  I am a newbie to LINUX and so it is kind of frustrating experience not knowing what to do. Please can you help ?     bob     It sounds like you don't have reasonable DNS or other name services properly configured.     Being unable to ping a machine by its name requires that the client (the running running the ping command) be able to translate that name into an IP address (called ""resolving"" in the vernacular).  This is usually done via the DNS system (using the named program from the BIND --- Berkeley Internet Naming Daemon --- package).     If you can do normal web browsing of Internet web pages, ping Internet hosts by name etc --- then you do have the resolvers on your Win '95 and NT systems configured reasonably for that purpose.     When you try to telnet to the Linux box by its IP address then your client is able to establish the connection. However a standard Linux distribution such as   Red Hat  will have a utility called ""TCP Wrappers"" ( tcpd ) installed and configured to protect your system from some relatively common forms of attack.     tcpd will attempt to perform a ""Double reverse lookup"" to match the source IP address of any telnet, rlogin, rsh or similar (inetd launched, or ""dynamic"" TCP service) to a fully qualified domain/host name (FQDN) and back.  First it performs a reverse lookup.     Let's say the connection is coming from  123.45.6.78  --- tcpd will look that up in the reverse DNS system (actually looking up  78.6.45.123.in-addr.arpa  for crufty historical reasons).  If it got a reply from that (this IP address example is obviously for pedogogical use --- it doesn't seem to actually be in use on the Internet) it will do a forward lookup on the alleged name.     Let's say that the hostmaster of  123.45.6.*  configured his copy of named to return the name "" mybad.mit.edu "" for his ...78 address.  It would be naive to assume that this was actually an MIT address from that piece of info.  All we know is that some  claims  that this is an MIT address. That response  probably  came from a caching server, which  probably  got it from an authoritative server for the  123.45.6.*  or  123.46.*.*  or  123.*.*.*  PTR zone, which probably  was uncompromised and  probably  was under the control of the proper hostmaster for that zone.  This doesn't imply that the any  123.*.*.*  addresses were ever delegated to MIT.     So tcpd now does a forward lookup asking for any IP addresses that are assigned to mybad.mit.edu.  That response will  probably  be legitimate (subject to the same issues as the reverse lookup).  It should contain a list of all IP addresses that are assigned to that hostname.  Note that there is no one-to-one correspondence between FQDN/host names and IP addresses.  Any host can have multiple interfaces each with its own IP addresses.  A host can also have a different name for each of it's interfaces and it can have multiple IP addresses on any interface (a technique called IP aliasing, which used to be used extensively for web server ""virtual hosting"" before the widespread support for HTTP 1.1 virtual hosting).     So, if tcpd finds the original IP address of the connecting client among the list of addresses returned by the reverse lookup then it logs the name and processes the connection according to the access rules listed in the  /etc/hosts.allow  and  /etc/hosts.deny .  Those two files allow you to accept, deny, or specially handle requests according to where they are (or  seem  to be) coming from, which service they are requesting and which interface/IP alias they are accessing.     I've described this ""double reverse lookup"" process before (although not usually in such detail).     The key point for you is that this can cause a very long delay when you are trying access a Linux box via telnet and most any other service that's listed in the  /etc/inetd.conf  file.     This delay will also affect NFS mounts off of a Linux server because the most command portmapper on Linux systems is apparently derived from one written by Wietse Venema (the author of TCP Wrappers) and is linked with the libwrap --- a programming library which implements the same checks and access control semantics as tcpd.     So, the problem is that you don't have name services correctly configured for your LAN.  Even if you properly configured your forward (name to IP address) mapping, you'd have this problem if you didn't ensure that the reverse mappings were consistent with them.     If you waited for several minutes you'd probably find that the telnet would work.  Once you logged it, everything would work at normal speeds.  This only affects the behaviour on initial connections.  The fact that ping works as you expect suggests that your addressing and routing is fine. The Linux kernel handles ping (and other ICMP) directly --- so tcpd doesn't protect you for (nor otherwise interfere with) these packets.     The web server, mail daemon (sendmail, smtpd), and named (DNS/BIND) processes on your Linux systems generally are not dynamically launched.  They usually are not linked with libwrap either.  Therefore they are some common services which are usually unaffected by this problem.     The question then becomes:  ""How do you provide name services for your LAN?""     One way would be to use static files.  On UNIX and Linux systems you can add entries to your  /etc/hosts  files on each system. This would contain entries like:     127.0.0.1 localhost  localhost.localdomain 192.168.2.192 win1.example.org win1 192.168.2.193 win2.example.org win2 192.168.2.194 wnt1.example.org wnt1     I've heard that there's a HOSTS file facility that can be enabled in Win '9x (presumably through a registry entry). I don't know where the file would be located and I can't guarantee that is uses the same syntax as a UNIX hosts file.  It would be similar to their LMHOSTS files (which are for old IBM LAN Manager implementations of their SMB file sharing protocol).     If you put the IP addresses and names (any names) of your client systems into the  /etc/hosts  file on your Linux box it will immediately solve the reverse DNS problems.     Actually this assumes that your  /etc/nsswitch.conf  is properly configured.  That should look a bit like:     # /etc/nsswitch.conf # # An example Name Service Switch config file. This file should be # sorted with the most-used services at the beginning. # # The entry '[NOTFOUND=return]' means that the search for an # entry should stop if the search in the previous entry turned # up nothing. Note that if the search failed due to some other reason # (like no NIS server responding) then the search continues with the # next entry. # # Legal entries are: # #       nisplus or nis+         Use NIS+ (NIS version 3) #       nis or yp               Use NIS (NIS version 2), also called YP #       dns                     Use DNS (Domain Name Service) #       files                   Use the local files #       [NOTFOUND=return]       Stop searching if not found so far #  passwd:         files [NOTFOUND=return] nisplus nis shadow:         files [NOTFOUND=return] nisplus nis group:          files [NOTFOUND=return] nisplus nis  hosts:          files dns [NOTFOUND=return] nisplus nis  services:       files [NOTFOUND=return] nisplus networks:       files [NOTFOUND=return] nisplus protocols:      files [NOTFOUND=return] nisplus rpc:            files [NOTFOUND=return] nisplus ethers:         files [NOTFOUND=return] nisplus netmasks:       files [NOTFOUND=return] nisplus bootparams:     files [NOTFOUND=return] nisplus  netgroup:   nisplus publickey:  nisplus  automount:  files [NOTFOUND=return] nisplus aliases:    db files [NOTFOUND=return] nisplus     Since you're using Red Hat 5.2 or later you should have one of these files (though their default settings are wrong for most sites --- files should generally be preferred over DNS or any other source; if you bothered to edit a name into a file the system should respect that).     The settings I've shown here insert an optional action to stop trying to resolve most of these mappings without bothering to try NIS and NIS+ (since I don't use those in my domain).     I realize you may be a bit confused at this point (I'm rambling again).  Basically all this NSS stuff has to do with how a modern Linux system's ""resolver"" works.     The resolution of names into IP addresses, services, and even account and group names into UIDs and GIDs (the numeric objects which the kernel and filesystems use to manage ownership and permissions) are all done through libraries (think DLLs since you're from an MS Windows background).     There are various mechanisms for performing these mappings. Originally it was all done through simple text files.  Thus the host name to IP address mapping was done by searching the  /etc/hosts  files, and the user accounts were found in the  /etc/passwd  file, and the groups were in the  /etc/group , etc.  Under UNIX and Linux these files are still respected and very widely used (especially for users and groups).     DNS was added to provide a host name to IP address service that was scalable to the needs of the Internet.  This also provided for some facilities that were not possible in the  /etc/hosts  file (like MX records which specify alternative locations to forward mail for a system that doesn't have its own smtpd running).     Then Sun introduced its ""Yellow Pages"" (YP) service for distributing user, group, host and other sorts of information over a network.  Apparently British Telecom prevailed in some legal wrangling, forcing Sun to officially rename YP to NIS (Network Information System).  This is vaguely analogous to Novell's NDS (Netware Directory Services), LDAP (lightweight directory acces protocol) and to the ""Active Directory"" vaporware that Microsoft is promising to deliver in NT 5.x ... err ... Windows 2000 ... err ... Windows ""Consumer"" or whenever.     (Later Sun implemented a more advanced version of the NIS protocols called NIS+).     MIT developed and used (uses?) a naming/directory service called ""Hesiod"" (as part of their Athena project if I understood it correctly).  This is essentially a way of distributing lines from  /etc/passwd  and  /etc/group  through DNS using a particular type of record.  It's the most obscure and rare of the existing naming services that I'll mention.     In the bad old days the sysadmin had no control over what order the various naming and directory services were queried.  The big commercial versions of UNIX provide a ""Names Services Switch"" configuration file named  /etc/nsswitch.conf .  (I think that would have been introduced in Solaris 2.x by Sun and emulated by HP-UX, AIX and others shortly thereafter).     In older versions of Linux (those relying on libc version 5.x) there were different versions of the libraries with and without support for files, DNS, NIS and NIS+.  The version of libc that supported NIS was often referred to as the ""NYS libc.""  You could use the  /etc/hosts.conf  file to give you limited control over the resolving process.     With the adoption of GNU glibc version 2.x (which is Linux libc version 6.x) Linux distributions gained support for  /etc/nsswitch.conf  and a fully modular NSS infrastructure. files, db, DNS, and NIS support is provided with most distributions.  NIS+, LDAP, Hesiod, NDS and even custom and as yet undeveloped naming services can be plugged in and supported without recompiling any of the software that ships with a typical Linux system.     Through the magic of dynamic linking this modular NSS will also be supported by all programs that conform to the standard glibc APIs for their name services request.     In all of these cases the DNS resolver further relies on an  /etc/resolv.conf  (NOTE: no 'e' on the end of that!).  That's where the resolver libraries find pointer to ""nearby"" name servers.  (Actually the libraries and code don't care if your name servers are ""nearby"" or not.  However, your sysadmin and others might be understandably irritated if you configure you system to send packets to Bangladesh for every name lookup that it performs).     That finally brings us back to your situation.  You can use just files through your network.  With only 20 or 30 hosts that generally isn't too cumbersome.   It's a bit of a hassle to add new hosts or change them around (you have make sure that all of the files get changed).  That's the whole reason all these other naming services were developed.     You can also configure your own DNS service for your network.     This gets to be a much more complex discussion.     Let's say that you have an Internet domain registered with the InterNIC.  That requires that you register primary and secondary nameservers with them.  These days many smaller domains (such as yours) are served by their ISPs nameservers.  ISPs that provide name services generally should have co-operative agreements with other ISPs or Internet sites so that each provides secondary services for the others.     This is all managed automatically by the BIND software --- once it's properly configured then it will automatically synchronize secondaries to primaries (using zone transfers).     It is also common for network administrators to run ""caching"" nameservers.  These aren't configured as primary or secondary authorites for any domain.  However they can have DNS requests directed to them and they will respond from their cache if they have recieved an authoritative answer recently enough.  The DNS protocols include plenty of information regarding the acceptable caching periods for any given record.  So they can be configured by the hostmasters of each domain.     BIND nameservers can be used for caching, and they can concurrently be primary to some domains, secondary to others.     So, why don't you just give a list of your machines to your ISP and one of their admins put all their names and IP addresses into your zones for you?     If you are a typical small site on the Internet these days you don't use IANA assigned addresses for all of your system.  You might have a dedicated connection to the Internet.  Perhaps you have an ISN line or even a modem that's configured for dial-on-demand.  Your ISP has probably only devoted a few IP addresses to you.  If you have a publiclly accessible web site it might be ""virtual hosted"" at your ISPs site on one of their servers.  The same might be true of your FTP server and your e-mail might be served to you through some POP mailbox hack.     Most of your system are probably using RFC1918 ""Private Network"" IP addresses ( 10.*.*.* ,  172.16.*.*  through  172.31.*.* , or  192.168.*.* ) and be accessing the Internet through IP masquerading (as provided by the Linux kernel or most modern routers) or through applications proxies (such as SOCKS).     In these cases you cannot publish those host names and their IP addresses through your public DNS records.     Even if you do have ""real IP addresses"" (which I refer to as DRIPs --- directly routable IP addresses) you might not want to publish them.  You really only need to publish the names and addresses of those systems which interact directly with the Internet (public web servers, mail exchange hubs, routers, proxy hosts, etc).     You want your LAN nodes to ""see"" one set of names and addresses in addition to allowing them to see the Internet name space.  As your network gets larger you don't want to have to manually synchronize alll those hosts files (and you might not want to even hack up Win '95 to force it to work with them in the first place).     So, what do you do?     This is where you configure your system to use ""split DNS.""     Basically you point your client systems to a nameserver that you set up (on your Linux system would be the natural choice).  This is their primary nameserver.  It is configured to be authoritative to your domain but it is NOT registered as an authoritative name server with the InterNIC.  In other words your domain services have a ""split"" personality.     Your internal systems look to one system for all name requests while the outside world looks to some other server (probably one maintained by your ISP or one of your ISP's secondaries).     This sounds much more complicated in discussion than it turns out to be in practice.  If you maintain a ""flat"" domain namespace (you don't create named subdomains within your organization) then running ""split DNS"" is fairly easy.     If you delegate subdomain zones to their own servers (departmental or regional, for example) then you'll have an added complication.  Typically you'd have to ensure that each of internal authoritative name servers is a secondary for each of the ""other"" subdomains.     In other words, let's you're running the foo.not domain. You decide to create subdomains for finance, engineering, and IS and call them: fin.foo.not, eng.foo.not, and is.foo.not.  You can just maintain a set of zone files for all of these on the same primary (internal) server. However, you might want to delegate these zone --- give the sysadmin/hostmaster of the engineering group his/her own internal DNS server.  In order for split DNS to work, and for the fin.foo.not and is.foo.not DNS servers to find hosts in the eng.foo.not subdomain --- the name servers for fin. and is. must be configured as secondaries to eng.     You can read more about why this is the case at:     Creating a split DNS environment  http://www.acmebw.com/askmrdns/00408.htm      However, it is relatively rare to have this problem. You probably are only running a small organization, and maintaining all of your domain in a single zone delegation is probably feasible.  In that case here's what you can do:     You can easily run a copy of named on your Linux box.  It's included with all major Linux distributions.  (Just install the BIND package from your Red Hat CD).     Red Hat 5.2 and later ship with BIND 8.x (there was a major change in the configuration file format between BIND 4.9x and 8.x --- as well as jump in the version numbering).     Once you've installed BIND all you have to do is to prepare a configuration file and a set of zone files for you forward and (especially) reverse zones.     Here's an example of a configuration file (similar to the one I use for my domain):     options {         directory ""/var/named"";         dump-file ""/var/tmp/named_dump.db"";         pid-file ""/var/run/named.pid"";         statistics-file ""/var/tmp/named.stats"";         memstatistics-file ""/var/tmp/named.memstats"";         check-names master warn;         datasize 20M;  forwarders { 209.157.85.7; 209.157.85.2; 123.45.6.7;}; };  zone ""."" {         type hint;         file ""named.root""; };  zone ""localhost"" {         type master;         file ""master/localhost"";         check-names fail;         allow-update { none; };         allow-transfer { any; };  };  zone ""0.0.127.in-addr.arpa"" {         type master;         file ""master/127.0.0"";         allow-update { none; };         allow-transfer { any; }; };  acl ""internal"" {         { 192.168.64.0/24; };         };  zone ""starshine.org"" {         type master;         file ""master/starshine.org"";         check-names fail;         allow-update { none; };         allow-transfer { any; };        // just allow the secondaries         allow-query { any; };  zone ""64.168.192.in-addr.arpa"" {         type master;         file ""master/192.168.64"";         allow-update { none; };         allow-transfer { internal; localnets; localhost; }; };      This configuration file refers to the starshine.org and 192.168.64 files in the ""master/"" directory. There are also localhost and 127.0.0 files under the master/ directory.  Here are copies of those two:     master/localhost:     $ORIGIN localhost. @               IN      SOA     @       root.localhost. (                                 2               ; serial                                 3H              ; refresh                                 15M             ; retry                                 1W              ; expire                                 1D )            ; minimum                         IN NS   @                         IN A    127.0.0.1      master/127.0.0:     $ORIGIN 0.0.127.in-addr.arpa. @               IN      SOA     localhost. root.localhost. (                                 2               ; serial                                 3H              ; refresh                                 15M             ; retry                                 1W              ; expire                                 1D )            ; minimum                 IN NS   localhost.  1       IN PTR  localhost.     Those two should be the same for every DNS server. (I won't get into the history surrounding this --- just take it as a quirk).     Here's a set of sample zone file excerpts from my domain:     master/starshine.org      @       IN      SOA     ns1.starshine.org. hostmaster.starshine.org. (                         1999071603      ; serial, todays date + todays serial #                         8H              ; refresh, seconds                         2H              ; retry, seconds                         1W              ; expire, seconds                         1D )            ; minimum, seconds                 IN NS      ns1.starshine.org.                 IN NS      ns2.idiom.com.                 IN MX 10   antares.in.starshine.org.                 IN MX 20   mx.starshine.org.                 IN MX 30   www.starshine.org.                 IN MX 90   mx.myisp.net.                 IN TXT     ""Starshine Technical Services""   IN A    209.157.85.7   flowpoint IN CNAME   gw.starshine.org. gw  IN A       209.157.85.1                 IN MX 10   antares.in.starshine.org.                 IN MX 20   mx.starshine.org.  pulsar  IN A       209.157.85.2 ntp  IN CNAME   ntp.starshine.org.  mx  IN A       209.157.85.7 mail  IN A       209.157.85.17  www  IN A       209.157.85.7                 IN MX 10   antares.in.starshine.org.                 IN MX 20   mx.starshine.org.  ftp  IN A       192.168.64.3                 IN MX 10   antares.in.starshine.org.                 IN MX 20   mx.starshine.org.  staging  IN A       192.168.64.4                 IN MX 10   antares.in.starshine.org.                 IN MX 20   mx.starshine.org.  lasfs  IN A       192.168.64.5                 IN MX 10   antares.in.starshine.org.                 IN MX 20   mx.starshine.org.  antares  IN A       192.168.64.11                 IN MX 20   mx.starshine.org. ant  IN CNAME   antares.starshine.org.  betelgeuse IN A       192.168.64.12                 IN MX 10   antares.in.starshine.org.                 IN MX 20   mx.starshine.org. bet  IN CNAME   betelgeuse.starshine.org.  canopus  IN A       192.168.64.13                 IN MX 10   antares.in.starshine.org.                 IN MX 20   mx.starshine.org. can  IN CNAME   canopus.starshine.org.  venus  IN A       192.168.64.14                 IN MX 10   antares.in.starshine.org.                 IN MX 20   mx.starshine.org. startop  IN CNAME   venus.starshine.org.  quit  IN CNAME use-exit-to-quit-nslookup.      master/192.168.64     $ORIGIN 64.168.192.in-addr.arpa. @  IN SOA 64.168.192.in-addr.arpa. hostmaster.starshine.org. (     4  ; serial     3H  ; refresh     15M  ; retry     1W  ; expire     1D )  ; minimum @                IN NS      ns1.starshine.org. @                IN NS      ns1.idiom.com.  1 IN PTR  antares.starshine.org. 2 IN PTR  betelgeuse.starshine.org. 3 IN PTR  canopus.starshine.org. 4 IN PTR  deneb.starshine.org. 5 IN PTR  eridani.starshine.org. 6 IN PTR  fomalhaut.starshine.org. 18 IN PTR  rigel.starshine.org. 19 IN PTR  spica.starshine.org. 22 IN PTR  vega.starshine.org. 33 IN PTR  andromeda.starshine.org. 97 IN PTR  mercury.starshine.org. 98 IN PTR  venus.starshine.org. 99 IN PTR  earth.starshine.org. 100 IN PTR  mars.starshine.org. 101 IN PTR  jupiter.starshine.org. 102 IN PTR  saturn.starshine.org. 103 IN PTR  neptune.starshine.org. 104 IN PTR  uranus.starshine.org. 105 IN PTR  pluto.starshine.org. 106 IN PTR  luna.starshine.org. 107 IN PTR  deimos.starshine.org. 108 IN PTR  phobos.starshine.org. 109 IN PTR  titan.starshine.org. 110 IN PTR  europa.starshine.org. 111 IN PTR  io.starshine.org. 112 IN PTR  ceres.starshine.org.     ... etc.     So you could take these as samples (though you'll have to edit in various values).  Every hostmaster I know uses a set of templates for all of their files.  Occasionally someone needs to build one ""from scratch"" but most of us maintain our zones in ""monkey-mode"" (as in ""monkey see; monkey do!).     For more information you could read the ""cricket book"" whole book on DNS/BIND (*)     (DNS and BIND, 3rd Edition  http://www.oreilly.com/catalog/dns3/noframes.html )      You can also can peruse the DNS Resources Directory ( http://www.dns.net/dnsrd ) web site, and you could visit the Internet Software Consortium at:  http://www.isc.org .  ISC is headed up by Paul Vixie, who has been the principle programmer and maintainer of BIND for about 20 years.     Hope that helps.  Sorry such a simple question leads to such a long answer.  I've been meaning to write up something on split DNS for awhile.     Incidentally the examples I showed were for the internal systems.  The publicly accessible servers and any hosts with ""real"" IP addresses would have entries in a different set of zone files which would be stored on a publicly access DNS server.  Keeping the two sets of zone files relatively in sync is one of the principle disadvantages of split DNS. There are systems out there that generate zone (and reverse zone) files from simple text tables and/or as reports from a database.  I don't know of any that specifically support zone ""splitting"" (though it would be a simple feature to add).     In my case I'd only have about three or four  entries in my public DNS and I don't maintain a reverse DNS zone for it directly (my ISP offers a web form (CGI) driven means to allow me to submit changes to my reverse names to his zone.  That is a complex issue that I won't cover this time around.               Thanks     From Bobby Mathew on Fri, 23 Jul 1999     Dear Jim,     I am so really impressed by your explanation of my problem. I am also grateful for your initiative to help out. I had given up on the problem after recieving no response for so long. But your email has encouraged me to venture into LINUX a little more deeply. I am a novice to LINUX and so very hesitant to venture far. Thanks a lot for your detailed explanation. Though I must admit that most of it went over me but neverthless your email has certainly inspired and enlightened me to go back to see if I can correct the problem.     Thanks a ton for sharing your expertise and your time. I will try it out and get back to you.....     God Bless you  bobby             Getting Access to the Internet     From albuquerque on Tue, 31 Aug 1999         Hope you can help me.  I have a DELL I7K laptop running WIN98 and Linux RH6.0.     Linux seems to be running fine, have  GNOME  as my window stuff, I can access the PCMCIA card and use a SYQUEST SCSI drive.     Now I'd like to use Linux to access the Internet!!!!!!!!!!!!!     I have read most or many How TO s etc. and keep getting lost in the forest.       That's a common problem.  The answer will be a rather lengthy one. To answer this question I'll have to start with a view from ""ten thousand feet"" and then swoop down for a closer look at some details.     As with the answers to many questions about Linux quite a bit of my response will be qualified with: ""It depends...""     Since Linux, and UNIX are written following a ""toolbox"" model it provides us with tools to apply to the whole class of problems. We have to know how to use those tools to fashion our own solution.     In the case of connecting to the Internet most of the ""It depends"" clauses are followed by the phrase ""...on your ISP.""  Other things depend on your hardware, your distribution, and even on your personal preferences.     Problem?  What are the steps need to get on the Internet.  (RH says use Linuxcfg's special command - which I can't find.)  What is need to set up the Modem; What is needed to set up the DNS numbers(like Win98); What is needed to set up E-Mail; Where is the ""Dialer""?     I think  Red Hat  recommends the use of the linuxconf package.  I don't know what Linuxcfg would be, or what sort of ""special commands"" it might offer.     (I suspect that you have simply mangled the name of the package and haven't referred to HOWTOs in the conventional way.  These may seem like nitpicks.  However attention to details of this sort, linuxconf vs. Linuxcfg and HOWTOs vs. ""How TO s"" is actually quite important in using most operating systems, particularly in using any UNIX like system).     So, your questions were:     What are the steps needed to ""get on the Internet"" with Linux?  What is needed to set up a modem under Linux?  What is needed to set up ""DNS numbers"" (by which I presume you mean: set your IP address, network/subnet mask, broadcast address, and specify the addresses of your ""nearest"" name servers)?  What is needed to needed to set up e-mail?  Where is the ""Dialer?""      That looks like five questions.  It could also be considered as one broad question for which you've provided four specifications to clarify what you mean by ""get on the Internet"".  I'll revisit each of these questions, with answers, below.     However, first I'll comment on some of the overall problems that lead to these sorts of questions.  The first thought might be to say: ""Linux is too hard to use.""  Getting on the Internet is one of the most common operations for PCs these days so it  SHOULD  be easy and straightforward.     Indeed it could be.  If we were buying our computers with appropriate modems included and with Linux pre-installed and pre-configured for our modems AND if we were subscribing to ISPs who catered specifically to the particular Linux distribution that our hardware vendor was providing.  If we didn't have so many choices --- then connecting to the Internet would be pretty easy.     Let's compare this to the typical experience of Window '98 user buying a new system and accepting whatever options are presented ""up front"" in that process.  They buy a system with a cheesy little winmodem pre-installed.  It includes icons to access MSN (the Microsoft Network) and possibly AOL.  These are already on the desktop.     Under those circumstances (and the similar ones which predominate the experience of new Mac users) it is pretty easy to ""get on the Internet.""  We'll ignore the trifling argument that being on MSN or AOL might not quite be the same as ""being on the Internet.""  That's a matter of personal bias.     That process is easy.  It sometimes isn't reliable.  It certainly isn't flexible and may not be economical nor convenient (you have to put up with quite a bit of advertising if you subscribe to either of these ""loss leader"" ISPs).  When things don't work right you are up against an unyielding brick wall.  Lost in all that ""ease of use"" is any control over the underlying mechanics (much like the situation under the hood of most modern vehicles --- somewhere deeply wedged under all those proprietary electronics is your basic internal combustion, gasoline driven piston engine).     Things get very interesting if you want to have choices; to do things your own way.  Linux is very much about ""doing things your way.""  This is a facet of it that comes with quite a cost.  It requires quite a time commitment to climb the Linux learning curve.     To complicate issues more every distribution starts out with a set of assumptions how things ""should"" be done.  For example RedHat 6.0 includes ' linuxconf ' --- and Red Hat Inc is encouraging people to use it.     Personally I don't like Linuxconf (nitpick,  linuxconf  is the command, Linuxconf is the subsystem which includes the command, some libraries, help files, an API and some other stuff).  What I want from a system configuration management tool is much more focused than Linuxconf is written to provide.     The biggest difference between configuring UNIX-like systems and managing the configuration of NT, Win '9x, MacOS, and other proprietary systems, is that UNIX (and Linux) use text files to store almost all configuration data.     The Microsoft operating systems use a ""Registry"" (which represents a giant single point of failure as well as a key, performance limiting lock point for which many critical subsystems compete).  Almost anything ""interesting"" that you want to do to configure an NT or Win '9x system involves tweaks to the registry.  Anyone from that background who complains about how ""non-intuitive"" UNIX/Linux configuration file names are should take a good look at those \HKLM\... references to which they've become accustomed.     So, what I want out of a configuration management interface is one which primarily consolidates the process of creating and modifying these configuration text files and integrates that with a documentation and context sensitive help system.     A nice thing about having lots of small, individual text configuration file is that you can prepare one canonical or template that is suited for a given site or situation and easily distribute that to as many systems as necessary. It's scaleable with simple distribution and processing (scripting and text processing) tools.     The dark side of this model is that each of these conf files has a unique syntax and set of semantics.  It's like having to know dozens of dialects of Hindi and Punjab to work within one administrative domain.  That's the problem that I want solved.     Linuxconf tries to do too many other things and doesn't offer me a way to just spit out the conf files.     So, I don't use it.     This means that its quite possible that you could use Linuxconf to do what you want with a minimum of fuss and virtually no understanding of what all the ""moving parts"" mean or how they relate.  However, I can't guide you along that path --- since I've taken the low road (or the ""low-level"" road as it were).     Any help or assistance you can provide would be ever so greatly appreciated!     Thankyou Al     So, let's revisit those questions:     What are the steps needed to ""get on the Internet"" with Linux?      What do you mean by ""on the Internet?""  You mention using a modem and using e-mail.  So I'll guess that you want to be a simple, dial-in PPP client, to access web and e-mail (presumably through a POP mailbox) from a conventional ISP.     Note that I'm guessing here.  There are many other ways to be ""on the Internet.""     For example you might want to have your own domain, configure one modem to maintain a persistent connection to the Internet, set up your own web and mail servers, configure another modem for dial-in by some associates etc.  That would an equally legitimate interpretation of your question.     In general the process of connecting a Linux box consists of the following steps:     Establish a physical link (communications channel)   Configure a TCP/IP interface (handle IP addressing, subnet masking, etc)   Configure routing (usually: set a default route)   Configure name services resolution ( /etc/resolv.conf )   Configure and access specific applications services      Most of these correspond to the other questions you asked.  Fans of the OSI networking reference model will note that I've listed these roughly in order from the lowest level (physical) towards the upper (applications) layer.  We're ""stacking"" each step on top of the ones on which it depends.  (I bet some of you have wondered by they call it a ""TCP/IP  stack "").     In your case you've said that you want to use a modem. So that will be your communications channel.  We'll cover that with your next question.     Once you've dialed into your ISP and established a modem connnection, you'll have to run some protocol over that connection in order to provide any sort of networking through it.  These days that will almost certainly be PPP.  In the days of yore (about 4 or 5 years ago) you might have been coping with SLIP.  That's virtually unheard of these days.     Under Linux PPP is provided by the PPP daemon, usually installed as  /usr/sbin/pppd.      Your ISP probably defaults to issuing ""dynamic IP"" addresses.  The PPP protocol has features for negotiating and establishing addressing, masking, and routing for each new connection.  So long as you stick with reasonable defaults then you won't have to deal with those issues directly.  We'll talk about that, and LAN addressing when we address your third question.     Almost all operations on the Internet are done using host and domain names.  So one of the most vital ""glue"" services provided by the Internet is DNS.     This is usually classified as an ""applications layer"" service, because the Internet TCP/IP protocols don't conform to the seven layer OSI reference model.  I tend to think of it as a ""presentation layer"" service (having to do with the translation between user/applications representation in the form of names to a lower level machine representation, IP addresses).  I'm sure some OSI purist will correct me on this.     In any event there is a bit of a chicken-and-egg problem when we think about DNS.  We have to provide an egg, in the form of one or more IP addresses, to gives us the whole specifies of other nameservers that form the DNS system.     So we list a few nameservers in our  /etc/resolv.conf.      Conventionally these would either being a local caching name server or one of the name servers operated and maintained by our ISP.  This makes quite alot of sense since it minimizes the number of network hops taken by our name resolution requests and their replies.  In other words it results in faster name resolution at less overall cost in bandwidth across the Internet.     Usually you can just create one  /etc/resolv.conf  and leave it in place permanently.  Even if you have multiple ISPs its possible to refer to any nameserver on the Internet, even if it isn't the ""closest.""     Once you have these networking basics in place you can access most Internet services.  You can browse the web, fetch Linux package updates over FTP, telnet, use the finger command etc.     Note that your ISP might provide a proxy/cache for its customers.  If that's the case you might be a bit happier (and make your ISP much happier) if you configure your web browsers to point to his Squid server, or whatever he's using.  If that's the case, your ISP should provide you with the information and support to use the feature (it's really of more benefit to him and your fellow customers than anyone else).     E-mail is special case.  There are many ways for you and your ISP to configure your e-mail services.  In the simplest case you have an address of the form:  YourName@YourISP.com  and you just periodically use a POP or IMAP client to fetch your mail from your ISP's server.     Your POP/IMAP client might be part of a mail user agent (MUA: a program for reading and composing/sending e-mail) or it be a separate utility like ' fetchmail ' which relays your mail from an mail store to a local ""spool"" (mailbox).     Note that POP is only a way of receiving e-mail.  When it comes to sending e-mail there are two methods that are commonly employed by UNIX MUAs.     Most well-behaved programs call on a local program named  /usr/lib/sendmail  (which might be a copy of the classic 'sendmail' MTA, mail transport agent, or it might be any program that provides a sufficiently compatible interface to allow MUAs to feed mail to the local system transport agents).     Some programs (""know-it-alls"") will bypass the local MTA and attempt to directly open their own connections to the mail transport agent on the recipients home host (or MX as the case may be).  Netscape Communicator is an example of this class of program.     The reason I make this distinction is that your choice of MUA has implications regarding how your configure your system so that the mail you generate has an appropriate return address.  It generates another ""It depends...""     If you don't configure your system correctly then most people will not be able to respond to any mail you send them.  They'll have to remember your address and type that in every time rather than being able to use the ""reply"" feature of their MUA.  That would not endear you to your correspondents.     We'll get to that in a bit more detail later.     That's the overview of ""getting on the Internet."" Obviously most of the details are left to the constituent questions that you've provided.     What is needed to set up a modem under Linux?      First you need a real modem.  This seems so obvious you might wonder why I'd even mention it.     winmodems (a.k.a. ""losemodems"").     To understand the difference between a real modem and a ""winmodem"" you have to know a little bit about how modems work.     The term modem originally stood for ""modulator/demodulator"" (which sounds like something Marvin the Martian might be brandishing as he says ""Take me to your leader"").     Telephone lines carry electrical signals which are normally analog modulations of sound.  The fact that sound can be easily represented and transmitted by and replayed from electrical signals (in the forms of telephone, radio and phonograph, for example) is the major realization on which Thomas Edison built his fortune and his historical legacy.     For computers to make use of this medium they must be able to convert their digital signals into modulated electrical signals and vice versa.  Thus we have devices that modulate and demodulate.     Fundamentally modems are programmable tone generators, usually with analog-to-digital (A/D) and digital-to-analog (D/A) circuitry and other stuff in them.     It's this other stuff that grew increasingly sophisticated throughout the late 70's, 80's and into the early 90's.  Modern ""smartmodems"" and ""Hayes Compatible"" modems are essentially special purpose computers running an embedded system.  The interface to that embedded system is any of the many variations to the AT set that every modem manufacturer has created.     In particular these modems needed to do signal transformations that were much more sophisticated that simple AM and FM (amplitude and frequency modulations respectively).  So they needed special DSP (digital signal processing) chips as well as a processor and memory to handle the interpretation of AT commands. Naturally they also had fairly significant ROMs to store the AT command set interpreters.     The advantage of all this is that modems work in a relatively standard way, through a minimal interface (the serial port) and without introducing much processing overhead on the host systems.     Ironically the most recent real modems have CPUs that are probably more powerful than early PCs.     However, some manufacturers came up with the brilliant idea of ripping out all the DSPs, processors and firmware out of their modems.  They produce a device which is essentially just the programmable tone generators, and force the host system to do all of the signal processing and provide the interface (AT command set emulation).  This entails running a rather bulky and computationally expensive driver on the host system.     Those are winmodems.     Winmodems wouldn't be such a bad idea under certain circumstances.  If the devices were priced  much  lower than ""real"" modems, and if the programming specifications were widely available, then the choice would be simply be a matter of comparing cost/benefit factors.     However, neither of these conditions is true of winmodems in the current PC market.  They aren't significantly less expensive to the consumer (so the manufacturers and distributors keep all of the margin). Also, and here's the part that's of interest to Linux users, the specifications for devices are not available. Therefore the only drivers that exist for most of them are for MS Windows.  In some cases it appears that some manufacturers have released proprietary UNIX drivers.     The economics that result in the widespread deployment of winmodems are instructive.  As far as I can tell they first their way into the market through bundling.  At a certain point it became a significant marketing handicap to sell a computer system without including a modem. However, the only characteristic of a modem that was important in marketing whole systems is the optimal throughput speeds.  So computer retailers included the cheapest modems (in the right ""speed"" range) that they could find.     Since almost every system shipped with a (win)modem there was a corresponding drop in the sales of (real) modems as separately purchased peripherals.  (Probably this wasn't really a ""drop"" so much as a slower growth in sales as compared to the broader expansion of the whole computing market).  These (win)modems are mostly made by the same manufacturers as real modems. Naturally it then made sense for them to package these devices in the same way as their real modems for separate sales.     So, when you go to the store to buy a modem you'll find that winmodems are packaged identically to internal (real) modems.  They are usually not clearly labelled (sometimes the warning doesn't even appear in the fine print on the outside packaging).     So, the easiest way to guarantee that you are getting a real modem is to buy an external one.  So far as I know it's not possible to make an external ""winmodem"" that connects to a plainn old serial port. (One could certainly design a ""RAM modem"" that required a software driver to be ""uploaded"" to it, and such devices might exist --- but I'd put those in a different class even if they did require MS Windows or other proprietary drivers to operate).     The real danger of winmodems (and winprinters, which are similar in some respects) is that they build an artificial economic and hardware barrier to the adoption of new or alternative software.  In other words, they give too much power to Microsoft (in this particular case).  Any similar technology is best avoided by the wise consumer (regardless whether the co-incident beneficiary is Microsoft or any other software company).     There are some efforts to write drivers for some winmodems.  Naturally the programming interfaces are different for each model and brand of these devices.  In most cases the manufacturers are not providing any support for the efforts (and in some cases I'd bet that the modem manufacturers can't do so, since they may have licensed their drivers through a third party, etc.).     If any of those projects is a success than the modems that are supported by Linux will probably be called ""linmodems.""     At that point there will probably be four or five classes of modems in the PC world.  ""Real"" modems (internal ISA, PCI, and external), winmodems (those that are still not supported by Linux), ""linmodems"" (those winmodems that are supported with a Linux driver), and possibly the USB modems will be in a class of their own.     Note that there is a potential problem with internal modems even if they are ""real"" (non-Winmodems).  Some of these are ""Plug and Pray"" devices that must be initialized by some proprietary driver.  In some cases you may be able to cope using the Linux pciutils package.     PCMCIA modems, such as you might be tempted to use in your laptop, come in both ""real"" and winmodem flavors. As with other internal modems there is usually nothing to clarify the matter on the packaging or in the marketing literature for these modems.     Calling the manufacturer's technical support line might help --- if they have one, if you can get through, and if the person you talk to has a clue what your asking about and the inclination and liberty to honestly answer your question.     However, the simple advice is:     Throw away the internal modem that came with your machine.     Buy an external modem!     If I recall correctly the Dell Inspiron 7000 that you have includes an internal ""winmodem"" --- ignore it. It's not supported by Linux.  (Although Dell may be providing a supported modem in future versions since I've heard rumors that they'll eventually be offering desktop and laptop system with Linux pre-installed).     That finally leads us to the answer to the question at hand.  How do we use a  real  modem under Linux?     Linux has a very simple interface to any normal modem. The application simply opens the device's node (entry in the filesystem which provides a means of access UNIX/Linux device drivers through normal file operations).     This would usually be  /dev/ttyS0  or  /dev/ttyS1 , though it could be any of the  /dev/ttyS*  devices that represent access to the conventional PC serial ports (COM1 through COM4).  It could also be any of the many devices associated with various multi-port serial cards (ttyR* for RocketPort, ttyC* for Cyclades, ttyD* for some Digiboard, and others for Stallion, etc.).     It's common for Linux users to create symlinks named  /dev/modem  and  /dev/mouse  which point to the real device interfaces for these common peripherals.  Then all of our applications and configuration files can use the symbolic name.  If we ever change to a different mouse or connect a modem to a different port we can simply update the symlink and leave all our software alone.     Once a process has an open read/write connection to the modem (and a lock on the device node to prevent other processings from jumping into the ""conversation"") then the use of the modem is rather simple.  The communications application handles all of the details for you.     What's going on under the hood is a structured conversation (protocol) between the application and the modem.  The application sends a special break signal after a pause to ""break"" the modem into command mode (similar to using the [Esc] key in 'vi' to break out of text entry mode into its command mode).  Then the application can send a series of AT commands (that is any command starting with the ASCII sequence ""AT""). These sequences set various options on the modem, and instruct it to dial and establish connections).     The modem reponds with various result codes like ""OK"" and ""CONNECT"" and ""BUSY"" etc.  (Most of them can be configured to return numeric codes instead of text).     The basic AT command set is the same for all Hayes compatible modems.  However, there are many extensions and settings that differ among brands and models of modem.  The most significant differences are in the ""init strings"" --- these are AT commands which configure the modem in preparation for a particular mode of operation.     Tweaking init strings is more art than science.  It can depend on the modem in use, the other modem to which it is connecting, and the software that will be communicating over the channel ... among other things. Every Linux serial communications utility is responsible for its own init strings and other dialogs with the modem.     This is quite unfortunate in some respects.  It would be nice if ' uucico ', ' kermit ', ' pppd / chat ',  ' mgetty ', ' efax ', ' minicom ', ' seyon ', and other modem-using Linux utilities were all ""reading off the same page"" for at least the major modem settings (if they were all written to read and parse an  /etc/modemcap  file, or something like that).  This would allow the admin to consolidate most of the information into one place, while allowing the applications to override those settings as necessary.     However, that's not the way it works, and it's not likely to become a new standard.  So we'll stop daydreaming and get back to how it DOES work.     Here's what's necessary to get an application to talk to your modem:     Provide it with the correct device name.   Ensure that the ownership and permissions of the device node and  /dev/  directory are suitable for your applications settings (this frequently involves marking the application/ utility as SGID to a ""modem"" group).   Configure it to use the same location, naming convention and format for its lock files as all other applications on your system which have access to the modem.   Provide your application/utility with any init strings or other specific settings it needs.   Ensure that the line is ""conditioned"" correctly.  Most modem using applications will do this for themselves, but sometimes you need to write a wrapper script that will use the 'setserial' and/or 'stty' commands to prepare the serial line (the settings of the device driver) for use, or reset it afterwards.     Distribution maintainers usually set their programs to be mutually consistent (to use compatible lock files for example).  They often don't configure their permissions and ownership to match my preferred policies, so I usually have to tweak some things to get them the way I want them to be.     In your case you're specifically interested in PPP.  It sounds like you won't be using ' mgetty ' (to recieve incoming data connections or faxes), and it seems unlikely that you'd be using any other modem utilities, or that you might just want to use ' sendfax ' or ' efax ' in addition to your PPP.     In addition it sounds like you are going to be running this system as a personal workstation, with no other accounts on it.  This means that you won't have any problem where you try to access the modem, and some other user on you system is already using it.  In other words, you don't have to concern yourself much with device locking and contention.  The Red Hat default settings are probably fine for your case.     There have been many articles on setting up ' pppd ' for Linux.  It's surprisingly difficult simply because there are so many options.  The Linux ' pppd ' is designed to act as a networking client or server.     Technically PPP is a peering system, so the terms ""client"" and ""server"" are misnomers here.  However, I use these terms to distinguish between the system that is initiating the connection (dialing in as a ""client"") and the one that is responding to it (answering the phone as a ""server"").     The Linux PPP daemon can act in both of these roles.     In your case you just want your pppd to act as a client.     The overall process is:    Edit the  /etc/ppp/options  file,  Create an  /etc/ppp/options.MYISP  file  Create a ""chat script"" ( /etc/ppp/chat.MYISP )  Create a script to call the pppd with the     directive to use  /etc/ppp/options.MYISP.   (Possibly) create entries in the      /etc/ppp/pap-secrets  and/or  /etc/ppp/chap-secrets  files     I personally recommend that the  /etc/ppp/options  file contains just one directive:     lock     That will force the PPP daemon to check for, respect and maintain a device lock file so that it can co-ordinate its use of the modem with any other programs that might be using it.  I've talked about the gritty details of lock files before.    You needn't worry about the details much since you probably will never really need the lockfiles.  However, it's a good ""placeholder"" for your  /etc/ppp/options  file in most cases.     This allows us to put all of our other directives in a more specific file.  We can then have different options files for different ISPs, and even for different modem banks at each ISP (when the fast local lines are busy you try the slower and more distant lines).  It also allows us to have special options files for each modem ( /etc/ppp/options.ttyXX ) and for individual users ( ~/.ppprc ).  Those options are for allowing dial-in PPP If you wanted to connect to your home computer from work, or allow your friends to connect to you.     After creating that file (or checking that your distribution has created a suitable one for you) you can then create an ISP specific options file.  That might look something like:      /dev/modem  115200  modem  crtscts  defaultroute  connect ""chat -f  /etc/ppp/chat.MYISP ""  # connect ""chat -v -f  /etc/ppp/chat.MYISP ""  # debug  # kdebug 7  # mtu 576 # 296  # mru 576  # 296     ... notice that the first line refers to our device and speed.  These must be the first options specified in this file, or they should be listed as parameters on the pppd command line in whatever script we write to make our calls.     The next two lines instruct the PPP daemon to treat the device as a modem (as opposed to a ""local"" or direct null modem connection) and to use the RTS/CTS (ready to send  /  clear to send) control wires on the cable between the modem and the computer (a common form of hardware handshaking).     The next directive instructs the PPP daemon to set a default route pointing to whichever interface it establishes while parsing this file.  This is sensible when you are using ' pppd ' as a client/caller to connect to an Internet ISP.  You would not use it if you were making a connection to some private network, especially if you had a DSL or other Internet connection (through an ethernet card or some other PPP connection). Obviously an ISP that was using Linux/pppd on its dial-in modem servers would also NOT use this directive.     The next directive is the hardest for new Linux/' pppd ' users to get working.  It supplies a command that pppd use to establish new connections.  As in this example this is usually an invocation of the ' chat ' command. The chat file contains supply a dialog between the system and the modem followed by a dialog between the local and remote computers.     Chat scripts are lists of ""send/expect"" pairs.  ' chat ' implements a very small programming language for describing these dialogs, setting timeout intervals and abort conditions, and handling simple errors.  Writing ' chat ' scripts by hand is a hassle.  There are several dialog/menu driven (text and GUI) front end programs (interfaces) which try to make this process (and the overall process of configuring PPP and connecting to the Internet) easier.  You can find a whole directory of such tools at:      http://metalab.unc.edu/pub/Linux/system/network/serial/ppp      One that is conspicuously missing from this directory is WvDial at:      http://www.worldvisions.ca/wvdial      ... This is probably the most popular of these interfaces. I've never used it personally (I edit my chat scripts by hand --- they aren't very long and I had to learn the syntax long before these tools existed).     However, I've heard many positive reports about it, so I can recommend it with some confidence.  I notice from my Freshmeat search (to find its home page) that WvDial has been upgraded quite recently (earlier this month).  So we have some indication that it's not suffering from ""code rot"" and neglect.     If you do have to create a chat script by hand here's what a typical one might look like:     TIMEOUT 30  ABORT BUSY  ABORT 'NO CARRIER'  """" ATZ  OK-AT&F-OK ATDT1234567890  CONNECT \d\r  ogin:-BREAK-ogin: MYUSERNAME  ssword:-\r-ssword: \qMYPASSWORD\q  ""starting PPP...""     The first line sets the a timeout setting.  The next two lines describe a couple of conditions under which chat should exit with an error exit value (if it receives either of these strings, it will ABORT the rest of the attempted dialog and call).     The following three lines are a simple modem dialog. The ""expect"" nothing (an empty string) and send a Hayes modem ""reset"" command (ATZ).  If that doesn't result in an OK response then a ""reset to factory defaults"" is issued (AT&F).  (If that doesn't result in the desired OK string then the script will time out and fail).  Then we see an attempt to dial the phone and we wait for any sort of CONNECT string.  We send a ""delay"" followed by a blank line.  Those are indicated with the ""escape sequences"" as marked by the backslash prefix in \d and \r.     If your modem need some ""init string"" tweaks you'd insert them after the ATZ command.     The last three lines are a dialog between the remote system and ours.  When a Hayes compatible modem connects it automatically shifts into ""connect/communications mode"" and ceases to interpret strings as commands.  We'd send a ""delay"" followed by a ""+++"" to break back into the modem's command mode.     This dialog implements a simple login procedure.  It expects a string like ""login:"" or ""Login:"" and sends a user/account name.  The it expects a string like ""Password:"" or ""password:"" and ""quietly"" sends a password.  (The ""quietly"" in this case refers to how ' chat ' treats is ""verbose"" and ""logging"" output, and has NOTHING to do with its communications to the remote system).  Finally our script expects an acknowlegement from the remote system indicating that it will now attempt to negotiate a PPP connection with us (using its implementation of PPP).  Many people will not need this last line.     After this last expect string the script simply ends.     If ' chat ' gets this far in the dialog it exits without returning any error (its system exit value is 0).  Then the pppd program which spawned it resumes control of the file descriptor ( /dev/modem ) and attempts to negotiate a network connection over this new communications channel.     As we can see, spaces and line feeds separate the expect strings from the send strings.  We have to quote any strings that contain spaces (using single or double quotes).  The ABORT and TIMEOUT directives each take a single argument.  That's why we have to use multiple ABORT directives to add a second abort string to the list.  The dashes we've embedded in some of the expect strings implement a very simple (and somewhat crude) error response option.  If the expected string (before the dash) is not detected within the timeout period, then the ""error string"" will be send to try to get the dialog back on track.     This is a very simplistic ""language.""  It has not structures to support conditionals (IF/THEN/ELSE) or loops, etc.  There are alternative utilities to implement more sophisticated chat scripting languages if you should need them.  In particular you could use the ' expect ' programming language (which is a TCL variant).     However ---- ' chat ' is adequate for most cases (all that I've encountered so far).     One trick for getting the expect/send dialog that we need is to manually log into our ISP using ' minicom ' or Kermit.  We can then capture the dialog (on paper or using a ""log to disk"" feature or the ' script ' (typescript) command.     One nice thing about using ' minicom ' for this early stage of preparation and debugging is that we can manually login and ""quit"" out of minicom without resetting the modem.  We can then invoke our PPP daemon with the chat script commented out.  This should result in a working PPP connection (thus assuring us that our PPP options are correct and allowing us to focus purely on the chat script).     Getting back to our example PPP options file we see a series of comments.  These can be used for doing debugging when we are having trouble with this connection.  The first comment is a copy of the connect command line with the  -v  option added to ' chat ' --- this provides us with verbose logging output (which is posted to our system logs so we can see our system engage in this dialog by reading our  /var/log/messages  file).     I usually login into one of my other virtual consoles when I'm debugging PPP connnections.  You might just open an extra ' xterm '.  From there just issue a command like:     tail -f /var/log/messages     ... and leave it running.  You'll see your log messages displayed as syslog receives them.  (Actually on my own systems I add a line to my  /etc/syslog.conf  to post copies of all syslog output to one of my extra virtual consoles --- usually #24.  But we won't get into that here).     The next couple of comments could be ""uncommented"" to direct ' pppd ' to be more verbose as it runs (resulting in more output in our  /var/log/messages ).     The last couple of lines in this sample PPP options file are examples of how we might over-ride the maximum transmission and receive unit sizes, with a couple of common values to which we might force them.  These mtu/mru settings might help us maintain faster, more robust connections under some line conditions and using some combinations of modems and other settings.     There are many other directives that we can put in your options files.  Some might say there are TOO many.     These include options for enabling software flow control (if the crtscts directive won't work for your modem and cable, for example) and ways to note which control characters can't be cleanly transmitted over your connection (which will force pppd to ""quote these"" as multi-character sequences).  There are several options to control the authentication and protocol negotiation between your PPP daemon and your ISP's system.     If you really want or need to know the gory details, read the ' pppd ' man page.     Once our PPP daemon is communicating with our ISP's PPP implementation the two of them will usually negotiate a number of communications settings and most ISPs will then send us our IP address, netmask, and associated route.     The Linux ' pppd ' will look for an executable  /etc/ppp/ip-up  and invoke that with a documented list of parameters (look in the man page).  This can be used to set up additional services or doing any other custom event handling.  Perhaps you want to resynchronize your system clock with an NTP server or three whenever you start up a new IP connection and run ' xntpd ' for the duration, or perhaps you only want to run the ' ntpdate ' command on the first connection of any given day. Perhaps you want to register your new, dynamically assigned IP address with some dynamic DNS system or announce that you're ""online"" to one or more of these ""ICQ"" services, etc.     There is also a  /etc/ppp/ip-down  hook and some analogous scripts for IPX handling.     Getting back to our bulleted list.  When we've created a suitable options file and a working chat script we'd then generally create a script to call pppd with the appropriate options to use them.     This might be as simple as:      #!/bin/sh  /usr/sbin/pppd  file  /etc/ppp/options.MYISP      ... which would simply instruct the PPP daemon to read our options file in addition to the global one ( /etc/ppp/options ).     In other cases we might have to prepare our serial port with commands like ' setserial ' and ' stty '. ' stty ' has an unusual syntax since it performs  ioctl()  calls on its stdin (standard input) file descriptor.  Thus we have to use a command like:     stty crtscts cs8 -clocal 38400 < /dev/modem     ... to actually affect the modem. Note that the redirection is FROM the device rather than to it. ' stty ' is the only command that I know of that requires this odd syntax.  The fact that I understand  why  it works this way doesn't make it any better for most users.     Hopefully your Red Hat installation is properly handling the serial ports on your system already. Otherwise you might have to play with the ' setserial ' command which I simply don't have time to explain here.     As I've said, pppd will automatically invoke the ip-up and ip-down scripts as appropriate.  So usually the invocation of pppd will be the last line in your ""call.MYISP"" script.  You could do some scripting to retry several times, or try alternate numbers or alternative ISPs if your connection fails too often.  In those cases you might want to use the -detach directive in your PPP options file.     Its possible to include most or all of your PPP options on ' pppd 's command line (and it's possible to include your chat script on ' chat 's command line; so with clever quoting you could have a long messy line that didn't rely on any of the custom configuration files that I've described here).     However, pppd is complicated enough without being downright obfuscatory.     The last bullet point I mentioned referred to "" /etc/ppp/pap-secrets  and/or  /etc/ppp/chap-secrets "" files.  Some ISPs may be using the PAP or CHAP authentication protocols (which are built into Linux pppd).  If so they should provide the name and password (secret) along with your other account information (like their phone numbers, and the IP addresses of their preferred nameservers).  Generally the use of these authentication protocols should shorten and simplify your chat script.  In our example the second part of the chat dialog (the host-to-host part) performed our authentication.     I realize that this was a long-winded (some might say excruciating) description of a very simple PPP configuration.  I go into this much detail (and even into a few digresssions) in the hopes that it will help you and others who have tried to read the HOWTOs and the man pages and walked away in utter confusion.     Notice that this whole handling of the ' pppd ' options files and the ' chat ' scripts is the hardest part of getting Linux connected to your ISP.  The fact that there so many options and several different files, and the fact that these all have to be consistent with one another in fairly complex ways it what confuses new users (and occasionally trips up even the most experienced of us).     When I'm teaching classes for Linuxcare (one of my roles with them) I refer to these as ""moving parts.""  Any time we have a list of options that must correlate to one another to get a particular feature or subsystem (like PPP) working it requires a bit of explanation was to how all of these options fit together.     I usually draw a mechanical analogy.  If I try to put a Toyota start motor into a typical Ford truck, it won't work.  The pieces will almost certainly not fit together.  The teeth in the starter's shaft will probably not mesh with those on the flywheel.  The solenoid's throw might not push the start shaft out far enough to even engage them.  The mounting holes probably won't line up, and the bolts probably wouldn't fit even if they did.  (Of course this analogy provides a bit more detail than most people with no automotive inclinations appreciate; but the idea has been pretty clear to my students so far).     This concept of ""moving parts"" is a recurring theme in all technical education.  There are many ""moving parts"" in MS Windows --- places where the value you put in one dialog box must ""match"" a different value in some other dialog, control panel or registry tree.     Often the settings on one machine must match settings on a different machine.  In fact, that is the essence of networking.     So, having gone into great detail on this central question we'll finish by providing somewhat shorter answers to your other questions.     What is needed to set up ""DNS numbers"" (by which I presume you mean: set your IP address, network/subnet mask, broadcast address, and specify the addresses of your ""nearest"" name servers)?     As I pointed out, most ISPs will provide your IP address through the PPP protocol.  They should also provide forward and reverse DNS mappings between your IP address and some name (often dyn-123.myisp.com or dialin-123.somepop.myisp.com; where pop in this context refers to a ""point of presence"" --- a location where your ISP has modems and phone lines that connect to their network).     Netmasks and broadcast addresses are handled automatically by PPP.  The basic interface route is also handled by the PPP daemon, as is the default route in most cases.     Your ISP will probably provide you with a list of preferred name servers.  You simply put those in your  /etc/resolv.conf  which should look something like:     domain starshine.org search starshine.org nameserver 123.45.67.89 nameserver 12.3.5.67 nameserver 12.3.5.78     If you were setting up your own network domain you'd have to register it with some naming authority (currently the InterNIC/NSI for the .com, .org, and .net domains, and various regional registries for the various national and .us state domains).  When you registered your domain you'd also register a list of authoritative name servers (by IP address).  These would have to be persistently online (through some form of ""dedicated 24x7"" connection to the Internet.     Usually small domains run by inexperienced used simply let their ISP handle all those details.  They ""outsource"" their DNS management.     I've written other articles in the past that go into way too much detail about configuring your own DNS.  That, and the fact that you almost certainly do NOT want to do this for yourself are reasons while I'll leave off further discussion of DNS here.     Basically everything is handled by your PPP configuration except for the contents of your  /etc/resolv.conf .     If you have multiple ISPs you can use the ip-up script to force a symlink change whenever you connect.  You create multiple  /etc/resolv.conf.*  files and use your script to create the appropriate symlink whenever you bring up the interface.  This also works reasonably well when you are using DHCP, connecting your laptop to someone's ethernet network.     You can then point your  /etc/resolv.conf  to  /etc/dhcpdc/resolv.conf  (or wherever your DHCP client puts it).     It's also possible to just leave one set of nameservers listed in your  /etc/resolv.conf  and ignore your ISPs preferred list.  This may result in slower response time and some wasted bandwidth (your name resolution requests will travel farther across the Internet before being answered).  However, it usually works well enough for the case where you have a secondary ISP that you only call occasionally.     What is needed to needed to set up e-mail?      I've described a little bit of the complexity of e-mail handling already.     Basically you'll need at least a mail user agent (and MUA).  Some MUAs (like Netscape Communicator and PINE) have integrated POP/IMAP clients and transport agents.     Others (like elm, mh, and mutt) will only provide the interface for reading, composing and managing your mail. They will require the use of separate utilities to receive your mail (i.e. ' fetchmail ' for POP or IMAP mail stores) and to deliver it (typically ' sendmail ' configured to ""masquerade"" as your ISP or vanity domain).     In your particular case it might be easiest to start with one of the ""all-in-one"" mail clients.  I personally don't like their approach.  However they can be simpler for a common case, even if they will cause problems for some networks where more centralization is required (behind firewalls  and on private networks, for example).     If you need or want to configure a proper MTA then ' sendmail ' is still the most widespread (a statement which will surely generate some flames from some ' qmail ' fans our there).  Here's is a simple sendmail ""mc"" (macro configuration) file:     divert(0)dnl OSTYPE(linux) include(`/usr/share/sendmail.cf/m4/cf.m4') FEATURE(`allmasquerade')dnl FEATURE(`masquerade_envelope')dnl FEATURE(`masquerade_entire_domain')dnl FEATURE(`always_add_domain')dnl FEATURE(`nocanonify')dnl FEATURE(`local_procmail')dnl MAILER_DEFINITIONS MAILER(`smtp')dnl MAILER(`local')dnl MAILER(`procmail')dnl undefine(`BITNET_RELAY')dnl  MASQUERADE_AS(`***MYISP.COM***')dnl define(`SMART_HOST', `smtp:***MAIL.MYISP.COM***')dnl     There are only two major ""moving parts"" to this file. You must change the last two lines to to match the domain/host name at which your ISP will accept mail for you (the part of your e-mail address after the @ sign) and you must provide a valid mail exchanger for your SMART_HOST.     This file would normally be created under  /etc/mail/  or under  /usr/share/sendmail-cf/  and would be used to generate a sendmail.cf file with a command like:     m4 < sendmail.mc >  /etc/sendmail.cf      ... issued from the same directory as the .mc file, of course.     Of course those other lines are also ""moving parts"" --- you might need to change the path to the include line, and you might need to include or even disable some features, etc.  Like so many other coniguration files in Linux, all I can provide is a reasonable example that should work in many cases.     I've included other sample .mc files in other Answer Guy columns in the past.  Usually I include one that's derived from whatever I'm running at home at any given time.   This has changed over the years as I've changed my network, changed ISPs, etc.     For this to work smoothly you should create an account on your system that matches your account name on your ISP, and use that to work with your e-mail from that address.   It's possible for you to control the name/address in your outgoing e-mail headers as well as the domain/host name portion.  In other words you could configure ' sendmail ' to modify the portion of your e-mail address that precedes the @ sign in the headers of your outgoing mail, as well as the part that follow it.   However, that would require you to use the "" genericstable "" feature which is somewhat more advanced than I want to go in this message.  (This is another case where the ""all-in-one"" mailers are easier to use. They'll generally let you set your e-mail address to anything you like without regard to any local system or network policies).     Where is the ""Dialer?""     I think I've answered this one.  ' chat ' is your ""Dialer"" for the PPP daemon.  Most other Linux/UNIX communications packages perform their own dialing by issuing ATDT (dial/tone) commands to the modem.  If (by some strange chance) you had a phone that required the old pulse dialing (a rotary phone!) you'd use the ATDP command.     Al,     I realize that this has been a long article.  I know that I've repeated myself in a few places (it's been written over several days, with a trip to L.A. and a conference in the middle).     Hopefully this will give you enough of a map of the forest that you can figure out which trees to climb, which ones to chop down and which branches to ignore.               Cash In On ... Spam!     From mindkiss on Wed, 28 Jul 1999         Cash In  On a Hot Opportunity!     Earn Full Time Income  On a Part Time Basis!  No special skills needed!!   Please Read This First     1. This email advertisement is transmitted in compliance with the new ""Email"" Bill: SECTION 301. Per Section 301, Paragraph (a)(2)(C) of S1618; Refer;   http://www.senate.gov/~murkowski/commercialemail/5771index.html      [ Hundreds of bills on many juicy political issues are promoted by          senators and representatives every year.  Until they are actually          passed (thus no longer a bill, but a law) they're fairly worthless.          This one is made more obvious, because its URL doesn't work...    The computer industry ought to recognize when people claim compliance          with a ""new standard"" that hasn't been ratified yet;  it happens in          our marketing literature all the time.  -- Heather ]      I don't care what delusion you are under.  This is unsolicited spam.  I've heard that it is illegal in the state of California --- which is my state of residence and where I'm sitting as I recieve this.     I'll be forwarding this along to by district attorney's office (once I dig up their e-mail address).     2. If you wish to be removed from our email list with respect to any further transmissions, you may do so without cost by simply clicking on your email program's ""Reply"" option and entering the word ""Remove"" into the ""Subject"" area.     I wish to never have recieved your mail.  I don't wish to ever hear from you or any of your ilk again.     3.  The business solicitation described below is offered by a real Florida based corporation ( name removed , Inc.), with a real address, real people and real products. Company details and testimony may be obtained by calling toll free 1-888-nnn-nnnn.     Whoop-de-doo!  You're a ""real corporation.""  That certainly doesn't preclude the likelihood that you are lying, thieving scumbags with no regards for courtesy or custom.     You're clearly unethical.  You KNOW that this message is unwelcome to most of your recipients and you sent it anyway.   Do not respond to this mail.       [ To their credit... they didn't. For more help in the fight    for valid mailbox contents, the Mail Abuse Prevention System   ( http://maps.vix.com/ )    is handy, and also points to other good resources.  -- Heather ]      ""Linux Gazette... making Linux just a little more fun! ""                 More 2¢ Tips!    Send Linux Tips and Tricks to   gazette@ssc.com       New Tips:          Using gmenu with fvwm2      Iomega ATAPI Zip Drive That Cables Up to IDE & Red Hat 6.0      A 2c Tip - Funny signature      HOWTO searching script         Answers to Mail Bag Questions:            Splitting big files      Formating drives      Kodak Problems      Installation problems      DNS on the fly      ipchains      gcc will not work      DHCP      ppp connection      ASCII to speach      2GB Limit in LINUX      Windows 98 inside Linux      Distributions      WORD to Postscript      g++ and including files that use templates                       Using gmenu with fvwm2     Sun, 01 Aug 1999 16:35:00 -0500  From: Tim Moran < tmoran@gbonline.com>     I usually use fvwm, but sometimes I like to switch to enlightenment. The problem was maintaining two sets of menus. So, with a little tweaking, I now use the gnome menu editor to maintain both.    Enlightenment is simple. The menu.cfg can read gnome's menus with:  BEGIN_NEW_GNOME_MENU(""GNOME_USER_SUBMENU"", ""ROOT"", HOME_DIR""/.gnome/apps"") ADD_MENU_TITLE(""User Apps"") END_MENU      Fvwm was a bit tricky. I probably am not using the best possible solution, but it works for me.     I recompiled wmconfig that comes with RedHat 6.0. In wmconfig.c there is a section that begins #if HAVE_GNOME. I changed this to read my ~/.gnome/apps directory:  ret = parse_gnome_files(""/home/tmoran/.gnome/apps"", NULL);      Then I made a little shell script to run wmconfig and clean up some unneeded files:   #!/bin/sh wmconfig --output=fvwm2 --no-sysdir --rootmenu=""ROOTMENU"" > .fmenu find /home/tmoran -name .order -exec rm -f {} \; find /home/tmoran -name .directory -exec rm -f {} \;       Finally, my .fvwm2rc contains:   AddToMenu RootMenu  +   ""&Rxvt""  Exec exec rxvt +   """"  Nop Read /home/tmoran/.fmenu AddToMenu RootMenu  +   """"  Nop +   ""&Fvwm Modules""           Popup Module-Popup +   """"  Nop +                       ""Refresh Screen""   Refresh +   """"  Nop +   ""&Exit Fvwm"" Popup Quit-Verify                    Iomega ATAPI Zip Drive That Cables Up to IDE & Red Hat 6.0     Tue, 17 Aug 1999 11:15:40 -0700  From: rbsimon < rbsimon@earthlink.net>     A simple way to mount your ATAPI Zip drive is to:      Create a mount point, e.g. /mnt/zip    Install loadable kernel module: 'insmod ide-scsi'    Mount the device: 'mount -t msdos /dev/sda4 /mnt/zip'    To unmount: 'umount /dev/sda4'                    A 2c Tip - Funny signature     Wed, 18 Aug 1999 20:58:49 +0200  From: Csaba Feher < csfeher@freemail.c3.hu>     Hello guys,    I just make up my mind to write a short shell-script to do some fun. It is for making funny signatures with 'fortune'. You can use it with your mailing software that can handle signatures. I tested it with Netscape and Pine, with a Mandrake Linux distro.    You need:      the 'fortune' application. I think many of you have it under  /usr/games/ (Or somewhere else, so you may edit the script if you need to.) If not, your installation media or a close FTP mirror should have it.    an 'sh' compatible shell...    the script below. I call it 'sigchange'.    a .signature file in your home directory (optional)     #!/bin/sh # # sigchange # # A simple shell script to get your .signature file looking more funny....   # # Written by Csaba Feher (csfeher@freemail.c3.hu) #    # First, if .signature exists, we just remove it, in order to start with an empty one   if [ -f $HOME/.signature ]; then     rm -f $HOME/.signature fi    #Then, make some good-sounding signature with the help of 'fortune'.  #The -s option is because of Netscape, it says that the estimated length of the signature was 4 lines.  #You may alter the categories to suit your needs. I prefer these two...           /usr/games/fortune -s linuxcookie computers > $HOME/.signature      S=$(cat $HOME/.signature)    #Take a short look at your basic signature file,  #which you may want to appear at the end of all newly-made signature. #Create & edit as you like. But, I suggest to keep it short.        O=$(cat $HOME/.signature.basic)    #Now put the whole stuff to the usual place echo -e ""$S\n $O"" > $HOME/.signature      Usage:      Use the script and make it executable for everybody you want to be able to use.    Copy it under /bin or /usr/bin, or wherever you want to. Do not forget to check your PATH variable, it should include the path to 'sigchange'.    Add the following line to your system initialization script:  sigchange   This is /etc/rc.d/rc.sysinit for Mandrake or Red Hat; it may be different in other distributions. You should check and find the script that initializes and boots up your system. The .signature will change each time you reboot your Linux box.    If you prefer more changes, you can add a line containing this:  sigchange   to /etc/rc.d/rc (Mandrake/Red Hat). It starts 'sigchange' each time the runlevel changes.    make a .signature.basic file in your home directory, or rename your existing .signature file to it. Edit it to contain a suitable signature you want to use at the bottom of your mails. I think you should keep it short.       Changes are made at the next reboot /runlevel change.    Feel free to use and enjoy it! Any comments are welcome!    p.s.: my recent signature is made with this method...   --   But what can you do with it?  -- ubiquitous cry from Linux-user partner.  (Submitted by Andy Pearce, ajp@hpopd.pwd.hp.com)      ### Keep on running LINUX! # Csaba Feher # csfeher@freemail.c3.hu ###                    HOWTO searching script     Wed, 25 Aug 1999 11:56:57 -0400 (EDT)  From: Matt Willis < matt@optimus.cee.cornell.edu>     I find that searching howtos is easier if you use a script. I was inspired by another program to write a semi-smart howto script. You use it like:   howto lilo      and it searches for lilo, Lilo, LILO etc in the HOWTO tree, and then finds LILO. If something is not found, it lists suggestions.    - Matt Willis    #!/bin/csh  # HOWTO Database searcher with limited smarts  setenv HOWTOBASE /usr/doc/HOWTO setenv HOWTOPATH `find $HOWTOBASE -type d -print` setenv FOUND 0  setenv NAME1 $1 setenv NAMELC `echo $1 | tr 'A-Z' 'a-z'` setenv NAMEUC `echo $1 | tr 'a-z' 'A-Z'` setenv NAMEPC `echo $1 | awk '{print toupper(substr($1,1,1)) substr($1,2)}'`  foreach NAME ($NAME1 $NAMELC $NAMEUC $NAMEPC)     foreach k ($HOWTOPATH)         if (-f $k/$NAME-HOWTO) then             echo $k/$NAME-HOWTO             less -r $k/$NAME-HOWTO             setenv FOUND 1; break; break         else if (-f $k/$NAME) then             echo $k/$NAME             less -r $k/$NAME             setenv FOUND 1; break; break         else if (-f $k/$NAME-HOWTO.gz) then             echo $k/$NAME-HOWTO.gz             gunzip -c $k/$NAME-HOWTO.gz | less -r             setenv FOUND 1; break; break         else if (-f $k/$NAME.gz) then             echo $k/$NAME.gz             gunzip -c $k/$NAME.gz | less -r             setenv FOUND 1; break; break         endif     end end  if ($FOUND == 0) then     echo ""Was unable to find '$1' .. possible matches:""     # use case-insensitive name search (iname)     setenv MATCH `find $HOWTOBASE -iname ''\*$1\*'' -print`       if (""$MATCH"" == """") then         echo ""Nothing (sorry)!""     else         foreach k ($MATCH)             echo $k | sed 's/^.*\// /'         end     endif endif                     Tips in the following section are answers to questions printed in the Mail Bag column of previous issues.                      ANSWER:  Splitting big files     Wed, 04 Aug 1999 13:41:02 +0200  From: Finn Jespersen < fje@ficsgrp.com>   Laurent Mulot (Laurent.Mulot@anp.lip6.fr) wrote:    I'd like to truncate a 3MB file so that I can put it on floppy disks.  The file is already compressed. Is there a Linux instruction or a  software that can do such a thing ?       Every Linux comes with the GNU utilities. One of these is ""split"" which will do the job. Read man split or info split.    To split a file into floppy sized files     split -b1440k a_whopping_big_file chunk      which produces chunkaaa, chunkaab, chunkaac etc.    Use mcopy to copy to/from floppy. To re-create a_whopping_big_file do     cat chunk* &gr; a_whopping_big_file      Hope this helps.  Finn    Martin Benthues < na1374@fen.baynet.de>  suggests:      The required task is rather easy to be achieved if both source and target system are linux and have GNU tar installed.    Assume floppy drive is a 3.5"" drive at /dev/fd0    Copy to disk:  tar -c -f /dev/fd0 -L1440K -M        Copy from disk:  tar -x -f /dev/fd0 -L1440K -M        tar will prompt the user to enter a new disk when ever it made one full.    Note:  The floppy disks will be overwritten without warning. Any old content is lost. No useable file system is installed. The disks are treated as a ""tape"" containing a set of blocks. For any later use with an operating system (DOS, Linux) the disks need to be reformatted.    Best regards,  Martin Benthues     Brian < vocalist@home.com>  says:       Short explanation:   If you use the 'split' command, you can split a file up into chunks. Once onto a floppy, you can transport the file. When you want to reclaim the files, you can simply copy them back to hard drive and"
GX010-35-4123053	BNL Physics Computing System    Welcome to the Brookhaven National Laboratory Physics Department Computing System home page. This page has recently been updated to reflect the new hardware additions and management.       System Manager: Stephen Adler. x5682, root@physgi01 or adler@bnlku5.phy.bnl.gov      Assistant System Manager: Hyon-Joo Kehayias. x4162, root@physgi01 or kehayias@bnl.gov        The primary mission of the Physics Computing system is to service the computing needs of the High Energy and Nuclear Physics experiments not directly related to the  RHIC project .     Physics Computing Hardware:       physgi01.phy.bnl.gov        SGI Challenge S Server       1 175 MHz R4400 CPU     128 Mbytes Memory     3 SCSI Controllers     2 Ethernet Controllers     1 SA FDDI Controller         Physgi01 is setup to be an  interactive server . No batch Jobs Allowed!      physgi02.phy.bnl.gov        SGI Indigo R4000       1 100Mhz R4000 CPU     48 Mbytes Memory     1 SCSI Controler     1 Ethernet Controller     1 SA FDDI Controller         physgi03.phy.bnl.gov        SGI Challenge L Desk Side Server       8 150 MHz R4400 CPUs     256 Mbytes Memory     8 SCSI Controllers     1 Ethernet Controller     1 DA FDDI Controller         phyppro0.phy.bnl.gov      Generic Intel PC running  Linux      2 200 Mhz Pentium Pro CPUs    512Kbyte L2 cache    128 Mbytes Memory    1 SCSI controller    1 Ethernet Controller        Physgi03 is the  batch server . Submit your batch jobs to this machine.      The following are some links to new features setup on  physgi01 .     /PublicDomain        Public Domain software. (Unrelated to SQRIT)     Includes the latest version of TeX (3.1415), LaTeX2e and support software       /PrivateDomain        All licensed software which cost more than $0, will be installed under this directory tree if possible.     Currently  Mathematica  and  Frame Maker  are installed under this directory tree.       Xterminal Server        physgi01 now servers to boot Xterms       Xdm Server        How to customize your Xdm session.     How to customize your  toolchest        Software of interest  to the  physgi01  user community.     ZMAIL      is now available      To get a zmail license, you need to satisfy the following qualifications     Have physgi01f.phy.bnl.gov as your primary e-mail server.     Be either a Physics Department staff member or a visiting scientist/graduate student spending their majority of there time here in BNL doing your research work.     If you want a zmail license, the send e-mail to root@physgi01f requesting one. There are a limited number left and are being given out on a first come, first serve basis.              Other Local Documents     Important  information/announcements ( Updated Nov. 17, 1994 )     General  User Information      PHYSGI01  Operating Rules      Requesting a PHYSGI account     Weekly  PHYSGI01 Scheduling Meeting      CERN Library       New 10BaseT Ethernet Network  in Bldg. 510    Computer Security      Other BNL Resources      Offsite Resources           Stephen Adler and H. Kehayias    (Updated on Nov 15 1995)
GX042-56-12788693	"""Linux Gazette... making Linux just a little more fun! ""                 Tcd and Gtcd   by  Larry Ayers               Introduction    CD-players for Linux abound these days, with both curses-based console programs and X programs available in a variety of degrees of usefulness, complexity, and polish.  There are even command-line players, though with the current CDROM drives (with their built-in controls) a player is no longer strictly necessary.  The main advantage of using a dedicated CD-player program  is the possibility of using a database containing titles and track names, as well as play-lists, auto-repeating and other user conveniences.   Xmcd is one of the more popular X-windows players; it's a freely available program but does require the proprietary Motif libs for compilation from source, though statically-linked binaries are available.  One reason for its popularity is the internet database of CD titles and tracklists which is accessible from within the program.  This database is remarkably complete, and  once you start using it only the most obscure titles should ever have to be entered manually.  This database project has really mushroomed; originally Ti Kan (author of Xmcd) created the database format for use in his program, and distributed database files made up of user contributions.  The files began to become excessively large and cumbersome, so the idea of making them directly accessible via the internet arose.  Ti Kan recruited Steve Scherf to write a protocol which would make possible quick retrieval of individual queries, and Steve found sites which agreed to become servers.  There are now CDDB servers distributed across the planet, and the databases are even accessible from behind firewalls from many HTTP servers.  Information on incorporating the protocol into a CD-player program is available from  the cddb website ; this material is freely available, and assistance is offered for freeware and shareware developers.   Unfortunately, I never have been able to get Xmcd to work consistently on my system; there is something in the way my ATAPI drive works which causes problems.  Xmcd was originally written with SCSI drives in mind, and although ATAPI IDE drive support has been added it didn't seem to care for my drive's peculiarities.   Tcd and Gtcd    I've been using Tim Gerla's simple but useful console-mode player tcd for several months, and have become quite adept at quickly typing in disc and track information.  Recently Tim introduced a new version. and after unpacking it I was surprised and pleased to see that not only had he produced a GTK-based X version, but the program now supports the CDDB protocol.  So one day I was on the internet, downloading some beta software, and started up the new tcd version.  I was playing a disc which I hadn't entered into the program's database, and I happened to see a notice on the screen which said ""[D] Download CDDB data"".  I gave it a try, thinking that it would probably take awhile, and that the particular CD I was playing probably wasn't even listed.  Within two seconds the title and track data was displayed on the screen, which startled and impressed me.   This newly released version, 2.0b, is a beta, though I haven't encountered any but the most minor bugs.  The GTK version doubtless will be revised, as GTK is still under active development.  Here's a screenshot of the interface:       It's a nice-looking interface, with that distinctive GTK look made familiar by the Gimp.  When the CDDB button is clicked a window opens with the default server and port displayed in entry fields, which can then be edited depending on your location.  A convenient drop-down menu of track titles (invoked by clicking the  Goto  button) is a feature not found on many players.   Most of tcd's features can be found on other X-windows players, though the only others which are CDDB-enabled (as far as I know) are Xmcd and the KDE CD-player Kscd, written by Johannes Wuebben.  The last-mentioned is a very usable and well-done application, but requires the KDE and Qt libraries in order to function.  Gtcd only needs gtk+-0.99.3, which is also needed by the Gimp.   An unusual feature is the existence of both console and X executables which  share the same features, configuration, and database.  I use X about two-thirds of the time, shutting it down when I'm compiling large applications  or just writing in an editor, and it's nice to be able to use the same CD-player in each environment.   Availability    As I write this, the source and binary distributions are still in the incoming directory at  Sunsite , with the filenames prefixed by tcd-2.0b; an alternate site is  here .            Copyright © 1998, Larry Ayers    Published in Issue 26 of  Linux Gazette , March 1998"
