<?xml version='1.0' encoding='UTF-8'?>
<search_results><query id="7449">Asics GT 2000</query><engine status="OK" timestamp="2014-04-20 06:57:32" name="CiteSeerX" id="FW14-e004"/><snippets><snippet id="FW14-e004-7449-01"><link cache="FW14-topics-docs/e004/7449_01.html" timestamp="2014-04-20 06:57:34">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=BCD794233081B237683E6EC8B7EF6B7D?doi=10.1.1.335.1262&amp;rank=1</link><title>Primer3 on the WWW for general users and for biologist programmers</title><description>Primer3 on the WWW for general users and for biologist programmers

by Steve Rozen, Helen Skaletsky \- Methods Mol. Biol , 2000

"... this effect is accomplished by the values in the fields labeled Product Size Lt and Gt, Tm Difference ..."

Abstract \- Cited by 712 (1 self) \- Add to MetaCart

Designing PCR and sequencing primers are essential activities for molecular biologists around the world. This chapter assumes acquaintance with the principles and practice of PCR, as outlined in, for example, refs. 1–4. Primer3 is a computer program that suggests PCR primers for a variety of</description></snippet><snippet id="FW14-e004-7449-02"><link cache="FW14-topics-docs/e004/7449_02.html" timestamp="2014-04-20 07:00:50">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=BCD794233081B237683E6EC8B7EF6B7D?doi=10.1.1.60.6740&amp;rank=2</link><title>A Simple, Fast, and Accurate Algorithm to Estimate Large Phylogenies by . . .</title><description>A Simple, Fast, and Accurate Algorithm to Estimate Large Phylogenies by . . .

by Stephane Guindon, Olivier Gascuel , 2003

"... task, particularly because of possible local optima (Chor et al., 2000). The usual heuristic method ..."

Abstract \- Cited by 851 (14 self) \- Add to MetaCart

The increase in the number of large data sets and the complexity of current probabilistic sequence evolution models necessitates fast and reliable phylogeny reconstruction methods. We describe a new approach, based on the maximumlikelihood principle, which clearly satisfies these requirements. The core of this method is a simple hill-climbing algorithm that adjusts tree topology and branch lengths simultaneously. This algorithm starts from an initial tree built by a fast distance-based method and modifies this tree to improve its likelihood at each iteration. Due to this simultaneous adjustment of the topology and branch lengths, only a few iterations are sufficient to reach an optimum. We used extensive and realistic computer simulations to show that the topological accuracy of this new method is at least as high as that of the existing maximum-likelihood programs and much higher than the performance of distance-based and parsimony approaches. The reduction of computing time is dramatic in comparison with other maximum-likelihood packages, while the likelihood maximization ability tends to be higher. For example, only 12 min were required on a standard personal computer to analyze a data set consisting of 500 rbcL sequences with 1,428 base pairs from plant plastids, thus reaching a speed of the same order as some popular distance-based and parsimony algorithms. This new method is implemented in the PHYML program, which is freely available on our web page: http://www.lirmm.fr/w3ifa/MAAS/. [Algorithm; computer simulations; maximum likelihood; phylogeny; rbcL; RDPII project.] The size of homologous sequence data sets has increased dramatically in recent years, and many of these data sets now involve several hundreds of taxa. Moreover, current probabilist...</description></snippet><snippet id="FW14-e004-7449-03"><link cache="FW14-topics-docs/e004/7449_03.html" timestamp="2014-04-20 07:01:45">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=BCD794233081B237683E6EC8B7EF6B7D?doi=10.1.1.105.9014&amp;rank=3</link><title>An application-specific protocol architecture for wireless networks</title><description>An application-specific protocol architecture for wireless networks

by Wendi Beth Heinzelman , 2000

"... of Philosophy at the MASSACHUSETTS INSTITUTE OF TECHNOLOGY June 2000 c Wendi Beth Heinzelman, MM. All rights ..."

Abstract \- Cited by 678 (18 self) \- Add to MetaCart

Abstract not found</description></snippet><snippet id="FW14-e004-7449-04"><link cache="FW14-topics-docs/e004/7449_04.html" timestamp="2014-04-20 07:02:59">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=BCD794233081B237683E6EC8B7EF6B7D?doi=10.1.1.132.970&amp;rank=4</link><title>Search and replication in unstructured peer-to-peer networks</title><description>Search and replication in unstructured peer-to-peer networks

by Qin Lv, Pei Cao, Edith Cohen, Kai Li, Scott Shenker , 2002

"... ]. This particular graph has ff = 0:8. The graph is generated by a modifiedversion of the GT-ITM topology generator ..."

Abstract \- Cited by 515 (6 self) \- Add to MetaCart

Abstract Decentralized and unstructured peer-to-peer networks such as Gnutella are attractive for certain applicationsbecause they require no centralized directories and no precise control over network topologies and data placement. However, the flooding-based query algorithm used in Gnutella does not scale; each individual query gener-ates a large amount of traffic and, as it grows, the system quickly becomes overwhelmed with the query-induced load. This paper explores, through simulation, various alternatives to gnutella's query algorithm, data replicationmethod, and network topology. We propose a query algorithm based on multiple random walks that resolves queries almost as quickly as gnutella's flooding method while reducing the network traffic by two orders of mag-nitude in many cases. We also present a distributed replication strategy that yields close-to-optimal performance. Finally, we find that among the various network topologies we consider, uniform random graphs yield the bestperformance. 1 Introduction The computer science community has become accustomed to the Internet's continuing rapid growth, but even tosuch jaded observers the explosive increase in Peer-to-Peer (P2P) network usage has been astounding. Within a few months of Napster's [12] introduction in 1999 the system had spread widely, and recent measurement data suggeststhat P2P applications are having a very significant and rapidly growing impact on Internet traffic [11, 15]. Therefore, it is important to study the performance and scalability of these P2P networks. Currently, there are several different architectures for P2P networks:</description></snippet><snippet id="FW14-e004-7449-05"><link cache="FW14-topics-docs/e004/7449_05.html" timestamp="2014-04-20 07:07:26">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=BCD794233081B237683E6EC8B7EF6B7D?doi=10.1.1.128.4967&amp;rank=5</link><title>Active Appearance Models</title><description>Active Appearance Models

by Timothy F. Cootes, Gareth J. Edwards, Christopher J. Taylor \- IEEE Transactions on Pattern Analysis and Machine Intelligence , 1998

"... .edwards@(email omitted);. Manuscript received 5 Apr. 2000; revised 10 Nov. 2000; accepted 7 Jan. 2001. Recommended for acceptance by M ..."

Abstract \- Cited by 1488 (50 self) \- Add to MetaCart

AbstractÐWe describe a new method of matching statistical models of appearance to images. A set of model parameters control modes of shape and gray-level variation learned from a training set. We construct an efficient iterative matching algorithm by learning the relationship between perturbations in the model parameters and the induced image errors. Index TermsÐAppearance models, deformable templates, model matching. 1</description></snippet><snippet id="FW14-e004-7449-06"><link cache="FW14-topics-docs/e004/7449_06.html" timestamp="2014-04-20 07:11:58">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=BCD794233081B237683E6EC8B7EF6B7D?doi=10.1.1.32.9956&amp;rank=6</link><title>A Comparative Study on Feature Selection in Text Categorization</title><description>A Comparative Study on Feature Selection in Text Categorization

by Yiming Yang, Jan O. Pedersen , 1997

"... the set of categories in the target space. The information gain of term t is defined to be: G(t) = \Gamma ..."

Abstract \- Cited by 947 (13 self) \- Add to MetaCart

This paper is a comparative study of feature selection methods in statistical learning of text categorization. The focus is on aggressive dimensionality reduction. Five methods were evaluated, including term selection based on document frequency (DF), information gain (IG), mutual information (MI), a Ø 2 -test (CHI), and term strength (TS). We found IG and CHI most effective in our experiments. Using IG thresholding with a knearest neighbor classifier on the Reuters corpus, removal of up to 98% removal of unique terms actually yielded an improved classification accuracy (measured by average precision) . DF thresholding performed similarly. Indeed we found strong correlations between the DF, IG and CHI values of a term. This suggests that DF thresholding, the simplest method with the lowest cost in computation, can be reliably used instead of IG or CHI when the computation of these measures are too expensive. TS compares favorably with the other methods with up to 50% vocabulary redu...</description></snippet><snippet id="FW14-e004-7449-07"><link cache="FW14-topics-docs/e004/7449_07.html" timestamp="2014-04-20 07:12:29">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=BCD794233081B237683E6EC8B7EF6B7D?doi=10.1.1.138.4837&amp;rank=7</link><title>Mfold web server for nucleic acid folding and hybridization prediction</title><description>Mfold web server for nucleic acid folding and hybridization prediction

by Michael Zuker \- Nucleic Acids Res , 2003

"... the fall of 1995. DNA folding parameters were added in the spring of 1996. From 1995 until the fall of 2000 ..."

Abstract \- Cited by 632 (0 self) \- Add to MetaCart

The abbreviated name,‘mfold web server’,describes a number of closely related software applications available on the World Wide Web (WWW) for the prediction of the secondary structure of single stranded nucleic acids. The objective of this web server is to provide easy access to RNA and DNA folding and hybridization software to the scientific community at large. By making use of universally available web GUIs (Graphical User Interfaces),the server circumvents the problem of portability of this software. Detailed output,in the form of structure plots with or without reliability information,single strand frequency plots and ‘energy dot plots’, are available for the folding of single sequences. A variety of ‘bulk ’ servers give less information,but in a shorter time and for up to hundreds of sequences at once. The portal for the mfold web server is</description></snippet><snippet id="FW14-e004-7449-08"><link cache="FW14-topics-docs/e004/7449_08.html" timestamp="2014-04-20 07:17:16">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=BCD794233081B237683E6EC8B7EF6B7D?doi=10.1.1.140.3129&amp;rank=8</link><title>A Scalable Content-Addressable Network</title><description>A Scalable Content-Addressable Network

by Sylvia Ratnasamy , Paul Francis, Mark Handley, Richard Karp, Scott Shenker \- IN PROC. ACM SIGCOMM 2001 , 2001

"... . Napster was introduced in mid-1999 and, as of December 2000, the software has been down-loaded by 50 ..."

Abstract \- Cited by 2677 (32 self) \- Add to MetaCart

Hash tables – which map “keys ” onto “values” – are an essential building block in modern software systems. We believe a similar functionality would be equally valuable to large distributed systems. In this paper, we introduce the concept of a Content-Addressable Network (CAN) as a distributed infrastructure that provides hash table-like functionality on Internet-like scales. The CAN is scalable, fault-tolerant and completely self-organizing, and we demonstrate its scalability, robustness and low-latency properties through simulation.</description></snippet><snippet id="FW14-e004-7449-09"><link cache="FW14-topics-docs/e004/7449_09.html" timestamp="2014-04-20 07:22:19">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=BCD794233081B237683E6EC8B7EF6B7D?doi=10.1.1.24.482&amp;rank=9</link><title>LogP: Towards a Realistic Model of Parallel Computation</title><description>LogP: Towards a Realistic Model of Parallel Computation

by David Culler , Richard Karp , David Patterson, Abhijit Sahay, Klaus Erik Schauser, Eunice Santos, Ramesh Subramonian, Thorsten von Eicken , 1993

"... 20 0 Sun 4 260 MIPS M/120 MIPS M2000 IBM RS6000 540 1987 1988 1989 1990 1991 1992 Integer FP HP 9000 ..."

Abstract \- Cited by 497 (14 self) \- Add to MetaCart

A vast body of theoretical research has focused either on overly simplistic models of parallel computation, notably the PRAM, or overly specific models that have few representatives in the real world. Both kinds of models encourage exploitation of formal loopholes, rather than rewarding development of techniques that yield performance across a range of current and future parallel machines. This paper offers a new parallel machine model, called LogP, that reflects the critical technology trends underlying parallel computers. It is intended to serve as a basis for developing fast, portable parallel algorithms and to offer guidelines to machine designers. Such a model must strike a balance between detail and simplicity in order to reveal important bottlenecks without making analysis of interesting problems intractable. The model is based on four parameters that specify abstractly the computing bandwidth, the communication bandwidth, the communication delay, and the efficiency of coupling communication and computation. Portable parallel algorithms typically adapt to the machine configuration, in terms of these parameters. The utility of the model is demonstrated through examples that are implemented on the CM-5.</description></snippet><snippet id="FW14-e004-7449-10"><link cache="FW14-topics-docs/e004/7449_10.html" timestamp="2014-04-20 07:26:57">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=BCD794233081B237683E6EC8B7EF6B7D?doi=10.1.1.330.5275&amp;rank=10</link><title>The SGI Origin: A ccNUMA highly scalable server</title><description>The SGI Origin: A ccNUMA highly scalable server

by James Laudon, Daniel Lenoski \- In Proceedings of the 24th International Symposium on Computer Architecture (ISCA’97 , 1997

"... @(email omitted); Abstract The SGI Origin 2000 is a cache-coherent non-uniform memory access (ccNUMA) multiprocessor designed ..."

Abstract \- Cited by 435 (0 self) \- Add to MetaCart

The SGI Origin &lt;em&gt;2000&lt;/em&gt; is a cache-coherent non-uniform memory access (ccNUMA) multiprocessor designed</description></snippet></snippets></search_results>