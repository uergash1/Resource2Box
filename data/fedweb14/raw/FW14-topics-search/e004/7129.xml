<?xml version='1.0' encoding='UTF-8'?>
<search_results><query id="7129">avg home edition</query><engine status="OK" timestamp="2014-05-21 14:50:53" name="CiteSeerX" id="FW14-e004"/><snippets><snippet id="FW14-e004-7129-01"><link cache="FW14-topics-docs/e004/7129_01.html" timestamp="2014-05-21 14:50:54">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=0AF98EA6D76D894F7AE8A4A47E8A49C9?doi=10.1.1.132.970&amp;rank=1</link><title>Search and replication in unstructured peer-to-peer networks</title><description>Search and replication in unstructured peer-to-peer networks

by Qin Lv, Pei Cao, Edith Cohen, Kai Li, Scott Shenker , 2002

"... of the graphs are also summarizedin Table 2.1. #nodes total #edges avg. node degree std. dev. max degree median ..."

Abstract \- Cited by 515 (6 self) \- Add to MetaCart

Abstract Decentralized and unstructured peer-to-peer networks such as Gnutella are attractive for certain applicationsbecause they require no centralized directories and no precise control over network topologies and data placement. However, the flooding-based query algorithm used in Gnutella does not scale; each individual query gener-ates a large amount of traffic and, as it grows, the system quickly becomes overwhelmed with the query-induced load. This paper explores, through simulation, various alternatives to gnutella's query algorithm, data replicationmethod, and network topology. We propose a query algorithm based on multiple random walks that resolves queries almost as quickly as gnutella's flooding method while reducing the network traffic by two orders of mag-nitude in many cases. We also present a distributed replication strategy that yields close-to-optimal performance. Finally, we find that among the various network topologies we consider, uniform random graphs yield the bestperformance. 1 Introduction The computer science community has become accustomed to the Internet's continuing rapid growth, but even tosuch jaded observers the explosive increase in Peer-to-Peer (P2P) network usage has been astounding. Within a few months of Napster's [12] introduction in 1999 the system had spread widely, and recent measurement data suggeststhat P2P applications are having a very significant and rapidly growing impact on Internet traffic [11, 15]. Therefore, it is important to study the performance and scalability of these P2P networks. Currently, there are several different architectures for P2P networks:</description></snippet><snippet id="FW14-e004-7129-02"><link cache="FW14-topics-docs/e004/7129_02.html" timestamp="2014-05-21 14:51:06">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=0AF98EA6D76D894F7AE8A4A47E8A49C9?doi=10.1.1.22.6538&amp;rank=2</link><title>How to Model an Internetwork</title><description>How to Model an Internetwork

by Ellen Zegura, Kenneth Calvert, Samrat Bhattacharjee \- In Proceedings of IEEE INFOCOM , 1996

"... degree, 2m=n, and the number of leaves (degree = 1). Network Nodes Avg Deg Diam. Bicomp. ARPAnet 47 2 ..."

Abstract \- Cited by 676 (8 self) \- Add to MetaCart

Graphs are commonly used to model the structure of internetworks, for the study of problems ranging from routing to resource reservation. A variety of graph models are found in the literature, including regular topologies such as rings or stars, "well-known" topologies such as the original ARPAnet, and randomly generated topologies. Less common is any discussion of how closely these models correlate with real network topologies. We consider the problem of efficiently generating graph models that accurately reflect the topological properties of real internetworks. We compare properties of graphs generated using various methods with those of real internets. We also propose efficient methods for generating topologies with particular properties, including a Transit-Stub model that correlates well with Internet structure. Improved models for internetwork structure have the potential to impact the significance of simulation studies of internetworking solutions, providing basis for the validi...</description></snippet><snippet id="FW14-e004-7129-03"><link cache="FW14-topics-docs/e004/7129_03.html" timestamp="2014-05-21 14:51:28">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=0AF98EA6D76D894F7AE8A4A47E8A49C9?doi=10.1.1.105.6398&amp;rank=3</link><title>Groupware: Some issues and experiences</title><description>Groupware: Some issues and experiences

by C. A. Ellis, S. J. Gibbs, G.L. Rein \- COMMUNICATIONS OF THE ACM , 1991

"... I am alone editing in my office or home (different time). Of course, there are other dimensions ..."

Abstract \- Cited by 691 (2 self) \- Add to MetaCart

Abstract not found</description></snippet><snippet id="FW14-e004-7129-04"><link cache="FW14-topics-docs/e004/7129_04.html" timestamp="2014-05-21 14:51:48">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=0AF98EA6D76D894F7AE8A4A47E8A49C9?doi=10.1.1.44.6030&amp;rank=4</link><title>Resource Description Framework (RDF) Model and Syntax Specification</title><description>Resource Description Framework (RDF) Model and Syntax Specification

by Ora Lassila, Ralph R. Swick, World Wide, Web Consortium , 1998

"... Lassila is the creator of the resource http://www.w3.org/Home/Lassila This sentence has the following ..."

Abstract \- Cited by 746 (5 self) \- Add to MetaCart

This document is a revision of the public working draft dated 1998-08-19 incorporating suggestions received in review comments and further deliberations of the W3C RDF Model and Syntax Working Group. With the publication of this draft, the RDF Model and Syntax Specification enters "last call." The last call period will end on October 23, 1998. Comments on this specification may be sent to www-rdf-comments@w3.org. The archive of public comments is available at http://www.w3.org/Archives/Public/www-rdf-comments. Significant changes from the previous draft are highlighted in Appendix E. While we do not anticipate substantial changes, we still caution that further changes are possible. Therefore while we encourage active implementation to test this specification we also recommend that only software that can be easily field-upgraded be implemented to this specification at this time. This is a W3C Working Draft for review by W3C members and other interested parties. Publication as a working draft does not imply endorsement by the W3C membership. The RDF Model and Syntax Working Group will not allow early implementation to constrain their ability to make changes to this specification prior to final release. This is a draft document and may be updated, replaced or obsoleted by other documents at any time. It is inappropriate to cite W3C Working Drafts as other than "work in progress". This work is part of the W3C Metadata Activity.</description></snippet><snippet id="FW14-e004-7129-05"><link cache="FW14-topics-docs/e004/7129_05.html" timestamp="2014-05-21 14:52:07">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=0AF98EA6D76D894F7AE8A4A47E8A49C9?doi=10.1.1.12.3161&amp;rank=5</link><title>Optimizing Search Engines using Clickthrough Data</title><description>Optimizing Search Engines using Clickthrough Data

by Thorsten Joachims , 2002

"... .net/software.html 10\. Lagrangian Support Vector Machine Home Page http : //www.cs.wisc.edu/dmi/lsvm Figure 1: Ranking ..."

Abstract \- Cited by 834 (22 self) \- Add to MetaCart

This paper presents an approach to automatically optimizing the retrieval quality of search engines using clickthrough data. Intuitively, a good information retrieval system should present relevant documents high in the ranking, with less relevant documents following below. While previous approaches to learning retrieval functions from examples exist, they typically require training data generated from relevance judgments by experts. This makes them difficult and expensive to apply. The goal of this paper is to develop a method that utilizes clickthrough data for training, namely the query-log of the search engine in connection with the log of links the users clicked on in the presented ranking. Such clickthrough data is available in abundance and can be recorded at very low cost. Taking a Support Vector Machine (SVM) approach, this paper presents a method for learning retrieval functions. From a theoretical perspective, this method is shown to be well-founded in a risk minimization framework. Furthermore, it is shown to be feasible even for large sets of queries and features. The theoretical results are verified in a controlled experiment. It shows that the method can effectively adapt the retrieval function of a meta-search engine to a particular group of users, outperforming Google in terms of retrieval quality after only a couple of hundred training examples.</description></snippet><snippet id="FW14-e004-7129-06"><link cache="FW14-topics-docs/e004/7129_06.html" timestamp="2014-05-21 14:52:27">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=0AF98EA6D76D894F7AE8A4A47E8A49C9?doi=10.1.1.148.3671&amp;rank=6</link><title>The WEKA Data Mining Software: An Update</title><description>The WEKA Data Mining Software: An Update

by Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, Ian H. Witten

"... an artificial data source and edit data manually using a dataset editor. The second panel in the Explorer gives ..."

Abstract \- Cited by 605 (11 self) \- Add to MetaCart

More than twelve years have elapsed since the first public release of WEKA. In that time, the software has been rewritten entirely from scratch, evolved substantially and now accompanies a text on data mining [35]. These days, WEKA enjoys widespread acceptance in both academia and business, has an active community, and has been downloaded more than 1.4 million times since being placed on Source-Forge in April 2000. This paper provides an introduction to the WEKA workbench, reviews the history of the project, and, in light of the recent 3.6 stable release, briefly discusses what has been added since the last stable version (Weka 3.4) released in 2003. 1.</description></snippet><snippet id="FW14-e004-7129-07"><link cache="FW14-topics-docs/e004/7129_07.html" timestamp="2014-05-21 14:52:42">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=0AF98EA6D76D894F7AE8A4A47E8A49C9?doi=10.1.1.187.6851&amp;rank=7</link><title>The Encyclopedia of Integer Sequences</title><description>The Encyclopedia of Integer Sequences

by N. J. A. Sloane

"... that the sequences are correct. The keywords “uned” and “obsc” indicate sequences that have not yet been edited ..."

Abstract \- Cited by 631 (15 self) \- Add to MetaCart

This article gives a brief introduction to the On-Line Encyclopedia of Integer Sequences (or OEIS). The OEIS is a database of nearly 90,000 sequences of integers, arranged lexicographically. The entry for a sequence lists the initial terms (50 to 100, if available), a description, formulae, programs to generate the sequence, references, links to relevant web pages, and other</description></snippet><snippet id="FW14-e004-7129-08"><link cache="FW14-topics-docs/e004/7129_08.html" timestamp="2014-05-21 14:52:54">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=0AF98EA6D76D894F7AE8A4A47E8A49C9?doi=10.1.1.109.6332&amp;rank=8</link><title>Grouplens: Applying collaborative filtering to usenet news</title><description>Grouplens: Applying collaborative filtering to usenet news

by Joseph A. Konstan, Bradley N. Miller, David Maltz, Jonathan L. Herlocker, Lee R. Gordon, John Riedl, High Volume \- Communications of the ACM , 1997

"... , working with Usenet news raised research problems. Two Avg 0.49 0.05 0.41 Pers 0.62 0.33 0.55 Table 2 ..."

Abstract \- Cited by 590 (15 self) \- Add to MetaCart

a collaborative filtering system for Usenet news—a high-volume, high-turnover discussion list service on the Internet. Usenet newsgroups—the individual discussion lists—may carry hundreds of messages each day. While in theory the newsgroup organization allows readers to select the content that most interests them, in practice most newsgroups carry a wide enough spread of messages to make most individuals consider Usenet news to be a high noise information resource. Furthermore, each user values a different set of messages. Both taste and prior knowledge are major factors in evaluating news articles. For example, readers of the rec.humor newsgroup, a group designed for jokes and other humorous postings, value articles based on whether they perceive them to be funny. Readers of technical groups, such as comp.lang.c� � value articles based</description></snippet><snippet id="FW14-e004-7129-09"><link cache="FW14-topics-docs/e004/7129_09.html" timestamp="2014-05-21 14:53:14">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=0AF98EA6D76D894F7AE8A4A47E8A49C9?doi=10.1.1.115.3829&amp;rank=9</link><title>DSR: The Dynamic Source Routing Protocol for Multi-Hop Wireless Ad Hoc Networks</title><description>DSR: The Dynamic Source Routing Protocol for Multi-Hop Wireless Ad Hoc Networks

by David B. Johnson, David A. Maltz, Josh Broch \- In Ad Hoc Networking, edited by Charles E. Perkins, Chapter 5 , 2001

"... is known in the ad hoc network as the node’s home address, as this address would typically be the address ..."

Abstract \- Cited by 505 (9 self) \- Add to MetaCart

The Dynamic Source Routing protocol (DSR) is a simple and efficient routing protocol designed specifically for use in multi-hop wireless ad hoc networks of mobile nodes. DSR allows the network to be completely self-organizing and self-configuring, without the need for any existing network infrastructure or administration. The protocol is composed of the two mechanisms of Route Discovery and Route Maintenance, which work together to allow nodes to discover and maintain source routes to arbitrary destinations in the ad hoc network. The use of source routing allows packet routing to be trivially loop-free, avoids the need for up-to-date routing information in the intermediate nodes through which packets are forwarded, and allows nodes forwarding or overhearing packets to cache the routing information in them for their own future use. All aspects of the protocol operate entirely on-demand, allowing the routing packet overhead of DSR to scale automatically to only that needed to react to changes in the routes currently in use. We have evaluated the operation of DSR through detailed simulation on a variety of movement and communication patterns, and through implementation and significant experimentation in a physical outdoor ad hoc networking testbed we have constructed in Pittsburgh, and have demonstrated the excellent performance of the protocol. In this chapter, we describe the design of DSR and provide a summary of some of our simulation and testbed implementation results for the protocol. 1</description></snippet><snippet id="FW14-e004-7129-10"><link cache="FW14-topics-docs/e004/7129_10.html" timestamp="2014-05-21 14:53:35">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=0AF98EA6D76D894F7AE8A4A47E8A49C9?doi=10.1.1.29.5833&amp;rank=10</link><title>Context-Aware Computing Applications</title><description>Context-Aware Computing Applications

by Bill N. Schilit , Norman Adams, Roy Want \- IN PROCEEDINGS OF THE WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS , 1994

"... and locations covering the office, meeting room, home, airport, hotel, classroom, market, bus, etc. Users might ..."

Abstract \- Cited by 659 (4 self) \- Add to MetaCart

This paper describes software that examines and reacts to an individual's changing context. Such software can promote and mediate people's interactions with devices, computers, and other people, and it can help navigate unfamiliar places. We believe that a limited amount of information covering a person's proximate environment is most important for this form of computing since the interesting part of the world around us is what we can see, hear, and touch. In this paper we define context-aware computing, and describe four categories of context-aware applications: proximate selection, automatic contextual reconfiguration, contextual information and commands, and context-triggered actions. Instances of these application types have been prototyped on the PARCTAB, a wireless, palm-sized computer.</description></snippet></snippets></search_results>