<?xml version='1.0' encoding='UTF-8'?>
<search_results><query id="7024">reinforcement learning</query><engine status="OK" timestamp="2014-04-18 17:32:16" name="CiteSeerX" id="FW14-e004"/><snippets><snippet id="FW14-e004-7024-01"><link cache="FW14-topics-docs/e004/7024_01.html" timestamp="2014-04-18 17:32:17">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=6DD8117E2A94F790380A4880ED4B442E?doi=10.1.1.124.1600&amp;rank=1</link><title>Reinforcement Learning</title><description>Reinforcement Learning

by Richard S. Sutton, Presented Pirooz Chubak, Dyna Architecture, Dyna Architecture , 1998

"... ﻿Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic ..."

Abstract \- Cited by 847 (7 self) \- Add to MetaCart

for all moves and compile its results into a set of rapid reactions (Reactive Systems) � It should &lt;em&gt;Learn&lt;/em&gt; a</description></snippet><snippet id="FW14-e004-7024-02"><link cache="FW14-topics-docs/e004/7024_02.html" timestamp="2014-04-18 17:33:17">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=6DD8117E2A94F790380A4880ED4B442E?doi=10.1.1.134.2462&amp;rank=2</link><title>Reinforcement learning: a survey</title><description>Reinforcement learning: a survey

by Leslie Pack Kaelbling, Michael L. Littman, Andrew W. Moore \- Journal of Artificial Intelligence Research , 1996

"... /96 Reinforcement Learning: A Survey Leslie Pack Kaelbling lpk@(email omitted); Michael L. Littman mlittman ..."

Abstract \- Cited by 1298 (23 self) \- Add to MetaCart

This paper surveys the field of &lt;em&gt;reinforcement&lt;/em&gt; &lt;em&gt;learning&lt;/em&gt; from a computer-science perspective</description></snippet><snippet id="FW14-e004-7024-03"><link cache="FW14-topics-docs/e004/7024_03.html" timestamp="2014-04-18 17:34:26">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=6DD8117E2A94F790380A4880ED4B442E?doi=10.1.1.32.7692&amp;rank=3</link><title>Reinforcement Learning I: Introduction</title><description>Reinforcement Learning I: Introduction

by Richard S. Sutton, Andrew G. Barto , 1998

"... Course Notes Reinforcement Learning I: Introduction Richard S. Sutton and Andrew G. Barto c fl ..."

Abstract \- Cited by 3760 (98 self) \- Add to MetaCart

In which we try to give a basic intuitive sense of what &lt;em&gt;reinforcement&lt;/em&gt; &lt;em&gt;learning&lt;/em&gt; is and how</description></snippet><snippet id="FW14-e004-7024-04"><link cache="FW14-topics-docs/e004/7024_04.html" timestamp="2014-04-18 17:35:35">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=6DD8117E2A94F790380A4880ED4B442E?doi=10.1.1.135.717&amp;rank=4</link><title>Markov games as a framework for multi-agent reinforcement learning</title><description>Markov games as a framework for multi-agent reinforcement learning

by Michael L. Littman \- IN PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING , 1994

"... ﻿Markov games as a framework for multi-agent reinforcement learning Michael L. Littman Brown ..."

Abstract \- Cited by 500 (10 self) \- Add to MetaCart

In the Markov decision process (MDP) formalization of &lt;em&gt;reinforcement&lt;/em&gt; &lt;em&gt;learning&lt;/em&gt;, a single adaptive</description></snippet><snippet id="FW14-e004-7024-05"><link cache="FW14-topics-docs/e004/7024_05.html" timestamp="2014-04-18 17:36:42">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=6DD8117E2A94F790380A4880ED4B442E?doi=10.1.1.43.4327&amp;rank=5</link><title>Predicting How People Play Games: Reinforcement Learning . . .</title><description>Predicting How People Play Games: Reinforcement Learning . . .

by Ido Erev, Alvin E. Roth \- AMERICAN ECONOMIC REVIEW , 1998

"... ﻿i Predicting How People Play Games: Reinforcement Learning i Experimental Games with Unique, Mixed ..."

Abstract \- Cited by 415 (21 self) \- Add to MetaCart

Abstract not found</description></snippet><snippet id="FW14-e004-7024-06"><link cache="FW14-topics-docs/e004/7024_06.html" timestamp="2014-04-18 17:37:34">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=6DD8117E2A94F790380A4880ED4B442E?doi=10.1.1.19.8208&amp;rank=6</link><title>Motivated Reinforcement Learning</title><description>Motivated Reinforcement Learning

by Peter Dayan , 2001

"... Motivated Reinforcement Learning Peter Dayan Gatsby Computational Neuroscience Unit 17 Queen ..."

Abstract \- Cited by 252 (9 self) \- Add to MetaCart

The standard &lt;em&gt;reinforcement&lt;/em&gt; &lt;em&gt;learning&lt;/em&gt; view of the involvement of neuromodulatory systems</description></snippet><snippet id="FW14-e004-7024-07"><link cache="FW14-topics-docs/e004/7024_07.html" timestamp="2014-04-18 17:38:24">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=6DD8117E2A94F790380A4880ED4B442E?doi=10.1.1.105.1944&amp;rank=7</link><title>Reinforcement learning with hierarchies of machines</title><description>Reinforcement learning with hierarchies of machines

by Ronald Parr, Stuart Russell \- Advances in Neural Information Processing Systems 10 , 1998

"... ﻿Reinforcement Learning with Hierarchies of Machines   Ronald Parr and Stuart Russell Computer ..."

Abstract \- Cited by 240 (9 self) \- Add to MetaCart

We present a new approach to &lt;em&gt;reinforcement&lt;/em&gt; &lt;em&gt;learning&lt;/em&gt; in which the policies considered</description></snippet><snippet id="FW14-e004-7024-08"><link cache="FW14-topics-docs/e004/7024_08.html" timestamp="2014-04-18 17:39:11">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=6DD8117E2A94F790380A4880ED4B442E?doi=10.1.1.32.8206&amp;rank=8</link><title>Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition</title><description>Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition

by Thomas G. Dietterich \- Journal of Artificial Intelligence Research , 2000

"... /00 Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition Thomas G. Dietterich tgd ..."

Abstract \- Cited by 367 (6 self) \- Add to MetaCart

This paper presents a new approach to hierarchical &lt;em&gt;reinforcement&lt;/em&gt; &lt;em&gt;learning&lt;/em&gt; based on decomposing</description></snippet><snippet id="FW14-e004-7024-09"><link cache="FW14-topics-docs/e004/7024_09.html" timestamp="2014-04-18 17:40:10">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=6DD8117E2A94F790380A4880ED4B442E?doi=10.1.1.41.7513&amp;rank=9</link><title>Algorithms for Inverse Reinforcement Learning</title><description>Algorithms for Inverse Reinforcement Learning

by Andrew Y. Ng, Stuart Russell \- in Proc. 17th International Conf. on Machine Learning , 2000

"... Algorithms for Inverse Reinforcement Learning Andrew Y. Ng ang@(email omitted); Stuart Russell ..."

Abstract \- Cited by 193 (5 self) \- Add to MetaCart

This paper addresses the problem of inverse &lt;em&gt;reinforcement&lt;/em&gt; &lt;em&gt;learning&lt;/em&gt; (IRL) in Markov decision</description></snippet><snippet id="FW14-e004-7024-10"><link cache="FW14-topics-docs/e004/7024_10.html" timestamp="2014-04-18 17:41:21">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=6DD8117E2A94F790380A4880ED4B442E?doi=10.1.1.146.4070&amp;rank=10</link><title>Policy Gradient Methods for Reinforcement Learning with Function Approximation</title><description>Policy Gradient Methods for Reinforcement Learning with Function Approximation

by Richard S. Sutton, David Mcallester, Satinder Singh, Yishay Mansour , 1999

"... Gradient Methods for Reinforcement Learning with Function Approximation Richard S. Sutton, David Mc ..."

Abstract \- Cited by 319 (18 self) \- Add to MetaCart

Function approximation is essential to &lt;em&gt;reinforcement&lt;/em&gt; &lt;em&gt;learning&lt;/em&gt;, but the standard approach</description></snippet></snippets></search_results>