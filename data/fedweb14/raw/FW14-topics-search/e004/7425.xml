<?xml version='1.0' encoding='UTF-8'?>
<search_results><query id="7425">coloring picture cars</query><engine status="OK" timestamp="2014-04-19 21:53:00" name="CiteSeerX" id="FW14-e004"/><snippets><snippet id="FW14-e004-7425-01"><link cache="FW14-topics-docs/e004/7425_01.html" timestamp="2014-04-19 21:53:02">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=72111F5FA6FF23F53CB19E7ECCAA01ED?doi=10.1.1.113.7132&amp;rank=1</link><title>Matching words and pictures</title><description>Matching words and pictures

by Kobus Barnard, Pinar Duygulu, David Forsyth, Nando De Freitas, David M. Blei, Michael I. Jordan \- JOURNAL OF MACHINE LEARNING RESEARCH , 2003

"... Words and Pictures Kobus Barnard KOBUS@(email omitted); Computer Science Department University of Arizona ..."

Abstract \- Cited by 512 (37 self) \- Add to MetaCart

We present a new approach for modeling multi-modal data sets, focusing on the specific case of segmented images with associated text. Learning the joint distribution of image regions and words has many applications. We consider in detail predicting words associated with whole images (auto-annotation) and corresponding to particular image regions (region naming). Auto-annotation might help organize and access large collections of images. Region naming is a model of object recognition as a process of translating image regions to words, much as one might translate from one language to another. Learning the relationships between image regions and semantic correlates (words) is an interesting example of multi-modal data mining, particularly because it is typically hard to apply data mining techniques to collections of images. We develop a number of models for the joint distribution of image regions and words, including several which explicitly learn the correspondence between regions and words. We study multi-modal and correspondence extensions to Hofmann’s hierarchical clustering/aspect model, a translation model adapted from statistical machine translation (Brown et al.), and a multi-modal extension to mixture of latent Dirichlet allocation</description></snippet><snippet id="FW14-e004-7425-02"><link cache="FW14-topics-docs/e004/7425_02.html" timestamp="2014-04-19 21:54:31">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=72111F5FA6FF23F53CB19E7ECCAA01ED?doi=10.1.1.132.5942&amp;rank=2</link><title>Color indexing</title><description>Color indexing

by Michael J. Swain, Dana H. Ballard \- International Journal of Computer Vision , 1991

"... ﻿Color Indexing MICHAEL J. SWAIN Department of Computer Science, University of Chicago, Chicago, IL ..."

Abstract \- Cited by 1324 (24 self) \- Add to MetaCart

fundamental goals are determin-ing the location of a known object. &lt;em&gt;Color&lt;/em&gt; can be successfully used for both</description></snippet><snippet id="FW14-e004-7425-03"><link cache="FW14-topics-docs/e004/7425_03.html" timestamp="2014-04-19 21:56:03">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=72111F5FA6FF23F53CB19E7ECCAA01ED?doi=10.1.1.176.7884&amp;rank=3</link><title>The JPEG still picture compression standard</title><description>The JPEG still picture compression standard

by Gregory K. Wallace \- Communications of the ACM , 1991

"... directly. A digitized version of a single, color picture at TV resolution contains on the order of one ..."

Abstract \- Cited by 864 (0 self) \- Add to MetaCart

compression standard for continuous-tone still images, both grayscale and &lt;em&gt;color&lt;/em&gt;. JPEG’s proposed standard aims</description></snippet><snippet id="FW14-e004-7425-04"><link cache="FW14-topics-docs/e004/7425_04.html" timestamp="2014-04-19 21:56:57">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=72111F5FA6FF23F53CB19E7ECCAA01ED?doi=10.1.1.126.2091&amp;rank=4</link><title>Bilateral Filtering for Gray and Color Images</title><description>Bilateral Filtering for Gray and Color Images

by C. Tomasi , 1998

"... ﻿Bilateral Filtering for Gray and Color Images C. Tomasi * Computer Science Pepartment Stanford ..."

Abstract \- Cited by 662 (2 self) \- Add to MetaCart

gray levels or &lt;em&gt;colors&lt;/em&gt; based on both their geometric closeness and their photometric similariv</description></snippet><snippet id="FW14-e004-7425-05"><link cache="FW14-topics-docs/e004/7425_05.html" timestamp="2014-04-19 21:57:53">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=72111F5FA6FF23F53CB19E7ECCAA01ED?doi=10.1.1.136.4303&amp;rank=5</link><title>Content-based image retrieval at the end of the early years</title><description>Content-based image retrieval at the end of the early years

by Arnold W. M. Smeulders, Marcel Worring, Simone Santini, Amarnath Gupta, Ramesh Jain \- IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE , 2000

"... of pictures, the role of semantics, and the sensory gap. Subsequent sections discuss computational steps ..."

Abstract \- Cited by 1135 (19 self) \- Add to MetaCart

with discussing the working conditions of content-based retrieval: patterns of use, types of &lt;em&gt;pictures&lt;/em&gt;, the role</description></snippet><snippet id="FW14-e004-7425-06"><link cache="FW14-topics-docs/e004/7425_06.html" timestamp="2014-04-19 21:59:41">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=72111F5FA6FF23F53CB19E7ECCAA01ED?doi=10.1.1.132.8548&amp;rank=6</link><title>Recognition-by-components: A theory of human image understanding</title><description>Recognition-by-components: A theory of human image understanding

by Irving Biederman \- Psychological Review , 1987

"... , or extensively degraded. The results from experiments on the perception of briefly presented pictures by human ..."

Abstract \- Cited by 726 (11 self) \- Add to MetaCart

presented &lt;em&gt;pictures&lt;/em&gt; by human observers provide empirical support for the theory. Any single object can</description></snippet><snippet id="FW14-e004-7425-07"><link cache="FW14-topics-docs/e004/7425_07.html" timestamp="2014-04-19 22:01:23">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=72111F5FA6FF23F53CB19E7ECCAA01ED?doi=10.1.1.10.8251&amp;rank=7</link><title>Display of Surfaces from Volume Data</title><description>Display of Surfaces from Volume Data

by Marc Levoy , 1988

"... by directly shading each sample and projecting it onto the picture plane. Surface shading calculations ..."

Abstract \- Cited by 724 (10 self) \- Add to MetaCart

is not required. Images are formed by directly shading each sample and projecting it onto the &lt;em&gt;picture&lt;/em&gt; plane</description></snippet><snippet id="FW14-e004-7425-08"><link cache="FW14-topics-docs/e004/7425_08.html" timestamp="2014-04-19 22:02:10">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=72111F5FA6FF23F53CB19E7ECCAA01ED?doi=10.1.1.20.1596&amp;rank=8</link><title>Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope</title><description>Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope

by Aude Oliva, Antonio Torralba \- International Journal of Computer Vision , 2001

"... textural, spatial and color properties (e.g., sport cars, sunsets). But their method, based as it is on a ..."

Abstract \- Cited by 666 (62 self) \- Add to MetaCart

In this paper, we propose a computational model of the recognition of real world scenes that bypasses the segmentation and the processing of individual objects or regions. The procedure is based on a very low dimensional representation of the scene, that we term the Spatial Envelope. We propose a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) that represent the dominant spatial structure of a scene. Then, we show that these dimensions may be reliably estimated using spectral and coarsely localized information. The model generates a multidimensional space in which scenes sharing membership in semantic categories (e.g., streets, highways, coasts) are projected closed together. The performance of the spatial envelope model shows that specific information about object shape or identity is not a requirement for scene categorization and that modeling a holistic representation of the scene informs about its probable semantic category.</description></snippet><snippet id="FW14-e004-7425-09"><link cache="FW14-topics-docs/e004/7425_09.html" timestamp="2014-04-19 22:03:41">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=72111F5FA6FF23F53CB19E7ECCAA01ED?doi=10.1.1.120.4505&amp;rank=9</link><title>Data cube: A relational aggregation operator generalizing group-by, cross-tab, and sub-totals</title><description>Data cube: A relational aggregation operator generalizing group-by, cross-tab, and sub-totals

by Jim Gray, Adam Bosworth, Andrew Layman, Don Reichart, Hamid Pirahesh , 1996

"... . For example, in trying to analyze car sales, we might focus on the role of model, year and color of the cars ..."

Abstract \- Cited by 693 (7 self) \- Add to MetaCart

Abstract. Data analysis applications typically aggregate data across many dimensions looking for anomalies or unusual patterns. The SQL aggregate functions and the GROUP BY operator produce zero-dimensional or one-dimensional aggregates. Applications need the N-dimensional generalization of these operators. This paper defines that operator, called the data cube or simply cube. The cube operator generalizes the histogram, crosstabulation, roll-up, drill-down, and sub-total constructs found in most report writers. The novelty is that cubes are relations. Consequently, the cube operator can be imbedded in more complex non-procedural data analysis programs. The cube operator treats each of the N aggregation attributes as a dimension of N-space. The aggregate of a particular set of attribute values is a point in this space. The set of points forms an N-dimensional cube. Super-aggregates are computed by aggregating the N-cube to lower dimensional spaces. This paper (1) explains the cube and roll-up operators, (2) shows how they fit in SQL, (3) explains how users can define new aggregate functions for cubes, and (4) discusses efficient techniques to compute the cube. Many of these features are being added to the SQL Standard.</description></snippet><snippet id="FW14-e004-7425-10"><link cache="FW14-topics-docs/e004/7425_10.html" timestamp="2014-04-19 22:07:02">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=72111F5FA6FF23F53CB19E7ECCAA01ED?doi=10.1.1.103.9186&amp;rank=10</link><title>Semantic matching</title><description>Semantic matching

by Fausto Giunchiglia, Fausto Giunchiglia, Mikalai Yatskevich, Mikalai Yatskevich, Enrico Giunchiglia, Enrico Giunchiglia \- The Knowledge Engineering Review , 2007

"... label formulas in the concept path to the root [5]. For example, the concept C2 for the node Pictures ..."

Abstract \- Cited by 528 (58 self) \- Add to MetaCart

Abstract. We think of Match as an operator which takes two graph-like structures and produces a mapping between semantically related nodes. We concentrate on classifications with tree structures. In semantic matching, correspondences are discovered by translating the natural language labels of nodes into propositional formulas, and by codifying matching into a propositional unsatisfiability problem. We distinguish between problems with conjunctive formulas and problems with disjunctive formulas, and present various optimizations. For instance, we propose a linear time algorithm which solves the first class of problems. According to the tests we have done so far, the optimizations substantially improve the time performance of the system. 1.</description></snippet></snippets></search_results>