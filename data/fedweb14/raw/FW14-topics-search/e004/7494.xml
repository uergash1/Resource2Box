<?xml version='1.0' encoding='UTF-8'?>
<search_results><query id="7494">cartoons festival</query><engine status="OK" timestamp="2014-04-21 00:19:15" name="CiteSeerX" id="FW14-e004"/><snippets><snippet id="FW14-e004-7494-01"><link cache="FW14-topics-docs/e004/7494_01.html" timestamp="2014-04-21 00:19:17">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=3AE0DCF227EA7236E819ECD33790DC2B?doi=10.1.1.411.4901&amp;rank=1</link><title>Project</title><description>Project

by Mary Hillis, Carla Raguseo

"... ﻿September 2008 Volume 12, Number 2 On the Internet: Cartoon Festival: An International Digital ..."

Abstract \- Add to MetaCart

&lt;carlaraguseo gmail.com&gt; Through a recent Learning with Computers (LwC) &lt;em&gt;Cartoon&lt;/em&gt; &lt;em&gt;Festival&lt;/em&gt;,</description></snippet><snippet id="FW14-e004-7494-02"><link cache="FW14-topics-docs/e004/7494_02.html" timestamp="2014-04-21 00:23:31">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=3AE0DCF227EA7236E819ECD33790DC2B?doi=10.1.1.30.7806&amp;rank=2</link><title>A Formal Framework for Linguistic Annotation</title><description>A Formal Framework for Linguistic Annotation

by Steven Bird, Mark Liberman \- Speech Communication , 2000

"... , to annotated ethnographic materials, to cartoon sound tracks. There have been many independent efforts ..."

Abstract \- Cited by 125 (22 self) \- Add to MetaCart

`Linguistic annotation' covers any descriptive or analytic notations applied to raw language data. The basic data may be in the form of time functions -- audio, video and/or physiological recordings -- or it may be textual. The added notations may include transcriptions of all sorts (from phonetic features to discourse structures), part-of-speech and sense tagging, syntactic analysis, `named entity' identification, co-reference annotation, and so on. While there are several ongoing efforts to provide formats and tools for such annotations and to publish annotated linguistic databases, the lack of widely accepted standards is becoming a critical problem. Proposed standards, to the extent they exist, have focused on file formats. This paper focuses instead on the logical structure of linguistic annotations. We survey a wide variety of existing annotation formats and demonstrate a common conceptual core, the annotation graph. This provides a formal framework for constructing, mai...</description></snippet><snippet id="FW14-e004-7494-03"><link cache="FW14-topics-docs/e004/7494_03.html" timestamp="2014-04-21 00:25:25">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=3AE0DCF227EA7236E819ECD33790DC2B?doi=10.1.1.126.4522&amp;rank=3</link><title>A Teacher’s Guide to Prepare Students for the Performance of GARRY KRINSKY Toying with Science!</title><description>A Teacher’s Guide to Prepare Students for the Performance of GARRY KRINSKY Toying with Science!

by Garry Krinsky, Toying Science

"... cartoon with his animated characters and non-stop energy. Garry was an original member of the Boston ..."

Abstract \- Add to MetaCart

It has been said that GARRY KRINSKY resembles a living &lt;em&gt;cartoon&lt;/em&gt; with his animated characters and non</description></snippet><snippet id="FW14-e004-7494-04"><link cache="FW14-topics-docs/e004/7494_04.html" timestamp="2014-04-21 00:26:40">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=3AE0DCF227EA7236E819ECD33790DC2B?doi=10.1.1.13.2025&amp;rank=4</link><title>Visual Speech Synthesis by Morphing Visemes</title><description>Visual Speech Synthesis by Morphing Visemes

by Tony Ezzat, Tomaso Poggio , 1999

"... videocamera recording of a human subject, and not that of a cartoon-like human character. In addition, we ..."

Abstract \- Cited by 58 (8 self) \- Add to MetaCart

We present MikeTalk, a text-to-audiovisual speech synthesizer which converts input text into an audiovisual speech stream. MikeTalk is built using visemes, which are a small set of images spanning a large range of mouth shapes. The visemes are acquired from a recorded visual corpus of a human subject which is specifically designed to elicit one instantiation of each viseme. Using optical flow methods, correspondence from every viseme to every other viseme is computed automatically. By morphing along this correspondence, a smooth transition between viseme images may be generated. A complete visual utterance is constructed by concatenating viseme transitions. Finally, phoneme and timing information extracted from a text-to-speech synthesizer is exploited to determine which viseme transitions to use, and the rate at which the morphing process should occur. In this manner, we are able to synchronize the visual speech stream with the audio speech stream, and hence give the impression of a photorealistic talking face.</description></snippet><snippet id="FW14-e004-7494-05"><link cache="FW14-topics-docs/e004/7494_05.html" timestamp="2014-04-21 00:29:01">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=3AE0DCF227EA7236E819ECD33790DC2B?doi=10.1.1.59.2387&amp;rank=5</link><title>Touch TV: Adding Feeling to Broadcast Media</title><description>Touch TV: Adding Feeling to Broadcast Media

by Sile O'Modhrain, Ian Oakley \- in proceedings of the European Conference on Interactive Television: from Viewers to Actors , 2003

"... effects for children’s' cartoons and the automatic capture of motion data to be streamed and displayed ..."

Abstract \- Cited by 13 (2 self) \- Add to MetaCart

effects for children's' &lt;em&gt;cartoons&lt;/em&gt; and the automatic capture of motion data to be streamed and displayed</description></snippet><snippet id="FW14-e004-7494-06"><link cache="FW14-topics-docs/e004/7494_06.html" timestamp="2014-04-21 00:31:00">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=3AE0DCF227EA7236E819ECD33790DC2B?doi=10.1.1.365.4668&amp;rank=6</link><title>unknown title</title><description>unknown title

by unknown authors

"... ﻿T! COMPUTE:R-A TOED CONI'ERENCES \- Enhanr:ing cJmmUitication at a large conference festival 85 ..."

Abstract \- Add to MetaCart

\- Enhanr:ing cJmmUitication at a large conference &lt;em&gt;festival&lt;/em&gt; 85- Facill.tatin] th' · networking</description></snippet><snippet id="FW14-e004-7494-07"><link cache="FW14-topics-docs/e004/7494_07.html" timestamp="2014-04-21 00:33:13">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=3AE0DCF227EA7236E819ECD33790DC2B?doi=10.1.1.184.1330&amp;rank=7</link><title>Travel and</title><description>Travel and

by unknown authors

"... the home of the Cannes Film Festival, an annual multimedia event. The conference location is only 8 miles ..."

Abstract \- Add to MetaCart

. The Riviera is also the home of the Cannes Film &lt;em&gt;Festival&lt;/em&gt;, an annual multimedia event. The conference location</description></snippet><snippet id="FW14-e004-7494-08"><link cache="FW14-topics-docs/e004/7494_08.html" timestamp="2014-04-21 00:35:33">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=3AE0DCF227EA7236E819ECD33790DC2B?doi=10.1.1.132.9403&amp;rank=8</link><title>What voice do we expect from a synthetic character?</title><description>What voice do we expect from a synthetic character?

by João Cabral, Luís Oliveira, Guilherme Raimundo, Ana Paiva

"... and energy of the recorded speech were copied to the synthetic speech generated with a FESTIVAL-based LPC ..."

Abstract \- Cited by 2 (0 self) \- Add to MetaCart

&lt;em&gt;FESTIVAL&lt;/em&gt;-based LPC-diphone synthesizer. At the same time, the synthetic character was also animated</description></snippet><snippet id="FW14-e004-7494-09"><link cache="FW14-topics-docs/e004/7494_09.html" timestamp="2014-04-21 00:36:19">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=3AE0DCF227EA7236E819ECD33790DC2B?doi=10.1.1.105.8181&amp;rank=9</link><title>Multimodal Expression in Virtual Humans</title><description>Multimodal Expression in Virtual Humans

by Celso Melo, Ana Paiva, Avenida Prof, Cavaco Silva Taguspark

"... -deterministic expression is robotics-based procedural body animation. Vocal expression is voice synthesis, through Festival ..."

Abstract \- Cited by 1 (0 self) \- Add to MetaCart

-based procedural body animation. Vocal expression is voice synthesis, through &lt;em&gt;Festival&lt;/em&gt;, and parameterization</description></snippet><snippet id="FW14-e004-7494-10"><link cache="FW14-topics-docs/e004/7494_10.html" timestamp="2014-04-21 00:38:49">http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=3AE0DCF227EA7236E819ECD33790DC2B?doi=10.1.1.100.4202&amp;rank=10</link><title>In-situ speech visualization in real-time interactive installation and performance</title><description>In-situ speech visualization in real-time interactive installation and performance

by Golan Levin \- In Proceedings of The 3rd International Symposium on Non-Photorealistic Animation and Rendering , 2004

"... cartoon language. 3.2.2 Implementation of “RE:MARK” RE:MARK employs an elementary phoneme classifier ..."

Abstract \- Cited by 22 (1 self) \- Add to MetaCart

Although we can sense someone’s vocalizations with our ears, nose, and haptic sense, speech is invisible to us without the help of technical aids. In this paper, we present three interactive artworks which explore the question: “if we could see our speech, what might it look like? ” The artworks we present are concerned with the aesthetic implications of making the human voice visible, and were created with a particular emphasis on interaction designs that support the perception of tight spatio-temporal relationships between sound, image, and the body. We coin the term in-situ speech visualization to describe a variety of augmented-reality techniques by which graphic representations of speech can be made to appear coincident with their apparent point of origination.</description></snippet></snippets></search_results>