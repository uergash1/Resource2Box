<?xml version='1.0' encoding='UTF-8'?>
<search_results><query id="7024">reinforcement learning</query><engine status="OK" timestamp="2014-05-20 14:31:19" name="Picasa" id="FW14-e122"/><snippets><snippet id="FW14-e122-7024-01"><link>https://plus.google.com/s/reinforcement%20learning/photos/107809899089663019971/albums/6012614985284170209/6012614985257759490</link><title>Udacity's Machine Learning Course on Reinforcement Learning is live! 

Course Page: 
http://bit.ly/1jkerF5 

Class Central course page: 
http://bit.ly/1jketNc 

Description: 
Can we program machines to learn like humans? This Reinforcement Learning course will teach you the algorithms for designing self-learning agents like us! 

Reinforcement Learning is the area of Machine Learning concerned with the actions that software agents ought to take in a particular environment in order to maximize rewards. You can apply Reinforcement Learning to robot control, chess, backgammon, checkers, and other activities that a software agent can learn. Reinforcement Learning uses behaviorist psychology in order to achieve reward maximization. 

This course includes important Reinforcement Learning approaches like Markov Decision Processes and Game Theory.﻿

Meer lezen (20 regels)Minder weergeven  ·  Vertalen</title><thumb cache="FW14-topics-docs/e122/7024_01_thumb.png">https://lh5.googleusercontent.com/-i4o6ulJqRTc/U3EZeQ96swI/AAAAAAAAAbo/xB6fNA1xuuw/w426-h237/410de448-4a5c-4fb2-9a2e-c090ee6d23f5</thumb></snippet><snippet id="FW14-e122-7024-02"><link>https://plus.google.com/s/reinforcement%20learning/photos/106808239073321070854/albums/5883363324292670305/5883363329746600354?authkey=CPuEzv3esNeb0wE</link><title>Reinforcement Learning Library for Education and Research 

"The aim of the RLPy is to simplify education and research in solving Markov Decision Processes by providing a plug-n-play framework, where various components can be linked together to create experiments." 

Source: http://acl.mit.edu/RLPy/index.html 

More: http://www.mit.edu/newsoffice/2013/machine-learning-algorithm-outperforms-predecessors-0529.html﻿

Meer weergevenMinder weergeven  ·  Vertalen</title><thumb cache="FW14-topics-docs/e122/7024_02_thumb.png">https://lh3.googleusercontent.com/-JiCCmoLWOOY/UaXnxuobAaI/AAAAAAAADBw/tfH6iqrmlXs/w426-h316/newsmallBigPicture.png</thumb></snippet><snippet id="FW14-e122-7024-03"><link>https://plus.google.com/s/reinforcement%20learning/photos/102044810784044246348/albums/5870310016775899649/5870310019936372754?authkey=CPSknNONjdy3Cw&amp;sqi=107342250273636310231&amp;sqsi=0552a5d7-2ad4-49af-809f-ed7f0a2115a0</link><title>Jay Cross will explain reinforcement learning techniques to boost learners' knowledge retention on Apr 30, 2013. Don't forget to join in! https://www1.gotomeeting.com/register/171928952﻿

Meer weergevenMinder weergeven  ·  Vertalen</title><thumb cache="FW14-topics-docs/e122/7024_03_thumb.jpg">https://lh5.googleusercontent.com/-n-g2gGngqWM/UXeH3GO5SBI/AAAAAAAAAFA/cgOGgJaHt6M/w426-h385/memory%2Bdecay.jpg</thumb></snippet><snippet id="FW14-e122-7024-04"><link>https://plus.google.com/s/reinforcement%20learning/photos/107080919366485426062/albums/5657460035361031057/5657460035746761202</link><title>A new paper is now online: 

http://graphics.stanford.edu/~vladlen/publications.htm 

The paper, "Nonlinear Inverse Reinforcement Learning with Gaussian Processes", will be presented at NIPS 2011 in December (http://nips.cc/Conferences/2011/). It is coauthored with Sergey Levine and Zoran Popovic. Sergey is the lead author and the driving force behind this paper, which forms part of his dissertation research on learning behavior from demonstration. 

The paper follows our NIPS 2010 paper, which described an inverse reinforcement learning algorithm that performed feature construction and learned a nonlinear reward function for a Markov decision process from demonstrations of its optimal policy. Since human behavior is rarely optimal, our previous algorithm did not handle human demonstrations well; the optimality assumption caused it to learn overly complex reward functions that attempted to model the noise in the examples. Our new paper presents a probabilistic algorithm called GPIRL that learns a nonlinear reward function from suboptimal stochastic behavior traces. In our experiments with human demonstrations, GPIRL significantly outperformed prior inverse reinforcement learning algorithms. 

The project page, http://graphics.stanford.edu/projects/gpirl/index.htm, includes Sergey's complete source code for GPIRL, alongside several other IRL algorithms.﻿

Meer lezen (23 regels)Minder weergeven</title><thumb cache="FW14-topics-docs/e122/7024_04_thumb.png">https://lh4.googleusercontent.com/-yAcWiqn8EaI/ToNV7ZGnifI/AAAAAAAACdI/waBtHS__T1c/w426-h930/gpirl.png</thumb></snippet><snippet id="FW14-e122-7024-05"><link>https://plus.google.com/s/reinforcement%20learning/photos/116447930756811931986/albums/5909844412887292849/5909844415148283442?authkey=CK7LzvPtgrvVLg</link><title>Studies show that you will forget 50 percent of what you learn if the new knowledge and skills are not reviewed and reinforced within 24 hours. 

You need to spend 30% of your time learning and 70% practicing! 

According to Dr. Vicki Halsey, Vice President of Applied Learning for The Ken Blanchard Companies. 

Some research suggests that, without proper reinforcement, learners risk losing up to 90 percent of what they've learned before they even get back to the work environment. 

Want to do something new and be good at it? 
http://www.kenblanchard.com/Business_Leadership/Management_Leadership_Newsletter/August2013_main_article/ 

#entrepreneur   #startup   #smallbusinessmarketing  ﻿

Meer lezen (16 regels)Minder weergeven  ·  Vertalen</title><thumb cache="FW14-topics-docs/e122/7024_05_thumb.jpg">https://lh3.googleusercontent.com/-sk-iCP5S0_w/UgP8LxK9VjI/AAAAAAAAL3Y/7oCPR06Mfvo/w426-h283/learn.jpg</thumb></snippet><snippet id="FW14-e122-7024-06"><link>https://plus.google.com/s/reinforcement%20learning/photos/108244246889191224357/albums/5963402342131947873/5963402342403970754</link><title>Learning the lessons of Incentive , rewards and value of reinforcement while feeding the ducks ...﻿

Meer weergevenMinder weergeven  ·  Vertalen</title><thumb cache="FW14-topics-docs/e122/7024_06_thumb.jpg">https://lh4.googleusercontent.com/-f-FAjaiGDBk/UsJC1b-4lsI/AAAAAAAAEjk/kYH_8LzI-jU/w426-h320/13%2B-%2B1</thumb></snippet><snippet id="FW14-e122-7024-07"><link>https://plus.google.com/s/reinforcement%20learning/photos/104340176530762389758/albums/5828686331549136289/5828686336698273218?authkey=CK6LoIKusYrzyQE</link><title>#neuroscience #precommitment #impulsivity #decision_making 

Don’t let me do that! – models of precommitment 

'..In other words, the deliberative system would have insight into the expected future impulsive choice of the habitual system, and would choose to take an action leading to a situation where the habitual or Pavlovian system would not have the impulsive action available. Interestingly, explicit insight or cognitive recognition of future impulsivity is sometimes assumed to be necessary for precommitment but the extent to which precommitment depends on insight is unknown at this time..' 

Precommitment, or taking away a future choice from oneself, is a mechanism for overcoming impulsivity. Here we review recent work suggesting that precommitment can be best explained through a distributed decision-making system with multiple discounting rates. 

This model makes specific predictions about precommitment behavior and is especially interesting in light of the emerging multiple-systems view of decision-making, in which functional systems with distinct neural substrates use different computational strategies to optimize decisions. 

Given the growing consensus that impulsivity constitutes a common point of breakdown in decision-making processes, with common neural and computational mechanisms across multiple psychiatric disorders, it is useful to translate precommitment into the common language of temporal difference reinforcement learning that unites many of these behavioral and neural data. 

\- Zeb Kurth-Nelson, A. David Redish﻿

Meer lezen (29 regels)Minder weergeven  ·  Vertalen</title><thumb cache="FW14-topics-docs/e122/7024_07_thumb.png">https://lh5.googleusercontent.com/-c6GbtAb4rAw/UOOnV24SzcI/AAAAAAAAE18/qdo0vvmM1yw/w426-h523/Screenshot%2B-%2B1_2_2013%2B%252C%2B11_11_33%2BAM.png</thumb></snippet><snippet id="FW14-e122-7024-08"><link>https://plus.google.com/s/reinforcement%20learning/photos/104340176530762389758/albums/5795633986574800017/5795633991691385570</link><title>#neurobiology #social_reinforcement_delays #response_rate 

Social Reinforcement Delays in Free-Flying Honey Bees (Apis mellifera L.) 

'..The applicability of this paradigm on various human behaviors, such as incarceration seems appropriate...' 

Honey bees are a model organism for behavioral, neurobiological, and cognitive research. Many phenomena such as spatial navigation, memory, learning, and social behaviors have been investigated in honey bees. 

Further, honey bees provide a unique opportunity to study novel reinforcement contingencies, for they shuttle their reinforcing nectar to their hive and quickly return to a foraging location. 

Free-flying honey bees (Apis mellifera L.) reactions were observed when presented with varying schedules of post-reinforcement delays of 0 s, 300 s, or 600 s. 

We measured inter-visit-interval, response length, inter-response-time, and response rate. Honey bees exposed to these post-reinforcement delay intervals exhibit one of several patterns compared to groups not encountering delays, and had longer inter-visit-intervals. 

We observed no group differences in inter-response time. Honey bees with higher response rates tended to not finish the experiment. 

The removal of the delay intervals increased response rates for those subjects that completed the trials. 
\- Craig DPA, Grice JW, Varnon CA, Gibson B, Sokolowski MBC﻿

Meer lezen (29 regels)Minder weergeven  ·  Vertalen</title><thumb cache="FW14-topics-docs/e122/7024_08_thumb.png">https://lh4.googleusercontent.com/-YX9XJrzV_9w/UG46aKrxuuI/AAAAAAAABjc/4eiDfY7l0Ao/w426-h240/2012-10-05%2B09_39_15-PLOS%2BONE_%2BSocial%2BReinforcement%2BDelays%2Bin%2BFree-Flying%2BHoney%2BBees%2B%2528Apis%2Bmellifera%2B.png</thumb></snippet><snippet id="FW14-e122-7024-09"><link>https://plus.google.com/s/reinforcement%20learning/photos/115825356079649831108/albums/5985831560175524849/5985831561575216514</link><title>Approaches to Human Learning 
Facilitation: The best way to teach adults knowledge is through facilitation. Adults have varied experiences which they bring to any learning environment. A facilitator guides the learning event. Adults learn in ways different from children. Adult learning focuses on satisfying needs; adults learn what they perceive as worthwhile for them to know. 

Adults prefer to participate actively during learning events rather than sit passively and absorb information. Andragogy (adult learning) is most effective in a supportive environment in which the adult learner is encouraged to participate and they can systematically explore answers to problems and find solutions. Adults prefer learning environments where they can share their experiences as well as preserve their dignity and self-esteem. 

Pedagogy: This approach assumes learning is achieved through exposure and repetition of the subject matter…learners absorb information. In K12 and college, a pedagogical approach to delivering knowledge is used; these students aren't expected to know much about the subject and they must progress to graduate. 

K12 learning is designed so that the succeeding grades depend on assumptions about what was learned in the preceding grades. The teacher is the sender of information and the learner is the receiver. Pedagogy requires a high tolerance for ambiguity. Everyone moves at the same pace, like cattle; this is called group lock-step. 

Perhaps a better method is to assess students prior to entry into the succeeding grade. This would help to place students where they appropriately belong i.e., slower students with slower learning students and the same for the faster learning students; or maybe an appropriate mixture of both types of learners. 

Demonstration/Performance: For teaching psychomotor skills, the demonstration/performance method is used. This method provides the learners with knowledge about the task to be performed, emphasizing safety; and graded performance of the task. The instructor tells learners what they are to do, then shows them how to do it properly. 

This teaching method requires an initial demonstration of how to correctly perform the task; the learning outcome is for the learner to perform the task, modeling (mimicking) the behavior and steps observed during the demonstration. This method of instruction serves to reduce the gap between theory and practice. 

K12 and college learners get some of this teaching method in labs and technical skills courses. Working adults generally get this method of learning on the job or in specialized commercial courses and workshops. 

That which we learn to do, we learn by doing (Aristotle): Modeling behavior is how children learn to walk and other psychomotor behavior. They began observing the behavior of those within their environment at some point during infancy; they subsequently attempt modeling the behavior. They are learning and we are teaching but do not realize it. This is associated with cognitive development in children. 

Whatever is learned at an early age will be difficult for children to unlearn later during their childhood lives.  This goes for the cute behavior of toddlers that we enjoy seeing and commenting on; during other stages of childhood, the behavior may no longer be deemed 'cute' or appropriate for the child's age and development. Check with competent children behavioral experts! 

Positive reinforcement of all behavior will likely guarantee repetition of the behavior. Likewise, negative reinforcement or ignoring behavior will likely result in extinguishing the behavior. 

Teaching and Learning: Teaching and learning are two mutually dependent functions. Teachers with knowledge of the information to be learned prepare and sustain the learning environment; the learners must be motivated to learn. 

The intrinsic motivational drive, ability, readiness, and willingness of the learners to want to know or to learn the information completes the learning system. 

If a learner is not motivated, learning will not take place! This is why it’s not prudent to hold teachers accountable for 100% of student grades. Teachers can’t alter the intrinsic motivation of the students; they can't change internal drive, ability, readiness, or willingness of the students to learn. During K12 learning, perhaps the parents are in a better position to assist learners with intrinsic motivation. 

Such things as hunger, stress, abuse, lack of sleep, not studying, the home environment and so on can and do effect intrinsic motivation. Check with competent children behavioral health professionals. 
_______________ 
Adult Learning Theory and Principles (Andragogy) 
http://www.qotfc.edu.au/resource/?page=65375 

Pedagogy 
http://en.wikipedia.org/wiki/Pedagogy 

Facilitation 
http://www.croplife.com/article/24938/employee-training-the-power-of-facilitating-learning 

Human Motivation 
http://lesswrong.com/lw/71x/a_crash_course_in_the_neuroscience_of_human/ 

#ParentsTeachersTeens﻿

Meer lezen (106 regels)Minder weergeven  ·  Vertalen</title><thumb cache="FW14-topics-docs/e122/7024_09_thumb.jpg">https://lh4.googleusercontent.com/-5RZ5Ai4xkIw/UxHyF0kDNYI/AAAAAAACH8M/_Yop-gZxl0Q/w426-h283/Picture1.jpg</thumb></snippet><snippet id="FW14-e122-7024-10"><link>https://plus.google.com/s/reinforcement%20learning/photos/104340176530762389758/albums/5833629802686074929/5833629805654158130?authkey=CKGW2L2V8a3eugE</link><title>#neuroscience #motor_cortex #reward #punishment #neuroral_model 

reinforcement learning of targeted movement in a spiking neuronal model of motor cortex 

'..Both reward and punishment together were essential for learning the task. The model was able to learn a stable attractor for the target, not merely relying on metastable, ad hoc learning for performance..' 

Sensorimotor control has traditionally been considered from a control theory perspective, without relation to neurobiology. In contrast, here we utilized a spiking-neuron model of motor cortex and trained it to perform a simple movement task, which consisted of rotating a single-joint ‘‘forearm’’ to a target. 

Learning was based on a reinforcement mechanism analogous to that of the dopamine system. This provided a global reward or punishment signal in response to decreasing or increasing distance from hand to target, respectively. 

Output was partially driven by Poisson motor babbling, creating stochastic movements that could then be shaped by learning. The virtual forearm consisted of a single segment rotated around an elbow joint, controlled by flexor and extensor muscles. 

The model consisted of 144 excitatory and 64 inhibitory event-based neurons, each with AMPA, NMDA, and GABA synapses. Proprioceptive cell input to this model encoded the 2 muscle lengths. 

Plasticity was only enabled in feedforward connections between input and output excitatory units, using spike-timing-dependent eligibility traces for synaptic credit or blame assignment. Learning resulted from a global 3-valued signal: reward (+1), no learning (0), or punishment (21), corresponding to phasic increases, lack of change, or phasic decreases of dopaminergic cell firing, respectively. 

Successful learning only occurred when both reward and punishment were enabled. In this case, 5 target angles were learned successfully within 180 s of simulation time, with a median error of 8 degrees. 

Motor babbling allowed exploratory learning, but decreased the stability of the learned behavior, since the hand continued moving after reaching the target. 

Our model demonstrated that a global reinforcement signal, coupled with eligibility traces for synaptic plasticity, can train a spiking sensorimotor network to perform goal-directed motor behavior. 

\- Chadderdon GL, Neymotin SA, Kerr CC, Lytton WW﻿

Meer lezen (49 regels)Minder weergeven</title><thumb cache="FW14-topics-docs/e122/7024_10_thumb.png">https://lh5.googleusercontent.com/-htI1Roq2lvA/UPU3Zn0lqzI/AAAAAAAAFek/ohjd_909nzc/w426-h301/Screenshot%2B-%2B1_15_2013%2B%252C%2B6_55_38%2BPM.png</thumb></snippet></snippets></search_results>