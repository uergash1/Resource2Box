<search_results><query id="7130">l1 versus l2 regularization</query><engine status="OK" timestamp="2014-04-22 00:05:30" name="BigWeb" id="FW14-e200"/><snippets><snippet id="FW14-e200-7130-01"><link cache="FW14-topics-docs/e200/7130_01.pdf" timestamp="2014-04-22 00:05:30">http://cs.nyu.edu/~rostami/presentations/L1_vs_L2.pdf</link><title>L1 vs. L2 Regularization and feature selection.</title><description>Main Topics. Covering Numbers. Definition. Convergence Bounds. L1 regularized logistic regression. L1 Regression Convergence Upper Bound. Rotational&#160;...</description></snippet><snippet id="FW14-e200-7130-02"><link cache="FW14-topics-docs/e200/7130_02.pdf" timestamp="2014-04-22 00:06:14">http://ai.stanford.edu/~ang/papers/icml04-l1l2.pdf</link><title>Feature selection, L1 vs. L2 regularization, and rotational ...</title><description>A description for this result is not available because of this site's robots.txt &#8211; learn more.</description></snippet><snippet id="FW14-e200-7130-03"><link cache="FW14-topics-docs/e200/7130_03.html" timestamp="2014-04-22 00:07:56">http://www.quora.com/Machine-Learning/What-is-the-difference-between-L1-and-L2-regularization</link><title>What is the difference between L1 and L2 regularization?</title><description>Sep 29, 2013 - Practically, I think the biggest reasons for regularization are 1) to avoid overfitting by not generating high coefficients for predictors that are sparse.</description></snippet><snippet id="FW14-e200-7130-04"><link cache="FW14-topics-docs/e200/7130_04.html" timestamp="2014-04-22 00:18:58">http://metaoptimize.com/qa/questions/5205/when-to-use-l1-regularization-and-when-l2</link><title>When to use L1 regularization and when L2 ... \- MetaOptimize</title><description>As per Andrew Ng's Feature selection, l1 vs l2 regularization, and rotational invariance paper, expect l1 regularization be better than l2 regularization if you have&#160;...</description></snippet><snippet id="FW14-e200-7130-05"><link cache="FW14-topics-docs/e200/7130_05.html" timestamp="2014-04-22 00:21:31">http://en.wikipedia.org/wiki/Regularization_(mathematics)</link><title>Regularization (mathematics) - Wikipedia, the free ...</title><description>Regularization, in mathematics and statistics and particularly in the fields of .... "Stochastic gradient descent training for l1-regularized log-linear models with&#160;...</description></snippet><snippet id="FW14-e200-7130-06"><link cache="FW14-topics-docs/e200/7130_06.pdf" timestamp="2014-04-22 00:24:37">http://www.cs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2004.pdf</link><title>Machine learning methodology: Overfitting, regularization ...</title><description>L2 regularization: complexity = sum of squares of weights. Combine with ... L2 Regularization Solution .... L1 regularization leads to many zero weights (sparsity).</description></snippet><snippet id="FW14-e200-7130-07"><link cache="FW14-topics-docs/e200/7130_07.html" timestamp="2014-04-22 00:27:21">http://www.chioka.in/differences-between-l1-and-l2-as-loss-function-and-regularization/</link><title>Differences between L1 and L2 as Loss Function and ...</title><description>Dec 18, 2013 - ... of the mysterious L1 vs L2. Usually the two decisions are : 1) L1-norm vs L2-norm loss function; and 2) L1-regularization vs L2-regularization.</description></snippet><snippet id="FW14-e200-7130-08"><link cache="FW14-topics-docs/e200/7130_08.pdf" timestamp="2014-04-22 00:29:02">http://cseweb.ucsd.edu/~saul/teaching/cse291s07/L1norm.pdf</link><title>L1-norm Regularization Overview</title><description>L2-Regularization. L1-Regularization. Proposed Algorithm basics. Summary ... the vector of unknowns, and v &#8712; Rm is the noise and A &#8712; Rmxn , we wish to find&#160;...</description></snippet><snippet id="FW14-e200-7130-09"><link cache="FW14-topics-docs/e200/7130_09.pdf" timestamp="2014-04-22 00:29:28">http://cseweb.ucsd.edu/~elkan/254spring05/Hammon.pdf</link><title>Ng feature selection talk</title><description>1\. Feature selection, L1 vs. L2 regularization, and rotational invariance. Andrew Ng. ICML 2004. Presented by Paul Hammon. April 14, 2005. 2. Outline. 1.</description></snippet><snippet id="FW14-e200-7130-10"><link cache="FW14-topics-docs/e200/7130_10.html" timestamp="2014-04-22 00:31:25">http://stats.stackexchange.com/questions/4961/what-is-regularization-in-plain-english</link><title>What is regularization in plain english? - Cross Validated</title><description>Nov 27, 2010 - LASSO is another related method, but puts an L1 constraint on the size of ... For instance, on models with large coefficients (L2 regularization,&#160;...</description></snippet></snippets></search_results>