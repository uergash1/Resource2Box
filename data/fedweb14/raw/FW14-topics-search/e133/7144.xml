<?xml version='1.0' encoding='UTF-8'?>
<search_results><query id="7144">can headphones cause hearing loss</query><engine status="OK" timestamp="2014-05-20 15:27:58" name="MetaOptimize" id="FW14-e133"/><snippets><snippet id="FW14-e133-7144-01"><link cache="FW14-topics-docs/e133/7144_01.html" timestamp="2014-05-20 15:28:04">http://metaoptimize.com/qa/questions/1609/optimizing-for-loss-a-but-evaluating-on-loss-b-when-does-it-matter</link><title>Optimizing for loss A but evaluating on loss B, when does it matter?</title></snippet><snippet id="FW14-e133-7144-02"><link cache="FW14-topics-docs/e133/7144_02.html" timestamp="2014-05-20 15:28:25">http://metaoptimize.com/qa/questions/392/what-is-a-good-reference-for-understanding-surrogate-loss-functions</link><title>What is a good reference for understanding surrogate loss functions?</title></snippet><snippet id="FW14-e133-7144-03"><link cache="FW14-topics-docs/e133/7144_03.html" timestamp="2014-05-20 15:28:57">http://metaoptimize.com/qa/questions/8709/role-of-loss-function-in-acurracy-of-structured-prediction</link><title>Role of LOSS function in acurracy of structured prediction</title></snippet><snippet id="FW14-e133-7144-04"><link cache="FW14-topics-docs/e133/7144_04.html" timestamp="2014-05-20 15:29:42">http://metaoptimize.com/qa/questions/8390/comparing-regression-algorithms-optimizing-different-loss-functions</link><title>Comparing regression algorithms optimizing different loss functions</title></snippet><snippet id="FW14-e133-7144-05"><link cache="FW14-topics-docs/e133/7144_05.html" timestamp="2014-05-20 15:30:09">http://metaoptimize.com/qa/questions/8715/loss-augmented-inference-to-find-negative-examples-in-structural-svm-learning</link><title>loss augmented inference to find negative examples in structural svm learning</title></snippet><snippet id="FW14-e133-7144-06"><link cache="FW14-topics-docs/e133/7144_06.html" timestamp="2014-05-20 15:30:33">http://metaoptimize.com/qa/questions/8400/optimizing-complex-loss-functions-in-structured-prediction</link><title>Optimizing Complex Loss Functions in Structured Prediction</title></snippet><snippet id="FW14-e133-7144-07"><link cache="FW14-topics-docs/e133/7144_07.html" timestamp="2014-05-20 15:31:01">http://metaoptimize.com/qa/questions/9739/list-of-loss-functions-for-linear-models-list-of-regularization-losses</link><title>List of loss functions for linear models? List of regularization losses?</title></snippet><snippet id="FW14-e133-7144-08"><link cache="FW14-topics-docs/e133/7144_08.html" timestamp="2014-05-20 15:31:27">http://metaoptimize.com/qa/questions/13253/least-squares-vs-cross-entropy-vs-hinge-loss</link><title>least squares vs cross-entropy vs hinge loss</title></snippet><snippet id="FW14-e133-7144-09"><link cache="FW14-topics-docs/e133/7144_09.html" timestamp="2014-05-20 15:31:56">http://metaoptimize.com/qa/questions/1210/a-basic-question-about-linear-svm</link><title>A basic question about Linear SVM</title></snippet><snippet id="FW14-e133-7144-10"><link cache="FW14-topics-docs/e133/7144_10.html" timestamp="2014-05-20 15:32:25">http://metaoptimize.com/qa/questions/13366/why-should-the-reconstruction-loss-of-an-auto-encoder-be-high-on-non-training-examples</link><title>Why should the reconstruction loss of an auto encoder be HIGH on non training examples?</title></snippet></snippets></search_results>