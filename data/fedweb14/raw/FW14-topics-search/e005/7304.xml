<?xml version='1.0' encoding='UTF-8'?>
<search_results><query id="7304">carmen electra video</query><engine status="OK" timestamp="2014-05-21 15:07:17" name="CiteULike" id="FW14-e005"/><snippets><snippet id="FW14-e005-7304-01"><link cache="FW14-topics-docs/e005/7304_01.html" timestamp="2014-05-21 15:07:19">http://www.citeulike.org/user/ste07gmbh/article/2402464</link><title>Annotating News Video with Locations</title><description>The location of video scenes is an important semantic descriptor especially for broadcast news video. In this paper, we propose a learning-based approach to annotate shots of news video with locations extracted from video transcript, based on features from multiple video modalities including syntactic structure of transcript sentences, speaker identity, temporal video structure, and so on. Machine learning algorithms are adopted to combine multi-modal features to solve two sub-problems: (1) whether the location of a video shot is mentioned in the ...</description></snippet><snippet id="FW14-e005-7304-02"><link cache="FW14-topics-docs/e005/7304_02.html" timestamp="2014-05-21 15:07:45">http://www.citeulike.org/user/artm/article/1269699</link><title>Overview of the H.264/AVC video coding standard</title><description>H.264/AVC is newest video coding standard of the ITU-T Video Coding Experts Group and the ISO/IEC Moving Picture Experts Group. The main goals of the H.264/AVC standardization effort have been enhanced compression performance and provision of a "network-friendly" video representation addressing "conversational" (video telephony) and "nonconversational" (storage, broadcast, or streaming) applications. H.264/AVC has achieved a significant improvement in rate-distortion efficiency relative to existing standards. This article provides an overview of the technical features of H.264/AVC, describes profiles and applications for the ...</description></snippet><snippet id="FW14-e005-7304-03"><link cache="FW14-topics-docs/e005/7304_03.html" timestamp="2014-05-21 15:07:56">http://www.citeulike.org/user/ankurcha/article/2709844</link><title>Video retrieval using high level features: exploiting query matching and confidence-based weighting</title><description>Recent research in video retrieval has focused on automated, high-level feature indexing on shots or frames. One important application of such indexing is to support precise video retrieval. We report on extensions of this semantic indexing on news video retrieval. First, we utilize extensive query analysis to relate various high-level features and query terms by matching the textual description and context in a time-dependent manner. Second, we introduce a framework to effectively fuse the relation weights with the detectors' confidence scores. ...</description></snippet><snippet id="FW14-e005-7304-04"><link cache="FW14-topics-docs/e005/7304_04.html" timestamp="2014-05-21 15:08:20">http://www.citeulike.org/user/gphroh/article/2384883</link><title>The Use and Utility of High-Level Semantic Features in Video Retrieval</title><description>This paper investigates the applicability of high-level semantic features for video retrieval using the benchmarked data from TRECVID 2003 and 2004, addressing the contributions of features like outdoor, face, and animal in retrieval, and if users can correctly decide on which features to apply for a given need. Pooled truth data gives evidence that some topics would benefit from features. A study with 12 subjects found that people often disagree on the relevance of a feature to a particular topic, including ...</description></snippet><snippet id="FW14-e005-7304-05"><link cache="FW14-topics-docs/e005/7304_05.html" timestamp="2014-05-21 15:08:42">http://www.citeulike.org/user/anelson/article/369280</link><title>A Multiple-Hypothesis Tracking of Multiple Ground Targets</title><description>The goal of the DARPA Video Verification of Identity (VIVID) program is to develop an automated videobased ground targeting system for unmanned aerial vehicles that significantly improves operator combat efficiency and effectiveness while minimizing collateral damage. One of the key components of VIVID is the Multiple Target Tracker (MTT), whose main function is to track many ground targets simultaneously by slewing the video sensor from target to target and zooming in and out as necessary. The ... ...</description></snippet><snippet id="FW14-e005-7304-06"><link cache="FW14-topics-docs/e005/7304_06.html" timestamp="2014-05-21 15:08:53">http://www.citeulike.org/user/fujiyoshi-masaaki/article/3006008</link><title>Robust Video Fingerprinting for Content-Based Video Identification</title><description>Video fingerprints are feature vectors that uniquely characterize one video clip from another. The goal of video fingerprinting is to identify a given video query in a database (DB) by measuring the distance between the query fingerprint and the fingerprints in the DB. The performance of a video fingerprinting system, which is usually measured in terms of pairwise independence and robustness, is directly related to the fingerprint that the system uses. In this paper, a novel video fingerprinting method based on ...</description></snippet><snippet id="FW14-e005-7304-07"><link cache="FW14-topics-docs/e005/7304_07.html" timestamp="2014-05-21 15:09:21">http://www.citeulike.org/user/wmdeneve/article/2890992</link><title>A Framework for Handling Spatiotemporal Variations in Video Copy Detection</title><description>An effective video copy detection framework should be robust against spatial and temporal variations, e.g., changes in brightness and speed. To this end, a content-based approach for video copy detection is proposed. We define the problem as a partial matching problem in a probabilistic model and transform it into a shortest-path problem in a matching graph. To reduce the computation costs of the proposed framework, we introduce some methods that rapidly select key frames and candidate segments from a large amount ...</description></snippet><snippet id="FW14-e005-7304-08"><link cache="FW14-topics-docs/e005/7304_08.html" timestamp="2014-05-21 15:09:34">http://www.citeulike.org/user/p2pstreaming/article/2822354</link><title>An analytically tractable model for video conference traffic</title><description>We propose an analytically tractable approach to model compressed video traffic called C-DAR(1). The C-DAR(1) model combines an approach utilizing a discrete-time Markov chain with a continuous-time Markov chain. We show that this approach accurately models the distribution and exponential autocorrelation characteristics of video conferencing traffic. Also, we show that by comparing our analytical results against a simulation using actual video conferencing data, our model provides realistic results. In addition to presenting this new approach, we address the effects of long-range ...</description></snippet><snippet id="FW14-e005-7304-09"><link cache="FW14-topics-docs/e005/7304_09.html" timestamp="2014-05-21 15:09:55">http://www.citeulike.org/user/p2pstreaming/article/2822178</link><title>Dynamic region of interest transcoding for multipoint video conferencing</title><description>This paper presents a region of interest transcoding scheme for multipoint video conferencing to enhance visual quality. In a multipoint video conference, usually there are only one or two active conferees at one time, which are the regions of interest to the other conferees involved. We propose a dynamic sub-window skipping scheme to firstly identify the active participants from the multiple incoming encoded video streams by calculating the motion activity of each sub-window and then dynamically reduce the frame rates of ...</description></snippet><snippet id="FW14-e005-7304-10"><link cache="FW14-topics-docs/e005/7304_10.html" timestamp="2014-05-21 15:10:07">http://www.citeulike.org/user/ratulmukh/article/2831646</link><title>Overview of the Scalable Video Coding Extension of the H.264/AVC Standard</title><description>With the introduction of the H.264/AVC video coding standard, significant improvements have recently been demonstrated in video compression capability. The Joint Video Team of the ITU-T VCEG and the ISO/IEC MPEG has now also standardized a Scalable Video Coding (SVC) extension of the H.264/AVC standard. SVC enables the transmission and decoding of partial bit streams to provide video services with lower temporal or spatial resolutions or reduced fidelity while retaining a reconstruction quality that is high relative to the rate of ...</description></snippet></snippets></search_results>